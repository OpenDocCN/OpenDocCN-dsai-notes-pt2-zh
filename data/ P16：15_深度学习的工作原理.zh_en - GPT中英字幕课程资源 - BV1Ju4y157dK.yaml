- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P16：15_深度学习的工作原理.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P16：15_深度学习的工作原理.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
- en: How does deep learning work？
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是如何工作的？
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_1.png)'
- en: So we've talked about the notion that we can take raw unstructured data and
    we can directly。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过可以直接使用原始非结构化数据的概念。
- en: start to make predictions using deep learning。 We don't have to go through this
    feature engineering step。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用深度学习进行预测。我们不需要经历这个特征工程步骤。
- en: We don't have to convert it to columns or individual variables or features that
    can be。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要将其转换为列或单独的变量或特征。
- en: used for prediction。 Unstructured data， we can start with its raw digital representation。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 用于预测。非结构化数据，我们可以从其原始数字表示开始。
- en: The first thing is that any unstructured data we're talking about text， sound，
    images， they。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，任何我们谈论的非结构化数据，包括文本、声音、图像，它们。
- en: can always be represented in some digital form。 So it might be a spectrogram
    if it's audio。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 始终可以以某种数字形式表示。因此，如果是音频，它可能是一个频谱图。
- en: It's an image data can be represented by pixels。 A set of text can be represented
    by vectors of words and so all of these different types。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数据可以通过像素表示。一组文本可以通过单词的向量表示，因此所有这些不同类型。
- en: of data can be represented in some kind of raw native digital format。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以以某种原始本地数字格式表示。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_3.png)'
- en: The data are then pre-processed in some way to make it standardized for the
    prediction， task。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据随后以某种方式预处理，使其在预测任务中标准化。
- en: Once the data is standardized， it's then passed into something called a neural
    network。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据标准化，就会传递到一种叫做神经网络的东西中。
- en: The reason we call this a neural network is that people have found that this
    is modeled。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之所以称之为神经网络，是因为人们发现这是基于模型的。
- en: essentially after a neuron。 So a neuron in the brain takes in a number of inputs
    and then depending on the value of。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上是继承自神经元。因此，大脑中的神经元接收多个输入，然后根据。
- en: those inputs it decides whether to fire or not。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些输入决定是否触发输出。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_5.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_5.png)'
- en: Very similarly a neural network in deep learning works very similarly in some
    way。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 非常类似地，深度学习中的神经网络在某种方式上非常相似。
- en: So a neural network that forms the basis of deep learning， the data， this raw
    native data。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，构成深度学习基础的神经网络，数据，这些原始的本地数据。
- en: that we were talking about forms the input layer， it comes into the neural network。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论的那个形成输入层，进入神经网络。
- en: And just like a neuron， neural networks basically are looking at the data that
    are coming in。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 就像神经元一样，神经网络基本上在查看输入的数据。
- en: and then depending on the value of that data， it's deciding whether or not to
    fire its output。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然后根据数据的值，决定是否触发其输出。
- en: or set its output at a certain level。 So you can imagine a neural network as
    a series of decision points or nodes or neurons and。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 或在某个水平上设置其输出。因此，你可以将神经网络想象为一系列决策点或节点或神经元。
- en: the input data are coming in one side。 The neural network is composed of a series
    of layers that are just looking at sort of。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据从一侧进入。神经网络由一系列层组成，这些层在进行某种观察。
- en: all different combinations of the input data。 So rather than the input data
    having to be converted into features。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所有输入数据的不同组合。因此，输入数据不需要转换为特征。
- en: the layers in a neural， network are basically automatically trying to figure
    out what it is about the raw unstructured。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的层基本上是自动尝试弄清楚原始非结构化数据的特征。
- en: data that can be combined and recombined to form the most effective features
    for prediction。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可以组合和重新组合的数据，以形成最有效的特征用于预测。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_7.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_7.png)'
- en: the most effective combinations for predictions。 So the way this happens is
    that engineers choose a loss function or a cost function to。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最有效的预测组合。因此，这种情况的发生是工程师选择一个损失函数或成本函数来。
- en: compare against the training labels。 That's just a way of saying how close are
    we to predicting the right answers。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与训练标签进行比较。这只是说我们离预测正确答案有多近的一种方式。
- en: So you have training data in this case， this is data where you know the right
    answers。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这种情况下，你有训练数据，这是你知道正确答案的数据。
- en: So let's go back to our medical diagnostic image examples。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的医疗诊断图像示例。
- en: So imagine you have a lot of data on images of people's medical images and you
    have data。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你拥有大量关于人们医疗图像的数据。
- en: on the right answers， which might mean you have data on whether or not the person
    or。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 关于正确答案的数据，这可能意味着你有关于这个人是否有疾病的数据。
- en: the patient actually had the condition as determined by a doctor。 So you have
    the medical data。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 患者的确有该疾病，这是医生确定的。因此你有医疗数据。
- en: the medical images and whether or not the person actually， had the condition
    or not。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗图像以及这个人是否实际上有该疾病。
- en: So the neural network is going to try to do is take in this image data， the
    neural， the。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，神经网络将尝试处理这些图像数据。
- en: layers in the neural network itself are going to try to find the right combinations
    of that。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的各层将尝试找到正确的组合。
- en: raw pixel data to make a prediction。 That prediction is going to be whether
    or not the person had the condition。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原始像素数据进行预测。这个预测将是这个人是否有该疾病。
- en: Since we already know the right answer from the training data， we can start
    to compare。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经知道训练数据中的正确答案，我们可以开始比较。
- en: how often do we make the right decision and how often is it wrong。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们多么频繁地做出正确决策，以及多么频繁地出错。
- en: And this is that loss function or a cost function。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是损失函数或成本函数。
- en: This is telling us how far we are from the truth as represented by the data
    we have to。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们与我们拥有的数据所代表的真实情况之间的距离。
- en: train the model。 And so what a neural network is going to do then is start to
    go back and forth。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型。因此，神经网络将开始前后反复进行。
- en: arranging， the values on the nodes， the weights into the nodes and so on。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 重新排列节点上的值、权重等。
- en: The different parts of the neural network is going to start to rearrange itself
    until it。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的不同部分将开始自我调整，直到它。
- en: gets to a point where the raw input data are getting combined， weighted and
    passed on to。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 达到一个点，原始输入数据被组合、加权并传递到。
- en: the prediction layer with a minimum of error。 Basically it's going to rearrange
    itself to the point that the predictions it's making。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 预测层的错误最小化。基本上，它将自我调整到一个预测的点。
- en: are as close as possible to what the truth is as represented in the training
    data that。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能接近训练数据中所代表的真实情况。
- en: has been given to learn。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 已被赋予学习的机会。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_9.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_9.png)'
- en: Some of the terms you might hear with reference to neural networks are back
    propagation。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会听到一些与神经网络相关的术语，比如反向传播。
- en: Back propagation is the process by which the network is tuned。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播是调整网络的过程。
- en: So networks should call it feed forward networks back propagation。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这些网络应称为前馈网络和反向传播。
- en: These are terms that refer to the data get passed forward and then different
    types of。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些术语指的是数据向前传递，然后不同类型的。
- en: information get passed forward and back in the network so that the network can
    kind of。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 信息在网络中前后传递，以便网络可以进行。
- en: learn from the data how to configure itself in a way that's optimal for making
    a prediction。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据中学习如何以最优方式进行配置以进行预测。
- en: So back propagation is part of that process。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，反向传播是该过程的一部分。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_11.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_11.png)'
- en: The great thing about deep learning or these kind of neural network context
    is that there。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习或这些神经网络上下文的一个好处是。
- en: is very limited domain information embedded in the model。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 模型中嵌入的信息是非常有限的领域信息。
- en: So you're substituting computation for expert knowledge。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你是在用计算来替代专家知识。
- en: What I mean by that is in this deep learning case what we've done is taken the
    medical。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，在这个深度学习案例中，我们所做的是处理医疗。
- en: diagnostic image， passed it into the deep learning engine and it's going to
    learn how to predict。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断图像，传递给深度学习引擎，它将学习如何进行预测。
- en: whether or not a patient has a condition or not。 With shallow learning with
    the feature engineering steps we had talked about before there was。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个患者是否有疾病。使用我们之前讨论的特征工程步骤，浅层学习是。
- en: a step where somebody would have to take the image and then look at how to select
    and hand。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个步骤，在这个步骤中，某人需要获取图像并查看如何选择和处理。
- en: code individual features from those images。 Again that's a very time consuming
    and difficult process。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些图像中编码个别特征。这是一个非常耗时和困难的过程。
- en: This deep learning approach requires much less domain information。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种深度学习方法需要的领域信息远远少于。
- en: It does require however a good deal of computation。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实需要相当多的计算。
- en: It's great though but for this reason for tasks with a lack of domain understanding
    for feature。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 不过这很好，但由于特征缺乏领域理解，任务的原因。
- en: extraction。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 提取。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_13.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_13.png)'
- en: So when you're hand coding features where you might have needed a developer
    as well as。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当你手动编码特征时，你可能需要开发人员和。
- en: somebody who has significant medical expertise with a deep learning approach，
    a deep learning。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 具备显著医学专业知识的人员，采用深度学习方法，深度学习。
- en: or machine learning engineer with a lot of solid data on medical images and
    the predictions。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 或机器学习工程师需要大量医学图像和预测的可靠数据。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_15.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_15.png)'
- en: that were ultimately made on those images can themselves create a deep learning
    engine。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最终在这些图像上做出的决策可以自己创建深度学习引擎。
- en: or deep learning engine that can do the prediction task effectively。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 或有效执行预测任务的深度学习引擎。
- en: One question that comes up is what is the role of the engineer。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的问题是工程师的角色是什么。
- en: In the prior case with feature engineering the engineer was important to be
    able to pull。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的特征工程案例中，工程师的重要性在于能够提取。
- en: out individual pieces of information。 So again back to the image example。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 提取出单独的信息片段。所以再回到图像示例。
- en: An engineer was important to take a raw image and then perhaps pull out features
    like say。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师重要的是处理原始图像，可能提取出特征，比如说。
- en: capillary width or something like color shade that requires image processing
    which requires。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 毛细管宽度或颜色阴影等需要图像处理的东西。
- en: some technical expertise。 Here you don't have that feature engineering anymore
    so what is the role of the engineer？
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一些技术专长。在这里你不再有特征工程，那么工程师的角色是什么？
- en: You have raw data being put into the neural network。 So what does the engineer
    do？
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你有原始数据输入神经网络。那么工程师做什么？
- en: Well it turns out there's still a number of things that have to be set for a
    deep learning。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，事实证明，仍然有许多事情需要为深度学习设置。
- en: approach。 These are called hyperparameter values that require engineering knowledge
    but generally。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 方法。这些被称为需要工程知识的超参数值，但通常。
- en: less domain knowledge。 These have names like epochs， batch size， learning rate，
    regularization。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 较少的领域知识。这些有称为 epochs、batch size、learning rate、regularization。
- en: activation functions， the number of hidden layers themselves。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数、隐藏层的数量。
- en: There's a variety of things that engineers have to decide how to set for the
    network to。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 工程师必须决定多种设置，以使网络能够。
- en: perform well。 These hyperparameter values have to be managed by the engineer
    but the workflow ultimately。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 表现良好。这些超参数值必须由工程师管理，但工作流程最终。
- en: changes。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 变化。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_17.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_17.png)'
- en: So again instead of having feature extraction be an important approach so without
    deep learning。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 所以再次强调，特征提取不是一个重要的方法，而是没有深度学习。
- en: we have a workflow where we have input data like image data and then we have
    a time consuming。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个工作流程，其中有输入数据，如图像数据，然后有一个耗时的。
- en: process which is pulling out individual columnar variable or features from those
    kinds of data。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 处理过程是从这些数据中提取单独的列变量或特征。
- en: which are then put into a classification or prediction step and then finally
    you get， the output。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将其放入分类或预测步骤，最后你得到输出。
- en: In a deep learning approach you don't have that feature extraction step。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习方法中，你没有特征提取的步骤。
- en: You can just start with the raw unstructured data that is well labeled， put
    that into the。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以直接从标注良好的原始非结构化数据开始，放入。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_19.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_19.png)'
- en: deep learning engine and you get your predictions without having to do any of
    that feature engineering。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习引擎，你可以得到你的预测，而不需要做任何特征工程。
- en: that's again expensive and uncertain。 Thank you。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这再次是昂贵且不确定的。谢谢。
- en: '![](img/ec4748e43c5bba94cec13768f4df0f25_21.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec4748e43c5bba94cec13768f4df0f25_21.png)'
