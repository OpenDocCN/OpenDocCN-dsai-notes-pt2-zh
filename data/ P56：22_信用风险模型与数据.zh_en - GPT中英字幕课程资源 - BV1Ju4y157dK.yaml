- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P56：22_信用风险模型与数据.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P56：22_信用风险模型与数据.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
- en: So now I want to talk about models versus data。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我想谈谈模型与数据。
- en: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_1.png)'
- en: And let me remind you of what we've done thus far。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我提醒你我们到目前为止所做的事情。
- en: We have estimated a logit model to predict whether a firm is， investment grade
    or speculative grade。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们估计了一个logit模型，以预测一个公司是投资级别还是投机级别。
- en: And I'm going to repeat the results， the old results using the 11 predictors
    that we had discussed in the past。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我将重复我们之前讨论的11个预测变量的结果。
- en: the 11 credit risk KPIs。 I'm going to put the precision recall and F1 score
    for。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 11个信用风险KPI。我将展示它们的精确度、召回率和F1分数。
- en: our logit model here just so we have a benchmark for comparison。 And to refresh
    your memory。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的logit模型在这里，为了比较提供一个基准。以刷新你的记忆。
- en: remember precision is the probability of correctly。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，精确度是正确预测的概率。
- en: predicting an investment grade outcome conditional on predicting， investment
    grade more generally。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 条件预测投资级别结果时，预测投资级别更为普遍。
- en: right？ When we predict investment grade， we can either get it right or we can
    get it wrong。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对吧？当我们预测投资级别时，我们要么预测正确，要么预测错误。
- en: So we're getting it right 76。8% of the time。 And then the recall score is the
    probability of correctly predicting an。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们的正确率为76.8%。然后，召回率是正确预测的概率。
- en: investment grade outcome when it is an investment grade outcome in the data。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据中是投资级别结果时，投资级别结果。
- en: So the data can either be investment grade or speculative grade。 We are getting
    it right 77。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以是投资级别或投机级别。我们的正确率为77。
- en: 3% of the time。 We're overlapping in the data with our model。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 3%的时间。我们在数据中与模型重叠。
- en: And then the F1 score is this harmonic mean or， weighted average of the precision
    and recall。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数是精确度和召回率的调和平均值或加权平均值。
- en: which is about 77。1%。 What I then did is I looked at several alternative models
    for。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大约为77.1%。然后，我查看了几种替代模型。
- en: classifying speculative grade and investment grade firms。 Specifically， K nearest
    neighbors。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 分类投机级别和投资级别公司。具体而言，K最近邻。
- en: a decision tree， a random forest and， a support vector machine。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一个决策树、一个随机森林和一个支持向量机。
- en: I also did something called cross validation for all of the models， including
    the logit。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我还对所有模型进行了交叉验证，包括logit模型。
- en: to ensure I'm not just overfitting on one particular sample。 Okay。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 确保我不是仅仅在一个特定样本上过拟合。好的。
- en: the details of that are not important。 Let's keep this relatively high level。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 细节并不重要。我们保持在相对高层次上。
- en: The point I'm trying to make here is that when I look at alternative models。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我想表达的观点是，当我查看替代模型时。
- en: I do see improvements on different dimensions。 For example， the K nearest neighbors
    has a very high。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我在不同维度上确实看到了一些改善。例如，K最近邻模型的表现非常好。
- en: well， relatively high recall score of 84% compared to all other models。 Although
    not surprisingly。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率相对较高，为84%，与其他所有模型相比，虽然这并不令人惊讶。
- en: it seems to suffer a bit on precision， at least when compared to the logit random
    forest and support vector machine。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与logit随机森林和支持向量机相比，精确度似乎有所下降。
- en: The decision tree， this just doesn't do particularly well along any metric。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树在任何指标上都表现得不好。
- en: relative to the other models。 And in terms of sort of overall precision and
    recall F1 score。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 相对其他模型而言。在整体精确度和召回率F1分数方面。
- en: we can see that the random forest and the K nearest neighbors， well。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到随机森林和K最近邻表现得不错。
- en: the K nearest neighbors wins it by a slight margin of 79。6%。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: K最近邻模型略微获胜，达到了79.6%。
- en: And so we do see some variation in the predictive accuracy of different models。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们确实看到不同模型的预测准确性有所变化。
- en: We can do better than logit given our current specification of inputs。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们当前的输入规格，我们可以比logit做得更好。
- en: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_3.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_3.png)'
- en: What I want to talk about now though， is comparing performance not just across，
    different models。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我现在想谈的是比较不同模型之间的表现。
- en: but also across different predictors。 Remember our original predictors were
    the 11 credit KPIs。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但也包括不同的预测变量。请记住，我们最初的预测变量是这11个信用KPI。
- en: What I then did is I went out and found an old， not too old。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我去找了一个旧的，不是太旧的模型。
- en: somewhat old Moody's research report detailing some of the predictors。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有些旧的穆迪研究报告详细描述了一些预测因素。
- en: that they use in their credit rating model。 Now， that's not going to lead to
    perfectly accurate predictions for。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 他们在信用评级模型中使用的。现在，这不会导致完全准确的预测。
- en: a variety of reasons， not the least of which I'm looking at S&P credit ratings。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种原因，尤其是我关注 S&P 信用评级。
- en: But also because there's a lot more that goes into credit ratings than just。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但也因为信用评级不仅仅涉及这些。
- en: the quantifiable P&L and balance sheet data for a firm。 There's lots of discussions。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 企业的可量化利润和资产负债表数据。讨论很多。
- en: there's industry analysis， competitive analysis， etc。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有行业分析、竞争分析等。
- en: But what I'm trying to see here is if I push better data， more informative data
    through the model。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但我想看看，如果我通过模型推动更好的数据、更具信息量的数据。
- en: will that lead to an improvement？ And how will that improvement compare relative
    to the improvement I got？
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致改进吗？而这种改进与我获得的改进相比如何？
- en: By looking at different models。 And so I've put all of this on the screen here。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察不同模型。因此我把所有这些都放在了屏幕上。
- en: Let me walk through and explain what it all means。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我逐步讲解一下这意味着什么。
- en: So the first three columns measure the precision recall in F1 score of our five。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 所以前面三列测量了我们五个模型的精准率、召回率和 F1 分数。
- en: different models using the 11 original predictors that we talked about from
    the。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 不同模型使用我们之前提到的 11 个原始预测因素。
- en: very start of this series。 The last three columns present the same metrics for
    the same models。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本系列的开始。最后三列展示了相同模型的相同指标。
- en: but using different inputs， different X variables， different predictors。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但使用不同的输入、不同的 X 变量、不同的预测因素。
- en: which I'll just refer to as Moody's predictors。 And what I think is important
    to take away from this table is that the increase。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我将其称为穆迪的预测因素。我认为从这张表中重要的是增长。
- en: in predictive accuracy across all measures moving from the original data。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有度量中，从原始数据转变为预测准确性。
- en: or the original predictors to the Moody's predictors。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 或者原始预测因素与穆迪的预测因素。
- en: is significantly larger than any increase in accuracy obtained from， alternative
    models。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 显著大于从其他模型获得的任何准确性提升。
- en: So let's just focus on the F1 score to make things concrete and simple。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们只关注 F1 分数，以使事情具体而简单。
- en: We can see that the F1 scores range from 71 up to 79。6% using the original predictors。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，使用原始预测因素时，F1 分数从 71 到 79.6% 不等。
- en: But when we use Moody's predictors， these numbers jump up all the way to 88。6%。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 但当我们使用穆迪的预测因素时，这些数字跃升至 88.6%。
- en: in the case of the random forest。 So what's the message here？ The message is
    data， not models。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在随机森林的情况下。那么这里的信息是什么？信息是数据，而不是模型。
- en: That's what leads to successful machine learning implementations。 Let me repeat
    that。 Data。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是导致成功的机器学习实现的原因。让我再说一遍。数据。
- en: not models。 Models can help。 I'm not dismissing the importance of models。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不是模型。模型可以帮助。我并不否定模型的重要性。
- en: I'm simply saying in terms of relative ranking， where you want to spend your。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我只是说，在相对排名方面，你想花费你的。
- en: resources is on better data， better understanding of the data generating process。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 资源在于更好的数据，更好地理解数据生成过程。
- en: That's what's going to drive successful machine learning exercises。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这将推动成功的机器学习工作。
- en: And that's what's going to translate those exercises into value。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使这些工作转化为价值。
- en: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_5.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_5.png)'
- en: accretive actionable decisions。 [BLANK_AUDIO]。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 增长的可行决策。[BLANK_AUDIO]。
- en: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_7.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93faf429e2a0e6bbf679cef1a4773fbb_7.png)'
