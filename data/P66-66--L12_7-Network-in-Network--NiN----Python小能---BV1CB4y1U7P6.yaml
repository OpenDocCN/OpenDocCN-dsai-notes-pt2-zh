- en: P66：66. L12_7 Network in Network (NiN) - Python小能 - BV1CB4y1U7P6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P66：66. L12_7 网络中的网络（NiN） - Python小能 - BV1CB4y1U7P6
- en: So let's talk about how we can actually make those networks a little bit smaller。
    Networks in networks are a convenient strategy for doing this。 So if you look
    at the picture。 you basically see that there's a multi-layer perceptron。 inserted
    as intermediate layers in my convolutional network。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们来谈谈如何将这些网络做得更小一些。网络中的网络是一种方便的策略。你看那张图片，你基本上可以看到，在我的卷积网络中插入了一个多层感知机作为中间层。
- en: And that sounds like an abstract and peculiar and strange idea， and as a matter
    of fact。 when that idea was published， people didn't quite appreciate the impact
    of it。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来这像是一个抽象、特殊而奇怪的想法，事实上，当这个想法发布时，人们并没有完全意识到它的影响。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_1.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_1.png)'
- en: Let's have a look at why it actually matters。 So if we look at the last layers
    in Lunette， well。 they're not that big， right？ The main is basically just， you
    know， 120 hidden units， 84 and then 10。 So that wasn't a big deal relative to
    whatever came before。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看为什么这实际上很重要。如果我们看一下Lunette中的最后一层，嗯，它们其实并不大，对吧？主要的基本上只是，120个隐藏单元，84个，然后是10个。所以相对于之前的部分，这并不算什么大问题。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_3.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_3.png)'
- en: But if we move on to AlexNet or VGG， well， those things actually get quite massive。
    So if you look at the last layer just connecting from the convolution， well。 you
    have number of channels times the width and the height of the last resolution，
    you know。 that you get before you go dense。 And in Lunette， there was 48，000 parameters。
    In AlexNet。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们转向AlexNet或VGG，那么这些东西就变得相当庞大了。所以如果你看看最后一层，它是从卷积层连接出来的，嗯，你会看到，卷积通道的数量乘以最后分辨率的宽度和高度，你知道，在你进入全连接层之前得到的分辨率。而在Lunette中，它有48,000个参数。在AlexNet中。
- en: there was 26 million parameters， so that's about， you know， 3/0 of magnitude
    more。 In VGG。 it was four times again that number。 So that's pretty bad。 whereas
    convolutions were actually kind of well behaved。 It's， you know， input times output
    times。 you know， convolutional kernel size， if you had， you know， kernel size
    of 3， then， you know， that's。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这有2600万个参数，大约是，3/0数量级的更多。在VGG中，这个数值又是它的四倍。所以那是相当糟糕的。而卷积层实际上还算比较合理。你知道，输入乘以输出乘以卷积核的大小，如果你有一个3的卷积核，那么。
- en: you know， 9， so it's 9 times input times output。 That's quite well behaved。
    But those last layers are the ones that really made life hard。 So the question
    is， of course。 how can you fix it？ And the issue is， in the end， you need to produce
    something that is， you know。 for dimensionality that matches the number of classes
    that you have。 So at some point。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道，9，所以它是输入和输出的9倍。这相当不错。但是那些最后的层才是真正让生活变得困难的地方。所以问题是，当然。你怎么能解决这个问题？问题在于，最终，你需要生成一个与你的类别数量相匹配的维度。所以在某一时刻。
- en: you need to go from a two-dimensional times， you know。 number of channels representation
    to something that's a vector。 And the challenge is how do you do that？
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要从一个二维的、乘以通道数的表示，转化为一个向量。挑战在于，如何做到这一点？
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_5.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_5.png)'
- en: So let's have a look at it in a bit more detail。 If I print the size distribution
    for VGG。 you can see that as I'm going from， sequential 5， so this is basically
    the last convolutional block。 so that's 512 channels， with 7x7 to a 4096-dimensional
    output。 Well， that eats a lot of memory。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那我们就更详细地看看吧。如果我打印VGG的大小分布，你可以看到，当我从，顺序第5层开始，这基本上是最后一个卷积块，所以是512个通道，7x7的尺寸，到一个4096维的输出。嗯，这占用了大量的内存。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_7.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_7.png)'
- en: Now， one way to address this is to get rid of those fully connected last layers。
    Well。 that sounds quite easy in theory， but how do you do it in practice？
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，解决这个问题的一种方法是去除那些完全连接的最后一层。嗯，这在理论上听起来很简单，但在实践中如何实现呢？
- en: The problem is convolutions and pulling reduce the resolution， so you keep on
    having things。 But then at some point， you still need to map to this， you know。
    number of classes dimensional object。 And at the same time。 you also need to have
    some degree of nonlinearity。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，卷积和池化操作会减少分辨率，所以你会不断地处理这些东西。但在某一时刻，你仍然需要映射到这个，类别数量的维度对象。而同时，你也需要有一定程度的非线性。
- en: to mix and transfer the information between the various channels into representation
    that works for the number of classes。 And this is exactly where one-by-one convolutions
    come in。 As we saw before。 they only act per pixel on all the channels。 So this
    is really a multi-layer perceptron applied to pixel-wise activations。 And so if
    in the end you only have maybe a 5x5 activation， well， resolution。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 目的是混合和转移不同通道之间的信息，将其转换为适用于类别数的表示。这正是逐一卷积派上用场的地方。正如我们之前看到的，它们仅在所有通道的每个像素上进行操作。因此，这实际上是将多层感知机应用于每个像素的激活值。所以如果最后你可能只剩下一个5x5的激活，嗯，分辨率。
- en: then this really allows you to get a large amount of already per channel information。
    quite nicely presented in the form that will tell you how many classes you need。
    Now。 in the very last layer， essentially they just got rid of it。 So rather than
    bothering with one last dense layer， they just perform global average。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的让你能够获取到大量已经按通道整理过的信息，非常清晰地呈现出来，告诉你需要多少个类别。现在，在最后一层，它们实际上直接去掉了它。所以与其纠结于最后一个全连接层，它们只是执行了全局平均。
- en: pulling in order to take care of things。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 按顺序拉取以处理问题。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_9.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_9.png)'
- en: That worked rather nicely。 So if you look at it again， well。 the one-by-one
    convolution is just a multi-layer perceptron。 And that's what address things。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这效果相当不错。所以如果你再看看，嗯，逐一卷积实际上就是一个多层感知机。这就是解决问题的方式。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_11.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_11.png)'
- en: So this led to something called the NIN block， network-in-network block。 So
    you basically have a convolution followed by two-one-by-one convolutions。 And
    those act in the same way as you would have a dense layer。 You repeat that a few
    times。 and so you get the following architecture。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了一个叫做NIN块的东西，即网络内网络块。所以基本上你会有一个卷积，接着是两个逐一卷积。这些操作就像你拥有一个全连接层一样。你重复这一过程几次，然后你就得到了如下的架构。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_13.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_13.png)'
- en: So the NIN net had a number of convolutions followed by one-by-one convolutions。
    max-pulling in order to reduce the resolution。 And you did that three times in
    order to get a meaningful network-in-networks network。 And this completely got
    rid of the dense layer。 So that's the contribution of network-in-networks。 They
    didn't perform quite as well as VGG， which is one of the reasons why people initially
    overlooked it。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以NIN网络包含了多个卷积，后跟逐一卷积，最大池化以减少分辨率。你重复这个过程三次，以得到一个有意义的网络内网络结构。这样完全摆脱了全连接层。这就是网络内网络的贡献。它们的表现不如VGG好，这也是人们最初忽视它们的原因之一。
- en: But they were a key component in order to go to things like inception or resnet。
    which we're going to cover in the next few lectures。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但它们是通向Inception或ResNet等技术的关键组成部分，而这些我们将在接下来的几节课中讲解。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_15.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_15.png)'
- en: But just to compare in the end， so rather than the dense layer。 you just had
    those multi-layer perceptrons and then average volume。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 但最终进行比较时，与全连接层不同，你只用了这些多层感知机，然后是平均池化。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_17.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_17.png)'
- en: So to summarize things， what you get is you get this dimensionality reduction。
    so you can see you go from 96 to 256 channels to 384 channels。 which then keeps
    on getting reduced further and further until we have something that's 5x5。 Then
    you drop down to in this case 10 dimensions because it's a 10-dimensional classification
    problem。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，你得到的是这种维度压缩。所以你可以看到，你从96个通道到256个通道，再到384个通道，这些通道会进一步减少，直到你得到一个5x5的结果。然后你降到10维，因为这是一个10分类问题。
- en: You perform global average， falling， you drop the remaining few dimensions，
    and there you go。 That's all you need。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你执行全局平均，降采样，丢弃剩余的几个维度，然后就完成了。这就是你需要的所有内容。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_19.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_19.png)'
- en: So in conclusion， what we cover today is Lynette。 So this was the first convolutional
    neural network。 Then we moved on to AlexNet， which was just bigger and better
    and better。 VGG was bigger still。 and then which offered a constructive alternative
    to those behemoths， dense layers。 The next lecture we will then see how all those
    ideas can be combined to get inception。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，今天我们讲的内容是Lynette。这是第一个卷积神经网络。然后我们讲到AlexNet，它更大更好。VGG则更大。然后提供了一个构建性的替代方案来应对这些庞大的全连接层。下节课我们将看到如何将这些思想结合起来，得到Inception。
- en: and then by further refinement of the function classes we will get to resnet
    and resnext。 But that's topic for the next lecture。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过进一步细化函数类别，我们将介绍resnet和resnext。但是这是下节课的内容。
- en: '![](img/d3c6b36f202a17ee0445617e1d9a4544_21.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d3c6b36f202a17ee0445617e1d9a4544_21.png)'
- en: '[BLANK_AUDIO]。'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[BLANK_AUDIO]。'
