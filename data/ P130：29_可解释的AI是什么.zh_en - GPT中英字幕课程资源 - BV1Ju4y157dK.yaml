- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P130：29_可解释的AI是什么.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 沃顿商学院《AI用于商业：AI基础／市场营销+财务／人力／管理》（中英字幕） - P130：29_可解释的AI是什么.zh_en - GPT中英字幕课程资源
    - BV1Ju4y157dK
- en: A key challenge with the use of AI systems is related to explainability。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AI系统的一个主要挑战与可解释性相关。
- en: '![](img/0417c3fc4047062ddcec8b70c338bd6e_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0417c3fc4047062ddcec8b70c338bd6e_1.png)'
- en: So AI explainability is the use of methods in AI systems where why the algorithm
    arrived。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，AI的可解释性是指AI系统中使用的方法，解释算法为何得出这样的结果。
- en: at a particular result can be easily understood by human experts。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 特定结果可以被人类专家轻松理解。
- en: This is closely related to the notion of interpretability， which is understanding
    why。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这与可解释性概念密切相关，即理解为什么。
- en: a decision was arrived at by an algorithm。 Even if you can。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 算法是如何得出决策的。即使你能够。
- en: it may not be able to necessarily explain that logic。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 它可能无法解释该逻辑。
- en: And this contrasts with kind of a black box approach that's normally associated
    with。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这与通常关联的黑箱方法形成对比。
- en: some types of more complex machine learning and particularly deep learning。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 某些类型的更复杂的机器学习，特别是深度学习。
- en: '![](img/0417c3fc4047062ddcec8b70c338bd6e_3.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0417c3fc4047062ddcec8b70c338bd6e_3.png)'
- en: So just to contrast these a little bit， if we have a decision that's made on
    basic business， rules。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所以稍微对比一下，如果我们的决定是基于基本商业规则。
- en: normally these are easy to explain。 How did we arrive at the decision？
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常这些是容易解释的。我们是如何得出这个决定的？
- en: What factors mattered for coming to that decision？ Some of the simpler machine
    learning models。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 哪些因素对得出该决定起了作用？一些更简单的机器学习模型。
- en: models based in decision trees for instance， are also relatively easy to interpret。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基于决策树的模型，例如，相对容易解释。
- en: One can look at a decision tree and sort of get a sense of how a particular
    decision was。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可以查看决策树，基本上可以了解特定决策是如何得出的。
- en: '![](img/0417c3fc4047062ddcec8b70c338bd6e_5.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0417c3fc4047062ddcec8b70c338bd6e_5.png)'
- en: arrived at or what factors mattered that led to that decision。 By contrast。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 到底是如何得出决策的，哪些因素对决策起了作用。相反。
- en: when we think about deep learning models based， for instance on neural networks。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑基于神经网络的深度学习模型时。
- en: especially complex ones based on a lot of data， they become relatively more
    difficult。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是基于大量数据的复杂模型，它们变得相对更难。
- en: '![](img/0417c3fc4047062ddcec8b70c338bd6e_7.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0417c3fc4047062ddcec8b70c338bd6e_7.png)'
- en: to interpret。 Sometimes harder to look inside the algorithm and understand what
    it is that led to that。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 去解释。有时很难深入算法内部，理解导致这一结果的原因。
- en: decision being made。 There is this major trade-off with more complex models
    where on the one hand they're able。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 决策被做出。对于更复杂的模型，这存在一个主要的权衡：一方面，它们能够。
- en: to handle enormous amounts of data and make very accurate predictions。 But on
    the other hand。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 处理大量数据并做出非常准确的预测。但另一方面。
- en: they can be difficult to explain the logic。 And so explainability， it turns
    out。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 它们可能难以解释逻辑。因此，可解释性结果。
- en: is key to adoption though in many contexts。 When you think about implementation。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多背景下，这对采纳至关重要。当你考虑实施时。
- en: even if a model is really accurate， an inability， to explain how it arrives
    at a decision is going to be a major impediment to adoption。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 即使模型非常准确，无法解释它是如何得出决策的，将成为采纳的主要障碍。
- en: We'll talk about some examples of that。 But explainability is a key initiative
    right now in AI。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会讨论一些例子。但可解释性目前是AI中的一个关键举措。
- en: It's key frontier。 Big tech companies are currently heavily invested in this
    issue。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关键的前沿。大型科技公司目前在这一问题上投入了大量资源。
- en: There are also efforts by the government， for instance， that are funding programs
    to。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 政府也在努力，比如资助相关项目。
- en: '![](img/0417c3fc4047062ddcec8b70c338bd6e_9.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0417c3fc4047062ddcec8b70c338bd6e_9.png)'
- en: develop better explainable AI。 [BLANK_AUDIO]。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 开发更好的可解释AI。[BLANK_AUDIO]。
- en: '![](img/0417c3fc4047062ddcec8b70c338bd6e_11.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0417c3fc4047062ddcec8b70c338bd6e_11.png)'
