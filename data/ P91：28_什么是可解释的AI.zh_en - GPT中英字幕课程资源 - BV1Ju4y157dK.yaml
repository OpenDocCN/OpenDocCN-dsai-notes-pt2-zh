- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P91：28_什么是可解释的AI.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 沃顿商学院《AI用于商业：AI基础／市场营销+财务／人力／管理》（中英字幕） - P91：28_什么是可解释的AI.zh_en - GPT中英字幕课程资源
    - BV1Ju4y157dK
- en: Another class of potential challenges and solutions arising around AI when applied
    to HR involves explainable AI。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个在HR中应用AI时可能出现的挑战和解决方案涉及可解释的AI。
- en: '![](img/ef4079a2b40aa07f2096b086e1a11e33_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef4079a2b40aa07f2096b086e1a11e33_1.png)'
- en: So what is explainable AI？ Explainable AI relates to methods where how and why
    the algorithm arrived at its decision can be understood by human experts。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 那么什么是可解释的AI？可解释的AI与方法有关，这些方法可以让人类专家理解算法是如何以及为什么做出决策的。
- en: And this contrasts with some types of machine learning that operate more like
    a black box。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这与一些类型的机器学习形成对比，后者更像是一个黑箱。
- en: So some types of machine learning you're going to put in the data and arrives
    at decisions。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一些类型的机器学习会输入数据并得出决策。
- en: We've talked about this， but reverse engineering this and trying to understand
    or explain， okay。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经谈论过这个，但进行逆向工程并尝试理解或解释，好的。
- en: well I see this decision being made by the algorithm。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，我看到这个决策是由算法做出的。
- en: Why did it come to that decision and not another one？ Sometimes that can be
    very difficult to trace。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么它会得出这个决策而不是另一个？有时候这可能非常难以追踪。
- en: And in a lot of industries a lot of context this causes some pretty significant
    problems。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多行业和上下文中，这会造成一些相当显著的问题。
- en: We'll contrast this with some other types of approaches we've talked about。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将与我们讨论过的一些其他方法进行对比。
- en: We talked about rule based systems which are when expertise from a human is
    put into an algorithm or a piece of software by a developer。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们谈到过基于规则的系统，即人类的专业知识是通过开发者放入算法或软件中的。
- en: This looks like a tree many times and these kinds of systems tend to be relatively
    easy to explain。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来许多时候像一棵树，这些系统往往相对容易解释。
- en: If you think about a decision tree， if you think about how you ended up in a
    particular bottom point on the decision tree。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑一下决策树，考虑一下你是如何最终到达决策树的某个特定底点的。
- en: it's pretty easy to trace through the different points in the tree to figure
    out exactly how it arrived at that decision。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易追踪树中的不同节点，以弄清楚它是如何得出这个决策的。
- en: This kind of decision tree output tends to be relatively easy to explain。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这种决策树输出往往相对容易解释。
- en: '![](img/ef4079a2b40aa07f2096b086e1a11e33_3.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef4079a2b40aa07f2096b086e1a11e33_3.png)'
- en: By contrast， once you get into the world of deep learning which involves a technology
    called neural networks。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，一旦你进入深度学习的世界，这涉及一种称为神经网络的技术。
- en: deep learning output can be much more difficult to explain。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的输出可能更难以解释。
- en: So it's very effective at taking in data and making a prediction。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，它在处理数据和做出预测方面非常有效。
- en: predicting or recommending a particular action。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 预测或推荐某个特定行动。
- en: '![](img/ef4079a2b40aa07f2096b086e1a11e33_5.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef4079a2b40aa07f2096b086e1a11e33_5.png)'
- en: But if we want to go back and understand why that system made that particular
    recommendation。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们想回头了解为什么那个系统做出了那个特定的推荐。
- en: that can be a pretty significant barrier。 It's always possible with these kinds
    of deep learning systems。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是一个相当显著的障碍。对于这些深度学习系统来说，总是有可能的。
- en: In the next video we'll talk about why this matters in a lot of contexts。 [BLANK_AUDIO]。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个视频中，我们将讨论这在许多上下文中为什么重要。[BLANK_AUDIO]。
- en: '![](img/ef4079a2b40aa07f2096b086e1a11e33_7.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef4079a2b40aa07f2096b086e1a11e33_7.png)'
