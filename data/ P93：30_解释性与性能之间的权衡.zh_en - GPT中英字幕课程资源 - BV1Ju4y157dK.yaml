- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P93：30_解释性与性能之间的权衡.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P93：30_解释性与性能之间的权衡.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
- en: We've talked about interpretability being important for a number of different
    types。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过可解释性对多种类型的重要性。
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dab4278f01173a133cc8b54b20a5261d_1.png)'
- en: of business contexts。 We want to be able to understand why an algorithm is coming
    to the decision that it's coming。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在商业背景中。我们希望能够理解算法得出某个决策的原因。
- en: to。 So why wouldn't we always make algorithms interpretable？ Well， it turns
    out there's a trade-off。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们不总是让算法可解释呢？结果证明存在权衡。
- en: There's generally a trade-off between explainability and performance。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在可解释性和性能之间存在权衡。
- en: So just like with fairness or with bias， sometimes when you want to make an
    algorithm。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，就像公平或偏见一样，有时当你想让一个算法。
- en: more explainable， it comes at the expense of performance。 And there's actually。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 更可解释的模型会以性能为代价。实际上存在这种情况。
- en: you can almost think about these as a spectrum with different machine。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你几乎可以把这些视为一个光谱，具有不同的机器。
- en: learning models that are commonly used， where the more interpretable they get，
    the less。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的学习模型，越可解释的模型，预测能力越低。
- en: predictive they get。 The ones that are very， that are least predictive sometimes
    are the easiest to go back and explain。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的预测能力有多强。有些预测性较低的模型，有时反而是最容易解释的。
- en: The ones that are really high， really predictive， deep learning models， neural
    network models。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那些非常高、非常预测性的深度学习模型，神经网络模型。
- en: tend to be very difficult to explain。 And we like， of course， to find ways to
    achieve both。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常很难解释。当然，我们希望找到实现两者的方法。
- en: We like to find ways that kind of find the sweet spot between explainability
    and prediction。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望找到一种方法，在可解释性和预测之间找到最佳平衡。
- en: But that， of course， is hard to do。 So in practice。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但这当然是很难做到的。因此在实践中。
- en: a precise prediction model often needs to be balanced by the ability to， justify
    the model。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 精确的预测模型通常需要平衡模型的可辩护能力。
- en: And so organizations are often trying to find the balance between having a predictive，
    highly。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 组织通常试图在拥有一个高预测性和高度可解释的模型之间找到平衡。
- en: predictive model， but also being able to go back and justify it in the case
    of， say。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 预测模型，但也能够回过头去为其辩护，比如说。
- en: loan processing or something like that。 Or it is important to go back to， say。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 贷款处理或类似的事情。或者重要的是能够回头去解释，比如说。
- en: customers or other stakeholders and explain why it is， a decision was arrived
    at。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 客户或其他利益相关者需要解释为什么做出这个决定。
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_3.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dab4278f01173a133cc8b54b20a5261d_3.png)'
- en: It does raise a difficult question， though， for lots of context， because both
    of these， things。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，这确实提出了一个困难的问题，因为这两者都涉及很多上下文。
- en: explainability is very important， so is accuracy。 Again， going back to the medical
    context。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性非常重要，准确性也是如此。再次回到医疗背景。
- en: it's hard to easily say they're both very important。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 很难简单地说这两者都很重要。
- en: You want to be able to explain the decision for all the different stakeholders
    in healthcare。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望能够向医疗保健中所有不同的利益相关者解释决策。
- en: and patients as well。 But it's also the case， of course。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以及患者。但是，当然也是这样。
- en: that you want to have very accurate predictions when。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当你希望得到非常准确的预测时。
- en: you're dealing with things that affect people's health。 So it's hard to say。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在处理影响人们健康的事情。所以很难说。
- en: not necessarily an easy question to answer about how to make these。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个简单的问题，关于如何使这些模型可解释。
- en: trade-offs that depends on the organizational context or the business context。
    Some applications。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这取决于组织背景或商业背景的权衡。一些应用程序。
- en: if you're thinking about predicting user clicks or maybe buying or selling，
    a financial asset。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在考虑预测用户点击或买卖金融资产。
- en: it doesn't matter as much if you can go back and explain the decision。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能够回头去解释决策，那就没那么重要。
- en: You're not affecting people in the same way， so it doesn't matter as much whether
    you。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你对人的影响并不一样，因此你是否能够解释就没那么重要。
- en: are able to go back and explain why the algorithm made the predictive decision
    that it did。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 能够回过头去解释算法为何做出预测决策。
- en: In that case， you may want to use a highly predictive model。 It doesn't need
    to be interpretable。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你可能希望使用高度预测性的模型。它不需要可解释。
- en: For something like employee promotions， it does matter。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于员工晋升这样的事情，准确预测确实很重要。
- en: You want to be able to go back and understand why the algorithm made the decision
    it did。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望能够回过头来理解算法为何做出这样的决策。
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_5.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dab4278f01173a133cc8b54b20a5261d_5.png)'
- en: And so for that type of application， an organization may try to strike a balance
    between an interpretable。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于这种类型的应用，组织可能会努力在可解释性和其他因素之间取得平衡。
- en: model and one that makes good predictive decisions。 [BLANK_AUDIO]。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 模型和一个能够做出良好预测决策的模型。[BLANK_AUDIO]。
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_7.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dab4278f01173a133cc8b54b20a5261d_7.png)'
