- en: P51：51. L10_5 Using GPUs - Python小能 - BV1CB4y1U7P6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P51：51. L10_5 使用GPU - Python小能 - BV1CB4y1U7P6
- en: '>> Using GPUs， my lab doesn''t have GPU。'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '>> 使用GPU，我的实验室没有GPU。'
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_1.png)'
- en: so I cannot run this notebook。 You can either using AWS or you can use a core
    lab as well。 So you can top check if you have GPUs by， run this media-smi。 here
    I show that I have small two GPUs here。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我无法运行这个笔记本。你可以使用AWS，或者也可以使用Core Lab。所以你可以通过运行这个`media-smi`来检查你是否有GPU。这里我展示的是我有两个小GPU。
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_3.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_3.png)'
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_4.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_4.png)'
- en: Okay， so for GPUs， you can introduce not a concept with core device。 They can
    either have CPUs or GPUs， before you can use the first GPU。 and you can specify
    which GPU you can have。 GPU 1 means the second GPU you have。 So here you can see
    that CPU is a CPU 0。 The 0 doesn't matter anything。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，关于GPU，你可以引入一个概念，那就是核心设备。它们可以是CPU或GPU，在你使用第一个GPU之前，你可以指定你要使用哪个GPU。GPU 1表示你拥有的第二个GPU。所以在这里你可以看到CPU是CPU
    0。数字0其实没有任何意义。
- en: so no matter how many GPU you have， you just a CPU 0， a CPU 0。 But for GPUs，
    this matters。 If you have two GPUs， you need distinguish the two GPUs。 So in default。
    you're going to have a GPU 0， and then you give 1， I'm going to get a second GPU。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所以无论你有多少GPU，你只有一个CPU 0。对于GPU来说，这很重要。如果你有两个GPU，你需要区分这两个GPU。所以默认情况下，你会有GPU 0，然后你给1，我就会得到第二个GPU。
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_6.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_6.png)'
- en: So if I create a array， access what the device is on by using x。contact。 So
    in default。 it's going to sit on CPU memory。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我创建一个数组，访问设备时，可以通过使用`x.contact`来查看。默认情况下，它会放在CPU内存上。
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_8.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_8.png)'
- en: And if I'm going to change it， we can specify CTX is a short of context by using
    GPUs。 So when you do that， you can see that here's the device。 Now this x we sit
    on GPU。 You already see that on the whole work。 Well， you can do random numbers
    as well， then but on GPU 1。 Because this machine I run on the AWS machine， then
    have two GPUs。 We actually can run on the GPU 1。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我要更改它，我们可以通过使用GPU来指定CTX是context的缩写。所以当你这么做时，你可以看到这里是设备。现在这个x我们放在GPU上。你已经可以看到整个工作的效果了。嗯，你也可以做随机数，但在GPU
    1上。因为我在AWS机器上运行这个程序，它有两个GPU。我们实际上可以在GPU 1上运行。
- en: But if you don't have GPU， then you， can-- if you don't have so many GPUs。 you
    get the error message。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你没有GPU，那么你可以——如果你没有那么多GPU，你会收到错误信息。
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_10.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_10.png)'
- en: One thing here， what's the data that's on GPUs？ We can make computations。 The
    computations we have happens on the devices， what the input data are。 So for example。
    if x is on GPU 0， and the y is on GPU 1， I cannot make computation， because it's
    on different GPUs。 If you want to make the data on GPU 1， any copy x into GPU
    1。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个问题，GPU上的数据是什么？我们可以进行计算。我们进行的计算发生在设备上，数据在哪里，计算就在哪里进行。例如，如果x在GPU 0上，y在GPU
    1上，我就无法进行计算，因为它们在不同的GPU上。如果你想让数据在GPU 1上，任何时候都可以将x复制到GPU 1。
- en: The reason we want users to explicitly copy data to GPU， to the same device
    is not just a fault。 We cannot implement that。 It's only tell you because we can
    secretly copy data for you。 But if you do that， your program may be too slow，
    because copy data from GPU to GPU is fine。 but GPU CPU is pretty slow。 We really
    want you to explicitly copy data to a particular GPU。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望用户明确将数据复制到GPU，同一设备上的原因不仅仅是因为错误。我们无法实现这一点。它只是告诉你，我们可以偷偷地为你复制数据。但如果你这么做，程序可能会非常慢，因为从GPU到GPU复制数据是可以的，但GPU到CPU的速度非常慢。我们真的希望你明确将数据复制到特定的GPU上。
- en: So you know that we're the computational running。 But maybe in the future。 GPU
    to GPU bandwidth is so high， and GPU to GPU bandwidth is so high， we maybe just
    ignore that。 You don't need to force every-- you can automatically schedule， for
    you。 But here。 you need to just x copy to the second GPU， z， and perform the results。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你知道我们正在进行计算。但也许在未来，GPU到GPU的带宽非常高，GPU到GPU的带宽也非常高，我们可能就忽略这一点。你不需要强制每次都这样做——你可以自动调度。但在这里，你需要把x复制到第二个GPU，z，并执行结果。
- en: Because y is allocated on GPU， the second GPU， you can see that both y plus
    z going to sit on the second GPU。 as well。 So the operator will happens on the
    device。 where the input has an output that will have the same device。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于y被分配到了第二个GPU上，你可以看到y和z都会放在第二个GPU上。所以操作会发生在设备上，输入在哪里，输出也会在同一设备上。
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_12.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_12.png)'
- en: as well。 You can also do as in context instead of copy to。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 同样。你也可以像在上下文中一样操作，而不是复制到。
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_14.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_14.png)'
- en: Almost give you the same results。 But different here is that if y is already
    on the second GPU。 and as in context using the second GPU， we do nothing。 Just
    return y itself。 So here。 y as in context GPU 1 actually is y。 So it's fine for
    you to write a lot of as in context on your code。 You don't frequently copy and
    move the data。 If you do copy to， no matter which GPU you have。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎给你相同的结果。但不同之处在于，如果y已经在第二个GPU上，并且在上下文中使用第二个GPU时，我们不做任何事情。只需返回y本身。所以这里。y作为上下文GPU
    1实际上就是y。所以你可以在代码中写很多“作为上下文”的操作。你不需要频繁地复制和移动数据。如果你执行复制到操作，不管你使用的是哪个GPU。
- en: we always copy it。 It's just a copy。 So be careful if you write a lot of copy
    to it。 make your program much slower。 And using Google， what you do here。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总是复制它。这只是一个副本。所以如果你对它进行大量复制，要小心。这会让你的程序变得更慢。而使用谷歌，你在这里做的是什么。
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_16.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_16.png)'
- en: is that while you do initializations， I can specify the context。 So you can
    specify the context on the GPU you're going to have。 And also you can copy if
    you can initialize on CPU， and copy to as well， the latter。 But here。 the normal
    way that it initializes， on the particular GPU。 Then once the prime is on that
    GPU。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，在进行初始化时，我可以指定上下文。你可以指定你要使用的GPU的上下文。你还可以选择在CPU上初始化，然后复制到GPU。不过这里。正常的初始化方式是在特定的GPU上进行。一旦主程序在那个GPU上。
- en: you need to copy the x。 Make sure that x is also on GPU as well。 So before we
    already copy x into the GPU 0， so this happens well。 So you can see that the result
    is also， happens on the first GPU。 And the weight is also on the GPU 0 as well。
    So if you're going to change to another one。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要复制x。确保x也在GPU上。所以在我们之前已经把x复制到GPU 0上，这样就能正常进行。所以你可以看到结果也会发生在第一个GPU上。而且权重也在GPU
    0上。所以如果你要切换到另一个GPU。
- en: you can change to another GPU。 You can x can copy to another GPU。 Primitives
    can also copy to another GPU as well。 So in the future。 we're going to tell you
    about multi-gPUs。 You can run that organ on multi-gPUs， but not today。 [BLANK_AUDIO]。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以切换到另一个GPU。你可以将x复制到另一个GPU。原始数据也可以复制到另一个GPU。所以将来。我们会告诉你如何使用多GPU。你可以在多个GPU上运行这个程序，但今天不讲这个。[BLANK_AUDIO]
- en: '![](img/c6f8dda003bcfa78d8be55514125e277_18.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6f8dda003bcfa78d8be55514125e277_18.png)'
