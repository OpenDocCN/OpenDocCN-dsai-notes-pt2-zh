- en: P33：33. L7_5 Dropout in Jupyter - Python小能 - BV1CB4y1U7P6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P33：33. L7_5 在Jupyter中使用丢弃 - Python小能 - BV1CB4y1U7P6
- en: Again， we impose on libraries。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们对库进行了约束。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_1.png)'
- en: The key thing is here。 We define dropout function。 They input this x。 and we
    specify the drop probability。 So we know that this should be larger than 0， or
    less than 0。 not larger than 1。 Then if dropout is equal to 1， we just return
    0s， because。 we drop out everything。 The reason we cannot do a special case is
    because it's。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点在这里。我们定义了丢弃函数。它接收输入x，并指定丢弃概率。所以我们知道，这个值应该大于0，小于1。如果丢弃概率为1，我们就返回0，因为我们丢弃了所有内容。我们不能做特殊情况的原因是因为它。
- en: hard to normalize it。 Then， otherwise， we sample some uniform results between
    0， and 1。 given the same shape of x。 And get the 1 is larger than the dropout
    probability。 This is a mask。 Then we return x tends the mask， and rescale by the
    1 minus， dropout probability。 So that is。 we reimplement the dropout definition。
    Then， some examples here。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 很难将其规范化。那么，除此之外，我们在0和1之间采样一些均匀的结果。给定相同形状的x。然后得到1大于丢弃概率。这是一个掩码。然后我们返回x与掩码的乘积，并通过1减去丢弃概率进行重新缩放。这样做就是重新实现了丢弃的定义。接下来是一些示例。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_3.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_3.png)'
- en: Let's just do gender x。 If you do dropout probability equal to 0， we keep， everything
    here。 If drop half of the results is like every time， should we， give you different
    results？ Well。 it's still training， so it's still training on that， letter。 But
    if we specify probability equal to 1， we drop， everything we have。 So again。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简单做一下性别分类。如果你设置丢弃概率为0，我们会保持所有内容。如果每次丢弃一半的结果，应该会给你不同的结果吗？嗯，训练仍然在继续，所以它仍然在训练这个模型。但如果我们指定丢弃概率为1，我们会丢弃所有内容。再一次。
- en: we implement a three layer， two multilayer。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了三层，其中有两层是多层的。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_5.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_5.png)'
- en: perceptron with two hidden layers。 So again， we using the fashion M list， the
    set， which is。 the input is 784。 Now， put these 10 classes。 The only thing here。
    we choose the first hidden layer output， 256 output。 The second hidden layer，
    actually， output more。 like， 512。 So that's it to have a reminder we choose。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 带有两层隐藏层的感知机。所以我们再次使用了fashion M列表，输入是784。现在，设置这10个类别。这里只是选择了第一隐藏层的输出为256，第二隐藏层实际上输出更多，像是512。所以这是我们选择的一个提醒。
- en: The lib is over complex models to train fashion M list。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个库用于训练过于复杂的模型。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_7.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_7.png)'
- en: So here's the thing， how to apply dropout to the networks。 We define two probabilities。
    We drop different probability for different layer。 Because the first hidden layer
    is lib is simple。 The second one is lib is complex。 We use a small probability
    job for the first layer， and is a。 high probability for the last layer。 But that's
    the hyperparameter you can choose。 Usually。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 那么问题来了，如何将丢弃应用于网络中。我们定义两个概率。我们为不同的层使用不同的丢弃概率。因为第一隐藏层的库比较简单。第二层的库比较复杂。我们对第一层使用较小的丢弃概率，对最后一层使用较大的丢弃概率。但这是一个超参数，你可以选择。通常是这样。
- en: here we use small models。 If you use complex models， usually choices you can
    choice， like 0。5， 0。9。 or 0。9 sometimes。 It's very complex models。 Then we do--
    this is the input we reshape。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们使用小型模型。如果使用复杂模型，通常你可以选择像0.5、0.9或者有时是0.9的概率。它们是非常复杂的模型。然后我们做——这是输入，我们重新调整形状。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_9.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_9.png)'
- en: Let me do a little bit。 This compute does the first hidden layer， that's as
    usual。 Then here's the thing。 When we are on the training model， we apply dropout
    to， the H1。 When it is an inference model， it doesn't apply dropout。 Similar thing
    for the second one。 the second of， hidden layers， we only apply dropout to the
    output of this。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我稍微做一下。这段计算是第一隐藏层，和往常一样。然后问题来了。当我们训练模型时，我们对H1应用丢弃。当它是推断模型时，就不应用丢弃。第二层也是类似的，第二层的隐藏层我们只对其输出应用丢弃，前提是它处于训练过程中。
- en: layer if it's during training。 And we give different probabilities here。 Last。
    we return the last of the Flichen layer。 So we usually don't apply dropout to
    the last output layer。 Because last output layer is used to predict each category，
    you don't want to-- OK， this time。 half of the category， is gone， and then you
    have a large loss。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是在训练过程中，我们给出不同的概率。最后，我们返回最后一层的输出。所以通常我们不会对最后的输出层应用丢弃。因为最后的输出层用于预测每个类别，你不希望——好吧，这次一半的类别丢失，然后你会有很大的损失。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_11.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_11.png)'
- en: So now we can train。 Training is no different to before。 Don't need to think
    that we dropout this slide here。 So we can see that the gap between the training
    accuracy。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在我们可以开始训练了。训练和之前没有什么不同。不要以为我们在这里放弃了这张幻灯片。所以我们可以看到训练精度之间的差距。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_13.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_13.png)'
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_14.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_14.png)'
- en: and the test accuracy is a little bit smaller。 It's actually very close to each
    other。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 测试精度稍微低一些。其实它们非常接近。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_16.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_16.png)'
- en: Sometimes the validation accuracy-- actually， the。 validation accuracy is even
    higher than the training accuracy。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有时验证精度实际上会高于训练精度。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_18.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_18.png)'
- en: So then this is like-- it happens a lot of time。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就像是——这种情况发生得很多。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_20.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_20.png)'
- en: You see that testing accuracy is higher than the training， accuracy。 because
    you're adding a lot of noise during training。 Actually。 this noise is making your
    training accuracy smaller。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到测试精度高于训练精度，因为在训练过程中你加入了很多噪声。实际上，这些噪声使得训练精度变得更低。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_22.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_22.png)'
- en: To implement dropout in Grun is pretty simple。 We have a layer called dropout。
    Then you add in this layer into a network， as a normal layer in the network。 It's
    a behavior as the same thing as we defined before。 This layer performs dropout
    when in the autograd scope， it does nothing in the inference model。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Grun 中实现 dropout 非常简单。我们有一层叫做 dropout。然后你将这一层添加到网络中，就像网络中的普通层一样。它的行为和我们之前定义的一样。在
    autograd 范围内，这一层会执行 dropout，而在推理模型中则什么也不做。
- en: And you can specify the dropout probabilities here。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里指定 dropout 的概率。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_24.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_24.png)'
- en: You also can train that。 Also， similarly， you can see that the test accuracy
    actually。 is higher than the training accuracy。 That is because we give a very
    strong， recognition here。 The last thing you're going to try that without dropout。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以进行训练。同样地，你会看到测试精度实际上高于训练精度。这是因为我们在这里提供了非常强的识别能力。接下来，你将尝试不使用 dropout 的情况。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_26.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_26.png)'
- en: whatever will be happened。 So leave me a slow。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不管发生什么情况。那就让我慢慢来。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_28.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_28.png)'
- en: Let me try that。 So let's change dropout to be 0 and 0。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我来试试这个。所以我们将 dropout 改为 0 和 0。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_30.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_30.png)'
- en: So without dropout。 Because we need to re-initialize the weight， if we don't
    do that。 we just train from the last time we have。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在没有 dropout 的情况下，因为我们需要重新初始化权重，如果不这样做，我们将继续使用上次训练的结果。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_32.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_32.png)'
- en: So let's re-initialize the random values。 And defined。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们重新初始化随机值并定义它们。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_34.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_34.png)'
- en: You may guess what will be happen。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能猜到会发生什么。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_36.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_36.png)'
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_37.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_37.png)'
- en: Any guess？ We'll be a different。 [INAUDIBLE]， Actually， we are not seeing too
    much difference here。 The reason is because we use tiny models here。 So we have
    16，000 images on the training dataset。 And this is a fashion list as it actually
    is more complex， than the amless dataset we have。 So it's pretty complex dataset。
    We construct pretty actually pretty similar models。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有什么猜测吗？我们会看到不同的结果。[听不清]，实际上，我们这里没有看到太大差异。原因是因为我们使用了非常小的模型。所以我们的训练数据集包含了16,000张图片。而且这个时尚数据集实际上比我们之前使用的图像数据集要复杂。所以这是一个相当复杂的数据集。我们构建了相当相似的模型。
- en: The whole feeling is actually small。 Adding regularizations or dropout here。
    doesn't make sense too much。 So let's see。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 整体感觉其实很小。在这里添加正则化或 dropout 并没有太大意义。所以让我们看看。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_39.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_39.png)'
- en: So comparing to the last one we have。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 所以与我们之前的结果相比。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_41.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_41.png)'
- en: actually you don't see much difference。 You can do that。 But the only thing
    you see is that the training accuracy， is much higher than before。 So here。 the
    training accuracy here is almost like before smaller。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上你不会看到太大区别。你可以这样做。但你唯一看到的区别是训练准确率，明显高于之前。所以在这里，训练准确率几乎和之前的相比较小。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_43.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_43.png)'
- en: By the end， these training accuracy pretty high。 And then with dropout。 the
    training accuracy is a little bit， slower here。 Because it's regularization。 actually
    make the training。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 到最后，训练准确率相当高。然后使用丢弃层时，训练准确率会稍微变慢。因为这是一种正则化方法，实际上会让训练过程更稳定。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_45.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_45.png)'
- en: accuracy lower。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率较低。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_47.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_47.png)'
- en: If you want to see the really the benefits of dropout。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想看到丢弃层的真正好处，
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_49.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_49.png)'
- en: what you can do is you can increase the number of hidden， layers here。 You can
    change to 1，024。 Because I run the Mac is pretty slow。 I won't do that。 You change
    to a very large number。 Usually you can do a very large number， then dropout，
    we have more effect on that。 In practice。 well， if the data set is a relative
    simple， and you want to build complex models， for example。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以增加隐藏层的数量。你可以把它改成1,024。因为我的电脑运行比较慢，我不打算这么做。你可以改成一个很大的数值。通常来说，你可以尝试更大的数值，这样丢弃层对结果会有更大的影响。在实践中，如果数据集相对简单，你又想构建复杂的模型，比如，
- en: you construct a new and I will have four hidden layers。 And each hidden layer
    is pretty a lot of hidden units。 You can apply dropout。 So from practice。 maybe
    for the homework four， what you can do is you can see the training error。 and
    the validation error。 You can see the validation across validation accuracy。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你构建一个新的模型，可能有四个隐藏层，每个隐藏层都有大量的隐藏单元。你可以应用丢弃层。所以在实践中，可能对于作业四，你可以观察训练误差和验证误差，看看验证集的交叉验证准确率。
- en: If you think the training loss is too small， the training loss too high， then
    you。 can increase the number of layers you can have。 You can increase the hidden
    units you can have。 But if you see the gap is large， you have two approaches here。
    One that you can apply away decay。 The other one that you can apply dropout。 You
    can apply insert dropout to the output of the hidden layer。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认为训练损失过小或者训练损失过高，那么你可以增加层数，增加隐藏单元数量。如果你看到差距很大，你可以有两种方法。一种是使用权重衰减，另一种是使用丢弃层。你可以在隐藏层的输出上插入丢弃层。
- en: You can specify the dropout probabilities。 You can try either 0。5 or 0。9 that
    are popular choice。 Otherwise， you don't need to add a dropout。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以指定丢弃率。你可以尝试0.5或0.9，这些是常用的选择。否则，你不需要添加丢弃层。
- en: '![](img/96dfb04884f243a06d87f02ab29b9783_51.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96dfb04884f243a06d87f02ab29b9783_51.png)'
- en: '[BLANK_AUDIO]。'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[BLANK_AUDIO]。'
