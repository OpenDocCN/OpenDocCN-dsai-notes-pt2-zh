- en: P61：61. L12_1 LeNet - Python小能 - BV1CB4y1U7P6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P61：61. L12_1 LeNet - Python小能 - BV1CB4y1U7P6
- en: In this lecture， we're going to talk about convolutional neural networks。 In
    the previous lectures。 we encountered the basic components， such as convolutions，
    padding， stride， pooling。 basically all the key components that make up a continent。
    Today we're going to use those components in order to design specific networks，
    and。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这节课中，我们将讨论卷积神经网络。在前几节课中，我们接触到了基本的组件，例如卷积、填充、步幅、池化，基本上构成卷积神经网络的所有关键组件。今天，我们将利用这些组件来设计具体的网络。
- en: in particular we're going to design Lynette， AlexNet， VGG， and then NIN as in
    networks。 inside networks。 The next lecture will cover advanced networks that
    lead us to the state-of-the-art in object。 recognition， but for today let's take
    a brief walk down history lane。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们特别要设计的网络有Lynette、AlexNet、VGG，以及内部网络（NIN）。下一节课将讲解先进的网络，它们引领我们进入物体识别领域的最新技术，但今天，我们将简要回顾一下历史。
- en: '![](img/a1a514643f65202683689405df9fdbea_1.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a514643f65202683689405df9fdbea_1.png)'
- en: So let's start with Lynette。 This was a network proposed in the '90s。 so Lynette
    V is around 1995 by Yandli Khan， his team。 In the simplest version。 this was engineered
    for low resolution black and white object， recognition。 The inputs were。 let's
    say 32 by 32 bit size images， and those images were then convolved。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 那我们先从Lynette说起。这是90年代提出的一个网络，Lynette V大约是在1995年由Yandli Khan和他的团队提出的。在最简单的版本中，这是为低分辨率的黑白物体识别设计的。输入是32x32像素大小的图像，然后这些图像经过卷积处理。
- en: to turn into six channels of 28 by 28 pixels， which were then reduced through
    average pooling。 to 14 by 14。 Remember the channel size is the same because pooling
    doesn't adjust that。 This was then followed by another convolution， which reduced
    it to 10 by 10 images with 16。 channels。 The resolution then gets halved again
    by average pooling， so you get 16 by 5。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 转换成六个28x28像素的通道，然后通过平均池化将其减少到14x14。记住，通道大小是相同的，因为池化操作不会调整通道数。接着进行了另一次卷积，最终将其减少到10x10的图像，并且有16个通道。然后通过平均池化将分辨率再次减半，变成16x5。
- en: This is in the end followed by 120 fully connected units， then by 84 fully connected
    units。 In this case， this was a Gaussian RBF network to map things into 10 classes。
    At the time this was serious engineering， it probably took about between three
    months。 and half a year to implement， including all the tooling that was needed。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个网络后接120个全连接单元，再接84个全连接单元。在这种情况下，这是一个高斯RBF网络，用于将数据映射到10个类别。当时这是一次严谨的工程实现，可能花了大约三个月到半年的时间来完成，包括所需的所有工具。
- en: '![](img/a1a514643f65202683689405df9fdbea_3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a514643f65202683689405df9fdbea_3.png)'
- en: Now why would people have cared about it in '95？ Well， essentially handwritten
    digit recognition。 So at the time， AT&T had a project in order to recognize handwritten
    characters for postal。 codes on letters and also check amounts on checks。 So the
    algorithm at the time was to identify whether check amount， the dollar amount
    is。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么人们在95年会关心这个问题呢？本质上是手写数字识别。当时，AT&T有一个项目，用于识别信件上的邮政编码以及支票上的金额。因此，当时的算法是确定支票金额是否正确。
- en: then to recognize it and to use that in order to then pay that amount。 Obviously。
    that's not quite a trivial。 For instance， if you look at the check， well， you
    could have picked。 you know， 11，725 assets， dollar amount， or you could have picked
    maybe the postcode of Wells Fargo Bank or the tracking。 number in the bottom。
    And while this sounds quite obvious to humans that it's not that。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然后识别它并利用它来支付该金额。显然，这并不是一件微不足道的事。例如，如果你看一下支票，你可能选择了11,725个资产的美元金额，或者你也可以选择可能是富国银行的邮政编码，或者支票底部的追踪号码。而虽然这对人类来说听起来显而易见，但实际上并非如此。
- en: it's non-trivial to do， that on checks。 But for the purpose of this tutorial。
    we're going to focus just on character recognition。 So MNIST was a data set that
    was engineered specifically for that purpose。 This consisted of centered and scaled
    images， 60，000 training data and 10，000 test data at。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在支票上做这件事并不简单。但为了本教程的目的，我们将专注于字符识别。因此，MNIST是一个专门为此目的设计的数据集。这个数据集包含了居中和缩放后的图像，共60,000个训练数据和10,000个测试数据。
- en: the resolution of 28 by 28 pixels。 There were 10 classes because， well， there
    are 10 digits。 And these digits were realistic digits as in obtained by looking
    at letters and actually。 segmenting them appropriately。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 其分辨率为28x28像素。因为有10个类——毕竟有10个数字。这些数字是真实的数字，即通过查看字母并适当地对其进行分割得到的。
- en: '![](img/a1a514643f65202683689405df9fdbea_5.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a514643f65202683689405df9fdbea_5.png)'
- en: To see how this worked， well， let's have a look at the demo of Lynette。 So here
    you can see digits scanning through the network and the network outputting its。
    estimate of what it thinks that digit would be。 And as these digits scan through。
    you can see that even for different shifts， it still recognizes， let's say， a
    5 and a 6， a 6。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看看这个是如何工作的，嗯，我们来看一下Lynette的演示。在这里，你可以看到数字通过网络扫描，网络输出它认为数字的估计。当这些数字扫描时，你可以看到即使在不同的位移下，它仍然能够识别，比如说5和6，6。
- en: And furthermore， you can see on the left hand side the activations of the various
    layers。 So you can see that in the first layer after the convolutions， you pretty
    much just get。 edge detectors， right？ So you get horizontal edges， vertical edges，
    things that enhance contrast。 things that reverse， contrast and so on。 The next
    layer， so that's the column here。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可以在左侧看到各层的激活值。所以你可以看到，在卷积后的第一层，你基本上得到的都是边缘检测器，对吧？比如水平边缘、垂直边缘、增强对比度的东西、反转对比度等等。下一层，就是这一列。
- en: you can see how this now turns into high-level， features but still sort of kind
    of spatially related。 Then beyond that， here are the activations of the fully
    connected layers。 And you can see that this is now much more diverse。 In the end。
    this is converted into an estimate of a particular digit。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到它是如何转化为高层次的特征，但仍然保持某种空间上的关联。然后，在这之后是全连接层的激活值。你可以看到现在的激活值要更加多样化。最终，这被转换为对某个特定数字的估计。
- en: So the paper that documents this from 1998 is a really landmark paper and I
    don't think。 it's getting anywhere the recognition that it should。 I strongly
    recommend reading this。 There's a lot of detail in there also on graph transducers
    which I don't think are fully。 appreciated even nowadays。 Now if you look at that
    network architecture。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文档了1998年的论文是一个真正的里程碑论文，我觉得它应该获得更多的认可，但并没有。我强烈推荐阅读这篇论文，里面有很多细节，包括图形转换器，至今我觉得这些概念还没有得到充分的理解。现在如果你看这个网络架构。
- en: I mean this wasn't such a big deal in 1995， because the images were not too
    high dimensional。 But what you can already see is that as you move towards the
    output parts of the network。 we have fully connected layers。 These fully connected
    layers can be quite expensive if we have many outputs。 So for 10 classes， it's
    not a big deal。 Once we will move to maybe a thousand classes for ImageNet。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，在1995年这并不是那么重要，因为当时图像的维度并不高。但你可以已经看到，随着网络逐渐接近输出部分，我们有了全连接层。如果输出很多，这些全连接层会变得非常昂贵。所以对于10个类别来说，这不是大问题。一旦我们可能需要处理像ImageNet这样上千个类别时。
- en: this will actually become the， dominant factor in our network design and we'll
    have to find ways around it。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上会成为我们网络设计中的主导因素，我们将不得不寻找绕过它的方法。
- en: '![](img/a1a514643f65202683689405df9fdbea_7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a514643f65202683689405df9fdbea_7.png)'
- en: We'll get to that in a moment。 Before that， let's have a look at how to actually
    implement that。 We'll see that later in action in our notebook， but let's look
    at it for now。 So all we do is we basically just say， okay， well， I want to have
    a sequential composition。 of layers in that network。 And then I just add a convolution，
    average pooling， another convolution。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会讲到这些。首先，我们来看一下如何实现这一点。稍后我们会在笔记本中看到实际的效果，但现在先来看一下实现的过程。所以我们做的就是基本上声明，好的，我想在这个网络中使用层的顺序组合。然后我添加一个卷积、平均池化，再加一个卷积。
- en: another average， pooling operation， and then two dense layers and a dense output。
    And that's it。 So this is something that fits very comfortably on a single screen，
    whereas， well， in 1995。 this would have been a lot more complex to implement。
    Mind you。 a lot of the size and the shape inference here is automatic， so you
    don't really。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个平均池化操作，然后是两个全连接层和一个全连接输出。就这样。所以这个网络架构非常适合放在一个屏幕上，而在1995年，这种实现会复杂得多。请注意，很多尺寸和形状的推断是自动的，所以你其实不需要做太多。
- en: need to specify what the input dimensions to the next layer are。 They implicitly
    define as you parse the network from input to output。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 需要指定下一层的输入维度。它们会在你从输入到输出解析网络时被隐式定义。
- en: '![](img/a1a514643f65202683689405df9fdbea_9.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a514643f65202683689405df9fdbea_9.png)'
- en: '![](img/a1a514643f65202683689405df9fdbea_10.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a514643f65202683689405df9fdbea_10.png)'
- en: And that's the net。 [BLANK_AUDIO]。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是网络。[BLANK_AUDIO]。
