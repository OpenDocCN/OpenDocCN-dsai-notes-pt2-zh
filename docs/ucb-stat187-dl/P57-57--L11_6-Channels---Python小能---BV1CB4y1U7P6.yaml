- en: P57：57. L11_6 Channels - Python小能 - BV1CB4y1U7P6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P57：57. L11_6 Channels - Python小能 - BV1CB4y1U7P6
- en: Let's talk about channels in convolutional neural networks。 So far we looked
    at mostly grayscale images which had just a different level of intensity， for。
    you know， very bright to very dark images。 For instance in fashion MNIST we had
    values between 0 and 255 to indicate how bright the。 pixel was。 But if we look
    at this picture of this woman here， then it's very clear that grayscale。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来谈谈卷积神经网络中的通道。到目前为止，我们主要看的是灰度图像，这些图像只有不同的亮度级别，从非常亮到非常暗。例如，在时尚MNIST中，我们的像素值在0到255之间，用来表示像素的亮度。但如果我们看看这里的这张女人的照片，就很明显，灰度图像并不足以展现它的细节。
- en: isn't quite going to do it justice。 Just a small side note。 it's a picture of
    a very famous woman called Lena。 And it's actually taken from Playboy magazine
    from， I think， 1971 and '72。 And mind you。 this is the safe for work crop of that
    image。 The reason why it got very popular among image processing researchers is
    because the image。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 灰度图像并不能完全体现其美感。顺便提一下，这张图片是一个非常著名的女性，名字叫做Lena。实际上，这张照片来自《花花公子》杂志，拍摄于1971年或1972年。请注意，这张图片是经过裁剪的适合工作的版本。之所以这张图片在图像处理研究者中非常流行，是因为它包含了很多有趣的图像细节。
- en: has a lot of really interesting and challenging details in there。 So there's
    a smooth skin。 there's a lot of texture in the feather hanging off her hat。 there's
    a lot of texture in her hat itself， there's background blur， there are sharp edges。
    namely the contour between the hat and the background。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 它有非常光滑的皮肤，帽子上的羽毛有很多纹理，帽子本身也有许多纹理，背景模糊，也有很多锐利的边缘，特别是帽子与背景的轮廓。
- en: There's some degree of bokeh here and other things。 So if you want to do really
    well in terms of image processing on that image， you have。 to invest a significant
    amount of work。 This is why this is actually one of the more popular pictures。
    That's it。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图片有一些程度的虚化和其他特效。所以如果你想在图像处理方面做得更好，你需要投入大量的工作。这也是这张图片成为比较流行的原因之一。它有很多非常有趣且富有挑战性的细节。
- en: '![](img/f64464afd4a26500125eeb82b2890c3c_1.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f64464afd4a26500125eeb82b2890c3c_1.png)'
- en: Let's look at the image in a bit more detail。 So this is the same image but
    now split into red。 green and blue。 You can see that there's different types of
    information in those three channels。 If we were to treat the image just as grayscale，
    we would lose a lot of information。 But if we have a convolutional neural network，
    well， we need to have a way how to deal with， it。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地观察一下这张图片。这里是同样的图片，但现在它被拆分成了红、绿、蓝三个通道。你可以看到这三个通道中包含了不同类型的信息。如果我们仅仅把它当作灰度图像处理，我们会丢失很多信息。但如果我们有卷积神经网络，那么我们就需要有方法来处理这些信息。
- en: Turns out this is very simple。 Recall what we did when we had a single channel
    input。 Well we just take our convolutional kernel， we applied it to that channel
    and we got some， output。 Now if we have two or three or more channels， it's very
    easy。 We just apply a convolutional filter。 most likely a different one， to every
    one of those， channels。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 结果证明，这非常简单。回想一下我们处理单通道输入时的做法。我们只需将卷积核应用到该通道，就能得到输出。现在如果我们有两个、三个或更多通道，做法也很简单。我们只需要对每个通道应用卷积滤波器，可能是不同的滤波器。
- en: in the end we just pair together the outputs， we add them up and we have a final，
    output。 So what happened here in this picture is we have two channels， we take
    two kernels， we。 apply them and we add it up and so we get this output and for
    instance in the upper left。 by convolving a 3 by 3 with a 2 by 2 kernel， we get
    the number 56。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最终我们只需将输出结果进行配对，加在一起，得到最终的输出。所以在这张图片中发生的事情是，我们有两个通道，我们取两个卷积核，应用它们并加起来，最终得到这个输出。例如，在左上角，通过将一个3x3的卷积核与2x2的卷积核进行卷积，我们得到数字56。
- en: '![](img/f64464afd4a26500125eeb82b2890c3c_3.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f64464afd4a26500125eeb82b2890c3c_3.png)'
- en: So here's the math for it。 I now have x which is now of ci times nh times nw
    dimensions。 So input channels times height times weight， I have the same thing
    for the kernel which。 now depends also on the input channels and I get mh times
    mw output so I still get only。 a 2 dimensional output because everything's padded
    together。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里是相关的数学公式。我现在有x，它是ci乘以nh乘以nw的维度。所以输入通道乘以高度乘以宽度，我对卷积核做了相同的处理，它现在也依赖于输入通道，因此我得到mh乘以mw的输出，所以我仍然只有一个二维的输出，因为所有的东西都进行了填充。
- en: This is how you deal with multiple input channels。 Of course you could now ask。
    well maybe a single input output channel isn't quite good。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是处理多个输入通道的方法。当然，你可能会问，单一的输入输出通道可能并不够好。
- en: '![](img/f64464afd4a26500125eeb82b2890c3c_5.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f64464afd4a26500125eeb82b2890c3c_5.png)'
- en: enough。 You might have multiple output channels for different features。 And
    that's very easy。 Well。 you just take one convolutional filter for every output
    channel that I want to have。 and then you stack up the results so you don't add
    them to get each stack them up。 In this case。 well， if input channels have now
    a kernel that depends on output and input， dimensions。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 足够了。你可能有多个输出通道来处理不同的特征。这很简单。你只需要为每个想要的输出通道拿一个卷积滤波器，然后将结果堆叠起来，而不是将它们相加。这样，在这种情况下，如果输入通道现在有一个依赖于输出和输入维度的内核。
- en: basically number of channels and the dimensions namely in terms of height and。
    width of the kernel itself applied。 Okay， so that's what you get and so you get
    input dimensions and you get output dimensions。 fairly straightforward。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，通道的数量和内核的尺寸，特别是内核的高度和宽度，是应用的关键。好吧，所以你得到的是输入维度和输出维度，这个过程非常直接。
- en: '![](img/f64464afd4a26500125eeb82b2890c3c_7.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f64464afd4a26500125eeb82b2890c3c_7.png)'
- en: Now why would you want to have this？ Well because every output channel may actually
    recognize a different particular pattern。 For instance you might have for example
    filters， you might have vertical edge detectors， diagonal。 ones， filters that
    detect circular parts， filters that detect greater green or blue things。 or maybe
    some combinations thereof。 So that's why you need more than one。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么你会想要这个呢？因为每个输出通道实际上可能会识别出不同的特定模式。例如，你可能有过滤器，可能有垂直边缘检测器、对角线检测器、检测圆形部分的过滤器，检测更大绿色或蓝色部分的过滤器，或者是它们的某些组合。所以，这就是为什么你需要多个输出通道的原因。
- en: And of course this is then fed as an input signal into the next layer where
    you can maybe。 do another fancy processing but this is basically how you can organize
    a meaningful convolutional。 network。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些信息会作为输入信号传入下一层，你也许可以在这里做一些更复杂的处理，但基本上这就是你可以组织一个有意义的卷积神经网络的方式。
- en: '![](img/f64464afd4a26500125eeb82b2890c3c_9.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f64464afd4a26500125eeb82b2890c3c_9.png)'
- en: Now there's one very special anomaly， namely one by one convolutional layers。
    So one by one layers actually sounds kind of weird， right？
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有一个非常特殊的现象，那就是一对一卷积层。那么一对一层听起来是不是有点奇怪？
- en: What's a one by one convolution after all because I'm not convolving that pixel
    with， anything else。 It's just that pixel and it stays that pixel as we go through
    that pipeline。 However what happens is that it takes a linear combination of all
    the input channel weights。 and performs matrix vector multiplication then followed
    by some nonlinearity and then。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 那么一对一卷积到底是什么呢？因为我并没有将那个像素与其他任何东西进行卷积。它就是那个像素，随着我们进入这个处理管道，它保持不变。然而，发生的事情是它会对所有输入通道的权重进行线性组合，并执行矩阵向量乘法，随后进行一些非线性操作。
- en: I get an output。 In other words this is a multi-layer perceptron which takes
    a certain set of input weights。 and to generate the corresponding output weights。
    So this is therefore equivalent to a dense network applied pixel-wise。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我得到一个输出。换句话说，这就相当于一个多层感知器，它接受一定的输入权重，并生成相应的输出权重。因此，这等同于应用在像素级的密集网络。
- en: '![](img/f64464afd4a26500125eeb82b2890c3c_11.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f64464afd4a26500125eeb82b2890c3c_11.png)'
- en: So to sum everything up our two dimensional convolutional layer summary we have
    input， channels。 we have kernels that depend on inputs and outputs and we have
    a bias which of course。 depends on input and output channels and then we have
    some outputs which are output channels。 times height times width。 So why would
    this matter？
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以总结一下我们的二维卷积层的摘要：我们有输入通道，我们有依赖于输入和输出的内核，还有一个偏置，当然，这个偏置依赖于输入和输出通道，最后我们有一些输出，这些输出是输出通道乘以高度乘以宽度。那么，为什么这很重要呢？
- en: Well because if you actually think care about computing this efficiently the
    cost now scales。 linearly with a number of input channels because they need to
    process them。 Linearly with a number of output channels because these are the
    ones that I need to generate。 the kernel height and width because that's the number
    of floating point operations that。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因为如果你真的考虑到如何高效地进行计算，成本现在随着输入通道的数量线性增加，因为它们需要被处理。随着输出通道的数量线性增加，因为这些是我需要生成的。还有内核的高度和宽度，因为那是浮点运算的数量。
- en: I perform and then times the output height and output width。 Okay so let's put
    some numbers behind that。 Suppose I have 100 input and 100 output channels that's
    not unusual。 Suppose I have a 5x5 convolution that's also not so unusual and let's
    say I have maybe。 64x64 pixel images。 So that all up if you work out the math
    gets you to about a gigaflop。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我执行然后乘以输出的高度和输出的宽度。好，我们来看看背后的数字。假设我有100个输入和100个输出通道，这并不罕见。假设我有一个5x5的卷积，这也不算罕见，我们假设有64x64像素的图像。那么，全部计算下来，如果你算一下，结果大约是一个吉弗洛普。
- en: Now one gigaflop doesn't sound like a lot but if I have 10 layers of such a
    convolutional。 network if I have maybe a million observations that's 10 petaflops。
    So on a CPU that might perform at around 150 gigaflops that takes 18 hours whereas
    in。 a GPU that performs maybe 12 teraflops so that's a modern GPU for less than
    $500 you。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一个吉弗洛普（gigaflop）听起来并不多，但如果我有10层这样的卷积网络，如果我有可能有百万个观察数据，那就是10拍弗洛普（petaflops）。所以在一个CPU上，性能大约是150吉弗洛普，可能需要18小时，而在一个性能可能达到12太弗洛普（teraflops）的GPU上，那么在不到500美元的现代GPU上，你可以在14分钟内完成相同的工作。
- en: can get the same work done in 14 minutes。 So now we have hours versus minutes
    and that's one of the reasons why people nowadays use。 GPUs if they want to run
    convolutional networks and similar structures on large amounts of， data。 [BLANK_AUDIO]。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在我们有了小时和分钟的对比，这也是为什么人们现在如果想在大量数据上运行卷积网络和类似结构时，通常会使用GPU的原因。[BLANK_AUDIO]。
- en: '![](img/f64464afd4a26500125eeb82b2890c3c_13.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f64464afd4a26500125eeb82b2890c3c_13.png)'
