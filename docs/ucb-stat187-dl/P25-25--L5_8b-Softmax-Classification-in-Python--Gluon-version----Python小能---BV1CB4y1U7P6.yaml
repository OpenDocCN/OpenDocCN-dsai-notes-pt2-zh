- en: P25：25. L5_8b Softmax Classification in Python (Gluon version) - Python小能 -
    BV1CB4y1U7P6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P25：25. L5_8b Python中的Softmax分类（Gluon版本） - Python小能 - BV1CB4y1U7P6
- en: '>> Okay。'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '>> 好的。'
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_1.png)'
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_2.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_2.png)'
- en: So it looks exactly the same as before。 We just go and import the data。 Right？
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它看起来与之前完全相同。我们只需去导入数据，对吧？
- en: So this is exactly the same code as before。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这与之前的代码完全相同。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_4.png)'
- en: The only difference is that now i can make my life really。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是，现在我可以轻松地处理我的生活。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_6.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_6.png)'
- en: Easy。 And i just define my network by saying， Hey， it's a sequential composition
    of layers。 And i have a whopping total of one layer。 And i want those parameters
    to be initialized with no。 Distribution with variance 0。01。 So that's it。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单。我只需通过声明我的网络是一个顺序的层组合来定义它。并且我总共只有一层。我希望这些参数的初始化采用均值为 0，方差为 0.01 的分布。就这样。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_8.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_8.png)'
- en: The interesting thing is i didn't have to specify the， Input dimensions anymore。
    The network is smart enough to。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我不再需要指定输入维度了。网络已经足够智能，能够自动处理。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_10.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_10.png)'
- en: Automagically configure the amount of parameters and the sizes。 And everything
    based on the size of the inputs。 So that's very convenient。 So if i， rather than
    28。 By 28， i might have maybe 30 by 30 pixels。 It will still work nicely。 By the
    way。 this flexibility comes with a serious downside in， Practice。 So a customer
    who shall not be。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自动配置参数的数量和大小，以及所有基于输入大小的内容。所以这非常方便。所以如果我将 28x28 改为 30x30 像素，它仍然能够很好地工作。顺便说一下，这种灵活性在实际应用中有一个严重的缺点。所以某些客户将无法处理。
- en: Named took one of the computer vision models that we had that， Were trained
    on 224 by 224 pixels。 So fairly small image net size。 And they applied it to 4k。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Named 使用了我们曾经训练过的计算机视觉模型，模型是在 224x224 像素的图像上训练的。所以是相对较小的 ImageNet 尺寸。然后他们将其应用到
    4K 图像上。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_12.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_12.png)'
- en: Images。 Okay。 So those 4k images created a lot of intermediate memory。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图像。好的。所以这些 4K 图像产生了大量的中间内存。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_14.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_14.png)'
- en: We'll get to convolution networks and so on later on。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会讲到卷积网络等内容。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_16.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_16.png)'
- en: But basically， the system ran pretty much out of memory and， Was horribly slow。
    I mean。 it was mathematically correct。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但基本上，系统几乎耗尽了内存，而且速度非常慢。我的意思是，数学上是正确的。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_18.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_18.png)'
- en: But it was a not terribly enlightened thing to do。 And then we got a report
    that our network isn't working。 So be careful when you make things automatic。
    You can be pretty much sure that the users will abuse the。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不是一个特别明智的做法。然后我们收到报告说我们的网络无法工作。所以当你让事情自动化时要小心。你几乎可以肯定用户会滥用它们。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_20.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_20.png)'
- en: Interface in some interesting ways。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以一些有趣的方式进行交互。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_22.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_22.png)'
- en: Okay。 But we're not going to do that here， Obviously。 Okay。 So here's the softmax。
    And now this is the numerically stable version of it。 So glue and loss， softmax
    cross entropy loss。 Okay。 We could have picked a shorter name， But you don't need
    to use it more than once。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。但是显然我们在这里不会这么做。好的。这里是 Softmax。现在这是它的数值稳定版本。所以 Gluon 损失，softmax 交叉熵损失。好的。我们本可以取一个更短的名字，但你不需要多次使用它。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_24.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_24.png)'
- en: Here's an optimization algorithm。 And a very simple one is， Stochastic rate
    descent。 It's actually doing something， Slightly smarter than Stochastic rate
    descent。 It's actually performing momentum and weight clipping and so on， Unless
    you switch it off。 So it's a very smart version of， S。G。D。 but for all intents
    and purposes， This one's fine。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个优化算法。一个非常简单的算法是随机梯度下降。它实际上做了一些比随机梯度下降稍微聪明的事情。它执行了动量和权重剪切等操作，除非你关闭它。所以它是一个非常智能的版本，S.G.D.，但就所有目的而言，这个就可以了。
- en: Just use that。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 就使用那个。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_26.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_26.png)'
- en: Okay。 And then we can go and train。 And the call signature of this is exactly
    the same as what we。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。那么我们可以开始训练了。这个调用签名和我们之前的一模一样。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_28.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_28.png)'
- en: Have before。 So except that it runs。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 和之前一样。所以除了它运行。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_30.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_30.png)'
- en: Marginally faster， you probably wouldn't be able to tell much。 Here because
    the overall operations are still very。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 略微更快一点，你可能无法察觉太多差异。这里因为整体操作还是非常。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_32.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_32.png)'
- en: Straight forward。 Once we go to more complex networks， We'll actually see that
    it does run faster。 Okay。 Anyway， so this is training that， Networking glue on。
    It looks very similar。 Any questions so far？ Okay。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 很直接。一旦我们进入更复杂的网络，我们实际上会看到它运行得更快。好的。无论如何，这就是训练，网络的连接部分。看起来非常相似。到目前为止有任何问题吗？好的。
- en: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_34.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5258cea0f9674e8d2d959edb3b6f07_34.png)'
