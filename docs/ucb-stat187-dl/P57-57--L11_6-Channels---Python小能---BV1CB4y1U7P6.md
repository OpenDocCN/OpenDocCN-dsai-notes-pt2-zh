# P57：57. L11_6 Channels - Python小能 - BV1CB4y1U7P6

让我们来谈谈卷积神经网络中的通道。到目前为止，我们主要看的是灰度图像，这些图像只有不同的亮度级别，从非常亮到非常暗。例如，在时尚MNIST中，我们的像素值在0到255之间，用来表示像素的亮度。但如果我们看看这里的这张女人的照片，就很明显，灰度图像并不足以展现它的细节。

灰度图像并不能完全体现其美感。顺便提一下，这张图片是一个非常著名的女性，名字叫做Lena。实际上，这张照片来自《花花公子》杂志，拍摄于1971年或1972年。请注意，这张图片是经过裁剪的适合工作的版本。之所以这张图片在图像处理研究者中非常流行，是因为它包含了很多有趣的图像细节。

它有非常光滑的皮肤，帽子上的羽毛有很多纹理，帽子本身也有许多纹理，背景模糊，也有很多锐利的边缘，特别是帽子与背景的轮廓。

这张图片有一些程度的虚化和其他特效。所以如果你想在图像处理方面做得更好，你需要投入大量的工作。这也是这张图片成为比较流行的原因之一。它有很多非常有趣且富有挑战性的细节。

![](img/f64464afd4a26500125eeb82b2890c3c_1.png)

让我们更详细地观察一下这张图片。这里是同样的图片，但现在它被拆分成了红、绿、蓝三个通道。你可以看到这三个通道中包含了不同类型的信息。如果我们仅仅把它当作灰度图像处理，我们会丢失很多信息。但如果我们有卷积神经网络，那么我们就需要有方法来处理这些信息。

结果证明，这非常简单。回想一下我们处理单通道输入时的做法。我们只需将卷积核应用到该通道，就能得到输出。现在如果我们有两个、三个或更多通道，做法也很简单。我们只需要对每个通道应用卷积滤波器，可能是不同的滤波器。

最终我们只需将输出结果进行配对，加在一起，得到最终的输出。所以在这张图片中发生的事情是，我们有两个通道，我们取两个卷积核，应用它们并加起来，最终得到这个输出。例如，在左上角，通过将一个3x3的卷积核与2x2的卷积核进行卷积，我们得到数字56。

![](img/f64464afd4a26500125eeb82b2890c3c_3.png)

所以这里是相关的数学公式。我现在有x，它是ci乘以nh乘以nw的维度。所以输入通道乘以高度乘以宽度，我对卷积核做了相同的处理，它现在也依赖于输入通道，因此我得到mh乘以mw的输出，所以我仍然只有一个二维的输出，因为所有的东西都进行了填充。

这就是处理多个输入通道的方法。当然，你可能会问，单一的输入输出通道可能并不够好。

![](img/f64464afd4a26500125eeb82b2890c3c_5.png)

足够了。你可能有多个输出通道来处理不同的特征。这很简单。你只需要为每个想要的输出通道拿一个卷积滤波器，然后将结果堆叠起来，而不是将它们相加。这样，在这种情况下，如果输入通道现在有一个依赖于输出和输入维度的内核。

基本上，通道的数量和内核的尺寸，特别是内核的高度和宽度，是应用的关键。好吧，所以你得到的是输入维度和输出维度，这个过程非常直接。

![](img/f64464afd4a26500125eeb82b2890c3c_7.png)

那么，为什么你会想要这个呢？因为每个输出通道实际上可能会识别出不同的特定模式。例如，你可能有过滤器，可能有垂直边缘检测器、对角线检测器、检测圆形部分的过滤器，检测更大绿色或蓝色部分的过滤器，或者是它们的某些组合。所以，这就是为什么你需要多个输出通道的原因。

当然，这些信息会作为输入信号传入下一层，你也许可以在这里做一些更复杂的处理，但基本上这就是你可以组织一个有意义的卷积神经网络的方式。

![](img/f64464afd4a26500125eeb82b2890c3c_9.png)

现在有一个非常特殊的现象，那就是一对一卷积层。那么一对一层听起来是不是有点奇怪？

那么一对一卷积到底是什么呢？因为我并没有将那个像素与其他任何东西进行卷积。它就是那个像素，随着我们进入这个处理管道，它保持不变。然而，发生的事情是它会对所有输入通道的权重进行线性组合，并执行矩阵向量乘法，随后进行一些非线性操作。

我得到一个输出。换句话说，这就相当于一个多层感知器，它接受一定的输入权重，并生成相应的输出权重。因此，这等同于应用在像素级的密集网络。

![](img/f64464afd4a26500125eeb82b2890c3c_11.png)

所以总结一下我们的二维卷积层的摘要：我们有输入通道，我们有依赖于输入和输出的内核，还有一个偏置，当然，这个偏置依赖于输入和输出通道，最后我们有一些输出，这些输出是输出通道乘以高度乘以宽度。那么，为什么这很重要呢？

因为如果你真的考虑到如何高效地进行计算，成本现在随着输入通道的数量线性增加，因为它们需要被处理。随着输出通道的数量线性增加，因为这些是我需要生成的。还有内核的高度和宽度，因为那是浮点运算的数量。

我执行然后乘以输出的高度和输出的宽度。好，我们来看看背后的数字。假设我有100个输入和100个输出通道，这并不罕见。假设我有一个5x5的卷积，这也不算罕见，我们假设有64x64像素的图像。那么，全部计算下来，如果你算一下，结果大约是一个吉弗洛普。

现在一个吉弗洛普（gigaflop）听起来并不多，但如果我有10层这样的卷积网络，如果我有可能有百万个观察数据，那就是10拍弗洛普（petaflops）。所以在一个CPU上，性能大约是150吉弗洛普，可能需要18小时，而在一个性能可能达到12太弗洛普（teraflops）的GPU上，那么在不到500美元的现代GPU上，你可以在14分钟内完成相同的工作。

所以现在我们有了小时和分钟的对比，这也是为什么人们现在如果想在大量数据上运行卷积网络和类似结构时，通常会使用GPU的原因。[BLANK_AUDIO]。

![](img/f64464afd4a26500125eeb82b2890c3c_13.png)
