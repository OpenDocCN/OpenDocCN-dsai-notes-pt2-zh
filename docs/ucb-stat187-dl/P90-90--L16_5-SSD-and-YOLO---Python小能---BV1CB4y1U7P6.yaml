- en: P90：90. L16_5 SSD and YOLO - Python小能 - BV1CB4y1U7P6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P90：90. L16_5 SSD 和 YOLO - Python小能 - BV1CB4y1U7P6
- en: So first let's talk about the SSD。 It's called single-shot， multi-box detections。
    So the idea is pretty simple。 So the major difference between。 RCN and SSD is
    that how the bondbox are generated。 In the RCN family， we have a fancy algorithm
    to。 how to generate the bondbox so that we want to， have the bondbox cover as
    much as possible。 For SSD。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 所以首先我们来谈谈 SSD。它被称为单次检测，多框检测。这个概念其实很简单。所以 RCNN 和 SSD 之间的主要区别在于边框是如何生成的。在 RCNN
    系列中，我们有一个复杂的算法来生成边框，以便我们希望边框能够尽可能覆盖更多内容。对于 SSD。
- en: it's much simpler。 So here for SSD for each pixel。 we can generate multiple
    bondboxes and center that as this pixel。 The multi-means。 we give different size，
    different shape， different ratio。 For example。 if we give N sizes from S1 to SN
    and M ratios from R1 to R M。
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 它要简单得多。所以在 SSD 中，对于每一个像素，我们可以生成多个边框并以此像素为中心。多重意味着我们给定不同的大小、不同的形状、不同的比例。例如，如果我们给定
    N 种大小，从 S1 到 SN，再给定 M 种比例，从 R1 到 RM。
- en: So size means the relative size to the original image。 The ratio is the width
    with height。 So then the idea here is generate M plus M minus 1 ankle boxes。 So
    it's not but N times M。 It's M plus M minus 1。 The way how it generates ankle
    boxes is first pick the first ratio R1。 and then change the size for S1 to SN。
    So this is for the first N boxes。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所以大小意味着相对于原始图像的大小。比例是宽度与高度。所以这里的想法是生成 M 加 M 减 1 的锚框。所以它不是 N 乘 M，而是 M 加 M 减 1。生成锚框的方式是首先选择第一个比例
    R1，然后改变大小从 S1 到 SN。这是前 N 个框。
- en: and then we're going to fix S1。 This is the size and then change the ratio from
    R1 to R1。 We already have for R2 to RM。 So in total， we have N plus M minus 1。
    The reason why we don't want to do N plus M， which means given any shape， any
    size and any ratio。 we generate one ankle boxes。 That's because it may be giving
    you too much。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将固定 S1，这是大小，然后改变比例从 R1 到 RM。我们已经为 R2 到 RM 做好准备。所以总的来说，我们有 N 加 M 减 1。之所以不做
    N 加 M，是因为这意味着给定任何形状、任何大小和任何比例，我们都会生成一个锚框。这是因为可能会给你太多。
- en: Like if you pick N equal to 10， M equal to 10， it give you 100 ankle boxes。
    So which means 100 ankle boxes for every pixel。 If it's 100 by 100 image， you
    get 10K pixels。 another 10K ankle boxes， then you just run out of memory。 So this
    is a trade-off。 We want to vary the size and the ratio， and we generate a linear
    combination of it。 OK。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，如果你选择 N 等于 10，M 等于 10，那就会给你 100 个锚框。这就意味着每个像素都有 100 个锚框。如果是 100x100 的图像，你将得到
    10K 个像素，另外 10K 个锚框，那么你的内存就会用完。所以这是一个权衡。我们希望调整大小和比例，并生成它们的线性组合。好的。
- en: so then the whole model is like this one。 So we first give an image。 We fit
    into the base network。 The base network do a feature instruction。 You can choose
    an SSD， you can choose a rest net。 you can choose any one as the base network。
    Then the base net will be not output。 A tiny one is kind of give you output like
    32 by 32 feature map。 And then given this feature map。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以整个模型是这样的。我们首先输入一张图片。将其输入到基础网络中。基础网络进行特征提取。你可以选择 SSD，也可以选择 ResNet，或者选择任何一个作为基础网络。然后基础网络将输出一个小的特征图，类似于
    32x32 的特征图。然后给定这个特征图。
- en: we generate the ankle boxes。 And for each ankle box， we're going to do a category
    prediction。 and a bound box prediction。 The other thing here， we've got multi-box
    or multi-scale。 is like the base network give you maybe 32 by 32 feature map。
    And can further have the width and height。 And then on the reduced the feature
    map。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成的是锚框。对于每一个锚框，我们都会进行类别预测和边框预测。这里的另一个特点是，我们有多框或多尺度。就像基础网络给你可能是 32x32 的特征图。然后可以进一步得到宽度和高度。然后在降低特征图时。
- en: I'm going to generate another bunch of ankle boxes。 and then do another category
    prediction and a bound box， prediction。 I do multiple times。 So the basic idea
    here， the bottom， which， is the output of the base network。 the feature map is
    still， large。 So I can generate small ankle boxes to catch up the small objects。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我将生成另一批锚框，然后进行另一次类别预测和边框预测。我会多次进行。所以这里的基本思路是，底部是基础网络的输出，特征图依然是大的。所以我可以生成小的锚框来捕捉小物体。
- en: And in the top， every time we reduce the width and height， of the feature map。
    and we generate slightly larger ankle， boxes。 So we can try to catch up larger
    objects here。 So the major difference here that we， don't need to predict how
    the ankle boxes are they。 And then for each pixel， we just generate a bunch of
    them。 So that makes the pipeline much easier。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部，每次我们减少特征图的宽度和高度时，我们会生成稍微更大的锚框。所以我们可以尝试捕捉更大的物体。所以这里的主要区别是，我们不需要预测锚框的具体位置。然后对于每个像素，我们只生成一堆框。这样就使得整个流程更简单。
- en: Question。 So we're no longer learning like the aspect of the show。 I mean。 or
    the size instead we're just， having these different level scales and just change
    the， growth。 Or I mean， we just have different s， y， and r1。 Yes。 so the thing
    that we don't have a linear algorithm to， predict the ankle box。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 问题。我们不再学习显示的方面。我是说，或者大小，而是我们只是在使用不同的尺度，改变其增长。或者我意思是，我们只是有不同的 s，y 和 r1。是的。所以我们没有线性算法来预测锚框的位置。
- en: we just have to pick up the different， s1 and r1 so that we can catch up all
    these different。 shapes。 So these hyperparameters。 So we can show you that how
    usually we pick up the hyper。 parameters。 But then you see that there's a lot
    of overlapping。 That's true。 We can see how to make the classifier and the predictor，
    much efficient to handle all the things。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要挑选不同的 s1 和 r1，这样我们就能捕捉到所有这些不同的形状。所以这些超参数。我们可以展示给你们，通常我们是如何选择这些超参数的。但你会看到有很多重叠。确实如此。我们可以看到如何让分类器和预测器更加高效地处理这些问题。
- en: So that's SST。 Another one。 So you can see this is the SST performance。 The
    x-axis is the throughput， number of， mh per second。 The y is the accuracy， you
    can think about。 So we can go up to the right corner， the better。 So you can see
    that SSC much faster can point out fast as。 the yellow ones compared to the blue
    one。 Well， the accuracy is OK。 Like SST is two。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是 SST。另一个。你可以看到这是 SST 的表现。X 轴是吞吐量，每秒 mh 数量。Y 轴是准确度，你可以理解为准确度。我们可以尽量向右上角走，越高越好。所以你可以看到，SST
    比较快，可以指向黄色的那些，和蓝色的相比。嗯，准确度是可以接受的。就像 SST 是 2。
- en: three years ago， or two， three years ago， algorithm。 So you'll always see we
    cannot show you a little bit of， leather。 This is last year。 So SST at that time
    outperformed fast-dossy and， family a lot on speed。 But they sacrificed accuracy，
    but people still use it at， that time。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 三年前，或者两三年前，算法。所以你总会看到我们无法展示一点点的，皮革。这是去年。所以当时 SST 在速度上超越了 Fast-Dossy 和很多家庭。但他们牺牲了准确度，但当时人们仍然在使用它。
- en: especially when they're faster inference。 Question？ [INAUDIBLE]， [INAUDIBLE]，
    Well， I'm both。 We can talk about what is map a leather。 OK。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在更快的推理时。问题？[INAUDIBLE]，[INAUDIBLE]，好吧，我是两者兼顾。我们可以讨论什么是地图皮革。好的。
- en: '![](img/05fab0db4e7a87b062198d26472634f4_1.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05fab0db4e7a87b062198d26472634f4_1.png)'
- en: So another one is the yellow one。 No， the green one。 It's called a yellow。 You
    only look one。 This is kind of front UW。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以另一个是黄色的。不是，绿色的。它叫做黄色。你只看一个。这是前置 UW 的一种方式。
- en: '![](img/05fab0db4e7a87b062198d26472634f4_3.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05fab0db4e7a87b062198d26472634f4_3.png)'
- en: The idea is pretty simple。 We were not diving deeper into that family。 The idea
    is like on SST。 all these anchor boxes just， are highly overlapped。 For each pixel，
    nearby pixels。 we generate a bunch of， anchor boxes almost like they are going
    to overlap。 For you law。 we don't want so much overlapped anchor， boxes。 What
    it does is like， give an input image。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法很简单。我们没有深入探讨这个家族。这个想法就像 SST。所有这些锚框只是高度重叠。对于每个像素，附近的像素，我们生成一堆几乎要重叠的锚框。为了你们的法则，我们不希望锚框重叠太多。它的做法是，给一个输入图像。
- en: give an input， feature map。 I can't even divide it by S rows and by S colors，
    which。 you generate as times S， like anchor boxes。 So everyone's not overlapped。
    Then for each anchor boxes， we can predict the B boundary， boxes。 because we reduced
    a lot of the anchor box。 And we have maybe have more boundary boxes。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 给一个输入特征图。我甚至可以将其按 S 行和 S 列划分，你生成的是 S 乘以锚框。所以每个框都没有重叠。然后对于每个锚框，我们可以预测边界框。因为我们减少了大量的锚框。也许我们有更多的边界框。
- en: But then for each anchor box， we can predict the B。 Usually you want it to one
    boundary boxes。 So that's a basic idea。 That's why you only look for one。 That
    is。 the anchor boxes will be not overlapped。 I will not go to the detail about--，
    you will have a V2。 have V3。 Basically， you will be once very different to SST，
    but V2， very close to SST。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但是对于每个锚框，我们可以预测B。通常你希望它是一个边界框。所以这是一个基本的想法。这就是为什么你只需要寻找一个。也就是说，锚框将不会重叠。我不会详细讲解——你将会看到V2，有V3。基本上，它会与SST非常不同，但V2与SST非常接近。
- en: Fast-out C and all these families very close to each other。 And how to do prediction。
    how to do class prediction， how to do boundary box prediction， they're very close
    to each other。 And V3 added another tiny improvement。 But the basic idea， it'll
    make it faster。 So you can see that the u-lock， the green one， up to the right
    one， which is， I think， two times。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Fast-out C和所有这些家族非常接近。如何进行预测，如何进行类别预测，如何进行边界框预测，它们彼此非常接近。而V3增加了另一个微小的改进。但基本思想是，它会让速度更快。所以你可以看到那个u-lock，绿色的那个，向右的那个，我认为它是两倍快。
- en: maybe 1， to 0。2 times 1。5 times faster than the tiny SST。 But we can improve
    that course a lot。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 可能比小型SST快1到0.2倍，1.5倍。但我们可以在此基础上做很多改进。
- en: '![](img/05fab0db4e7a87b062198d26472634f4_5.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05fab0db4e7a87b062198d26472634f4_5.png)'
- en: Okay。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。
