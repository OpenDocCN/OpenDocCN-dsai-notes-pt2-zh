# 智源大会 2024（四）



# 2024北京智源大会-大模型产业技术 - P4：大模型训练方法论及Yi-Large的实践：黄文灏 - 智源社区 - BV1HM4m1U7bM

还有谢谢谢仲远的介绍和邀请啊，我简单自我介绍一下，我叫黄浩，然后现在灵异万物主要负责预训练部分，就包括language model，就是语言模型和多模态模型的预训练，OK然后我们可以先介绍一下。

就是我们在上个月发布的e large模型，然后这个其实是我们上一上一代的一个模型吧，然后他是一个千亿以上的一个稠密模型，当时发布的时候，其实可以看到，在很多指标上都已经就是接近或者超过了，呃GB4啊。

然后cloud呃的呃，GEMINI这些就是海外的第一梯队的模型吧，然后我们其实还有一个更大的一个，MOE的ex large模型在训练当中啊，这个应该是当时发布的时候的一个分数吧。

啊现在其实比当时还是呃就又训练了一段时间，还是会有小幅的提升对，但这过程当中，其实因为这个这个这些数据，主要还是我去收集和自己去做一些评测的，然后我们也发现了一些问题，就是发现大家的就是公开的评测数据。

其实是会有很大的呃，BIOS一个是我发现对点这个问题很难对，就是大家比如说拉玛三，他报的点，我用了各种评测的框架，其实都对不上呃，然后我们最后选的都是，他们当时自己报的一个成绩。

但我们从来没有测出过这么高的成绩对，然后包括这个GP4和cloud，那些API其实是一样的，那这里面其实会有很很多问题，然后第二时间题目其实都会相对来说，是先静态的题目吧，大家可能会用一些。

就是在这个领域去构造一些数据来做做，做一些就是对这些领域的定向增强，然后同时我们在发布这个模型的时候，提出了呃一个就是模音一体，就是模型和应用要一体化的概念，所以我们想找一个和我们应用场景更加接近的。

一个评测数据集，然后我们也发现就是open i和呃，google还有cloud，大家都比较认可的一个评测集叫LLM cs，然后它是这里是一个简单的演示，就是用户会提一个问题，然后这问题是用户随机提的。

所以就不存在任何就是题目泄漏的一个问题，然后在后台就是LMC4的那个主办方，他们会随机选两个模型，然后生成两个答案，这时候用户去做一个选择，就是哪个答案好，在做选择之前。

其实他们也不知道就是A和B是哪个模型，有点像我们自己在产品里面会做一些，就是呃AB测试这样的一个感觉吧，但是它是一个完全的一个盲测，然后我们觉得这个就比如说这里面，用户题目的分布和用户实际使使用。

就是CHECHARGET类的，chair bot的分布式更加接近的，然后这样的评测也会更加的公平和客观，然后然后国际的第一梯队的厂商，其实也在使用这个呃。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_1.png)

LMCS作为一个评测的一个榜单吧，啊然后我们提交完以后应该是额差不多呃，一就我们发布完一周左右的时间，就发布那天LMC4才可以测，就是他们还是有一个比较严谨的一个流程的，然后一周左右出了我们的成绩。

然后我们成绩差不多是在就是世界第一梯队，然后在我们前面的只有就是open an，ANTHROPIC和呃google的模型，然后一这里看到的是第七，其实因为open i他们提交了四个模型。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_3.png)

在上面，然后进步的话里面，其实还有关于中文的一个排行榜，然后我们和GP4是并列第一的一个能力，然后还有一个就是他们叫hard prompt，就是因为prompt里面用户有些问题会，比如说你好啊。

比如今天星期几这种比较简单的问题，也有一些稍微复杂的问题，所以他们做对这个问题做了一个分类，因为之前在简单问题的时候，大家基本上会选一个打平的选项，所以这个分数会有些BIOS，然后在这个复杂的排行榜上。

我们基本上也是处于全球第二的一个水平吧，然后这让我们对自己的模型会比较有信心，然后我们自己在海外的一些产品当中，其实也做了一些就是AB的测试，其实会发现用我们的模型。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_5.png)

比如说和GP3。5做比较的时候，用户的呃留存，然后付费都是有比较大的一个提升，然后和GB4做比较的时候，基本上是打平，就因为数据不会掉，其实这个给了我们比较大的信心。

说我们这个模型其实训练的还是挺不错的，嗯除了这个必然模型，其实呃灵万物也做了很多开源模型的工作，这是去年11月份我们做了34B模型，当时在哈根face的呃LM里lead bd上呃。

也排在就是全球第一的水平呃，然后今年就是上个月，我们其实也对这个开源模型，进行了一系列的更新，发布了一呃11。5系列的一些模型，然后这些模型都是开源的啊，这里面其实也发现。

就是因为我们当时做34B模型的时候，是特特地选择了一个，对用户来说相对比较友好的一个尺寸，就是呃三四部分模型做完量化以后，是可以在一张4090卡里面去放假的，然后我们就就方便了很多用户去做呃SFT。

然后以以及去做现prompt engineering，然后当时受到了就是国外的很多开发者的，者的好评和反馈吧，然后有很多人就跟我们做联系，联系我们，然后也基于我们的模型，其实做了很多的呃很多版本吧。

比如说呃比比较有名的，有就是呃呃north north research他们做的open harms模型，其实很多多模态模型的，后面的语言模型都是用的这个模就是E的模型。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_7.png)

作为一个基地的对，然后今天主要是跟大家分享一下，我们在做预训练的过程当中，主要坚持的一些就是我们称为方法论吧，然后分别包括就是skin law呃，The the blesson，就是苦涩的教训。

然后高质量数据系统工程，还有对人才的一些判断，OK啊啊，前面那一页可能不知道为什么会有些乱码，就是他其实是对呃skin load一个定义吧，然后这个大概是模型输出的一个结果，然后可以大概说一下。

就是因为大家其实现在很很多人都在谈论skin law，包括上午的就是呃论坛里面，就重重点的论坛里面，大家也讨论了很多skin law的问题，然后也有人去呃去质疑skin law能不能通向AJI。

这个事情，对我觉得，首先我们需要对skin law有一个就基本的定义，其实它是表示，就是模型的性能和资源之间的一个关系，那这个关系其实很简单，就是资源越大，字会资源越多，模型的性能就会越好。

所以从这个这个层面上来看，我们觉得skin law是没有问题的，那然后我们其实比较好奇的是，skin skin law能不能通向AJI，然后我们可以看一下过去几年的一个表现吧，就是这里面的重重重走。

应该是就是数据，然后它是一个指指数级的一个增呃，就是算力就是一个指指指数级的增长嘛，就训练模型所需要用的flops，然后右边其实代表了不同阶段，模型的一个能力吧，比如说gg p two。

大家会认为它是一个学前儿童的能力，然后GP3是个小学儿童的能力，然后GP4可能是一个高中生的一个能力，然后未来我们可能就是模型是可以自动的，去做AI的research和engineer的嗯。

但大家怎么看，就是这个能力它是线性的，还是指指数级的，如果大家觉得这个能力是线性的话，那就是说随着资源的指数消耗，模型能力可以做到线性的增长，如果觉得这是指数级的提升，那就是两边其实就是个线性关系了。

然后右边其实给了很多，就是大家在评测级上的一些表现，就每每个模型刚出来的时候，其实可能就最低的一个点，然后呃随着就是训训练呃，训练用的算力的增增加，很很大，多数的能力都会有了一个很大的一个飞跃。

然后前面我介绍其实是广义的4SKYO，然后其实还有比较狭义的思skin law的定义吧，我觉得这个可能就是做技术的同学，会相对来说觉得更能接受一些，这个其实是来自于open i的一篇paper。

就是关于skin off neural language models啊，这也可以注意一下，他的一作就是java kaplan，他是一个物理，他是研究物理的，就是像skin law这个公式啊。

后面会讲它的一些公式啊，就是其实和物理会非常像，比如说跟我们常见的万有引力定律的一些公式，会非常像，然后做物理的人是会很会把这些很经验的，或者系统性的实验，然后进行一些建模，然后把它做一些提高的。

然后这里面其实我华丽很一些，重点就是说首先它是一个经验性的公式，就它不是一个严格的数，有数学证明的公式，只是我们有了大量的实验结果以后，可以发现用一个很简单的呃，方程式来来把它就是表示起来。

然后这个这个公式还非常的work，然后它有很多作用，这里讲了一个作用是可以去计算最优化的，就是资源的分配，就说如果我们给定一个算力的一个budget，就是你有多少算力可以使用，那我们应该怎么去分配数据。

怎么去分配那个呃模型的参数，然后呢这边paper其实有大量的一个数学公式吧，然后如果就这里我选了一个最重要的公式，应该是论文中的公式，1。5对它其实是这样的一个表示形式，然后这个L是表示模型的loss。

然后loss越低就是模型能力越强，这是一个就是线性关系，然后这个N是模型的参数量，N对模型的参数量，D是模型训练使用的数据大小，然后剩下的就带角标的，全都是全都是常数，也就是我们用大量的。

比如说大家之前会从比如说100万参数的模型，一直训练到呃呃一一千万参数或者稍微大一点，就是5000万参数的模型，然后通过这些很小的模型的训练，我就可以去预测大模型的表现会是什么样子的。

然后通过前面的很多打点，就把这些呃常数给拟合出来，拟合出来以后，根据我们现在想训练模型的大小和模型的参数，我就可以预测这个模型的loss，大概会训练到什么什么程度，那这个公式有哪些重要的意义呢。

第一个就是我前面说的广义的词skin law，就是我们可以发现，就是因为这个N和D都在分母的，就这就分母越大，然后这项就越小嘛，所以整个loss就会越低，所以它就代表数据越多，模型的能力越强。

然后参数越多，模型能力越强，然后这个是很显然的一个广义的词skin落，第二就前面介绍了，就给定computer，就给定给定的算力条件下，最优的setting是什么样子的，就是我们应该创一个多大的模型。

用多少的数据，然后因为就是算力其实是等于6ND就是六，就是一个简单的计算公式，是六倍的呃，参数量乘以一个数据量，就会大概估计模型训练的flops，所以我们可以判断在这个环这个条件下。

数据和参数的收益是什么，是怎样的，然后第三个其实是它会这个公式，有很多的可扩展性，就是说我们会发现，我们在很小的模型上做训练以后，我就可以去预测，比如说大100倍的模型。

它的loss表现大大概会是什么样的，这样可以节省我们大量算力，我们在很多研究都可以在小模型上面做，然后我们利用小模型去理拟合这个skin roll公式，我就可以预测模型变大以后的效果。

同样对很多对模型结构的改变，都可以基于这个公式去做，然后这里主要介绍一下，就是就是最优的setting大概什么意思，就是比如说我们选定了我，我的算力大概只有6亿呃，18次这样的一个flops。

然后它的横轴是模型的参数，因为前面介绍了就是呃呃呃算力数据，还有参数之间的公式，就是C等于6ND，然后确定了就是呃算力和模型的大小以后，我就可以知道这个数据是多少，然后在这个配比下就可以呃。

得到一个就是一个曲面，就是不同的setting下面哪个模型的效果会更好，这样最优的可能这个点是最优的，然后这样我们可以得到就是不同算力下，它最优的点，这个其实是对我们选择模型的参数量和呃。

数据是有很大指导意义的，然后其实有很多人在质疑以前skin law的问题，比如说呃朗玛三乘了15T的数据，已经远远超过了这个最优值微微，但它模型效果还是很好，其实因为它给定的是一个给定算力条件之下的。

一个限制，然后我们也可以分析下这个问题，就是如果我给定模型的参数，就类似于拉玛三做的啊，这这是1B就比如假设这是8B的一个点，那我给的算力越多，就代表我给的数据越多，所以它是一直可以提升的。

就并不是说我的呃，我我呃，我确定了最优的参数以后，我的数据就不可不可以提升了，但当然我们回到前面的这个公式也可以发现，这个提升收益肯定是有效，是是有限的，就这项随着地变得越来越大。

就模型的用的数据越来越大，这一项其实会趋趋向越来越小，所以大家大家可以估计到，比如说用呃10T的数据和用15T的数据，我大概能带来的loss的增增益是多少，其实这些都是可以提前估计出来的。

对然后再讲一下，就说loss的可预测性，这这这两张图是来自于欧派的，就是呃GP4tech report里面，就是我在用很小的算力的情况下，那可可以看这里的横轴，其实是一个就指指数级的增长。

所以我可以用就十倍以下的呃参数，然后训练很多模型，然后对模型在某一个能力上的loss，进行一些打点，然后做完打点以后，它就可以拟合出一个曲线，然后我训练就两个数量级，就100倍以上的一个模型。

然后它可以精确的的预测就是模型的表现，其实用的就是前面那个那个公式啊，这个其实在我们自己训练大模型当中，我们花了很长的时间，去把这套skin load系统建立起来，这样我们的所有大模型的训练。

其实是比较丝滑过渡的，然后这里还会有些很衍生出来非常有趣的事情，就比如说大家会讨论，就最近讨论很多的，比如说transformer结构会不会被member结构，griffin结构，就这种结构给替替代掉。

其实你回到这个公式，大家可以自己去做一些实验，就是把把这个数据和模型参数量固定下来以后，我们只要TRA很小的模型，确认一些模型以后，就可以去拟合一下这个skin law的一个公式。

然后就可以得到这些系数，就间间系数如果越小就整整呃，应该是越大，因为这项会小于一嘛，就这先系数越大，这一项就会越小，然后就证明这个模型的可扩展性其实是更好的，那这样其实是很容易去比较出这些模型结构。

哪些在什么样的setting下，它会有更好的一个表现呢，对，然后这这个方法其实同样适用于我们，对transformer结构做一些改变的时候，就比如说，呃我们常见的有就是PRENORM。

就是在每一层之前去做normalization和post norm，在后面做某normalization，然后这个其实我们去做一些setting和skin load拟合，就可以知道在什么样的条件下。

哪一种norm方式更好，还有最近就是像deep sick，他们提了MLA的一些方法，然后我们要比较不同的TENTION机制，比如说multi head attention。

Multicquattention，group quattention和呃MLA的时候，其实也可以用这样的参数去呃，比较给定算力下的一些训训练，loss1些变化，这样其实对我们去做一些呃。

模型结构的改变是有很大的一个指导意义的好，然后第二点是the blesson，就是这其实是来自rich sutton的一个tag blog，对这这也写了很多，我就用中文，很简单的讲。

就是有能够有效利用计算能力的方法，通常会有比较好的结果，然后这个其实跟skin law是相符的，就是这两个其实是要联合起来看的，也就是说呃，我们其实优化的。

其实就是对competition的一个使用的一个能力。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_9.png)

然而competition也是skin里面最重要的一个部分啊，这贝贝lesson有很多人在看这个是找JSON way，在就是open的个researcher，在推特上发的他的每天工作时间。

然后可以发现它每，这里面有两个非常有意思的点嘛，这个框出来一个是早，比如说早上他会他每天都会学贝特lesson，就是要反我跟他们内部人聊，他们就说就要反复阅读并背诵贝特lesson对，然后第二个点是。

他们每他每天五点会跟大家讨论，算法有什么可以改变的，然后5。05这项就结束了，然后觉得算法的改变太risky了，大家应该去做，就是计算和数据的SKR。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_11.png)

哦这里就是学BLESSON以后，就是我我觉得他要跟skin law结合起来看，就是说我们现在看问题的视角可能有些不一样，因为我自己之前在MSI也是做一些research的工作。

就是我们会发现研究范式有了一个很大的变化，因为我们之前的研究基本上是在算力条件，就是增长不是非常迅猛的呃，就非常速度的情况下进行的，也就是说它算力条件可能每年增加增加一倍，然后在这种情况下的话。

假设有一个方法，它是这个这里面的这条红色的线，然后我们做研究的人其实是在做各种各样的对，针对这个方法的优化，所以针对这种方法优化，会提高这个方法的起点，然后这个起点做了提高以后。

就可以得到不同的一些新的方法，然后有很多新的paper出来，在当时这个时代，其实这种方法是很很work的，但到了现在这个时代，就是每年的算力可能是一个指数级的增加，就是我比如说每年算力增加十倍。

这时候起点已经没有那么重要了，这个方法的斜率才更加的重要，然后我们回过头来看，我为了提高这个方法的起点，我相当于给这个方法加了很多的prior，就加了很多的鲜艳，就是做机器学者其实会知道各种各样的鲜艳。

其实是会损害这个方法的一个泛化泛化能力的，所以他的斜率就会变低，那在这种情况下，其实大多数在，所以我们回过头来看，之前的很多研究工作都在雕花，因为雕花就是说你在一个小的算力范围之内。

我不自断地提高它的模型能力的一个起点，但是到了一个更大的尺度下去看的话，这些工作其实都变得没有意义了。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_13.png)

而这里其实会引引申出一个非常有趣的讨论，就是我们去年发布E34B模型的时候，其实有很多人，比如说我们的模型借鉴了拉玛三的结构，然后还有人说我们抄袭了二三，然后我觉得这里面分几个角度来讨论吧。

就第一个是我们在开源的时候，做的不是非常规范，有些变量名没有没有做好，这个是我们做的不对，但是当然如果说我们借鉴了朗玛三结构，这个事情，就这个呃呃如果说抄袭这个就是无稽之谈资产，然后就说借鉴拉玛三结构。

其实我觉得有些可以可以可以研究的事情，就说呃一个是拉玛三的结构，这个事情就现在很多人说，lama architecture就是没有拉玛，就没有中国的大模型，我觉得这个我自己是完全反对这个观点的。

然后就是这是lama的paper里面，他对于architecture部分的描述，它说它们是基于了transformer的结构，然后只做了三个不一样的地方。

然后第一个是把传统的POSTOMM改成了PRENORM，然后这JPGP3就做了，然后第二是用了sweet group，然后就把软路换成sweet glue，第三个是换成了loop，所以有很多人说。

就比如说这是TAE的线twitter，他说就其间很多的改进都是google提出来的，然后大家却把它叫做一个拉玛三的architecture，这个是完全没有道理的。

然后他们自己的tech report也把它称为了norm，Architecture，就是norm其实是这里面很多技术的发明人嘛，其实我这里想说的是一个就说呃，从transformer17年提出到拉玛。

应该是去年提出很多年的时间，其实模型的结构并没有太大的变化，一共大家也可以看到只有这三个变化，所以说我们用最简单的方法，只要去scale up这个competition就可以了。

然后然后第二就是如果我们自己做训练的时候，其实这三个改变都是有损害的，就是要我我前面讲了，会发现他们follow lama的结构并不能很好的scale up，其就是LARA，比如说做70币还好。

你做一个200B300元模型，其实是会碰到很多的瓶颈的，就是他做的这些改变并不是都是有效的，呃它在不同的算力条件下其实是有不一样的点，那我们可以分享一下，比如说我们做了很多实验。

发现当模型参数超过千亿以后，用post post norm可能会比PRENORM更好，只是你要把它调的更稳定，然后第二就是sweet glue，比软弱收敛性快，但是它的计算能力是计算所花的时间是更长的。

所以我们用海量的算力的时候，其实是要去平衡这个它带来的额外的时，训练的呃，时间和带来的快速收呃，收敛之间的一个trade off的，而lop也是lope，其实现在会占到呃。

transformer或者GGPT系列模型训练，大概10%左右的时间，那在很大的算力条件下，是不是不用loop，可能我可以节省10%的时间，我可以把收敛那个时间换回来。

这个是需要大家去做很多的实验验证的，那做实验就可以用用selescreen or for load，方法去做一些验证吧，OK然后这个其实是欧派呃，里面一个员工写的一个一个blog，我觉得非常有意思。

就可以分享给大家，就是说一个是说我们在一个同样的数据集上，训练足够长的时间，假设我们的算力是无限的，所有模型都会收敛在一个点，就不管它是transformer，它是即使是CN，他可能也会收收敛在一个点。

那这里面其实区别是什么呢，区别就是哪个模型可以更快的收敛到那个点，或者更快的接近那个收敛的点，其实这里以就是有价值的，其实就是对算力的有效使用效率，然后他还提出一个观点。

就说如果所有的模型在同样的数据集上，就不不同的模型架构的模型，在同样的数据集上训练都会收敛在一个点，然后我们假设现在大家发布的这些模型，都是收敛的情况下，那其实决定模型的能力的其实就是数据。

所以每个每个模型它不代表自己的模型架构，也不代表自己的呃，呃训练过程只代表了它原始数据的一个质量，就这就引申了我下面一个要讨论的点。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_15.png)

就是说高质量的数据是在这里面最重要的，然后这里面是截了呃E的tech report里面的呃，两两张图片嘛，就我们有个比较复杂的一个，数据处理的一个流程下，其实这个现在基本上大家都很重视数据。

应该也都有这样的数据处理流程，我可以分享一下，就是我加入灵万物之后，前三个月其实没有让团队训练模型，就基本上我们只训很小很小的模型，去建立SSKIN落，剩下所有的时间都是在做数据这个事情。

然后到9月份以后，我们的数据比较ready的情况下，我们去训练模型就会非常的顺利，所以我们每个模型基本上都是一次训练出来的，然后在同等参数下都可以对比其他友商训练好。

就是这个数据质量是非常重要的一个工作吧，然后聊到数据质量，其实大家也会经常问的一个问题，就说数据会不会用尽，这个其实是之前一篇paper里面的图，就说假设数据是一个线性增长的状态，我们现在对数据的消耗。

其实超过了这个数据的一个斜率的呃，我在这里我可以分享一些，我对这个问题的一些观点吧，就是这个更多是个人观点，第一就是我们发现数据增长的速度，是比预期的要快的，特别是很多语言模型出来了以后。

网络上有很多原模型生成生成的一些数据，然后这个数据的质量我们去处理，就是每年不同的那个，就我们拿com CD来举例子的话，其实是由大量的一个增增加的，然后第二个就是合成数据，其实现在很。

就刚才谢健也提到了很多，关于合成数学研究工作，然后我们自己其实也做了大量合成数据工作，然验证了合成数据的一个有效性嘛，哦这里我其实截了一个翻web，他们对数据分析的一个图。

就他发现用24年的数据去训练呃，原模型，它效果就比23年要好，比二让呃，然后这个原因就是他们分析一下发现，因为现在的数据里面已经有大量是语言模型，生成的数据了，这GP4生成的数据。

这就导致我们用把所有的网上数据都拿下来，以后，我在训练的时候效果就是会好，这从侧面验证了我们用模型产生的数据，去训练模型，这个是可以让模型就不停的去做一个提高了，呃，啊。

第三个是我个人觉得最近比较有趣的一个，finding吧，这是我们在做多模态预训练的时候，发现用多模态的数据是可以提高模型的智能的，这是呃，所以做多模态也不是扩展了语言，模型的一个能力。

而是真正的能提高语言模型的智能，然后这里面有也有些很很有趣的研究工作，然后这研究工作其实是非常理论的一个工作，然后当时伊利亚也对，就离开open安以后，也对这个工作做了一个点赞吧，就是他的其实含义。

简单来说就是假设这里有个Z这个数据，你不管是用语言描述它，还是用图像记录它，当你做多模态模型训练的以后，这两个数据的表征是我会造，会越来越趋向于收敛到同一个表征空间，也就是说他们在做压缩的时候。

是会压缩到同一个点的，然后如果有了这样的理论基础的话，就是我们可以认为就是多模态数据是完整，就是扩展了，就是呃语言模型的数据的一个缺口，那我们未来就有大量数据可以使用，好看看快超时了。

我后面两页稍微快一些，就是呃第四个点其实要分享的是大模型，其实是个极致的系统工程嘛，就是去年XGP刚出来的时候，大家很担心的事情是，比如说国内有没有相应的算法人才啊，比如说我拍google研究了这么久。

大家之前其实没有怎么训练过大模型对，然后实际做的发时候会发现，这里面其实对研究的呃需求，其实没有对系统的需求大，就是包括前面的数据清洗，然后训练过程中的一些就是训练的dynamics。

其实都是一些非常细致的一个系统工程，我们需要把系统工程当中的每一环做好，然后每个细节都都抠的很细，自然就会有比较好的一个成绩对，然后第二个是说呃，就大规模的机器学习其实是一种实验科学。

就很多人想就是在质疑，比如说deep learning是没有数学解释的，但是其实open在一开始就有这样的认知，就说大规模机器学习是实验科学，我只有通过大量就不停的做实验。

然后用实验的数据去去得到一些近似的一些，就是数学的一些表示，然后这个过程其实和前面提到，和实验物理是非常接近的，就是我们通过大量的实验呃，消耗了大量的算力，得到了大量的结论，然后去推动智能的一个发展。

然后第三个就是因为他是个系统工程，所以我们需要就是又懂算法，然后又懂INFA，又懂工程的这种复合型人才，就是之前国内人才，可能他在单一方面都会做的很很很强，但做到一些比较复合的事情的时候。

是会有些困难的，然后所以我们比如说我们对团队的要求是，要懂算法，要写库大的可能，对然后最后回到人才，就是这也是这段时间，我跟大家经常有争论的一个点，我觉得中美的人才差距其实非常小。

就美国有一部分非常top的人，OPII可能有一些XAI会有一些，但是他们只是因为过去有了比较好的经验，在做这个事情，但是国内的就是聪明的人是完全不比美国少的，然后大家现在很重重视大模型。

投入了比较多的算力，所以呃现在有很多的人都非常的强，就是我觉得就一点都不比一，就是呃头部的那些机构的人才差吧，然后里面有很多非常呃非常年轻的new new，Fresh pp h d。

他们展现出了非常强的一些潜能吧，然后第二个就是说这些人才需要是算法，INFA工程一体的，就是过去这种比如我算法很好，但我不太会写代码，对我我不懂info，我不知道怎么能把一个高效去训练，算法调的更高效。

这人间可能是不work的，如果这方面都是懂的话，其实这样的复合型人才可以发挥很大的作用吧，呃第三个其实是我们给自己的一个要求吧，就是其实我的团队一直都只有十多个人对，因为我们要求。

每个人的人均GPU要超过1000张，就是如果公司的GPU还没有在网上，扩展到2万张，就不要招人，这啊只有在这种情况，但当然这1000可能拍的有点随意啊，但但我是觉得就是每个人需要有大量的卡。

就如果如果就是比如我们可以定500，可可可以定定200，但是呃每个人如果没有大量的卡可以玩，你招人其实都是副作用，然后只会让大家去抢卡对，然后最最后就是我们会很坚持招非常年轻的。

我前面讲了很多new fresh p h d，因为他们其实因为最近大家一直在讨论，AI native嘛，就他们从做research开始就是LLM native的。

他们接触的第一个research就是大悦模型，而不像像我们这一辈的人，就是之前可能呃对我我可能还比较好，我是我，我做博士的时候看，在第一年就看到了deep learning。

然后完全就决定all in去做deep learning，但是当时不是从SKYUP的角度去看问题的，就相当于我前面讲的，我们在做很多提高方法起点的事情，但没有去重视这个斜率，而现在很多很年轻的人。

他们从一开始的视角，就是去重视方法的斜率和SCALABILITY，这个其实是非常重要的。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/ade5dd4185be5ba68b679a61d245aced_17.png)

好我分享就到这，谢谢大家，对好非常谢谢文浩，非常有insight的分享啊，那个看看，因为时间比较紧张，我们现场看有有哪位朋友想提问的，我们一个问题吧，好那位穿黑衣服的同学，哦你好。

我可能可能问几个问题啊，就是第一个是关于那个SKYUP范围这个事情，就是从你角度来看呢，这种SKYP的范围如果到两年之后，这种就是比如说现在是200K，可能未来是500K怎么样。

两年之后这个scar5的范围大概是多少呢，从你角度来看，我觉得就是你就是scale up的范围是吧，呃对对呃，sky up就是那个那个输入的文本长度哦，你说长度的范围就是我觉得长窗口这个事情。

现在已经是一个被业界解决的问题，就你只要解决算力问题就可以了，就是在技术上基本上已经解决了，我们有一些paper就说怎么去做长窗口，长窗口问题了，对所以它只是个算力问题，它不是个技术问题。

所以你认为它是会无限扩展下去吗，对对理论上是可以无限扩展，就是它它的增长其实跟你的算力是有限的呃，是是直接一个正相关关系，就是你现在有多少的算力，你就可以做多少的窗口哦，好的好的。

第二个问题是关于是关于一个数据类型的，就是我们看到再去训很多这个模型的时候，其实比如说我们会用呃，IP8这种混合精度的训练呃，像英伟达也推出了他的IP4FP6，对于这两个进度你是怎么看的，你现在会用吗。

呃因为就是现在的H100其实还没有这方面的，就是我们现在应该没有拿到，可以支持FP4和六的一些机器吧，但是我们在做e large的时候，是完全用FP8训练的，就是你只要解决工程问题之前。

就是之前提高效率的方法都是work的，好的好的哦，好我我多问最后一个问题啊，好意思，就是我们现在看到所有的语言模型能力，其实最后都会比较趋同对吧，呃就单纯从语言来说，那国内这些大模型厂商。

你觉得就是互相之间竞争的差异化，会在什么地方，对我觉得其实模型能力比较趋同，这个我并不100%白影，就是我因为我也玩各个厂商的模型嘛，我觉得大家的还是有自己的特点的，就前面回到前面说的那句话。

大家用的训练数据肯定不是100%一样的，肯定有overlap，但是每每家会有一些自己侧重的数据，然后比如说我们会更侧重globalize的一些数据，就是会放很多其他国家的语言的数据进去。

然有有些厂商可能侧重于娱乐，有些侧重于呃医疗，所以每个模型能表现出来的能力，也是会有差异的对，然后第二就是呃，我觉得大家商业模式可能也不完全一样，就是自己每每家其实基基本上都是有自己的一，些商业模式吧。

所以渐渐可能也会有些分化。

# 2024北京智源大会-大模型产业技术 - P5：混元大模型的研发和业务应用之路：康战辉 - 智源社区 - BV1HM4m1U7bM

好大家下午好呃，首先感谢志源和中原院长的邀请啊，呃我是腾讯会员呃，以及这个I搜索的负责人康振辉，下午呃，跟大家去分享一下，这个我们腾讯会员大模型的一个技术研发，以及它的应用落地，对。

那前面几位刚刚我们的同行嘉宾也提到了这个，其实呃猪根溯源，我们那个整个的GPT它的一个基础结构，这个transformer结构，其实也不是什么新鲜的这个东西啊，像2017年。

其实就由google上提出来的一个标准的，完整的transformer，实际是它是一个encoder和decoder这么一个结构，那很快啊随着这这个呃传播出来之后，其实业界就存在三种不同的路径。

那最早期像18年，很快这种双向encoder的这种啊，典型的做个这个工作就是BT啊，这个基本上是啊代表了这个上一代，我觉得是RP的一个创，一个跨越式的一个发展吧，呃在此之后。

其实我们国内外很多同行实际上都在follow这个啊，领域去做这个，那会还不叫大模型，那会应叫应该叫ptrain model，那另外还有一条路就是呃很快接着啊，基本差不多，同时吧像这个最早的GPT啊。

一到后面的那个google的T5很快出来之后，你就会发现这两条路径，其实最早期包括到TP3的时候啊，这个T5T5也出来了，那那个时候其实大家发现这个整个的T5，又成为那个时代的一个SOTA模型。

就是这种encode decode这种结构，那这条路线就一个叫ECODECODE，一个decode learning，基本上也是后来成为业界啊follow的一个主流吧。

尤其是以下面encode跟decode这种结构呃，当然上面迪克罗尼像啊，我觉得可能国内的各家吧，其实大家都在尝试过，但即使到GP3的时候，其实发现其实这条路线上面，其实当时投入最大的。

其实说实话还是open i啊，包括google自己其实也没有去follow这个路线，主要还是因为当时七比三啊，刚刚讲前面去讲啊，几位前面讲这个skin的问题啊，还是没有达到说诶一个效果。

有一个有个突然的这个这个呃跃升，所以包括我们自己啊，腾讯会员啊，我们会员其实在做这个大模型，或者叫这个生成大模型之前，其实我们在202122年，我们上就已经在做一些跟啊大门相关的。

不过我们那个时候是我们应该叫做pretrain model啊，那个时候我们是一个T5，类似这样的结构，那其实讲到这个三条不同路线啊，其实我们可以看一下这个引用了一个这个呃，这个理查德费曼对吧。

他是一个很有名的一个物理学家啊，讲过一句话叫做说，如果我不能够很好的这个创造，那我就不能够理解，那翻译到大模型或者AJI领域，我们就今天可以解读为说，如果我不能去生产，那我就不能理解。

那就变成了JOOK，今天我们通过生成式模型去解决了，所有理解跟生成的问题，那这个其实也是欧派的一个啊信条，或者叫宪章啊，抵扣欧尼，那这里面我呃提到open，我们就讲讲了呃，刚才我们前面我们那个文浩啊。

不是提到这个这个讲的open这个宪章啊，open这个这个四管齐下啊，那这这里面我是这呃深有认同啊，其实是欧派，其实我们就今天整个的啊，整个的欧派的XGB系列，能够能够这个一骑绝尘。

我觉得他们还是啊深刻的去践行着这四条啊，四条不同的这个思考的方式啊，第一个是说我们要去做，我们要做AGI，我们很重要一点，我们就要寻找，我们要寻找正确的生成模型，那我们从神经网络最早系统BP神经网络。

那很早了，基本上是198几年就有了，到刚刚讲2717年这个transformer，那出来之后，其实我们发现诶我们怎么有一个，我们怎么能够有一个这个啊一个正确的模型，这个模型的吞吐。

它SKILLING是很容易做的，那其实到后面到了22年二三年这一波，其实大家基本上今天我觉得大家国内外吧，我就做这个生成式AI的，基本上都采用了迪克罗尼啊这种结构。

那这是一个第二个就是我们还是另外一个问题，我们一个好模型架构，那我们怎么screen up，那这里面其实啊，刚才那个文浩讲到这个苦涩的教训，就是杰森WCOT的作者啊，他在推特里面提到了。

每天都要去读宪章，然后去去回顾这个苦涩教训，那这里面其实一个背景，刚刚讲我们一个好的模型，那这个模型的参数啊，模型的这个吞吐我们怎么去扩展，那这涉及到一个算力问题，那我们知道我们的摩尔定律对吧。

我们的算力基本12~18个月扩展一倍，但是我们的大模型大家可以去看一下，从GPT1到GP3，到今天GP4啊，甚至GPT5可能已经在路上了，我们发现可能很多时候是在每一年或一年半。

时间都是一个在以十倍的这个速度去扩张，也就是说如果我们去看模型的size，它的增速，它的这个提升的这个速度，是远远高于我们的物理硬件提升，那这里面我们怎么解决这个扩展的问题，那我觉得这里面刚刚讲第一个。

我们的大的batch训练，那这个也是18年很有名的paper，那open今天能够去训练超大型模型，那它的batch一定要开的很大，另外还有低精度的问题，我们用最早期IP32，I p16，B f16。

到今天大家可能很多的我们的一些友商，包括我们自己都在采用，像FF18这样的一些低精度训练，当然为了随着未来这个刚也讲到这个FB4呃，六跟四对吧，这是现在的最新的卡，当然国内也买不到对吧。

但我们知道这个可以看到，就是说我们不论是硬件，还是在我们的这个算法上面，实际上整个都是在去啊探索模型，怎么去能够更有效的去扩展啊，那这两个我觉得很非常重要的，它是体现了我们对世界世界深度呃。

理解的这么两条路线，另外一个就是我们看一下，包括后面出来这种我们的言语学习啊，我的MAMATALL，那这个基本上呃这叫乱码，OK好，那我们通过元学习，那我们其实可以教会了模型啊。

怎么去去做这种fishort zero shot，就我们的ISL能力本身来讲呢，我们只需要一个pretrain model，我们可以给一些啊训练样本，只要很简单，用一些任务描述加测试样例。

模型就可以follow这样的输出，那最后一个那就是我们的TRAGT推出来之后，其实大家看到业界啊，我们有这种叫对齐啊，或者叫模仿学习，那其实上来讲我们就跟教一个小孩一样，像人的智能一样的。

我们不需要去告诉他应该怎么做，我们只要给他一些例子，告诉他什么是对的，什么叫错的，是他就会学会，这是一种模仿学习，另外我们通过强化的方法，可以更加有效的去拉高我们的这个天花板。

那我们都知道我们的pretrain model，或者我们的我们的大模型底座，其实代表的是我们模型的上限，那么通过对齐，通过强化学习，我们来解决是我们的下限怎么往上提，当然这个如果再往后讲。

包括今天我们讲的这个self play对吧，就是我们怎么让整个GBT从类似于alpha go时代，走向阿尔法zero，未来可能我们会有我们自己的g p t zero，好，那前面回顾了一下。

我们这个整个大模型的这个发展历程，以及欧派上面的，我觉得一个给我们一个很好的启示啊，那我们自己来看一下，我们在做大模型，其实我们上是面临我们在算法工程和应用上，实际上都有些挑战，包括在工程上面。

那我们的算力一方面要强，另外方面我们也需要一些高性能的虚体框架，还有我们整个一站式的去做各种各样的呃，业务平台，TESA上面呢我们呃我整个整个的盛世之AI，我们可以看，比如说像我们的大语言模型啊。

纹身纹啊，像我们图声纹啊，也是一种多模态大语言模型，包括文松图，包括啊图声哎，文声视频啊，这样的一些，我们认为啊，今天主流方法可能是以def人为代表的，这样一这样一些算法模型在之上。

我们这个会员的系会员大模型系列上面，我们目前我们自己在公司内，我们支持了很多，我们自己，包括我们的微信平台，包括我们的QQ平台，包括我们的浏览器平台与腾讯啊，在音乐在在整个我们在腾讯云上面。

我们去服务千行百业，实际上都在基于会员啊，我们在对外输出，那目前来讲我们整个会员的模型，刚刚讲我们的呃公众平台，我们是有一个呃超大规模的ego的算集群啊，包括我们星海的服务器。

以及我们自己自研的这个RDMA的网络，高速网卡集群，以及我们啊这种我们的这种呃GPU集群，以及我们室内外啊，包括国内也新创了一些易购芯片，在之上，我们自己推出了我们的这个这个android的这个。

集群的框架，我们目前我们这个会员我们可以看，我们基本上在文身文来讲，我们大语言模型去覆盖，像我们中小size的啊，这7B13B啊，到我们最早第一代，我们去年刚推出第一代的模型啊。

是一个1760亿的176B的模型，那到今天我们基本上把这些模型都做了，MOE化，像我们最新的这个主模型的MOE，我们应该是国内啊比较早的，这个推出了万亿的MOE啊，不在了知识之上。

我们自己也有一些领域的模型啊，包括我们这种代码的模型啊，我们包括我们自己代码们，相当于我们的呃会员的COCODEX啊，以及我们的这个可信的模型，还有我们的rap的模型啊。

广泛去支支撑我们公司内外大概600多个业务，那目前来讲，我们整个啊，我们最主要的这个万亿的MOE模型啊，我们内部呃，中文评上面其实跟吉普斯TOBER，应该是在处于一个梯队啊。

这个其实可能跟我们现在国内的一些啊，我们头部的一些友商啊，基本上大家处于都是啊，我觉得已经基本上处于一个比较相当的位置，那我们刚刚讲，我们自己也也推出了，我们很多的这种中小模型啊，包括7B13B啊。

当然我们可能内部还有一些1B3B的一些啊，端测模型啊，这些模型基本上我们也是做了，有dance版跟它MOE版，那另外一个就是我们也在这个我们的语言模，基础上，我们也推出我们自己的混元的VR模型。

那这个模型基本上我们在中文上面啊，也是跟GB4V啊，应该是比较相当的，最后一个就是我们啊最近我们应该是啊，上个月我们刚刚开源了，我们的会员文生图的DIT模型啊，目前来讲大概是呃应该是中文第一个呃。

中文原声的开源的啊，DIT模型，那训练平台刚刚讲我们自己啊的android平台，包括我们的android的训练平台以及android的推理平台啊，重点啊来讲就是它整个来讲，整个框架我们自支持万卡规模啊。

比我们开源的，比如说deep speed这样的这样的开源框项目，大概快2。6倍，我们的成本，我们的GPU的这个利用率，我们大概可MFU可以做到62%，我们整个在迁移模型下，我们同等可比情况下。

只要50%算力啊，就可以训这样的模型，我们在推理上面，其实我们自己也比我们现在啊大家可以看到的，这个主主流的这个最好的开源框架，我们大概嗯能够提升1。3倍的推理速率，大概我们现在像我们最啊。

之前大家很多开源社区都在用这个SD的，这种纹身图模型，我们可以想用一个啊最标准的第四去推的话，我们可以从十秒可以做到啊，3~4秒三张图啊，单图我们大概可以做到一秒以内啊，好，那我们这里面。

我们最最重重要就是我们这个万亿级的这个，MOE的啊，大于原模型啊，我刚刚讲我们从去年9月份啊，第一次推出时候，那个时候我们学上是一个116，B的模型啊，是个千亿的模型啊，是个dance。

那个时候我们大概训练了，大概有有2万亿的token啊，坦白讲今天回过头去看那个模型，其实我是觉得整个训练的啊还是不够充分的，那今天我们啊最新的我们其实从去年啊，年底，我们就开始去升级到我们万亿的这个。

MOV的这个架构啊，这个架构下面，目前我们最新的大概是训练了，超过7万亿的token，那我们最近大半年我们去可以看看，我们其实通过一些优化，包括啊刚刚讲啊，前面嗯呃黄渤是在讲说我们这个呃自然啊。

这个数据的这个啊现在够不够用的问题啊，其实我是觉得现在整个自然数据啊，如果按这个趋势讲啊，当然按趋势讲的话，自然数据可能是人不够了，但是其实我确实想从另外角度去讲，确实合成数据。

很多时候效果确实比自然数据要好啊，这个也是个我觉得现在可能大家在行业里面，大家普遍都有一个共识，包括我们了解到啊，像44。5甚至五啊，其实里面可能有啊，据说哈有有有超过将近一半的数据是合成数据。

然后这里面呃包括在数据层面大量合成数据啊，以及我们多种训练策略优化，还有我们的呃对其整个强化算法的升级，我们整体效果其实比那个时候应该是，累计超过50%的提升，除了我们tom1之外，那我们也支持啊。

我们一些领域的，刚刚讲，我们一些呃，可能在行业业务里比较关心的一些一些能力啊，包括我们的角色扮演啊，像腾讯内部，我们其实有大量的这种啊业务场景游戏啊，包括我们的这种很多的，像KQ的这种娱乐的平台。

我们需要有些角色扮演这样的模型，包括放生靠，那这个是我们agent a里面最关键的一个啊，一个环节啊，代码生成啊，这个其实在我看来，那代码模型其实啊不光是说诶，我这个是一个代码的本身的。

这个可以用来做IDE对吧，可以做来做tto circle做提效，其本身来讲代码也是整个大圆模型啊，能够突飞猛进啊一个很关键的一个环节，那我们MM呃，万一MOE的这个优势，其实这个也是今天。

我觉得大家今天可能已经成为行业一个共识了，包括我们都知道从包括GBT3。5，GP3。5TOBER啊，他们就是一个啊一个很小的一个激活量，这个MV架构啊，包括今年GBGB4GP4。5啊，包括GB4O对吧。

这都是一个MOV架构，那MOV的优势就在于说我们相相同成本下面，我们MOE的这个效果，是要优于我们的筹备模型的，然后另外就是我们的蓄力成本啊，相同成本相同的规模下也更低啊。

另外就是刚刚讲SKING问题对吧，那我们如果我们对D词当然也可以堆上去，但是同等的成本下面你会一发现，那我相同的激活量，那我其实我可以做更大的模型参数量，这样的话我就意味着我可以吃更多的参数。

而吃更多数据，那当然去年MOE啊，这个其实MOE本身这个东西，其实啊其实最早我觉得一个千亿万亿级的架构，switch transformer很早就有了，但是说实话这个业界啊，其实啊没有太多的这个最早期。

没有太多的这个这个这个大家有这样经验，能够训练一个几千亿上万亿的啊，transformer的这个MOE架构，那其实它里面只有几个它的一些挑战，一个就是它的训练稳定性很差啊。

另外就是它是呃这种网络的这种root，那它的专家负载可能不均衡，还有一个就是呃他的这些专家之间，F分其实特别容易趋同，那我们怎么解决这个问题啊，第一个就刚刚讲我们的路由机制啊。

我们要有一些高效的一些root机制，另外一个就是啊就为了整个训练的稳定性啊，那我们啊我们dance上面，我们我们探索自己的schedule，那在MV上面它有一些特殊的SCHEDU。

包括我们要有一些lost去些设计啊，一些trick让我们模型可以训练的更加快啊，更加稳定啊，比较平滑下降，那skill l上面其实也是一样啦，这个就所有都大模型，我们今天第一件事啊。

我很认同刚刚文浩讲的对吧，我们第一件事肯定是要先做数据啊，先去探索自己的模型结构下的skin law，那今天对我们来讲也是一样，那我们自己MOE，我们是因为从无到还有开始做。

我们很早就探索了自己的各种一些参数配置啊，包括我们的自己的skin的问题。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/b7bce53001e2a7fc269b16b9ec2ea595_1.png)

那另外一个就是讲了今天这个长文啊，长文这一波，基本上我觉得已经成为行业标配了啊，那我们会员我们自己的MV架构，其实我们也是这个支持这种高效的，超常温的attention啊，包括用一些多间断的方式啊。

最早最开始我们可以用平方级的for attention，到店窗影响程度之后啊，那我们可以做一些窗口外推，再到最后我们可以甚至我们要我们做百万级，那我们可能可以做到啊，我们可以做到几乎无损。

但再往上走几百上千万，那这个时候我觉得啊，这个涉及到这个这个这个这个，这个你能不能接受什么样训练速度，你要涉及到有你有多少算力，包括你推理的时候啊，你能介绍什么样的实验啊。

这里面可能会有些几乎无损的一些，细数化方案啊去做，那目前来讲我们自己原生的啊，我们自己API里面啊，我们自己呃这个会员的pro版本，就是我们的这个万亿的MOE，我其实我们原生的支持是百万级的啊。

这个window size啊，当然我们也做了一些啊测试呀，在业界现用的比较多的这个大海捞针对吧，基本上是捞单针对吧，我们自己也构建了捞多针啊，这样一些白CHMARK，那刚刚讲，那今天我们的大模型啊。

其实从去年早期大家比较关注，说我们的知识能力的文科能力，那今天其实已经已经引进到，大家普遍比较关心这个术语能力，那我们认为术语能力其实啊，可能很多时候就代表一个AGI，很重要的一个方面。

那我们自己其实也是一样，那我们这里面的数学逻辑，其实我们自己也采用了大量的核心数据啊，包括这种用COT加一些加上一些啊，用代码解释器的方法，POT的方法，去解决我们很多高阶的数学跟推理的问题。

那这里面涉及到OK，我们自己构建了一个自动化的几个大规模的，数理数据的合成以及ref的流程啊，不断去获取更多的，更优质的这种这种数理的这种QA队，那通过这样的一些数据啊，我们来去做我们的啊。

包括我们在我们的PRETRAIN里面，也加了大量这种数据，包括我们在SIF对齐厘米阶段，不同阶段啊，去做很多这样的一些数理能力的提升，那最后来讲，目前来讲，可以说整个呃这个也是我们大概最近几个月吧。

经过不同维度的啊多次的评测，我们在中文中文上面，我们的数理水平应该是整体上，是接近吉普斯TOBER的，那其中我们在小学和初中上面，小学和初中数学上面，我们是应该是超过G比四的，对，那刚刚讲了。

我们整个大模型这个核心的底座能力，那其实今天大模型啊即使对吧，从最早期到3。5，很多人觉得就二三十%的这种幻觉对吧，今年GB4啊，普遍认为有10%以十的，当然那我觉得那个应该指的是英语。

那现在中文领域我觉得大家应该有感受，应该不止10%啊，就它的幻觉率，那怎么解决大问题幻觉那除了这个模型啊，必须哦就要有更大的SKILLING，另外就是模型本身要训练更充分，去降低幻觉之外。

包括通过对齐的方法，算法之外，其实呃绕不开一个问题，就是模型它没有办法，他对他没见过的东西啊，他其实并不知道这样的问题应该怎么回答，那他这个时候如果强行回答的话，就很容易出现幻觉。

那我们自己啊其实引入了我们自己啊，会员的AI搜索，也是今天我们啊可能大家也有体验到，像混元的元宝啊，我们的元宝的app里面，其实我们自己的AI搜索啊，实际上是来自于，主要是说我们来自于我们内部的。

包括像用了啊，我们微信搜一搜，整合了我们微信里面生态的数据啊，包括搜狗，那是它是一个网页的引擎，当我们自己啊也会自建一些锤炼引子引擎，以及公司内一些其他的一些生态内容啊，都会进到我们混元的AI搜索啊。

主要是要解决我们的一些信源的权威问题，还有我们的一些实心问题，那另外我们在架构上面，那我们刚现在在讲啊，我们今天啊整个大模型啊，从system m1到C4M2，那么今天agent这件事情。

我觉得已经让整个的大模型变成一个，我们要去啊从这个快思考走向慢思考，那我们自己的这个AI搜索本身，我们主体的架构啊也是一个基于agent的啊，planner加action这样一个机制。

那再一个就是那我们今天要去做啊，要做一个很好的AI搜索啊，当然我们离不开，有一个有一个会员的通用的底座，但同同时呢，其实整个的搜索领域里面，还有很多很特殊的些任务，那我们需要去通过一些增讯啊。

包括一些多任务精条啊，去构建我们自己的40GPT模型，那前面讲了我们的呃，就我们的纹身纹模型啊，语言模型K那后面接下来我们呃简单讲一下，我们刚刚说我们自己现在的混元的，VR的多模态模型。

目前我们在混元的VR模型上面，我们内部评估下来，其实整体上中文场面是我们是啊，基本上跟GB4应该是相当的，那这里面就给了几个case呀，也包括这个啊，很多这种场景对吧，那我们拍一个啊。

我们啊今天吃的一顿饭对吧，那我们可以计算一些热量，给些建议啊，他这个其实是典型，它要先解决它的物体识别问题，同时啊他还要知道这里面的理解的问题啊，做一些COT做个推导啊，再做一些给你生成很多这种建议。

那导游对吧，那我们在做很多导外出去旅游，然后随手一拍，我们给一个景点，那我们就可以做很多很多介绍，那我觉得我们是觉得这个这个多模态，这种这种模型，其实未来在很多应用场景下面啊，会给大家一些不一样的体验。

那另外就是我们呃我们近期我们在上个月吧，应该是刚刚开源的这个我们的文生图的啊，混元的啊，DIT模型，那这个模型来讲，我们应该是呃在开源社区里面第一个放出来的，这个中文领域原生的这个这个大模型。

加上DIT这种架构，那其实它呃，我觉得它主要涉及我们有几个优化点啊，包括在前面啊，我们这里面，我们实际上是一个多模态的一个语言模型啊，可以让这个模型啊，这个支持多轮的交互式的编辑啊。

和以及和这个chat的互动，另外我们在生成模型上面啊，那这个DIT本身其实这也是这个骚扰是吧，赖以成功的一个最关键的核心的一个模拟结构，从把最早期我们把unit啊，变成现在我们自己的一个DIT。

可以让模型有更大的更强，这个图像跟文本的这种信息的捕获能力，那刚才讲到我们会员文中图现在也已经开源，大概我们大概三个礼拜吧，我刚才会前还专门看了下，目前超过呃呃2300个style。

那目前来讲我们其实哎可以看一下，基本上我觉得还是处于一个在业界吧，啊排名前三的一个算法吧，那当然现在最好的啊大理三对吧，啊MJNV6啊，当然看最近这个这个SD3可能也出来了。

那我们自己其实现在放的这个版本，我们内部其实也在还继续沿着DIT路径，我们不断在去做我们内部更好的模型，好那那个整个会员大模型啊，我目前来讲刚才讲我们的一些啊，除了我们这个这是呃。

左边一个是我们内部的一个评测啊，我们大概在最近几个月啊，每每个月会有一个呃，这个很全面的一个一个对标的评测啊，我们整体来讲，刚刚讲我们跟JP斯TOBER啊，当然是最新的吉普森。

应该是4月份的GP斯TOBER吧，啊我们大概是略微超一点点啊，就我觉得中文上应该是比较相当的，那其中中文上面文科上面我们还是要领先一些，但理科上面我觉得还是要略低一点点，那那当然这现在外面也有很多对吧。

行业有很多这种呃呃各种这种评测，我们可以看一下，其实我觉得我们今天可能在整个行业同行里面，我觉得还是处于一个第一梯队嗯，好前面讲了我们这个会员大模型的一个基础，研发的一个状况。

那接下来可能给大家去啊分享一下这个会员啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/b7bce53001e2a7fc269b16b9ec2ea595_3.png)

大模型的这个在我们司内外的一些应用落地，那目前来讲，会员我们其实已经是作为呃腾讯公司，这个呃我觉得一个很基础的一个呃，一个一个团队啊，这个一个大模型团队，然后呃接入了我们公司里面，基本上各个业务线的啊。

基本上主要一些主要头部的一些业务啊，大概超过600多个业务啊，那呃几个典型的场景，可能呃在座大家可能呃在日常的工作生活中，有可能也会也会用过啊，就包括第一个，我像我们腾讯会议的AI小助手啊。

那这个实际上是一个非常刚需场景，我们知道我们开个会对吧，通常的人很多啊，这个有人对吧，有人上有人下，然后呢，同时呢这个可能一个会就呃一两个小时啊，可能我们得好几万字对吧，那这些这些问题，这面对这种场景。

我们突然中间来了对吧，我们上线了，我们去可能问哎这个之前是谁说什么东西对吧，我们模拟性能不能很快去帮你做这种的，这样的问答，包括会后呢我们都要去去写写写总结对吧，写摘要，那我们今天我们有大模型。

我们可以做会后的总结啊，包括还有一些啊会议代办啊，那另外刚刚讲我们那个我们的这个，我们的这个代码模型，那我们今天我们我们我们知道，就是我们大量的数据啊，我们是存在于互联网当中的啊，以plan test。

以多模态形态，但是还是有很多数据，其实并不在公开的互联网里面，可能在各个企业的数据库里面啊，那我们实际上有一个呃，有一个呃有一个很重要的方向叫BI方向，那我们能不能用大模型的。

用语言模型的方法的这个能力，去改造我们的BI，那我们叫做腾讯，我们自己推推出了腾讯的这个这个会员的这个，chat b i的模型啊，可以使使得我们可以做这种啊。

很多SQL语言的这种tel circle的代码生成，甚至我们可以做一些呃智能代理，用一些自然语言方式去完成一些表格的分析啊，以及我们啊，把这样东西集中在我们的链路里面啊，让我们的这个BI啊。

这个让我们可以认为说，我们过去可能有需要专门有些做BI的，一些数据分析的同学，今天可能不需要了啊，今天可能我们只要是说OK我们的一个业务方，我们就可以用我们的差别。

用自然语言的方式啊去获得自己想要的信息，做很多很啊，各种各样灵活的这种数据的洞察，呃刚讲过这个呃腾讯会议对吧，腾讯会议，腾讯文档都属于腾讯的office系列对吧，讲了会议之后。

还还有个有一个在我们日常工作生活中啊，经常打交道的一个产品，就我们腾讯的文档，我们腾讯文档呢也推出了，基于会员的这个这个AI助手啊，它支持像这个啊，基于呃大模型的这种文案创作啊，包括这种啊表格处理啊。

包括我们甚至可以去啊写一段文档之后，很快可以把它变成各种样格式啊，包括幻灯片啊，PDF呀这些东西，那这个其实我觉得也是一个啊，我们在日常的办公和包括文字创作中啊，非常非常啊常用的一个啊。

一个一个一个AI的能力，呃还有我们自己在我们的呃广告营销场景下面，包括我们啊腾讯广告的妙思啊，我们可以去通过会员大模型，我们可以高效去产出我们很多广告的素材，那这些素材因为是我们大部自己产生的。

那我们其实我们知道在广告当中很重要一点，就是我们这个素材出来之后，我们要去人审，Ok，那如果今天这个模，这个这个广告是我们AI可以做出来，而是我们VI生成出来，那我们其实也可以通过AI的方法啊。

去加速它的这个审核的这个速度，其实可以让整个的广告投放的效率更高，包括我们也可以啊，用这个我们这个呃会员大语言模型做，我们很深入的，在腾讯的这个，我们各种各样的一些流量平台上面的，一些数据的啊。

呃广告效果的场景分析啊，以甚至我们可以做一些，我们啊跟我们广告用户的一些呃在啊，这个基于大模型的这个这个推荐领域里面，做一些尝试，好那最最后这一个我呃你可以看一下，像我们这个最近应该刚刚推出来的。

我们的那个微信读书，我们推出一个嗯，我觉得一个还是非常好用的，一个一个一个功能叫做嗯AI问书啊，包括我们AI大纲，那这个其实都是基于整个混元大模型，那过去来讲，我们读一本书，我们中间有什么一些问题。

可能我们要切出来，我们到索引擎里面啊，甚至我们到某一个啊大模型的这种chat里面啊，去提一些问题，那今天我们不需要了，我们只需要长按啊，我们用直接的方法，我们就可以选取去直接可以去触达。

包括这个文章内的这个书籍内部的，以及它相关的一些知识啊，这个是我们这个新推出的，叫做这个微信读书里面的AI问书，还有一个就是我们现在除了说我们这个呃，我们这这个原模型啊。

我们的多模态模型在各自场上去发挥作用，那其实我们也可以在我们的新闻啊这个写作啊，包括海报的配图当中啊，新华社啊，也许这种融媒体啊，我们做了很多什么江山如苏多娇啊。

做了很多这种基于AI创意的很多这种宣传片，那最后1part就是我们介绍一下，就是我们大概是在上个月5月30号啊，我们发布了呃，会员发布了全新的AI助手，我们叫腾讯元宝啊，那腾讯元宝来讲的话呢。

我们目前啊，像我们主打支持的是像我们的AI搜索啊，包括我们的这种长文的这种解析阅读，我们叫AI解析，还有我们的AI写作啊，包括我们这种写各种各样的文章，包括我们最近啊大家可能很多在高考对吧。

都关注到这个大模型，这个写作文元年啊，今年我觉得实际上是也是这个，大家很关注这件事情，另外就是我们也有一些我们自己的发现，里面的一些AI的一些应用啊，包括我们一些好玩的一些生图生视频啊，这样的一些玩法。

那整个腾讯元宝我们的slogan叫做呃，轻松工作啊，多点生活啊，这个也是刚刚啊在5月30号在各个市场啊，应用市场里面去上架，也欢迎大家啊多体验啊，多啊多提问题。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/b7bce53001e2a7fc269b16b9ec2ea595_5.png)

好谢谢大家嗯，好谢谢谢谢战辉，看看现场的朋友有没有想提问的，举个手，啊内位，诶你好哦，刚才您会议中讲到了，有一个点我特别感兴趣，希望您能展开问说一下，就是说呃，您提到。

就是我们可以用这个会员模型去做这个，广告创意，然后呢广告创意里面呢又可以用AI去做审核，来加速这个审核，请问在这个审核方面，你们用I是怎么做的，或者是用了一样的什么样的技术，能去让它能省的。

能让这个广告创意更符合物理世界，更更更让那个甲方能够接受，就是在这方面你们是怎么付出的，都想了解一下啊，K好，首先第一个我们自己做这个这个AI审核，因为这个模型就是这个素材，是整个会员自己生成的。

那我们在生成的时候，首先我们生的时候就会让它去符合，比如广告法呀，比如各种各样的法律法规，那这个地方在生成的地方，我们上是有些把握的啊，另外一种我们在审核时候其实也是一样，因为模型是模型生成的。

那我们在这个审的时候，其实我们也很清楚模型哪里可能会有些问题，我们可能会有一些内部的一些啊一些特征啊，一些东西会可以辅助你去判断，这个道理没问题，所以我觉得是一个输入跟输出啊，都会做一个把控。

其实这可让会让整个的这个素材的，这个这个生产的效率会更高，好啊，要不然那位吧，那位再加一追加一个问题啊，那位啊，谢谢，呃你好，我们是做那个数字营销的，然后我想问一下，你刚才提到那个用那个呃。

在微信里面做AI的数字营销，能够再展开的说一下吗，呃微信里面我刚刚应该讲的是微信的AI读书啊，关键的问题是还是刚才那次那个同学做的，说那个就是广告营销的事情，是不是对K啊，广告营销里面。

其实刚刚讲我们一个腾讯的妙思平台，刚刚讲，我们学校支持各种各样的这个广告素材的，这个生产审核这么一站式平台，包括像这种纯文本的这种，包括这种图片，以及我们一些这个声视频，这种短短视频短片的这种生产。

跟整个的这个审核，以及整个的对广告主的服务的一个体系啊，基本上是这么来做的啊，好好时间关系就先这样了。



# 2024北京智源大会-大模型产业技术 - P6：可灵(KLING) 视频生成大模型：万鹏飞 - 智源社区 - BV1HM4m1U7bM

好感谢仲远的介绍，今天也非常高兴有这个机会呃，跟大家介绍一下，我们6月6号啊，一周之前发布的快手克林视频生成模型，啊啊我叫万鹏飞，就快手快手可能也不需要太多介绍吧。

就是快手的slogan叫拥抱每一种生活啊，所以快手是一个拥有将近400000000DAU的一个，短视频的一个内容平台啊，所以可想而知，视频这种内容的形式，对于快手来说是非常之关键的。

然后呢啊围绕着视频的各种各样的技术啊，包括应用也非常的丰富啊，那我们快手在呃整个大模型这个方向上，其实也有比较广泛的布局啊和丰富的产出呃，这个可以简单分为三层来理解吧，哈最底层的话infer层。

这个就是啊做大模型是一个庞大的啊，复杂的系统性工程啊，需要有AIAI的平台，然后数据的平台，还有啊评测的平台等等，这样的一些基础设施作为支撑，那再往上的话对于快手来说。

其实快手里面的内容的形式是非常丰富的啊，包含了像大语言模型啊，多模态的啊，理解的模型以及图像视频语音，包括3D的这种生成的模型啊，对于快手来说都是非常有呃实际的呃，意义和价值。

所以我们在这方面都这些方面上都有啊，非常大的投入啊，和好的产出，那对往上一层的话，这应用啊这个从大的方面来讲的话，就是内容的生产创作啊，内容的理解以及内容的分发匹配啊，基本上在这三个大方向上的话就可以。

然后这个涵盖快手里面的大部分的一些，业务场景啊，所以可以想象的是说快手的这个大模型，然后我们做这些事情的话啊，第一啊我们是有实际的应用场景啊，另外的话我们在这方面的一些技术上啊，也有深厚的布局。

然后最终的话是能够形成这样，一个商业的闭环啊，呃今天跟大家讲一讲，那可林啊，可林本质上是一个视频生成的模型，所以还是有必要讲一下，就是什么叫哦视频生成啊，给它一个定义啊，这是我给他一个嗯不太严谨的定义。

当然当然这个视频上传，好像也没有一个官方的定义哈，然后不妨呃给一段描述吧，就是通过生成式AI的技术啊，将用户的多模态输入转化为一个视频的信号啊，这里面有几个点哈，第一个是说用户的输入。

用户的输入它本质是一个多模态的啊，真正的视频生成的话，用户可以输入他想要他，他对于这个内容的各种各样的一些想法，可以是文本，也可以是图像，也可以是一些动作，然后其他的一些控制信息啊。

然后最终它的输出是应该是一个视频的信号啊，从计对计算机来说，它其实就是一个在一个2D的空间上，再加一个时间维度的这样一个三维信号啊，那用到的技术的话，就是如果我们讲视频生成的技术的话，我们一般来讲。

还是说它是用到了一个AI的基础啊，特别是生成式的AI，那所谓生成式AI啊，从数学上来讲的话，可以简略理解为，就是从一个某一种随机的一些嗯噪声或者信号，然后经过一系列的计算和处理。

然后得到一个目标的一个信号，这个目标的信号，可以认为是在某种目目标的分布下的，一个采样啊，然后呃另外的话想跟大家呃聊一下，就是视频这种信号啊，它的获取方式通常来说可以用这三种方式了哈，来涵盖。

第一种方式叫相机拍摄，那相机拍摄大家比较熟悉，大家拍一个视频，包括在快手上，然后我们拍一段视频，这一做相机拍摄，这个他大我，我相信大家都应该做过这样的事情对吧，然后拍个视频，然后啊传到网站上。

或者自己来来留作纪念都是可以，它本质上是将一个物理世界的一些光的信号，转化为像素的信号，OK还有一种视频的获取的方式，叫就是图形渲染，那它本质上是将一些预设好的一些三维的模型，包括他一些材质的信息。

通过一系列的模仿物理物理现象的一些计算，然后得到了像素的信息，所以它不存在是光到电的一个转换，它是所有这些都在计算机里计算出来的K，然后它这里面大部分的计算，其实都是叫叫是确定性的。

就是它有一些一些公式啊，这些公式是描述了一个场景，它应该是长成什么样子的，OK那第三种的话，就是我们今天要讨论的就是视频生成，它本质上来讲是说，从一个它本质上是一种从目标的分布中采样啊。

样本的一种技术啊，这个样本，然后其本质上一个三维星号，这个三维信号解码出来，它就是一个可以转化成一个像素，就是大家看到的视频，那这不同的方式，其实都有它们各自的优缺点对吧，像相机的拍摄使用成本很低啊。

但是它内容自由度是受限的，为什么，就是那拍摄本质是就是3D世界一个投影对吧，3D世界长啥样，你拍出来也就是啥样啊，很难有些天马行空的一些想法啊，那图形的渲染的话，它它的好处就是效果可以很精美，对吧啊。

游戏啊，特效啊等等啊，这些动画都可以落在这个范畴，那但是他的这个使用上手成本太高了，就是正常普通的人是没有能力，去真正做一个动画或者动一个游戏出来的对吧，包括说元宇宙前几年非常火。

最后的话其实也是最大的限制，也是它的一个成本的一个问题啊，而视频生成的话，它的好处是它的内容自由度非常的高啊，就是它的内容是可以天马行空的，包括概念的组合，然后它这个一些这个各种各样的想像中的一。

些场景对吧，然后包括一些仿真的场景，他都可以做的很好，它内容都自由度非常高，但是过去的话，它最大的一个问题在于，它的平均效果水平是有问题的啊，如果大家关注这个方向的话，就可以知道。

就是这这个这块领域一直是备受关注，因为这个事情的价值很高，但是呃过去这么多年的效果，一直是呃是有问题的对吧，就是它的平均收入水平有问题，那直到是说啊最近一段时间有一些新的技术，新的产品出来。

然后把它的效果的这个下限也往上给提了提啊，OK所以视频我们在讲是说呃它的获取方式的话，第三种方式它有它的非常大的一个潜力，本质上是跟前两者是平行的啊，那从技术的角度来说的话啊，有几种吧。

就是我先讲就是现在比较流行的一种对吧，就是视频生成是用用diffusion models，就是扩散模型对吧啊可以啊，它本质上是一种呃，它本质上是一种数学呃，叫什么，就是一个模模拟这个呃一个概呃。

概率采样的一个过程，其实它是一个思路啊，它里面的一个核心是用一个神经网络去预测，预测噪声啊，预测噪声，那用什么样的神经网络，其实这个是flexible对吧，比如说早期很多人用这个CNN的一些方式。

去预测噪声，为什么呢，是因为CNN它天然的对对图像这种信号的话，在过去几年就是表现的性质还是不错的对吧，然后它的整个设计的原理，卷积的这种方式也比较适合图像信号啊，所以就很自然的就会有一些方法。

是用CNN的方法去预测噪声的，那现在也会有一些方法是，用transformer的方式啊的，用transformer这样的一个啊这一类的结构，去在扩散模型里面去做噪声的预测啊。

啊这里面包含了各种各样的一些呃，呃一些一些一些技术吧，啊包这个包含有产品对吧，包括那个SORA，包括快手的可林啊，都是落在这个范畴，那它最大的优势好处在于transformer本身，它具有比较好的对吧。

那这个事情就是在其他单元模型，其他大模型里面是被反复验证了，然后在扩散模型的这种语境下的话，也被观察到具有这样的一个性质哈，所以所以呃现在有很多的方法可以转向，用transformer来做啊。

本质上还是有它有很好的skin law性质，当然还有一些技术的路线，比如说auto aggressive的路线对吧，这样的方法它在概念上也是很听，也是很直接很make sense对吧。

因为这个视频的信号，你是可以把它当成是一种，带有某种序列关系的信号的，那用一个AUTOGRASSIVE的方法，然后来对它建模其实也是非常make sense的啊，只是说现阶段里面有一些新的方法慢慢出来。

然后啊只是可能当前这个效果可能还是不如啊，DEFICIMODELS的方法啊，但是也是一个合理的路线，当然生成式AI其实但凡是一个生成式AI，它只要能够概念上把一个噪声。

一个随机信号转化成一个目标信号的话，它其实都可以做信号的生成，另外视频也是一个信号而已啊，所以其他的像gr v1的这样的一些方法，也可以做视频生成啊，那快手做视频生成的优势呃，第一点是特别重要的。

就是快手本视，本质上就是一家视频的内容平台啊，所以这个场景用户的需求，应用的场景是天然存在的，这是一个非常非常重要的前提，可能非常多的这个技术的研发，其实其实都是要啊，遵循这样一个重要的一个前提的啊。

这样的话它让我们能够在做的过程中啊，基于我们过去对于视频这种内容的一些认知，积累的技术，然后及时以及用户的反馈啊，让这个技术能够真的越做越好，当然对快手来说，我们快手从诞生第一天开始。

其实像内容的生产创作就是一个需求对吧，最早的快手是GIF快手拍技术的对吧，然后呢后面就是拍视频，其实用户的这个需求，我们一直是用不在不同的阶段，用不同的技术方案，去满足用户生产创作的需求啊。

所以在这上面我们有超过10年的技术积累啊，和实战经验啊，以及说我们在大模型领域的布局，非常全面且坚决啊，曾经推出了这个备受好评的快意大语言，模型和可图啊，呃文生图模型啊，效果都是非常不错的好。

那接下来就正式介绍一下可林啊，呃可林如果用一句话，然后来描述他的话，他它可以这么去说，就是它是一个可以实际体验的啊，并且它的效果是呈现了很多SARA啊，这个这个级别的性质和效果的。

这样一个视频生成模型K啊，这个这是克林的官网，大家感兴趣可以看一下啊，那目前的话我们的生成的视频啊，从硬的指标上来说，它的分辨率啊可以呃高达71080P啊，时长的话啊可以长达数分钟啊。

然后我们目前目前开放到了线上的，那个版本的话啊，分辨率是720P，时长是五秒钟的K，然后我们自从发布之后也受到了很多的关注，就是这个申请量是非常之爆炸的，我们也在积极的想办法哈。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/1b8efb84e845bd9671710e546d7a7766_1.png)

能够让大家都能够呃呃尽早的体验上啊，这个就是在我们的快影APP上，有个体验的链接，就是大家啊可以提交，不过现在已经好几万的申请量了，我们在啊就是还是受到了很多的关注啊。

包括还好像还有些外国人在在各种想办法，然后拿到中国，找到证，有手机号上来来体验我们的模型，好，那呃关于可林的话，可能还是先从一个一个一个直观的一个，例子上来给大家呃介绍一下吧，我先声明一下。

就这个例子是我们的内部的同学，那不是什么专业的创作者，内部的同学花点时间，用我们的模型做出来的一个小短片啊，他大概可以大家可以体感为这就是一个普通人，然后用我们的模型花一些时间。

然后能够做出来的一个效果啊，然后我们实际上呃，因为我因为我们实际上线了嘛，我们有很多的这个实际体验者，然后创作者在我们群里，其实我们发现他们比我们会玩多了，他们做出来的视频品质比这个要高了啊。

我之所以放这个视频，更多的是让大家有个体感，就是说啊我们普通人如果用克林模型能做什么，呃今天是动物城一年度的自行车比赛，你们俩准备给谁投票，克尼胡先生身材健硕，我们袋鼠喜欢我们老侯家。

当然是支持嘎嘎星的，啊什么东西过去了。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/1b8efb84e845bd9671710e546d7a7766_3.png)

嘘OK呃那这个就给先给大家一个直观的体感哈，然后接下来谢谢谢谢谢谢，接下来我们先从他的一些效果的亮点，然后来展示，然后我总结了六个亮点啊，讲完这六个亮点的话，我会再去讲它的技术方案里面的一些设计。

K那从如果从效果的来说的话，第一个亮点应该叫大幅度的合理运动啊，因为这个事情对于视频生成来说，是一个很相当本质的一个事情，就是因为它跟图像最大的区别，就带了一个时间的序列对吧，所以运动的建模。

运动的幅度，它的一些合理性，是衡量一个视频生成模型的能力的，一个很非常重要的一个因素啊，所以我们就是用到了一些啊，3D时空联和注意力的一些机制，然后建模复杂运动啊，可以看到生成的这些case的话。

就是整个运动的话啊，不管是幅度和合理性来说，都是啊非常不错的，比如说左边这个视频，这里面有很多东西在运动哈，首先镜头在运动对吧，然后这个马在跑，然后它后面的尘土在运动，而这个人也跟着马在上下颠簸的运动。

所以这里面涉及到很多的运动，包括它的运动幅度，然后整个结构是都是做事做事相当可以的，那右边这个熊猫这个呃，这个例子好像也也也也也，很多人这个拿来拿来拿来讨论哈，就是说这个熊猫弹吉他对吧。

他的手一只手是要在那扫，一只手还要按那个品对吧，然后可能还要摇头晃脑一下，就整整体的这些运动啊，不管是从精细的程度和它的一些幅度，合理性来说，都是啊相当不错的，那第二个亮点。

我们总结了叫分钟级的长视频生成啊，这个事情就是说啊对于一个视频生成来说，它在实际使用的时候，还往往在很多时候的话，还是需要能够达到一定程度的，那即使对于一个短视频的平台，短视频的公司。

它的这个视频最起码也得有个十几秒吧，OK啊，我们展示了我们的模型，具备生成分钟级的长的视频能力，那下面这两个case，就左边这个是一个小孩穿着蓝衣服，戴着头盔骑自行车的一个小孩，然后在一个公园里面骑。

他的场景是在慢慢的发生四季的变化的，然后他在公园里面也会去拐弯什么的，这里要说明一下，就是骑自行车啊，这个事情本身就是比较有挑战的啊，其实很多产品是搞不好这个事情的啊。

因为他要知道这个脚要踩在这个地方对吧，然后他要联动着这个那个杆，然后要动，然后车要往前去骑啊，包括他的身体姿态要跟着去变，所以骑自行车本身一个比较tough的1case，那这里面我们重点要讲的是说。

它是一个长的一个视频生成，那右边这个是描述了一个呃火车的车厢里面，从窗啊，窗户往外看去，然后外面的景色的更替啊，这个这个视频比较长，有2分钟，有有有有一段时间是一个小镇，然后这个雪地，然后草原啊。

后面还有大海等等等等啊，这里面的话就是呃一方面是我们模型比较有，比较好的这种扩展的能力啊，另一方面的话，这个啊也依赖于我们一些高校的一些呃，基础的设施训练和推理基础设施啊。

所以可以看到就是说这种长的视频生成，它的整体的这种一致性是还是相当不错的，你很难看得出来是说这里面对吧，然后有什么突然就变了，崩了还不一致的这个问题，第三个能力的亮点。

然后呃我们叫它就是模拟物理世界的特性，这个也是非常重要的，有生成的东西，它要它要符合物理规律对吧，比如说左边这个倒应该是在在咖啡里面倒牛奶，做拿铁对吧，那首先这个杯子，然后这个这个牛奶要这种流下来。

它是一个流体的一个状态，进了杯子之后，那个水是不能从杯子里面渗出来的，然后慢慢的这个水面要往上去往上去上涨，那这就是一个典型的这种体现了哈，这里面一些流这种流体的这种，物理规律的一个case。

那右边这个case好像非常多人喜欢啊，就好像我们我们的模型在吃东西，这个这个这个场景下能力非常的强啊，这个老外好像也很喜欢这个case，就是这个吃面条对吧，吃面条这个case其实很难，大家想象一下。

就是个手呀，要以某种姿势抓着筷子对吧对吧，然后呢筷子要只要伸到面里面，把面夹起来，这个面还要还还是个软的，但要抖对吧，然后这个人还要张着个大嘴巴，然后把那个面给吃下去了，然后嚼咀嚼，然后咬断对吧。

而且其实他吃了面之后，嘴巴还嘴巴上还沾了些油啊，就是嘶，就这里，这里面其实是里面有很多的一些，很有挑战的东西在里面的啊，包括我们那个吃汉堡那个case，反正好像也是好像比SARA那个吃汉堡的case。

要好啊，这就是讲的是描呃模拟物理世界特性啊，这个也是非常之重要的，或者说它能够反映一个一个视频生成模型，它有没有真正的学到东西的吧，啊，第四点就是丰富的强大的概念，组合能力和想象力啊。

这个这个是生成模型与生俱来的一些规律哈，但是我们这个效果也是也也也是非常的，非常的好的，比如说左边这个是一个是一个小白猫对吧，然后开着一辆黑色的跑车在城市街道里面呃走，然后旁后面有行人和车经过对吧。

这个小白猫那握着方向盘，然后左顾右盼，然后包括他车漆上的一些反光，就这这，这这种很显然是现实世界中不存在的东西，对吧啊右边这个就更不存在了对吧，就是一个杯子里面有一个火山爆发对吧。

然后这个呃岩浆还留了下来啊，这些都是能够非常好的去呈现一些呃，这种天马行空的想法啊，啊第五个亮点是指叫什么电影级的画面生成啊，就是说它生成的这个画质，要能够达到一个非常精美的程度啊。

比如说这两这两个case，然后这个鱼对吧，就这个鱼我个人是蛮喜欢的，就是首先它它它是个整体的，细节还是非常丰富的，另外它在水里游的动态，是看起来是不违和的对吧，就是如果它在水里，然后不怎么动，就在那飘。

那很显然就哼不是条真的鱼在那游了的，然后右边这个花其实也是非常有挑战的，它的挑战在于说一个花开的过程，这种现象在现实世界中是非常少啊，这就是这个这个这个叫什么哎，就是即使在这个我们的视频呃。

大家平时见到视频里面，很少有视频是记录这样的场景的对吧，然后但是我们的模型能够把这个东西呈现出来，那说明他是学到了一些东西啊，能够把一个不太常见的一个现象给呈现出来，第六个能力亮点叫。

要支持自由的输出输出的视频宽高比啊，就是我们的模型可以指定任何的，任意的宽高比的输出对吧，让这个小狗戴着墨镜，柯基戴着墨镜在热带的沙滩上走这个case，反正就是都可以啊，它会自适应的生成呃合适的内容。

OK那接下来再讲一些技术上的东西吧，第一个讲模型的设计，呃，呃我快点说吧，啊啊第一个第一个讲的是说影空间的边界码，也就是说处理视频这样的信号的话，呃如果在原始的这种像素空间上做的话。

这个是非常不划算的对吧，它里面的有很多的信息冗余，对于计算的消耗也非常大啊，视频信号大家都理解就是非常大对吧，然后所以我们是呃，设计了一套这个3D的VE的结构，然后能够对视频进行高效压缩。

其实这个3DVE要做好还是挺不容易的啊，它既要能够很好的去压缩这个信号，同时还要能够具备不要有太多信息损失，还能具备很好的生存能力，然后保持这个画质啊，第二个是从网络基础结构来说。

我们是用了一个transformer的这样一个结构，然后做这个扩散的过程啊，并且我们验证了它的SCALABILITY的性质啊，这个是其对一个大模型来说，非常关键的一个性质啊，持续信息建模的话。

刚才也提到了，我们是用一个时空3D的一个联合建模的方式，能够把这个时空的这个整个的感受也打开，然后增加模型的能力啊，还有一个就是说一个文本扩展编码，就是文字怎么去输入啊，这里面会用到了一些啊大圆模型啊。

相关的一些能力，然后能够确保是说它能够很好的去响应，文本的输入，数据也是非常重要的对吧，我们有一个啊一个高度自动化的，一个视频的数据的一个平台，另外的话我们有非常精细的，这种视频的标签体系。

然后帮助我们去把一些这个不合适的对吧，然后或者是质量低的，或者各种各样不符合要求的，然后的一些数据给给筛掉啊，确保我们训练的数据的质量，然后呢训练数据里面除了视频之外，还要有对应的文本啊。

所以我们研发了一个caption的那个模型啊，专门用来做视频的这种文本的描述啊，啊最后一点就是说数据驱动的效果评估啊，这一点对于模型的迭代效率是比较有关键的，对吧，就是说我们不断有新模型的产生。

我们怎么去评价一个模型，比之前的模型好了还是不好对吧，如果请人来看，那这个东西一不准二效率比较低是吧，所以我们有一个数据驱动的一个评估模型，啊计算这一部分的话呃，有分几部分啊，第一个是说算法本身。

扩散模型本身是有，可以有不同的求解的方案的啊，所以啊我们我们在这里用的是一个传输路径，更短的一个flow base的一个模型，那这个它有比较好的这种啊，效率和效果上的一些性质啊。

这个是目前还是算是比较先进的一些模型，另外的话在训练的话是一个啊，大范围的一个分布式的一个训练集群啊，然后来保障我们的训练效率，然后在训练的策略上的话，也有一些特殊设计对吧，就是比如说分辨率由低到高啊。

低分辨率时候可以多过一些数据的概念，然后到高分辨率时候，然后来提升它的品质，所以是可以结合量与质的优势，另外我们的模型是有很好的能力扩展能力的啊，首先他也讲了，它是可以支持输出不同宽高比的视频。

另外的话开它可以在时序上做延展啊，这个持续的延展就可以延长视频，或者让一个图像变成视频，或者是在把视频做一些插帧等等操作都是OK的，另外的话就是支持多模态输入的可控，因为如果仅仅是文本作为输入的话。

那在实际作为一个产品功能上的话，它还是有很大的使用的门槛，和交互上的不合理性的啊，所以我们是支持各种不同模态的输入啊，确保最终内容是符合用户的预期的，回到最开始的概念，视频生成是将用户的多模态的输入。

转化成一个视频信号，所以这个多模态的输入这一点非常重要的，而不仅仅应该是文本，如果如果展望一下未来的话，第一个是说我们可以看到视频生成的效果，是在快速的提升的啊，其实大家已经能看到一些case。

比如说它的质量已经接近于视频拍摄了啊，也会有一些case，然后它的这个质量接近于图形渲染，那随着这个效果提升越来越快，他对会对一些相关的一些行业带来一些机遇啊，或者是变革，另外的话视频生成。

将视频创作的这个门槛和，效和效果的这个ROI，然后提大幅的提升，那这样的话，视频创作者和消费者的界限会逐渐的模糊，那假如有越来越多的视频的消费者变成创作者，对于整个视频内容生态的繁荣。

是非常非常有价值的，那在技术层面的话，很显然技术在快速的发展啊，不同的模态啊在不断的融合，包括理解和生成这两大任务也在融合啊，第二点是说有好的技术不意味着有好的产品啊，这里面是存在一个巨大的鸿沟的啊。

所以这里面有非常多的工作，然后才能够真正的把一个好的技术推向市场啊，当然是从技术的基础创新也是非常重要的啊，生成式AI的技术，它本质上是一些生成社AI这个任务的一些，基础的一些做法。

然后再不断不断的更新迭代，然后带来一各种不同的啊应用的一些算法上，再带来了一些产品的一些效果的提升啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/1b8efb84e845bd9671710e546d7a7766_5.png)

最后打个小广告，就是我们在在招人，就是实习校招社招，如果对我们感兴趣，都可以联系我们啊，好谢谢谢谢，好好谢谢老万啊，对现场的朋友有没有想提问，举个手啊，这位一，呃呃万万老师您好，非常感谢您的精彩分享。

也非常佩服贵公司的这个呃呃模型，那就是可林大魔型挺特别厉害啊，然后就是呃能不能向您请教一下，就是您觉得呃大概在未来呃5年左右之后，就是这就是有哪些是呃模型，就是大概率肯定比人类创作的好的。

就是然后哪些事，就是人类可能还能保有一些优势的，就是人类导演还能保有一些优势的创作呃，技能啊，或者流程或者领域什么的，嗯您是大大概怎么认为的呢，那就是谢谢谢谢哦，OK好。

我觉得首先不应该把这个东西割裂来看对吧，就是模型做什么，人类做什么，也是，本质上它是一个，它长期会是一个共创的逻辑对吧，然后技术是帮助人们解决一些实际的需求的，如果从5年的维度来看呢。

我如果看技术这个事情是非相当有挑战的，按照现在的技术发展规律，但是如果按需求来说，我觉得还是可以看5年的，比如说每个人都有表达自己的需求啊，他的一种体现形式就是内容的创作，但是内容的创作它是有门槛的啊。

创作出来内容普通人效果可能是有问题的对吧，但这个需求是一直存在的啊，不同的时间阶段的话是由不同的技术满足，但是即使到现在啊，比如说用户创作视频的这种需求，也没有被很好的去满足啊，所以从需求的角度的话。

我觉得未来在5年内，这个需求一定还是存在的啊，只是说我们怎么去解决它，我们可能会有在不同阶段有不同的方式啊，但本质上它应该是一个机器和人，然后协同来解决一个实际问题的，这么一个模式啊。

所以所以不需要割裂割裂来看对吧，好的好的，谢谢啊，谢谢啊，把提问的机会留给其他人吧，好的好的好的额好，后面那黑穿黑衣服的，谢谢王院长，我今天问题有点多啊，对我第一个问题是方便说下可怜的规模吗。

参数量规模啊，如果不方便可以不说哈哈不方便哈哈，好的好的好的好的对，然后第二个就是呃我们训练的话，就是说这个训练的计算规模大概是什么样子，就是大概是用多少张卡训练的这种，不好意思，好，那我第三个就是。

比如说我们这边去生成一个五秒的视频哈，这边一个生成五秒视频，大概所需要的一个时间和成本大概是多少，就如果你实际去用那个那个快影上的，那个东西的话，就是你提交提交请求，3分钟输出。

结果是就是就是完整的一个生成时间，五秒钟，需要3分钟来生成一个端到端的物体感的，产品级的端到端的等待时长是3分钟对，所以我们实际下面运行的是A1版吗，这这我觉得这是一个选择对吧，他就是不重要对吧哈哈。

我估计4090也也可以，哈哈啊，所以我觉得可以可以说的，一个是说这个这个在呃这个这个这个可怜，这个事情肯定是一个呃非常复杂的，然后重资源投入的，然后多兵种协作的这么一个复杂项目嗯。

他肯定不是一个单一的啊，我有某有个天才的天才的一个想法，然后啪啦啪啦随便转一搞就搞出来的东西嗯，好给给这边的同学一个提问机会啊，就那位同学，嗯嗯感谢您的分享，哎就是我刚刚看到我们最后有句话。

就是说呃我们这么好的技术，然后离我们好的产品，然后其实还有一些鸿沟，就是我本人是一个产品经理，所以我对这句话很感兴趣，就从您的角度来看的话，就我们可能这么好的技术到一个好的产品。

还差哪些鸿沟可以被去去被填平，谢谢嗯，这个问题挺大的啊，嗯它的不它首先它可以有不同的产品形式形态，然后来满足不同的需求，嗯如果寄希望于说它是一个统一的产品形态，满足所有的需求的话，那有的场景可以。

但是在视频的生产创作上来说比较难的啊，一个现实世界中的一个视频的创作的工作流，还是比较复杂的，所以上从基础的模型到上层应用，这一层是目前来看是不太可能做的很薄的，嗯当然大圆模型可以做的比较薄啊。

但是对于视频来说是不太容易做的薄的啊，以及说不同的领域的那视频的生产创作的需求，是应该有不同的方式进行满足的，它对应了不同的产品形态嗯，这就是先就是大概括的来说，然后具体来说的话就是就是对吧。

就是一个AI的产品，现在被大家诟病比较多的，是说它的留存等等这样的一些问题对吧，所以它提它反映出来了一些共性啊，就是说我们要重视在产品的打造啊，包括用户的一些人机交互方面的设计等等啊，这些工作非常重要。

好额最后一个问题吧，这位女士，呃汪老师您好，我想问一下就是可林这个项目的话，我们什么时候是正式可以开源，然后第二呃然后还有然后就是我想问一下，现在不是线上可以去申请这个试用吗，然后这个试用的话。

就是我是呃是克林提供了这个算力，还是说我需要对我自己的电脑，这个需要有这个显卡的要求，哈哈第一个什么什么是开源这个事情，呃我们会我们会其实我们放你刚才讲的是，我们放出了一些。

我们的一些关键的一些判断和设计，然后未来我们也会把一些呃，一些一些硬核的东西，然后逐步的时候释放出来，然后让大家然后一起来学呃，一起来交流学习啊，我觉得这是第一点啊，至于你说的这种一股脑的开源这个事情。

我们呵呵嗯呵呃可能还是要需要谨慎考虑的，就是肯定啊，不是不是那么简单的事情啊，就是呃目前还是没有这个打算，OK然后关于你说的是使用的时候，我们目前开放过来的用户，使用都是提交一一段文字对吧。

然后我们自己的服务器，然后给你返回一个结果，不需要你们不需要自己的机器对吧，嗯都在云端生成的哈，对对对，服务器生存嗯，好时间关系哈。



# 2024北京智源大会-大模型产业技术 - P7：圆桌讨论：主持人：张一甲-嘉宾：颜水成-谢剑-黄文灏-万鹏飞 - 智源社区 - BV1HM4m1U7bM

好的谢谢谢谢院长，也请刚才院长提到的几位嘉宾来到我们台上，按照屏幕顺序就座哈，嗯呃告诉大家一个好消息啊，就各位观众，我看到最后一排也站了好几排，我刚才也是穿越层层人海才找到位置呃。

刚才院长跟我嘱咐了几个核心概念啊，因为我也比较好奇，我很少去主持一个圆桌，是没不限主题，没有提纲，没有手卡呃，而且随呃院长跟我说啥都能讲，然后随便发挥时间都好，完全不着急，因为我们是今天的最后一个环节。

然后我就冒昧的问了一下院长，我说那我最后我想几点结束就几点结束吗，院长说你想几点结束，就几点结束，而且我决定在今天的后半部分，把时间留给现场观众，让大家想怎么聊，我们就怎么聊，中间如果实在不行的话。

也欢迎大家直接举手，好不好，好，那呃我自己是甲子光年的这个创始人张英甲，然后也一直是这个行业里面的一个，第三方的一个角色哈，然后我们今天的这个配置也非常有意思，有大厂，然后有呃创业公司啊，然后有学院派。

技术做技术的，还有产业派，所以呃，首先还是把这个发言的权利给到几位嘉宾哈，大家我的第一个问题是呃，听了今天的所有的这个分享，大家有没有什么新的收获，是都在预期中，还是有些预期外都认同，还是有非共识。

我们按照我们的顺序来求问号哦，对我觉得大部分的观点，我觉得基本上行业也形成一个共识了吧，就是比如说大家对skin law，然后对数据的一些观点，所以我觉得基本上还是在比较认同，就比较共识的一个状态。

明白对我，我我基本上也是赞同文浩的，如果从观点上来看，我觉得大家其实还是蛮共识的，但我可能都分享一下感受，就是啊如果说去年的时候，整个国内的整个在大模型上的这个技术生态，我感觉还没有那么大。

没有那么多的话，今年其实参加这个会，我觉得还是就感受比较深，其实今年我们在很多的这个基础上，其实都做的很好了，其实嗯李姐来水城师兄，我其实miss掉前面的一部分了对，但是从后面几个talk合来看的话。

就是我觉得有个共同的特点，就是说大家都没有真正的去触及，就是说里面最最关键最最最最隐秘，最最最最有价值的这个部分，但是都是讲自己的话，有什么样的这个能力对。

但是我觉得有个从这个今年快手的这个presentation，来说的话，他的这他的能做到当前这个结果的话，那绝对不只是在屏幕上，所所所所展示的这些信息，应该有很多的就是不便于去分享的。

这个这个技术和这个创新，所以说从这个角度来说的话，我觉得其实应该在应该应该来说的话，就是说在过去这啊半年多的这个时间的话，我觉得其实还是在技术维度上，还是有很多的这个这个创新和进展的。

对明白那个呃水城呃，就水城其实是我的本科的嫡系师兄哈，我们都是北大书院的，然后我邀请师兄给我扮演一个COHOST啊，等会如果你要是觉得大家没说真话，你就直接提问或者打断啊，没问题。

然后那个可能在这也是我年龄最大，所以我可以没有关系，对我对，然后我们就一起嘛，然后你要是有话不说的，直接我就给你翻译啊，来万总好，哎呀哈严老师点评让我压力很大啊，就是嗯呃不过确实吧。

我觉得那个我们在做视频生成这个topic的时候，还是面临着一些挑战啊，在这块领域的话，相对来说不是那么的open啊，其实中间塌了还是很多坑，然后整个这个事情做下来呃，大大小小的一些创新点还是是有的啊。

所以呃但一些大的一些方向上，我我我今天听下来的话，我觉得大家的普遍认知还是还是比较比较一致，和趋同的啊，另外我我有一个印象比较深刻，就感觉今天这个还关注度还挺高的，挺多同学都站在站在门外。

你从今天开始可能就要一直习惯这件事情哈，那这也说明就是整个这个事情这个大模型啊，这AI这个事情受到了越来越多关注，那这是一个很好的一个基础嘛，那呃随着各各各各行各业，然后各个这个角色的。

然后这个人力和资源投进来，我相信我，我相信我们是可以做的越来越好的，嗯好的，那我这样吧，我先把话题从今天下午的话题拉出来哈，我们先聊一个他山之石，我们再来看一看今天各自的真实观点。

呃大家都知道最近有一个公司其实挺火的，是苹果啊，然后呃我是全程看了他的发布会，我相信大家多多少少也都会关注到苹果的进展，自从他几个月前停止官宣啊，放弃了造车计划，然后几乎是全情投入人工智能这个主方向。

之后呢，我们都期待那个moment，就说苹果会拿出一个什么样的东西，因为这个东西是，无论在座的各位是是不是做技术从业者，我们大家都会期待的说，他真正AI步入我生活的那一瞬间，他的横截面是什么样子。

当然苹果的整个维为期几天的这个讨论里面，也包括技术的路线，也包括它端测模型只有非常非常小的啊，然后这样一个路径，然后呢包括SIRI跟open AI的结合，包括数据层面明确提到了合成数据的微调啊。

然后包括很多很多从技术到产品理念，到用户反馈，到市值反馈，一系列的这个关注点，我们叩记一点，回声四面，首先问大家对这件事情怎么看，哪些事情你觉得哦，是跟你们心中的某些事情契合。

哪些事情是你有想法说我不同的意见，我们换一个来鹏飞就转过来了，嘿嘿嘿，这个呃我觉得首先啊说像苹果这家公司，就是跟我之前做的很多事情，都是非常多非常大的关系，所以我还是非常啊respect这家公司。

就我我之前呃我在快手也做XR这个方向啊，一些这个互动啊，多模态一些互动，然后也也包括说苹果这次出的一些端测的模型，其实我过去几年也做了很多，就是把AI的能力，然后上到移动端上。

让几亿的快手用户都能够用起来，然后做的这样一些事情啊，所以呃比较有比较有体感的一点是说，它推出了一个3D的模型，这个3D模型可以在它的应该是15啊，IPHONE十五八B的内存下，然后去运行。

而且是云端模型是私有云计算，端测只有三个币对吧，所以对这个事情其实是很好的，就是因为很多的应用场景的话，它确实啊这个不需要非常非常大参数量的模型，包括说啊像现在的小模型，如果经过更多的数据是吧。

有程序LSLOW，然后能够展现出来一个比较好的一些性质，而且它有很好的一点，就是它把成本能够给这个问题，给相相应的给解决，就是比如说这个模型跑到用户的手机上，那它不需要有部署庞大的服务器啊。

来支撑这么一个服务啊，以及说它含有天然的一个隐私保护的，这样一个性质，那这些啊都是非常啊非常impressive的啊，从技术的角度，我觉得就是一个3B无线，8B的一个机器上去很好的去跑。

然后这个模型表现也非常好啊，所以它综合能力非常强的啊，呃另外的话就是对于苹果这家公司来说，我觉得它展现出来它提示了一个点，就是说生态位啊，生态位非常重要，所以从这个角度出发的话，呃，像苹果呀。

像adobe呀，像这些公司我都是非常看好，然后他们在AI领域的一些未来的应用的，嗯理解，因为我相信只要谈到真正的uuser interface，苹果确实不太可忽视，而快手的角色正好视觉生成互动。

其实快手也也也是有那么个意思，就是说我们的视频里天然有很多应用场景，这样的话就是是有一个很好的一个生态的，一个闭环和应用的闭环的，这个也是很重要的，就是生态位这个点啊，对比如说我觉得现在很多这个。

包括我已经退休的父母，大家也都用AI产品，大家会觉得这个东西看起来很AI，用起来很AI，它就很AI了，所以它更重要的还是从交互视觉触感，然后第一瞬间的本能反应来去理解AI的，我想问一下这个水城师兄。

你怎么看这件事情，就是说呃其实呃我这次的话呃，我没有看他的那个那个直播啊，但看了他后面有一些文字性的这个介绍，就说啊其实我当初的话是有一个很强的期待的，就是因为什么东西说啊。

大家知道就是那个vision pro已经发布了，那么道理上来说的话，像最近出现的，比如说像那个open AI的那个g p four o的话，再比如说像像谷歌的这个多原生，多模态大模型的话。

那么其实在这个vision pro里面的话，应该是一个非常的原生的这样的一个应用，因为它有你看到的所有的内容，有你看到的所听到的所有的内容，它可以当做是一个非常智能的一个assistant的话。

就可以帮助你做这个，你就可以想象出无穷无尽的这个场景出来，但是好像应该在发布会上应该没有讲到，没有讲到这个这个这个应用，对不对，呃，所以这这地方有一点小小的失望，但是后来看到他们就是对于端测的话。

这个就是的这个努力的话，恰好我的一个当时在UIUC的一个室友的话，他也是在也是去了苹果以后，在恰好在这做这个相关的这一块，他做了一个分享对，所以就是说这块我觉得还是非常啊，让人觉得就这个路子是对的。

因为就是说几个原因，就是说啊我们也在思考，就是说比如说像那个原生多模态的，这个大模型嘛，那么最终如果真的要用的话，你不可能所有东西都全部都往云上去走的，那么你用所有都往云深上去走。

用这可能收这个网络带宽，或者说收5G的这个速度，或者说覆盖的各种原因的影响的话，可能他的体验并不是特别的好，那么必然就是有一部分的东西的话，它可能会有一个有一个那个gating一样的话。

就是有一些他们是local，有些可能是就是上传到云端，那另外的话还有一些，我觉得肯定最后的话一定会有一个模式，说在一些特殊的场景的话，用这种端上的这个智能的呃，呃的手头用这个AI的时候了。

我们还是希望它是能够privacy能够preserving，那么这时候的话肯定就是说，希望所有东西都是local做处理，那么这时候的话，我觉得端上的这种智能的话是是非常重要的。

而且他们的这个模型的这个体量，和他们这个本身现在的这个苹果的手机，所具备的，这个就是啊就是啊NPU相关的这种计算的，这个能力的话，应该是可以绰绰有余去应付的，所以我觉得这个的话。

应该可能会成为未来的一个趋势，在国内的话，比如说像那个OPPOVIVO，小米啊，还有华为这些手机的话，肯定也会走同样的这种路线，会越来越重视在这个端上的这种AI的，这个这个能力的这个发挥好吧。

所以这点我觉得还挺挺值得期待的，对好来来自百川的谢总，对我觉得我可以分享两点吧，第一个就是我觉得苹果是一如既往的，在产品的定义和用户心智上，我觉得非常的成功，就是我的感受是。

他其实在因为他后面在提apple的这个intelligence嗯，核心其实是希望做personal的intelligence，所以他其实从一而终，一直从端到，尤其在云端上。

还用所谓的privacy的这种computer，其实核心想要贯穿的心智是说这个智能只为你，而且就一方面是只为你，第二方面是真的很为你隐私考虑，因为大家其实如果说第一时间想到，苹果和安卓两个的区别。

就觉得哎苹果关安够安全，Go privacy for you，所以我觉得在产品的定义和心智的传达上，我觉得还是一如既往的非常成功，就这一点上我觉得还是打得非常穿的，但是呃第二个点，我觉得从技术上来说。

我其实跟啊杨老师有一点点稍微的一致的点，就我觉得还有一点点小小的不够的地方吧，就是我觉得如果到personal的这个intelligence，尤其是SIRI这么大的一个入口。

其实如果更好的应该是真的变成跟人一样的，这种交互，但我觉得这次至少没有把类似这种foo的，原生的这种audio to audio的这种模型在用上，所以大家一方面。

可能苹果内部就自己可能技术还没有做到这个，第二个呢，如果跟open i合作，我觉得这趴可能会有很多PRIVICE的问题，所以我觉得这一趴是略我觉得还不够的地方吧，但我相信以苹果的这种体量和那个。

应该会很快会推出相应的这个技术了，对这可能是我分享的两点，就再次补充一下，我看发布会的现场细节，就是呃他到了AI intelligence这一趴，整个发布会的语速全部变快了，然后我当时就在想。

为什么一定要语速变这么快，是有太多卖点没有说清楚吗，我发现其实可能有一个原因是因为卖点太多，第二个原因是每当他说出他AI很厉害，他马上就会接，但是很安全，然后再说下一个点，这个还很厉害。

然后马上他会再接下一句说这个，但是我们还是用了很多关于privacy的技术，换句话说我觉得苹果在整个对外的沟通当中，因为它主C它是，而且他是一个市值龙头，所以他必须要照顾到大众的心理安全感。

自己心理安全感，所以他每说一左边刚说完，我们很厉害，右边马上就说，但我们很安全，是他一直在这个左右的螺旋当中去传递，他对AI生态和时代的理解，这个也是可能是他一贯的这个做法，比如说像手机里面一个典型的。

比如说像那个折叠的这个手机，对不对，那么其他的手机厂商都已经推出了，但是但是我觉得可能苹果觉得就是说，无论从这个技术的完美性角度来说的话，还没有达到他的要求，所以它就暂时不发布。

所以我觉得有可能这个原生多模态大模型，也是觉得还没有达到他期待的，就是那种perfect状态，所以他就DELER这个发布对是好的东西，值得等待对，尤其我觉得端云和协同这个，其实本质上我觉得多模态。

尤其是在交互这个层面，如果我来设想一下，如果真的啊苹果手里也有foo的技术，那它一定也是端云协同的一个技术，因为多模态的这个interaction，这种实时交互的这个数据太隐私了，想想如果一直都在听你。

那你要是这样讲，我就很想插一个问题了，就是应该是在座的所有嘉宾里，百川是唯一一个对多模态似乎不太感冒的，没有没有可能，这个一会我澄清一下，是说你跟小川的观点不同，不是不是跟一同相同相同啊。

等会我们再问这个问题，我们先听一下来自这个灵异万物的观点，或者来自你个人的也行哦，对我觉得可以从三个层面讲吧，首先是应用的层面，就是apple的发布会，其实给大家看到了很多应用的可能性嘛。

然后其实我们其实也提出了就是模音一体嘛，就模型和应用要一块去做，其实应用是很重要的一个part，然后第二从技术层面的话，其实我们之前就有个技术判断，就是我们先把模型做大，然后做大了以后。

他的能力会就是又，这是一个符合skin law的一个法则吧，然后模型能力会强，然后我们再想办法把模型能力做小，就是我们现在大包差不多可以做到，比如说做到十倍或者十一一百倍，十倍到100倍之间嘛的。

就是参数会少这么多，但是模型能力基本基本不掉对，然后单侧模型其实是说明了，这个技术路径其实很重要的对，然后第三个从AGI的层面，我就相对会比较失望一点，就包括苹果的发布会和GP4O。

我觉得这些模型都没有提高智能的商界吧，就我们自己有些评测就不GP4O，其实在很多能力上比GP4是弱的，特别是复杂能力上，这个其实我觉得不是一个很好的signal，OK丽姐，我刚刚在呃直播间看了你的分享。

我觉得非常精彩，其中也跟我们非常坦诚的分享了很多数据，比如说每一个人保证要有多少张卡，然后什么样的一个技术路线，我希望各各位嘉宾也可以，多多给我们贡献一些干货哈，好，那我们接下来进入多模态这一趴。

首先还是谢总嗯，最近其实动模态的命呃更新频率比较高，包括stable diffusion的three，然后包括像呃鲁马AI，然后包括像这个皮卡啊等等的很多进展，包括我在啊这个皮卡和这个龙马AI。

我是在3月份都面对面采访过呃，然后呃也看到大家有很多的一些新闻，包括像苹果快手，那就不用说了，简直就是原生动模态啊，所以在这件事情上，还是没有影响到百川对这个事情的本质判断吗，百川的本质判断我理解。

我不知道是不是误解啊，就是说语言才是智慧的皇冠，语言才是极致AGI的唯一可取之处，或者说不能叫唯一可取之处，总之就是他是至上的，刚攻克了语言，所有的事情都在里面了啊，至于其他的都是分心，不是智慧的主轴。

这句话你认同吗，对我，我觉得，首先第一我觉得先先需要把几个概念先分一下，就第一呢多模态不代表多模态不等于纹身图，纹身视频就是我们如果我们这么来看啊，就是啊模态之间我们可能会有假设，我们在多模态上。

大概也可以把它分成understanding和generation，就是any to text，一定程度上是在做理解，然后text to any在做生成，所以这是第一个。

我觉得DOM泰并不等于这个纹身图和纹身视频，这是第一个，第二个呢就是呃，百川内部确实和小川也讨论过多，就是我们一直的一个论论，就是对未来的一个大的技术判断，我觉得是这样，语言是智能的中轴心。

就他是不是主轴跟中轴线有什么区别吗，啊那差不太多，OK继续，因为你刚才前面提的说唯一嘛，唯一这个OK太过于这个这个好给我买的扔掉，对对对，太过于严格了，那其实我们内部在判断说诶，SARA这个这个点位上。

我们该以什么样的方式去投入，我觉得会有几个方面的思考，当然我自己原先也是在想要不要做到，后面也做过一些思考，我觉得我我问你一个小问题，如果SARA也好，任何一个多模态的产品也好。

如果他把语言都包在里面了，我觉得是从要不我先表达完，就是从从技术上来看的话，其实SARA从text to video嗯，这个过程中，其实语言模型并没有在里面发挥足够大的作用。

如果我们去看整个这个技术的这个过程中，我觉得语言在这过程中中轴心不够大，那未来是什么，我们先说最后的未来，未来我们当然希望是any to any，但现在确实盖在就是一定程度上有有所乌云的。

是any need to text，已经大家都已经做，就是肯定有一个统一的backbone能scale能做到，不管是现在的GEMINI也好等等也好，然后text to any这个生成的过程。

现在其实还在diffusion的这套架构上，其实大家做得更加更加成功，那这个理解所谓的any to text和text to any，的这两个部分，未来是不是一定要和，也许就如果我们信。

可能信未来一定会合，但现在没有一个可SCALABLE的这个方案去做，所以回过来从技术上来看，我们认为智能的就是提升AJI的这个技，智能语言依然是这其中的中轴性，所以我们一定程度上。

百川没有选择在SA上做大的特就是去去做，我觉得有两个吧，第一个就是我们会持续聚焦在，提升智力的这个角度上，语言上为中轴心的，所以我们any to text的多模态模型，我们会做百川四。

也推了我们的百川思维，所以这条线依然会做，然后第二个呢，就是当然也会有一些其他的一些战略考虑啊，就是你看快手手里有这么多的这个视频，Data，有很多其他的这个东西。

这个本身其实text to video的这个应用，前景依然非常广阔，对这我这个我是我想表达的一个观点啊，好的哦，我我觉得可能各位嘉宾可能要针对，刚才百川谢总的观点，可能进行一些评价或者是补充。

或者是问题都可以，呃，我我先再补充问一下，刚才我的那个点，就是你所谓的这个主啊，主中轴心，主轴这个概念里面是从技术的视角看，还是从产品的视角看，还是从一种智能的目标的视角看。

我觉得更多其实是从技术和智能目标，其实语言本质上是在，就是把人类的知识做了一个抽象和压缩，一定程度上是这样子的，所以他其实在学习效率上来看，从语言为中轴心，把其他模态跟他去做align之后。

其实是能够及能够更好的去提升，整个智能的学习效率，这个是很核心的点啊，对我我不一定是就是我可以发表一下我的看法，就不一定是反驳，就可能我觉得这里面有很大的探索的空间嘛，就是它不是一个完全收敛的状态。

其实就可以说几个点吧，就一个是说就刚才谢贤提到any to text这个事情，其实我们我刚才分享里面其实也提了，就是我们现在证明了一个事情，是说呃不同模态的数据，它是在往同一个压缩空间里面去做表示的。

所以比如说多模态数据是可以提高智能的上界，那这是一个很重要的事情，然后第二个就是any to any，这个事情其实大家要解决问题，是生成和理解一起做的话，生成部分的loss对理解有没有帮助。

就它到底有没有提升智能的上界，对我们之前的实验结果都不是很promising，但是最近我们对数据，特别是DMI数据做了很多处理以后，已经开始有些promising的实验结果了。

但这并不是一个非常确定的结论，所以我觉得这是一个open的问题，就大家还是要在自己的实验条件下，去看到自己的房顶，然后找到一个路，然后第三个其实回到我刚才分享的一个观点吧。

其实上午这个open i的ADDITIATE的那个talk里面，他也说到了，比如说他的point很鲜明，他说就是language model不一定是通向AJI的唯一路径。

它就video或者视视频的findation model其实是可以的，对我其实某种程度上我是同意这个观点的，就是我就是我前面提到，其实我们现在优化的目标，其实是在给定算力条件下的智能水平。

或者说单位算力条件下的智能水平，我同一现象观点，现在语言的效率是更高的，但语言的数据会不会碰到瓶颈，或者在它scale up的时候，这个效率会不会依然是那么高，就是视觉数据可能比较少，然后它效率也低。

但它可以利用更多的算力，那他就有可能成为更容易通向A加I的路径，但这个现在是个开放的question，就是我们只能说我们现在的算力条件，或者是我们现在实验结果都证明，语言是更加高效的一个表示方法。

但不表代表未来也一定是这样的，就是但大家可以很open的去探索吧，我觉得整个多模态其实都没有一个很fix的，就是BB去说哪个方法是最好的，就不要open，这里面其实有很多可以探索的空间哦。

我我还得我可能稍微再澄清一下啊，就说我们的claim，不是说动态这件事情，或动态的这个数据没有价值，而是说我觉得核心是说首尔之前的这条路线上，它其实对LM为中轴的这个利用并不那么够。

其实他一定程度上是也是open i内部的一个side project，但它的主轴线g b five，和那个也许会把很多的技术融进去，但它一定不是一个只是solar，就这是我们的观点。

不是说动模态的这个数据没有价值，我觉得这个可能是要澄清一下，我觉得零一和百川有一个非常大的相似点，就是大家对于技术本身，或者对智能本身是有着非常执着的追求的，这点其实我在跟皮卡也好啊。

跟硅谷的很多创业公司来讲，我说句我实在的感觉大家对技术没有任何执念，大家就是要搞一款产品，然后技术什么available，用什么路径不重要啊，然后模型什么DIT什么的不重要啊，然后呢嗯随时拿来即用。

他的目标，比如皮卡，他的目标不是做一家AI公司，他的目标是要做一家视频公司，是一个苹果一样的公司，会一个类似这样的公司对，然后呃这个时候可能大家的讨论，反而我们会觉得最该讨论技术的人，大家觉得无所谓啊。

就是两位，我再补充问一下两位，两位觉得技术现在路线这件事情，是过眼云烟一样的存在，还是信仰般的存在，还是什么样的一个存在，首先我想问一下，你为什么觉得他们是更应该讨论技术的人啊。

我当然不是说从创业者的角度，谁来讨论技术的人，而是我问到非常多关于技术的问题的时候，我得到的反馈并不本能，反馈是这个事情我可以回答，但似乎这件事情也不是我的坚持哦，就是说我下下个礼拜。

可能跟这个礼拜聊的事情就不一样了，然后呃，包括一些500强公司的CTU或者CL，也是我指的，在硅谷啊，就大家可能会认为说not sure，未来的structure到底是什么，呃，Not sure。

而且没有权威，没有绝对的权威，所以当然也许技术，最终技术本身这个轴是重要的，但是在当下横截面上，这个技术长什么样子的，大家觉得不是那么重要，这是我刚才的意思对，其实我们是同意这个观点的。

就是但是每个公司的vision可能是不一样的，就是我们公司还是一个，以AGI为主要Mission的公司，就是我前面也说了，实现AJI的路径可能很多，我们不会拘泥于很具体的一条路径，去做AI这个事情。

但是我们的目标是要达到1ZI，然后我们做很多模型和应用，111起开发的事情，是因为我们觉得这个时代最大的机会，其实是在A加A这个事情上，或者这次技术革命，最大的机会是在A加A这个事情上。

那你实现了技术上的，就是你可以更快的达到AGI，你就会有更多的模型和应用的机会，明白理解，所以我我两边这边是做AGI的，然后那边肯定不是为了AHI的对吧，有水陈老师也是做AJI的，水陈老师。

你你你JI是你的目标吗，哪个a g i artificial general，实是你的目标，对我觉得他们的意思应该是说，就是说，其实就是说，如果我们专注在语言这一个维度的话，从技术从产品的角度来说。

已经可以造就一个伟大的公司了啊对对，所以所以首先是一家公司，其次再是一个学术的至上的皇冠，当然我这样说，在今天的会场可能有点格格不入，毕竟我们居然是新型研发机构，而且我也很愿意讨论学术问题。

这个我必须要说在前面呃，但我们先把这个目标先定义清楚啊，就是AGI是核心目标的是这边两位，然后那个万总你你的目核心目标是什么，伟大的产品，OK呃水成总啊，水成兄我我我们这边公司是是说是V呃。

目标是两个呃，就一个了，就相当于说是叫做实现通用人工智能，然后让每个人都更好的造就和塑造和表达自己，对明白对，就shape and express对，因为大家前阵子的很多论坛。

就是在我们智源之外的非常多的片呃，比如说媒体或者说是一些产业的论坛，大家可能会关注啊，你是市场派的还是技术派的，还是派的，然后你到底是是需求驱动还是供给驱动，但我发现呃。

这个01万物和百川其实是突破驱动，或者说是AGI驱动，某我我指的意思是说啊，他这个东西是我的，我要证明这件事情的能力去触及这个边界，我可以这么理解吗，我我可以先补充一下，我觉得我们的目标是ACI。

但我们的claim是最好的产品，和AJI是一体的，就这两个分不开，就是你没有A加I，你做不出最好的产品，这个事情是你们的claim，还是已经有一些佐证的，嗯应该是我们的信仰对未来的判断吧，判断OK好。

我也补充一下，就是呃其实百川也是叫超级模型加超级应用，双轮驱动的这么一，所以我觉得就对，其实小松也表达过这个观点，技术派这个这个所谓的市场派，其实都都也算是蛮能摸下嘛，其实最终你要真正做到真的。

因为一谈A加，大家当然非常嗯非常兴奋，但最终你要怎么做到那一步，一定会有是有跟市场的结合，有跟应用的结合，也有很多时候也需要用户的反馈，所以我觉得这个不是一个exactly。

绝对我觉得现在这个世界上可能唯一一家，也许真的说exactly只以A加为目标的，可能就OpenAI吧，并没有open i也open i键，也没有哦，Open open i，Open ai。

我越来越不知道他们是什么驱动了，所以所以这两者其实嗯也一点都不割裂，对不对，如果要打造一个伟大的产品的话，那现在这个时代的话，那最大的一个变量还是说技术的突破啊，倘若说呃。

一个如果要做成一个非常好的一个产品，它的核心的驱动力是技术突破的话，那这不就是殊途同归了嘛，就一体了嘛，就是那个一讲，我这其实这里面涉及到一个很重要的一个，一个问题，就是道理AJI是什么，怎么定义。

如何定义说AJI已经被实现了，对哎如果如果这个东西定义清楚了，那么其实就是这家公，我们这家公司到底是不是以A加R为目标的话，它就变得越来越清晰了，对这里我也可以，我特别理解。

因为我帮你回答一下百川的观点啊，如果百川没有改变观点的话，呃在去年哈哈哈，去年4月11号的时候，百川发布他的宣官宣成立，然后呃我有一篇文章叫就是贾牙语对话王小川，然后其实聊了很多维度。

然后小川特别让我把标题改成了，就一句话叫通用人工智能时代已经到来了，他不是说我们将实现AJI，而是AGI正在已经发生了，我理解我猜测这个概念其实是说，我们没有必要等一个小孩子长到18岁成年。

我才判断他是个人，他三岁那一刻起，我就认为他是个人了，无非接下来他怎么成熟，怎么成长，怎么就业，怎么去发展，怎么贡献价值而已，这是我复我复述，或者我翻译我理解到的东西，呃谢总，这个现在有变化吗。

呃我我是觉得是这样的，我们叫内部叫做智能纪元，就是我觉得是一个叫从如果从deep learning开始出现，就deep learning开始开始之后，就是我觉得在HIGB的出现。

是让我们看到了AGI的曙光，就很重要的，其实核心是说我所有的任务，都就如果以自然源处理为为例，就在此之前我做了很多年的LP，但既包括一点，一直在困扰心中的是。

为什么每一个task我都要用一个deep learning的model去做，有没有可能一个all in one的，人类所谓的通用人工智能，或所谓的那个是我一个model。

能不能one rule o all in one，所以我觉得ChatGPT，或者说这个jg b t系列的原模型，是第一个先看到了这个曙光，所以我觉得我们内部更更多叫智能的纪元吧。

因为这个门看看上去似乎看到了理解对，好我现在要把时间，我先抛一个问题给各位呃，观众或者说各位同学就是呃，我后面可能也可以去聊大模型的其他产业化，价格战，或者是其他的技术路线的实现难题，或者实操的问题。

或者工程问题或者理论问题，现场想继续听AGI的请举手，现场想pass a h i去听应用问题呃，或者实操问题的请举手哦，不不不举手啊，好我喊321K还是有大概目测十五百%，8%左右的观众想继续听AJI。

这样我给呃四位嘉宾，每个嘉宾大概一分钟的时间来谈一下，你和你的所在的公司团队，对这件事情，在目前你们的版图里，他是一个什么存在，以及对今天的JI怎么定义和理解来OK对，其实我还挺surprise。

包括听了上午的那个大家的讨论，大家对E加没有个很统一的定义，就我在硅谷其实跟很多公司聊，Anthropio open i，我觉得他们的定义是统一的，就是A加A就是能够替代人类白领，80%到90%的工作。

这是一个完全可以量化的指标，当这一天发生的时候，贝加就到了，对然后大家讨论的很多事情，比如说能不能完全超过人类，这个在大家定义里面叫super intelligence，这个和AI的定义是不一样的对。

所以我们基本上也是follow这个定义，来定义什么是AJI的对，然后第二是AJI是呃，在公司是什么位置，就是我们的呃，公司的vision是让AJI可以。

Uh beneficial and acacaccessible to everyone，Okay，Ok，所以零一版本的定义是80%到90，实现人可以做的事情，人类白领可以做的事情，人类白领白领。

那AHI那几乎就是唾手可得的一个，大家对这个事情的统一判断是6年六年，这个统一大家是谁，硅谷的硅谷，但你刚才也讲，硅谷跟中国其实差距好像没那么大，没什么差距，没什么差距。

OK那一个非常clear的答案了6年，然后中美同时步入AJI的时代，OK谢总对了，因为其实AGI这个我一定程度上，我其实是赞同啊那个文浩的。

然后那个google dem呢发了一篇paper叫the level of a g i，然后那个的定义我基本上是认同的，就是他的是叫他的这个AGI，是90%分位的，Skilled adults。

就是有技巧的，成年人的90分位到95分位的，就大概超过这些，你觉得基本上AGI倒了，然后如果超过了所有分位的人，那就是super intelligence，所以skilled adults。

然后呃我是觉得刚才回顾到刚才那个问题啊，就是大圆模型有all in one的方式，开始看到了曙光嘛，但是同样的，比如说比今天我介绍的那个benchmark叫盖亚。

就他是一个复杂任务的这种这种这种的benchmark，你会看到其实人类很轻松的，或者说人类花一些时间是能够解决好的，这些问题，现在大模型其实大概也就十几分的水平。

可能做上复杂的system two的思考之后，大概在30几分，所以这是现在万亿左右参数量级的这个模型的，这个大概的这个这个情况吧，至于说多少年到一家，说实话我很难predict。

但可能从大家看到的可能是有人说3年，有人到6年吧，我觉得三到6年maybe对我可能比较，有没有人可以给我分享一下，这个数字怎么算出来的，其实没有，我觉得都是各种大家的predict对。

所以这个我觉得就比较比较tricky，我核心我觉得得要看一定程度上，可能要看GB t five，所谓再做十个t FPS的这种提升之后，智能到底到什么程度，我觉得这可能会是一个蛮标志性的问题。

你可以理解为，比如说6年还不能做到80%，到90%，这个BUBLE就破了，对对对，就是他们就是open i和AEROPPER，对投资人讲的都是这个事情，就是他们大家都是对A加I有个，非常明确的定义的。

对嗯行，那个其实其实一开始大家都在讨论A，在讲A加R，那其实每个人的定义都不一样，但我觉得就是嗯前面他们两位讲的就是A加的，这个一个评判的标准是很有道理的，就是可能就是大部分，也别说60%到80%吧。

就是说大部分人能完成的事情的话，这个AI都能完成，那么这个时候的话，其实有一个很好的一个一个标准，就是说其实就已经具备了人的某种意义上，已经具备人的这个意识了，那么这个意识的话是是什么东西的话。

其实是有是在心理学的角度来说，是有人做研究的，还有一套理论叫做global workspace，叫全局空间理论是什么意思，他认为在人类大脑里面的话，除了system ones外的话。

有一个专门的空叫做system two，这个system m two，就像有有点类似于像我们是一个stage一样，也是一个总导演，这种总导演会决定人的各种模态的，这个信息的话。

哪些信息会被attention就select到这个global workspace，就是这个舞台上，然后呢它同时会去提取记忆，提取人的target，他的intention要把这些信息传，还。

有可能会去提取一些特殊的，大脑里面的一些功能区，比如说专门做数学计算的，专门做逻辑推理的，那么这些区域合在一起的话，会做这个reasoning，reasoning完了之后的话。

他会把这个信息的话从system two的话，在广播到这个所有的season watch，就是那个子系统，比如说这个是视觉，这个是触觉，这个是听觉，这个是这可能是感知温度的对。

那么这样一个过这样的一个整个的一个，global workspace的理论的话，他就认为能形成意识对，那如果从这个角度来说的话，其实我个人认为就是首先要想实现A加R，就一定是有意识，有意识就可能会符合。

这个就是global workspace这个理论，那么第一点它一定是一个多模态的，一定是要多模态的啊，就是相当于说它最终它就是，而且最好的一个表现形式就是一个超级智能体，它是一个超级自身体。

它能够ACCE到不同的单模态的这种foundation model，可以去访问到各种不同的工具，可以去访问memory，去update memory，可以去更新我的那个这个各个单个的。

这个多模态的这个这个这个模型都是可以的，那么这个超级智能体的话，会最终的话会去形成这个AGI对，所以它一定是多模态的对，所以所以从这个角度来说的话，就是说我这研究多模态的话。

其实还是一个非常有必要的这个事情，还有一点就是说，因为我自己的背景也是做多做多博泰出身的，相当于是就是说跟基因也有关系，就是说因为我们我们一周开始做研究，就是说经常的话在PPT的第一页。

就是说人的70%的信息，是通过视觉获得的，而且视觉的话是一个3D的，英语音的话是一个ED的，相当于是，所以它的信息量的话是比其他的模态要多很多，比文字要多很多很多对，那么在这种意义上来说的话。

就是说就是这个从信息量角来说的话，也是就是消被消耗的这个信息来说，太多的都是用这个视觉来做了，而且的话现在的话，我们每天所消耗的这个信息的话，包括像抖音，像快手，那基本上都在消耗这个这个这个视频对。

所以从这个角度来说，其实从这个角度来说的话，我就觉得就是说这个就是纯粹的文字的话，可能要跟这个就是要跟这个就是呃，就是呃要跟这个就是视觉的一些东西，可能啊音乐的东西，云东西要结合起来，哎好吧。

我就先分享这么多嗯，非常精彩呃，鹏飞你先答，然后我们再展开讨论，刚才是那个水长师兄的一个判断，整体上我还是比较赞同杨老师的一些观点的哈，我我我我说两个点哈，第一个点就是伟大的产品，我举两个例子吧。

chat g b t是一个伟大的产品，IPHONE是一个伟大的产品，它们背后都有非常强的技术，嗯只是说这个技术有的可能是AI的突破，G b t，那有可能是软件硬件的某种深度的融合啊，某种交互上的人。

就是说伟大的产品往往离不开牛逼的技术，包括电话的诞生，那也是在当年那个时代是非常牛逼的技术，OK所以所以我还是想要再强调一遍，这这个东西不不适合割裂的来讲啊，第二点我想说的是呃，关于关于智能。

关于多模态啊，如果按照刚才讲的是说，白领80%或者90的工作，能够被AI所替代的话，那AI一定是一个巨神能移动的东西，这个点其实刚才没有被被被被聊的很充分啊，就是这个挺重要的，就是有一部分的智能。

它应该是从与世界的交互中来习到的，OK所以这个这个是一个啊，第二个讲的是多模态啊，比如说我们可以暂且认为也是白领对吧，我们现在在这坐在这聊天对吧，那如果AI要替代我们的工作的话。

这个AI它不单单应该是只有语言的能力的啊，它一定是动模态的，就是国外有这个不知道心理学家，社会学家，反正有人做过实验，就是在这种face to face的这种人和人的交流当中，视觉的就论信息量的话。

视觉信息传递的信息量是占55%的，然后语音和文本各占了二三十%，好像语音还要多一点，OK这是这是有人就是就不就非AI人士，但是他们可能是一个社会学家，然后做的一个实验啊，纯从信息量的角度。

它就是从以某个角度，然后来说明了，如果AI想要替代我们这现在做的聊天，这个工作的话，它得是多模态，而且里面有些模态，包括视觉可能还是比较重要的，然后如果是智能体的话，跟环境的，跟世界这个交互。

这个事情在视觉信息又又变得很重要对吧，包括一些物理对吧，然后这种交互这些跟物理世界打交道的事情啊，所以呃所以在我看来，真正如果说要达到刚才定义的AGI的话，它得是巨深的，得是多模态的，非常清晰。

我我补充一个，其实这那一套理论里面，还有一个很有趣的一个结，一个结论就是说不同的模态，最终在那个global workspace里面进行交互，和这个和这个reasoning的时候的话。

他用的就表示形式是用language对，所以这个也从一从某种程度上来说的话，就说明了language的重要性，也就是说只有language才可能变成一个self complete的。

就自我完备的一个这样的一个generalist，对，就是说要想它是一个自我完，本意思就是说我从这里面生成出来的东西的话，它一定还在这里面的话，那么只有language才可以图像是不行的。

语音语音其实最终也是会变成是language，对不对对，所以从这个角度来说，其实也说明了language的话的的重要性，这也是为什么说，现在我们其实做这个多模态大模型的话。

其实是先TRA一个language model以后，再把其他的模态，以这种就是token alization的方式把它再插进去，对不对，其实可能跟global workspace可能还有一些相似性。

对刚好其实那个杨老师提的这个grow work space，我们在盖亚里面的那个architecture里面，就就用到了这个呃，其实刚好，所以那个确实会比较大的，会会去提升这个任务。

在规划当中的一些很多的memory上的那种管理，对好的，那我就总结一下刚才AJI这趴的讨论，其实呃，我我希望大家不要听起来好像有很多的立面，但以为大家有很多本质分歧。

我听下来其实大家是一个浑然的一个立方体的，不同的投影在不同的面上呃，当我们在谈AGI的时候，其实我们可能从很多层面谈，比如它技术的底色，那些被封装在盒子里面的那些技术的逻辑。

它到底是预言还是多模态表现出来的东西，它是语言还是多模态对吧，然后从这个对AJI的定义的角度来讲，一定是呃理科生，工科生，文科生的定义方式天然不同，比如说理工科生可能会说。

OK6年90%的对什么角色的替代，理科生可能会说的是你替代的白领，白领先定义一下，然后对吧，就这个定义如果不是一个好定义，那么更本质的定义是什么，可能是对吧，那个是水城师兄应该知道，比如说数学上。

如果我们定义一条定义实数，其实我是无法告诉大家说呃，根号二是个实数，然后1/2是一个实数啊，3。333是个实数，我是要用漫长无穷长的直线，戴德金分割砍一刀是一个实数，这叫严谨定义。

就是说它跟实数和直线上的点一一对应，这叫严格定义，一一映射对吧，所以我们无法对AGI进行真正意义上，本源的严格定义，但是我们可以基于某些假设进行推理，比如刚才彭飞总讲。

就是说OK如果说要替代八九十%的白领，那么他一定要动模态这个东西，我觉得大家是可以，很容易就把刚才所有的嘉宾观点串起来了啊，这个其实是刚才我们这一趴，对AGI本身这件事情的呃，一个阶段性的一个呃逗号吧。

应该是逗号啊，然后我再补充问一个小小的问题，那个水中师兄，你刚提到了一个，我们可能最近在讨论那个热词叫意识，能不能展开说一下你对于这件事情，用2分钟来说一下你对这个事情的理解。

其实意识的话就是其实就是呃是一个有，就是当他有自我的这个这个概念的时候的话，他就相当有意识了，对但是但是客观来说，我刚才讲的我们刚才讲的这个global work space话。

和有我的这件事情的话的关系不是特别的强，对他只是说用GLOBWORKSPACE的话，里面的话会用到一点，就是说啊我还有一个子模块，这个子模块就是自我，就是就是就是self，意思。

就是说我在做这个做这个reasoning的时候的话，我是把cf这个这个信息考虑进来的，那么这个时候的话，他就认为就是说我就有了了，这有了这个意识的这个这个整个的experience了。

它说它里面讲的是叫做叫做意识的experience，对，还是说到底什么是意识，其实我觉得其实不是特别地清楚，但是self这个事情可以清楚，对不对，呃，但是它是用一种偏比较偏数学的语言的话，来表达的。

但是那个sap到底是一个什么样的东西的话，它只是说在我做reasoning的时候，就好像做做long context的这个这个L，比如说用IIM的话去做这个推理的时候的话，他只是说把那部分的信息拉过来。

放到了这个模型里面，然后把这个因素考虑到了而已，但是真正的就是说这个save是什么东西，以及就是说我这个结束之后的话，我是怎么去更新cf的话，其实根本就说不明白，对我我听到那个就是之前百川内部有一个。

应该说是你们的两个皇冠吧，一个是意识，一个是生命对吧，AGI的皇冠就是AGI替换八九十%，那么白领这可能是一个宣告宣判它成了，但真正的皇冠是意识和生命，这两个模型是不一样的，对生命是一个复杂系统。

而意识可能是甚至是量子力学对吧，它其实完全不是一个东西，那么这件事情我就想好奇一下啊，本能的好奇，然后我们就聊价格战了啊，然后哈哈就是说四位能不能分别说一下，在两个皇冠上。

最前沿的进展到底是一个什么样的，就是风起微风送来一个信号，这个信号可能是什么，对呃彭飞你你要第一个讲吗，来我理解一下这个问题啊，那这个来文浩仔第一讲不就在意识，在以AI来抵达意识。

和以AI来构建生命这两件事情上，呃虽然我知道大家听起来非常之科幻，但我们知道智源其实专门还有一个呃，平行的圆桌，是专门聊意识的，我其实很遗憾没去听哈哈，然后那个能不能，大家嗯可能简简单单一两句话吧。

说一下在AGI的这个我我理解为门槛，假设是八九十%替代白领，那么皇冠现在能看到什么信号，微风送来一个信号，或者说风起于青萍之末，这个微风可能是什么，是一个小技术，也可以是一个小的论文。

也可以是一个小的猜想，也可以，师兄水成你，我们大家这个问题这样，因为我可能问出了一个，大家心中不一定有清晰共识的问题，所以大家对接下来的回答，我们尽可能的都K嗯，嗯嗯我我用快手的使命来回答吧。

嗯提升每个人独特的幸福感啊，如果能以某种方式达成这个目的的话，嗯就可以你说的没有任何问题，我们可以回答11万个提问，你都可以用这句话来我们的那个水城师兄，我我这意识的话是在解释。

就是说这个人为什么是人对，那么生命的话其实是讲，就是说，从这个有点像是从那个物理的机制的角度来说，去解释人的生命，就是从细胞啊，从根细的这个组织上来说，它到底是怎么运作的，以后能把人为什么是人。

这件事情的话能够巨化具象化对OK具象化对，来就是一，就是可以真正的一个是，就好像说是怎么样变成一个真实的实例的，相当于是，其实我自己感受啊，现在在讨论的AGI，包括super intel卷式。

其实我觉得都基本没有在谈意识，当然我觉得意识这个东西，因为我说如果智媛的人在志源会跟你谈，有很多的，这对对对，非常多，这个我觉得你千万不要说没有人在谈，没有我说所谓的构建自我意识。

至少我觉得或者说我们说从判断标准上来看，替代就是你达到了刚才所谓的判断标准，替代80%，或者说智力上超过了80%和90的，这个，就或者能够完成80%和90分位的，这个人和建立自我意识。

我觉得这还是两个概念，就是你说最后我构建了一个制定核心，是说这个生命和自我意识的核心是，他自己有自己的目标，有自己的使命，有自己的去做三次，就是去删减的这个动作，这件事情和我接构建了一个智能体。

他可以接受你的command，他可以告诉他可以完成这个任务，我觉得这是两个概念，我说的是说没有人在做，这个是说我们在定义所谓level a g i的时候，说哎，我可以达到80%和90分位。

人能干的这件事，它和一定有意识之间测，这两个我感觉并不是一个直接连接的，这是我的点，并不是说我相信应该很有很多人在研究，我怎么去构造，所谓能够有自己的self意识的，对我觉得这是这是核心的点。

是的那个meta的有一个研究员叫那个田园洞啊，就是呃正好我们前两天刚刚去聊过这个事情，他其实有一个很自然的表达，就是说意识是对自我的建模，对我们要区分自我这个东西，把它定义清楚。

可能就那个旋的部分就扔掉，我们先把自我这件事情什么是我，什么是外面有什么是里面，什么是外面这个边界线搞清楚的话，他可能就迈出了一步对吧，来收一下这趴对我分享一下我个人的思考吧。

就可能不肯定不代表公司观点吧，其实前段时间JP4O出来的时候，就比较具体点，就我们很多人其实一块思考过这个问题，包括很早以前我们在做一些语音的事情，就讨论过，就是假设这模型在听听你说话的时候。

它能自主决定我什么时候应该打断你，那这个可能他已经有意识了，但我们回过头很仔细的看了GPS的一些demo，会发现它其实我我们猜猜想它还是个模型，在predict，你是不是已经说完了。

如果protect完，你说完了，然后我就开始把前面那句话传给模型，然后模型开始给你回回复，然后在回复的过程中看到你还在说话，他就把这个回复打断，我们去看他的那个demo，其实有很多这样的case。

但如果有一天这个模型可以自主决定，就像我们人在对话的时候，比如刚才我们在讨论的时候，有人会就是插插烟话去表述一下自己的观点，模型可以自己决定什么时候应该做这个事情了，那这个其实已经离有意识非常接近了。

因为他自己在做很多的判断，而不是一个就是显示的一个行为，我就是我要去做，他是不是说完了这样的事情，因为我是在思考你说的话，然后我在我一直在思考，我什么时候应该打断你，我应该插入我的表述，对明白，好的。

那我接下来问题我们换一种方式，快问快答一下啊，快问快答一下嗯，好价格战呃，大家都知道这个今年但在座的好像也没有呃，没有字节跳动火山引擎的人，也没有百度智能云的人啊，也没有阿里云的人嗯。

然后但但是我们在半个礼拜之内，几个大厂把价格战打到地板价免费，或者是非常便宜啊，然后各位呃怎么看这件事情，以及在你们的商业闭环里面，这个事情应该你们的这个呃是一开始就绕开了，这个事情。

还是会经历一个心态的调整，然后未来会怎么做啊，每个人我觉得还是大家还是尽量的几句话，我们快问快答好吧，呃那还是昆仑万维，我呃我们其实是一开始就避开这件事情了，因为我们觉得呃。

因为我们觉得就是说一个公司的话啊，对于我们这个体量公司就是中型的公司，大概500亿500亿人民币的这种公司的话，我们觉得产品对我们来说是最重要的，新的产品对我们来说最重要的。

所以就是说我们在做这些大模型的时候的话，那么我们先是有五个不同的app，再去事先就定义好了，比如说我们会做一个search一个APP就是天宫，然后有一个音乐的一个APP，有一个做漫画的APP。

有一个做这个就是啊陪伴的这个APP，还有一个是游戏的对，那我们就说一开始时候就是认为有这个六个的，这个呃，我有五个这样的APP的话，它会是我们这些大模型落地的这个场景，所以我们的这些模型的这个研发的话。

就是至少90%以上的目的的话，是希望就是说为这些to c的这些产品的，那么其实内在呢有一个原因，一个就是说我们比较擅长于to c，因为我们一直是做出海的，一直做出海的业务。

所以我们的比如说这个这些成功的产品的话，基本上都都to c的，另外的话就是说我们觉得中国的话，其实一直就是卷嘛，就是说可能会出现，类似于像当年就是CV市售一样的话，本来在安防的市场里面的话。

其实应该是有蛮好的，这这样的这个市场对不对，但是通过因为价格战的话，其实就让这个就是revenue的话，是受到了很大的影响，所以我们觉得有可能在这个大模型，这个维度的话，也会发生类似的这种这种事情。

就是说最后本来是一摊很好的生意，但是因为这个价格的这种之争的话，就可以让它的revenue的话，就会变得就没有那么attractive了，对所以我们大概是这样一个逻辑理解，快手怎么看呃。

我觉得它背后的一个本质问题还不是价格，那是RI嗯，就是它不管是价格怎么样，只要是说对于一个组织来说，它的商业模式里面对吧，它的RI是正的什么，跟他的客户的LY是正的，那这个这个模式就可以跑起来。

那你你价格低一点对吧，但你成本也更低，这个事情是完全是OK的，比如说在快手里面，我们做的这些事情的话，在我们的应用场景里面，它的商业模式是可以跑通的，什么意思呢，就是说呃可能由于快手它独特的一个生态位。

它的一些商独特的商业模式，我们做的一些大，我们的大模型，包括基于大模型的产品，在整个生态里面的运转，它就是能够以一个非常容易skill的方式，然后LI大于一的方式，然后给公司创造价值，那这个价格高一点。

成本高一点，低一点，对我们来说不是那么的关键啊，所以不嗯如果不是快手，然后其他的一些公司，其实我觉得本质上也是这么个逻辑嘛，就是只要这个这个这个这个模式能跑通的，然后客户也是满意的，然后公司也是OK的。

那他就它就属于一个健康的范畴对吧，如果说托ROI，然后整个它就不是一个正向的一个飞轮，那这个事情可能就会有一些问题，长期来看好嗯，两位都可以行，那个我分享，我觉得核心其实为什么云产商。

因为回顾一下这个历史的事件是这样子，其实一开始大家我理解，云厂商也并没有要涨降价，其实是deep sick，还是呃，做了一个，确实是在降低成本的一个技术上的优化，于是他们把价格做到了一厘千头啃一离。

但是紧接着因为这场这个动作之后呢，云厂商本来就在做一件事情，就是它的降价一定程度上是羊毛出在猪身上，就他的生意模式本质上是说OK，那我模型卖给你，我API给你核心，我可以哪怕这里不挣钱。

我可以在云的其他服务上挣钱，所以他那就变成一种获客的模式了，我觉得它的核心是羊毛出在猪身上，那对于百川而言，显然这不是我们的能做的这种商业模式，那我们可能更多，我觉得对于创业公司来说。

我们肯定更大的就是C肯定的超级应用的突破，一定是未来最大的商业模式，那B端可能还有会有其他的一些附加价值的，一些打法吧，这我这是我的能理解啊，对啊我我可能可以提供两个不一样的视角吧。

第一个其实刚才谢健说到了，就是最早打价格战，也不是价，把价格降下来，是deep sick，他们提了MAA，然后还有MOE的一些方法，其实这个是所有就是在做大模型，就是讯推一体的公司都在优化的目标。

其实我们也做了很多事情，然后我们也复现了MLA，我们有些跟他不一样的技术思思路，但都可以把成本降到就是1%，所以他们一美联就100万的token，一块钱是可以挣钱的，然后模型能力是比较强的。

但这这并不是一个烧钱的打法，对，然后第二个视角其实是，大家可以仔细去看每个公司的价格战，大家每个公司有很多档模型，大家把价格降下来都是最弱的那档模型，然后如果大家可以去比较一下，最强的那档模型的价格。

因为我们刚发布的时候，我们的定价就非常低，我们的API定价会非常低，我们看到很多在OMCS上比我们就排名，比我们低一些的模型吧，就大家可能能力在差不多的一个level上面，我们认为这是比较强的模型。

他们的价格降完以后还比我们高，所以大家只是在一个低端模型上面去做价格战，我觉得这个意义不是特别大吧，okay呃，其实这个商业逻辑的事情，我觉得大家应该都已经看得比较清楚了，所谓的羊毛出在猪身上对吧。

它大闭环对大厂大闭环，小厂小闭环，大公司可能是用户买产品，产品买模型模型，买云计算，云计算买卡，然后顺便再做一把投资，还有二级市场对啊，但是但是其实那个溢价就是可以对比一下中美，为什么美国的话。

它可以不把这个价格降下来的话，也还能够生存下来，这个对比下来说来话长，就是我还可以跟你讲，美国的智库也不是我今天的商业模式哈哈对，就是这个说来话长了，而且这个是不不是由技术或者说大模型。

就是跟大模型和技术都没有关系，就是非常多的事情，其实都是要以市场来导向来影响，对这个其实不是我们今天要展开，也不太能够说得完哈，对那呃这一趴里面呃，其实大家有没有什么想补充的关于商业模式啊。

或者商业模式建议啊，或者商业模式呼吁啊，好看来大家都不想聊这个话题，哼，OK那我们再看看有其他的我我还抓到了一个点，是超出我的预期的一个点，就是我不知道大家怎么理解，我觉得听下来今天的现场啊。

就大家其实每个人对skin all多多少少是乐观的，或者说阶段性乐观啊，我们先用skin law实现一些东西，然后大不了我们再把它搞便宜哈，我们先用skin law共同法则搞大一个事情。

大不了最后再做小，所以现在大家四位同时举个手啊，因为我前面错过了半场，我需要再回溯一下规模法则这件事情，你认为你现在一路做大，请举左手，然后你现在正在考虑做大还是做小，你不举手。

你觉得开始准备做小举右手好吧，来321请举手，做大你现在在做大，举举左手，你现在往小了做举右手，然后你现在没考虑清楚，或者正在中间节点上就不举手，来321请举手，哈哈可以，但不是投降，是这样。

来那个彭飞，你是不举手，OK懂，因为你是大厂，你可以分层，拿出不好的去免费打价格战，按照他们的逻辑，你认同吗，认同啊，就是有一定的优势，其实彭飞刚才向我流露出了一种微笑的眼神，是我就看着你们这么的骄傲。

但我什么都可以有呃，呃并不是我觉得就是不同的公司对吧，使命不同，然后这个组织包括这个商业模式都不一样，所以他打法就天然是有些不同的，就是最终还是服务于某一个目标是吧，所以说大还是小。

在我看来就是赋予不同的目标对吧，比如说我一个模型要服务4亿的用户，让他们用我，我不可能做大，成本受不了，是其实一旦你to c，尤其是to大C的超级产品，你其实就把某种意义上的战略的骄傲。

让渡给了用户了啊，然后某种意义上是真正意义上的，所谓让大家的生活更美好，这件事情就没有那么高不可攀的，严肃的，所以我说嘛，快手的使命是提升每个人独特的幸福感，我还是看快手，我非常喜欢快手。

因为我曾经尝试在很多年前同样发短视频，在快手跟抖音，然后在快手上涨了20万粉，在抖音涨了1万粉，同样的视频，那说明你的内容比较优质，可能我比较符合太快手的粉丝画像，对我我比较呃对下沉哈哈。

然后嗯我我不想继续问了，因为时间其实已经到了，我觉得大家是这样，我们就轻松一点，因为中远院长刚才说他要去接待，然后跟我说嗯，你到时看着办，聊完咱就直接结束这场七天的展会，现在把时间留给我们现场。

还留在现场的朋友们，大家可以举手，然后来提问好吧，提问谁都可以，呃万博士您好，刚才我们聊到快手的使命，然后我们都知道快手一个slogan叫做，拥抱每一种生活，那根据AJI的发展。

然后每个人都能生成自己的视频，那么未来快手上是否会充实很多的那种，理想的美好生活，而非真实的生活呢，我们slogan是否还会依旧继续改变呢，好多问题啊，我觉得首先啊就是我我我在我的PPT里，我也讲了。

就是视频的获取，然后是不同的形式，它只是一个形式对吧，但是它的内容是可以在符合社区的一些规范呢，明白吗，就它指我们现在讲大模型，目前我们只是踏实到了一个内容生产，然后的一个一个情况对吧。

但未来的话这样一个视频到了用户这边，然后对他来说，他可能还是满足于他之前的需求，但是有可能会满足的更好，比如说我就就让一个小孩看到了一个奥特曼，打孙悟空的一个是什么样子的对吧，所以社区的管控啊。

这些事情的话依然是存在的，用户的需求是依然是可以，以相同的方式进行满足的，它并不并不一定会破坏整个，比如说一个短视频内容生态的，一个基础的结构啊，他肯定会带来一些挑战，更会带来一些机会啊，我是这么看。

我还是比较乐观的很好，那如既然如此，每个人都能生成视频，那么我们是否可以写一个脚本丢给她，她帮我生成一个爽剧，然后我去当女主呢，这个您觉得这也是一种需求哈，这种需求。

但是你得考虑另外的一些社会的因素什么的，就是如果作为一个内容平台的话，我们都会考虑很多不同的方方面面啊，但是是一种需求，也许在某些特定场景下，可能就是要释放压力，看看一个你你自己表演的一个爽剧霸总是吧。

是不是能够带你给你带来些快乐呢对吧，那您觉得这会多少年就是我们丢给他一个脚本，人人当编剧，人人当导演，视频创作力还是相对来说比较复杂的，这个事情不太好预测，但是整体的发展很快，我们可以拭目以待吧。

好十分期待，谢谢，嗯好那位先生，嗯我有几个问题想问一下老师，首先是万老师，我也是快手的忠实粉丝，嗯跟张老师的感受一样，我觉得快手的话，其实对我们呃普通的用户推流更多一点。

所以说普通人在快手可能会有更多的机会，快出油比较接地气嘛，那其实我的问题也比较接地气，嗯刚刚的一个问题已经有其他人问过了，就是开源的一个问题，什么时候可以全面开源，这个是大家比较关注的。

大家都可以希望白嫖嘛，那第二个问题就是说我们在快手生成，快手视频生成这块的话，如何能够嗯首先的话是如何能够保住，因为现在的话算力啊，数据啊等等，这些都是呃都是已经有一些定向的一些内容了。

那现在大家比拼的，可能关注的更多的是一些安全的问题，那么如何保证我们在这个视频生成的过程中，前期的一些数据啊，呃这样的一些投入，或者说它的一个生成，它的产品设计等等。

这些方面来保证我们生成的这样的一些内容，是符合一些安全规范的，否则和法律允许的是在道德之内的，嗯然后对这个事请老师回答一下，然后如果其他老师觉得这个话题要有价值，也可以帮忙再探讨一下嗯，发散思维一下。

另外的话我想问一下呃，灵异万物的老师和百川的老师，因为呃大家的这这几个大模型，我其实我也一直在用嘛，就是希望能够比较一下哪家的产品嗯，回答的一个效果呀，或者说它的一个生成的内容，更符合用户的预预期。

嗯但是我发现灵异万物和百善智能，其实现在还没有开放多模态的一个内容，是什么的，也是什么样的一些原因，是你们的战略布局呢，还是说是你们的这边的呃资金有限呢，还是说技术不到位呢等等嗯。

你们的一个规划是怎么样的，来啊回忆一下啊，首先那个关于什么开源白嫖，然后感谢你的坦诚，对这个问题我刚才已经回答过了，呃，暂时不考虑，但是我们会会逐步开放出一些东西出去哈。

然后第二个问题讲是包括社区治理啊，这些问题，我觉得这事肯定是肯定是重要的问题啊，这些问题我们是去需要一个阶段，然后大家一起去想想办法，怎么去把这问题解决，因为AI发展确实很快啊。

带来一些新的一些挑战和新的一些问题，但是从长远来看，刚才我回答上一个提问人的来说，就是嗯比如说内内容的社区对吧，然后它它的生态，然后它的治理，它的规范，这些问题是不管在什么时代它都是存在的啊。

所以我们还是一会用呃新的思路，新的想法，然后去解决新的挑战，嗯好回去啊，对啊，我我不知道那个同学，您定义的这个多模态是指纹身图，纹身视频是吧，但其实白小印我们推的那个白小印。

因为我刚才其实还是想澄清一点，就多模太不只是纹身图，纹身视频，就我们说如果你上传一张图片，你问说哎这张图片是什么，你跟他去交流，那本质上其实也是多模态的输入，然后文本的输出。

这个白小樱现在就有这样的能力，所以这这是我澄清的一点对对，大家一定要在走出今天会场之前下载快手，下载白小印，还有什么要下载的吗，我现在一口气都说了，没有了啊，天天物呃，不天宫天宫。

然后是小程序小小程序啊，OK那大家先不用管他们，好下载快手下载百晓应下载天宫，而且据说现在一个下载要十几块钱推广费，所以我帮你们省点钱哈，然后呃还有没有什么问题哦，对诶我刚才也补充一下。

刚才那个是不是也Q到了哦，就是一个是我们的多模态模型，其实去年11月12月就已经开源了，当时是一个就是呃视觉和文字就是理解的模型，然后是开源的，然后有相应的API对，然后因为后来刚才谢建问就补充了。

就是因为你可能特指纹身图和纹身视频嘛，我我可以就是再就是复述一下我们之前的观点，其实就是说生成和理解统一来做，并不一定对智能的商界有帮助，所以我们就没有走这条路线，对最近我没有先finding。

所以我们应该是会走这个路线，然后今年会有一些更强的多模态模型推出吧，对我们觉得，多模态的核心作用是提升智能的上界，而不是在应用上拓宽一些，大家可用可玩性，明白好嘞，还有没有哪位啊。

呃就这边的这位高高举手的对先生，呃我想问一下那个万博士，然后就是呃现在呢就是英伟达的GPU呢，是全世界最领先的，然后作为快手的话，也算是呃第一阵营的，那么是不是在这个GPU方面能够发力。

为我们国家争一口气呢，这是一个问题，第二个呢就是快手和抖音，在国内的竞争是比较激烈的啊，然后呢，我想看到是否那个快手能够呃，逐渐呢能够超越抖音，好谢谢，就这两个问题哈哈哈。

我发现这个因为我专门问了一下志愿大会，我说这次观众报名分布大概50%，是学院派，50%是就是工程师，但后来我发现大家都是老百姓，我们还是喜闻乐见，快手来，你说第一第一个问题，这个确实还是有自知之明啊。

就是但是非常非常期待，然后我们自己国家能够，突破各种算力的一个限制，然后瓶颈啊啊第二个问题，快手超越抖音是吧啊我我我是有信心的啊，然后对吧，只要全是吧，全国十几亿人都有信心的话。

是不是就超过了哈哈哈哈哈，观影体验，我觉得快手还是一个很好的产品啊，可能很多有人还没有没有真正去使用过，然后可以试不妨试一试对吧，也许你会爱上你，能给在场的人做一点流量倾斜吗，这个这个我还真做不了。

我们是一个这个一个非常公平普惠，然后有有规则规范的一个平台来呃，还有吗，嗯哦那中间那位男生对，呃各位老师好，我想请问一个关于我们计算卡方面的问题，就是呃回望我们去年的话，在大模型技术不断爆发的时候。

大模型各个厂商之间的竞争，仿佛是卡数量之间的竞争，那么现在我们进入到大模型的后半场的阶段，的时候，嗯以及有越来越多的新的技术不断涌现，我们似乎是发现我们可以用更少的资源，达到更好的效果，但是呃。

当我们觉得卡的竞争，已经不再是我们需要考虑的问题的时候，我们又会发现像技术生成类的模型又在出来了，那么卡还肯定又是我们需要去考虑的问题，所以我想问四位老师，就是呃我们未来还是会把呃囤卡放在呃。

首要考虑还是说会去优化技术，用好我们现有的卡呢，谢谢，卡的问题来，2万张卡没有，你没有，我没有说我们有多少卡，我是我啊，Sorry，继续哦，对我觉得是这样，就是卡的数量是绝对算力，然后算法是相对算力。

就决算力这两个肯定都是越大越好，然后但就是比如说对作为创业公司来说，可能跟大厂很难比拼绝对算力，那可能就要发挥创业公司的优势，比如说人均卡肯定比大厂多对吧，大厂你看算法团队有多少人。

我们算法团队才多少人，那这样我们其实就可以发挥卡的优势，去研究一些能提升相对算力的算算法，所以这两个应该是稳步发展的，然后你模型做得好了，你的绝对算力也会提升，但随着你的商业化模式。

所以就是一个两者相辅相成的关系吧，所以我觉得就是在绝对的量上很难，短期之内有指数级突破的时候，我们先在相对算力上做指数级突破，然后再期待有一天，绝对算力也可以进行指数级的突破。

那一叠加就是会比别人多一个指数级了，好的还有问题吗，最后一个问题好，那位男生，哎好谢谢呃，就是我想请教一下，就是其实在去年的时候，就是嗯各个做大模型的厂商，其实好像还蛮统一的，或者说很多的业务方向。

是在弊端去做努力和探索，然后特别像今年之后，像近期，然后呃我们很多的公司，其实很多就往to c的方向出了很多的app，像请教一下各位老师，就是在这个方面是怎么考虑和思考，对谢谢，嗯嗯你是问的哪一位。

不好意思，我刚才被一个消息打断了，没关系没关系，我其实想问一下呃，呃各位的那个四位老师，可以多回答一下这个问题，对哪位想回答直接回答，我先开始吧，就大家可能轮轮轮来对，我觉得就是是去年。

可能我觉得大家也不是很统一吧，就其实我其实提到了，大家的技术发展路径都是有diversity的，然后比如说我们可能自己会比较坚持globalization，我们会做全球化的模型和全球化的应用。

当然中国也非常重要的一个市场对，然后比如说在中国，我们就没有特别就是想做to b，因为这个to b还是有一些就是传统问题，中国和美国不一样，但是globalize我们会同时做to b和to c。

在中国可能会做to c为主，所以大家可能没我觉得因为大家都是友商嘛，对别公司也比较了解，大家上来其实都有自己的一个主张，我觉得并没有像您刚才说的，就是大家一开始就只坚定做to b这个赛道。

大家差异化其实还是蛮明显的，而且现在大家都是沿着自己当时的，就是先主张继续再往下做的，然后差异化也是在做的越来越大，对然后我觉得大家都是，反正A加I路上大家都是朋友嘛，就是都是同行者，但只是在发展路上。

大家开始逐渐做一些分化，而这市场很大，应该可能to b的话，他的那个就是如果你是做大模型的，就to b的这个速度会更快一些，因为你有大模型出来可以做测试，可以做POC的话，它可能就很快的就能够就是出。

就是可以卖给那个第三方了，但是to c的话，你从一个产品的设计到最后的话，能够上线去去去获客，那么其实这个周期比较长，所以可能是可能是一种感觉吧，但其实我觉得，可能很多公司在开始做的时候的话。

他就已经想清楚了，自己到底是以to c的产品为主，还是以to b的产品为主了，对对我，这里也补充一下，因为百川其实在成立的时候，其实我们更大的view肯定是在C端了，然后我我自己的一个感觉和解读是。

去年可能没有那么多C或，但其实由于有很多C端的应用，但我觉得核心是去年模型的水平，本身也没有到一个很好的水平，就如果去年在前期的时候连3。5都做不到，那大家也都知道这这个时候的模型能力。

想要去支持一个好的C端的应用，就更不现实了嘛，那到今年其实大家都开始逐步接近到四的，那这个时候其实至少在助手很多的这个场景下，C端的应用是有一定的，能够真正用户的新的这种价值争议，这是我的感受啊。

好的呃，我不知道我们这个会场是否是最后一个结束的，会场，那个后面的同学能帮我看一下，隔壁会场结束了吗，OK太好了哈哈哈，这边只有一个会场哦，哦这样哦哦哦我错了，这儿只有一个会场是吗。

OK那我们我说怪不得我以为隔壁的走过路过，可以过来一起讨论，那没关系，对我平时不这么做哈，我是想给大家争点这个下载量，然后呃那我们今天呢我们在这个台上的讨论，我觉得就可以到此为止了。

因为可能我觉得嘉宾们可能还有一些晚餐哈，需要去交流，然后在座的感谢大家坚持到今天这个时间节点，然后我们可以欢迎大家呃来呃，结束之后，我们快速的建立一下联系方式，快速的跟各位嘉宾认识一下，然后欢迎大家。

就是想要跟这四位所在的企业，产生任何形式的合作，我代表他们答应你们呃，四位嘉宾亮出你们的二维码，那我们今天的这个圆桌论坛就到这里，然后呃，志源的院长和同事们好像也去接待别的嘉宾了。

我就代表主办方宣布今天的论坛呃，到此结束。

# 2024北京智源大会-大模型前沿探索 - P1：论坛背景与嘉宾介绍;李永翔 - 智源社区 - BV1yS411A73A

尊敬的各位嘉宾，社会各界的朋友，大家上午好，欢迎大家来参加志愿大会，大模型前沿探索论坛，本论坛的重点在于，特别看重大模型前沿技术的发展，我是中国电信人工智能研究院林永祥，很荣幸。

今天由我和智能智源研究院，我们知道，随着深度学习技术的迅速发展，以GBT系列为代表的大模型，取得了显著的成果，我们这个论坛的主题是大模型的前沿技术探索，旗帜鲜明来说，我们是用前沿技术去解决基础的问题。

有哪些基础问题呢，我们都知道，大模型的研发和应用仍然面临着诸多的挑战，如训练成本的高昂，能耗问题，对其的质量以及大模型和小模型的协同，训练和推理，机器学习理论的反思以及无约束感知。

从视觉的垂直领域到多模态的统一架构，现在人工智能的大火，很多程度上得益于技术的突破，随着技术突破慢慢进入深水区，那么接下来在学术界和工业界的方向，将会成为一个至关重要的问题，今天在本论坛。

我们也会对本问题展开探索和讨论，下面由我来介绍今天出席的论坛嘉宾，王叶璇博士，智源研究院研究员，青年科学家，国家新一代人工智能国家科技重大专项负责人，FLM团队负责人。

中国人工智能学会聚生智能专委会委员，他王岳泉博士是本次大会的歌，邹双永博士，是中国电信人工智能研究院，语一大模型团队负责人，高级算法总监，集团高级专家，先后在阿里巴巴和京东科技，担任算法负责人工作。

目前负责中国电信，星辰与一大模型和智能对话等算法研发，宋庄勇博士，敖翔博士，博士生导师，CCF高级会员，先后主持国家重点研发项目课题，一项国家自然科学基金项目，三项，是担任曾获得多项阿里巴巴腾讯奖项。

以及担任多项学术会议的程序委员，翱翔博士，黄磊博士，北京航空航天大学人工智能学院的副教授，研究方向主要集中在深度学习，训练技术以及理论分析方面，最后我来介绍赵建博士，是赵建博士。

是中国电信人工智能研究院，多摩体认知团队负责人，青年科学家，西北工业大学光电院研究员博导，博士毕业于新加坡国立大学，曾获吴文俊人工智能优秀青年奖，吴文俊人工智能科自然科学一等奖，赵建博士。

好下面开始我们的主题报告环节，第一个，首先由我来给，由王叶璇博士，给大家带来，全球首个单体万已稠密的大模型的报告，ti f l v e t b是全球首个低碳的开源多语言，万亿稠密大模型。

由智源研究院和中国电信，人工智能研究院共同研发，针对大模型超参敏感成本极高等关键问题，研发了损失预测生长技术等核心技术，实现了大模型训练零调整，并在892张A800集群环境中。

成功实现了万亿稠密模型的训练，是全球首个实现了低碳预训练的大模型。

# 2024北京智源大会-大模型前沿探索 - P2：全球首个稠密万亿模型揭秘：王业全 - 智源社区 - BV1yS411A73A

(音乐)，尊敬的各位领导 各位来宾，大家上午好，我是王毅权，下面由我来代表团队，给大家汇报一下，全球首个稠密万亿模型的一些基本情况，昨天在开幕式的时候，我们中远院长介绍了一下，我们模型的一个总体情况。

以及现在能达到的性能，然后我今天主要是来给大家揭秘一下，这背后存在的技术原理大概是什么样子的，当然今天时间有限，可能我并不能把所有的技术细节全都讲到，我会尽量让大家能够听明白。

我们是如何做成功这件事情的，然后具体的技术细节，大家可以参考我们的技术报告，包括接下来我们会开源更多的一些技术细节，然后这一个稠密万亿模型，是我们试验研究院，和中国电信人工智能研究院一起联合研发的。

然后过去的这一个，大概有四个多月的时间里，然后双方的团队一起经过了非常艰辛的合作，然后经常会有这种撤业的连条等等，然后非常辛苦，但是幸运的是我们做到了这件事情，终于做成了全球首个稠密万亿模型。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_1.png)

下面我从动机和意义关键问题，核心技术评测基础模型，评测对话模型，总结和展望总共六个部分，来给大家进行一下简单的概述。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_3.png)

首先第一点，动机和意义，我们先来回顾一下，目前的大模型的发展脉络，我们都知道OpenAI是目前这一波，生存式大模型的一个核心驱动者所在，然后我们首先要强调一个观点，GPT它的能力的最大来源是在哪里。

我们仍然认为GPT能力的主要来源，是它强大的语言大模型，后面的SFT，强化学习等等阶段，更多的是在做一件什么事情呢，和人类做一些相对齐的工作，并不是说把更多的知识给灌输进去。

然后它能力的最大来源还是语言大模型，然后相信大家已经在过去，知道了解比较多的大模型训练相关的信息了，那么大模型训练最重要的三个点，第一个是大数据，第二个是大算力，第三个是强算法。

有了这三个非常非常重要的支撑以后，就有可能能够训练成功一个优秀的大模型，那么首先是大数据，我想强调的是现在的大数据，和以前大家所关注的大数据，可能已经有了一个很本质的区别，在以前的情况下。

比如说这种千万量级，几亿的量级，然后大家就可以认为是一个大的数据量，但是对于现在的大模型来说，可能事情不是这样的，对现在的大模型来说，大家可能要穷尽整个人类互联网上的余量，然后把它当成一个大数据。

由于这个数据量比以前的大数据，是大了非常多的，所以说会带来更多的技术挑战，然后第二个大算力，在以前的情况下，大家常用的大算力，就是各种超算集群，然后在现在的这种大算力的情况下。

以前的超算集群是不能够满足需求的，所以说现在大家的这种大数据，往往是采用这种，非常多的英伟达的显卡的并行计算，来达到的，比如说我们知道最典型的一个例子，GPD3，它在2020年的时候。

就实现了上万张卡的互联，然后训练出了1750亿的GPD3，然后第三点强算法，强算法现在有些情况下，大家可能很重要，但有些情况下，大家觉得这件事情不是特别重要，我想给大家分享一个例子，然后以此来表达算法。

其实仍然是很重要的一个点，就是说在LAMA出现之前，然后大家沿着GPD这条路线走，然后可能是属于走得比较缓慢，LAMA出来了以后，然后大家沿着LAMA的路线走，然后就进展比较快，然后大家仔细分析。

你会发现LAMA和GPD，它的区别在哪里，可能并不是一些很大的区别，甚至来说是在以前深度学习时代，大家认为是一些，脆壳的情况下的一些变化，就能够使得模型的能力发生，巨大的提升。

这点是属于我认为是我们这些，做算法的研究人员，还是说业界的一些工程师朋友们，需要非常注意的一个点，然后最后有了这三项，基本能力的一个好的合作以后，我们就可以训练得到一个大模型。

然后这是一个基础的语言大模型，在一个语言大模型的基础上，可以通过一些相应的微调和对齐的手段，就可以得到目前非常常见的对话模型，比如说SideGPD 3。5，SideGPD 4 GPD 4等等。

它们就是在这些，千亿级 万亿级的，语言大模型的基础上，去训练得到的一个模型，好 刚才讲了这一个语言大模型，我们来回顾一下语言大模型的本质，语言大模型的本质是什么呢，就是用前K一个单词。

预测第1K+1个单词，这一个本质是属于直到今天，仍然一直大家在遵循的一个对象，它就是这么简单，然后给一个例子，the cat sat on the mat，然后它的预测方法就是非常简单。

相信在座的所有人都能听得非常明白，自左向右挨个的预测下一个单词，基本流程，给定the预测下一个单词cat，给定the cat预测下一个单词set，给定the cat set预测on，以此类推。

就是这么的简单，但是这一个简单的语言模型的本质的背后，是存在着非常非常多的这种原理在里面的，比如说当这个context，前面的内容足够长的情况下，那是不是对未来预测得很精准，就能够有非常强大的智能。

在包含在里面呢，这是属于目前非常重要的一个，大家对语言里的认知，然后对于在座的朋友，可能有一些来自产业的朋友，然后大家可能会经常疑虑一个问题，什么叫做模型参数规模，比如说大家经常听到一个词。

我有一个模型是70亿，100亿 1000亿 10000亿等等，然后这个模型参数是什么意思，这个地方我给出了一个非常，简单的通俗解释，比如说我们有一个非常简单的模型。

y=a1x1+a2x2+a3x3+a4x4，一直加到b，然后这里a1到a4以及b这5个量，就是这模型参数，对待这一个模型来说，它的参数量就是5，然后我们可以有很多的历史数据，对这一个模型进行拟合。

就可以得到参数a1到a4和b的估计值，然后那么这种情况下，这个拟合过程本质上来说，就是代表了训练过程，当然实际的大模型的训练过程中，它可能是非常非常难的一个系统性工程，我这里只是用了一种简单的方法。

来给大家概述一下，这个模型参数规模大概是一个什么的意思，然后最后说到大模型，我们一定离不开的一家是OpenAI，那么这种情况下我们去看一看，OpenAI它的技术路线，演进路线是什么样子的。

最重要的几个里程碑，2019年2月份，OpenAI做了GPT-2，然后2020年5月份它做了GPT-3，GPT-3的参数是1750亿，比GPT-2的参数大了足足有1000倍。

然后接下来2022年的12月，它发布了Site-GPT，然后这就是属于大家所熟知的一个，它的技术路线，以及2023年，OpenAI又发布了GPT-4，GPT-4的模型参数，距网传是1。8万亿。

以及现在他们正在训练的GPT-5，GPT-5的距网传，它的模型规模大概是在，百亿，百万亿的一个量级，100T的一个量级是非常巨大的，那么OpenAI的技术路线，说明了一个什么问题呢。

首先大家肯定能想到的一个点，就是属于Scaling Law，Scaling Law大家都知道，对于目前OpenAI的技术路线来说，他们是认为随着模型参数的越变越大，以及相应的数据量的提高。

模型的性能会有一个继续持续的变化，这就是属于语言大模型，最重要的一个Scaling Law，然后OpenAI直到今天，仍然没有找到Scaling Law的边界所在，好 这就是属于我们训练万亿大模型的。

一个非常重要的动机所在，Scaling Law已经多次被实验证明，增加这种模型规模是带来稳定的收益的，然后以及以落实作为指标，这种模型的能力的提升，其实本质上来说是可以预估的，我们想问一个问题。

比如说在下游任务上，模型规模会带来能力的提升，它的上限在哪里呢 等等，这都是属于我们需要做出来一个万亿级的模型以后，才能够回答的一个问题，我们都知道目前其实业界对这个问题，已经有了一个共识。

就是现在的模型规模可能还是不够的，比如说国内外的一些主流模型，比如千维1。5，它现在已经有1000亿的量级，欧洲的Mixor 1400亿，DeepSake 2000亿，Glock 3000亿。

Lama 3，现在他们正在训练一个4000亿的模型，说明大家仍然在朝着这条路线前进，另外对于万亿模型，一个非常关键的问题就是，西数模型和酬亿模型之间的对比，网传的GPC的模型规模是1。8万亿。

它大概是由单体的3000亿的模型，用了8个，做成了一个1。8万亿的MOE，那么为什么OpenAI要采用MOE，而不采用西数模型呢，这个地方我觉得是值得我们每一个深思的一个问题。

我们把时间倒钟拨回到2022年的时候，2022年的20，不好意思 是在2021年的时候，然后当时智原发布了乌刀2。0，它是一个1。75万亿的MOE模型，然后 但是接下来的模型都变成了酬亿模型。

为什么会有这种转变，以及直到现在为止，很多情况下又把酬亿模型给拿了回来，其实本质上来说是有这么一个方面的问题，从工业的角度来看，MOE它会有一些好处，比如说它的这种训练和推理的效率，来说是比较好的。

但是在另外一些方面，MOE是有劣势的，比如说在相同的模型参数的条件下，然后这个模型的性能，然后下游任务小样本的微调表现等等，均是证明酬亿模型要显著地比MOE模型强的，那么这种情况下。

一个酬亿模型的这种能力上界的探索，可能是更加重要的，此外呢 从科学研究和行业发展的角度来说，这个研究酬亿模型是非常有必要的，比如说对于AFO膳食，这种对时效性可能要求不是特别多的一些场合。

那么我们做一个能力更强的酬亿模型，其实本质上来说，对这些科学的发展来说是非常好的一件事情，因此 为了探索大模型的上限，促进社区的发展，资源研究院和中国电信人工智能研究院。

我们一起合作研发了TeleFM-ET，然后该模型是全球首个低碳的，多语言单体万亿稠密语言大模型。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_5.png)

下面我来介绍一下，这个模型训练过程的一些关键问题。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_7.png)

首先第一个是属于高效，刚才提到了GPC它的模型参数是1。8万亿，那么OpenAI肯定也知道，稠密模型的能力要比MOE的能力强，为什么OpenAI没有选择做一个稠密模型，而是选择做了一个MOE模型呢。

本质上来说就是因为算力，据估算 如果即使有一个非常大的千卡，甚至来说万卡的一个机群，训练一个稠密的万亿模型，可能需要的时间是非常长的，大概是长达三年到十年，才可能训练出来一个模型。

如果其中存在的一些设置的错误，数据的错误，导致你的模型训练是出现了一定问题的，那么这个时间会继续翻番，可能是长达一个无法忍受的程度，这就是属于为什么现在目前的万亿模型。

全都是MOE架构的一个根本性的原因，所以说对于我们来说，我们的目标是给定数据量和目标模型大小，目标的模型大小已经确定了，就是一个万亿稠密的模型，那么我们如何在有限的机制内，完成这个模型训练呢。

这是一个非常关键的问题，此外呢 这个问题已经有了一个前提条件，我们都知道的一个事实是，模型的能力会随着数据量的变大而变好，那就说明了我们是希望数据量是尽可能的多的，第二个关键的问题是。

大模型的训练对超三是非常敏感的，这个相信是行业内的朋友都有所了解，为什么这么说呢，比如说这个大模型训练的时候，大家的技术报告中往往会把它所采用的，LR等等关键的一些超三给公开，比如说1。5亿-3 1。

5亿-4，3亿-3 3亿-4 3亿-5等等，那么这种情况下为什么会采用这一个设置呢，是不是有些设置它做了一些试错，只是说没有告诉大家呢，这就反映了一个问题，一些不太友好的设置。

可能会产生一个非常高的试错成本，最终导致模型的性能不可预期，那么对于我们来说一个关键问题是，能不能形成一种成熟的方法论，可以控制风险，在模型的训练过程中尽可能地，不再调整 不再重视。

做到一个零调整和零重视的目标呢，是的 这就是第二个关键问题，第三个关键问题就是，对社区的一个贡献了，我们一直以来是坚持一个开源的路线，希望我们所探索出来的各种技术，核心技术 包括模型参数等等。

能够对社区产生一种有益的进步，所以说我们的核心技术，包括模型参数等等 全部开源，下面介绍一下核心技术，首先跟大家汇报一下，我们对大模型的一个认知，现在的大模型和以前的大模型，可能会有比较大的gap。

以前的deep learning的时代，可能一个模型更多的是一个算法，但是目前的大模型，我们认为其更多是一个系统，是一个系统 这就代表什么呢，这不是一个非常简单的算法工程，它是从质底上上。

是有一系列的这种系统工程的一些实现的，包括最底层的音法，然后以及数据 然后框架，然后效率等等各个方面，这个地方跟大家简单分享一下，首先对于数据这一个角度，我们整体来说，严核研发团队的一个感受就是。

对于数据来说 质量是非常重要的，给大家一句可以take away的一句话，无论你如何重视数据质量都不为过，你越重视它，它越会在你的模型性能中，加倍地回报你，然后数据获取 数据清洗，数据取询 数据打分。

这都是属于老生常谈的一些问题，可能大家觉得非常简单，但是这个地方我要给大家说，虽然说看起来简单，但它其实是非常重要的一个点，而且做不好的情况下，会让你的投资变得可能是，不是特别的好 不是特别的高。

数据获取相对来说，只要是属于有足够的数据源，就能做得比较好，数据清洗这个地方我只有一个问题，如何定义高质量数据集，比如说广告，比如说黄读读的信息是真的差吗，好 这是属于我给大家抛出的疑问。

如果要是要大家感兴趣，一会可以展开探讨，然后第三点 数据去存，数据去存我常举的一个例子是这样的，比如说一个1000万级的数据去存，找一个研究生 博士生就可以解决，一个亿级 十亿级。

可能找一个阿里的PC就能解决，然后等到百亿级 可能P8就能解决，但是把全网的数据拿过来呢，阿里的P级可能都解决不了了，以及目前的技术可能确实都不能够，很好的解决这个问题。

这都是属于大模型是一个系统性工程的，一个很重要的表现，然后第二个维度是框架的优化，框架的优化如果你不是做一些底层的，Fab System的我建议大家就直接。

采用BF16 Flash Attention Backdrop等等，直接采用即可，然后效率提升Muse Gating和生长技术等等，这是接下来我们要讲的一个重点。

然后在实际上我们最终就得到了FM系列的模型，FM系列的模型距离至今已经发展了有三代，然后首先是两年前的预言代，预言代的时候我们就发现了一个典型的问题啊，目前的语言模型其实是存在着一个很大的弊端的。

我给大家举一个例子，奥巴马的妻子是张女士，这句话从语言模型的角度来说，它是完全对的，一个男士的妻子是一位女士，它是完全对的，但是从事实的角度来说，我们都知道这句话是不对的。

奥巴马的老婆 奥巴马的妻子是米歇尔，那么这种情况下对于语言模型来说，这就造成了它的一个本质的幻觉的原因所在，我们的方法是在语言模型的训练过程中，就引入了这种国安的信号，希望把这种男妇力给它区别出来。

然后就可以让我们的语言模型生成的质量更高，这是第一代，第二代我们发现了另外一个核心问题，就是对于大模型来说，它的成本实在太高了，然后我们就搞定了生长技术，来训练迁语模型，在去年9月份的时候。

我们是使用了70万人民币的成本，就做到了一个迁语级的语言模型，可以达到GPT-3的水平，然后有了这两项技术以后，然后就共同地构成了我们目前的这个，TelFM-ET，就是和中国电信人工智能研究院。

一起做的全球首个万亿大模型的一个基石，它首先是有一个损失预设技术，可以保证训练零调整零重视的，然后我们全面多维度的能力测评，显示它的语言能力是接近GPT-4的，此外核心技术是全面开源的。

右下角的Loss曲线，上面的那一个是我们模型的一个Loss曲线，右下角的那一个模型是DeepSeq的一个曲线，从这一个Loss曲线收敛值来看，我们最后的值是1。58，DeepSeq的值大概是在1。78。

我们比它低0。2个点，这在一个52对比67B的一个模型的角度来说，是一个非常难的一个进步，好 刚才讲到了生长式域训练，然后这个地方就是要给大家汇报一下，我们这个生长式域训练到底是怎么做的。

然后这个地方我只给大家介绍一个核心观点，然后具体的技术细节，大家可以去看我们的技术报告，以及我们这个技术已经开源，大家可以实际上去看代码都可以，然后首先介绍一下什么是生长技术，目前的大模型训练。

大家都是在训练的时候，你的模型参数固定是多少，到最后它的模型目标就是多少，比如说你训练一个千亿级的模兵，千亿级的语言模型，你的目标是千亿级，那么从模型的开始训练，到最后的阶段。

它的模型规模不变是千亿级的，然后我们的生长技术，它背后的含义是这样的，虽然说我们的目标，还是要训练一个千亿级的语言模型，但是我们在训练到刚开始的阶段，我们训练的一个模型的规模是一个十亿。

然后接下来训练到一百亿，然后接下来训练到五百亿，最后训练到一个千亿，然后这种方法来进行的，那么一个核心问题，就是我打在右边的一句话，生长对模型能力是有增益的，还是有损害的，这是一个核心问题。

然后另外一个核心问题是说，到底能减少多少成本，然后其中的这个左下角的图，B C D则是一个节省成本的预估，对于B来说，它节省的算力成本大概是50%，C来说它节省的是少于50%的，D是节省大于50%的。

那么对于D这种非常极端的一种情况来说，只要是D这种搞定了，那么B和C肯定是行的，所以说我们最后采用的策略是D这种策略，然后第二个点，生长对模型能力是有增益还是有损害的，然后这个地方的话。

本来我们的预期是，既然可以节省了算力，那是不是会有所损害的呢，后来答案恰恰相反，它不仅没有损害，甚至来说还会有些比较微弱的提升，为什么这么说呢，我们探索其本质发现原因是这样的，训练一个迁移模型。

它刚开始的这一个模型的一个优化空间，是一个迁移远模型的空间，但是对于我们来说，我们早期训练的是一个实异的模型，然后它的这个优化空间是比较小的，那么这种情况它的优化效率就会比较高。

然后由于我们在生长的过程中，采用了一系列的技术手段，达到了保值等等关键的这些设置，然后我们就可以达到最后的这个模型能力，会比较好，不仅没有损害 而且是比较好的，然后对于生长来说，有四个常见的扩展维度。

包含影程的宽度 注意力头的个数，模型的层数，还有MOP中间层的维度等等，然后在我们的实际的这个，万语级语言模型的训练过程中，我们成功实现了这些所有维度的通识生长，都是没有问题的，然后生长算法的核心要素。

是生长算子和生长流程，然后这个地方我就不再跟大家具体汇报了，大家感兴趣的话可以关注我们的技术报告，然后最后给大家汇报一下，我们这一个万语级语言模型，它的生长策略，我们到最后依据我们前置的研究。

FL101B的成果，Tile FL最后的生长路线是，首先是有一个500亿级的大模型，是第一阶段训练了2。0T的，Token的数据量，然后在这一个500亿级的，模型的基础上，我们生长到了一个千亿级的规模。

然后第二阶段用了0。3T的，数据量进行训练，最后在千亿级的这个模型的基础上，我们成功地生长到了万语级的大模型，训练了大概是0。015T的数据量，达到了我们万语模型的训练目标，好 然后刚才提到了训练框架。

是一件非常重要的事情，然后呢 所以说为了保证训练的成功，我们也在训练框架的方面，做了一些优化，比如说3D并行，然后序列并行，比如说TechPoint灵活存储，比如说这些自动评估等等，以及很重要的一点。

在我们的这一个，把我们的生长技术等等，相关的技术集成到了，Microsoft框架里面去，综合上述的技术，联合研发团队最后采用了，112台A800的GPU，在4个月内完成了，百亿千亿万亿模型的训练。

第二个关键问题，也是属于目前大家，可能不再常说的一个问题，就是属于数据配比，和数据的一些认知，目前只有LAMA1还是有的，LAMA2 LAMA3等等，均不再提数据配比这一个地方，然后我们这个地方是把。

所有的数据配比相关的信息，都给放在了技术报告当中，然后供大家来参考使用，有三个很重要的一个观察，供大家参考，第一个是属于，对数据来源进行过去清洗，最大程度上来说，避免脏数据和低质数据，然后这个地方。

就是刚才我提到的一个核心问题，我们必须知道什么是高质量数据，好，然后第二个呢，我们是在训练的过程中，采用了恒定的数据分布，避免中途调整会产生一些不稳定，最后的话，我们在这个采样的预训训练数据中。

重新训练了Tokenizer，具有领先的压缩比，提高了训练的效率，然后右下角有个很关键的结论，质比量更重要，即使是我们的目标是训练一个。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_9.png)

优秀的中稳的大模型，然后下面汇报一下这一个超参搜索，刚才提到了目前业界的常见做法，是属于训练一个模型，它可能会试很多超参，那么这种情况下带来的一个不利之处，就是如果超参选择的不好，模型的性能就会不好。

然后我们做到了小模型超参搜索这件事情，它就可以达到的一个目标是，在模型训练开始之前，用一个非常小的模型参数，去大量的搜索，然后搜索到的最优超参，是可以直接应用在最后的，大规模的模型训练上。

而且来说它是可以保证，你的模型是收敛的。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_11.png)

这些都是毫无问题的，然后有了这一个理论以后，我们就做到了，使用小模型在这种，进行了超参搜索，然后就可以做到我们刚才提到的一个关键问题，就是我们在这个万亿模型的实验中，0调整 0试错。

然后此外的话52B的良好性能，可以保证后续的千亿级，万亿级模型参数，继承了正确的知识，会有一个比较优秀的起始点。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_13.png)

然后介绍一下评测的情况。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_15.png)

首先是基础模型的评测，基础模型的评测最直观的一个指标，就是落实的评测，然后我们在落实当中，进行了两个主要的评测，一个是中文的评测，一个是英文的评测，然后中文的评测显示。

TeleFM它是属于目前最优的一个中文模型，它优于千位1。5 72B，且优于拉玛3 70B，然后英文的BPP评测显示，TeleFM 52B的英文能力，是接近拉玛3 70B的。

然后但是我们要注意到它的数据量，一个是2T 一个是15T，参数量的话是52B对比70B，然后且它能超过，包括拉玛2 70B在内的其他所有的模型，所以说总体来说，这个基础模型的训练是非常好的。

然后第二个评测的维度是对话的维度，对话的维度我们主要进行了中文的评测，包含两个评测，第一个是外部评测，AliveBench，第二个是内部评测，TeleEvo，在AliveBench的评测当中。

显示出来我们这一个模型的语言能力，是特别强的，基本上来说可以达到了，GPT-4中文语言能力的96%，总体的能力也已经达到了，GPT-4能力的80%，但是这个地方有一个值得注意的点。

目前我们这一个模型还是语言模型，GPT-4模型是一个多姆态模型，所以说多姆态方面的能力不可比，GPT-4还是非常强大的，然后内部的评测是这样的，显示中文对话能力达到了，GPT-4的93%。

然后这和外部的这一个评测，基本上来说，它们俩的相符度是比较高的，好 最后在结束我的报告之前，给大家汇报一下我们的一个实验经验，总结和展望，第一个是数据方面，质量和数量是并重的，且很重要的一点是质量优先。

比如说虽然说我们是想训练一个，优秀的中文模型，但是我们最后英文比中文的配比是2比1，中文只占了大概是30%的数据，但是实践证明，在我们保证了质的情况下，我们的模型效果是非常好的，然后第二个 超参优秀。

基于这种我们刚才提到的，Mewpool的这种网格的超参搜索，是非常有效的，它可以节省大家的大量的成本，避免你一次性投入，几千万的这种算力规模，带来的这种算力损失，最后一个训练的效率和稳定性。

一个很重要的关键点是在于落实，然后大家以前的很多经验都证明，落实发生了坚持这种情况，大家会认为它不够健康，但是我们的实践证明，即使偶发的这种落实的坚持，其实是正常的，而且大概率模型是能够自我修复的。

当然这个地方要持续观察轨道纳姆，轨道纳姆和落实曲线的关系是比较复杂的，有很多种正常的健康的对应关系，最后一种情况可能是比较不好的，就是持续上升的轨道纳姆，可能会导致你的训练的落实曲线。

发生一些发散等不利的情况，好 最后给大家说一下开源情况，我们目前所有的核心技术均已经开源，然后右边二维码是一个，它的技术研讨和效果的反馈群，大家感兴趣的话都可以加入，然后在里面探索一些大模型相关的知识。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/4503ee7dbc6093ce81b293b462c9d748_17.png)

大家一起分享，好 我的汇报就到这里结束，感谢大家，现场的同学看看有没有什么问题，这位同学，你好，您在报告中刚刚多次提到了，大模型的训练是一个系统工程，我想请教一下您，就是您觉得这种系统工程的特性。

具体体现在哪些方面，因为系统工程的话它单独是一门，也是一门学科，然后我也觉得它是一门系统工程，但是我对这个它里面的这种关联，以及它体现的这种特性，还是存在一些疑惑，然后这是我的第一个问题。

然后第二个问题呢，我刚看到就是电信大模型，在中文推理上面，就是相比于其他任务，性能要稍低一些，想问问您就是后续电信大模型，在比如说推理，包括符号推理 数学推理等等，它方面有没有什么下一步的。

接下来的进一步的这种措施，以及现在正在研究的这种技术路线，好的 谢谢，非常好的两个问题，首先是第一个问题，是属于那个系统工程的问题，然后这一个问题，我给大家先说一个例子，比如说以前我在带学生的时候。

然后让他写一个深度学习的算法，然后可能啊，好的学生或者说对于，优化做得比较好的学生，他做一次实验的时间是三个小时，我算了下我的成本，大概是花了我五千块钱，然后呢 另外一个学生，他可能动手特别快。

但是呢他不注重效率问题，他认为只要是正确性保证得好就行，他的成本是多少呢，他用了三十个小时跑一个模型，那么这种情况他的这个成本是五万块钱，对我来说五千和五万，这个区别我是可以接受的一件事情。

但是换到大模型这里的话，可能这件事情就会让我变得不可接受，以前我的成本，比如说还是说这个十倍的一个优化效率，以前我的成本可能是五百万，那么现在来说我的成本变成了五千万，那是绝对不可接受的一个问题。

这就是属于为什么要把这件事情做好的一个本质所在，所以说目前只要是训练过大模型的人，以及这个机器比较多的一些实践，大家会非常关注一个指标叫MFU，MFU就是决定你到最后。

你的这个投入成本大概有多好的一个关键指标，然后MFU本质上来说可以当做，你的一个算力优化的目标，那么在这个过程中，可能制约它的因素有哪些，从你的存储到你的网络，到你的模型结构，甚至来说你的带宽。

你的不同的数据量走什么样的地方等等，都会是有一个系统性的问题，然后对于你来说，可能要把这些问题，都有一个非常清晰的认识，然后在此基础上，把每个问题都做到尽可能的好，有可能这是属于非常重要的一个点。

对于你来说，既可以让你的模型效率高，甚至来说你的投资成本也会变得好很多，这是第一个角度的问题，然后如果是说我们需要讨论一下，具体的怎么做可能时间比较长，我在这里就不再展开了，然后第二个问题。

您刚才提到一个非常好的点，目前的模型评测显示，它的语言模型能力很强，但是推理方面看起来还不是特别好，然后这个地方有两个角度，第一个角度，我们目前是和GPD 4比的，GPD 4是一个1。8万亿的模型。

单体模型3000亿，我们刚才给的一个模型的结论，是52B的一个结果，然后这样的话，我们的规模是远小于它的，然后我们还有一个结果，是和GPD 3。5的结果对比，其实我们和它是差不多的，这是第一个角度。

然后第二个角度是这样的，目前我们这一个对齐，还是有大量的工作要做的，比如说思维链，大家都知道这是一种常见的方式对吧，然后除了思维链以后，思维链以外还有没有其他角度问题，比如说昨天一些嘉宾提到了。

慢系统和快系统，思考快和思考慢等等，这些都是属于接下来我们要研究，而且可能会带来很大的用处的一些点，而且这些研究目前是做得比较少的，所以说我觉得这是一个非常重要的方向，可能能够解答你的疑问。

把这个问题整体来说解决到一个非常好的程度，好 谢谢，鉴于时间，我们感谢王逸泉博士的精彩分享。

# 2024北京智源大会-大模型前沿探索 - P3：大模型精细化微调和对齐方案：宋双永 - 智源社区 - BV1yS411A73A

啊那感谢啊永祥总和叶全博士的组织，感谢永翔总的介绍，那我我是中国电信人工智能研究院的宋双勇，那我今天给大家带来的是关于大模型，精细化微调和对齐方案的一个一些介绍啊，也是接着刚才叶璇博士。

关于很多的这种基础模型训练的介绍的，一个这样啊，有一个顺承的关系，那今天分三个维度哈，第一个是在大模型精细化微调，然后第二个方向是在偏好对齐，以及说呃，中国电信在大木星场景化能力建设方面的一些。

工作进展的介绍，那首先呃，当然刚才叶璇博士在这个基础模型训练，也提到了数据的这个数量和质量的关系哈，但这里边我这呢主要介绍的是在SFT，也是在微调阶段这种啊，大家在数据思路上的一个转变。

那可能在22年年底，那差点BD出来之后，那大家在这个处于一个尽快追赶的阶段，那不管是在基础模型，还是在这个SID数据个阶段，可能首先是要收集了大量的这种训练的数据，那么在SFT这个也就相当于是问答数据。

这样的一个呃收集的初期，那包括中国电信在内，可能到了23年的34月份的时候，我们手里就已经超过了千万条，这样的问答的训练数据，那这个时候可能说，我们觉得这个模型本身是一个通用模型，那是不是学到的。

不管从基础还是到问答，我学到的知识越多越自然，那么它这个通用的能力都越强，其实大家带着这样的一个思维，然后去做训练，然后呢在这个呃出来结果以后的，实际上呃感觉看上了效果还不错哈。

但是呢这个一直朝这个方向说，我们还是在想，甚至说很多呃，通过了解那其他的这种单配件厂商也是在想，那是不是数据还不足，通过增强呃，增加数据的数量，是不是效果还能进一步提升，然后呢后来在去年应该是5月份吧。

这个出来这样的一个工作，就是立马立马号称是说，我只用了这个1000条的高质量的数据集，就把这个SFT，就这个chat模型训练到一个非常好的一个效果，那个其实这时候的话就会就引起了一个反思哈。

这这个数量和质量的这个维度上，是怎么样达到更好的一个balance，然后来去把这个模型的这个能力，去更好的去诱导出来，那其实包括后面的lama two，其实也是这样哈，可能用的数据也也不多。

然后其呃生成的效果也很好，所以这个时候我们对比呃，就是在这些工作之前和之后的这个，在数据上的一些思路的转变，那可能在之前这个数据取胜的阶段，基本就是百万条起步可能都算比较少哈，刚才我也接到中国电信。

可能我们训练第一版，在这个23年34月份的时候，是用了超过千万条的SFD数据，那再后来的话其实质量为王，质量为王，这个阶段我会发现很多的工作，其实呃公开出来之后，说自己的SFT数据可能不到10万条。

但是效果呢也很好，然后对应的有这样一篇文章哈，叫这个qualities，all you need呃，这个大家有时间也可以读一下，其实在这样的一个呃背景下，那其实大量大量的工作。

现在开始投入到数据质量的提升上啊，SFD训练数据质量的提升，那在这个阶段的话，就会有产生很多对应的一些工作，那包括我们其实也是在做，那精细的话分析在这两个方面哈，一个是数量。

一个质量它到底有什么一些区别，那首先说最开始这个数量的阶段，数呃追求数量的阶段可能是数据虽然很多，但是但是它呃，可能大家并没有太关注它的一个全面性，就是我们手里有哪些数据。

然后就把这些数据都啊收集起来都训进去，我们觉得这样反正是越模型学的越多越好，对不对，但具体这个里面是不是有一些缺失，比如说哈当然这个不是事实啊，就是我手里即使有几千万条数据。

但是里面发现几乎没有这个数学相关的，那这个模型可能训出来他的数学能力呃，相当于它是一个不全面的，然后但这个质量为王的阶段，不是说我追刻意的追求数量的少，而是说要保证质量的前提下，然后再去做训练。

然后这个时候导致说在目前的情况下，高质量的数据的量相对较少，少只是一个呃表象，但这个时候少不是单纯的少哈，而是要少，而全面，就是尽量要覆盖全面，这是一个它的非常重要的一个要求。

那第二个阶段就是在最开始这个呃，这个粗暴收集数据的阶段，可能就是偏free style这个每一种类别的问题，它的格式是非常的五花八门，甚至同样的一个问题的答案的话也非常的形式，也非常的发散。

那这个不能说每个答案是错的，只是说这样对模型学习来讲，它是一个比较有害的对吧，就好像一个小孩，那有好几个老师教同样一个问题，给的答案是不一样的，那这个其实对小孩的学习并不是一个好的事情。

那所以其实在这个后面这个追求质量的阶段，我们就要求这个答案格式，答案格式尽量的规范，尤其是同类问题的这个格式尽量的去统一，这样让模型学习的拟合的会更好，然后在这个数量维度其实还涉及到一个点。

那就是说呃包括最开始这个22年年底，23年初的时候，大家可能为了尽快的追赶，那在基础模型阶段可能训练的数据不太够啊，可能这个大家也可以在翻阅这个一年前的一些，公开的一些公这个工作报告。

可能大家训一个T的，两个T的，可能三个T的这个基础数据就算比较多的，对不对，然后大家会有一些错误的认知，就是说我在基础模型训练不足的情况，我会通过SFT训练更多的数据，把这个能力补齐。

但其实现在证明这种情况，可能会导致说就是基础模型，如果某一块数据不足，那SFT去硬加训练的话，可能会导致明显的幻觉的问题，所以这个时候，其实在我们注重SFD数据质量的同时，反而也能反推。

我们对基础模型的数据是不是训练不足，我们要要求在基础的全面性和SFD的全面性，它是有一个这种互相配合的关系，所以从这这几个方面综合来看，我们在这个质量维度，其实还是有很多的工作要做啊。

呃然后下一个叫介绍的就是那根据刚才的思路，首先我们要对手里大量的数据，是要进行一个数据的筛选对吧，那这个筛选的过程，其实现在已经呃很多，这个研究者提出了非常多的方法哈。

这里边这块的就简单介绍几个也时间问题呃，这个方法可以简单分成两类，一个叫NTARGET，一个叫target，这个区别呢，就是说可能左边这类的方法更具有通用性，它可以针对各各类的数据。

做全面通用的一些筛选，那右边的这类方法呢可能稍微的更有一些呃，指向性，针对一些重点的呃，具体的任务，它的效果会更好一些，那比如左边这个叫IFD这样的一个方法，它实际上这个思路比较简单哈。

我比较直观的介绍，他就是说同样的一条数据，那我给它加了一些提示的情况下，然后它生成答案的这个得分，和我直接去问这个问题得到的得分，它这个差值越大，证明说这个数据是更加合理。

因为我们直观的认为它加了提示之后，它的效果就应该会更好，如果说我加不加提示，然后他的分数是一样的，或者说我加了提示分数反而降低，那么这个问题本身它可能质量就是有问题的啊，通过这样一种方式来筛选。

哪些问题的本身的质量更好，当然呢这个有一些呃，这个容易失，这个判断失误的点就在于说，如果两这两种情况得分都很高，或者都很低的时候，实际上这个判断会有很大的一些啊失误。

所以我我其实我们目前的工作也在有一些思想，基于这个IFD的基础上进行了很多的改进，尤其是针对这种容易失误的情况，然后下面像这种还有叫一个super呃，floating这种这个方法。

它实际上是以IFD为基础，但是他觉得这个FD的效率比较低哈，因为我我要训一个，比如这个几百亿或者千亿参数的模型的时候，用这种方式来过滤数据，它的效率太低了，所以他希望在一些小参数的模型上。

然后这个过滤数据，然后在大模型上进行训练，那这个时候会导致这个误差更多一些，因为毕竟是不同参数的模型嘛，它选择质量的这种结果是不一样的，然后后面这个就呃，时间问题就不不挨个介绍了哈。

然后右边这个就是这种，针对具体任务的一些过滤算法，那像这个NGAS的话，是，就是首先它是判断这个候选样本，对测试及每条数据的一个训练增益呃，这个直白怎么说呢，比如说我选了20条测试样本，然后呢。

我针对一条这个准备要判断的候选样本呃，如果加入这条样本的训练，能够让这20条数据的训练增益，就是这个loss值哈，其中有15条这个增益就变大，那实际上它这个叫增益占比呢，就是十五五除以20，就是0。

75，相当于我给他打一个0。75的分，最后按这个分数来排序，来找这种质量更高的这种候选样本呃，然后这个还有一个方法叫这个less less，其实是呃也是同样固定这样的一个测试集。

但是它直接考察的是候选样本对定义模型，这个梯度优化方向，对测试及损失的这样一个降低程度，可能不是说按照刚才说这个15÷20，这样一个占比啊，这这是这个两个方法的一个一个差别。

那目前的话我们的工作其实更多的是，基于less s在做，针对一些重点任务项上做一些数据的筛选啊，因为这种效果是比那个NAS的这个方式，要更好的啊，这是这样的一个介绍，然后基于这些呃思考也好。

还有基于一些方法的理解也好，其实我们正在做的一个事情，可以概括为这样一张图，就是针对一些重点能力的提升，所谓的重点能力就是图上画的这些哈，三大类逻辑认知和理解，然后每个大类下面也有一些小类嗯。

大概这样十几个重点的啊，这种能力的类别，那我们结合刚才的这种数据筛选的方式，同时结合这个PPL啊，RRRFT就是这个拒绝采样的一个方式啊，做一些筛选任务呃，然后去拆这个筛选更优的数据。

同时呢我们还面向一些标准的评测集，来定向提升单项的重点能力，然后在这个基础之上，那我们怎么样做通用能力的融合呢，就是按照这个三个大类，然后划分能力的维度呢，进行一个强化这样的一个训练呃。

在这个过程中呢就会非常重要的一个点，就是这个迭代优化数据的配比，那我们在保证每一个能力的数据质量呃，构建尽量高的同时，每一个能力有提升的同时，怎么样把这些能力的训练的过程融合到一起。

保证每一个能力都有明显的提升，所以这个过程中其实对这个数据配比呃，是有很多的一个经验性的一个积累啊，呃这个举了一个SFT优化的一个效果哈，这个主要是一个逻辑推理的问题，呃这个问题本身就不念了。

首先其实像这类问题哈，在我们原来的经验来看，那只是通过这种比较粗糙的基础训练，加赛的训练的话，它确实是很难去学习到的一类问题，因为这类问题对数据质量要求是非常高，这个也是我们在SFT过程呃。

优化过程中比较重点优化的一类这个数据呃，数据类型，那经过刚才聊到的这些，很多的这SFT的数据的优化的手段之后呢，其实在这个原有的基础上，我们整个的chat能力啊，是可以提升到大约8%这样的一个啊。

一个比例，那里面重点提升的几项就包括像逻辑推理，幻觉，数学和翻译能力分别提升的也比较高，尤其是这个数学计算，因为数学计算其实就像我刚才说，可能在之前呃，大量收集这个SID数据的时候，是比较少覆盖到的。

并且它的质量很难保证，然后这块其实是需要很定向的去呃，提高它的质量，所以这块的数学能力的提升也比较明显，然后第二部分呢就是大明星偏好对齐的介绍，那偏好对齐本身，我先可能说一些我自己的理解哈。

不一定是这个公开的，或者大家公认的一些呃一些这种定义，那其实偏好对齐全称就是叫人类偏好对齐，怎么让模型呃，学习的东西更加符合人类想要的那个呃结果，但其实这样去说下来的话，好像我们不光是做这个呃强化学习。

还有像现在这个DPO哈，还有包括刚才提到的SFT，甚至我们把这个范围扩展到这个基础模型训练，好像他都是在做偏好对齐，对不对，因为所有的语言文字，所有的文章段落，它都是人为的去写出来的。

那么其实每一条数据的学习，都是在做一个人类偏好的对齐，当然今天要讲的这个偏好，对齐呢是是一个比较狭义的偏好对齐哈，就是在通用SFT之后，那么怎么样这个模型更好的去按照人类的偏好。

去产生更呃符合人类要求的结果，这个是稍微狭义一些哈，呃这个我就不不再介绍这个偏好对齐，目前有各种方法，目前我们用的就是DPO这种方式啊，我们直接对比一下，这个SFT和DPO到底有什么样的一个区别。

因为按照刚才来讲，好像他都是在学习人类呃，呃这个人类创造的一些数据嘛，但是它本身在这个方法上是有区别的哈，呃比较直观的一个理解就是SFT，我们是不是每过来一条数据我就学习，反正你给我的数据长什么样。

我就觉得我要把这条数据学会，但是DPO阶段它实际上是一个pair的方式，在学习，就是同样一个问题我该怎么回复，我知道哪些问题回复是得分高的，更好的，得分差的呃，这个这个我不应该去学的。

所以它实际上有一个PARALYSE这种概念在里面，所以我们可以简单的哈，比较粗粗糙的认为说，SFT是point wise的这种方式，然后DPO是一个PARAGRASE，这样的学习的方式，来以此加以区分。

然后这个其实DPO和SFT本身，在这个模型训练上，它的目标函数已经不一样了，因为paradise它相当于是这个呃，中间会有个减法啊，这个loss它是一个一个减法的方式，呃对啊。

这个细节我就不一行一行念了，然后呢我们具体的这个DPO实践的方式，其实就是用这种一种迭代的这种方式来做，其实DPU不是说训练一次就结束的，而是说我们拿刚才这个通用SFD。

训练好的模型作为出版的这种DPO模型，那么在这个基础上的话，把这个代表性的query数据去生成，对应的这个pair，就相当于一个模型，我可以跑跑出不同的结果，然后在这个过程中。

我们的标注人员是要去标注哪个pair，是啊，这个效果更好的那个pair是效果啊，不是不是哪个结果是更好的，哪个结果是比较差的，这样生成的par数据在这个基础上。

通过刚才说到PARAGRASE的方式来迭代模型，这样一轮一轮的迭代，到最后发现这个模型会越来越接近人类，它这个我们标注人员哈想要的这种啊，生成结果的样式，最终产生最后的final模型。

其实思路比就是比较简单的，思路是比较简单的，然后针对个DPO的话呃，这是举了一个DPO的这个pad的数据啊，这里边通常我们管它叫接受和拒绝，就是刚才说的这个好的结果和坏的结果。

那其实这个里边我们主要针对的是一些呃，逻辑等类的一个问题，就在这块就没有像SFD那样，我们把通用的，刚才说的十几20个这样的重点领域，以及说这个通用的领域都做优化。

这里面其实呃优化的这个方向就稍微少一些啊，这个这个例子就不念了哈，然后整个DPU的效果，那我们重点优化的是主要是三个大类，一个是逻辑推理，一个是安全问答，还有一个是幻觉问题呃。

那其实这里边幻觉问题提升是比较多的，因为刚才这个月卷博士也提到啊，其实很多数据在学习过程中，它其实是符合语言逻辑的对吧，语是符合语言逻辑的，但是模型本身其实很难判定说呃，这个符不符合事实嗯。

尤其是关于一些时效性的事实对吧啊，比如这个呃这个明星之间的这个结婚离婚啊，这个这个选举啊等等选举变化等等，其实这些呃呃当然这是另外一个问题啊，这个实时性，但是在本身的一些事实类的幻觉问题上。

还是要通过一些呃，定向的这种数据优化来做提升，所以这块的我们在这个基于DPO的这个，幻觉问题优化上，效果提升也比较明显，啊最后一部分呢是介绍中国电信在大复兴，长景化能力呃，建设一些进展工作。

那刚才基于这个呃整个模型训练之后的话，我们实际上是在一些技术积累和开源上，有这样的一些产出，那首先的话我们目前的模型的话是，从1B到千亿万亿参数，当然前面这个呃这个从怎么说呢。

这个版本的话其实覆盖面目前比较全，但是真正开源的话，目前我们是把7B12B和52B模型，以及1T的高质量训练数据，目前已经是面向全网开源，另外在国产化试备阶段，那不管是这个芯片禁令，也好。

还是我们这个国央企信创国产化的要求也好，其实在这块的进展，我们做的也是比较多，包括像升腾，寒武纪随缘和登临，这种国产化芯片的适配的推理，都已经这个完成适配，另外还有就是刚才呃叶翔博士也提到。

那我们和这个GBT3。5，3。5tuber和GBT4的一个效果的对比，其实目前来看的话，我们的可以简单理解为，我们12B的模型，和GBT3。5的效果是持平，然后呃52B模型适合3。5突破的水平，呃持平。

然后达到GPT4的这个93%，当时这个我们在内部测试，是基于中文效果上的一个对比，然后基于这些能力的话，我们主要在当，我们已经在很多的场景上有些呃落地哈，今天主要介绍这样四个场景，一个是行文写作啊。

一个是这个智能客服，一个是辅助经营分析，其实就是智能取数的一种呃，特别的应用场景，还有就是一个会议纪要盒子呃，啊，这个是给出来12B和3。5的一个，一个对比哈，大家可以看到在各类方向上是有胜有负。

然后整体的能力是基本持平，那首先第一个点呢，就是我们介绍这个行文写作这样一个能力啊，我们叫星辰绘笔这样的一个产品，那在这里边的话，其实在写作的过程中，可能最原始的这种呃文本生成方式，就是我给一个题目。

我直接生成一篇文章哈，那这个其实不太符合人类的一个写作的方式，正常我们会列一个大纲对吧，哪怕我们这个考试写作文，我会想第一段，第二段是总分分总总分总，哪怕后也会有这样的一个思考对吧。

所以这个我们是按照第一步先生成大纲，然后再从大纲生成文章这样的一个过程，然后在生成大纲的过程中呢，这个大纲大家还可以，这个根据自己的需要进行一些修改，同时在使从题目生成大纲以及大纲生成文章。

就每个段落的时候，都提供了这种参考文献的能力，可以基于参考文献来模仿它的结构，生成大纲，然后基于这个参考文献的内容，来生成每一个这个长文的章节，同时在生成结果之后呢。

我们还会针对每一这个每句话进行这种扩写，续写改写的这种自动化的能力，而构成了这样的整个的一个产品化的写作能力，然后第二点的话是介绍关于这个智能客服，智能客服，相信呃很多这个老师专家也稍微了解哈。

那其实在这里边的话，一个是在线的问答能力，还有一个是离线的，对人工客服的一个辅助的能力，就包括这里面列举到的像智能填单，像这种辅助问答，还有这个大明星知识采编，其实都属于这个离线针对人工客服辅助工作。

这样的一个能力，那这里边我可能简单介绍一下这个关于大模型，知识采编这样其中的一个能力，那传这个知识彩片我要介绍是什么，这个可能是电信特有的一种叫法，那就是在离线的话，人工客服要对很多的一种呃。

产品介绍或者是套餐介绍进行一个内容的抽取，那这样方便他在客户服务的时候，会有快速的准确的一个回复，那这里面的字段和传统的这个命名，实体识别还有很大的差别哈，因为这里面不光识别实体句子。

有可能是很长的一个段落的一个介绍呃，然后在这个这个传统的采编，靠人力呢肯定是费时费力的，然后基于小模型的话，相当于每一种类别，每一种这个抽取知识的类别，可能我要单独训练模型。

而且一个迭代起来相当于是要迭代很多模型，那这个时候相当于我们用大模型做知识，采编的话，就是用统一的模型，把刚才说的这种看似结构化，但实际内容又五花八门了，这样的一个能力去实现啊。

这样大大提升了一个人工抽取的效果，然后下一个能力的话是呃，这种辅助企业经营分析，它其实是智能取出的一种呃特别的应用场景哈，我用用在这个基因分析，包括像这个数据自动的提取，然后数据展示以及自动的数据分析。

和基于分析的结果的一个报告生成，这个其实在目前大模型落地场景上，是一个比较火的方向，然后在这个方向上，其实我们还在持续大力的投入，然后把这个能力做的其实越来越精细化啊。

还有一个点呢是在这个高精准会议就要生成，当然这个首先第一步，是要保证高精准的一个语音转写，还有就是这个画者分离，然后在这个基础上，我们这个基于大模型的会议就要生成，包括像这个整个会议的呃。

呃这个主要内容的生成，以及针对每一个说话人的主要内容的生成，这个其实都做了很很多的这种优化的迭代呃，当然刚才都是一些静态的介绍哈，最后一个整体的一个视频也给大家展示一下呃。

比如第一个展示的是刚才提到的星辰绘笔，那个长文写作功能，我们发现在这个基于标题写大纲的时候。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e3565046635da90b6c226a500c774dbb_1.png)

就可以加入一个参考文献，我们相当于可以参考这这个文献里边的内容，以及这个文献对于，这个章节题目的一个写作方式，然后来生成这样大纲，这样就能保证是说比如我要写的是一个电信呃，这个内部风格的公文的话。

那其实我给你一篇这个参考，你写的我就会更精准，这样相当于在大纲维度改动就会更少，那这个里面就具体介绍了一些其他的能力哈，在我们这个问答平台上，标语包括一些表格读取，以及像这个表格生成。

还有像各类的这种呃代码语言生成，还有像这个应该是呃一些古文的理解的能力，还有这个是关于逻辑推理，当逻辑推理，刚才我在介绍SFD和DPO数据的时候，也重点介绍过很多啊，包括像数学计算。

刚才也有一一定的介绍，是说我们在这方面其实做了很多定向的提升啊，不目前目前其实关于K12的能力。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e3565046635da90b6c226a500c774dbb_3.png)

覆盖的也比较全面，那这个是比较偏娱乐性哈，这个可能十几个这个历史人物的一些啊，对话的能力也是集成到了我们弹幕心中，这也是刚才提到的星辰会记，那第一步是先是一个精准的呃会议语音转写。

然后在这个基础上的话呃。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e3565046635da90b6c226a500c774dbb_5.png)

就会生成一个这样精准的一个会议基啊，当然这个我们测试压力比较短。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e3565046635da90b6c226a500c774dbb_7.png)

所以生成的内容也比较短，好的呃。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e3565046635da90b6c226a500c774dbb_9.png)

呃感谢大家啊，这个是我的，现场同学看看有什么问题，啊这，好老师想问一下，就是呃现在就是我们今天介绍，其实关于这种预训练，大模型和这种反衬的大模型嘛，就是从您角度来看，我们比如两到3年之后这样一个大模型。

它的一个体量，就是参数量大概会到一个什么样的一个量级啊，好的呃，呃这第一个问题啊，然后第二个第二个问题是说，就是其实今天是说微调和一些预训练呃，主要是说在数据上有些差异，那如果你会看到。

就是我们对于很多国产化的这个芯片算力，其实做了适配，那未来的趋势来说，如果我们对于显存啊，带宽啊，互联还有一些基建通信，就是对于这一方面，从我们的这样一个训练的过程中。

有没有一些就是比较这种量化的趋势的分析哈，大有两个，抱歉，那个第二个问题中间其实这回音比较大啊，没太听清啊，对第二个就是关于那个显存带宽，互联和一些基建通信这样的一个未来趋势。

有没有一些比较量化的这种分析啊，啊抱歉，显存在什么时候显存带宽，显存带宽啊，对基建通信互联对哦，好的好的呃，首先第一个问题啊，在参数量这块，在参数量这块怎么说呢，反正目前这个参数量的增长大家也看到了。

包括这个昨天跟叶璇博士还在聊啊，现在我们发布的模型是ET，未来可能就是10T百T起步，像刚才说的这个传言的GBT5，可能已经达到了这个几次，百T这样的一个参数规模，所以我觉得参数规模肯定是要上去的。

因为其实我们现在我个人理解哈，我们追求的这个参数的量，其实并不是盲目的去追求参数的量，其实在下一个阶段我们要考虑落地的话，肯定要考虑基于这种大参数量的这种scaling，loss的这种效果，怎么样把它。

可能蒸馏或者近似于蒸馏的方式，把它的效果给它去映射到一个小参数的模型上，然后实现一个参数小，但是效果会更好的，这样的一个模型，其实我们现在并不是追求说一个大参数量，因为如果说一个模型部署。

一路要几十台甚至上百台这种A100，A800的机器来做推理的话，这个其实对于我们的实用性是呃不太友好的啊，所以下一步其实就会涉及到一个从大到小，但是这个大的探索一定要去做。

因为我们到现在还没有探索到多大的参数量，是达到一个能力的上限对吧，我们其实在探索到这个上限之后，才会去考虑怎么样把它缩小，然后第二个问题，关于这个问题哈，呃其实我在想这个量化的事情。

其实很难去给出一个一个公式，因为这个本身和硬件相关，其实现在我们在做这个事情的过程中，就会发现呃怎么说呢，我我就直白一点哈，我们在软件维度这模型维度，我们可能我们是在快速的追赶。

其实我们国内在这个硬件方向，也是有很大的空间要去做追赶，然后现在涉及到这个芯片禁令，导致说我们刚才也提到在这个呃升腾啊，随缘上做了很多的适配，但是我可以直观来讲，那具体这个数字就不说哈。

确实和我们刚刚才提到这个A100，A800，甚至说我们现在这个呃只能听到还碰不到的，是是B200对吧，这样的一些这个这个GPU比起来，确实差距还比较大，所以这个啧，我觉得目前谈到量化可能还是一方面。

最重要的还是一个持续的这个软件，硬件的这个持续的提升吧，你看啊对我能先问一个问题吗，啊对就是那训练的话，其实没有办法做一个量化的这种提升啊，但是我们看到，如果现在这种前沿的MOE的模型。

对他这种可能从传统的这种TP，PP到DP的运行方式，可能会像这种呃就是EP，甚至是可能SP就是sequence，LDS这种呃sequence的一个并行方式，这样一转变，这种转变的方式。

对于我们再去做这种硬件系统的时候，它主要是在什么方面需要去做一些调整呢，比如我们之前其实是一个算力棒的过程，在后面我们会是一个通信和基建互联的这样，一个棒的过程吗，嗯对是的，其实现在嘶啊。

现在其实您说的这几个点啊，反而是它的目前我们训练遇到的很多，一个限制呃，其实好多时候它这个单卡或者单机，它的训练的性能其实可能还好，但涉及到一个通信，比如像这个我们的IB卡对吧。

像那个GPU用到的IB卡，其实现在在这个方向也是也是一个限制，那我们现在遇到一个问题呃，比如在这个三四千卡和七八千卡，它很难达到说一个两倍的计算效能，其实就是在这个问题上，所以当然这个关于硬件本身呢。

我并不是一个这个方向的专家，哈哈我也我可能懂得稍微少一些，所以在这个维度上的话，呃，怎么说呢，我觉得您的问题本身就是答案就在里面，就这个东西确实很重要，但是怎么样，我在这些地方给出一个量化的结果。

好像也比较难，是不是不好意思啊。

# 2024北京智源大会-大模型前沿探索 - P4：大小模型协同训练初探：敖翔 - 智源社区 - BV1yS411A73A

喂好谢谢叶璇的介绍，嗯很高兴能够在职研大会来报告，我们团队的一些这个研究进展啊，主要是在大小模型协同训练这一块，呃其实很惭愧啊，就是我们做这个方面的研究呢，啊也是被逼无奈啊，就为什么这么讲呢。

你看这个基座模型啊，一般都是像智源啊，啊像这个BAT啊这种大厂对吧，人家有算力，有数据啊，然后有一堆这个算法工程师啊，才能玩得起的对吧，那如果说这个想做垂玉的行业的大模型啊。

得像咱们中国电信啊这样有数据啊，然后有这个算力中心对吧，有很多这样的行业数据的机构才能做得起，那如果作为我们这种高校啊研究机构啊，既没有特别大的算力啊，然后也没有特别多的这个行业数据的积累。

那我们也想做大模型，那这时候怎么办呢，那只能只能把这个大模型啊当成一种工具了啊，就是作为一种比较高级的工具啊，然后来辅助我们日常的一些啊，关于小模型的研究啊，所以就有了这个报告哈。

就是大小模型的一些协同训练方面的研究啊，我分四个方面来介绍吧，呃首先这个大模型现在有多火啊，就不用我再赘述了，我特意浏览了一下，咱们今天上午的三个平行的论坛啊，除了咱们这个论坛名字里面是显示的。

提了大模型三个字啊，另外两个论坛呢我看了一下名字啊，一个叫做多模态论坛，多模态模型论坛，另外一个叫AI安全论坛，但是里边的这个报告的内容啊，或多或少的其实都和大模型是息息相关的啊。

所以说就通过志愿大会啊，这样的一个在同一个时期举行的平行论坛，都能够看出来现在大模型有多火，那就更不用说我在这列的这个slice了，就每一次我出来做报告啊，用这一页的时候我都非常的焦虑啊，为什么呢。

就总得check一下，是不是又有一些新的东西没写上啊，特别是在这个箭头上面的这些模型的名字对吧，就从今年春节之后啊，大家这个耳熟能详的一个是SORA，一个是这个g b t four o啊。

就必须得写上对吧，但是好在呢底下的这个核心的技术啊，似乎到目前为止啊，我认为还没怎么变化啊，但是刚才听了这个呃叶全博士的报告啊，我觉得可以加上一个生长的这种训练的方式啊。

也许可以写到这个核心的技术路线上啊，作为人类反馈的这个强化，学习的一个更先进的啊，更先进的一个替代啊，写到最新的呃这个时间轴上，但不论怎么样，就是大家其实我们说现在叫这个大模型呢，其实省略了几个字啊。

叫做生成式的人工智能大模型，就前面那个生成式，大家觉得呃能力是非常强的，非常震撼啊，但是在我在这呢必须要强调的一点啊，就是说它除了生成能力以外，其实他的这个意图理解能力啊。

还有包括分析推理能力也是非常强的啊，非常强的，但是可能大家都呃，呃被它的生成能力震撼了以后呢，就忽略了这两方面的能力，那我们这个研究呢，实际上主要是在用大模型的这个，意图理解和推理的能力啊。

然后来帮助我们做一些事情呃，除了我们这块有一个案例以外呢，做了一定的调研学习啊，他们其实也是在和百度合作啊，然后再用生成式大模型的，意图理解和分析的能力啊，他们在做什么事情呢，他们是在就用这个大模型啊。

做这个呃反诈的这个这个这个案件的推理啊，还是非常有意思的啊，大家有兴趣的话可以去关注一下，我在这就不多说了啊，那可能有人会问说，你们这个这么多人现在这么呃，特特这么关心大模型，那大模型出来以前啊。

你们这帮做人工智能的人都在干什么呢哈，呃答案非常简单，就是我们一直在研究小模型啊，这块画了几个区域啊，就原来这个每一个这个框呢，实际上都代表了不同的门派啊，不同的门派，比如说我们在分析时序数据的时候啊。

可能大家就会用这个LSTM啊，那如果做这种关系数据处理的时候啊，可能会用图神网络GN啊，然后我原来可能在GN这个方向啊，做的是比较多的，那么即使是这种生成的领域啊，就是在大模型出来以前。

实际上也有这个以干模型为代表的，这种图像的生成模型一直是存在的啊，包括transformer等等，那原来呢就是大家这个门派之间啊，或者说这个研究领域之间是基本上互斥的啊，就没有大模型之前呢。

我们都认为自己是属于不同的领域啊，就举个例子，可能在我后边讲的黄磊老师啊，原来是做CV的，然后我可能是做这个data manning的，做这个用户行为建模的，那我们按理说是不会产生交集的啊。

就不会在一个同样的论坛里，大家来这个做报告啊，因为我们属于不同的子领域啊，但是现在因为有了大模型了，可能都认为哎你是做人工智能的啊，所以今天我们也在同样也同一个厂子碰着了啊，但其实呢就是多年以来。

这个小模型在各自的领域里面，还是比较不错的啊，都是一些这个SOTA的代表啊，就已经有了一些卓越的能力了，那因为大模型出来了对吧，那我们这个小模型还要不要啊，就面临了这样的一个选择。

那我们的回答呢应该是还是得要啊，要不然我们这么多几十年来的努力，全都白费了对吧，而且呢这个大模型呢它并不是现在可以啊，直接替代很多小模型的啊，只是举了两个场景啊。

第一个就是在这种端侧做轻量化部署的时候啊，你这么大参数的一个模型，这么呃这个这个这么耗这个算力啊，费电啊，这样的一个模型啊，如果放到手机里面去啊，特别是大家讲如果C端的应用对吧啊，一定要强调用户隐私。

我要在本地部署，那对不起，你的手机可能会很快就没电对吧，因为这个大模型非常耗电，所以呢这个在端侧部署的时候，小模型还是有一定的用武之地的，另外呢就是在一些特定的任务上，可能还没有取得特别好的表现哈。

比如说在一些非常专业的领域啊，或者是我们给他提出一些比较苛刻的要求啊，就是每次问他同样的问题，但是呢要求他的回答要保持一致啊，这个对于大模型来讲可能都非常困难啊，因为大模型是一个生成式的。

一个比较flexible的模型对吧，所以说呢在当前的这个时代啊，小模型并不是呃就一下被丢弃了啊，还是有一些这个用武之地的，那怎么来让小模型发挥更好的作用，或者说怎么让大模型去指导啊。

优化小模型能够更好的在现在这个时代啊，发挥自己的作用啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_1.png)

我们就做两方面的尝试，第一个方面呢，我们就是用这个知识蒸馏的这种思路啊，这个当然是比较传统的一个思路呃，现在如果想说这个大小模型怎么结合啊，基本上都是采用了右边的那个图的，这样的一个方式啊。

就是让大模型当老师啊，让教这个小模型怎么着去更好的进行优化啊，然后完成它的任务，那我们就用了一个这个代表性的任务，做了一个尝试哈，就主要是做问答啊，当然这个问答呢跟传统的问答不太一样。

就是在给出答案的同时呢，还是希望这个小模型啊，能够给出一些所谓的解释啊，啊就现在说这个可解释机器学习比较流行嘛，所以这个问题的输入啊就是给一段问题。

然后中间那个language model呢它可大可小啊，可以是一个比较小参数量的一个语言模型，右边的output有两个这个field啊，第一个就是答案是什么，关于问题的答案是什么，下边有一个解释啊。

就这个模型必须要输出关于这个回答的一些啊，一些这个这个这个解释啊，这是我们的一个任务的设定嗯，但是很遗憾，就这个任务实际上没有标准化的数据啊，就原来我们所谓的这个NLP领域的benchmark。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_3.png)

可能只有问题和答案，但是没有解释呃，那我们想得到这个解释怎么办呢，那大模型就可以来稍微借鉴一下啊，因为大模型作为一个生成模型对吧，你即使问他一个问题啊，然后让他给出答案，它会天然的生成一大堆解释。

那这个时候呢我们就让这个大模型啊，来帮我们这个任务啊，来生成一些所谓的训练数据啊，呃大概的形式就长这个样子，就是我们问这个大模型一个问题，然后让他回答这个答案，然后并且呢给出他的解释。

然后他就巴拉巴拉能生成好多，右边的这种训练数据呃，但是我们要必须要注意到，就是现在大模型的能力，并没有完全达到一个非常巅峰的水平是吧，那他即使是做一些比较标准的benchmark，他的回答正确率。

也就大概是个七八十分的水平啊，有大概223成的这个答案是回答错误的，但是呢我们发现一个比较有意思的现象哈，就是即使大模型它回答这个问题啊，回答错了，它生成的这个解释呢，和他的错误答案还是非常相关的。

哎就是它推理的还是比较正确的，这有一个柱状图可以看到橘色的是，他即使是回答错了啊，但是他的推理依然非有非常有道理，非常有逻辑啊，跟他的这个错误的答案是非常一致的，比例甚至比回答正确的那部分还要高。

那有了这个观测以后呢，我们就想，那能不能诶，我们就去训练一个所谓的这种，一致性评分的模型啊，然后我们来评价一下这个答案和这个解释之间，的这个呃逻辑的一致性啊，如果一致性高的话。

那我们就可以用这样的数据啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_5.png)

来训练我们的小模型，那么一致性不行的话，我们就把这个数据给扔掉了啊，就非常简单的一个呃这个这个想法，那好那这个时候我们面临这个任务的话，我们想用大模型来收集训练数据对吧，然后就面临了两方面的选择。

那么一方面就是，我们完全相信大模型给的东西啊，就给了一个输入之后，不管大模型回答的对或者错，然后都用他的答案和解释的这个pair，当成训练数据，那这么做的话呢，可能可呃，即虽然他的解释和答案。

是相对来比较来说比较一致的，但是毕竟他的回答是错误的对吧，那这种错误的数据会对小模型呢，来引入一些所谓的训练噪声啊，最后小模型可能训着训着就跑偏了，那当然还有一种做法，就是我们不是有真实的答案吗，对吧。

就原始的数据集没有解释，但是有答案对吧，我们可以用训练集里的ground truth当答案，但然后用大模型的这个解释啊，当成所谓的这个回答的explanation啊，但是这样做的话。

那很显然因为大模型有的时候会回答错吗啊，所以他的这个解释和答案之间会发生不一致，对吧，会发生不一致，那我们怎么办呢，我们就采取了一种trade off的方法对吧，刚才提到。

就是我们可以去设计构建一个所谓，答案和回答之间一致不一致的这样的一个呃，呃一致性的判别模型对吧，就中间那个黄色的箭头，那这个时候我们就可以啊，去构造一个这个所谓的一致性的函数，来评价大模型给的解释。

和真实答案之间的一致性啊，就通过我们刚才讲了这个判别的模型。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_7.png)

那么有了这个黄色的箭头以后呢，实际上我们再去做这个任务的时候啊，这这有点细节了啊，这个就简单讲一下，就三部分的loss啊，一部分就是给一个问题呃，然后给生成答案的一个loss。

然后给一个问题生成解释的loss，以及这个答案和这个解释之间，一致性的一个loss啊，三部分这个loss，那这样的话就会让这个小模型，从大模型给出的这些数据里啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_9.png)

去学习到他所谓的这个知识，那我们在这个三个benchmark上做了一些实验啊，最后一行是我们的方法，可以发现，我们跟其他的一些这种蒸馏的框架比的话啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_11.png)

还是能够取得一些比较不错的呃提升的，然后同时我们也用这种人工的评估的方法啊，大概检测了80个问题啊，也会发现在不同的方面啊，我们的这个方法呢，都会比原来的一些框架取得了呃一些提升啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_13.png)

最后看一个case study啊，这个是英文展示了啊，因为数据集就是英语的，他大概讲的意思就是说这个呃这个货商对吧，他货商他决定去呃买进羊毛对吧，卖出棉花啊，因为什么东西的价格比较高啊。

如果是我们来做这道问答题的话，肯定会选这个这个棉花对吧，就是选这个2B啊，因为价高对吧，低买高卖嘛，因为它价格比较高，所以我把这个货物啊进行卖出，那可以看到我们对比的几个方法啊。

首先是chi g b t啊，就没有回答正确啊，给出了一个错误的答案，那么他的解释呢，因此我们就不用看了啊，不用看了，那我们看这个其他的对比的框架啊，比如说这个一种传统的蒸馏的框架。

它虽然答案回答的是对的啊，选择了棉花，但是他的解释里面一直在写，什么羊毛的价格比较高啊，所以答案应该是A对吧，他跟他自己已经发生了冲突，所以叫他的这个这个这个呃，这个解释肯定是不正确的。

那我们所提出的这种蒸馏的框架呢，就不仅选择了正确的答案，同时呢对这个答案的呃这个这个产生的过程啊，也给出了一个比较啊make sense的一个解释啊，就是说这个棉花的价格比较高啊。

所以呢答案呢应该是选择2B啊，因为这个价高的话，那它会让这个供货商去呃卖掉这个东西，然后同时去选择购买更便宜的，另外的一种商品啊，所以这个是我们在这个NLP的这个任子，任务上吧，然后来看了一下。

就是大小模型，在数据层面啊发生协同训练之后啊，能够对小模型的呃能力呢能够取得一些提升，那么除了这种比较传统的框架以外呢，我们团队最近也啊做了一些这个小小的探索啊，就是在这个意见咨询的啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_15.png)

这个视角上也可以去做大小模型的一个训练，那么在这呢，我们的研究对象就不再是做NLP了啊，就变成了这个图神经网络啊，这个领域也就是大圆模型和这个graph的数据啊，怎么来结合这个方向呢。

还是呃相对来说比较前沿的，那么现有的两个范式啊，分别是最左边和最右边的那种范式啊，左边的这种呢，我们可以把它叫做大模型作为预测器啊，就是说来了一个图的数据啊，我们直接把这个图结构啊。

翻译成一些文字表述的prompt，然后扔到这个大圆模型里面去，然后让大圆模型呢去做出一些预测啊，然后再基于这个预测呢做一些精调什么的啊，但是在这个范式上，我们会发现GN这三个字压根就没出现过对吧。

就完全用大模型在做图了啊，但是我们刚才这个知道我刚才也提到，就是在这个图数据的处理上，现在图神经网络肯定是SOTA嘛啊，就是我们没有必要这个另起炉灶，就完全用大语言模型，而且说实话。

现在大语言模型在这个这个处理图数据上，他也不是非常的擅长啊，我指的是graph，而不是image，那么当然就有由于没有结合GN对吧，就出现了右边的那种范式啊，叫做大圆模型作为增强器啊，在那个图上。

我们会发现GN出现在了最下边对吧，说明这个大圆模型呢确实是和图神经网络呀，发生了一些交互啊，但是这个交互呢相对来说呢比较初级啊，就有点像我刚才讲的这个，我们做的第一个NLP的那个工作。

就是通过大圆模型去帮这个GNN啊，准备一些数据啊，准备一些数据，就还是把图数据的这个结构呢翻译成prompt，以后，让大圆模型呢去做节点的属性增强啊，因为我们现在可能这个属性上是文本的，数据是比较多的。

那么增强了以后呢，相当于这个graph data呢，它的这个信息量啊就得到了扩充，然后再去训练GN的时候，也许效果能够提升啊，那么这种范式虽然跟GNN发生了交互，但是我们注意到它的交互仅发生了一次对吧。

没有充分的去利用啊大圆模型的推理的能力，那于是呢，我们就呃这个这个结合现有工作的一些呃，这个缺陷吧，然后提出了一些改进啊，就给出了中间的一种新的范式，叫做大圆模型作为顾问啊，作为consultant。

那么中间是一个循环对吧，就是说我们在这个GN的训练过程当中啊，总会遇到一些比较难的case啊，就好比如说我们看病对吧，总有一些疑难杂症对吧，可能是这个GN这种初级的医生是解决不了的。

那么这个时候我们就把这些疑难杂症对吧，交给一个专家啊，大圆模型，大圆模型呢来针对这个疑难的杂症啊，这个比较难的节点去做一下预测，那么预测之后呢，我们会把这些信息啊再反馈给这个GN，然后再去做调优。

那么如此循环的这样迭代的话呢，最后会获得一个更强的GN啊，获得更强的GN，所以这个是我们这个呃，就是今天那报告的一个核心的思想，就是用大语言模型作为工具，然后去提升那些哎原来传统方法的一些效果啊。

那么大概的一个框架呢就分成这几个步骤啊，就包括不确定点的选择呀，自动提示工程啊，啊大圆模型的咨询和回复的利用等等啊，分别来看一下，我们刚才讲，就说，我们并不希望这个所有的点都去问，那个大圆模型啊。

原因呢因为GN他能力还可以对吧，有一些简单的case，我们就没有必要惊动专家了对吧，所以就是我们只去挑选部分节点，那怎么来挑呢啊我们可以用简单的一种策略啊，就是通过不同的参数啊。

去构造不同版本的图神经网络，然后对同一个图来做预测啊，那么预测的时候呢总会出现在某些节点上，它的预测的方差啊，就是这个分类的概率啊，它的方差比较大，那么这种概率大的节点啊，分方差比较大的节点。

我们就认为是所谓的疑难杂症啊，然后我们就开始向大语言模型呢发起咨询对吧，那么咨询的时候呢，我们就得像那个大圆模型，来描述这个节点的情况啊，这块也比较简单，我们就把这个节点周围的一些邻居啊，就是连边嘛。

连边它的一些一二阶的邻居的信息啊，包括这些节点的属性啊，以及label啊，还有这个GN是怎么预测的啊，就像写病历一样啊，写成一些文字的信息，然后来向啊大圆模型呢发出一个提问。

那么大圆模型呢接到了这些输入之后呢，它会根据他的一些理解对吧，做推理分析，最后给出他的回复，他的回复呢我们的要求的格式也比较简单啊，一个呢就是这个节点到底是哪个类啊，标签是什么，第二就是呃对于它的分类。

要给出他的推理的解释，那么有了这个回复以后呢，我们毕竟要和基恩做联合的训练对吧，那我们怎么来让GN来使用这些文本呢，那么这块呢用了一些比较启发式的方法呃，我们知道大圆模型对这个图结构啊。

就图节点做分类的时候呢，无非会遇到两种情况，一种情况就是大圆模型，它的预测和我的ground truth之间是一致的啊，就是他预测对了，那么预测对的时候，我们就自然相信他的解释也比较合理对吧。

因为刚才我第一个工作里面已经讲了，就是它大圆模型每次对自己的回答的这个推理，还是比较合理的，那我们也相信他的这个解释是比较合理的，那我们可以遵循像这个大圆模型作为增强器啊，这样的范式。

把大圆模型反馈回来的这个文本的解释，作为图上这个节点的属性的补充啊，就直接把这个文本堆到它的属性里，那这样的话呢，能够带来更丰富的一些语义信息的补充，当然大圆模型也会有失误的时候对吧。

就是他的预测和ground truth，之间是不一致的啊，就是大圆模型也没有搞对啊，这个疑难杂症，那么在这种时候呢，我们就做了一个这个假设哈，就之所以GNN预测方差比较大啊，这个节点比较难啊。

大圆模型也做不对，是因为它周边的这个图结构出了问题啊，可能是在我们构图的时候啊，由于我们的这种啊规则设计的不好啊，它有一些噪声连边被加进来了，或者是这个节点遭到了某些这个注入的攻击啊。

有一些噪声的连边存在，那这个时候呢我们就把它周围的结构啊，做一个简化啊，让它让它这个连边的关系呢，得到一个这个呃比较简单的一个情况，看能不能做对啊，说白了就是把一些那个连边给它剪掉啊。

剪掉之后看下一次GN还能不能预测对啊，所以就是有两种呃，利用它反馈的这个方法，那么整个的这个设定我大概就讲完了啊，然后因为我们是在这个，TRANSACTIVE的场景下做的啊，所以我们在这个大图上。

一上来就能够看到所有的training sample，跟test sample啊，所以我们任何一次大圆模型的反馈，无论是属性增强也好，还是结构的去造也好，都是在整张图上能够可见的。

那么在最后的测试的阶段啊，由于我们的GN已经在不断的和大语言模型的，交互当中啊，得到了强化，所以在测试的时候，他已经是一个得到了专家指导的，一个终极医生了对吧，所以他就不用再去向大圆模型发生发起咨询了。

直接就是对那些test sample啊做出自己的预测啊，当然我们的实验结果也是比较受鼓舞啊，就是我们为了去充分的验证这样的一个范式，能不能有效哈，所以我们在呃同配偏好的图上。

还有包括异配偏好的图上都分别做了实验啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_17.png)

那可以看到就是我们的这个训练的方式啊，然后和一些非常传统的GN做了一些结合啊，就上半篮这些方法基本上都是在啊，19年以前的啊，一些经典的GNN的方法，那么当它和大圆模型发生了协同训练啊。

开始交互学习之后，它可以和底下的这些22年二三年提出的，SOTA的GN的方法达到一个可比的状态，在某些数据集上啊，甚至会比SOTA的GN还要更强一些啊，当然这呃当然我们也可以把这个这种范式啊。

装配到这些SOTA的GNN上啊，也许会更好，但我们没做这方面的实验啊，这是消融实验跳过了呃，同时我们也可以跟那个其他的范式，做了一些对比啊，比如说大圆模型作为预测器，作为增强器啊，都是已有的范式。

那我们的这个方法呢，也能够在这个更小参数的啊，大圆模型的加持下啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_19.png)

取得一个稳定的提升，对我还有一分钟的时间哈，做一下总结和展望呃，实际上就是作为这个高校研究所对吧，没有算力资源，没有数据资源，那我们也去想用大圆模型啊，帮助我们做一些工作。

所以我们就选择了用大圆模型来辅助，这个机器学习模型的构建啊，这个角度呃我们采用了两个框架哈，一个是知识蒸馏啊，比较传统的结合的方式，还有意见咨询两个角度呃，分别呢在这个大小模型的呃协同训练上呢。

做了一些探索呃，那么特别是这个呃大圆模型作为咨询咨询师啊，或者作为专家这样的一个框架呢，我相信不只是在技能的训练上，也许在其他小模型的训练上啊，都能够呃得到一些这个应用，那么当然呃我们目前的这种范式呢。

它还有很多局限哈，很多局限，比如说大圆模型，它整个的这个推理过程还是比较慢的啊，我们现在做这个图数据的训练，说句实话还是呃非常高效的，那么结合了大圆模型以后，尽管我们只问部分的节点。

那么整体的这个训练的效率呢也会被拖慢啊，所以在这个实际的运用当中，如何去提升效率，控制成本啊，这是一个非常重要的问题，那么另外呢就是我们目前啊，就是大圆模型和小模型之间的交互。

还是停留在这个数据层面的啊，第一个工作是做这个训练数据的生成对吧，第二个工作呢是在训练过程当中啊，做一些数据的增强啊，结构的去造等等，还是在数据层面，那么什么时候能够在这个算法层面。

比如说在模型的设计上对吧，这个loss的改进上，能够采用上这个大圆模型的能力，也许是呃更值得研究的一个话题哈。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/71acdbb0892b86d68797eb5ef64c0c85_21.png)

好那以上就是我今天的报告哈，说的不对的地儿，敬请各位批评指正啊，谢谢，呃感谢翱翔博士的精彩报告，现在请现场观众提问，感谢老师，我提个关于图的这个一个小问题，就是我想问一下。

就现在你用的是现成的这个大语言模型，是不是有没有，就说针对这个图数据的这种大模型，就是我这个大模型在前期训练的阶段，就是用的图的这个数据，然后嘞，我在各种各样的这种图的这种任务上，都会有一些效果。

而不是说就是用的预训练的这种大语言模型，就这方面不知道老师看能不能给一些呃展望，或者说看法，好好谢谢您的问题啊，就实际上您说的这个针对图的数据，去精调大语言模型，或者是构建所谓的图基础模型还是有的啊。

但是我们团队就这反正我个人吧，我是不不支持这样的技术路线啊，因为是我，我感觉是这样的，就首先啊就说这个你精调完了以后哈，因为图的这个下游任务无非就是两种，一种是节点分类，一种是链接预测。

它不像自然语言或者是图像，它的下游任务非常多啊，所以我们是否有必要去构建一个，这个需要大量的这个数据的标注啊，因为你要做精条，肯定要标注吗，然后甚至是这个从零构建一个针对图的一个，基础模型是否有必要啊。

这个是存疑的，而且现在对吧，像叶璇他们这个万亿级的参数的模型，能力已经非常强了，那我们在这轻量级的用一下，如果能够帮助我们做提升，那何乐而不为呢，这是我个人观点，好谢谢您的问题啊。

不知道能不能回答您的问题，对您说的那种路线实际上是有的，而且也非常火啊。