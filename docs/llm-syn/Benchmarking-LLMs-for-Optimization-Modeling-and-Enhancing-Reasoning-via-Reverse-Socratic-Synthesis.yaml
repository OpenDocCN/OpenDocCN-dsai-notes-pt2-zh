- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:59:13'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.09887](https://ar5iv.labs.arxiv.org/html/2407.09887)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \pdfcolInitStack
  prefs: []
  type: TYPE_NORMAL
- en: tcb@breakable
  prefs: []
  type: TYPE_NORMAL
- en: Zhicheng Yang¹    Yinya Huang⁴    Wei Shi⁷    Liang Feng⁶
  prefs: []
  type: TYPE_NORMAL
- en: Linqi Song⁴    Yiwei Wang³    Xiaodan Liang⁵    Jing Tang^(1,2)
  prefs: []
  type: TYPE_NORMAL
- en: ¹The Hong Kong University of Science and Technology (Guangzhou)
  prefs: []
  type: TYPE_NORMAL
- en: ²The Hong Kong University of Science and Technology
  prefs: []
  type: TYPE_NORMAL
- en: ³University of California, Los Angeles ⁴City University of Hong Kong
  prefs: []
  type: TYPE_NORMAL
- en: ⁵Sun Yat-sen University    ⁶Chongqing University    ⁷Huawei Noah’s Ark Lab
  prefs: []
  type: TYPE_NORMAL
- en: yangzhch6@gmail.com, yinya.huang@hotmail.com,
  prefs: []
  type: TYPE_NORMAL
- en: shiwei87@huawei.com, liangf@cqu.edu.cn, linqi.song@cityu.edu.hk,
  prefs: []
  type: TYPE_NORMAL
- en: wangyw.evan@gmail.com, xdliang328@gmail.com, jingtang@ust.hk
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large language models (LLMs) have exhibited their problem-solving ability in
    mathematical reasoning. Solving realistic optimization (OPT) problems in industrial
    application scenarios requires advanced and applied math ability. However, current
    OPT benchmarks that merely solve linear programming are far from complex realistic
    situations. In this work, we propose E-OPT, a benchmark for end-to-end optimization
    problem-solving with human-readable inputs and outputs. E-OPT contains rich optimization
    problems, including linear/nonlinear programming with/without table data, which
    can comprehensively evaluate LLMs’ solving ability. In our benchmark, LLMs are
    required to correctly understand the problem in E-OPT and call code solver to
    get precise numerical answers. Furthermore, to alleviate the data scarcity for
    optimization problems, and to bridge the gap between open-source LLMs on a small
    scale (e.g., Llama-2-7b and Llama-3-8b) and closed-source LLMs (e.g., GPT-4),
    we further propose a novel data synthesis method namely ReSocratic. Unlike general
    data synthesis methods that proceed from questions to answers, ReSocratic first
    incrementally synthesizes optimization scenarios with mathematical formulations
    step by step and then back-translates the generated scenarios into questions.
    In such a way, we construct the ReSocratic-29k dataset from a small seed sample
    pool with the powerful open-source large model DeepSeek-V2. To demonstrate the
    effectiveness of ReSocratic, we conduct supervised fine-tuning with ReSocratic-29k
    on multiple open-source models. The results show that Llama3-8b is significantly
    improved from 13.6% to 51.7% on E-OPT, while DeepSeek-V2 reaches 61.0%, approaching
    65.5% of GPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: \settocdepth
  prefs: []
  type: TYPE_NORMAL
- en: part
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large language models (LLMs), such as GPT-3 [[1](#bib.bib1)], GPT-4 [[2](#bib.bib2)],
    and Llama [[3](#bib.bib3), [4](#bib.bib4)], have demonstrated their emerging capability
    in logical reasoning [[5](#bib.bib5), [6](#bib.bib6)] and mathematical reasoning [[7](#bib.bib7),
    [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)], such as solving elementary
    [[11](#bib.bib11)] to high-school level [[12](#bib.bib12)] math problems. Yet
    a follow-up curiosity is to what extent LLMs apply their mathematical intelligence
    to practical scenarios. Optimization problem solving is a field of applied mathematics
    that has been proven beneficial in many applications such as supply chain management,
    power energy scheduling, marketing, and quantitative trading. Optimization problem-solving
    is a comprehensive task that evaluates the mathematical and coding capabilities
    of LLMs. To provide the optimal solution to an optimization problem, LLMs are
    not only required to understand and construct the mathematical formulation according
    to the given problem but also to call an optimization solver to get the final
    answers.
  prefs: []
  type: TYPE_NORMAL
- en: Previous studies [[13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15)] have
    done some primary exploration of large language models solving operations research
    problems. However, these studies have not yet extended to more generalized scenarios
    regarding practical optimization problems. Specifically, NL4OPT [[13](#bib.bib13),
    [16](#bib.bib16)] uses named entity recognition to extract entity and numerical
    values in the given question text, and then formulate it into mathematical models.
    They only measure the model’s ability to correctly construct mathematical formulations,
    without considering solving the mathematical formulations being constructed. To
    further evaluate models providing the final optimal solution, i.e., the numerical
    values of the variables and the optimization objective, ComplexOR [[14](#bib.bib14)]
    and NLP4LP [[15](#bib.bib15)] benchmark the models to solve a problem with an
    optimization solver in the setting without explicit input numbers. However, due
    to the difficulty of collecting such data, these benchmarks are still on a small
    scale. Moreover, the recent MAMO [[17](#bib.bib17)] proposes to further benchmark
    optimization problem solving with a code solver. Nevertheless, one common pitfall
    of all the aforementioned works is that they merely focus on linear programming,
    whereas nonlinear optimization problems and practical tabular format are not included.
    Table [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ Benchmarking LLMs for Optimization
    Modeling and Enhancing Reasoning via Reverse Socratic Synthesis") provides a comparison
    of the aforementioned benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Comparison of optimization problem solving benchmarks. The “End2End”
    indicates whether the benchmark requires the model to solve for the optimal values
    of the variables and the optimization objective.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | Numbers | End2End | Linear | Nonlinear |'
  prefs: []
  type: TYPE_TB
- en: '| w/ table | w/o table | w/ table | w/o table |'
  prefs: []
  type: TYPE_TB
- en: '| ComplexOR [[14](#bib.bib14)] | Implicit | $\surd$ |'
  prefs: []
  type: TYPE_TB
- en: '| NLP4LP [[15](#bib.bib15)] | Implicit | $\surd$ |'
  prefs: []
  type: TYPE_TB
- en: '| NL4OPT [[16](#bib.bib16)] | Explicit | $\times$ |'
  prefs: []
  type: TYPE_TB
- en: '| MAMO [[17](#bib.bib17)] | Explicit | $\surd$ |'
  prefs: []
  type: TYPE_TB
- en: '| E-OPT (Ours) | Explicit | $\surd$ |'
  prefs: []
  type: TYPE_TB
- en: 'In this work, we propose E-OPT, a new benchmark with high-quality data to evaluate
    LLMs’ end-to-end solving ability in optimization problems. We carefully select
    605 questions and conduct careful manual verification to form the dataset. E-OPT
    contains linear and nonlinear programming with both integer and mixed integer
    variables in the programming problems. E-OPT also includes tabular data, which
    fills the gap in current optimization benchmarks. Figure [1](#S1.F1 "Figure 1
    ‣ 1 Introduction ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis") demonstrates E-OPT examples in the four problem
    types: linear programming problems without tables, linear programming problems
    with tables, nonlinear programming problems without tables, and nonlinear programming
    problems with tables. A model solves an E-OPT problem by reading the natural language
    input and then generating Python code that solves the problem, where the code
    will be processed to acquire the numerical value of the variables and the objective
    function. We remark that a preliminary subset of E-OPT is released in April 2024
    as a contest track¹¹1[https://www.codabench.org/competitions/2438/](https://www.codabench.org/competitions/2438/)
    of ICML 2024 Challenge on Automated Math Reasoning.²²2[https://sites.google.com/view/ai4mathworkshopicml2024/challenges](https://sites.google.com/view/ai4mathworkshopicml2024/challenges)'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the data scarcity issue in optimization problems [[14](#bib.bib14),
    [15](#bib.bib15)] cannot be ignored. The data samples of the optimization problem
    are relatively complex. Optimization problem solving requires not only correct
    natural language solutions but also the accurate code of calling optimization
    solvers. Data annotation in this field requires annotators to possess good professional
    knowledge, making the process not only expensive but also time-consuming and labor-intensive.
    In addition, there is a significant performance gap between small open-source
    models (e.g., Llama2-7b, Llama3-8b³³3[https://github.com/meta-llama/llama3](https://github.com/meta-llama/llama3))
    and large closed-source models (e.g., GPT-4) in many complex reasoning tasks [[7](#bib.bib7),
    [8](#bib.bib8), [5](#bib.bib5), [9](#bib.bib9), [10](#bib.bib10), [6](#bib.bib6)].
    To alleviate the issue of data scarcity and mitigate the performance gap between
    small open-source language models and large models, we propose ReSocratic, a novel
    method for synthesizing diverse and reliable data for optimization problems. Our
    ReSocratic first generates high-quality natural language scenarios step by step
    from a very small number of seed samples. We then back-translate the scenarios
    generated in each step into questions, which can be seen as a reverse Socratic
    approach. We collect 29k samples with ReSocratic, resulting in the ReSocratic-29k
    dataset. Further ablation experiments show that our reverse data synthesis (from
    scenario to question) is more accurate than the forward data synthesis (from question
    to answer), and the step-wise sub-samples manufactured by the ReSocratic further
    improve the performance of the small open-source language models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, our contributions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We propose a high-quality benchmark named E-OPT for optimization problems with
    complex samples in multiple forms. As far as we know, this is the first large-scale
    benchmark to measure the model’s end-to-end solving ability in optimization problems
    including nonlinear and tabular data. We evaluate GPT families, Llama families,
    and DeepSeek-V2 [[18](#bib.bib18)] on our proposed E-OPT in few-shot and zero-shot
    settings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We propose ReSocratic, a novel method for generating diverse and reliable data
    for optimization problems. We first create high-quality natural language scenarios
    step by step from a very small number of seed samples. We then back-translate
    the generated scenarios at each step into sub-questions, which can be seen as
    a reverse Socratic approach. Experimental analysis shows that the accuracy of
    reverse data synthesis is higher than that of forward data synthesis, and the
    sub-questions generated in each step of ReSocratic can further improve the model
    performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We synthesize the ReSocratic-29k dataset with 29k samples by using our ReSocratic.
    Experimental results show that the ReSocratic-29k significantly improves the performance
    of open-source models on E-OPT (Llama2 from 0.0% to 30.6%; Llama3 from 13.6% to
    51.7%), which further demonstrates the validity of our synthetic data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7e98a9e1292ac49f78441e4e5248fcd4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Our E-OPT contains various types of data (linear, nonlinear, table).
    To enhance readability, we present the table in an excel format and included a
    diagram to illustrate the nonlinear example without a table. However, it should
    be noted that our question comprises text only.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large Language Models. Recent progress in natural language processing (NLP)
    has led to the development of large language models (LLMs) [[1](#bib.bib1), [2](#bib.bib2),
    [3](#bib.bib3), [4](#bib.bib4)]. With a large amount of data and computation resources,
    LLMs excel beyond human capability in the domains of writing[[19](#bib.bib19),
    [20](#bib.bib20)], translation [[21](#bib.bib21), [22](#bib.bib22)], and knowledge
    reservoirs [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26)].
    Moreover, large models are observed gaining emergent abilities for example in
    multi-step reasoning tasks [[27](#bib.bib27)]. Furthermore, in the realm of multi-step
    reasoning, few-shot prompting techniques [[28](#bib.bib28)] are observed to surpass
    the performance of fine-tuning with the full training set, even when applied to
    the same large model [[29](#bib.bib29)]. In recent years, researchers have focused
    on the performance of language models on complex reasoning tasks, including mathematical
    reasoning [[7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)] and
    logic reasoning [[5](#bib.bib5), [6](#bib.bib6)]. In this work, we mainly focus
    on optimization problem solving, which has strong practical application value.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarks for Optimization Problems. More closely related to our approach,
    the NL4OPT benchmark [[13](#bib.bib13), [16](#bib.bib16)] investigates controlled
    generation techniques to obtain an automatic suggestion of formulation. They first
    use named entity recognition methods to extract a set of entity-typed declarations,
    then they transform it into linear program models. As one can see, NL4OPT only
    evaluates an AI model’s ability to establish mathematical models, while we contribute
    an end-to-end framework in this work. Optimus [[15](#bib.bib15)] and ComplexOR
    [[14](#bib.bib14)] also make significant research in the field of operations research
    with LLMs. However, they provide a very small test set, containing less than 70
    test samples. Recently, MAMO [[17](#bib.bib17)] is proposed to benchmark mathematical
    modeling with code solvers. However, all these works merely focus on linear programming,
    ignoring the nonlinear problems that exist widely in practical applications. In
    addition, these benchmarks are simple in form, ignoring the tabular data that
    often occurs in industrial scenarios. In this work, we contribute E-OPT, which
    is an end-to-end benchmark containing 605 multi-type data samples. E-OPT is a
    comprehensive benchmark that involves linear, non-linear, and tabular data, and
    the types of variables involved in the problems include continuous, integers (IP),
    and mixed integers (MIP). Additionally, we notice a simultaneous work Tang et al.
    [[30](#bib.bib30)] explores synthesizing nonlinear programming via a semi-automated
    process. However, the data are solely applied for LLM fine-tuning. Contrastively,
    in this paper, we aim to benchmark practical optimization modeling with a high-quality
    manually checked test-bed E-OPT and also automatically synthesize more comprehensive
    optimization data including table data and code solutions resulting in ReSocratic-29k.
    Therefore, Tang et al. [[30](#bib.bib30)] is orthogonal to ours regarding the
    benchmark and method purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Data Synthesis with LLMs for Mathematical Reasoning. One of the important ways
    to improve the performance of language models in mathematical reasoning tasks
    is to upscale the number of fine-tuning data for LLMs. A lot of work [[31](#bib.bib31),
    [32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36)]
    has been done in this area. Rejection sampling fine-tuning (RFT) [[34](#bib.bib34)]
    uses supervised models to generate and collect correct reasoning paths as augmented
    fine-tuning datasets. MAmmoTH [[36](#bib.bib36)] collects both Chain-of-Thoughts
    solutions in natural language and Program-of-Thoughts solutions in formal language
    using RFT with GPT-4\. MetaMath [[31](#bib.bib31)] conducts both data augmentation
    on question and answer text. MathGenie [[35](#bib.bib35)] collects a large amount
    of data through open-source language models.
  prefs: []
  type: TYPE_NORMAL
- en: All of these works are oriented to primary school math word problems, a field
    that already has high-quality data sets (such as GSM8K [[11](#bib.bib11)] and
    SVAMP [[8](#bib.bib8)]), and these work builds on that. However, there is very
    little high-quality data for optimization problems, which poses a great challenge
    to data synthesis. Therefore, these previous approaches can’t transferred directly
    to optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Socratic Large Language Model. The Socratic method [[37](#bib.bib37)] is a critical
    thinking method with dialogic disassembled multi-step subquestions and answers
    cultivating in answering a complex question. This method has been applied by current
    language model techniques for advanced reasoning tasks, such as prompting step-wise
    reasoning [[38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40)], multi-agent
    interaction [[41](#bib.bib41)], and discovering math knowledge [[42](#bib.bib42)].
    For example, Qi et al. [[38](#bib.bib38)] proposes a divide-and-conquer style
    algorithm that mimics recursive thinking by asking Socratic questions, it thus
    relieves the reliance on the initial decision as chain-of-thought (CoT) and achieves
    performance improvements on several complex reasoning tasks. Dong et al. [[42](#bib.bib42)]
    prompt GPT-4 with Socratic reasoning to facilitate self-evaluation and refinement
    so that encourages the model to recursively discover, solve, and integrate problems,
    resulting in proving the challenging “$P\neq NP$” problem through 97 dialogue
    turns. Another line of work [[43](#bib.bib43), [11](#bib.bib11)] applies the Socratic
    method for fine-grained dataset construction. GSM8K Socratic dataset⁴⁴4[https://github.com/openai/grade-school-math?tab=readme-ov-file#socratic-dataset](https://github.com/openai/grade-school-math?tab=readme-ov-file#socratic-dataset)
    [[11](#bib.bib11)] is the most related work to our paper. They inject automatically
    generated “Socratic subquestions” before each step, resulting in fine-grained
    math data. To construct a step-by-step benchmark for optimization problem solving
    with intermediate solutions, in this work, we explore the Socratic method to synthesize
    optimization problems. Unlike the previous study, we propose a reverse Socratic
    approach (ReSocratic) that generates optimization problems from the answer back
    to a question, and we demonstrate its superiority to traditional forward Socratic
    synthesis.
  prefs: []
  type: TYPE_NORMAL
- en: '3 E-OPT: Human-Readable Optimization Problems Benchmark'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The benchmark E-OPT is to evaluate the capability of large language models
    to solve end-to-end optimization problems. Table [1](#S1.T1 "Table 1 ‣ 1 Introduction
    ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis") compares E-OPT and related optimization-problem benchmarks.
    E-OPT covers a substantial number of optimization problems with a wider range
    of problem types. Specifically, E-OPT features linear programming (linear), non-linear
    optimization problems (non-linear), and table content as in industrial use (Table),
    resulting in a comprehensive and versatile benchmark for LLM optimization problem-solving.
    E-OPT is an end-to-end benchmark, which takes natural language as input and numerical
    values of variables and objective as output. One data example of E-OPT is demonstrated
    in Figure [2](#S3.F2 "Figure 2 ‣ 3 E-OPT: Human-Readable Optimization Problems
    Benchmark ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/49f6b182e28a642ed1efce0454f4405e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: An example of E-OPT. This example is about a mixed integer nonlinear
    optimization problem. We use pyscipopt to solve the given question. Finally, we
    collect the results of the code execution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Collection and Annotation. In the data annotation stage, we assign workers
    to collect questions from textbooks [[44](#bib.bib44), [45](#bib.bib45), [46](#bib.bib46)],
    and a university’s course assignments and examinations. The workers are required
    to collect the questions first and save the text of the question in markdown format.
    If the question contains a table, convert the table to markdown format as well.
    If there is a standard answer to the question, it is also saved; if not, we let
    the worker complete the answer in natural language form. We require our workers
    to write Python code, call the pyscipopt⁵⁵5[https://github.com/scipopt/PySCIPOpt](https://github.com/scipopt/PySCIPOpt)
    solver to solve each problem, and ask them to output the values of the variables
    and optimization targets at the end of the code. These numerical solutions are
    recorded in the dataset as ground truth answers. Figure [2](#S3.F2 "Figure 2 ‣
    3 E-OPT: Human-Readable Optimization Problems Benchmark ‣ Benchmarking LLMs for
    Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")
    shows a mixed integer nonlinear programming sample of E-OPT. For each sample,
    we provide the “Question” and “Results” For every problem, we ask the workers
    to judge the uniqueness of the optimal solution. If the workers determine that
    the solution is unique, the “Results” will contain the description (colored in
    orange in Figure [2](#S3.F2 "Figure 2 ‣ 3 E-OPT: Human-Readable Optimization Problems
    Benchmark ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis")) and optimal value (colored in green in Figure
    [2](#S3.F2 "Figure 2 ‣ 3 E-OPT: Human-Readable Optimization Problems Benchmark
    ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis")) of all the variables and optimization objective; otherwise
    “Results” contains only the optimal value of the optimization objective.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Statistics. In Figure [2](#S3.F2 "Figure 2 ‣ 3 E-OPT: Human-Readable Optimization
    Problems Benchmark ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis"), we show the statistical results of
    four data formats (linear w/ table, linear w/o table, nonlinear w/ table, and
    nonlinear w/o table). Overall, E-OPT is the first optimization modeling benchmark
    with nonlinear data and table format data.'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation. Unlike NL4OPT [[16](#bib.bib16)], which only measures the mathematical
    modeling ability of the language model, we also measure the solving ability of
    the language model to call code solver. In this paper, the evaluation approach
    we adopt is an end-to-end process where natural language text is the input and
    numerical form answers are the output. Given an optimization problem $p$ to calculate
    the accuracy. A problem is considered solved if and only if all the variables
    and objectives are correctly matched. We provide a zero-shot prompt and a few-shot
    prompt to solve the problem in the Appendix.
  prefs: []
  type: TYPE_NORMAL
- en: Challenge on Automated Optimization Problem-Solving with Code. An initial subset
    of E-OPT is released in April 2024 as a contest track¹ of ICML 2024 Challenge
    on Automated Math Reasoning,² where we have collected some information about the
    current model capability in the end-to-end optimization problem-solving setting.
    The challenge has received 784 submissions from 77 participants.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fae2d7192f0f663b1d8ecd441b7aa1c6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: (a) The forward data synthesis method is to synthesize the question
    first, and then let the LLM generate the answer to the synthetic question. (b)
    In contrast, the reverse data synthesis method we propose, ReSocratic, first synthesizes
    carefully designed formatted scenarios, and then transforms the synthesized scenarios
    into code (answers) and questions. (c) Our carefully designed scenarios are structured
    in a step-by-step manner, with each step containing a natural language description
    as well as the corresponding formalized mathematical content. Starting from the
    third step of the synthetic scenario, each subsequent step is transformed into
    a question-code pair.'
  prefs: []
  type: TYPE_NORMAL
- en: '4 ReSocratic: Reverse Socratic Data Synthesis'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within the domain of optimization problems, the procurement of data presents
    significant difficulties, and the process of manual annotation is both time-intensive
    and financially burdensome, leading to substantial costs. To alleviate the data
    scarcity in this domain and to improve the optimization problem solving capabilities
    of open-source small models such as (Llama2-7b and Llama3-8b), we introduce ReSocratic,
    a novel data synthesis method for eliciting diverse and reliable data. The ReSocratic
    framework is shown in Figure [3](#S3.F3 "Figure 3 ‣ 3 E-OPT: Human-Readable Optimization
    Problems Benchmark ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")(a). The main idea of ReSocratic is
    to synthesize an optimization problem with step-by-step generation via Socratic
    method [[37](#bib.bib37)] in a reverse manner from our elaborate scenarios to
    questions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Optimization Scenario. Figure [3](#S3.F3 "Figure 3 ‣ 3 E-OPT: Human-Readable
    Optimization Problems Benchmark ‣ Benchmarking LLMs for Optimization Modeling
    and Enhancing Reasoning via Reverse Socratic Synthesis")(b) shows a 4-step scenario.
    The scenario is constructed step by step, where each step is clearly delineated
    and builds upon the previous one. Each step consists of three parts:1) A header
    with “##” that introduces the specific aspect of the scenario being addressed,
    such as “Defining Variables”, “Objective Function”, or “Constraints”. 2) A narrative
    description (colored in blue) in natural language that provides context and details
    about the element being introduced. This helps to understand the rationale and
    the requirements of that particular part of the optimization problem. 3) Mathematical
    formalization following “//” that translates the natural language description
    into a precise mathematical expression or constraint.'
  prefs: []
  type: TYPE_NORMAL
- en: Synthesis New Scenarios. We collect 27 elaborate optimization scenarios as a
    seed data pool. We first sample 2 scenarios each time from the pool to form the
    synthesis scenario prompt as shown in the Appendix. The LLM will follow the given
    prompt to generate new scenarios step by step. We set the temperature as 0.7,
    and sample 50 responses for each input. We then deploy a rule filter to detect
    whether each step of the generated scenario contains the above-mentioned three
    parts. If not, the data corresponding to the step is rejected and the generation
    stops. For all generated scenarios, we set a similarity filter, which converts
    all scenario texts into TF-IDF vectors and filters out scenarios with cosine similarity
    higher than a threshold set at 0.7.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code and Question Translation. We construct a code generation prompt to solve
    the mathematical formulations in the synthetic scenarios and output the optimal
    solution results. If the code runs incorrectly, we delete this scenario. Next,
    to acquire the questions in plain text format and the questions in table format,
    we construct two back-translation prompts. All the prompts are shown in the Appendix.
    Then, for each generated scenario starting from the third step, we translate it
    into a question-code pair, as shown in Figure [3](#S3.F3 "Figure 3 ‣ 3 E-OPT:
    Human-Readable Optimization Problems Benchmark ‣ Benchmarking LLMs for Optimization
    Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")(b).'
  prefs: []
  type: TYPE_NORMAL
- en: The Socratic method guides students to think about themselves through a series
    of sub-questions, gradually approaching the answer to the problem. Our data synthesis
    method, on the other hand, starts with a scenario and progressively synthesizes
    questions step by step, which can be seen as a reverse Socratic method.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic Dataset. We use DeepSeek-V2 [[18](#bib.bib18)] to apply ReSocratic.
    As an open-source large language model, DeepSeek-V2 [[18](#bib.bib18)] stands
    out due to its competitive performance to GPT-4, while concurrently offering a
    more cost-effective alternative. Furthermore, it exhibits a superior throughput,
    approximately 6 times greater, when contrasted against the existing 70b open-source
    model [[18](#bib.bib18)]. Utilizing the advanced capabilities of DeepSeek-V2,
    we contribute 29k synthetic data, leveraging merely 27 seed scenarios. This results
    in the ReSocratic-29k dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1 Baselines and Setting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We select GPT-3.5-Turbo [[1](#bib.bib1)], GPT-4 [[2](#bib.bib2)], Llama-2-7b-Chat
    [[4](#bib.bib4)], Llama-3-8b-Instruct and Llama-3-70b-Instruct as our language
    model baselines. The evaluation metric of our E-OPT is the answer accuracy, as
    detailed in Section [2](#S3.F2 "Figure 2 ‣ 3 E-OPT: Human-Readable Optimization
    Problems Benchmark ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis"). We show the solving accuracy of the
    four data types along with the code pass rate. We evaluate LLMs under three settings:
    Zero-shot, Few-shot, and Supervised Fine-Tuning (SFT) setting. We conduct SFT
    experiments on two A800 GPUs, the epoch is set as 3, the learning rate is $2e^{-5}$,
    and the batch size is 128.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Main Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in Table [2](#S5.T2 "Table 2 ‣ 5.2 Main Results ‣ 5 Experiments ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis"),
    GPT-4 has the strongest overall performance and achieves state-of-the-art performance
    on almost all kinds of data formats. The performance of the two open-source models,
    llama3-70b and deepseek-v2, is close to that of GPT-4 in the few-shot setup. In
    addition, open source small models perform extremely poorly on E-OPT, with Llama-2-7B-Chat
    not getting a single question correctly solved and Llama-3-8B-Instruct getting
    only 13.6% accuracy on the few-shot setting. From the perspective of data type,
    the nonlinear data of our E-OPT is more challenging than the linear data, and
    the data with table (w/ table) is more challenging than without table (w/o table).
    Then, to show the validity of ReSocratic, we SFT Llama-2-7B-Chat, and Llama-3-8B-Instruct
    with our synthetic data ReSocratic-29k. We improved the performance of the Llama-2-7B-Chat
    from 0.0% to 30.6%, and the Llama-3-8B-Instruct from 13.6% to 51.1% (+37.5%),
    which is very close to the GPT-3.5-Turbo. In addition, Llama-3-8B-Instruct even
    exceeds GPT-4 in the data type of linear w/table, reaching state-of-the-art performance.
    We present a more detailed dataset performance analysis in the Appendix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Main results on E-OPT. “Code Pass” indicates the rate of code that
    is successfully executed. Bold indicates the sota in the current setting, and
    underline indicates the sota in the overall situation.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Linear | Nonlinear | All | Code Pass |'
  prefs: []
  type: TYPE_TB
- en: '| w/ Table | w/o Table | w/ Table | w/o Table |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-3-8B-Instruct | 0.29% | 0.0% | 0.0% | 0.0% | 0.17% | 8.8% |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-3.5-Turbo | 37.5% | 68.1% | 16.0% | 19.5% | 49.1% | 85.0% |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-3-70B-Instruct | 50.0% | 76.9% | 32.0% | 30.8% | 59.5% | 86.8% |'
  prefs: []
  type: TYPE_TB
- en: '| DeepSeek-V2 | 27.5% | 40.4% | 18.0% | 29.3% | 34.4% | 74.0% |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-4 | 62.5% | 75.4% | 32.0% | 42.1% | 62.8% | 88.8% |'
  prefs: []
  type: TYPE_TB
- en: '| Few-shot Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-3-8B-Instruct | 2.5% | 17.8% | 8.0% | 11.3% | 13.6% | 26.9% |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-3.5-Turbo | 40.0% | 75.4% | 26.0% | 28.6% | 56.4% | 93.2% |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-3-70B-Instruct | 57.5% | 79.2% | 32.0% | 33.8% | 62.5% | 91.2% |'
  prefs: []
  type: TYPE_TB
- en: '| DeepSeek-V2 | 56.3% | 79.5% | 32.0% | 27.1% | 61.0% | 85.5% |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-4 | 71.3% | 80.7% | 34.0% | 34.6% | 65.5% | 88.3% |'
  prefs: []
  type: TYPE_TB
- en: '| SFT with Synthetic Data |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-Chat | 11.3% | 40.6% | 32.0% | 15.8% | 30.6% | 93.7% |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-3-8B-Instruct | 32.5% | 63.5% | 44.0% | 33.0% | 51.1% | 96.3% |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Ablation study on synthetic data.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | SFT Data | Linear | Nonlinear | All |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| w/ Table | w/o Table | w/ Table | w/o Table |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-Chat | ReSocratic w/o step questions | 10.0% | 38.3% | 32.0% |
    15.0% | 28.9% |'
  prefs: []
  type: TYPE_TB
- en: '| ReSocratic w/o filters | 11.3% | 40.1% | 30.0% | 14.3% | 29.6% |'
  prefs: []
  type: TYPE_TB
- en: '| ReSocratic-29k | 11.3% | 40.6% | 32.0% | 15.8% | 30.6% |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-3-8B-Instruct | ReSocratic w/o step questions | 32.5% | 62.9% | 42.0%
    | 31.6% | 50.2% |'
  prefs: []
  type: TYPE_TB
- en: '| ReSocratic w/o filters | 31.3% | 62.3% | 36.0% | 32.3% | 49.4% |'
  prefs: []
  type: TYPE_TB
- en: '| ReSocratic-29k | 32.5% | 63.5% | 44.0% | 33.0% | 51.1% |'
  prefs: []
  type: TYPE_TB
- en: 5.3 Ablation Study on ReSocratic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In Table [3](#S5.T3 "Table 3 ‣ 5.2 Main Results ‣ 5 Experiments ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis"),
    we present the performance outcomes of the models with and without the application
    of filters, specifically, the rule filter and similarity filter, which are illustrated
    in Figure [3](#S3.F3 "Figure 3 ‣ 3 E-OPT: Human-Readable Optimization Problems
    Benchmark ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis")(a). Additionally, we compare the performance
    when incorporating step questions versus when they are excluded, an aspect that
    is depicted in Figure [3](#S3.F3 "Figure 3 ‣ 3 E-OPT: Human-Readable Optimization
    Problems Benchmark ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")(b). We conduct an ablation study on
    Llama-2-7B-Chat and Llama-3-8B-Instruct. The experimental results show the validity
    of our filters, this conclusion is similar to RFT [[34](#bib.bib34)] that redundant
    data can negatively affect language models. Moreover, the step questions generated
    in ReSocratic can bring positive improvement to the model’s solving ability.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Comparison between Reverse Synthesis and Forward Synthesis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Furthermore, we compared the forward data synthesis approach with the reverse
    data synthesis approach (our ReSocratic method). WizardLM[[47](#bib.bib47)] is
    a typical forward data synthesis method, which first prompts the language model
    to generate questions similar to the seed data and then answer them. Using the
    same seed data, we sample 1000 responses from DeepSeek-v2 with wizardLM and ReSocratic
    respectively, and then fine-tune Llama-2-7B-Chat. The experimental results are
    shown in Table [4](#S5.T4 "Table 4 ‣ 5.4 Comparison between Reverse Synthesis
    and Forward Synthesis ‣ 5 Experiments ‣ Benchmarking LLMs for Optimization Modeling
    and Enhancing Reasoning via Reverse Socratic Synthesis"). The experimental results
    show that our ReSocratic synthesis method is superior to the forward synthesis
    method. Moreover, we sample 30 pieces of data generated by ReSocratic and WizardLM
    respectively, and manually identify the data accuracy, which also shows that the
    data generated by ReSocratic is more accurate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Comparision between ReSocratic (Reverse Method) and WizardLM (Forward
    Method). ReSocratic-29k is the synthetic data we contribute.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | SFT Data | Linear | Nonlinear | All |'
  prefs: []
  type: TYPE_TB
- en: '| Method | Data Acc | w/ Table | w/o Table | w/ Table | w/o Table |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-Chat | Wizard (1k responses) | 76.7% | 7.5% | 15.5% | 6.0% | 3.8%
    | 11.1% |'
  prefs: []
  type: TYPE_TB
- en: '| ReSocratic (1k responses) | 86.7% | 6.3% | 21.6% | 6.0% | 5.3% | 14.4% |'
  prefs: []
  type: TYPE_TB
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we propose the E-OPT benchmark, which includes various types
    of data, to evaluate the ability of language models to solve mathematical optimization
    problems end-to-end. Additionally, in order to alleviate the issue of data sparsity
    and mitigate the performance gap between large models and open-source small models,
    we introduce the ReSocratic method, a reverse data synthesis approach. Experimental
    results show that our ReSocratic method outperforms the forward data synthesis
    method. After fine-tuning with our synthetic data, ReSocratic-29k, the performance
    of Llama-2-7B-Chat and Llama-3-8B-Instruct have been significantly improved, demonstrating
    the effectiveness of our synthesis method. In the future, we plan to extend ReSocratic
    to other complex reasoning tasks such as math word problem solving, and evaluate
    more large language models on our proposed E-OPT benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to financial and human resource constraints, we were unable to collect and
    annotate a larger-scale test dataset. Due to computational resource limitations,
    we only explored the application of the ReSocratic method to optimization problems.
    In the future, we plan to extend ReSocratic to other complex reasoning tasks such
    as math word problem solving, and evaluate more large language models on our proposed
    E-OPT benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Brown et al. [2020] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. Language models are few-shot learners. *Advances in neural information
    processing systems*, 33:1877–1901, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Achiam et al. [2023] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. [2023a] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language
    models. *arXiv preprint arXiv:2302.13971*, 2023a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. [2023b] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. *arXiv
    preprint arXiv:2307.09288*, 2023b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suzgun et al. [2023] Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian
    Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny
    Zhou, and Jason Wei. Challenging BIG-bench tasks and whether chain-of-thought
    can solve them. In *Findings of the Association for Computational Linguistics:
    ACL 2023*, pages 13003–13051, Toronto, Canada, July 2023\. Association for Computational
    Linguistics. doi: 10.18653/v1/2023.findings-acl.824. URL [https://aclanthology.org/2023.findings-acl.824](https://aclanthology.org/2023.findings-acl.824).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. [2023a] Yinya Huang, Ruixin Hong, Hongming Zhang, Wei Shao, Zhicheng
    Yang, Dong Yu, Changshui Zhang, Xiaodan Liang, and Linqi Song. Clomo: Counterfactual
    logical modification with large language models. *arXiv preprint arXiv:2311.17438*,
    2023a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ling et al. [2017] Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom.
    Program induction by rationale generation: Learning to solve and explain algebraic
    word problems. In *Proceedings of the 55th Annual Meeting of the Association for
    Computational Linguistics (Volume 1: Long Papers)*, pages 158–167, Vancouver,
    Canada, July 2017\. Association for Computational Linguistics. doi: 10.18653/v1/P17-1015.
    URL [https://aclanthology.org/P17-1015](https://aclanthology.org/P17-1015).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Patel et al. [2021] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are
    NLP models really able to solve simple math word problems? In *Proceedings of
    the 2021 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies*, pages 2080–2094, Online, June 2021\.
    Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.168.
    URL [https://aclanthology.org/2021.naacl-main.168](https://aclanthology.org/2021.naacl-main.168).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. [2022] Zhicheng Yang, Jinghui Qin, Jiaqi Chen, Liang Lin, and Xiaodan
    Liang. Logicsolver: Towards interpretable math word problem solving with logical
    prompt-enhanced learning. *arXiv preprint arXiv:2205.08232*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. [2023] Zhicheng Yang, Yiwei Wang, Yinya Huang, Jing Xiong, Xiaodan
    Liang, and Jing Tang. Speak like a native: Prompting large language models in
    a native style. *arXiv preprint arXiv:2311.13538*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cobbe et al. [2021] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math
    word problems, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. [2021] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora,
    Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical
    problem solving with the math dataset. *arXiv preprint arXiv:2103.03874*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ramamonjison et al. [2022a] Rindra Ramamonjison, Haley Li, Timothy T. L. Yu,
    Shiqi He, Vishnu Rengan, Amin Banitalebi-Dehkordi, Zirui Zhou, and Yong Zhang.
    Augmenting operations research with auto-formulation of optimization models from
    problem descriptions. In Yunyao Li and Angeliki Lazaridou, editors, *Proceedings
    of the 2022 Conference on Empirical Methods in Natural Language Processing: EMNLP
    2022 - Industry Track, Abu Dhabi, UAE, December 7 - 11, 2022*, pages 29–62\. Association
    for Computational Linguistics, 2022a. doi: 10.18653/V1/2022.EMNLP-INDUSTRY.4.
    URL [https://doi.org/10.18653/v1/2022.emnlp-industry.4](https://doi.org/10.18653/v1/2022.emnlp-industry.4).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiao et al. [2023] Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Yuan Jessica
    Wang, Xiongwei Han, Xiaojin Fu, Tao Zhong, Jia Zeng, Mingli Song, et al. Chain-of-experts:
    When llms meet complex operations research problems. In *The Twelfth International
    Conference on Learning Representations*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AhmadiTeshnizi et al. [2024] Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine
    Udell. Optimus: Scalable optimization modeling with (mi) lp solvers and large
    language models. *arXiv preprint arXiv:2402.10172*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ramamonjison et al. [2022b] Rindranirina Ramamonjison, Timothy Yu, Raymond
    Li, Haley Li, Giuseppe Carenini, Bissan Ghaddar, Shiqi He, Mahdi Mostajabdaveh,
    Amin Banitalebi-Dehkordi, Zirui Zhou, and Yong Zhang. Nl4opt competition: Formulating
    optimization problems based on their natural language descriptions. In Marco Ciccone,
    Gustavo Stolovitzky, and Jacob Albrecht, editors, *Proceedings of the NeurIPS
    2022 Competitions Track*, volume 220 of *Proceedings of Machine Learning Research*,
    pages 189–203\. PMLR, 28 Nov–09 Dec 2022b. URL [https://proceedings.mlr.press/v220/ramamonjison23a.html](https://proceedings.mlr.press/v220/ramamonjison23a.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. [2024] Xuhan Huang, Qingning Shen, Yan Hu, Anningzhe Gao, and
    Benyou Wang. Mamo: a mathematical modeling benchmark with solvers. *arXiv preprint
    arXiv:2405.13144*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DeepSeek-AI et al. [2024] DeepSeek-AI, Aixin Liu, Bei Feng, Bin Wang, Bingxuan
    Wang, Bo Liu, Chenggang Zhao, Chengqi Dengr, Chong Ruan, Damai Dai, Daya Guo,
    Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fuli Luo, Guangbo
    Hao, Guanting Chen, Guowei Li, H. Zhang, Hanwei Xu, Hao Yang, Haowei Zhang, Honghui
    Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J. L. Cai, Jian Liang, Jianzhong
    Guo, Jiaqi Ni, Jiashi Li, Jin Chen, Jingyang Yuan, Junjie Qiu, Junxiao Song, Kai
    Dong, Kaige Gao, Kang Guan, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao,
    Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang,
    Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qihao Zhu, Qinyu
    Chen, Qiushi Du, R. J. Chen, R. L. Jin, Ruiqi Ge, Ruizhe Pan, Runxin Xu, Ruyi
    Chen, S. S. Li, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng
    Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Size Zheng,
    T. Wang, Tian Pei, Tian Yuan, Tianyu Sun, W. L. Xiao, Wangding Zeng, Wei An, Wen
    Liu, Wenfeng Liang, Wenjun Gao, Wentao Zhang, X. Q. Li, Xiangyue Jin, Xianzu Wang,
    Xiao Bi, Xiaodong Liu, Xiaohan Wang, Xiaojin Shen, Xiaokang Chen, Xiaosha Chen,
    Xiaotao Nie, Xiaowen Sun, Xiaoxiang Wang, Xin Liu, Xin Xie, Xingkai Yu, Xinnan
    Song, Xinyi Zhou, Xinyu Yang, Xuan Lu, Xuecheng Su, Y. Wu, Y. K. Li, Y. X. Wei,
    Y. X. Zhu, Yanhong Xu, Yanping Huang, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Li,
    Yaohui Wang, Yi Zheng, Yichao Zhang, Yiliang Xiong, Yilong Zhao, Ying He, Ying
    Tang, Yishi Piao, Yixin Dong, Yixuan Tan, Yiyuan Liu, Yongji Wang, Yongqiang Guo,
    Yuchen Zhu, Yuduan Wang, Yuheng Zou, Yukun Zha, Yunxian Ma, Yuting Yan, Yuxiang
    You, Yuxuan Liu, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhen Huang, Zhen Zhang,
    Zhenda Xie, Zhewen Hao, Zhihong Shao, Zhiniu Wen, Zhipeng Xu, Zhongyu Zhang, Zhuoshu
    Li, Zihan Wang, Zihui Gu, Zilin Li, and Ziwei Xie. Deepseek-v2: A strong, economical,
    and efficient mixture-of-experts language model, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gómez-Rodríguez and Williams [2023] Carlos Gómez-Rodríguez and Paul Williams.
    A confederacy of models: A comprehensive evaluation of llms on creative writing.
    *arXiv preprint arXiv:2310.08433*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. [2024] Susan Lin, Jeremy Warner, JD Zamfirescu-Pereira, Matthew G
    Lee, Sauhard Jain, Shanqing Cai, Piyawat Lertvittayakumjorn, Michael Xuelin Huang,
    Shumin Zhai, Björn Hartmann, et al. Rambler: Supporting writing with speech via
    llm-assisted gist manipulation. In *Proceedings of the CHI Conference on Human
    Factors in Computing Systems*, pages 1–19, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. [2023b] Hui Huang, Shuangzhi Wu, Xinnian Liang, Bing Wang, Yanrui
    Shi, Peihao Wu, Muyun Yang, and Tiejun Zhao. Towards making the most of llm for
    translation quality estimation. In *CCF International Conference on Natural Language
    Processing and Chinese Computing*, pages 375–386\. Springer, 2023b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. [2024] Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen,
    Benjamin Van Durme, Kenton Murray, and Young Jin Kim. Contrastive preference optimization:
    Pushing the boundaries of llm performance in machine translation. *arXiv preprint
    arXiv:2401.08417*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bai et al. [2024] Yuyang Bai, Shangbin Feng, Vidhisha Balachandran, Zhaoxuan
    Tan, Shiqi Lou, Tianxing He, and Yulia Tsvetkov. Kgquiz: Evaluating the generalization
    of encoded knowledge in large language models. In *Proceedings of the ACM on Web
    Conference 2024*, pages 2226–2237, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fei et al. [2023] Zhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han,
    Songyang Zhang, Kai Chen, Zongwen Shen, and Jidong Ge. Lawbench: Benchmarking
    legal knowledge of large language models. *arXiv preprint arXiv:2309.16289*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rein et al. [2023] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson
    Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R Bowman.
    Gpqa: A graduate-level google-proof q&a benchmark. *arXiv preprint arXiv:2311.12022*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cui et al. [2019] Wanyun Cui, Yanghua Xiao, Haixun Wang, Yangqiu Song, Seung-won
    Hwang, and Wei Wang. Kbqa: learning question answering over qa corpora and knowledge
    bases. *arXiv preprint arXiv:1903.02419*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2023] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey
    of prompting methods in natural language processing. *ACM Comput. Surv.*, 55(9),
    jan 2023. ISSN 0360-0300. doi: 10.1145/3560815. URL [https://doi.org/10.1145/3560815](https://doi.org/10.1145/3560815).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wei et al. [2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. Chain-of-thought prompting
    elicits reasoning in large language models. In Sanmi Koyejo, S. Mohamed, A. Agarwal,
    Danielle Belgrave, K. Cho, and A. Oh, editors, *Advances in Neural Information
    Processing Systems 35: Annual Conference on Neural Information Processing Systems
    2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022*, 2022.
    URL [http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html](http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lewkowycz et al. [2022] Aitor Lewkowycz, Anders Johan Andreassen, David Dohan,
    Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil,
    Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and
    Vedant Misra. Solving quantitative reasoning problems with language models. In
    Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, *Advances
    in Neural Information Processing Systems*, 2022. URL [https://openreview.net/forum?id=IFXTZERXdM7](https://openreview.net/forum?id=IFXTZERXdM7).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tang et al. [2024] Zhengyang Tang, Chenyu Huang, Xin Zheng, Shixi Hu, Zizhuo
    Wang, Dongdong Ge, and Benyou Wang. Orlm: Training large language models for optimization
    modeling. *arXiv preprint arXiv:2405.17743*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. [2023] Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying
    Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. Metamath:
    Bootstrap your own mathematical questions for large language models. *arXiv preprint
    arXiv:2309.12284*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Yao [2024] Haoxiong Liu and Andrew Chi-Chih Yao. Augmenting math word
    problems via iterative question composing. *arXiv preprint arXiv:2401.09003*,
    2024.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2023] Chengpeng Li, Zheng Yuan, Guanting Dong, Keming Lu, Jiancan
    Wu, Chuanqi Tan, Xiang Wang, and Chang Zhou. Query and response augmentation cannot
    help out-of-domain math reasoning generalization. *arXiv preprint arXiv:2310.05506*,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. [2023] Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi
    Tan, and Chang Zhou. Scaling relationship on learning mathematical reasoning with
    large language models. *arXiv preprint arXiv:2308.01825*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. [2024] Zimu Lu, Aojun Zhou, Houxing Ren, Ke Wang, Weikang Shi, Junting
    Pan, Mingjie Zhan, and Hongsheng Li. Mathgenie: Generating synthetic data with
    question back-translation for enhancing mathematical reasoning of llms. *arXiv
    preprint arXiv:2402.16352*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yue et al. [2023] Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan
    Sun, Yu Su, and Wenhu Chen. Mammoth: Building math generalist models through hybrid
    instruction tuning. *arXiv preprint arXiv:2309.05653*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikipedia [2024] Wikipedia. Socratic method — Wikipedia, the free encyclopedia.
    [http://en.wikipedia.org/w/index.php?title=Socratic%20method&oldid=1224318017](http://en.wikipedia.org/w/index.php?title=Socratic%20method&oldid=1224318017),
    2024. [Online; accessed 31-May-2024].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qi et al. [2023] Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, Qifan
    Wang, and Lifu Huang. The art of SOCRATIC QUESTIONING: Recursive thinking with
    large language models. In Houda Bouamor, Juan Pino, and Kalika Bali, editors,
    *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*,
    pages 4177–4199, Singapore, December 2023\. Association for Computational Linguistics.
    doi: 10.18653/v1/2023.emnlp-main.255. URL [https://aclanthology.org/2023.emnlp-main.255](https://aclanthology.org/2023.emnlp-main.255).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chang [2023] Edward Y. Chang. Prompting large language models with the socratic
    method. In *13th IEEE Annual Computing and Communication Workshop and Conference,
    CCWC 2023, Las Vegas, NV, USA, March 8-11, 2023*, pages 351–360\. IEEE, 2023.
    doi: 10.1109/CCWC57344.2023.10099179. URL [https://doi.org/10.1109/CCWC57344.2023.10099179](https://doi.org/10.1109/CCWC57344.2023.10099179).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shridhar et al. [2022] Kumar Shridhar, Jakub Macina, Mennatallah El-Assady,
    Tanmay Sinha, Manu Kapur, and Mrinmaya Sachan. Automatic generation of socratic
    subquestions for teaching math word problems. In Yoav Goldberg, Zornitsa Kozareva,
    and Yue Zhang, editors, *Proceedings of the 2022 Conference on Empirical Methods
    in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December
    7-11, 2022*, pages 4136–4149\. Association for Computational Linguistics, 2022.
    doi: 10.18653/V1/2022.EMNLP-MAIN.277. URL [https://doi.org/10.18653/v1/2022.emnlp-main.277](https://doi.org/10.18653/v1/2022.emnlp-main.277).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeng et al. [2023] Andy Zeng, Maria Attarian, Brian Ichter, Krzysztof Marcin
    Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael S.
    Ryoo, Vikas Sindhwani, Johnny Lee, Vincent Vanhoucke, and Pete Florence. Socratic
    models: Composing zero-shot multimodal reasoning with language. In *The Eleventh
    International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda,
    May 1-5, 2023*. OpenReview.net, 2023. URL [https://openreview.net/pdf?id=G2Q2Mh3avow](https://openreview.net/pdf?id=G2Q2Mh3avow).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong et al. [2023] Qingxiu Dong, Li Dong, Ke Xu, Guangyan Zhou, Yaru Hao, Zhifang
    Sui, and Furu Wei. Large language model for science: A study on P vs. NP. *CoRR*,
    abs/2309.05689, 2023. doi: 10.48550/ARXIV.2309.05689. URL [https://doi.org/10.48550/arXiv.2309.05689](https://doi.org/10.48550/arXiv.2309.05689).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ang et al. [2023] Beng Heng Ang, Sujatha Das Gollapalli, and See-Kiong Ng.
    Socratic question generation: A novel dataset, models, and evaluation. In Andreas
    Vlachos and Isabelle Augenstein, editors, *Proceedings of the 17th Conference
    of the European Chapter of the Association for Computational Linguistics, EACL
    2023, Dubrovnik, Croatia, May 2-6, 2023*, pages 147–165\. Association for Computational
    Linguistics, 2023. doi: 10.18653/V1/2023.EACL-MAIN.12. URL [https://doi.org/10.18653/v1/2023.eacl-main.12](https://doi.org/10.18653/v1/2023.eacl-main.12).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bertsimas and Tsitsiklis [1997] Dimitris Bertsimas and John N Tsitsiklis. *Introduction
    to linear optimization*, volume 6. Athena Scientific Belmont, MA, 1997.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conforti et al. [2014] Michele Conforti, Gérard Cornuéjols, Giacomo Zambelli,
    Michele Conforti, Gérard Cornuéjols, and Giacomo Zambelli. *Integer programming
    models*. Springer, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wolsey [2020] Laurence A Wolsey. *Integer programming*. John Wiley & Sons, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. [2023] Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan
    Feng, Chongyang Tao, and Daxin Jiang. Wizardlm: Empowering large language models
    to follow complex instructions. *arXiv preprint arXiv:2304.12244*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: \resettocdepth
  prefs: []
  type: TYPE_NORMAL
- en: Appendix
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[1 Introduction](#S1 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[2 Related Work](#S2 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[3 E-OPT: Human-Readable Optimization Problems Benchmark](#S3 "In Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[4 ReSocratic: Reverse Socratic Data Synthesis](#S4 "In Benchmarking LLMs for
    Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[5 Experiments](#S5 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[5.1 Baselines and Setting](#S5.SS1 "In 5 Experiments ‣ Benchmarking LLMs for
    Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[5.2 Main Results](#S5.SS2 "In 5 Experiments ‣ Benchmarking LLMs for Optimization
    Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[5.3 Ablation Study on ReSocratic](#S5.SS3 "In 5 Experiments ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[5.4 Comparison between Reverse Synthesis and Forward Synthesis](#S5.SS4 "In
    5 Experiments ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[6 Conclusion](#S6 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[7 Limitations](#S7 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[A More Detail of ReSocratic](#A1 "In Benchmarking LLMs for Optimization Modeling
    and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[A.1 Scenario Pool](#A1.SS1 "In Appendix A More Detail of ReSocratic ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[A.2 Synthesizing Different Data Types](#A1.SS2 "In Appendix A More Detail
    of ReSocratic ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[B Analysis](#A2 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[B.1 Dataset Statistical Results](#A2.SS1 "In Appendix B Analysis ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[B.2 Analysis of SFT Data and Evaluation Results](#A2.SS2 "In Appendix B Analysis
    ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[B.2.1 Analysis of Zero-shot and Few-shot Evaluation Results on E-OPT](#A2.SS2.SSS1
    "In B.2 Analysis of SFT Data and Evaluation Results ‣ Appendix B Analysis ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[B.2.2 Analysis of ReSocratic-29k and SFT Results](#A2.SS2.SSS2 "In B.2 Analysis
    of SFT Data and Evaluation Results ‣ Appendix B Analysis ‣ Benchmarking LLMs for
    Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[C Benchmark and Dataset](#A3 "In Benchmarking LLMs for Optimization Modeling
    and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[C.1 Data Format](#A3.SS1 "In Appendix C Benchmark and Dataset ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[C.2 Datasheet of E-OPT](#A3.SS2 "In Appendix C Benchmark and Dataset ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[C.3 Datasheet of ReSocratic-29k](#A3.SS3 "In Appendix C Benchmark and Dataset
    ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[C.4 Data Hosting, Licensing, and Maintenance](#A3.SS4 "In Appendix C Benchmark
    and Dataset ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[D Limitations](#A4 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E All Prompts](#A5 "In Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.1 Prompts for Evaluation of E-OPT](#A5.SS1 "In Appendix E All Prompts ‣
    Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.1.1 Zero-Shot Prompt](#A5.SS1.SSS1 "In E.1 Prompts for Evaluation of E-OPT
    ‣ Appendix E All Prompts ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.1.2 Few-Shot Prompt](#A5.SS1.SSS2 "In E.1 Prompts for Evaluation of E-OPT
    ‣ Appendix E All Prompts ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.1.3 Results Extraction Prompt](#A5.SS1.SSS3 "In E.1 Prompts for Evaluation
    of E-OPT ‣ Appendix E All Prompts ‣ Benchmarking LLMs for Optimization Modeling
    and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.2 Prompts of ReSocratic](#A5.SS2 "In Appendix E All Prompts ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.2.1 Linear Scenario Generation](#A5.SS2.SSS1 "In E.2 Prompts of ReSocratic
    ‣ Appendix E All Prompts ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.2.2 Nonlinear Scenario Generation](#A5.SS2.SSS2 "In E.2 Prompts of ReSocratic
    ‣ Appendix E All Prompts ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.2.3 Question Generation](#A5.SS2.SSS3 "In E.2 Prompts of ReSocratic ‣ Appendix
    E All Prompts ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[E.2.4 Code Generation](#A5.SS2.SSS4 "In E.2 Prompts of ReSocratic ‣ Appendix
    E All Prompts ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis")'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Appendix A More Detail of ReSocratic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already shown the process of our synthesis method in our paper. This
    section adds more detail to our ReSocratic.
  prefs: []
  type: TYPE_NORMAL
- en: A.1 Scenario Pool
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We collect 27 elaborate scenarios (13 linear scenarios and 14 nonlinear scenarios)
    in the scenario pool. An example is shown in the following bellow.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)##  Define  Variables:Chip  Green  is  the  head  groundskeeper  at  Birdie  Valley  Golf  Club.  There  are  four  fertilizers  (Fertilizer  1-4)  available  in  the  market,  Chip  would  like  to  mix  them  together  to  obtain  a  mixture.  Chip  needs  to  determine  the  optimal  proportion  of  each  fertilizer  in  the  mixture.//  {"proportion  of  Fertilizer  1  in  the  compost":  "x1",  "range":  "0  <=  x1  <=  1",  "type":  "continuous"}//  {"proportion  of  Fertilizer  2  in  the  compost":  "x2",  "range":  "0  <=  x2  <=  1",  "type":  "continuous"}//  {"proportion  of  Fertilizer  3  in  the  compost":  "x3",  "range":  "0  <=  x3  <=  1",  "type":  "continuous"}//  {"proportion  of  Fertilizer  4  in  the  compost":  "x4",  "range":  "0  <=  x4  <=  1",  "type":  "continuous"}//  The  sum  of  the  proportions  should  be  1:  x1  +  x2  +  x3  +  x4  =  1##  Define  Objective  Function:The  price  of  Fertilizer  1-4  is  $21.75,  $23.75,  $22.00,  and  $19.50  per  100  pounds,  respectively.Chip  wants  to  minimize  the  cost  of  the  mixture  per  100  pounds.//  Minimize:  21.75*x1  +  23.75*x2  +  22.00*x3  +  19.50*x4##  Generate  Constraint-1:The  Nitrogen  percentage  of  Fertilizer  1-4  is  10%,  8%,  12%,  and  10%;the  Phosphorus  percentage  of  Fertilizer  1-4  is  8%,  11%,  7%,  and  10%;the  Potash  percentage  of  Fertilizer  1-4  is  12,  15%,  12%,  and  10%.Chip  knows  that  the  best  proportion  of  the  chemical  content  should  be  10-8-12  (10%  nitrogen,  8%  phosphorus,  and  12%  potash),  but  no  more  than  0.5%  above  them.  So  the  nitrogen  level  should  be  between  10%  and  10.5%;  the  phosphorus  level  should  be  between  8%  and  8.5%;  the  potash  level  should  be  between  12%  and  12.5%.//  10  <=  10*x1  +  8*x2  +  12*x3  +  10*x4  <=  10.5//  8  <=  8*x1  +  11*x2  +  7*x3  +  10*x4  <=  8.5//  12  <=  12*x1  +  15*x2  +  12*x3  +  10*x4  <=  12.5##  Generate  Constraint-2:The  mixture  should  contain  at  least  20%  Fertilizer  1.//  x1  >=  0.2'
  prefs: []
  type: TYPE_NORMAL
- en: We show some statistical results of our scenario pool in Figure [4](#A1.F4 "Figure
    4 ‣ A.1 Scenario Pool ‣ Appendix A More Detail of ReSocratic ‣ Benchmarking LLMs
    for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9792562433fb6d5fbea5dc512668fd7e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Statistical results of our scenario pool.'
  prefs: []
  type: TYPE_NORMAL
- en: We compare the distribution of the scenario with that of the composite data
    in section [5](#A2.F5 "Figure 5 ‣ B.1 Dataset Statistical Results ‣ Appendix B
    Analysis ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis"). The data distribution of our synthetic dataset
    ReSocratic-29k is similar to the data distribution in our scenario pool.
  prefs: []
  type: TYPE_NORMAL
- en: A.2 Synthesizing Different Data Types
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To facilitate the synthesis of different types of data (linear and nonlinear),
    we produce different prompts, which are shown in Section [E.2.1](#A5.SS2.SSS1
    "E.2.1 Linear Scenario Generation ‣ E.2 Prompts of ReSocratic ‣ Appendix E All
    Prompts ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis") and Section [E.2.2](#A5.SS2.SSS2 "E.2.2 Nonlinear
    Scenario Generation ‣ E.2 Prompts of ReSocratic ‣ Appendix E All Prompts ‣ Benchmarking
    LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis").
    In addition, in the back-translate stage, to get the question text with a table
    and the question text without a table, we construct two different back-translation
    prompts, as shown in Section [E.2.3](#A5.SS2.SSS3 "E.2.3 Question Generation ‣
    E.2 Prompts of ReSocratic ‣ Appendix E All Prompts ‣ Benchmarking LLMs for Optimization
    Modeling and Enhancing Reasoning via Reverse Socratic Synthesis").
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: B.1 Dataset Statistical Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For E-OPT: We already show some statistical results of the distribution of
    the data types in our paper. In this section, we further show more statistical
    results of our E-OPT benchmark in question length and the number of variables.
    The question length refers to the number of characters in the question text. The
    results are shown in the following Figure [5](#A2.F5 "Figure 5 ‣ B.1 Dataset Statistical
    Results ‣ Appendix B Analysis ‣ Benchmarking LLMs for Optimization Modeling and
    Enhancing Reasoning via Reverse Socratic Synthesis"). The distribution of the
    number of variables involved in our E-OPT is similar to the long-tail distribution,
    with more variables, the smaller the sample size. So is the distribution of the
    question length.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0420a0ea2603cde4ca85527d5baec9d0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Statistical results of E-OPT'
  prefs: []
  type: TYPE_NORMAL
- en: For ReSocratic-29k We show the distribution of each type (linear-notable, linear-table,
    nonlinear-notable, nonlinear-table,) of synthetic data along with the distribution
    of question length and the number of variables in Figure [6](#A2.F6 "Figure 6
    ‣ B.1 Dataset Statistical Results ‣ Appendix B Analysis ‣ Benchmarking LLMs for
    Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis").
    The distribution of our synthesized dataset ReSocratic-29k is slightly different
    from the distribution of E-OPT. First, our data types are more balanced. In addition,
    we generate less data with variables less than or equal to 2, because there is
    only a small proportion (3/27) of samples in our scenario pool with variables
    less than or equal to 2\. The distribution of the length of the problem text we
    generate is also not a long-tail distribution. Overall, the distribution of our
    synthesized data is similar to that of the data in the scenario pool.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3aa1a7df81306e2a539d1d8e42cedd65.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Statistical results of ReSocratic-29k'
  prefs: []
  type: TYPE_NORMAL
- en: B.2 Analysis of SFT Data and Evaluation Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: B.2.1 Analysis of Zero-shot and Few-shot Evaluation Results on E-OPT
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The relationship between accuracy and the number of variables. We show the evaluation
    results of Zero-shot and Few-shot setting for GPT-4 and GPT-3.5-Turbo in Figure
    [7](#A2.F7 "Figure 7 ‣ B.2.1 Analysis of Zero-shot and Few-shot Evaluation Results
    on E-OPT ‣ B.2 Analysis of SFT Data and Evaluation Results ‣ Appendix B Analysis
    ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis"). We show the accuracy of E-OPT split by data type, number
    of variables, and question length.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/77be99821281a9874e8c1508d93fa515.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Analysis of zero-shot results of GPT-4 and GPT-3.5-Turbo.'
  prefs: []
  type: TYPE_NORMAL
- en: The relationship between accuracy and the length of question text. We show the
    evaluation results of Zero-shot and Few-shot settings for GPT-4 and GPT-3.5-Turbo
    in Figure [8](#A2.F8 "Figure 8 ‣ B.2.1 Analysis of Zero-shot and Few-shot Evaluation
    Results on E-OPT ‣ B.2 Analysis of SFT Data and Evaluation Results ‣ Appendix
    B Analysis ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/13c530d06ee05851146b8f4775b88687.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Analysis of few-shot results of GPT-4 and GPT-3.5-Turbo.'
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the evaluation results on E-OPT, we can find that:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-3.5-Turbo is less accurate on the questions with a higher number of variables
    and longer question length, regardless of the zero-shot or few-shot Setting. However,
    the performance of the GPT-4 is more balanced compared to the GPT-3.5-turbo.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, we find from the experimental results that for the LLMs we tested,
    it is more difficult to solve table questions than no-table questions, and nonlinear
    questions are more difficult than linear questions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: B.2.2 Analysis of ReSocratic-29k and SFT Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We use the bert-base-uncased model to vectorize question text in E-OPT benchmark
    and ReSocratic-29k. The embedding of the question text is calculated by averaging
    the output of the last layer transformer. Next, we use the t-SNE algorithm to
    reduce the dimension of the embedding of the question texts for each type of data
    (linear-notable, linear-table, nonlinear-notable, nonlinear-table). The visualization
    is shown in Figure [9](#A2.F9 "Figure 9 ‣ B.2.2 Analysis of ReSocratic-29k and
    SFT Results ‣ B.2 Analysis of SFT Data and Evaluation Results ‣ Appendix B Analysis
    ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse
    Socratic Synthesis").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5b834dd107979824a18b7f0211fd6faf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Visualization of the question texts in E-OPT benchmark and ReSocratic-29k
    using t-SNE.'
  prefs: []
  type: TYPE_NORMAL
- en: In the Experiments Section of our paper, we find that after fine-tuning with
    our ReSocratic-29k, the accuracy of Llama3-8B-Instruct and Llama2-7B-Chat on nonlinear-table
    data exceeded the nonlinear-notable table. This is different from our observation
    that "table questions are more difficult than no-table questions".
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/92ba7ed80a9094901beab510745072fc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: The cosine similarity of the question text embedding between synthetic
    data and test dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As can be seen in Figure [9](#A2.F9 "Figure 9 ‣ B.2.2 Analysis of ReSocratic-29k
    and SFT Results ‣ B.2 Analysis of SFT Data and Evaluation Results ‣ Appendix B
    Analysis ‣ Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning
    via Reverse Socratic Synthesis"), this is due to the deviation between the distribution
    of our synthetic data ReSocratic-29k and the distribution of E-OPT test data.
    In order to quantify the deviation between the synthesized data and the E-OPT
    test data, we calculate the embedding similarity score of each type of problem
    text. The calculation process is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $s={\rm mean}({\rm cos}(f_{i},f_{j})),i\in\texttt{E-OPT},j\in\texttt{ReSocratic-29k}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: The similarity score is shown in Figure [10](#A2.F10 "Figure 10 ‣ B.2.2 Analysis
    of ReSocratic-29k and SFT Results ‣ B.2 Analysis of SFT Data and Evaluation Results
    ‣ Appendix B Analysis ‣ Benchmarking LLMs for Optimization Modeling and Enhancing
    Reasoning via Reverse Socratic Synthesis"). The nonlinear-table synthetic data
    has the greatest similarity to test data, but nonlinear-notable synthetic data
    has the least similarity to test data. We believe that this is the reason for
    the fluctuations in the performance of fine-tuned small models (Llama-2-7B-Chat
    and Llama-3-8B-Instruct). Our synthesized nonlinear data is closer to the table
    questions of the nonlinear part in E-OPT and deviates far from the no-table data
    of the nonlinear part in E-OPT.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Benchmark and Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our code and data are released on [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic).
  prefs: []
  type: TYPE_NORMAL
- en: C.1 Data Format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data Format of E-OPT.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We store E-OPT data in the form of JSON files. A sample of our E-OPT benchmark
    is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,ewogICAgInF1ZXN0aW9uIjogIkEgcmVjdGFuZ3VsYXIgZ2FyZGVuIGlzIHRvIGJlIGNvbnN0cnVjdGVkIHVzaW5nIGEgcm9jayB3YWxsIGFzIG9uZSBzaWRlIG9mIHRoZSBnYXJkZW4gYW5kIHdpcmUgZmVuY2luZyBmb3IgdGhlIG90aGVyIHRocmVlIHNpZGVzLiBHaXZlbiAxMDBmdCBvZiB3aXJlIGZlbmNpbmcsIGRldGVybWluZSB0aGUgZGltZW5zaW9ucyB0aGF0IHdvdWxkIGNyZWF0ZSBhIGdhcmRlbiBvZiBtYXhpbXVtIGFyZWEuIFdoYXQgaXMgdGhlIG1heGltdW0gYXJlYT8iLAogICAgInJlc3VsdHMiOiB7CiAgICAgICAgIlRoZSBsZW5ndGggb2YgdGhlIGdhcmRlbiI6ICI1MC4wIiwKICAgICAgICAiVGhlIHdpZHRoIG9mIHRoZSBnYXJkZW4iOiAiMjUuMCIsCiAgICAgICAgIlRoZSBtYXhpbXVtIGFyZWEgb2YgdGhlIGdhcmRlbiI6ICIxMjUwLjAiCiAgICB9LAogICAgInR5cGUiOiAibm9ubGluZWFyLW5vdGFibGUiLAogICAgImluZGV4IjogMwp9){"question":  "A  rectangular  garden  is  to  be  constructed  using  a  rock  wall  as  one  side  of  the  garden  and  wire  fencing  for  the  other  three  sides.  Given  100ft  of  wire  fencing,  determine  the  dimensions  that  would  create  a  garden  of  maximum  area.  What  is  the  maximum  area?","results":  {"The  length  of  the  garden":  "50.0","The  width  of  the  garden":  "25.0","The  maximum  area  of  the  garden":  "1250.0"},"type":  "nonlinear-notable","index":  3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'We construct samples in dictionary format, and all the data is stored as a
    list in a JSON file. Each sample has the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“question”: The question text, presented in natural language, contains the
    background as well as the optimization objective and associated constraints. In
    order to solve the question, it is necessary to first find out the variables that
    can be optimized, then build a mathematical model, and then call a code solver
    to get the optimal numerical results of the variables and objective.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“results”: This field is presented in the form of a dictionary, where the key
    is the natural language description of the variables and objectives, followed
    by their optimal values. During the annotation process, if the taggers cannot
    confirm that there is only one optimal solution to the problem, the results only
    contain the description of the optimization objective and its optimal value.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“type”: This field records the type of the current sample, and there are four
    types: linear-table, linear-notable, non-linear-table, and nonlinear-notable.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“index”: The index of the sample.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Data Format of ReSocratic-29k.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We show a sample of our ReSocratic-29k in the following bellow.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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){"question":  "A  logistics  company  operates  four  different  routes  for  delivering  packages.  They  need  to  determine  the  number  of  trucks  to  allocate  to  each  route  to  optimize  their  operations.  Each  route  has  a  different  cost  and  revenue  structure.  On  route  1,  each  truck  incurs  a  cost  of  $100  per  day  and  generates  a  revenue  of  $150  per  day.  On  route  2,  each  truck  incurs  a  cost  of  $120  per  day  and  generates  a  revenue  of  $180  per  day.  On  route  3,  each  truck  incurs  a  cost  of  $140  per  day  and  generates  a  revenue  of  $210  per  day.  On  route  4,  each  truck  incurs  a  cost  of  $160  per  day  and  generates  a  revenue  of  $240  per  day.  The  company  aims  to  maximize  the  total  daily  profit  across  all  routes.  The  company  has  a  total  of  50  trucks  available.  Please  help  the  company  to  determine  the  optimal  allocation  of  trucks  to  each  route.","code_solution":  "import  math\nimport  pyscipopt\n\n#  Create  a  new  model\nmodel  =  pyscipopt.Model()\n\n#  Define  variables\nT1  =  model.addVar(vtype=\"INTEGER\",  name=\"T1\",  lb=0)  #  number  of  trucks  on  route  1\nT2  =  model.addVar(vtype=\"INTEGER\",  name=\"T2\",  lb=0)  #  number  of  trucks  on  route  2\nT3  =  model.addVar(vtype=\"INTEGER\",  name=\"T3\",  lb=0)  #  number  of  trucks  on  route  3\nT4  =  model.addVar(vtype=\"INTEGER\",  name=\"T4\",  lb=0)  #  number  of  trucks  on  route  4\n\n#  Define  objective  function\nProfit_route1  =  150  *  T1  -  100  *  T1\nProfit_route2  =  180  *  T2  -  120  *  T2\nProfit_route3  =  210  *  T3  -  140  *  T3\nProfit_route4  =  240  *  T4  -  160  *  T4\n#  So,  the  objective  function  is:  Maximize  (Profit_route1  +  Profit_route2  +  Profit_route3  +  Profit_route4)\nobj  =  model.addVar(’obj’)\nmodel.setObjective(obj,  \"maximize\")\nmodel.addCons(obj  ==  Profit_route1  +  Profit_route2  +  Profit_route3  +  Profit_route4)\n\n#  Add  constraints\n#  The  company  has  a  total  of  50  trucks  available.\nmodel.addCons(T1  +  T2  +  T3  +  T4  <=  50)\n\n#  Solve  the  problem\nmodel.optimize()\n\n#  Print  the  optimal  solution  (value  of  the  variables  &  the  objective)\nprint(’-’*10)\nif  model.getStatus()  ==  \"optimal\":\n  print(\"Number  of  Trucks  on  Route  1:  \",  model.getVal(T1))\n  print(\"Number  of  Trucks  on  Route  2:  \",  model.getVal(T2))\n  print(\"Number  of  Trucks  on  Route  3:  \",  model.getVal(T3))\n  print(\"Number  of  Trucks  on  Route  4:  \",  model.getVal(T4))\n  print(\"Maximized  Total  Daily  Profit:  \",  model.getObjVal())\nelse:\n  print(\"The  problem  could  not  be  solved  to  optimality.\")\n"}'
  prefs: []
  type: TYPE_NORMAL
- en: 'We construct samples in dictionary format, and all the data is stored as a
    list in a JSON file. Each sample has the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“question”: The question text, presented in natural language, contains the
    background as well as the optimization objective and associated constraints. In
    order to solve the question, it is necessary to first find out the variables that
    can be optimized, then build a mathematical model, and then call code solver to
    get the optimal numerical results of the variables and objective.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“code_solution”: The corresponding python code to solve the question.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C.2 Datasheet of E-OPT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We present a datasheet for documentation and responsible usage of E-OPT Benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For what purpose was the dataset created? It was created as a benchmark for
    evaluating LLM’s end-to-end solving ability for optimization modeling. The “end-to-end”
    refers to a measurement approach of text in and numerical values out.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who created the dataset (e.g., which team, research group) and on behalf of
    which entity (e.g., company, institution, organization)? It was created by the
    authors of this paper.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who funded the creation of the dataset? If the paper is accepted, we will point
    this out in our acknowledgments.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Composition.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What do the instances that comprise the dataset represent (e.g., documents,
    photos, people, countries)? The dataset consists of questions, solution results
    (natural language descriptions of variables and objective, and their corresponding
    optimal numerical values), question type, and its index.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many instances are there in total (of each type, if appropriate)? There
    are 605 samples in the E-OPT benchmark. Specifically, we have four categories
    of data, of which nonlinear-notable has 133, nonlinear-table has 50, linear-notable
    has 342, and linear-table has 80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the dataset contain all possible instances or is it a sample (not necessarily
    random) of instances from a larger set? The dataset is collected by collecting
    questions from text-books, exercises, and examinations in Universities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What data does each instance consist of? The solution “results” of each sample
    are obtained by coding and solving by annotators with higher education background.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are relationships between individual instances made explicit? The data instances
    are collected one by one by workers and categorized according to their types.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there recommended data splits? Yes, we recommend four data splits according
    to the data type.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there any errors, sources of noise, or redundancies in the dataset? The
    solution results of each sample are cross-verified by at least two annotators.
    That is, when all the annotators of a sample can reach a consistent solution,
    we will adopt the data; otherwise, we discard the sample.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the dataset self-contained, or does it link to or otherwise rely on external
    resources (e.g., websites, tweets, other datasets)? The dataset is self-contained.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the dataset contain data that might be considered confidential (e.g., data
    that is protected by legal privilege or by doctor-patient confidentiality, data
    that includes the content of individuals’ non-public communications)? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the dataset contain data that, if viewed directly, might be offensive,
    insulting, threatening, or might otherwise cause anxiety? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Collection Process.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How was the data associated with each instance acquired? The data is directly
    observable by opening the JSON file in any Integrated Development Environment
    (IDE).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What mechanisms or procedures were used to collect the data (e.g., hardware
    apparatuses or sensors, manual human curation, software programs, software APIs)?
    We assign workers to collect the question text and write code to solve those questions,
    finally the solution results (numerical values of variables and objective) are
    saved.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who was involved in the data collection process (e.g., students, crowd workers,
    contractors), and how were they compensated (e.g., how much were crowd workers
    paid)? We hired six college students with a good knowledge of math and code fundamentals
    to collect and annotate the data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over what timeframe was the data collected? The final version of the dataset
    was collected in April 2024.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Uses.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Has the dataset been used for any tasks already? An initial subset of E-OPT
    benchmark is used in April 2024 as a contest track [(https://www.codabench.org/competitions/2438/)](https://www.codabench.org/competitions/2438/)
    of ICML 2024 Challenge on Automated Math Reasoning [(https://sites.google.com/view/ai4mathworkshopicml2024/challenges)](https://sites.google.com/view/ai4mathworkshopicml2024/challenges).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a repository that links to any or all papers or systems that use the
    dataset? Yes, we show the our github repo [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic),
    the ICML 2024 workshop [(https://sites.google.com/view/ai4mathworkshopicml2024)](https://sites.google.com/view/ai4mathworkshopicml2024),
    and the ICML 2024 Challenges on Automated Math Reasoning [(https://www.codabench.org/competitions/2438/)](https://www.codabench.org/competitions/2438/).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Distribution.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the dataset be distributed to third parties outside of the entity (e.g.,
    company, institution, organization) on behalf of which the dataset was created?
    Yes, the dataset is publicly available on the Internet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will the dataset be distributed (e.g., tarball on website, API, GitHub)?
    The dataset can be downloaded on the github repo [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the dataset be distributed under a copyright or other intellectual property
    (IP) license, and/or under applicable terms of use (ToU)? The dataset is distributed
    under CC BY 2.0.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have any third parties imposed IP-based or other restrictions on the data associated
    with the instances? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do any export controls or other regulatory restrictions apply to the dataset
    or to individual instances? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Maintenance.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who will be supporting/hosting/maintaining the dataset? The authors of this
    paper.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can the owner/curator/manager of the dataset be contacted (e.g., email address)?
    Please contact Zhicheng Yang at yangzhch6@gmail.com.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there an erratum? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the dataset be updated (e.g., to correct labeling errors, add new instances,
    delete instances)? Please check [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic)
    for any update.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If others want to extend/augment/build on/contribute to the dataset, is there
    a mechanism for them to do so? Yes, they can directly contact us through the github
    and email.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C.3 Datasheet of ReSocratic-29k
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We present a datasheet for documentation and responsible usage of E-OPT Benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: Motivation.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For what purpose was the dataset created? It was created as a dataset to fine-tune
    LLMs for optimization problem solving.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who created the dataset (e.g., which team, research group) and on behalf of
    which entity (e.g., company, institution, organization)? It was created by the
    authors of this paper.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who funded the creation of the dataset? If the paper is accepted, we will point
    this out in our acknowledgments.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Composition.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What do the instances that comprise the dataset represent (e.g., documents,
    photos, people, countries)? The dataset consists of optimization questions and
    its corresponding code solutions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many instances are there in total (of each type, if appropriate)? There
    are 29164 samples in the ReSocratic-29k dataset. Specifically, we have four categories
    of data, of which nonlinear-notable has 7044 samples, nonlinear-table has 4376
    samples, linear-notable has 9286 samples, and linear-table has 8458 samples.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the dataset contain all possible instances or is it a sample (not necessarily
    random) of instances from a larger set? The dataset is a synthetic dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What data does each instance consist of? Each instance consists of a question
    text and its code solution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are relationships between individual instances made explicit? The data instances
    are synthesized by Deepseek-V2-Chat.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there recommended data splits? No
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there any errors, sources of noise, or redundancies in the dataset? This
    dataset is synthesized by an LLM, so there is some noise in it. We measure the
    data noise to some extent in the paper.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the dataset self-contained, or does it link to or otherwise rely on external
    resources (e.g., websites, tweets, other datasets)? The dataset is self-contained.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the dataset contain data that might be considered confidential (e.g., data
    that is protected by legal privilege or by doctor-patient confidentiality, data
    that includes the content of individuals’ non-public communications)? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the dataset contain data that, if viewed directly, might be offensive,
    insulting, threatening, or might otherwise cause anxiety? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Collection Process.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How was the data associated with each instance acquired? The data is directly
    observable by opening the JSON file in any Integrated Development Environment
    (IDE).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What mechanisms or procedures were used to collect the data (e.g., hardware
    apparatuses or sensors, manual human curation, software programs, software APIs)?
    We synthesize the data using our proposed ReSocratic with Deepseek-V2-Chat.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who was involved in the data collection process (e.g., students, crowd workers,
    contractors), and how were they compensated (e.g., how much were crowd workers
    paid)? We didn’t hire anyone, we just used Deepseek-V2-Chat, an open source LLM.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Over what timeframe was the data collected? The final version of the dataset
    was collected in April 2024.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Uses.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Has the dataset been used for any tasks already? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a repository that links to any or all papers or systems that use the
    dataset? Yes, we show the github repo [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic),
    the ICML 2024 workshop [https://sites.google.com/view/ai4mathworkshopicml2024](https://sites.google.com/view/ai4mathworkshopicml2024),
    and the ICML 2024 Challenges on Automated Math Reasoning [(https://www.codabench.org/competitions/2438/)](https://www.codabench.org/competitions/2438/).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Distribution.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the dataset be distributed to third parties outside of the entity (e.g.,
    company, institution, organization) on behalf of which the dataset was created?
    Yes, the dataset is publicly available on the Internet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will the dataset be distributed (e.g., tarball on website, API, GitHub)?
    The dataset can be downloaded on the github repo [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the dataset be distributed under a copyright or other intellectual property
    (IP) license, and/or under applicable terms of use (ToU)? The dataset is distributed
    under CC BY 2.0.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have any third parties imposed IP-based or other restrictions on the data associated
    with the instances? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do any export controls or other regulatory restrictions apply to the dataset
    or to individual instances? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Maintenance.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who will be supporting/hosting/maintaining the dataset? The authors of this
    paper.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can the owner/curator/manager of the dataset be contacted (e.g., email address)?
    Please contact Zhicheng Yang at yangzhch6@gmail.com.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there an erratum? No.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the dataset be updated (e.g., to correct labeling errors, add new instances,
    delete instances)? Please check [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic)
    for any update.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If others want to extend/augment/build on/contribute to the dataset, is there
    a mechanism for them to do so? Yes, they can directly contact us through the github
    and email.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C.4 Data Hosting, Licensing, and Maintenance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The dataset and code of E-OPT Benchmark and ReSocratic-29k dataset is distributed
    under the CC BY 2.0 license. The data is hosted on [https://github.com/yangzhch6/ReSocratic](https://github.com/yangzhch6/ReSocratic)
    (a long-term data repository). The code is also released at the github repo under
    the MIT license.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Due to financial and human resource constraints, we were unable to collect and
    annotate a larger-scale test dataset. In addition, as we discussed in Section
    [B.2.2](#A2.SS2.SSS2 "B.2.2 Analysis of ReSocratic-29k and SFT Results ‣ B.2 Analysis
    of SFT Data and Evaluation Results ‣ Appendix B Analysis ‣ Benchmarking LLMs for
    Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis"),
    due to the lack of scenario samples, there is some deviation between our synthesized
    data ReSocratic-29k and the benchmark data E-OPT. In the future, we will add more
    diverse scenario samples for data synthesis. We will also explore the application
    of the language model self-refine mechanism to data synthesis to generate more
    accurate data. Due to computational resource limitations, we only explored the
    application of the ReSocratic method to optimization problems. In the future,
    we plan to extend ReSocratic to other complex reasoning tasks such as math word
    problem solving, and evaluate more large language models on our proposed E-OPT
    benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E All Prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We show all the prompts we used in this section.
  prefs: []
  type: TYPE_NORMAL
- en: E.1 Prompts for Evaluation of E-OPT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: E.1.1 Zero-Shot Prompt
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '“system”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIHVzZSBweXRob24gY29kZSB0byBzb2x2ZSB0aGUgZ2l2ZW4gcXVlc3Rpb24uCg==)1Please  use  python  code  to  solve  the  given  question.'
  prefs: []
  type: TYPE_NORMAL
- en: '“user”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,W0NvZGUgVGVtcGxhdGVdOgpgYGBweXRob24KaW1wb3J0IG1hdGgKaW1wb3J0IHB5c2NpcG9wdAoKIyBDcmVhdGUgYSBuZXcgbW9kZWwKbW9kZWwgPSBweXNjaXBvcHQuTW9kZWwoKQoKIyBEZWZpbmUgdmFyaWFibGVzCi4uLgoKIyBEZWZpbmUgb2JqZWN0aXZlIGZ1bmN0aW9uCiMjIHNldCBvYmplY3RpdmUgYXMgYSB2YXJpYWJsZSAocHlzY2lwb3B0IGRvZXMgbm90IHN1cHBvcnQgbm9uLWxpbmVhciBvYmplY3RpdmUpCm9iaiA9IG1vZGVsLmFkZFZhcignb2JqJykKbW9kZWwuc2V0T2JqZWN0aXZlKG9iaiwgIi4uLiIpICMgIm1heGltaXplIiBvciAibWluaW1pemUiCm1vZGVsLmFkZENvbnMob2JqID09IC4uLikgIyBvYmogZnVuY3Rpb24gYXMgYSBjb25zdHJhaW50CgojIEFkZCBjb25zdHJhaW50cwouLi4KCiMgU29sdmUgdGhlIHByb2JsZW0KbW9kZWwub3B0aW1pemUoKQoKIyBQcmludCB0aGUgb3B0aW1hbCBzb2x1dGlvbiAodmFsdWUgb2YgdGhlIHZhcmlhYmxlcyAmIHRoZSBvYmplY3RpdmUpCnByaW50KCctJyoxMCkKaWYgbW9kZWwuZ2V0U3RhdHVzKCkgPT0gIm9wdGltYWwiOgogICAgLi4uCmVsc2U6CiAgICBwcmludCgiVGhlIHByb2JsZW0gY291bGQgbm90IGJlIHNvbHZlZCB0byBvcHRpbWFsaXR5LiIpCmBgYAoKW0ZvbGxvdyB0aGUgY29kZSB0ZW1wbGF0ZSB0byBzb2x2ZSB0aGUgZ2l2ZW4gcXVlc3Rpb24sIHlvdXIgY29kZSBzaG91bGQgYmUgZW5jbG9zZWQgaW4gYGBgcHl0aG9uXG57fWBgYF06CmBgYHF1ZXN0aW9uCjwuLi4gQSB0ZXN0aW5nIHF1ZXN0aW9uIGhlcmUgLi4uPgpgYGAK)[Code  Template]:‘‘‘pythonimport  mathimport  pyscipopt#  Create  a  new  modelmodel  =  pyscipopt.Model()#  Define  variables...#  Define  objective  function##  set  objective  as  a  variable  (pyscipopt  does  not  support  non-linear  objective)obj  =  model.addVar(’obj’)model.setObjective(obj,  "...")  #  "maximize"  or  "minimize"model.addCons(obj  ==  ...)  #  obj  function  as  a  constraint#  Add  constraints...#  Solve  the  problemmodel.optimize()#  Print  the  optimal  solution  (value  of  the  variables  &  the  objective)print(’-’*10)if  model.getStatus()  ==  "optimal":...else:print("The  problem  could  not  be  solved  to  optimality.")‘‘‘[Follow  the  code  template  to  solve  the  given  question,  your  code  should  be  enclosed  in  ‘‘‘python\n{}‘‘‘]:‘‘‘question<...  A  testing  question  here  ...>‘‘‘'
  prefs: []
  type: TYPE_NORMAL
- en: E.1.2 Few-Shot Prompt
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '“system”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIGZvbGxvdyB0aGUgZ2l2ZW4gZXhhbXBsZXMgYW5kIHVzZSBweXRob24gY29kZSB0byBzb2x2ZSB0aGUgZ2l2ZW4gcXVlc3Rpb24u)1Please  follow  the  given  examples  and  use  python  code  to  solve  the  given  question.'
  prefs: []
  type: TYPE_NORMAL
- en: '“user”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)[Example-1]:‘‘‘questionA  bakery  specializes  in  producing  two  types  of  cakes:  chocolate  and  vanilla.  The  bakery  needs  to  decide  how  many  of  each  type  of  cake  to  produce  daily  to  maximize  profit  while  considering  the  availability  of  ingredients  and  the  minimum  daily  production  requirement.  The  profit  from  each  chocolate  cake  is  $5,  and  from  each  vanilla  cake  is  $4.  The  bakery  aims  to  maximize  its  daily  profit  from  cake  sales.  Each  chocolate  cake  requires  2  eggs,  and  each  vanilla  cake  requires  1  egg.  The  bakery  has  a  daily  supply  of  100  eggs.  Please  help  the  bakery  determine  the  optimal  number  of  chocolate  and  vanilla  cakes  to  produce  daily.‘‘‘‘‘‘pythonimport  mathimport  pyscipopt#  Create  a  new  modelmodel  =  pyscipopt.Model()#  Define  variables##  The  number  of  each  type  of  cake  to  produce  dailyChoc  =  model.addVar(vtype="INTEGER",  name="Choc",  lb=0)  #  number  of  chocolate  cakesVan  =  model.addVar(vtype="INTEGER",  name="Van",  lb=0)  #  number  of  vanilla  cakes#  Define  objective  function##  set  objective  as  a  variableobj  =  model.addVar(’obj’)model.setObjective(obj,  "maximize")model.addCons(obj  ==  5*Choc  +  4*Van)#  Add  constraints##  Each  chocolate  cake  requires  2  eggs,  and  each  vanilla  cake  requires  1  egg.  The  bakery  has  a  daily  supply  of  100  eggs.model.addCons(2*Choc  +  Van  <=  100)#  Solve  the  problemmodel.optimize()#  Print  the  optimal  solution  (value  of  the  variables  &  the  objective)print(’-’*10)if  model.getStatus()  ==  "optimal":print("Number  of  chocolate  cakes:  ",  model.getVal(Choc))print("Number  of  vanilla  cakes:  ",  model.getVal(Van))print("Maximized  Daily  Profit:  ",  model.getObjVal())else:print("The  problem  could  not  be  solved  to  optimality.")‘‘‘[Example-2]:‘‘‘questionA  company  produces  three  types  of  widgets:  X,  Y,  and  Z.  The  company  needs  to  determine  how  many  units  of  each  widget  to  produce  in  next  week.For  Widget  X,  the  selling  price  is  10$,  the  material  cost  is  5$,  and  the  production  time  is  2  hours.For  Widget  Y,  the  selling  price  is  15$,  the  material  cost  is  7$,  and  the  production  time  is  3  hours.For  Widget  Z,  the  selling  price  is  20$,  the  material  cost  is  9$,  and  the  production  time  is  4  hours.The  company  has  $500  available  for  material  costs  next  week.  The  company  wants  to  produce  at  least  10  units  of  each  widget  next  week.  The  company  wants  to  spend  at  most  200  hours  on  production  next  week.  The  company  has  only  one  production  line  and  can  only  produce  one  widget  at  a  time.  Please  help  the  company  to  maximize  the  rate  at  which  it  earns  profits  (which  is  defined  as  the  sum  of  the  selling  profit  divided  by  the  sum  of  the  production  times).‘‘‘‘‘‘pythonimport  mathimport  pyscipopt#  Create  a  new  modelmodel  =  pyscipopt.Model()#  Define  variables##  The  company  wants  to  produce  at  least  10  units  of  each  widget  next  week.X  =  model.addVar(vtype="INTEGER",  name="X",  lb=10)  #  number  of  units  of  widget  XY  =  model.addVar(vtype="INTEGER",  name="Y",  lb=10)  #  number  of  units  of  widget  YZ  =  model.addVar(vtype="INTEGER",  name="Z",  lb=10)  #  number  of  units  of  widget  Z#  Define  objective  function##  set  objective  as  a  variable  (pyscipopt  does  not  support  non-linear  objective)obj  =  model.addVar(’obj’)model.setObjective(obj,  "maximize")Profit_X  =  (10  -  5)  *  XProfit_Y  =  (15  -  7)  *  YProfit_Z  =  (20  -  9)  *  ZProductionTime  =  2  *  X  +  3  *  Y  +  4  *  Z##  the  objective  function  is:  Maximize  (Profit_X  +  Profit_Y  +  Profit_Z)  /  ProductionTime##  convert  the  division  to  multiplicationmodel.addCons(obj  *  ProductionTime  ==  Profit_X  +  Profit_Y  +  Profit_Z)#  Add  constraints##  The  company  has  $500  available  for  material  costs  next  week.model.addCons(5  *  X  +  7  *  Y  +  9  *  Z  <=  500)##  The  company  wants  to  spend  at  most  200  hours  on  production  next  week.model.addCons(2  *  X  +  3  *  Y  +  4  *  Z  <=  200)#  Solve  the  problemmodel.optimize()#  Print  the  optimal  solution  (value  of  the  variables  &  the  objective)print(’-’*10)if  model.getStatus()  ==  "optimal":print("Number  of  Widget  X:  ",  model.getVal(X))print("Number  of  Widget  Y:  ",  model.getVal(Y))print("Number  of  Widget  Z:  ",  model.getVal(Z))print("Maximized  Profit  Rate:  ",  model.getObjVal())else:print("The  problem  could  not  be  solved  to  optimality.")‘‘‘[Follow  the  examples  to  solve  the  given  question]:‘‘‘question<...  A  testing  question  here  ...>‘‘‘'
  prefs: []
  type: TYPE_NORMAL
- en: E.1.3 Results Extraction Prompt
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,YGBgcHl0aG9uCjwuLi4gc29sdXRpb24gY29kZSBnZW5lcmF0ZWQgYnkgdGhlIExMTSAuLi4+CmBgYAoKYGBgY29kZSBvdXRwdXQKPC4uLiBjb2RlIGV4ZWN1dGlvbiByZXN1bHQgLi4uPgpgYGAKCkFjY29kaW5nIHRvIHRoZSBjb2RlIG91dHB1dCwgcGxlYXNlIGdpdmUgeW91ciBmaW5hbCBhbnN3ZXIgZm9yIHRoZSBmb2xsb3dpbmcgcXVlcnkuIChUaGUgYW5zd2VyIHNob3VsZCBiZSBib3hlZCBpbiAnXFxib3hlZHt9JywgYW5kIG9ubHkgaW4gbnVtZXJpY2FsIGZvcm0sIGFuZCByb3VuZCBpdCB0byA1IGRlY2ltYWwgcGxhY2VzLCBzdWNoIGFzICdcXGJveGVkezI3LjAwMDAwfScsICdcXGJveGVkezMuMjAwMDB9JywgYW5kICdcXGJveGVkezAuMjMzMzR9JykuCgo8Li4uIHF1ZXJ5IGZvciB0aGUgdmFyaWFibGVzIGFuZCBvYmplY3RpdmUgLi4uPg==)‘‘‘python<...  solution  code  generated  by  the  LLM  ...>‘‘‘‘‘‘code  output<...  code  execution  result  ...>‘‘‘Accoding  to  the  code  output,  please  give  your  final  answer  for  the  following  query.  (The  answer  should  be  boxed  in  ’\\boxed{}’,  and  only  in  numerical  form,  and  round  it  to  5  decimal  places,  such  as  ’\\boxed{27.00000}’,  ’\\boxed{3.20000}’,  and  ’\\boxed{0.23334}’).<...  query  for  the  variables  and  objective  ...>'
  prefs: []
  type: TYPE_NORMAL
- en: E.2 Prompts of ReSocratic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: E.2.1 Linear Scenario Generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '“system”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIGZvbGxvdyB0aGUgc2NlbmFyaW8gZXhhbXBsZXMgdG8gZ2VuZXJhdGUgYSBbTmV3IFNjZW5hcmlvXSB3aXRoIGEgbmV3IGJhY2tncm91bmQuIFRoZSBzY2VuYXJpbyBzaG91bGQgYmUgYSByZWFsLXdvcmxkIGxpbmVhciBvcHRpbWl6YXRpb24gcHJvYmxlbS4gTWFrZSBzdXJlIHRoYXQgdGhlIG1hdGhlbWF0aWNhbCBsb2dpYyBpbiBbTmV3IFNjZW5hcmlvXSBpcyBjb3JyZWN0Lg==)Please  follow  the  scenario  examples  to  generate  a  [New  Scenario]  with  a  new  background.  The  scenario  should  be  a  real-world  linear  optimization  problem.  Make  sure  that  the  mathematical  logic  in  [New  Scenario]  is  correct.'
  prefs: []
  type: TYPE_NORMAL
- en: '“user”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,W1NjZW5hcmlvIEZvcm1hdF06CiMjIERlZmluZSBWYXJpYWJsZXM6Cm5hdHVyYWwgbGFuZ3VhZ2UgZGVzY3JpcHRpb24uCi8vIGZvcm1hbCBkZWZpbml0aW9uIG9mIHZhcmlhYmxlcyAoaW50ZWdlciwgcmVhbCwgYmluYXJ5LCBldGMuKSBhbmQgdGhlaXIgZG9tYWlucy4KCiMjIERlZmluZSBPYmplY3RpdmUgRnVuY3Rpb246Cm5hdHVyYWwgbGFuZ3VhZ2UgZGVzY3JpcHRpb24uCi8vIGZvcm1hbCBkZWZpbml0aW9uIG9mIGFuIG9iamVjdGl2ZSBmdW5jdGlvbiwgbWF4aW1pemUgb3IgbWluaW1pemUgc29tZXRoaW5nLiBUaGVyZSBjYW4gb25seSBiZSBvbmUgb2JqZWN0aXZlIGZ1bmN0aW9uLgoKIyMgR2VuZXJhdGUgQ29uc3RyYWludC0xOgpuYXR1cmFsIGxhbmd1YWdlIGRlc2NyaXB0aW9uLgovLyBmb3JtYWwgZGVmaW5pdGlvbiBvZiBjb25zdHJhaW50LTEKCi4uLgoKIyMgR2VuZXJhdGUgQ29uc3RyYWludC1uOgpuYXR1cmFsIGxhbmd1YWdlIGRlc2NyaXB0aW9uLgovLyBmb3JtYWwgZGVmaW5pdGlvbiBvZiBjb25zdHJhaW50LW4KCgo8Li4uIFNhbXBsZSAyIHNjZW5hcmlvcyBpbiB0aGUgZXhhbXBsZSBwb29sIC4uLj4KCgpbTmV3IFNjZW5hcmlvXTo=)[Scenario  Format]:##  Define  Variables:natural  language  description.//  formal  definition  of  variables  (integer,  real,  binary,  etc.)  and  their  domains.##  Define  Objective  Function:natural  language  description.//  formal  definition  of  an  objective  function,  maximize  or  minimize  something.  There  can  only  be  one  objective  function.##  Generate  Constraint-1:natural  language  description.//  formal  definition  of  constraint-1...##  Generate  Constraint-n:natural  language  description.//  formal  definition  of  constraint-n<...  Sample  2  scenarios  in  the  example  pool  ...>[New  Scenario]:'
  prefs: []
  type: TYPE_NORMAL
- en: E.2.2 Nonlinear Scenario Generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '“system”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIGZvbGxvdyB0aGUgc2NlbmFyaW8gZXhhbXBsZXMgdG8gZ2VuZXJhdGUgYSBbTmV3IFNjZW5hcmlvXSB3aXRoIGEgbmV3IGJhY2tncm91bmQuIFRoZSBzY2VuYXJpbyBzaG91bGQgYmUgYSByZWFsLXdvcmxkICoqbm9ubGluZWFyKiogb3B0aW1pemF0aW9uIHByb2JsZW0uIE1ha2Ugc3VyZSB0aGF0IHRoZSBtYXRoZW1hdGljYWwgbG9naWMgaW4gW05ldyBTY2VuYXJpb10gaXMgY29ycmVjdC4=)Please  follow  the  scenario  examples  to  generate  a  [New  Scenario]  with  a  new  background.  The  scenario  should  be  a  real-world  **nonlinear**  optimization  problem.  Make  sure  that  the  mathematical  logic  in  [New  Scenario]  is  correct.'
  prefs: []
  type: TYPE_NORMAL
- en: '“user”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,W1NjZW5hcmlvIEZvcm1hdF06CiMjIERlZmluZSBWYXJpYWJsZXM6Cm5hdHVyYWwgbGFuZ3VhZ2UgZGVzY3JpcHRpb24uCi8vIGZvcm1hbCBkZWZpbml0aW9uIG9mIHZhcmlhYmxlcyAoaW50ZWdlciwgcmVhbCwgYmluYXJ5LCBldGMuKSBhbmQgdGhlaXIgZG9tYWlucy4KCiMjIERlZmluZSBPYmplY3RpdmUgRnVuY3Rpb246Cm5hdHVyYWwgbGFuZ3VhZ2UgZGVzY3JpcHRpb24uCi8vIGZvcm1hbCBkZWZpbml0aW9uIG9mIGEgKipub25saW5lYXIqKiBvYmplY3RpdmUgZnVuY3Rpb24sIG1heGltaXplIG9yIG1pbmltaXplIHNvbWV0aGluZy4gVGhlcmUgY2FuIG9ubHkgYmUgb25lIG9iamVjdGl2ZS4KCiMjIEdlbmVyYXRlIENvbnN0cmFpbnQtMToKbmF0dXJhbCBsYW5ndWFnZSBkZXNjcmlwdGlvbi4KLy8gZm9ybWFsIGRlZmluaXRpb24gb2YgY29uc3RyYWludC0xCgouLi4KCiMjIEdlbmVyYXRlIENvbnN0cmFpbnQtbjoKbmF0dXJhbCBsYW5ndWFnZSBkZXNjcmlwdGlvbi4KLy8gZm9ybWFsIGRlZmluaXRpb24gb2YgY29uc3RyYWludC1uCgoKPC4uLiBTYW1wbGUgMiBzY2VuYXJpb3MgaW4gdGhlIGV4YW1wbGUgcG9vbCAuLi4+CgoKW05ldyBTY2VuYXJpb106)[Scenario  Format]:##  Define  Variables:natural  language  description.//  formal  definition  of  variables  (integer,  real,  binary,  etc.)  and  their  domains.##  Define  Objective  Function:natural  language  description.//  formal  definition  of  a  **nonlinear**  objective  function,  maximize  or  minimize  something.  There  can  only  be  one  objective.##  Generate  Constraint-1:natural  language  description.//  formal  definition  of  constraint-1...##  Generate  Constraint-n:natural  language  description.//  formal  definition  of  constraint-n<...  Sample  2  scenarios  in  the  example  pool  ...>[New  Scenario]:'
  prefs: []
  type: TYPE_NORMAL
- en: E.2.3 Question Generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '“system”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,WW91IGFyZSBhIG1hdGhlbWF0aWNhbCBhc3Npc3RhbnQuIE5vdywgeW91IHdpbGwgYmUgcHJvdmlkZWQgd2l0aCBhbiBvcHRpbWl6YXRpb24gc2NlbmFyaW8uIFBsZWFzZSBmb2xsb3cgdGhlIGV4YW1wbGUgdG8gY29udmVydCB0aGUgZ2l2ZW4gc2NlbmFyaW8gdG8gcXVlc3Rpb24u)You  are  a  mathematical  assistant.  Now,  you  will  be  provided  with  an  optimization  scenario.  Please  follow  the  example  to  convert  the  given  scenario  to  question.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating questions without table.
  prefs: []
  type: TYPE_NORMAL
- en: '“user”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)[Task  Description]:You  will  be  given  a  scenario  that  involves  optimization  problem.  The  scenario  is  organized  into  a  few  sections  start  with  "##".Each  section  contains  a  few  lines  of  text  that  describe  the  scenario.  The  mathematical  formal  solution  of  the  scenario  is  provided  in  the  comments  starting  with  "//".Your  job  is  to  convert  the  scenario  into  a  question  without  missing  any  information.  The  question  should  be  clear  and  concise,  and  do  not  expose  the  mathematical  formal  solution  of  the  scenario.[Example  of  converting  a  Scenario  to  a  Question]:‘‘‘scenario##  Define  Variables:A  company  produces  five  types  of  widgets:  X,  Y,  Z,  W,  and  V.  The  company  needs  to  determine  how  many  units  of  each  widget  to  produce  in  next  week.//  {"number  of  units  of  widget  X":  "X",  "range":  "X  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  Y":  "Y",  "range":  "Y  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  Z":  "Z",  "range":  "Z  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  W":  "W",  "range":  "W  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  V":  "V",  "range":  "V  >=  0",  "type":  "integer"}##  Define  Objective  Function:For  Widget  X,  the  selling  price  is  $10,  the  material  cost  is  $5,  and  the  production  time  is  2  hours.For  Widget  Y,  the  selling  price  is  $15,  the  material  cost  is  $7,  and  the  production  time  is  3  hours.For  Widget  Z,  the  selling  price  is  $20,  the  material  cost  is  $9,  and  the  production  time  is  4  hours.For  Widget  W,  the  selling  price  is  $25,  the  material  cost  is  $11,  and  the  production  time  is  5  hours.For  Widget  V,  the  selling  price  is  $30,  the  material  cost  is  $13,  and  the  production  time  is  6  hours.The  company  has  only  one  production  line  and  can  only  produce  one  widget  at  a  time.  The  company  aims  to  maximize  the  rate  at  which  it  earns  profits  (which  is  defined  as  the  sum  of  the  selling  profit  divided  by  the  sum  of  the  production  times).//  Selling  profit  of  X:  Profit_X  =  (10  -  5)  *  X//  Selling  profit  of  Y:  Profit_Y  =  (15  -  7)  *  Y//  Selling  profit  of  Z:  Profit_Z  =  (20  -  9)  *  Z//  Selling  profit  of  W:  Profit_W  =  (25  -  11)  *  W//  Selling  profit  of  V:  Profit_V  =  (30  -  13)  *  V//  So,  the  objective  function  is:  Maximize  (Profit_X  +  Profit_Y  +  Profit_Z  +  Profit_W  +  Profit_V)  /  (2  *  X  +  3  *  Y  +  4  *  Z  +  5  *  W  +  6  *  V)##  Generate  Constraint-1:The  company  has  $900  available  for  material  costs  next  week.//  5  *  X  +  7  *  Y  +  9  *  Z  +  11  *  W  +  13  *  V  <=  900##  Generate  Constraint-2:The  company  wants  to  produce  at  least  10  units  of  each  widget  next  week.//  X  >=  10;  Y  >=  10;  Z  >=  10;  W  >=  10;  V  >=  10##  Generate  Constraint-3:The  company  wants  to  spend  at  most  200  hours  on  production  next  week.//  2  *  X  +  3  *  Y  +  4  *  Z  +  5  *  W  +  6  *  V  <=  200##  Generate  Constraint-4:The  company  wants  to  ensure  that  the  total  production  of  Widget  W  does  not  exceed  the  combined  production  of  Widgets  X,  Y,  and  Z.//  W  <=  X  +  Y  +  Z‘‘‘‘‘‘questionA  company  produces  five  types  of  widgets:  X,  Y,  Z,  W,  and  V.  The  company  needs  to  determine  how  many  units  of  each  widget  to  produce  in  next  week.For  Widget  X,  the  selling  price  is  $10,  the  material  cost  is  $5,  and  the  production  time  is  2  hours.For  Widget  Y,  the  selling  price  is  $15,  the  material  cost  is  $7,  and  the  production  time  is  3  hours.For  Widget  Z,  the  selling  price  is  $20,  the  material  cost  is  $9,  and  the  production  time  is  4  hours.For  Widget  W,  the  selling  price  is  $25,  the  material  cost  is  $11,  and  the  production  time  is  5  hours.For  Widget  V,  the  selling  price  is  $30,  the  material  cost  is  $13,  and  the  production  time  is  6  hours.The  company  has  $900  available  for  material  costs  next  week.  The  company  wants  to  produce  at  least  10  units  of  each  widget  next  week.  The  company  wants  to  spend  at  most  200  hours  on  production  next  week.  The  company  wants  to  ensure  that  the  total  production  of  Widget  W  does  not  exceed  the  combined  production  of  Widgets  X,  Y,  and  Z.  The  company  has  only  one  production  line  and  can  only  produce  one  widget  at  a  time.Please  help  the  company  to  maximize  the  rate  at  which  it  earns  profits  (which  is  defined  as  the  sum  of  the  selling  profit  divided  by  the  sum  of  the  production  times).‘‘‘[Follow  the  Example  to  Convert  the  following  Scenario  to  a  Question]:'
  prefs: []
  type: TYPE_NORMAL
- en: Generating questions with table.
  prefs: []
  type: TYPE_NORMAL
- en: '“user”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)[Task  Description]:You  will  be  given  a  scenario  that  involves  optimization  problem.  The  scenario  is  organized  into  a  few  sections  start  with  "##".Each  section  contains  a  few  lines  of  text  that  describe  the  scenario.  The  mathematical  formal  solution  of  the  scenario  is  provided  in  the  comments  starting  with  "//".Your  job  is  to  convert  the  scenario  into  a  question  without  missing  any  information.  The  question  should  be  clear  and  concise,  and  do  not  expose  the  mathematical  formal  solution  of  the  scenario.[Example  of  converting  a  Scenario  to  a  Question  with  table]:‘‘‘scenario##  Define  Variables:A  company  produces  five  types  of  widgets:  X,  Y,  Z,  W,  and  V.  The  company  needs  to  determine  how  many  units  of  each  widget  to  produce  in  next  week.//  {"number  of  units  of  widget  X":  "X",  "range":  "X  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  Y":  "Y",  "range":  "Y  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  Z":  "Z",  "range":  "Z  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  W":  "W",  "range":  "W  >=  0",  "type":  "integer"}//  {"number  of  units  of  widget  V":  "V",  "range":  "V  >=  0",  "type":  "integer"}##  Define  Objective  Function:For  Widget  X,  the  selling  price  is  $10,  the  material  cost  is  $5,  and  the  production  time  is  2  hours.For  Widget  Y,  the  selling  price  is  $15,  the  material  cost  is  $7,  and  the  production  time  is  3  hours.For  Widget  Z,  the  selling  price  is  $20,  the  material  cost  is  $9,  and  the  production  time  is  4  hours.For  Widget  W,  the  selling  price  is  $25,  the  material  cost  is  $11,  and  the  production  time  is  5  hours.For  Widget  V,  the  selling  price  is  $30,  the  material  cost  is  $13,  and  the  production  time  is  6  hours.The  company  has  only  one  production  line  and  can  only  produce  one  widget  at  a  time.  The  company  aims  to  maximize  the  rate  at  which  it  earns  profits  (which  is  defined  as  the  sum  of  the  selling  profit  divided  by  the  sum  of  the  production  times).//  Selling  profit  of  X:  Profit_X  =  (10  -  5)  *  X//  Selling  profit  of  Y:  Profit_Y  =  (15  -  7)  *  Y//  Selling  profit  of  Z:  Profit_Z  =  (20  -  9)  *  Z//  Selling  profit  of  W:  Profit_W  =  (25  -  11)  *  W//  Selling  profit  of  V:  Profit_V  =  (30  -  13)  *  V//  So,  the  objective  function  is:  Maximize  (Profit_X  +  Profit_Y  +  Profit_Z  +  Profit_W  +  Profit_V)  /  (2  *  X  +  3  *  Y  +  4  *  Z  +  5  *  W  +  6  *  V)##  Generate  Constraint-1:The  company  has  $900  available  for  material  costs  next  week.//  5  *  X  +  7  *  Y  +  9  *  Z  +  11  *  W  +  13  *  V  <=  900##  Generate  Constraint-2:The  company  wants  to  produce  at  least  10  units  of  each  widget  next  week.//  X  >=  10;  Y  >=  10;  Z  >=  10;  W  >=  10;  V  >=  10##  Generate  Constraint-3:The  company  wants  to  spend  at  most  200  hours  on  production  next  week.//  2  *  X  +  3  *  Y  +  4  *  Z  +  5  *  W  +  6  *  V  <=  200##  Generate  Constraint-4:The  company  wants  to  ensure  that  the  total  production  of  Widget  W  does  not  exceed  the  combined  production  of  Widgets  X,  Y,  and  Z.//  W  <=  X  +  Y  +  Z‘‘‘‘‘‘questionA  company  produces  five  types  of  widgets:  X,  Y,  Z,  W,  and  V.  The  company  needs  to  determine  how  many  units  of  each  widget  to  produce  in  next  week.  The  selling  price,  material  cost,  and  production  time  for  each  widget  are  given  in  the  following  Table.|  Widget  |  Selling  Price  |  Material  Cost  |  Production  Time  ||--------|---------------|---------------|-----------------||  X  |  10$  |  5$  |  2  hours  ||  Y  |  15$  |  7$  |  3  hours  ||  Z  |  20$  |  9$  |  4  hours  ||  W  |  25$  |  11$  |  5  hours  ||  V  |  30$  |  13$  |  6  hours  |The  company  has  $900  available  for  material  costs  next  week.  The  company  wants  to  produce  at  least  10  units  of  each  widget  next  week.  The  company  wants  to  spend  at  most  200  hours  on  production  next  week.  The  company  wants  to  ensure  that  the  total  production  of  Widget  W  does  not  exceed  the  combined  production  of  Widgets  X,  Y,  and  Z.  The  company  has  only  one  production  line  and  can  only  produce  one  widget  at  a  time.Please  help  the  company  to  maximize  the  rate  at  which  it  earns  profits  (which  is  defined  as  the  sum  of  the  selling  profit  divided  by  the  sum  of  the  production  times).‘‘‘[Follow  the  Example  to  Convert  the  following  Scenario  to  a  Question  with  table]:'
  prefs: []
  type: TYPE_NORMAL
- en: E.2.4 Code Generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '“system”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,WW91IGFyZSBhIG1hdGhlbWF0aWNhbCBhc3Npc3RhbnQuIE5vdywgeW91IHdpbGwgYmUgcHJvdmlkZWQgd2l0aCBhbiBvcHRpbWl6YXRpb24gc2NlbmFyaW8gd2l0aCBpdHMgY29ycmVzcG9uZGluZyBxdWVzdGlvbi4gUGxlYXNlIGZvbGxvdyB0aGUgZXhhbXBsZXMgdG8gc29sdmUgdGhlIG9wdGltaXphdGlvbiBzY2VuYXJpbyB1c2luZyBweXRob24gY29kZSB3aXRoIHB5c2NpcG9wdC4gKFRpcHM6IDEuIFNldCBvYmplY3RpdmUgYXMgYSB2YXJpYWJsZSB0byBhdm9pZCBub24tbGluZWFyIG9iamVjdGl2ZS4gMi4gVG8gZXhwZWRpdGUgY29tcHV0YXRpb24sIGNvbnZlcnQgZGl2aXNpb24gdG8gbXVsdGlwbGljYXRpb24uKQ==)You  are  a  mathematical  assistant.  Now,  you  will  be  provided  with  an  optimization  scenario  with  its  corresponding  question.  Please  follow  the  examples  to  solve  the  optimization  scenario  using  python  code  with  pyscipopt.  (Tips:  1.  Set  objective  as  a  variable  to  avoid  non-linear  objective.  2.  To  expedite  computation,  convert  division  to  multiplication.)'
  prefs: []
  type: TYPE_NORMAL
- en: '“user”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)[Example-1]:‘‘‘scenario##  Define  Variables:Now  we  need  to  create  a  cylindrical  metal  jar  with  a  metal  shell.//  variables:  {"radius  of  the  cylindrical  jar":  "r",  "height  of  the  cylindrical  jar":  "h"},  where  r,  h  >=  0##  Define  Objective  Function:The  cost  of  the  metal  is  $10  per  square  meter.  Find  the  dimensions  that  will  minimize  the  cost  of  the  metal  to  manufacture  the  jar.//  The  surface  area  of  the  cylindrical  jar  is  the  sum  of  the  area  of  the  two  circular  ends  and  the  lateral  surface  area.  The  area  of  each  circular  end  is  \pi  *  r^2,  and  the  lateral  surface  area  is  2\pi*rh.//  So,  the  surface  area  of  the  cylindrical  jar  is  2\pi*r^2  +  2\pi*rh,  and  the  cost  of  the  metal  is  10  *  (2\pi*r^2  +  2\pi*rh).//  So,  the  objective  function  is:  Minimize  10  *  (2\pi*r^2  +  2\pi*rh)##  Generate  Constraint-1:The  volume  of  the  jar  must  be  at  least  1000  cubic  centimeters.//  \pi*r^2h  >=  1000‘‘‘‘‘‘pythonimport  mathimport  pyscipopt#  Create  a  new  modelmodel  =  pyscipopt.Model()#  Define  variables##  The  radius  and  height  of  the  cylindrical  jarr  =  model.addVar(vtype="CONTINUOUS",  name="r",  lb=0,  ub=100)  #  radius  of  the  cylindrical  jarh  =  model.addVar(vtype="CONTINUOUS",  name="h",  lb=0,  ub=100)  #  height  of  the  cylindrical  jar#  Define  objective  function##  set  objective  as  a  variable  (pyscipopt  does  not  support  non-linear  objective)obj  =  model.addVar(’obj’)model.setObjective(obj,  "minimize")##  the  objective  function  is:  Minimize  10  *  (2\pi*r^2  +  2\pi*rh)model.addCons(obj  ==  10  *  (2*math.pi*r**2  +  2*math.pi*r*h))#  Add  constraints##  The  volume  of  the  jar  must  be  at  least  1000  cubic  centimeters.model.addCons(math.pi*r**2*h  >=  1000)#  Solve  the  problemmodel.optimize()#  Print  the  optimal  solution  (value  of  the  variables  &  the  objective)print(’-’*10)if  model.getStatus()  ==  "optimal":print("Radius  of  the  cylindrical  jar:  ",  model.getVal(r))print("Height  of  the  cylindrical  jar:  ",  model.getVal(h))print("Minimized  Cost:  ",  model.getObjVal())else:print("The  problem  could  not  be  solved  to  optimality.")‘‘‘[Example-2]:‘‘‘scenario##  Define  Variables:You  are  designing  a  rectangular  poster  by  cutting  from  a  rectangular  piece  of  paper.//  variables:  {"width  of  the  poster":  "w",  "height  of  the  poster":  "h"},  where  w,  h  >=  0##  Define  Objective  Function:The  top  and  bottom  margins  are  2  inches,  and  the  side  margins  are  1  inch.  What  dimensions  of  the  poster  should  you  use  to  minimize  the  area  of  paper  used?//  The  width  of  the  used  paper  is  w  +  2*1,  and  the  height  of  the  used  paper  is  h  +  2*2.//  Therefore,  the  objective  function  is:  Minimize  (w  +  2)  *  (h  +  4)##  Generate  Constraint-1:The  poster  must  have  an  area  of  100  square  inches.//  The  area  of  the  poster  is  given  by  the  product  of  the  width  and  the  height,  and  it  is  given  that  the  area  is  100.  Therefore,  the  constraint  is  w  *  h  =  100‘‘‘‘‘‘pythonimport  mathimport  pyscipopt#  Create  a  new  modelmodel  =  pyscipopt.Model()#  Define  variables##  The  width  and  height  of  the  posterw  =  model.addVar(vtype="CONTINUOUS",  name="w",  lb=0,  ub=100)  #  width  of  the  posterh  =  model.addVar(vtype="CONTINUOUS",  name="h",  lb=0,  ub=100)  #  height  of  the  poster#  Define  objective  function##  set  objective  as  a  variable  (pyscipopt  does  not  support  non-linear  objective)obj  =  model.addVar(’obj’)model.setObjective(obj,  "minimize")##  the  objective  function  is:  Minimize  (w  +  2)  *  (h  +  4)model.addCons(obj  ==  (w  +  2)  *  (h  +  4))#  Add  constraints##  The  poster  must  have  an  area  of  100  square  inches.model.addCons(w  *  h  ==  100)#  Solve  the  problemmodel.optimize()#  Print  the  optimal  solution  (value  of  the  variables  &  the  objective)print(’-’*10)if  model.getStatus()  ==  "optimal":print("Width  of  the  poster:  ",  model.getVal(w))print("Height  of  the  poster:  ",  model.getVal(h))print("Minimized  Area  of  Paper  Used:  ",  model.getObjVal())else:print("The  problem  could  not  be  solved  to  optimality.")‘‘‘[Convert  the  following  Scenario  to  code]:‘‘‘scenario<...  Put  your  synthetic  scenario  here  ...>‘‘‘'
  prefs: []
  type: TYPE_NORMAL
