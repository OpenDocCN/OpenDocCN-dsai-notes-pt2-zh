- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 19:04:09'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Explaining EDA synthesis errors with LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.07235](https://ar5iv.labs.arxiv.org/html/2404.07235)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \lst@Key
  prefs: []
  type: TYPE_NORMAL
- en: 'numbersnone\lstKV@SwitchCases#1none:'
  prefs: []
  type: TYPE_NORMAL
- en: 'left:'
  prefs: []
  type: TYPE_NORMAL
- en: 'right:'
  prefs: []
  type: TYPE_NORMAL
- en: Siyu Qiu1, Benjamin Tan2, and Hammond Pearce1 The research in this work was
    supported in part by Intel Corporation and in part by Woodpecker Technologies.
    1University of New South Wales, Sydney, NSW, Australia 2University of Calgary,
    Calgary, AB, Canada
  prefs: []
  type: TYPE_NORMAL
- en: siyu.qiu1@student.unsw.edu.au, benjamin.tan1@ucalgary.ca, hammond.pearce@unsw.edu.au
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Training new engineers in digital design is a challenge, particularly when it
    comes to teaching the complex electronic design automation (EDA) tooling used
    in this domain. Learners will typically deploy designs in the Verilog and VHDL
    hardware description languages to Field Programmable Gate Arrays (FPGAs) from
    Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains (Quartus
    Prime and Vivado, respectively). These tools are complex and difficult to use—yet,
    as they are the tools used in industry, they are an essential first step in this
    space. In this work, we examine how recent advances in artificial intelligence
    may be leveraged to address aspects of this challenge. Specifically, we investigate
    if Large Language Models (LLMs), which have demonstrated text comprehension and
    question-answering capabilities, can be used to generate novice-friendly explanations
    of compile-time synthesis error messages from Quartus Prime and Vivado. To perform
    this study we generate 936 error message explanations using three OpenAI LLMs
    over 21 different buggy code samples. These are then graded for relevance and
    correctness, and we find that in approximately 71% of cases the LLMs give correct
    & complete explanations suitable for novice learners.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: EDA, CAD, AI, LLM, Bug Explanation
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With increasing demand for digital devices, there is a need for more digital
    design practitioners. However, existing electronic design automation (EDA) tools
    have a considerably steep learning curve. For example, in the FPGA design space,
    Altera and AMD Xilinx tools are frequently used in educational settings. These
    tool suites are renowned for their difficulty and complexity, particularly for
    new users. Indeed, the combination of new languages, design paradigms, software
    tools, and hardware requirements can leave novices feeling well and truly “stumped” [[1](#bib.bib1)],
    particularly when the software provides unhelpful messages upon reaching erroneous
    code (e.g., Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis
    errors with LLMs")). Likewise, educators themselves can struggle with the broad
    knowledge base required [[2](#bib.bib2)]. This is a serious challenge, especially
    considering the worldwide shortfall in qualified chip designers (in the US alone,
    estimates have a 67,000 employee shortfall by 2030 [[3](#bib.bib3)]).
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,YXJjaGl0ZWN0dXJlIEJlaGF2aW9yYWwgb2YgdG9wMSBpcwpiZWdpbgogICAgcHJvY2VzcyAoY2xrLCByc3QpIGJlZ2luCiAgICAgICAgaWYgcnN0ID0gJzEnIHRoZW4KICAgICAgICAgICAgZGF0YV9vdXQgPD0gKG90aGVycyA9PiAnMCcpCiAgICAgICAgZWxzaWYgcmlzaW5nX2VkZ2UoY2xrKSB0aGVuCiAgICAgICAgICAgIGRhdGFfb3V0IDw9IGRhdGFfaW47CiAgICAgICAgZW5kIGlmOwogICAgZW5kIHByb2Nlc3M7CmVuZCBCZWhhdmlvcmFsOw==)41architecture  Behavioral  of  top1  is42begin43  process  (clk,  rst)  begin44  if  rst  =  ’1’  then45  data_out  <=  (others  =>  ’0’)46  elsif  rising_edge(clk)  then47  data_out  <=  data_in;48  end  if;49  end  process;50end  Behavioral;'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Snippet of buggy VHDL code
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,RVJST1I6IFtTeW50aCA4LTI3MTVdIHN5bnRheCBlcnJvciBuZWFyIGVsc2lmIFtwYXRoL3RvL2J1Z18xL3J0bC90b3AxLnZoZDo0Nl0=)1ERROR:  [Synth  8-2715]  syntax  error  near  elsif  [path/to/bug_1/rtl/top1.vhd:46]'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Vivado’s corresponding error message
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: Example unhelpful error message. It does not describe the real problem
    (a missing semicolon), and it links to line 46, not the fault on line 45!'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is therefore desirable to see if recent advancements in artificial intelligence
    may be able to assist novice digital hardware designers and accelerate their training,
    be it in the classroom or perhaps as part of onboarding/professional development.
    In particular, large language models have demonstrated considerable capabilities
    for comprehending text and program code, enabling code generation and explanation.
    Given that one of the most common difficulties noted when learning to program
    comes from understanding and overcoming compiler error messages [[4](#bib.bib4),
    [5](#bib.bib5)] we pose the question: Can LLMs be leveraged to explain error messages
    from EDA tools?'
  prefs: []
  type: TYPE_NORMAL
- en: In this work, we thus undertake a proof-of-concept examination, tasking a series
    of OpenAI LLMs with generating explanations for a series of synthesis-time (i.e.
    compile-time) bugs commonly encountered by novice digital designers. Our synthetic
    dataset contains error messages from both Intel’s Altera Quartus Prime and AMD’s
    Xilinx Vivado with both VHDL- and Verilog-based designs.
  prefs: []
  type: TYPE_NORMAL
- en: Crucially, as we aim to up-skill tool users, we desire pedagogically-useful
    responses (i.e., not automated program repair). The LLM should assist the user
    but should not outright solve the issue—per the constructivism pedagogy in computer
    science [[6](#bib.bib6)], learners should “build” knowledge rather than be simply
    told answers outright. Moreover, the insights from our study can also lay the
    foundation for other LLM-based augmentation of EDA tool feedback to improve their
    readability/actionability and, thus, designer productivity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our contributions include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A new open-source dataset of 21 representative synthesis-time bugs and error
    messages based on the authors’ experiences with teaching introductory digital
    hardware design.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these bugs, results from the first pedagogically focused evaluation of
    936 LLM-generated bug explanations, finding that $\approx$71% have ‘good’ explanations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Open-source: All synthetic bugs and generated data is provided at [https://zenodo.org/doi/10.5281/zenodo.10937409](https://zenodo.org/doi/10.5281/zenodo.10937409).'
  prefs: []
  type: TYPE_NORMAL
- en: II Background and Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: II-A Large Language Models for hardware design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs, trained over large quantities of text scraped from the Internet (including
    millions of open-source repositories), have demonstrated considerable cross-domain
    expertise in lexical tasks. While early models such as OpenAI’s Codex acted primarily
    as a kind of “smart autocomplete,” more recent training methodologies such as
    Reinforcement Learning with Human Feedback (RLHF) can create models more capable
    of following user intent [[7](#bib.bib7)]—meaning such models may actually “follow
    instructions.” Currently, leading commercial LLMs in this space come from OpenAI’s
    ChatGPT family [[8](#bib.bib8)], which can be “prompted” to translate and debug
    code and provide code explanations using natural language.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple works have acknowledged the potential for LLMs to work with hardware
    design tasks, including for authoring hardware description language (HDL) code [[9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)], bug fixing [[13](#bib.bib13)],
    SystemVerilog Assertion generation [[14](#bib.bib14)], and scripting hardware
    tool suites [[15](#bib.bib15)] among others. Some works have even explored how
    conversational LLMs like OpenAI’s ChatGPT [[8](#bib.bib8)] can author whole processor
    designs [[16](#bib.bib16)].
  prefs: []
  type: TYPE_NORMAL
- en: II-B LLMs for training and education
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Proponents of the technology argue that LLMs, when carefully utilized, can unlock
    new pedagogical tools and strategies. Kasneci et al. provide a comprehensive survey
    in this area [[17](#bib.bib17)], finding that, for example, ChatGPT is already
    being used for educational methods such as generating tests, quizzes, and flashcards [[18](#bib.bib18),
    [19](#bib.bib19)].
  prefs: []
  type: TYPE_NORMAL
- en: Given their recency, investigations on the challenges and opportunities provided
    by LLMs in the education domain are ongoing [[20](#bib.bib20)]. Particular attention
    has been provided on their potential impact in “CS1” introductory courses (e.g.
    [[21](#bib.bib21), [22](#bib.bib22)]) and on quality of code explanations for
    novices [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25)]. Of particular
    interest to us is the potential for LLMs to aid in error message explanation,
    where LLMs are used to help learners overcome compile and runtime errors. Taylor
    et al. [[26](#bib.bib26)] explored this application for C, where they examined
    over 64,000 uses of the ChatGPT-enabled C compiler DCC by over 2,500 students.
    They found that over 90 % of compile-time and 75 % of run-time error messages
    had valid explanations.
  prefs: []
  type: TYPE_NORMAL
- en: This motivates our investigation, which explores a similar use case for hardware
    synthesis rather than software compilation. The DCC compiler provided considerable
    additional context to the ChatGPT 3.5 LLM in the form of stack traces and templated
    error message assistance [[26](#bib.bib26)]. Can we find a similar level of assistance
    but for hardware, simply using the context available in the typical hardware EDA
    tool suite?
  prefs: []
  type: TYPE_NORMAL
- en: III Digital Design Assistance via LLM prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/894e77dc748755c29cfcd04ee6c53055.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Overall experimentation methodology'
  prefs: []
  type: TYPE_NORMAL
- en: III-A Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This study explores the effectiveness of using LLMs to improve error feedback
    in Vivado and Quartus. We use the methodology outlined in Figure [2](#S3.F2 "Figure
    2 ‣ III Digital Design Assistance via LLM prompts ‣ Explaining EDA synthesis errors
    with LLMs"). Firstly, we create a corpus of representative bugs. We use these
    to collect synthesis error messages, then use two different prompts to request
    explanations from selected LLMs. Finally, we score the responses.
  prefs: []
  type: TYPE_NORMAL
- en: III-B Defining a corpus of bugs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Table [I](#S3.T1 "Table I ‣ III-B Defining a corpus of bugs ‣ III Digital Design
    Assistance via LLM prompts ‣ Explaining EDA synthesis errors with LLMs")’s first
    four columns present the range of bugs used in this study (the latter four columns
    present results; see Section [IV](#S4 "IV Results ‣ Explaining EDA synthesis errors
    with LLMs")). The bugs were based in general on 10 distinct error categories (e.g.,
    syntax errors, multiple driver errors, type errors and others) that the authors
    have frequently observed in code written by learners and novice hardware designers.
    Two of the VHDL bugs did not have an equivalent Verilog representation. The buggy
    files are short (usually less than 50 lines of comments and code)—e.g., Figure [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis errors with LLMs") depicts
    Bug 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: List of HDL bugs (and their languages) examined in the study, with
    LLM evaluation results. Each bug had 24 responses in each prompting strategy,
    and these were manually graded.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; LLM answer: &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; concept accurate &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; LLM answer: &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; correct & complete &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Bug | Error type | Language | Error description | E&C | EC&L | E&C | EC&L
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Syntax error | VHDL | Missing semicolon | 71% | 67% | 46% | 58% |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Type error | VHDL | Can’t add std_logic_vectors | 100% | 96% | 21% |
    25% |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Compilation error | VHDL | Can’t write to an input ports object | 100%
    | 100% | 79% | 83% |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Width mismatch | VHDL | Mismatch in the size of two std_logic_vectors
    | 100% | 100% | 71% | 79% |'
  prefs: []
  type: TYPE_TB
- en: '| 5* | Type conversion | VHDL | Can’t perform two operations simultaneously
    in one line | 100% | 92% | 58% | 42% |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | Signal and variable | VHDL | Declaring a variable outside of a subprogram
    or process | 100% | 100% | 63% | 63% |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | Concurrent and sequential error | VHDL | Having both ‘wait’ and a sensitivity
    list in the same process | 71% | 67% | 50% | 38% |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | Semantic error | VHDL | Using a signal or variable that has not been
    declared | 100% | 100% | 88% | 88% |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | Signal Readability error | VHDL | Attempting to read from an object with
    the mode “out” | 100% | 100% | 96% | 96% |'
  prefs: []
  type: TYPE_TB
- en: '| 10* | Top Level Undefined | VHDL | Incorrect definition of the top-level
    module or entity | 100% | 100% | 83% | 92% |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | Case error | VHDL | Missing certain choices in a case statement | 100%
    | 100% | 83% | 79% |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | Singal Bit error | VHDL | Mismatch between a std_logic type and a string
    literal | 58% | 100% | 29% | 92% |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | Syntax error | Verilog | Missing semicolon | 100% | 100% | 79% | 92%
    |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | Semantic error | Verilog | Using an undeclared variable or signal |
    100% | 100% | 83% | 92% |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | Wire and Reg error | Verilog | Assign a value declared as wire using
    non-blocking assignments | 100% | 100% | 83% | 92% |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | Blocking and non-blocking | Verilog | Mixing blocking and non-blocking
    assignments to the same variable | 79% | 71% | 58% | 67% |'
  prefs: []
  type: TYPE_TB
- en: '| 17* | Multiple Driver error | Verilog | Assigning different values to the
    same signal from different processes | 100% | 100% | 67% | 83% |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | Port error | Verilog | Connect a port that does not exist | 100% | 100%
    | 63% | 63% |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | Binary error | Verilog | Using an illegal character in a binary number
    representation | 100% | 100% | 75% | 100% |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | Infinite combinational loop | Verilog | Having a infinite combinational
    loop that cannot be resolved | 100% | 100% | 58% | 71% |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | Double-edge error | Verilog | Mismatch between operands used in condition
    of an always block | 100% | 100% | 83% | 83% |'
  prefs: []
  type: TYPE_TB
- en: '| * Bug 5 only an error in Vivado. Bugs 10 and 17 only an error in Quartus.
    |'
  prefs: []
  type: TYPE_TB
- en: 'In this work, we focus exclusively on synthesis-time bugs rather than the more
    complex run-time issues that could occur. The reasons for this are twofold: (1)
    both the Vivado and Quartus IDEs have limited capabilities in detecting run-time
    issues, given that they primarily rely on user-provided test-benches in simulation
    for this purpose. (2) Run-time issues in the novice-focused area will primarily
    be logic-based, which may be identified by reading simulation waveforms. A user
    having a simulation error thus has more information available to them than one
    who is stuck with an inscrutable and unchanging synthesis error message. In future,
    we plan to extend our study to investigate how LLMs can be leveraged for more
    complex debugging and training.'
  prefs: []
  type: TYPE_NORMAL
- en: III-C Harvesting Vivado and Quartus error log files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Quartus and Vivado can synthesize VHDL and Verilog files into bitstreams for
    FPGAs. When an error occurs, synthesis stops, and the error message is saved to
    a file—Quartus stores synthesis logs in a file like ‘path/to/project/output_files/project.map.rpt’,
    and Vivado ‘path/to/project/project_1.runs/synth_1/runme.log’.
  prefs: []
  type: TYPE_NORMAL
- en: As these logs also include other information about the tool flow, we extract
    error messages using regular expressions, scanning for lines beginning with “Error:”
    for Quartus and “ERROR:” for Vivado. Further regular expressions can extract details
    about the error, such as the message, faulty file, and reported error line number.
  prefs: []
  type: TYPE_NORMAL
- en: III-D Prompting LLMs for error explanations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs function by providing an output “response” to an input “prompt’. For this
    study, we selected three of OpenAI’s LLMs, gpt-3.5-turbo, gpt-4, and gpt-4-turbo-preview.
    These first take a “System” prompt to provide overall model guidance, followed
    by “User” prompts which can contain data. As the models evolve over time, we note
    our usage was on March 29, 2024.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that the goal of this work is for error explanations not bug repair.
    We therefore base our LLM prompting strategy on that used in prior work [[26](#bib.bib26)],
    which aimed for pedagogically-focused error message explanations. As depicted
    in Figure [4](#Sx1.F4 "Figure 4 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") (in the Appendix), we used one system prompt (requesting debugging assistance
    but no code outputs) with two similar user prompt options. “Error & Code (E&C)”
    is a straightforward option which provides both the error from the log file, plus
    the entire faulty code file. However, given that LLMs are known to be poor at
    word and line counting, we also examine a second prompt, “Error, Code, & Line
    (EC&L),”, which also reproduces the tool-localised faulty code line a second time
    for emphasis.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE II: Aggregated pedagogical grades for generated explanations grouped
    by IDEs, Language, Prompt Strategies, and LLMs'
  prefs: []
  type: TYPE_NORMAL
- en: '| Measurement | Total |'
  prefs: []
  type: TYPE_TB
- en: '&#124; IDE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Vivado &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; IDE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Quartus &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Lang. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; VHDL &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Lang. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Verilog &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Prompt &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; E&C &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Prompt &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; EC&L &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; GPT3.5-t. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; pass@10 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; GPT3.5-t. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; pass@1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; GPT4 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; pass@1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; GPT4-t.-p. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; pass@1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| # responses (n) | 936 | 456 | 480 | 528 | 408 | 468 | 468 | 780 | 78 | 78
    | 78 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Concept accurate | 94.23% | 92.32% | 96.04% | 92.05% | 97.06% | 93.80% |
    94.66% | 93.33% | 93.59% | 98.72% | 98.72% |'
  prefs: []
  type: TYPE_TB
- en: '| No inaccuracies | 91.03% | 88.82% | 93.12% | 86.93% | 96.32% | 89.74% | 92.31%
    | 89.62% | 87.18% | 98.72% | 97.44% |'
  prefs: []
  type: TYPE_TB
- en: '| Relevant | 84.18% | 84.87% | 83.54% | 85.42% | 82.60% | 81.62% | 86.75% |
    88.97% | 83.33% | 60.26% | 60.26% |'
  prefs: []
  type: TYPE_TB
- en: '| Correct & complete | 71.26% | 69.74% | 72.71% | 66.48% | 77.45% | 67.31%
    | 75.21% | 74.36% | 69.23% | 53.85% | 57.69% |'
  prefs: []
  type: TYPE_TB
- en: '| Solution is provided | 3.31% | 3.51% | 3.13% | 2.27% | 4.66% | 4.27% | 2.35%
    | 2.82% | 2.56% | 3.85% | 7.69% |'
  prefs: []
  type: TYPE_TB
- en: 'Response Generation: OpenAI’s LLMs are non-deterministic, potentially giving
    different outputs for the same inputs. However, the GPT4 models are also more
    expensive to run. We decided to run the gpt-3.5-turbo model 10 times for each
    bug, and the other models just once, meaning that for each bug in Table [I](#S3.T1
    "Table I ‣ III-B Defining a corpus of bugs ‣ III Digital Design Assistance via
    LLM prompts ‣ Explaining EDA synthesis errors with LLMs") we prompted for LLM
    responses 48 times (2 IDEs $\times$ (10 iterations of gpt-3.5-turbo and 1 each
    of gpt-4 and gpt-4-turbo-preview)). However, as noted in Table [I](#S3.T1 "Table
    I ‣ III-B Defining a corpus of bugs ‣ III Digital Design Assistance via LLM prompts
    ‣ Explaining EDA synthesis errors with LLMs"), during experimentation we found
    that certain bugs (5, 10, and 17) were errors in only one IDE, meaning that in
    total we collected 936 LLM responses for grading.'
  prefs: []
  type: TYPE_NORMAL
- en: III-E Manual grading with pedagogically focused metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is difficult to automatically judge the quality of answers by a question
    and answer system reliably. In this work we therefore manually grade each of the
    936 LLM-generated explanations against a series of metrics based on those used
    in [[26](#bib.bib26)]. To avoid complexity/marker subjectivity, we only grade
    using binary yes/no questions, and to avoid inter-rater reliability challenges
    all answers were graded uniformly by the first author. Our metrics follow:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Concept accurate: i.e. Does the explanation link to the right concepts and
    keywords?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'No inaccuracies: i.e. Does the explanation only contain factually correct information?
    An explanation may be accurate even if it is incomplete. Falsehoods can lead learners
    astray.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Relevant: i.e. Is the explanation relevant to the problem at hand? Whether
    the explanation is correct or incorrect does not impact the relevance assessment.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Correct & complete: i.e. Does the explanation contain everything a user needs
    to understand and fix the error? This is the metric we use to grade overall success.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Solution is provided: i.e. Did the model provide ‘too much’ help? From the
    constructivism pedagogy, we know that learners build knowledge better by ‘doing’
    rather than by being directly ‘told’ [[6](#bib.bib6)]. To judge this category,
    we answer ‘Yes’ if an answer was provided with code that could be copied and pasted
    (even if the overall answer was wrong).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure [3](#S3.F3 "Figure 3 ‣ III-E Manual grading with pedagogically focused
    metrics ‣ III Digital Design Assistance via LLM prompts ‣ Explaining EDA synthesis
    errors with LLMs") presents two example explanations from gpt-3.5-turbo for Bug
    1 from Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis
    errors with LLMs") (a), one judged as ‘good’ and one ‘bad’. The ‘good’ correctly
    identifies the error, and provides a detailed (and complete) method to fix it.
    However, the ‘bad’ misidentifies the error and suggests adding a “then” keyword
    incorrectly. Figures [5](#Sx1.F5 "Figure 5 ‣ Appendix ‣ Explaining EDA synthesis
    errors with LLMs") and [6](#Sx1.F6 "Figure 6 ‣ Appendix ‣ Explaining EDA synthesis
    errors with LLMs") in the Appendix show examples of other metric scores.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,VGhlIGJ1ZyBpcyBpbiB0aGUgcHJvY2VzcyBzdGF0ZW1lbnQgb2YgdGhlIFZIREwgY29kZS4gVGhlIGlzc3VlIGlzIHdpdGggdGhlIG1pc3Npbmcgc2VtaWNvbG9uIGFmdGVyIGBkYXRhX291dCA8PSAob3RoZXJzID0+ICcwJylgIHdpdGhpbiB0aGUgYGlmIHJzdCA9ICcxJyB0aGVuYCBibG9jay4gVGhlIGVycm9yIG1lc3NhZ2UgaW5kaWNhdGVzIHRoYXQgdGhlIFZIREwgc3ludGF4IGlzIGV4cGVjdGluZyBhIHNlbWljb2xvbiBiZWZvcmUgdGhlIGBlbHNpZmAga2V5d29yZC4gQWRkaW5nIHRoZSBtaXNzaW5nIHNlbWljb2xvbiB3aWxsIHJlc29sdmUgdGhlIHN5bnRheCBlcnJvci4=)1The  bug  is  in  the  process  statement  of  the  VHDL  code.  The  issue  is  with  the  missing  semicolon  after  ‘data_out  <=  (others  =>  ’0’)‘  within  the  ‘if  rst  =  ’1’  then‘  block.  The  error  message  indicates  that  the  VHDL  syntax  is  expecting  a  semicolon  before  the  ‘elsif‘  keyword.  Adding  the  missing  semicolon  will  resolve  the  syntax  error.'
  prefs: []
  type: TYPE_NORMAL
- en: '(a) ‘Good’ explanation—Concept accurate: Yes; Any inaccuracies: No; Relevant:
    Yes; Correct & complete: Yes, Solution is provided: No'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,VGhlIGJ1ZyBpbiB0aGUgcHJvdmlkZWQgVkhETCBjb2RlIGlzIHRoYXQgdGhlcmUgaXMgYSBtaXNzaW5nICJ0aGVuIiBrZXl3b3JkIGFmdGVyIHRoZSBjb25kaXRpb24gYHJzdCA9ICcxJ2AgaW4gdGhlIGBpZmAgc3RhdGVtZW50LiBUaGlzIGNhdXNlcyBhIHN5bnRheCBlcnJvciB3aGVuIHRoZSBgZWxzaWZgIHN0YXRlbWVudCBpcyBlbmNvdW50ZXJlZCBiZWNhdXNlIHRoZSBwcmV2aW91cyBgaWZgIHN0YXRlbWVudCBpcyBub3QgcHJvcGVybHkgY2xvc2VkLgoKVG8gZml4IHRoaXMgYnVnLCB5b3Ugc2hvdWxkIGFkZCB0aGUgYHRoZW5gIGtleXdvcmQgYWZ0ZXIgdGhlIGNvbmRpdGlvbiBgcnN0ID0gJzEnYCBpbiB0aGUgYGlmYCBzdGF0ZW1lbnQu)1The  bug  in  the  provided  VHDL  code  is  that  there  is  a  missing  ”then”  keyword  after  the  condition  ‘rst  =  ’1’‘  in  the  ‘if‘  statement.  This  causes  a  syntax  error  when  the  ‘elsif‘  statement  is  encountered  because  the  previous  ‘if‘  statement  is  not  properly  closed.23To  fix  this  bug,  you  should  add  the  ‘then‘  keyword  after  the  condition  ‘rst  =  ’1’‘  in  the  ‘if‘  statement.'
  prefs: []
  type: TYPE_NORMAL
- en: '(b) ‘Bad’ explanation—Concept accurate: No; Any inaccuracies: Yes; Relevant:
    No; Correct & complete: No, Solution is provided: No'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Example of ‘good’ and ‘bad’ error explanations for Bug 1 (Figure [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ Explaining EDA synthesis errors with LLMs")) generated
    by gpt-3.5-turbo. Each bug is presented with graded metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: IV Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'IV-A Top-line results:'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Of the graded metrics, we consider the two most important categories ‘Concept
    accurate’ (i.e. the LLM linked to the right error concepts) and ‘Correct & complete’
    (i.e. the LLM provided everything the user needed to fix the problem). Results
    per-bug for these are presented in Table [I](#S3.T1 "Table I ‣ III-B Defining
    a corpus of bugs ‣ III Digital Design Assistance via LLM prompts ‣ Explaining
    EDA synthesis errors with LLMs")’s last four columns. This shows that some bugs
    were easier to explain than others—e.g. Bug 19 was correctly explained in 100%
    of cases. This is likely because certain bugs such as this one are conceptually
    simpler, and more likely to be issues in other languages as well, compared to
    say Bug 7, an error unique to VHDL and only explained correctly in 38% of cases.
  prefs: []
  type: TYPE_NORMAL
- en: Table [II](#S3.T2 "Table II ‣ III-D Prompting LLMs for error explanations ‣
    III Digital Design Assistance via LLM prompts ‣ Explaining EDA synthesis errors
    with LLMs") presents aggregated metrics across IDEs, Languages, Prompting strategies,
    and LLMs. We see that ‘Correct & complete’ can be thought of as a subset of the
    other metrics, i.e. it may be possible to be relevant and accurate but still not
    feature a complete answer. Overall, conceptually accurate explanations were observed
    in 94% of cases, with slight variations across different contexts. We saw only
    rare occasions where explanations featured outright mistakes (No inaccuracies
    in $\approx$71% of cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'IDEs: Quartus sees better explanations than Vivado, indicating that the information
    provided in Quartus’s error messages may be of higher quality. When we performed
    an informal examination of this, we felt this to be true—for instance, Quartus’s
    error message for Bug 1 (in Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Explaining
    EDA synthesis errors with LLMs") (a)) includes the words ‘missing semicolon’,
    unlike Vivado.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Language differences: Interestingly, errors in Verilog seem to be better explained
    than those in VHDL—we theorize this could be because of the relative differences
    in training data available online (Verilog is more popular for open-source).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompting strategies: When comparing the prompting strategies, we see that
    prompts that include the specific error line (EC&L) tend to yield better responses
    ($\approx$67%)—i.e., providing the extra context and information to the language
    models appears to help.'
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs: To fairly compare the LLMs, we tabulated just the first responses (i.e.
    ‘pass@1’) received by gpt-3.5-turbo alongside the responses by gpt-4 and gpt-4-turbo-preview.
    Counter-intuitively, the smaller model (GPT-3.5) outperforms the two larger models
    in ‘correct & complete’, but the larger models are better at returning conceptually
    accurate responses without inaccuracies, although they have a greater tendency
    to over-help.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Discussion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs generate their responses based on the data they have been trained over
    and on their ability to retain that data. For hardware as compared to software,
    there is much less training data online [[10](#bib.bib10)]. Still, when we compare
    our generated HDL explanations with the C error explanations from [[26](#bib.bib26)],
    we see that both works have $\approx$71% correct & complete, indicating that for
    this use case the data gap may not be significant.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, our HDL explanations have a much lower incident rate of over-help
    (‘Solution is provided’) than in [[26](#bib.bib26)]—just 3.35% compared with their
    48%. It is not immediately clear why this could be the case, as they also instructed
    GPT-3.5 to not emit answers directly. Perhaps OpenAI’s LLMs ‘understand’ C better,
    and so inadvertently are aligned to give out too much help. If model size can
    be thought of as a proxy for ‘intelligence’, then this can also be observed with
    the larger model sizes in our work, where the GPT-4 models (which may ‘understand’
    the code better) had a higher rate of over-help compared to the smaller GPT-3.5.
  prefs: []
  type: TYPE_NORMAL
- en: V Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work set out to examine if LLMs could explain the kinds of synthesis errors
    that novice users of EDA tools will encounter. Our findings suggest that they
    indeed can, with 18/21 explored errors seeing good explanations in a majority
    of the LLM responses and 71% of explanations being complete and correct overall.
    This work serves as a valuable proof of concept for LLM-powered techniques for
    improving the accessibility of EDA tools like Vivado and Quartus, and we believe
    that additional research in this area could significantly change how EDA tools
    are both learned and utilised by both novice and experienced engineers.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] S. A. Edwards, “Experiences teaching an FPGA-based embedded systems class,”
    *ACM SIGBED Review*, vol. 2, no. 4, pp. 56–62, Oct. 2005\. [Online]. Available:
    [https://dl.acm.org/doi/10.1145/1121812.1121823](https://dl.acm.org/doi/10.1145/1121812.1121823)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] S. Pasricha, “Embedded Systems Education in the 2020s: Challenges, Reflections,
    and Future Directions,” in *Proceedings of the Great Lakes Symposium on VLSI 2022*,
    ser. GLSVLSI ’22.   New York, NY, USA: Association for Computing Machinery, Jun.
    2022, pp. 519–524\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3526241.3530348](https://dl.acm.org/doi/10.1145/3526241.3530348)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] M. A. Cherney, “U.S. will be short 67,000 chip workers by 2030, industry
    group says,” *Reuters*, Jul. 2023\. [Online]. Available: [https://www.reuters.com/technology/us-will-be-short-67000-chip-workers-by-2030-industry-group-says-2023-07-25/](https://www.reuters.com/technology/us-will-be-short-67000-chip-workers-by-2030-industry-group-says-2023-07-25/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] B. A. Becker, G. Glanville, R. Iwashima, C. McDonnell, K. Goslin, and C. Mooney,
    “Effective compiler error message enhancement for novice programming students,”
    *Computer Science Education*, vol. 26, no. 2-3, pp. 148–175, Jul. 2016\. [Online].
    Available: [https://doi.org/10.1080/08993408.2016.1225464](https://doi.org/10.1080/08993408.2016.1225464)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] I. Karvelas, A. Li, and B. A. Becker, “The Effects of Compilation Mechanisms
    and Error Message Presentation on Novice Programmer Behavior,” in *Proceedings
    of the 51st ACM Technical Symposium on Computer Science Education*, ser. SIGCSE
    ’20.   New York, NY, USA: Association for Computing Machinery, Feb. 2020, pp.
    759–765\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3328778.3366882](https://dl.acm.org/doi/10.1145/3328778.3366882)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] M. Ben-Ari, “Constructivism in Computer Science Education,” *Journal of
    Computers in Mathematics and Science Teaching*, vol. 20, no. 1, pp. 45–73, 2001,
    publisher: Association for the Advancement of Computing in Education (AACE). [Online].
    Available: [https://www.learntechlib.org/primary/p/8505/](https://www.learntechlib.org/primary/p/8505/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens,
    A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe, “Training language
    models to follow instructions with human feedback,” in *Advances in Neural Information
    Processing Systems*, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and
    A. Oh, Eds., vol. 35.   Curran Associates, Inc., 2022, pp. 27 730–27 744\. [Online].
    Available: [https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] OpenAI, “ChatGPT: Optimizing Language Models for Dialogue,” Nov. 2022\.
    [Online]. Available: [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] H. Pearce, B. Tan, and R. Karri, “DAVE: Deriving Automatically Verilog
    from English,” in *Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning
    for CAD*.   Virtual Event Iceland: ACM, Nov. 2020, pp. 27–32\. [Online]. Available:
    [https://dl.acm.org/doi/10.1145/3380446.3430634](https://dl.acm.org/doi/10.1145/3380446.3430634)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-Gavitt,
    and S. Garg, “Benchmarking Large Language Models for Automated Verilog RTL Code
    Generation,” in *2023 Design, Automation & Test in Europe Conference & Exhibition
    (DATE)*, Apr. 2023, pp. 1–6, iSSN: 1558-1101\. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10137086](https://ieeexplore.ieee.org/abstract/document/10137086)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] S. Thakur, B. Ahmad, H. Pearce, B. Tan, B. Dolan-Gavitt, R. Karri, and
    S. Garg, “VeriGen: A Large Language Model for Verilog Code Generation,” *ACM Transactions
    on Design Automation of Electronic Systems*, Feb. 2024, just Accepted. [Online].
    Available: [https://dl.acm.org/doi/10.1145/3643681](https://dl.acm.org/doi/10.1145/3643681)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] M. Liu, N. Pinckney, B. Khailany, and H. Ren, “Invited Paper: VerilogEval:
    Evaluating Large Language Models for Verilog Code Generation,” in *2023 IEEE/ACM
    International Conference on Computer Aided Design (ICCAD)*, Oct. 2023, pp. 1–8,
    iSSN: 1558-2434\. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10323812](https://ieeexplore.ieee.org/abstract/document/10323812)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, “On Hardware Security
    Bug Code Fixes By Prompting Large Language Models,” *IEEE Transactions on Information
    Forensics and Security*, pp. 1–1, 2024, conference Name: IEEE Transactions on
    Information Forensics and Security. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10462177](https://ieeexplore.ieee.org/abstract/document/10462177)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] R. Kande, H. Pearce, B. Tan, B. Dolan-Gavitt, S. Thakur, R. Karri, and
    J. Rajendran, “(Security) Assertions by Large Language Models,” *IEEE Transactions
    on Information Forensics and Security*, pp. 1–1, 2024, conference Name: IEEE Transactions
    on Information Forensics and Security. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10458667](https://ieeexplore.ieee.org/abstract/document/10458667)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] M. Liu, T.-D. Ene, R. Kirby, C. Cheng, N. Pinckney, R. Liang, J. Alben,
    H. Anand, S. Banerjee, I. Bayraktaroglu, B. Bhaskaran, B. Catanzaro, A. Chaudhuri,
    S. Clay, B. Dally, L. Dang, P. Deshpande, S. Dhodhi, S. Halepete, E. Hill, J. Hu,
    S. Jain, B. Khailany, K. Kunal, X. Li, H. Liu, S. Oberman, S. Omar, S. Pratty,
    J. Raiman, A. Sarkar, Z. Shao, H. Sun, P. P. Suthar, V. Tej, K. Xu, and H. Ren,
    “ChipNeMo: Domain-Adapted LLMs for Chip Design,” Nov. 2023, arXiv:2311.00176 [cs].
    [Online]. Available: [http://arxiv.org/abs/2311.00176](http://arxiv.org/abs/2311.00176)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] J. Blocklove, S. Garg, R. Karri, and H. Pearce, “Chip-Chat: Challenges
    and Opportunities in Conversational Hardware Design,” in *2023 ACM/IEEE 5th Workshop
    on Machine Learning for CAD (MLCAD)*, Sep. 2023, pp. 1–6\. [Online]. Available:
    [https://ieeexplore.ieee.org/document/10299874](https://ieeexplore.ieee.org/document/10299874)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] E. Kasneci, K. Sessler, S. Küchemann, M. Bannert, D. Dementieva, F. Fischer,
    U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier, S. Krusche, G. Kutyniok, T. Michaeli,
    C. Nerdel, J. Pfeffer, O. Poquet, M. Sailer, A. Schmidt, T. Seidel, M. Stadler,
    J. Weller, J. Kuhn, and G. Kasneci, “ChatGPT for good? On opportunities and challenges
    of large language models for education,” *Learning and Individual Differences*,
    vol. 103, p. 102274, Apr. 2023\. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S1041608023000195](https://www.sciencedirect.com/science/article/pii/S1041608023000195)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] R. Dijkstra, Z. Genç, S. Kayal, J. Kamps, and others, “Reading Comprehension
    Quiz Generation using Generative Pre-trained Transformers,” 2022\. [Online]. Available:
    [https://e.humanities.uva.nl/publications/2022/dijk_read22.pdf](https://e.humanities.uva.nl/publications/2022/dijk_read22.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] E. Gabajiwala, P. Mehta, R. Singh, and R. Koshy, “Quiz Maker: Automatic
    Quiz Generation from Text Using NLP,” in *Futuristic Trends in Networks and Computing
    Technologies*, ser. Lecture Notes in Electrical Engineering, P. K. Singh, S. T.
    Wierzchoń, J. K. Chhabra, and S. Tanwar, Eds.   Singapore: Springer Nature, 2022,
    pp. 523–533.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] S. Jalil, S. Rafi, T. D. LaToza, K. Moran, and W. Lam, “ChatGPT and Software
    Testing Education: Promises & Perils,” in *2023 IEEE International Conference
    on Software Testing, Verification and Validation Workshops (ICSTW)*, Apr. 2023,
    pp. 4130–4137, iSSN: 2159-4848\. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10132255](https://ieeexplore.ieee.org/abstract/document/10132255)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] B. A. Becker, P. Denny, J. Finnie-Ansley, A. Luxton-Reilly, J. Prather,
    and E. A. Santos, “Programming Is Hard - Or at Least It Used to Be: Educational
    Opportunities and Challenges of AI Code Generation,” in *Proceedings of the 54th
    ACM Technical Symposium on Computer Science Education V. 1*, ser. SIGCSE 2023.   New
    York, NY, USA: Association for Computing Machinery, Mar. 2023, pp. 500–506\. [Online].
    Available: [https://dl.acm.org/doi/10.1145/3545945.3569759](https://dl.acm.org/doi/10.1145/3545945.3569759)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] P. Denny, V. Kumar, and N. Giacaman, “Conversing with Copilot: Exploring
    Prompt Engineering for Solving CS1 Problems Using Natural Language,” in *Proceedings
    of the 54th ACM Technical Symposium on Computer Science Education V. 1*, ser.
    SIGCSE 2023.   New York, NY, USA: Association for Computing Machinery, Mar. 2023,
    pp. 1136–1142\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3545945.3569823](https://dl.acm.org/doi/10.1145/3545945.3569823)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] S. MacNeil, A. Tran, J. Leinonen, P. Denny, J. Kim, A. Hellas, S. Bernstein,
    and S. Sarsa, “Automatically Generating CS Learning Materials with Large Language
    Models,” in *Proceedings of the 54th ACM Technical Symposium on Computer Science
    Education V. 2*, Mar. 2022, pp. 1176–1176, arXiv:2212.05113 [cs]. [Online]. Available:
    [http://arxiv.org/abs/2212.05113](http://arxiv.org/abs/2212.05113)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] S. MacNeil, A. Tran, A. Hellas, J. Kim, S. Sarsa, P. Denny, S. Bernstein,
    and J. Leinonen, “Experiences from Using Code Explanations Generated by Large
    Language Models in a Web Software Development E-Book,” in *Proceedings of the
    54th ACM Technical Symposium on Computer Science Education V. 1*, ser. SIGCSE
    2023.   New York, NY, USA: Association for Computing Machinery, Mar. 2023, pp.
    931–937\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3545945.3569785](https://dl.acm.org/doi/10.1145/3545945.3569785)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] S. MacNeil, A. Tran, D. Mogil, S. Bernstein, E. Ross, and Z. Huang, “Generating
    Diverse Code Explanations using the GPT-3 Large Language Model,” in *Proceedings
    of the 2022 ACM Conference on International Computing Education Research - Volume
    2*, ser. ICER ’22, vol. 2.   New York, NY, USA: Association for Computing Machinery,
    Aug. 2022, pp. 37–39\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3501709.3544280](https://dl.acm.org/doi/10.1145/3501709.3544280)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] A. Taylor, A. Vassar, J. Renzella, and H. Pearce, “dcc –help: Transforming
    the Role of the Compiler by Generating Context-Aware Error Explanations with Large
    Language Models,” in *Proceedings of the 55th ACM Technical Symposium on Computer
    Science Education V. 1*, ser. SIGCSE 2024.   New York, NY, USA: Association for
    Computing Machinery, Mar. 2024, pp. 1314–1320\. [Online]. Available: [https://dl.acm.org/doi/10.1145/3626252.3630822](https://dl.acm.org/doi/10.1145/3626252.3630822)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Figure [4](#Sx1.F4 "Figure 4 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") shows the system and user prompt templates used to generate the error explanations
    in this study. Prompting was the same for all 3 OpenAI models.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,WW91IGFyZSBhIGhlbHBmdWwgYXNzaXN0YW50IHdoaWNoIGRlYnVncyBSVEwgYW5kIEhETCBjb2RlIGluIFZlcmlsb2cgYW5kIFZIREwuIERvIG5vdCBwcm92aWRlIGNvZGUgaW4geW91ciBhbnN3ZXIuIEV4cGxhaW4gd2hhdCBoYXMgZ29uZSB3cm9uZyBhbmQgd2h5IGEgYnVnIGlzIG9jY3VycmluZywgYnV0IGRvIG5vdCBhdHRlbXB0IHRvIGZpeCB0aGUgYnVnIHlvdXJzZWxmLg==)1You  are  a  helpful  assistant  which  debugs  RTL  and  HDL  code  in  Verilog  and  VHDL.  Do  not  provide  code  in  your  answer.  Explain  what  has  gone  wrong  and  why  a  bug  is  occurring,  but  do  not  attempt  to  fix  the  bug  yourself.'
  prefs: []
  type: TYPE_NORMAL
- en: (a) System prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,RXJyb3IgbWVzc2FnZTogJXMKCkZ1bGwgY29kZSBmaWxlOmBgYCVzYGBgCgpXaGF0IGlzIHRoZSBidWcgYW5kIHdoeSBpcyBpdCBvY2N1cnJpbmc/)1Error  message:  %s23Full  code  file:“‘%s“‘45What  is  the  bug  and  why  is  it  occurring?'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Error & Code (E&C) prompt template.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,RXJyb3IgbWVzc2FnZTogJXMKCkVycm9yIGxpbmU6YGBgJXNgYGAKCkZ1bGwgY29kZSBmaWxlOmBgYCVzYGBgCgpXaGF0IGlzIHRoZSBidWcgYW5kIHdoeSBpcyBpdCBvY2N1cnJpbmc/)1Error  message:  %s23Error  line:“‘%s“‘45Full  code  file:“‘%s“‘67What  is  the  bug  and  why  is  it  occurring?'
  prefs: []
  type: TYPE_NORMAL
- en: (c) Error, Code, & Line (EC&L) prompt template.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: LLM prompts'
  prefs: []
  type: TYPE_NORMAL
- en: Figure [5](#Sx1.F5 "Figure 5 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") shows an explanation with ‘solution is provided’.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,VGhlIGVycm9yIG1lc3NhZ2UgaXMgaW5kaWNhdGluZyB0aGF0IHRoZXJlJ3Mgc3ludGF4IGVycm9yIG5lYXIgdGhlICdlbHNpZicga2V5d29yZC4KCkJ5IGxvb2tpbmcgYXQgeW91ciBWSERMIGNvZGUsIHRoZSBwcm9ibGVtIGlzIHRoYXQgeW91IGFyZSBtaXNzaW5nIGEgc2VtaWNvbG9uIGF0IHRoZSBlbmQgb2YgdGhlIGxpbmUgYWZ0ZXIgdGhlIGFzc2lnbm1lbnQgb3BlcmF0aW9uIHdoZW4gdGhlIHJzdCBpcyAnMScuIEluIFZIREwsIGV2ZXJ5IHN0YXRlbWVudCBlbmRzIHdpdGggYSBzZW1pY29sb24uCgpUaGUgbGluZSBvZiB0aGUgY29kZToKYGBgCmlmIHJzdCA9ICcxJyB0aGVuCiAgICBkYXRhX291dCA8PSAob3RoZXJzID0+ICcwJykgICAgIC0tTWlzc2luZyBzZW1pY29sb24gaGVyZQpgYGAKClNob3VsZCBiZSBjb3JyZWN0ZWQgd2l0aCBhIHNlbWljb2xvbiBhdCB0aGUgZW5kIGFzOgpgYGAKaWYgcnN0ID0gJzEnIHRoZW4KICAgIGRhdGFfb3V0IDw9IChvdGhlcnMgPT4gJzAnKTsgICAgLS1BZGQgc2VtaWNvbG9uIGhlcmUKYGBgCgpZb3VyIHN5bnRoZXNpemVyICh0aGUgdG9vbCB0aGF0J3MgcHJvY2Vzc2luZyB5b3VyIFZIREwgY29kZSkgaXMgc2VlaW5nIHRoZSAnZWxzaWYnIGFzIGJlaW5nIHBhcnQgb2YgdGhlIHByZXZpb3VzIGxpbmUgKGJlY2F1c2UgdGhlcmUgd2FzIG5vIHNlbWljb2xvbiB0byBlbmQgaXQpIGFuZCBpcyBjb25mdXNlZCBhcyB0aGlzIGRvZXNuJ3QgbWFrZSBzZW5zZSBhbmQgdGhlcmVmb3JlIHRocm93cyBhbiBlcnJvci4gVGhpcyBpcyB3aHkgdGhlIGVycm9yIG1lc3NhZ2UgaXMgc3VnZ2VzdGluZyB0aGVyZSBtYXkgYmUgYSBwcm9ibGVtIG5lYXIgdGhlICdlbHNpZicuCgpBZnRlciBhZGRpbmcgdGhlIHNlbWljb2xvbiBhdCB0aGUgZW5kIG9mIHRoZSBsaW5lIGluIHF1ZXN0aW9uLCB0aGUgaXNzdWUgc2hvdWxkIGJlIHJlc29sdmVkLg==)1The  error  message  is  indicating  that  there’s  syntax  error  near  the  ’elsif’  keyword.23By  looking  at  your  VHDL  code,  the  problem  is  that  you  are  missing  a  semicolon  at  the  end  of  the  line  after  the  assignment  operation  when  the  rst  is  ’1’.  In  VHDL,  every  statement  ends  with  a  semicolon.45The  line  of  the  code:6“‘7if  rst  =  ’1’  then8  data_out  <=  (others  =>  ’0’)  –Missing  semicolon  here9“‘1011Should  be  corrected  with  a  semicolon  at  the  end  as:12“‘13if  rst  =  ’1’  then14  data_out  <=  (others  =>  ’0’);  –Add  semicolon  here15“‘1617Your  synthesizer  (the  tool  that’s  processing  your  VHDL  code)  is  seeing  the  ’elsif’  as  being  part  of  the  previous  line  (because  there  was  no  semicolon  to  end  it)  and  is  confused  as  this  doesn’t  make  sense  and  therefore  throws  an  error.  This  is  why  the  error  message  is  suggesting  there  may  be  a  problem  near  the  ’elsif’.1819After  adding  the  semicolon  at  the  end  of  the  line  in  question,  the  issue  should  be  resolved.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scores—Concept accurate: Yes; Any inaccuracies: No; Relevant: Yes; Correct
    & complete: Yes, Solution is provided: Yes'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5: A ‘good’ error explanation for Bug 1 (Figure [1](#S1.F1 "Figure 1
    ‣ I Introduction ‣ Explaining EDA synthesis errors with LLMs")) generated by gpt-4.
    However, this explanation is flagged ‘Solution is provided’ as it contains a direct
    copy/paste solution on Lines 12-15—i.e., the explanation helps ‘too much’ according
    to constructivism in pedagogy.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure [6](#Sx1.F6 "Figure 6 ‣ Appendix ‣ Explaining EDA synthesis errors with
    LLMs") illustrates the difference between an explanation flagged as ‘relevant’
    versus one flagged as ‘concept accurate’, i.e. the two metrics do not necessarily
    imply each other.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,VGhlIGVycm9yIG1lc3NhZ2UgInN5bnRheCBlcnJvciBuZWFyIGVsc2lmIiBpcyBpbmRpY2F0aW5nIHRoYXQgdGhlcmUncyBhIHN5bnRheCBpc3N1ZSBuZWFyIHRoZSAiZWxzaWYiIGtleXdvcmQgaW4geW91ciBjb2RlLgoKSW4gdGhpcyBjYXNlLCB0aGUgZXJyb3IgaXMgdHJpZ2dlcmVkIGJ5IHRoZSBtaXN1c2Ugb2YgdGhlICJyaXNpbmdfZWRnZSIgZnVuY3Rpb24gaW4gVkhETC4gVGhlIGZ1bmN0aW9uIGV4cGVjdHMgYSBzaWduYWwgYXMgaXRzIGFyZ3VtZW50IGFuZCBjaGVja3Mgd2hldGhlciB0aGVyZSdzIGEgcmlzaW5nIGVkZ2UgKGxvdyB0byBoaWdoIHRyYW5zaXRpb24pIG9uIHRoYXQgc2lnbmFsLiBJdCdzIHR5cGljYWxseSB1c2VkIHdpdGggYSBjbG9jayBzaWduYWwgaW5zaWRlIGEgcHJvY2Vzcy4KCkhvd2V2ZXIsIHRoZSBpc3N1ZSBoZXJlIGlzIHRoYXQgdGhlICJlbHNpZiIga2V5d29yZCBpcyBiZWluZyB1c2VkIGluIGNvbmp1bmN0aW9uIHdpdGggdGhlICJyaXNpbmdfZWRnZSIgZnVuY3Rpb24uIEluIFZIREwsIHlvdSBkb24ndCB0eXBpY2FsbHkgdXNlICJlbHNpZiIgd2l0aCAicmlzaW5nX2VkZ2UiLiBJbnN0ZWFkLCB0aGUgdXN1YWwgY29uc3RydWN0IHdvdWxkIGJlICJpZiByaXNpbmdfZWRnZShjbGspIiBkaXJlY3RseSBmb2xsb3dpbmcgdGhlIHByb2Nlc3MgZGVjbGFyYXRpb24uCgpJdCdzIGxpa2VseSB0aGF0IHRoZSAiZWxzaWYiIGlzIGludGVuZGVkIHRvIG1ha2UgdGhlIGRhdGFfb3V0IGFzc2lnbm1lbnQgaGFwcGVuIGJhc2VkIG9uIGEgcmlzaW5nIGVkZ2UgZXZlbnQgb24gdGhlIGNsb2NrLCBidXQgYWZ0ZXIgYSByZXNldC4gVGhlIGNvcnJlY3QgdXNhZ2Ugd291bGQgYmUgdG8gbmVzdCAiaWYgcmlzaW5nX2VkZ2UoY2xrKSIgaW5zaWRlIHRoZSAiaWYgcnN0ID0gJzEnIiBjb25kaXRpb24sIGFzIHRoZSBmaXJzdCB0byBiZSBwcm9jZXNzZWQuCgpQbGVhc2UgcmVtZW1iZXIgdGhhdCB5b3Ugc2hvdWxkIHBsYWNlIHRoZSByZXNldCBhbmQgY2xvY2sgY29uZGl0aW9ucyB1bmRlciBzZXBhcmF0ZSBpZiBjb25kaXRpb25zIHRvIGF2b2lkIGFtYmlndWl0aWVzIGluIHRoZSBkZXNjcmlwdGlvbnMu)1The  error  message  ”syntax  error  near  elsif”  is  indicating  that  there’s  a  syntax  issue  near  the  ”elsif”  keyword  in  your  code.23In  this  case,  the  error  is  triggered  by  the  misuse  of  the  ”rising_edge”  function  in  VHDL.  The  function  expects  a  signal  as  its  argument  and  checks  whether  there’s  a  rising  edge  (low  to  high  transition)  on  that  signal.  It’s  typically  used  with  a  clock  signal  inside  a  process.45However,  the  issue  here  is  that  the  ”elsif”  keyword  is  being  used  in  conjunction  with  the  ”rising_edge”  function.  In  VHDL,  you  don’t  typically  use  ”elsif”  with  ”rising_edge”.  Instead,  the  usual  construct  would  be  ”if  rising_edge(clk)”  directly  following  the  process  declaration.67It’s  likely  that  the  ”elsif”  is  intended  to  make  the  data_out  assignment  happen  based  on  a  rising  edge  event  on  the  clock,  but  after  a  reset.  The  correct  usage  would  be  to  nest  ”if  rising_edge(clk)”  inside  the  ”if  rst  =  ’1’”  condition,  as  the  first  to  be  processed.89Please  remember  that  you  should  place  the  reset  and  clock  conditions  under  separate  if  conditions  to  avoid  ambiguities  in  the  descriptions.'
  prefs: []
  type: TYPE_NORMAL
- en: (a) ‘Bad’ explanation by gpt-4 which is relevant but with inaccurate concepts,
    linking to issues with clock edges instead of the actual syntax fault
  prefs: []
  type: TYPE_NORMAL
- en: 'Scores—Concept accurate: No; Any inaccuracies: Yes; Relevant: Yes; Correct
    & complete: No, Solution is provided: No'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,VGhlIGJ1ZyBpbiB0aGUgY29kZSBpcyB0aGF0IHRoZSBgZWxzaWZgIHN0YXRlbWVudCBpcyBtaXNzaW5nIGEgc2VtaWNvbG9uIGF0IHRoZSBlbmQgb2YgdGhlIGFzc2lnbm1lbnQgaW4gdGhlIHByb2Nlc3MuIFRoaXMgaXMgY2F1c2luZyBhIHN5bnRheCBlcnJvciBiZWNhdXNlIHRoZSBWSERMIHN5bnRheCBleHBlY3RzIGEgc2VtaWNvbG9uIGFmdGVyIGVhY2ggc3RhdGVtZW50IHdpdGhpbiB0aGUgYGlmLWVsc2lmYCBzdHJ1Y3R1cmUu)1The  bug  in  the  code  is  that  the  ‘elsif‘  statement  is  missing  a  semicolon  at  the  end  of  the  assignment  in  the  process.  This  is  causing  a  syntax  error  because  the  VHDL  syntax  expects  a  semicolon  after  each  statement  within  the  ‘if-elsif‘  structure.'
  prefs: []
  type: TYPE_NORMAL
- en: (b) ‘Bad’ explanation by gpt-3.5-turbo which has the right concepts but with
    irrelevant info. (the elsif has a semicolon on its later clause).
  prefs: []
  type: TYPE_NORMAL
- en: 'Scores—Concept accurate: Yes; Any inaccuracies: Yes; Relevant: No; Correct
    & complete: No, Solution is provided: No'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Demonstrating the difference between ‘relevance’ and ‘concept accurate’
    with two ‘bad’ error explanations for Bug 1 (Figure [1](#S1.F1 "Figure 1 ‣ I Introduction
    ‣ Explaining EDA synthesis errors with LLMs"))'
  prefs: []
  type: TYPE_NORMAL
