- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:53:31'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Are LLMs Any Good for High-Level Synthesis?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.10428](https://ar5iv.labs.arxiv.org/html/2408.10428)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yuchao Liao Electrical and Computer Engineering
  prefs: []
  type: TYPE_NORMAL
- en: University of ArizonaTucsonArizona, USA [yuchaoliao@arizona.edu](mailto:yuchaoliao@arizona.edu)
    ,  Tosiron Adegbija Electrical and Computer Engineering
  prefs: []
  type: TYPE_NORMAL
- en: University of ArizonaTucsonArizona, USA [tosiron@arizona.edu](mailto:tosiron@arizona.edu)
     and  Roman Lysecky Electrical and Computer Engineering
  prefs: []
  type: TYPE_NORMAL
- en: University of ArizonaTucsonArizona, USA [rlysecky@arizona.edu](mailto:rlysecky@arizona.edu)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The increasing complexity and demand for faster, energy-efficient hardware designs
    necessitate innovative High-Level Synthesis (HLS) methodologies. This paper explores
    the potential of Large Language Models (LLMs) to streamline or replace the HLS
    process, leveraging their ability to understand natural language specifications
    and refactor code. We survey the current research and conduct experiments comparing
    Verilog designs generated by a standard HLS tool (Vitis HLS) with those produced
    by LLMs translating C code or natural language specifications. Our evaluation
    focuses on quantifying the impact on performance, power, and resource utilization,
    providing an assessment of the efficiency of LLM-based approaches. This study
    aims to illuminate the role of LLMs in HLS, identifying promising directions for
    optimized hardware design in applications such as AI acceleration, embedded systems,
    and high-performance computing.
  prefs: []
  type: TYPE_NORMAL
- en: 'High-level synthesis, hardware accelerator design, electronic design automation,
    large language models^†^†ccs: Hardware High-level and register-transfer level
    synthesis^†^†ccs: Computing methodologies Machine learning'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The increasing demand for custom hardware accelerators, driven by applications
    ranging from artificial intelligence to high-performance computing, necessitates
    innovative design methodologies to meet the challenges of rapidly evolving technology.
    High-Level Synthesis (HLS) has emerged as a valuable approach for designing, synthesizing,
    and optimizing hardware systems. HLS (Coussy et al., [2009](#bib.bib9)) enables
    designers to define systems at a high abstraction level, independent of low-level
    circuit specifics, and utilize HLS tools to produce an optimized low-level hardware
    description of the target system. With current HLS tools (e.g., Vitis HLS, SmartHLS),
    designers can create application-specific embedded systems using high-level languages
    like C/C++ and translate them into register-transfer level (RTL) implementations
    using hardware description languages (e.g., Verilog. VHDL), thereby enhancing
    design productivity and reducing both design time and cost. Despite the advantages
    of HLS, the tools can still be time-consuming to use and demand considerable expertise,
    thus creating the potential for substantial improvement, especially with the integration
    of technologies like large language models (LLMs).
  prefs: []
  type: TYPE_NORMAL
- en: Recent advancements in LLMs (Zhao et al., [2023](#bib.bib31)) have showcased
    their ability to automate various computational tasks, including code generation
    and software engineering. This presents a unique opportunity to explore the potential
    of LLMs in streamlining the HLS process, from high-level language specifications
    to efficient hardware implementations (Chang et al., [2023](#bib.bib7)). The ability
    of LLMs to understand and generate code, combined with the potential for natural
    language interaction, can revolutionize the way we design hardware, making the
    process more accessible and less time-consuming. This integration can lead to
    significant improvements in design productivity and efficiency, ultimately transforming
    the landscape of hardware development.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we explore the burgeoning field of LLMs for HLS, which has sparked
    growing interest. We first present a taxonomy of LLM use cases for HLS, highlighting
    the various ways these models can be integrated into the design flow. Building
    on this foundation, we survey the state-of-the-art, highlighting the most promising
    research and techniques. To assess the viability of LLMs in the HLS design flow,
    we perform an experimental evaluation, comparing the Verilog designs generated
    using a standard HLS tool, specifically Vitis HLS, to those produced with LLM-based
    approaches. These approaches include direct LLM translation of C benchmarks from
    the PolyBench Suite (Pouchet and Yuki, [2012](#bib.bib21)) to Verilog using ChatGPT-4o,
    and the use of LLMs to interpret natural language specifications into both benchmarks
    and Verilog. Our evaluation focuses on the quality (performance, power, resource
    utilization) of designs produced by each methodology.
  prefs: []
  type: TYPE_NORMAL
- en: 'This study seeks to answer several key questions: Can existing LLMs generate
    Verilog code comparable in quality to that produced by traditional HLS tools?
    What are the advantages and limitations of using LLMs in this context? Could the
    natural language understanding capabilities of LLMs open up new avenues for hardware
    design? By addressing these questions, we aim to provide valuable insights into
    the role of LLMs in HLS and their potential to transform the future of hardware
    design.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3e59caf93f22737ecc9b9e66bdd56e6d.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1. Taxonomy of LLM applications in HLS
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Taxonomy of LLM for HLS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The application of LLMs to different stages of the HLS process has emerged
    as a promising research direction. To provide a structured overview of this evolving
    landscape, we present a taxonomy (illustrated in Figure [1](#S1.F1 "Figure 1 ‣
    1\. Introduction ‣ Are LLMs Any Good for High-Level Synthesis?")) that categorizes
    LLMs based on their primary role in HLS: specification generators, design space
    exploration assistants, code generators, and hardware verification tools. This
    classification provides a framework for understanding how LLMs can augment HLS
    methodologies, as detailed in the following subsections.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. LLM as Specification Generator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs hold promise as specification generators in HLS, translating natural language
    or higher-level code into HLS-compatible formats (e.g., HLS-C) (Swaroopa et al.,
    [2024](#bib.bib24); Collini et al., [2024](#bib.bib8); Xu et al., [2024](#bib.bib30)).
    This allows for intuitive and accessible expression of hardware functionality.
    Challenges persist in mitigating ambiguities inherent in natural language, which
    can lead to misinterpretations. Techniques like prompting, clarification dialogues,
    and formal verification are crucial for ensuring the correctness of LLM-generated
    specifications (Lu et al., [2024](#bib.bib16)).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. LLM as Code Generator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs can help with code generation, directly generating synthesizable HDL from
    high-level specifications (Blocklove et al., [2023](#bib.bib5); Thakur et al.,
    [2024](#bib.bib27); Chang et al., [2023](#bib.bib7)). This automation can boost
    productivity and reduce errors. The challenge lies in ensuring generated code
    quality and providing designers control over code structure and style (Lu et al.,
    [2024](#bib.bib16)). Recent research demonstrates LLM capabilities in generating
    functional HDL for various hardware components, including arithmetic units (Liu
    et al., [2023](#bib.bib15)), controllers, and simple processors (Blocklove et al.,
    [2023](#bib.bib5)), suggesting a promising future for this approach.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. LLM as Hardware Verification Assistant
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs can assist with hardware verification in HLS, by automating the generation
    of test cases and identifying potential design flaws (Ahmad et al., [2024](#bib.bib2);
    Kande et al., [2023](#bib.bib13)). This can lead to significant time savings and
    improved design reliability. However, challenges persist in ensuring the accuracy
    of LLM-generated test cases and their integration into existing HLS workflows.
    Ongoing research (Orenes-Vera et al., [2023](#bib.bib20)) explores the potential
    of LLMs in areas like formal verification, further highlighting their potential
    in ensuring the correctness of complex designs.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4\. LLM as Design Space Exploration Assistant
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although receiving less attention than other applications, LLMs are promising
    in aiding HLS design space exploration (DSE) by suggesting optimizations and exploring
    design alternatives (Liao et al., [2023](#bib.bib14)). Their ability to analyze
    design constraints and objectives can lead to faster design cycles and innovative
    solutions. However, effective LLM DSE assistance requires incorporating domain-specific
    knowledge and addressing potential biases in suggestions. Recent research shows
    LLMs can optimize hardware accelerators, explore neural network architectures,
    and propose circuit-level optimizations, emphasizing their transformative potential
    for DSE (Thakur et al., [2023](#bib.bib26)).
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Survey of the State-of-the-Art in LLMs for HLS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section surveys the diverse applications of LLMs in HLS, spanning hardware
    design automation, software-hardware co-design, and design of embedded systems.
    We examine key research areas such as natural language processing (NLP) to HDL
    translation, code generation, optimization and verification, and multimodal approaches.
    We also discuss input modalities used in the state-of-the-art, like textual descriptions
    and pseudocode, and the output modalities such as HDLs (VHDL, Verilog, SystemVerilog)
    and HLS-compatible programs (e.g., HLS-C). Finally, we highlight current approaches
    to benchmarking and evaluating LLM-driven HLS, emphasizing the need for standardized
    metrics and datasets to facilitate fair comparisons and drive further advancements
    in this rapidly evolving field.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. LLMs Used for HLS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recent advancements in LLMs such as ChatGPT, Gemini, Claude, and LLAMA have
    great potential for use in HLS. While many current works leverage the popular
    ChatGPT for their HLS experimentation, both general-purpose and custom-tuned LLMs
    have been utilized to automate and optimize synthesis processes (Fu et al., [2024](#bib.bib11)).
    As expected, fine-tuning models on domain-specific data often yields superior
    performance in generating desired outputs within the HLS workflow. For instance,
    Nadim et al. (Nadimi and Zheng, [2024](#bib.bib18)) introduced a multi-expert
    LLM architecture to address the challenges of design complexity. By using specialized
    models and a complexity classifier, they achieved an improvement of up to 23.9%
    in the pass@k metric. However, a consistent theme emerging from both existing
    literature and our experiments is the necessity of human-in-the-loop (HITL) approaches
    for successful LLM integration in HLS. For example, Collini et al. (Collini et al.,
    [2024](#bib.bib8)) highlighted the significant human expert guidance required
    for converting a C-based QuickSort kernel to HLS-C. Similarly, Swaroopa et al.
    (Swaroopa et al., [2024](#bib.bib24)) demonstrated a semi-automated approach for
    generating HLS-C from natural language using LLMs, acknowledging the need for
    human intervention in the design process, though their work did not evaluate the
    quality of the resulting designs. Such a HITL approach leverages the computational
    strengths of LLMs while retaining the nuanced understanding and decision-making
    capabilities of human experts, to achieve superior HLS outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The increasing interest in applying LLMs to HLS has led to promising developments
    across various domains. For example, LLMs have shown success in automating the
    generation of analog/mixed-signal (AMS) circuit netlists from transistor-level
    schematics (Tao et al., [2024](#bib.bib25)). In the domain of RTL generation,
    LLMs have demonstrated their capability to generate RTL code from natural language
    descriptions (Lu et al., [2024](#bib.bib16)) and, as explored in (Blocklove et al.,
    [2023](#bib.bib5)), have the potential to aid in writing and debugging HDL code
    through conversational interactions with existing LLM tools like ChatGPT. Additionally,
    LLMs are being integrated into tools like MATLAB and Simulink to translate high-level
    design specifications into synthesizable Verilog and VHDL code, streamlining the
    HDL generation process. In the domain of code security, Nair et al. (Nair et al.,
    [2023](#bib.bib19)) investigated the vulnerabilities in hardware code generated
    by ChatGPT, specifically analyzing common weaknesses enumerations (CWE) and proposing
    strategies to guide secure hardware code generation.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond these applications, LLMs are being explored for broader roles in the
    HLS workflow. Recent work has explored the potential of LLMs to refactor existing
    C code into HLS-compatible formats, bridging the gap between software and hardware
    design (Collini et al., [2024](#bib.bib8); Fu et al., [2023](#bib.bib12); Swaroopa
    et al., [2024](#bib.bib24); Xu et al., [2024](#bib.bib30)). Models like ChatGPT
    have been leveraged to convert high-level design specifications into synthesizable
    HDL, targeting specific hardware components such as random number generators (Meech,
    [2023](#bib.bib17)). They have been used for automated code repair and optimization
    to improve the quality of HLS-C programs (Xu et al., [2024](#bib.bib30)). Furthermore,
    LLMs have shown promise in generating HLS pragmas (Fu et al., [2023](#bib.bib12);
    Xu et al., [2024](#bib.bib30)), which are compiler directives that can significantly
    impact the quality of the generated hardware. Moreover, the use of LLMs for automated
    testbench generation (Qiu et al., [2024](#bib.bib22); Bhandari et al., [2024](#bib.bib4))
    and hardware design verification tasks (Ahmad et al., [2024](#bib.bib2); Kande
    et al., [2023](#bib.bib13)) further expands their potential applications in HLS.
    The growing breadth of LLM applications in HLS underscores their potential to
    enhance automation, efficiency, and accessibility throughout the hardware design
    process.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8f42ed431a2861747bcc53a51b96b4fd.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) HLS-based approach
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4d4e359b1f0c2ebdebd3933b30862d06.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) LLM-based approaches
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2. HLS-based (a) and LLM-based (b) approaches to generating hardware
    accelerators
  prefs: []
  type: TYPE_NORMAL
- en: 3.3\. Input and Output Modalities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The versatility of LLMs in HLS stems, in part, from their ability to process
    and generate information across diverse modalities. Textual descriptions, including
    high-level design specifications, natural language explanations of functionality,
    and code snippets in languages like C/C++ often serve as primary input modalities.
    LLMs can transform these textual inputs into HDL such as Verilog or VHDL, as seen
    in applications that convert natural language descriptions directly to HDL (Meech,
    [2023](#bib.bib17); Blocklove et al., [2023](#bib.bib5); Lu et al., [2024](#bib.bib16)).
    Beyond text, advanced LLMs are increasingly capable of handling multimodal inputs,
    which incorporate images, schematics, or other data types (Chang et al., [2024](#bib.bib6)).
    This can allow for a more nuanced understanding of design requirements by integrating
    visual and textual information.
  prefs: []
  type: TYPE_NORMAL
- en: The output modalities of LLMs for HLS are equally diverse. Primarily, LLMs can
    generate synthesizable HDL code from textual or multimodal inputs (Lu et al.,
    [2024](#bib.bib16)). Additionally, LLMs can optimize existing code by automatically
    inserting and tuning pragmas to enhance the synthesis process. Moreover, LLMs
    can generate testbenches and verification scripts, which are vital to validate
    the functionality and performance of the synthesized hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4\. Benchmarking and Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The evaluation and advancement of LLMs in HLS rely on robust benchmarks and
    datasets. Several key initiatives have emerged to address this need, including
    the RTLLM benchmark (Lu et al., [2024](#bib.bib16)), which provides a framework
    for evaluating LLM performance in generating RTL from natural language instructions,
    encompassing syntax, functionality, and code quality. The RTL-Repo benchmark (Allam
    and Shalan, [2024](#bib.bib3)) expands this evaluation by assessing LLM capabilities
    in generating Verilog code autocompletions within large-scale and complex RTL
    projects, reflecting real-world design scenarios. VerilogEval (Liu et al., [2023](#bib.bib15))
    is a framework for evaluating the effectiveness of LLMs in generating Verilog
    code, including tasks like module implementation, code debugging, and testbench
    construction, to assess their potential in hardware design automation. Similarly,
    VHDL-Eval (Vijayaraghavan et al., [2024](#bib.bib28)) is a specialized framework
    designed to evaluate LLM performance specifically in VHDL code generation. Wan
    et al. (Wan et al., [2024](#bib.bib29)) explored using LLMs to insert bugs into
    HLS code, and created a dataset including both correct and injected buggy codes.
    These benchmarks and datasets, along with other emerging efforts, are crucial
    in LLM-driven HLS research, facilitating the evaluation of LLM capabilities and
    guiding the development of more robust HLS solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Experimental Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section details our experimental methodology for evaluating the effectiveness
    of integrating LLMs into the HLS process. We aim to assess both the design process
    and the quality of the hardware generated using LLMs in comparison to solely using
    traditional HLS tools. We investigate four approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Baseline: Generating Verilog using a standard HLS tool (Vitis HLS) from C code.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Direct LLM translation: Employing LLMs to translate C code into Verilog.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Natural language to Verilog: Directly generating Verilog code from natural
    language specifications using LLMs.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Natural language to code: Using LLMs to interpret natural language specifications
    into HLS-C benchmarks, which are then translated into Verilog using Vitis HLS.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 4.1\. HLS Approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The general HLS design flow, as illustrated in Figure [2(a)](#S3.F2.sf1 "In
    Figure 2 ‣ 3.2\. Applications ‣ 3\. Survey of the State-of-the-Art in LLMs for
    HLS ‣ Are LLMs Any Good for High-Level Synthesis?"), transforms a high-level language
    input to a synthesizable hardware description (e.g., in Verilog or VHDL). This
    process starts with describing the desired hardware functionality in a high-level
    language like C/C++/SystemC), followed by synthesis for a specific hardware target,
    e.g., FPGAs like the Artix-7 or Zynq UltraScale+. We refer to this process as
    C$\rightarrow$Verilog.
  prefs: []
  type: TYPE_NORMAL
- en: HLS tools offer a range of directives to guide the synthesis process, allowing
    designers to control various aspects of the design, such as loop unrolling, pipelining,
    array partitioning, and performance optimization. While these directives provide
    flexibility, the resulting HDL code generated by HLS tools can often be complex
    and challenging to interpret for designers who are primarily accustomed to higher-level
    programming languages. This limited visibility into the generated HDL code is
    a key consideration that motivates the exploration of LLMs in HLS, aiming to improve
    the design process by providing higher-level abstractions or enhancing code understandability.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,QmFja2dyb3VuZDogSSBhbSBhIGhhcmR3YXJlIGVuZ2luZWVyLCBhbmQgSSB3YW50IHRvIHRyYW5zZmVyIGEgQyBwcm9ncmFtIHRvIHN5bnRoZXNpemFibGUgSGFyZHdhcmUgRGVzY3JpcHRpb24gTGFuZ3VhZ2UgKFJUTCkgaW4gVmVyaWxvZyB3aXRoIGEgZnVsbCBtb2R1bGUsIGluY2x1ZGluZyBJL08gYW5kIGZ1bmN0aW9uYWxpdGllcyBmcm9tIHRoZSBDIHByb2dyYW0uIFRoaXMgVmVyaWxvZyBtb2R1bGUgc2hvdWxkIHRhcmdldCBhIFhpbGlueCBGUEdBIGJvYXJkLg==)Background:  I  am  a  hardware  engineer,  and  I  want  to  transfer  a  C  program  to  synthesizable  Hardware  Description  Language  (RTL)  in  Verilog  with  a  full  module,  including  I/O  and  functionalities  from  the  C  program.  This  Verilog  module  should  target  a  Xilinx  FPGA  board.'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Prompt
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,U3VyZSwgSSBjYW4gaGVscCB3aXRoIHRoYXQuIFBsZWFzZSBwcm92aWRlIHRoZSBDIHByb2dyYW0geW91IHdhbnQgdG8gdHJhbnNsYXRlIHRvIFZlcmlsb2cuIEFkZGl0aW9uYWxseSwgbGV0IG1lIGtub3cgaWYgdGhlcmUgYXJlIGFueSBzcGVjaWZpYyBmdW5jdGlvbmFsaXRpZXMgb3IgY29uc3RyYWludHMgeW91IG5lZWQgdG8gY29uc2lkZXIgZm9yIHRoZSB0cmFuc2xhdGlvbiwgc3VjaCBhcyB0aGUgSS9PIHBpbiBjb3VudCBvciBzcGVjaWZpYyBmZWF0dXJlcyBvZiB0aGUgWGlsaW54IEZQR0EgYm9hcmQgeW91IGFyZSB0YXJnZXRpbmcu)Sure,  I  can  help  with  that.  Please  provide  the  C  program  you  want  to  translate  to  Verilog.  Additionally,  let  me  know  if  there  are  any  specific  functionalities  or  constraints  you  need  to  consider  for  the  translation,  such  as  the  I/O  pin  count  or  specific  features  of  the  Xilinx  FPGA  board  you  are  targeting.'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Feedback
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3. Background, role, and constraints
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,I2RlZmluZSBOIDY0Cgp2b2lkIHN5cmsoZmxvYXQgYWxwaGEsIGZsb2F0IGJldGEsCiAgICBmbG9hdCBBW05dW05dLCBmbG9hdCBCW05dW05dLCBmbG9hdCBDX291dFtOXVtOXSkgewogICAgaW50IGksIGosIGs7CgogICAgZmxvYXQgYnVmZl9BMFtOXVtOXTsKICAgIGZsb2F0IGJ1ZmZfQjFbTl1bTl07CiAgICBmbG9hdCBidWZmX0JbTl1bTl07CiAgICBmbG9hdCBidWZmX0Nfb3V0W05dW05dOw==)#define  N  64void  syrk(float  alpha,  float  beta,float  A[N][N],  float  B[N][N],  float  C_out[N][N])  {int  i,  j,  k;float  buff_A0[N][N];float  buff_B1[N][N];float  buff_B[N][N];float  buff_C_out[N][N];'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Prompt
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,YHRpbWVzY2FsZSAxbnMgLyAxcHMKbW9kdWxlIHN5cmsjKHBhcmFtZXRlciBOID0gNjQpICgKICAgIGlucHV0IFszMTowXSBhbHBoYSwKICAgIGlucHV0IFszMTowXSBiZXRhLAogICAgaW50ZWdlciBpLCBqLCBrOwogICAgaW5wdXQgWzMxOjBdIEFbMDpOLTFdWzA6Ti0xXSwKICAgIGlucHV0IFszMTowXSBCWzA6Ti0xXVswOk4tMV0sCiAgICBvdXRwdXQgcmVnIFszMTowXSBDX291dFswOk4tMV1bMDpOLTFdKTsKICAgIHJlZyBbMzE6MF0gYnVmZl9BMFswOk4tMV1bMDpOLTFdOwogICAgcmVnIFszMTowXSBidWZmX0ExWzA6Ti0xXVswOk4tMV07CiAgICByZWcgWzMxOjBdIGJ1ZmZfQlswOk4tMV1bMDpOLTFdOwogICAgcmVnIFszMTowXSBidWZmX0Nfb3V0WzA6Ti0xXVswOk4tMV07KTs=)‘timescale  1ns  /  1psmodule  syrk#(parameter  N  =  64)  (input  [31:0]  alpha,input  [31:0]  beta,integer  i,  j,  k;input  [31:0]  A[0:N-1][0:N-1],input  [31:0]  B[0:N-1][0:N-1],output  reg  [31:0]  C_out[0:N-1][0:N-1]);reg  [31:0]  buff_A0[0:N-1][0:N-1];reg  [31:0]  buff_A1[0:N-1][0:N-1];reg  [31:0]  buff_B[0:N-1][0:N-1];reg  [31:0]  buff_C_out[0:N-1][0:N-1];);'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Feedback
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,VGhlIGlucHV0cyBBLCBCLCBhbmQgQ19vdXQgYXJlIG5vdCBjb3JyZWN0LiBXZSBuZWVkIGFuIGV4dGVybmFsIFJBTSB0byBoYW5kbGUgdGhlIDJEIGFycmF5LiBUaGUgd2lkdGggb2YgdGhlIGFkZHJlc3MgYW5kIHRoZSB3aWR0aCBvZiB0aGUgZGF0YSBzaG91bGQgYmUgZGVjbGFyZWQgYXMgbW9kdWxlIHBhcmFtZXRlcnMu)The  inputs  A,  B,  and  C_out  are  not  correct.  We  need  an  external  RAM  to  handle  the  2D  array.  The  width  of  the  address  and  the  width  of  the  data  should  be  declared  as  module  parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: (c) Prompt2
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,bW9kdWxlIHN5cmsjKHBhcmFtZXRlciBOID0gNjQsREFUQV9XSURUSCA9IDMyKSgKICAgIGlucHV0IGNsaywKICAgIGlucHV0IHJzdCwKICAgIGlucHV0IFtEQVRBX1dJRFRILTE6MF0gYWxwaGEsCiAgICBpbnB1dCBbREFUQV9XSURUSC0xOjBdIGJldGEsCiAgICBpbnB1dCBbREFUQV9XSURUSC0xOjBdIEFfZGF0YSwKICAgIGlucHV0IFtEQVRBX1dJRFRILTE6MF0gQl9kYXRhLAogICAgb3V0cHV0IHJlZyBbREFUQV9XSURUSC0xOjBdIENfb3V0X2RhdGEsCiAgICBpbnB1dCBbJGNsb2cyKE4qTiktMTowXSBBX2FkZHIsIEJfYWRkciwKICAgICAgICAgICAgQ19vdXRfYWRkciwKICAgIGlucHV0IEFfd2UsIEJfd2UsIENfb3V0X3dlKTs=)module  syrk#(parameter  N  =  64,DATA_WIDTH  =  32)(input  clk,input  rst,input  [DATA_WIDTH-1:0]  alpha,input  [DATA_WIDTH-1:0]  beta,input  [DATA_WIDTH-1:0]  A_data,input  [DATA_WIDTH-1:0]  B_data,output  reg  [DATA_WIDTH-1:0]  C_out_data,input  [$clog2(N*N)-1:0]  A_addr,  B_addr,C_out_addr,input  A_we,  B_we,  C_out_we);'
  prefs: []
  type: TYPE_NORMAL
- en: (d) Feedback2
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4. Inputs and error checking (I/O)
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Li4uCmxwMTogZm9yIChpID0gMDsgaSA8IE47IGkrKykgewogICAgbHAyOiBmb3IgKGogPSAwOyBqIDwgTjsgaisrKSB7CiAgICAgICAgaWYgKGogPiBpKSBjb250aW51ZTsKICAgICAgICBscDM6IGZvciAoayA9IDA7IGsgPCBOOyBrKyspIHsKICAgICAgICAgICAgICBidWZmX0Nfb3V0W2ldW2pdICs9IGFscGhhICoKICAgICAgICAgICAgICBidWZmX0EwW2ldW2tdICogYnVmZl9BMVtqXVtrXTsKICAgICAgICB9CiAgICB9Cn0KLi4u)…lp1:  for  (i  =  0;  i  <  N;  i++)  {lp2:  for  (j  =  0;  j  <  N;  j++)  {if  (j  >  i)  continue;lp3:  for  (k  =  0;  k  <  N;  k++)  {buff_C_out[i][j]  +=  alpha  *buff_A0[i][k]  *  buff_A1[j][k];}}}…'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Prompt
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Li4uCmZvciAoaSA9IDA7IGkgPCBOOyBpID0gaSArIDEpIGJlZ2luCiAgICBmb3IgKGogPSAwOyBqIDwgTjsgaiA9IGogKyAxKSBiZWdpbgogICAgICAgIGlmIChqIDw9IGkpIGJlZ2luCiAgICAgICAgICAgIGZvciAoayA9IDA7IGsgPCBOOyBrID0gayArIDEpCiAgICAgICAgICAgIGJlZ2luCiAgICAgICAgICAgICAgICBidWZmX0Nfb3V0W2ldW2pdIDw9IGJ1ZmZfQ19vdXRbaV1bal0KICAgICAgICAgICAgICAgICsgYWxwaGEgKiBidWZmX0EwW2ldW2tdCiAgICAgICAgICAgICAgICAqIGJ1ZmZfQTFbal1ba107CiAgICAgICAgICAgIGVuZAogICAgICAgICAgICBidWZmX0Nfb3V0W2ldW2pdIDw9IGJ1ZmZfQ19vdXRbaV1bal0KICAgICAgICAgICAgKyBiZXRhICogYnVmZl9CW2ldW2pdOwogICAgICAgIGVuZCBlbHNlIGJlZ2luCiAgICAgICAgICAgIENfb3V0W2ldW2pdIDw9IDA7CiAgICAgICAgZW5kCiAgICBlbmQKZW5kCi4uLg==)…for  (i  =  0;  i  <  N;  i  =  i  +  1)  beginfor  (j  =  0;  j  <  N;  j  =  j  +  1)  beginif  (j  <=  i)  beginfor  (k  =  0;  k  <  N;  k  =  k  +  1)beginbuff_C_out[i][j]  <=  buff_C_out[i][j]+  alpha  *  buff_A0[i][k]*  buff_A1[j][k];endbuff_C_out[i][j]  <=  buff_C_out[i][j]+  beta  *  buff_B[i][j];end  else  beginC_out[i][j]  <=  0;endendend…'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Feedback
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,VGhpcyBsb29rcyB3cm9uZywgQSwgQiwgQ19vdXQsIGFyZSBleHRlcm5hbCBCUkFNLCBwbGVhc2UgdXBkYXRlIHRoaXMgYWdhaW4u)This  looks  wrong,  A,  B,  C_out,  are  external  BRAM,  please  update  this  again.'
  prefs: []
  type: TYPE_NORMAL
- en: (c) Prompt2
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Li4uCkNPTVBVVEU6IGJlZ2luCiAgICBBX3JlYWQgPD0gMDsKICAgIEJfcmVhZCA8PSAwOwogICAgcmVnX0EgPD0gQV9kYXRhX2luOwogICAgcmVnX0IgPD0gQl9kYXRhX2luOwogICAgcmVnX0MgPD0gcmVnX0MgKyBhbHBoYSAqIHJlZ19BICogcmVnX0I7CiAgICBrIDw9IGsgKyAxOwogICAgaWYgKGsgPT0gTikgYmVnaW4KICAgICAgICBrIDw9IDA7CiAgICAgICAgc3RhdGUgPD0gV1JJVEVfQzsKICAgIGVuZAogICAgZWxzZSBiZWdpbgogICAgICAgIHN0YXRlIDw9IExPQURfQTsKICAgIGVuZAplbmQKLi4u)…COMPUTE:  beginA_read  <=  0;B_read  <=  0;reg_A  <=  A_data_in;reg_B  <=  B_data_in;reg_C  <=  reg_C  +  alpha  *  reg_A  *  reg_B;k  <=  k  +  1;if  (k  ==  N)  begink  <=  0;state  <=  WRITE_C;endelse  beginstate  <=  LOAD_A;endend…'
  prefs: []
  type: TYPE_NORMAL
- en: (d) Feedback2
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5. Inputs and error checking (loop)
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIHdyaXRlIGEgdGNsIGNvZGUgdG8gY3JlYXRlIGEgYnJhbSBJUCB3aXRoIHByb3BlcnRpZXMgbGlrZSB0aGlzIDoKLXZlbmRvciB4aWxpbnguY29tCi12ZXJzaW9uIDguNAotbW9kdWxlX25hbWUgYmxrX21lbV9nZW5fMAotV3JpdGVfRGVwdGhfQSB7NDA5Nn0KLVdyaXRlX1dpZHRoX0EgezMyfQ==)Please  write  a  tcl  code  to  create  a  bram  IP  with  properties  like  this  :-vendor  xilinx.com-version  8.4-module_name  blk_mem_gen_0-Write_Depth_A  {4096}-Write_Width_A  {32}'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Prompt
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,IyBDcmVhdGUgQlJBTSBJUCB3aXRoIHNwZWNpZmljIHByb3BlcnRpZXMKY3JlYXRlX2lwIC1uYW1lIGJsa19tZW1fZ2VuIC12ZW5kb3IgeGlsaW54LmNvbSAtbGlicmFyeSBpcCAtdmVyc2lvbiA4LjQgLW1vZHVsZV9uYW1lIGJsa19tZW1fZ2VuXzAKIyBTZXQgcHJvcGVydGllcyBmb3IgQlJBTSBJUApzZXRfcHJvcGVydHkgLWRpY3QgW2xpc3QgXAogICAgQ09ORklHLkVuYWJsZV9BIHtBbHdheXNfRW5hYmxlZH0gXAogICAgQ09ORklHLlJlZ2lzdGVyX1BvcnRBX091dHB1dF9vZl9NZW1vcnlfUHJpbWl0aXZlcwogICAge2ZhbHNlfSBcCiAgICBDT05GSUcuV3JpdGVfRGVwdGhfQSB7NDA5Nn0gXAogICAgQ09ORklHLldyaXRlX1dpZHRoX0EgezMyfSBcCl0gW2dldF9pcHMgYmxrX21lbV9nZW5fMF0K)#  Create  BRAM  IP  with  specific  propertiescreate_ip  -name  blk_mem_gen  -vendor  xilinx.com  -library  ip  -version  8.4  -module_name  blk_mem_gen_0#  Set  properties  for  BRAM  IPset_property  -dict  [list  \CONFIG.Enable_A  {Always_Enabled}  \CONFIG.Register_PortA_Output_of_Memory_Primitives{false}  \CONFIG.Write_Depth_A  {4096}  \CONFIG.Write_Width_A  {32}  \]  [get_ips  blk_mem_gen_0]'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Feedback
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6. Inputs and error checking (IP)
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIHdyaXRlIGEgdGVzdGJlbmNoIGZvciB0aGlzIFZlcmlsb2cgY29kZSwgd2l0aCBpbnN0YW50aWF0ZWQgQlJBTS4gVXNlIHRoZSAzMi1iaXQgSUVFRS03NTQgZm9ybWF0IGFuZCBzZXQgYWxsIGluaXRpYWwgdmFsdWVzIG9mIHRoZSBpbnB1dHMgdG8gYmUgYmV0d2VlbiAwIGFuZCAxLCB3aGVyZSBOID0gNjQgYW5kIHRoZSBwZXJpb2QgaXMgMTBucy4gVGhlIGZsb2F0X3RvX2llZWU3NTQgZnVuY3Rpb24gaXMgcHJvdmlkZWQuIFN0b3Agd2hlbiBkb25lLCBhbmQgdXNlIGZpeGVkIGlucHV0IHZhbHVlcyBkbyBub3QgdXNlIHJhbmRvbSB2YWx1ZXMuIEZvciBpbnB1dCBBLCBzZXQgQVtpXVtqXSA9ICgoaSArIGopICUgMTAwKSAvIDEwMC4wOyBhbmQgeFtpXSA9IChpICUgMTAwKSAvIDEwMC4wLiBUaGUgaW5pdGlhbCBpbnRlZ2VyIHNob3VsZCBiZSBkZWNsYXJlZCBvdXRzaWRlIHRoZSBpbml0aWFsIGJsb2NrLg==)Please  write  a  testbench  for  this  Verilog  code,  with  instantiated  BRAM.  Use  the  32-bit  IEEE-754  format  and  set  all  initial  values  of  the  inputs  to  be  between  0  and  1,  where  N  =  64  and  the  period  is  10ns.  The  float_to_ieee754  function  is  provided.  Stop  when  done,  and  use  fixed  input  values  do  not  use  random  values.  For  input  A,  set  A[i][j]  =  ((i  +  j)  %  100)  /  100.0;  and  x[i]  =  (i  %  100)  /  100.0.  The  initial  integer  should  be  declared  outside  the  initial  block.'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Prompt
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Li4uCi8vIEluc3RhbnRpYXRlIHRoZSBzeXJrIG1vZHVsZQpzeXJrICMoLk4oTiksIC5EQVRBX1dJRFRIKERBVEFfV0lEVEgpKSBzeXJrX2luc3QgKAogICAgLmNsayhjbGspLAogICAgLnJzdChyc3QpLAogICAgLnN0YXJ0X2NvbXB1dGF0aW9uKHN0YXJ0X2NvbXB1dGF0aW9uKSwKICAgIC5hbHBoYShhbHBoYSksCiAgICAuYmV0YShiZXRhKSwKICAgIC5BX2RhdGFfaW4oQV9kYXRhX2luKSwKICAgIC5CX2RhdGFfaW4oQl9kYXRhX2luKSwKICAgIC5DX2RhdGFfb3V0KENfZGF0YV9vdXQpLAogICAgLkFfYWRkcl9vdXQoQV9hZGRyX291dCksCiAgICAuQl9hZGRyX291dChCX2FkZHJfb3V0KSwKICAgIC5DX2FkZHJfb3V0KENfYWRkcl9vdXQpLAogICAgLkFfcmVhZChBX3JlYWQpLAogICAgLkJfcmVhZChCX3JlYWQpLAogICAgLkNfd3JpdGUoQ193cml0ZSksCiAgICAuZG9uZShkb25lKQopOwouLi4=)…//  Instantiate  the  syrk  modulesyrk  #(.N(N),  .DATA_WIDTH(DATA_WIDTH))  syrk_inst  (.clk(clk),.rst(rst),.start_computation(start_computation),.alpha(alpha),.beta(beta),.A_data_in(A_data_in),.B_data_in(B_data_in),.C_data_out(C_data_out),.A_addr_out(A_addr_out),.B_addr_out(B_addr_out),.C_addr_out(C_addr_out),.A_read(A_read),.B_read(B_read),.C_write(C_write),.done(done));…'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Feedback
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7. Inputs and error checking (Testbench)
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. LLM-Assisted HLS Approaches
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, we describe the three LLM-assisted approaches explored herein, showcasing
    the diverse ways in which LLMs can contribute to hardware design. The direct LLM
    translation approach, denoted as C$\rightarrow$HLS-C, on the other hand, highlights
    the potential for LLMs to augment existing HLS tools by raising the level of abstraction
    to natural language input. Figure [2(b)](#S3.F2.sf2 "In Figure 2 ‣ 3.2\. Applications
    ‣ 3\. Survey of the State-of-the-Art in LLMs for HLS ‣ Are LLMs Any Good for High-Level
    Synthesis?") illustrates the design flow for each of these LLM-assisted HLS methodologies.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1\. C$\rightarrow$Verilog
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The use of LLMs to directly generate synthesizable hardware accelerators in
    Verilog requires a well-defined procedure. This procedure involves the steps to
    generate Verilog code from high-level specifications and subsequent steps to produce
    a fully functional accelerator, from simulation to place-and-route. For example,
    a testbench is necessary to validate the accelerator’s functionality during simulation.
    A place-and-route-ready hardware accelerator consists of Verilog code, TCL commands
    to automate the assembly of the accelerator’s design (instantiating IP cores,
    connecting them, and setting up the overall project structure), and XDC files
    to specify the constraints of the accelerator such as clock period and I/O delay.
  prefs: []
  type: TYPE_NORMAL
- en: Figures [3](#S4.F3 "Figure 3 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology
    ‣ Are LLMs Any Good for High-Level Synthesis?"), [4](#S4.F4 "Figure 4 ‣ 4.1\.
    HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for High-Level
    Synthesis?"), [5](#S4.F5 "Figure 5 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology
    ‣ Are LLMs Any Good for High-Level Synthesis?"), [6](#S4.F6 "Figure 6 ‣ 4.1\.
    HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for High-Level
    Synthesis?"), and [7](#S4.F7 "Figure 7 ‣ 4.1\. HLS Approach ‣ 4\. Experimental
    Methodology ‣ Are LLMs Any Good for High-Level Synthesis?") illustrate our C$\rightarrow$Verilog
    process for different components of the hardware design flow. The first step defines
    the context of the generation process, including, but not limited to, the designer’s
    role, the hardware background, and the constraints that the LLM (ChatGPT-4o, in
    our case) should follow to better identify the corresponding context and purpose
    of this process. Figure [3](#S4.F3 "Figure 3 ‣ 4.1\. HLS Approach ‣ 4\. Experimental
    Methodology ‣ Are LLMs Any Good for High-Level Synthesis?") shows the context
    we used in our experiments. We identify ourselves as hardware engineers and aim
    to translate a C program to HDL in Verilog. We specify that this Verilog module
    should target the Xilinx FPGA part xc7a200tfbg-484-1\. Although ChatGPT-4o records
    the part in its memory, the design is not guaranteed to meet the I/O or resource
    constraints unless we explicitly instruct the LLM to meet the I/O constraints.
    If the specification of the part does not exist or is incorrect in the LLM, we
    must manually provide this information to the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: 'After providing the role, background, and constraints of the designer and hardware
    to the LLM, we provide the source code to the LLM. It is important to be mindful
    of ChatGPT-4o’s limitations: a 128k token limit for combined input and output,
    with a maximum of 4k tokens for the output alone. If a larger program is needed,
    it should be divided accordingly. In our experiments, all C benchmarks were within
    the 128k token limit, allowing us to input the entire program at once. However,
    due to the 4k output constraint, generating the complete Verilog accelerator required
    multiple iterations. Once generated, the Verilog output undergoes syntax and design
    error checking.'
  prefs: []
  type: TYPE_NORMAL
- en: For designers proficient in hardware design, syntax and design error checking
    can be performed directly within the LLM. Otherwise, a validation tool like Vivado
    is necessary. Once an error is identified, we describe the error in natural language
    to the LLM and regenerate the Verilog code. This process is repeated until successful
    simulation and implementation in Vivado. We encountered some common errors in
    the process, such as incorrect data type mapping in I/O (Figure [4](#S4.F4 "Figure
    4 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for
    High-Level Synthesis?")), misrepresentation of sequential and parallel execution
    (Figure [5](#S4.F5 "Figure 5 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology
    ‣ Are LLMs Any Good for High-Level Synthesis?")), and state machine implementation
    errors (figures omitted for brevity). The designer’s expertise level significantly
    impacts the speed and efficiency of this iterative error resolution process.
  prefs: []
  type: TYPE_NORMAL
- en: The final step in the LLM-assisted design flow is generating TCL scripts for
    IP integration, XDC constraints, and testbench content (Figures [6](#S4.F6 "Figure
    6 ‣ 4.1\. HLS Approach ‣ 4\. Experimental Methodology ‣ Are LLMs Any Good for
    High-Level Synthesis?") and [7](#S4.F7 "Figure 7 ‣ 4.1\. HLS Approach ‣ 4\. Experimental
    Methodology ‣ Are LLMs Any Good for High-Level Synthesis?")). This step faces
    similar challenges as previous steps if the LLM lacks knowledge of the latest
    syntax or specifications, leading to more errors in generated files. For example,
    defining a proper clock period and calculating IEEE 754 standard floating-point
    values require the latest specifications. To address this problem, we manually
    provided the necessary information to the LLM, which learns and adapts over time,
    potentially reducing errors in future iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2\. NL$\rightarrow$Verilog
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The second approach is similar to C$\rightarrow$Verilog but uses natural language
    descriptions (or pseudocode) of the program’s functionality as input to the LLM,
    instead of a programming language like C/C++. We described details such as input/output,
    variable types, loops, and operations. The number of prompts required in this
    approach depends on the complexity of the program and the designer’s preferences,
    with LLMs like ChatGPT-4o potentially accommodating the entire program in a single
    prompt, as in our experiments.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3\. NL$\rightarrow$HLS-C
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The third approach differs from the previous two by leveraging the strengths
    of both LLMs and traditional HLS tools. Instead of generating Verilog directly,
    it utilizes an LLM to translate natural language descriptions into HLS-compatible
    input (HLS-C), which is then processed by the HLS tool to produce the synthesizable
    Verilog output. This approach combines the expressiveness of natural language
    with the power and completeness of existing HLS tools, ultimately lowering the
    barrier to entry for hardware design by minimizing the need for proficiency in
    high-level programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Experimental Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To evaluate the three LLM-based approaches and compare them with the baseline
    HLS approach, we used nine benchmarks (syrk, syr2k, mvt, k3mm, k2mm, gesummv,
    gemm, bicg, and atax) from the Polybench suite (Pouchet and Yuki, [2012](#bib.bib21)),
    specifically designed for evaluating the performance of HLS tools and compiler
    technologies. These benchmarks encompass computational kernels common in scientific
    and engineering applications, such as matrix multiplication, 2D convolution, and
    Cholesky decomposition. We employed ChatGPT-4o as our LLM model, Vitis HLS 2023.2
    as our HLS tool, and Vivado 2023.2 for implementation targeting a Xilinx xc7a200tfbg484-1
    FPGA. For each benchmark, we generated designs using all four approaches and collected
    data on resource utilization, power consumption, execution cycles, and critical
    path delay from Vitis HLS and Vivado. Note that the NL$\rightarrow$Verilog approach.
    As such, these approaches share the same steps after the initial input stage,
    and thus have the same evaluation data. We tracked the number of prompts used
    to generate HLS-C, Verilog, TCL, XDC, and testbench content for the LLM-based
    approaches. For a fair comparison, we disabled automatic optimizations like pipelining
    in Vitis HLS. For LLM-based approaches, we used LLMs to generate all necessary
    content (Verilog code, TCL scripts, IPs, testbenches, XDC files) to form a complete
    project.
  prefs: []
  type: TYPE_NORMAL
- en: Table 1. The number of Prompts for LLM-based approaches
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | HLS-C | Verilog | TCL | Testbench | XDC |'
  prefs: []
  type: TYPE_TB
- en: '| syrk | 4 | 50 | 9 | 12 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| syr2k | 1 | 20 | 3 | 7 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| mvt | 1 | 36 | 3 | 7 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| k3mm | 1 | 21 | 3 | 5 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| k2mm | 1 | 29 | 3 | 6 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| gesummv | 1 | 23 | 3 | 7 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| gemm | 1 | 22 | 3 | 6 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| bicg | 1 | 16 | 3 | 6 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| atax | 1 | 11 | 3 | 8 | 3 |'
  prefs: []
  type: TYPE_TB
- en: Table 2. Place & routing results for C$\rightarrow$Verilog approaches
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | Approach | Execution cycles | FF | LUT | Slice | DSP | BRAM |
    Power (W) | CP |'
  prefs: []
  type: TYPE_TB
- en: '| syrk | LLM | 1859983 | 954 | 5300 | 1649 | 6 | 8 | 0.164 | 9.934 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 3744260 | 662 | 521 | 221 | 5 | 32 | 0.350 | 8.191 |'
  prefs: []
  type: TYPE_TB
- en: '| syr2k | LLM | 2125846 | 542 | 472 | 197 | 2 | 12 | 0.181 | 9.446 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 9028229 | 1042 | 960 | 1649 | 5 | 56 | 0.383 | 6.872 |'
  prefs: []
  type: TYPE_TB
- en: '| mvt | LLM | 44996 | 8628 | 2663 | 4404 | 2 | 4 | 0.197 | 9.312 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 119492 | 713 | 991 | 342 | 5 | 12 | 0.332 | 6.55 |'
  prefs: []
  type: TYPE_TB
- en: '| k3mm | LLM | 2371593 | 623 | 328 | 236 | 2 | 28 | 0.207 | 9.924 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 10277509 | 927 | 956 | 1649 | 5 | 56 | 0.398 | 6.646 |'
  prefs: []
  type: TYPE_TB
- en: '| k2mm | LLM | 1863816 | 537 | 311 | 202 | 2 | 20 | 0.189 | 9.967 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 7963269 | 929 | 659 | 313 | 5 | 56 | 0.400 | 6.814 |'
  prefs: []
  type: TYPE_TB
- en: '| gesummv | LLM | 65991 | 437 | 288 | 170 | 2 | 16 | 0.176 | 9.253 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 148805 | 795 | 561 | 228 | 5 | 20 | 0.316 | 6.855 |'
  prefs: []
  type: TYPE_TB
- en: '| gemm | LLM | 1601739 | 488 | 332 | 200 | 2 | 16 | 0.178 | 9.697 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 4542980 | 807 | 505 | 238 | 5 | 32 | 0.359 | 6.551 |'
  prefs: []
  type: TYPE_TB
- en: '| bicg | LLM | 46478 | 505 | 194 | 198 | 2 | 20 | 0.196 | 9.251 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 119492 | 711 | 429 | 223 | 5 | 12 | 0.333 | 6.599 |'
  prefs: []
  type: TYPE_TB
- en: '| atax | LLM | 57669 | 453 | 257 | 164 | 2 | 16 | 0.167 | 9.952 |'
  prefs: []
  type: TYPE_TB
- en: '| HLS | 119492 | 741 | 428 | 209 | 5 | 11 | 0.309 | 6.573 |'
  prefs: []
  type: TYPE_TB
- en: 6\. Results and Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Table [1](#S5.T1 "Table 1 ‣ 5\. Experimental Setup ‣ Are LLMs Any Good for High-Level
    Synthesis?") presents the number of prompts required for each file type (HLS-C,
    Verilog, TCL, testbench, and XDC) to construct a complete hardware accelerator
    from C benchmarks. As demonstrated in Sec. [5](#S5 "5\. Experimental Setup ‣ Are
    LLMs Any Good for High-Level Synthesis?"), the C$\rightarrow$Verilog approaches
    share the same place-and-route outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Notably, generating the Verilog code generally required the most prompts compared
    to other file types. But the number of prompts required varied significantly depending
    on the benchmark, as well as our growing familiarity with the LLM’s behavior with
    Verilog generation. The syrk benchmark, for example, required considerably more
    interaction with the LLM compared to atax (the last benchmark we worked on). The
    syrk kernel exhibits a higher level of complexity, containing four nested loops
    with multiple multiplications in a single operation and three 2D arrays for inputs
    and outputs. Conversely, atax only comprises two nested loops and one 2D array
    for input. This suggests that the inherent complexity of the benchmark code, as
    well as our initial learning curve to effectively prompt the LLM to minimize errors,
    heavily influenced the number of prompts needed for accurate Verilog generation.
    As we gained experience and refined our prompting strategies, we were able to
    consolidate prompts, leading to faster generation for subsequent benchmarks. In
    contrast, the number of prompts for TCL generation remained relatively consistent
    across all benchmarks, implying that this task is less sensitive to the specific
    characteristics of the input code. The complexity of the benchmark and the designer’s
    growing familiarity with LLM interaction are key factors in determining the number
    of prompts needed for successful Verilog generation, although prior design experience
    can also play a role.
  prefs: []
  type: TYPE_NORMAL
- en: Table [2](#S5.T2 "Table 2 ‣ 5\. Experimental Setup ‣ Are LLMs Any Good for High-Level
    Synthesis?") presents the simulation and implementation results for both LLM-based
    and HLS-based approaches. For each benchmark, LLM refers to the C$\rightarrow$Verilog
    approaches. To determine the quality of a resulting hardware accelerators, the
    evaluation metrics include execution cycles, resource utilization (FFs, LUTs,
    Slices, DSPs, and BRAMs), total power consumption, and critical path delay.
  prefs: []
  type: TYPE_NORMAL
- en: A key observation is the significant variation in results across different benchmarks.
    For the syrk and mvt benchmarks, the LLM-based approaches consume more resources
    (except DSPs and BRAMs) compared to HLS. This is attributed to the use of LUT
    RAM for the inner matrix in the LLM-generated designs.
  prefs: []
  type: TYPE_NORMAL
- en: However, for the remaining seven benchmarks, LLM-based approaches consistently
    outperformed the HLS-based approaches across all metrics. This includes a notable
    reduction in resource utilization (with an average decrease of 38.67%), a significant
    improvement in execution cycles (average reduction of 64%), and a substantial
    reduction in total power consumption (average reduction of 38.67%). For the critical
    path, the HLS-based approach outperformed LLM-based approaches by an average of
    28.82%.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the results in Table [2](#S5.T2 "Table 2 ‣ 5\. Experimental Setup ‣
    Are LLMs Any Good for High-Level Synthesis?") demonstrate the potential of LLMs
    in optimizing various aspects of hardware design. While the LLM-based approaches
    did not outperform in every metric for all benchmarks, their consistent success
    in the majority of cases, particularly in resource utilization, power consumption,
    and often execution cycles, highlights the promise of this technology for HLS.
    Further research is needed to refine and expand these capabilities, and explore
    them in a wider variety of usage scenarios, but the current results are encouraging
    and suggest that LLMs could play a significant role in the future of hardware
    design automation.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. The Energy Elephant in the LLM-HLS Room
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While the initial excitement surrounding the integration of LLMs into the HLS
    workflow has spurred significant research, a critical aspect has been conspicuously
    absent from most discussions: the energy implications. The majority of studies
    have focused on the potential of LLMs to streamline the design process, enhance
    automation, and improve the quality of generated hardware. However, they have
    largely overlooked the energy consumption associated with both the training and
    inference of these models.'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs, particularly large-scale models like GPT-3 and GPT-4, are notorious for
    their computational demands. Training LLMs can consume hundreds of megawatt-hours
    to several gigawatt-hours of electricity (Schwartz et al., [2020](#bib.bib23)).
    Even inference, the process of generating responses to prompts, can be computationally
    intensive, requiring substantial energy resources. The Electrical Power Research
    Institute (EPRI) estimates that a single ChatGPT query can consume approximately
    2.9 W-hours of energy—nearly 10 times the power of a single Google search (Electric
    Power Research Institute, [2024](#bib.bib10))—a considerable amount when numerous
    queries are needed for HLS tasks. This raises concerns about the overall energy
    efficiency of incorporating LLMs into the HLS flow. Given that a primary goal
    of HLS is to design hardware accelerators that are more energy efficient than
    general-purpose computers, the energy overhead of utilizing LLMs could outweigh
    the intended benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the process of fine-tuning LLMs for specific HLS tasks can exacerbate
    the issue of energy consumption. Fine-tuning involves retraining the model on
    domain-specific data, which is computationally expensive. If the energy cost of
    fine-tuning and utilizing an LLM is greater than the energy saved across all resulting
    hardware designs, then employing LLMs in this way would be counterproductive for
    energy efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: The lack of attention to power/energy implications in current research raises
    concerns about the sustainability and practicality of LLM-driven HLS. As the field
    progresses, it is imperative to thoroughly investigate and quantify the energy
    costs associated with LLM utilization. This will enable a more comprehensive evaluation
    of the trade-offs between design efficiency and power consumption, ultimately
    leading to more informed decisions regarding the appropriate use of LLMs in HLS.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper has explored the application of Large Language Models (LLMs) in High-Level
    Synthesis (HLS), evaluating their potential to transform hardware design workflows.
    Through a survey and experimental evaluations, we assessed the ability of LLMs
    to generate Verilog code from high-level specifications, including both C benchmarks
    and natural language descriptions. Our findings reveal that LLM-based approaches
    can significantly enhance the efficiency of the HLS process, demonstrating notable
    improvements in resource utilization, execution cycles, and power consumption
    for most benchmarks compared to traditional HLS tools. However, challenges remain
    in ensuring the quality and optimization of LLM-generated code, particularly regarding
    critical path delays and the complexity of initial prompt interactions. Additionally,
    the substantial energy consumption associated with training and utilizing LLMs
    raises concerns about the overall energy efficiency of their integration into
    HLS workflows. Despite these challenges, the promising results suggest that with
    further refinement and research, LLMs could play a pivotal role in the future
    of hardware design automation, offering a powerful tool to streamline and optimize
    the HLS process.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This work was partially supported by the Technology and Research Initiative
    Fund (TRIF) provided to the University of Arizona by the Arizona Board of Regents
    (ABOR) and by NSF Grant 1844952.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ahmad et al. (2024) Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Karri,
    and Hammond Pearce. 2024. On hardware security bug code fixes by prompting large
    language models. *IEEE Transactions on Information Forensics and Security* (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Allam and Shalan (2024) Ahmed Allam and Mohamed Shalan. 2024. RTL-Repo: A Benchmark
    for Evaluating LLMs on Large-Scale RTL Design Projects. *arXiv preprint arXiv:2405.17378*
    (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bhandari et al. (2024) Jitendra Bhandari, Johann Knechtel, Ramesh Narayanaswamy,
    Siddharth Garg, and Ramesh Karri. 2024. LLM-Aided Testbench Generation and Bug
    Detection for Finite-State Machines. *arXiv preprint arXiv:2406.17132* (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Blocklove et al. (2023) Jason Blocklove, Siddharth Garg, Ramesh Karri, and
    Hammond Pearce. 2023. Chip-chat: Challenges and opportunities in conversational
    hardware design. In *2023 ACM/IEEE 5th Workshop on Machine Learning for CAD (MLCAD)*.
    IEEE, 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chang et al. (2024) Kaiyan Chang, Zhirong Chen, Yunhao Zhou, Wenlong Zhu, Haobo
    Xu, Cangyuan Li, Mengdi Wang, Shengwen Liang, Huawei Li, Yinhe Han, et al. 2024.
    Natural language is not enough: Benchmarking multi-modal generative AI for Verilog
    generation. *arXiv preprint arXiv:2407.08473* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chang et al. (2023) Kaiyan Chang, Ying Wang, Haimeng Ren, Mengdi Wang, Shengwen
    Liang, Yinhe Han, Huawei Li, and Xiaowei Li. 2023. ChipGPT: How far are we from
    natural language hardware design. *arXiv preprint arXiv:2305.14019* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Collini et al. (2024) Luca Collini, Siddharth Garg, and Ramesh Karri. 2024.
    C2HLSC: Can LLMs Bridge the Software-to-Hardware Design Gap? *arXiv preprint arXiv:2406.09233*
    (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coussy et al. (2009) Philippe Coussy, Daniel D Gajski, Michael Meredith, and
    Andres Takach. 2009. An introduction to high-level synthesis. *IEEE Design & Test
    of Computers* 26, 4 (2009), 8–17.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Electric Power Research Institute (2024) Electric Power Research Institute.
    2024. *Powering Intelligence: Analyzing Artificial Intelligence and Data Center
    Energy Consumption*. Technical Report. Electric Power Research Institute (EPRI).
    [https://www.epri.com/research/products/3002028905](https://www.epri.com/research/products/3002028905)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu et al. (2024) Weimin Fu, Shijie Li, Yifang Zhao, Haocheng Ma, Raj Dutta,
    Xuan Zhang, Kaichen Yang, Yier Jin, and Xiaolong Guo. 2024. Hardware Phi-1.5B:
    A Large Language Model Encodes Hardware Domain Specific Knowledge. In *Proceedings
    of the 29th Asia and South Pacific Design Automation Conference* (Incheon, Republic
    of Korea) *(ASPDAC ’24)*. IEEE Press, 349–354. [https://doi.org/10.1109/ASP-DAC58780.2024.10473927](https://doi.org/10.1109/ASP-DAC58780.2024.10473927)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu et al. (2023) Yonggan Fu, Yongan Zhang, Zhongzhi Yu, Sixu Li, Zhifan Ye,
    Chaojian Li, Cheng Wan, and Yingyan Celine Lin. 2023. Gpt4aigchip: Towards next-generation
    ai accelerator design automation via large language models. In *2023 IEEE/ACM
    International Conference on Computer Aided Design (ICCAD)*. IEEE, 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kande et al. (2023) Rahul Kande, Hammond Pearce, Benjamin Tan, Brendan Dolan-Gavitt,
    Shailja Thakur, Ramesh Karri, and Jeyavijayan Rajendran. 2023. Llm-assisted generation
    of hardware assertions. *arXiv preprint arXiv:2306.14027* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liao et al. (2023) Yuchao Liao, Tosiron Adegbija, and Roman Lysecky. 2023. Efficient
    system-level design space exploration for high-level synthesis using pareto-optimal
    subspace pruning. In *Proceedings of the 28th Asia and South Pacific Design Automation
    Conference*. 567–572.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023) Mingjie Liu, Nathaniel Pinckney, Brucek Khailany, and Haoxing
    Ren. 2023. Verilogeval: Evaluating large language models for verilog code generation.
    In *2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)*.
    IEEE, 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2024) Yao Lu, Shang Liu, Qijun Zhang, and Zhiyao Xie. 2024. Rtllm:
    An open-source benchmark for design rtl generation with large language model.
    In *2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC)*.
    IEEE, 722–727.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meech (2023) James T Meech. 2023. Leveraging High-Level Synthesis and Large
    Language Models to Generate, Simulate, and Deploy a Uniform Random Number Generator
    Hardware Design. *arXiv preprint arXiv:2311.03489* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nadimi and Zheng (2024) Bardia Nadimi and Hao Zheng. 2024. A Multi-Expert Large
    Language Model Architecture for Verilog Code Generation. *arXiv preprint arXiv:2404.08029*
    (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nair et al. (2023) Madhav Nair, Rajat Sadhukhan, and Debdeep Mukhopadhyay. 2023.
    Generating secure hardware using chatgpt resistant to cwes. *Cryptology ePrint
    Archive* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orenes-Vera et al. (2023) Marcelo Orenes-Vera, Margaret Martonosi, and David
    Wentzlaff. 2023. Using LLMs to Facilitate Formal Verification of RTL. arXiv:2309.09437 [cs.AR]
    [https://arxiv.org/abs/2309.09437](https://arxiv.org/abs/2309.09437)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pouchet and Yuki (2012) Louis-Noël Pouchet and Tomofumi Yuki. 2012. Polyhedral
    Benchmark suite. [https://web.cs.ucla.edu/~pouchet/software/polybench/](https://web.cs.ucla.edu/~pouchet/software/polybench/)
    Accessed: 8/12/2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2024) Ruidi Qiu, Grace Li Zhang, Rolf Drechsler, Ulf Schlichtmann,
    and Bing Li. 2024. AutoBench: Automatic Testbench Generation and Evaluation Using
    LLMs for HDL Design. *arXiv preprint arXiv:2407.03891* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schwartz et al. (2020) Roy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni.
    2020. Green ai. *Commun. ACM* 63, 12 (2020), 54–63.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swaroopa et al. (2024) Sneha Swaroopa, Rijoy Mukherjee, Anushka Debnath, and
    Rajat Subhra Chakraborty. 2024. Evaluating Large Language Models for Automatic
    Register Transfer Logic Generation via High-Level Synthesis. arXiv:2408.02793 [cs.AR]
    [https://arxiv.org/abs/2408.02793](https://arxiv.org/abs/2408.02793)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tao et al. (2024) Zhuofu Tao, Yichen Shi, Yiru Huo, Rui Ye, Zonghang Li, Li
    Huang, Chen Wu, Na Bai, Zhiping Yu, Ting-Jung Lin, et al. 2024. AMSNet: Netlist
    Dataset for AMS Circuits. *arXiv preprint arXiv:2405.09045* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thakur et al. (2023) Shailja Thakur, Baleegh Ahmad, Zhenxing Fan, Hammond Pearce,
    Benjamin Tan, Ramesh Karri, Brendan Dolan-Gavitt, and Siddharth Garg. 2023. Benchmarking
    large language models for automated verilog rtl code generation. In *2023 Design,
    Automation & Test in Europe Conference & Exhibition (DATE)*. IEEE, 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thakur et al. (2024) Shailja Thakur, Baleegh Ahmad, Hammond Pearce, Benjamin
    Tan, Brendan Dolan-Gavitt, Ramesh Karri, and Siddharth Garg. 2024. Verigen: A
    large language model for verilog code generation. *ACM Transactions on Design
    Automation of Electronic Systems* 29, 3 (2024), 1–31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vijayaraghavan et al. (2024) Prashanth Vijayaraghavan, Luyao Shi, Stefano Ambrogio,
    Charles Mackin, Apoorva Nitsure, David Beymer, and Ehsan Degan. 2024. VHDL-Eval:
    A Framework for Evaluating Large Language Models in VHDL Code Generation. *arXiv
    preprint arXiv:2406.04379* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wan et al. (2024) Lily Jiaxin Wan, Yingbing Huang, Yuhong Li, Hanchen Ye, Jinghua
    Wang, Xiaofan Zhang, and Deming Chen. 2024. Software/hardware co-design for llm
    and its application for design verification. In *2024 29th Asia and South Pacific
    Design Automation Conference (ASP-DAC)*. IEEE, 435–441.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2024) Kangwei Xu, Grace Li Zhang, Xunzhao Yin, Cheng Zhuo, Ulf Schlichtmann,
    and Bing Li. 2024. Automated C/C++ Program Repair for High-Level Synthesis via
    Large Language Models. *arXiv preprint arXiv:2407.03889* (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2023) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.
    2023. A survey of large language models. *arXiv preprint arXiv:2303.18223* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
