# P15：15.Week 8 – Practicum_ Variational autoencoders - 大佬的迷弟的粉丝 - BV1o5411p7AB

好吧，哦97是的，差不多还有100个，再来三个，我应该邀请我妈妈，好吧，哦97是的，差不多还有100个，再来三个，我应该邀请我妈妈，她在今天上午的谈话中砍死了，这很有趣，她设法做到了。

她在今天上午的谈话中砍死了，这很有趣，她设法做到了，hack假设只有上帝知道是的，不要将这两种设备结合在一起，hack假设只有上帝知道是的，不要将这两种设备结合在一起。

只是增加数量是100 100 100 k这就像狗还好，所以。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_1.png)

只是增加数量是100 100 100 k这就像狗还好，所以，让我们回到编码器入门指南，让我们回到编码器入门指南，生成模型正确，因此让我们快速回顾一下有关，生成模型正确，因此让我们快速回顾一下有关。

输出编码器，所以我们再次在底部有一个粉红色的输入，输出编码器，所以我们再次在底部有一个粉红色的输入，可以看到颜色，然后进行仿射变换和，可以看到颜色，然后进行仿射变换和，然后您再次获得隐藏层的另一个旋转。

然后获得，然后您再次获得隐藏层的另一个旋转，然后获得，我们将要强制执行的最终输出接近于，我们将要强制执行的最终输出接近于，再次类似于输入，您有一个平行的图，其中每个，再次类似于输入，您有一个平行的图。

其中每个，转换用一个右框表示，因此在这种情况下，人们称之为，转换用一个右框表示，因此在这种情况下，人们称之为，该网络扩展为神经网络，因为有两种转换，该网络扩展为神经网络，因为有两种转换。

但是我实际上你知道主张的是，这是一个三层神经网络，但是我实际上你知道主张的是，这是一个三层神经网络，因为对我来说，层是那种激活，因为对我来说，层是那种激活，通常是定义，然后是的。

现在使用那种看起来像新的符号，通常是定义，然后是的，现在使用那种看起来像新的符号，像一个带有圆形顶部的盒子，好吧，所以我们有两个不同的图，像一个带有圆形顶部的盒子，好吧，所以我们有两个不同的图，在这里。

因为我们可以在表示之间来回切换，在这里，因为我们可以在表示之间来回切换，当我们想谈论单身时，有时使用左身更容易，当我们想谈论单身时，有时使用左身更容易，神经元，但有时我们更喜欢使用另一个，神经元。

但有时我们更喜欢使用另一个，就像您知道的那样，它占了多个层次，所以每个类似块都在这里或，就像您知道的那样，它占了多个层次，所以每个类似块都在这里或，编码器和解码器也可以是多层。

编码器和解码器也可以是多层，我猜有两个宏模块，所以输入信号进入编码器内部，我猜有两个宏模块，所以输入信号进入编码器内部，这给了我们一个代码，所以H之前，这给了我们一个代码，所以H之前，当我们谈论您时。

神经网络的隐藏表示形式会知道编码器，当我们谈论您时，神经网络的隐藏表示形式会知道编码器，H被称为代码，因此我们有一个编码器对输入进行编码，H被称为代码，因此我们有一个编码器对输入进行编码，到此代码中。

然后我们有一个解码器，它将代码解码为，到此代码中，然后我们有一个解码器，它将代码解码为，这种情况下的任何表示都与相同表示类似，这种情况下的任何表示都与相同表示类似，作为输入。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_3.png)

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_4.png)

好吧，所以在右侧您已经离开了左侧的编码器，好吧，所以在右侧您已经离开了左侧的编码器，您将看到什么是变化值如何正确编码，您将看到什么是变化值如何正确编码，你去一个变化的alt编码器好吧，它看起来。

你去一个变化的alt编码器好吧，它看起来，一样，所以有什么区别，什么都没有丢失，所以，一样，所以有什么区别，什么都没有丢失，所以，第一个区别是，我们现在不再具有隐藏层的年龄，第一个区别是。

我们现在不再具有隐藏层的年龄，代码实际上是由两件事组成的，它是由一件事组成的。代码实际上是由两件事组成的，它是由一件事组成的。Z的资本e和Z的V的资本，它们将很快代表均值和，Z的资本e和Z的V的资本。

它们将很快代表均值和，这个潜在变量的方差表示然后我们将进行采样，这个潜在变量的方差表示然后我们将进行采样，从已经由编码器参数化的分布中，我们得到，从已经由编码器参数化的分布中，我们得到，改为Zedd。

这是我的潜在变量我的潜在表示形式，然后这，改为Zedd，这是我的潜在变量我的潜在表示形式，然后这，潜在表示在解码器内部，因此我采样的参数，潜在表示在解码器内部，因此我采样的参数，从像我有一个正态分布。

其中有一些参数E和VE和，从像我有一个正态分布，其中有一些参数E和VE和，V由输入X确定性地确定，但Z不是，V由输入X确定性地确定，但Z不是，确定性Zed是随机变量，可从，确定性Zed是随机变量，可从。

分布是由编码器参数化的，所以假设H是，分布是由编码器参数化的，所以假设H是，尺寸T现在，编码器按此处左侧的解码将是，尺寸T现在，编码器按此处左侧的解码将是，大小是D的两倍，因为我们必须代表所有的均值。

然后再代表所有，大小是D的两倍，因为我们必须代表所有的均值，然后再代表所有，在这种情况下，我们假设您知道D均值和D，在这种情况下，我们假设您知道D均值和D，方差，所以每个这些分量都是独立的好吧。

所以我们可以，方差，所以每个这些分量都是独立的好吧，所以我们可以，还可以将经典的out编码器视为仅对均值进行编码，因此，如果您，还可以将经典的out编码器视为仅对均值进行编码，因此，如果您。

对均值进行编码，您基本上将零方差设为，对均值进行编码，您基本上将零方差设为，还是确定性输出编码器，因此在这种情况下H可能是D，因此在，还是确定性输出编码器，因此在这种情况下H可能是D，因此在。

左侧的e和V将总计为D，左侧的e和V将总计为D，因为我们有D表示，这也意味着我们要对分布进行采样，因为我们有D表示，这也意味着我们要对分布进行采样，这将是一个正交的多元高斯，所以如果你有。

这将是一个正交的多元高斯，所以如果你有，所有彼此独立的组件，以及，所有彼此独立的组件，以及，因此Z将成为D维向量，但随后将采样，因此Z将成为D维向量，但随后将采样，来自高斯的D维矢量，您将需要D均值。

然后在这种情况下，来自高斯的D维矢量，您将需要D均值，然后在这种情况下，方差，因为我们假设，方差，因为我们假设，协方差矩阵都是零，只有对角线，协方差矩阵都是零，只有对角线，你有所有的变化都可以。

所以这里只是回顾一下，你有所有的变化都可以，所以这里只是回顾一下，将这种输入分布映射成类似输入的编码器，将这种输入分布映射成类似输入的编码器，R 2 D中的一组样本，因此在这种情况下，我们可以认为。

R 2 D中的一组样本，因此在这种情况下，我们可以认为，X到隐藏的表示形式，然后解码器改为映射z空间，X到隐藏的表示形式，然后解码器改为映射z空间，进入RN，该RN返回到DX的原始空间，因此我们从。

进入RN，该RN返回到DX的原始空间，因此我们从，小写到X帽子的人问EFC和VFC是，小写到X帽子的人问EFC和VFC是，Z的编码器ye和e的编码器只是震耳欲聋的参数。

Z的编码器ye和e的编码器只是震耳欲聋的参数，编码器确定性地输出，因此编码器是确定性的，编码器确定性地输出，因此编码器是确定性的，知道这只是经典的旋转和挤压，然后再好，知道这只是经典的旋转和挤压。

然后再好，转换，所以它只是神经网络的一部分，正在输出一些，转换，所以它只是神经网络的一部分，正在输出一些，参数确定，所以这是给我这些参数E的编码器，参数确定，所以这是给我这些参数E的编码器。

和V给定我的输入X正确，所以这是确定性部分，然后给定我们，和V给定我的输入X正确，所以这是确定性部分，然后给定我们，有这些参数这些参数是您知道的给我一个高斯，有这些参数这些参数是您知道的给我一个高斯。

具有特定方法和特定差异的分布，具有特定方法和特定差异的分布，高斯分布的方差，我们可以简单地建立一个样本集，高斯分布的方差，我们可以简单地建立一个样本集，然后我们解码。

这意味着我们将在一秒钟内看到什么意思，但是，然后我们解码，这意味着我们将在一秒钟内看到什么意思，但是，基本上，您将要编码，基本上，您将要编码，他们的意思是，然后您将要添加一些其他的声音，好吗。

他们的意思是，然后您将要添加一些其他的声音，好吗，到去噪自动编码器中的编码，我们得到了输入，到去噪自动编码器中的编码，我们得到了输入，您将噪声添加到输入中，然后尝试重建，您将噪声添加到输入中。

然后尝试重建，在这里输入没有噪音的唯一变化是，在这里输入没有噪音的唯一变化是，噪声被添加到内部表示而不是添加到，噪声被添加到内部表示而不是添加到，输入有意义吗，是的，这更有意义，谢谢，所以我注意到了。

输入有意义吗，是的，这更有意义，谢谢，所以我注意到了，该符号本身看起来像是期望值，该符号本身看起来像是期望值，只是Z的正常平均值，或者我们实际上是在计算我的加权平均值，只是Z的正常平均值。

或者我们实际上是在计算我的加权平均值，不，不，没有，所以我的X而不是输出，而是输出，不，不，没有，所以我的X而不是输出，而是输出，说D将是10，现在是隐藏的表示，而不是10，说D将是10。

现在是隐藏的表示，而不是10，代表平均值的值我们将有20个值10个值是，代表平均值的值我们将有20个值10个值是，代表平均值，10个值代表方差，所以我们，代表平均值，10个值代表方差，所以我们。

只是输出一个向量H在这里给定我的X向量的前半部分代表，只是输出一个向量H在这里给定我的X向量的前半部分代表，高斯分布和另一半的标准偏差的均值，高斯分布和另一半的标准偏差的均值。

向量的代表相同高斯分布的方差，向量的代表相同高斯分布的方差，因此第一个成分h1的成分年龄将是，因此第一个成分h1的成分年龄将是，首先是高斯，然后是成分年龄，好吧，我们称其为h 2 in，首先是高斯。

然后是成分年龄，好吧，我们称其为h 2 in，这种情况将是方差，那么你有h 3这将是另一个意思，这种情况将是方差，那么你有h 3这将是另一个意思，H 4它的力可能是另一个变化，所以好吧，这与。

H 4它的力可能是另一个变化，所以好吧，这与，使得Z像是从yeah yeah yeah采样的10维向量，使得Z像是从yeah yeah yeah采样的10维向量，是这里将是这些网站的一半。

所以编码器给了我，是这里将是这些网站的一半，所以编码器给了我，Z尺寸的两倍，然后因为您获得一半的尺寸，Z尺寸的两倍，然后因为您获得一半的尺寸，像其中一组是模因，一组是方差，像其中一组是模因，一组是方差。

然后我们从具有这些值的高斯样本中进行采样，因此网络可以简单地给出，然后我们从具有这些值的高斯样本中进行采样，因此网络可以简单地给出，我不仅是古典奥尔顿冷却器的装置，而且，我不仅是古典奥尔顿冷却器的装置。

而且，给我一些范围，我可以在什么时候选择合适的东西，给我一些范围，我可以在什么时候选择合适的东西，我们在这里使用经典的输出编码器，我们只有手段，然后您，我们在这里使用经典的输出编码器，我们只有手段。

然后您，在这种情况下，只需解码均值，您不仅拥有均值，而且还可以，在这种情况下，只需解码均值，您不仅拥有均值，而且还可以，有一些变体，这些变体意味着可以，所以编码器，有一些变体，这些变体意味着可以。

所以编码器，普通编码器确定性输出确定性输入功能，普通编码器确定性输出确定性输入功能，输入的变化停止编码器的输出不再是确定性的，输入的变化停止编码器的输出不再是确定性的，它不再是输入的确定性功能，而是。

它不再是输入的确定性功能，而是，给定输入权，则条件分配就是，给定输入权，则条件分配就是，输入，因此在这种情况下，我们确实看到我们上次看到类似的图表，输入，因此在这种情况下。

我们确实看到我们上次看到类似的图表，我们从左侧的特定点到右侧的位置，我们从左侧的特定点到右侧的位置，在这种情况下，我们从一个点开始，然后通过，在这种情况下，我们从一个点开始，然后通过，编码器。

您将在这里找到一些位置，但是还有，编码器，您将在这里找到一些位置，但是还有，噪音对，如果您只希望得到一个Zed，那么，噪音对，如果您只希望得到一个Zed，那么，鉴于还有一些额外的噪音是由于我们。

鉴于还有一些额外的噪音是由于我们，没有零方差，最终Zed不会是，没有零方差，最终Zed不会是，只是一点，就好像是模糊点，所以与其，只是一点，就好像是模糊点，所以与其。

现在一个点一个一个X将被映射到点的一个区域中，所以，现在一个点一个一个X将被映射到点的一个区域中，所以，实际上会占用一些空间，然后我们如何训练，实际上会占用一些空间，然后我们如何训练。

当我们通过将潜变量Z发送回去训练系统时，当我们通过将潜变量Z发送回去训练系统时，解码器，以便使这些X变得很热，当然不会，解码器，以便使这些X变得很热，当然不会，将其精确地还原到原始点。

因为也许我们尚未训练，将其精确地还原到原始点，因为也许我们尚未训练，所以我们必须重构原始输入并做到这一点，所以我们必须重构原始输入并做到这一点，试图最小化重建与，试图最小化重建与，原始输入。

然后我们遇到了问题，原始输入，然后我们遇到了问题，在喜欢去潜伏之前，先从潜伏到输入空间，在喜欢去潜伏之前，先从潜伏到输入空间，需要知道或延迟这种潜在的分布或强制执行一些。

需要知道或延迟这种潜在的分布或强制执行一些，上次发布时，我们看到我们在做类似的事情时，上次发布时，我们看到我们在做类似的事情时，我们正在使用经典的标准输出编码器，但我们要。

我们正在使用经典的标准输出编码器，但我们要，从一个点X到一个点Z，然后回到现在的X，相反，我们是，从一个点X到一个点Z，然后回到现在的X，相反，我们是，将要在潜在空间中的这些点上进行分布。

将要在潜在空间中的这些点上进行分布，在我们经历一个点一个点然后一个点之前，然后，在我们经历一个点一个点然后一个点之前，然后，不知道如果您在潜伏空间四处走动，请记住，不知道如果您在潜伏空间四处走动。

请记住，如果您左侧有任何样品，您将自动获得，如果您左侧有任何样品，您将自动获得，另一方面，十个潜在变量，但是你不知道怎么去，另一方面，十个潜在变量，但是你不知道怎么去，在这些输入之间。

您不知道该如何潜伏，在这些输入之间，您不知道该如何潜伏，空间，因为我们不知道该空间的行为还可以吗？空间，因为我们不知道该空间的行为还可以吗？颜色增强了某些结构，它们通过添加被惩罚来实现。

颜色增强了某些结构，它们通过添加被惩罚来实现，与正态分布不同或相距甚远，因此如果您有潜伏，与正态分布不同或相距甚远，因此如果您有潜伏，分布实际上不是高斯分布，分布实际上不是高斯分布，这将非常高非常高。

并且当我们训练一个传统编码器时，这将非常高非常高，并且当我们训练一个传统编码器时，我们将通过最小化这两个术语来培训NIT，我们将通过最小化这两个术语来培训NIT，这个术语在这里。

所以左侧的术语可以确保我们，这个术语在这里，所以左侧的术语可以确保我们，可以回到原来的位置，右侧的术语可以强制执行，可以回到原来的位置，右侧的术语可以强制执行，潜在空间中的结构，因为否则我们将无法为您。

潜在空间中的结构，因为否则我们将无法为您，当我们想使用此解码器作为生成模型时，从那里知道样本，当我们想使用此解码器作为生成模型时，从那里知道样本，好吧，这也许不太清楚，但是让我给您更多一点，好吧。

这也许不太清楚，但是让我给您更多一点，考虑一下，我们如何实际创建此潜在变量Z，所以我的Z就是，考虑一下，我们如何实际创建此潜在变量Z，所以我的Z就是，将会是我z的平均值y加上一些你知道的。

将会是我z的平均值y加上一些你知道的，一些噪声epsilon是来自正态分布的样本，例如，一些噪声epsilon是来自正态分布的样本，例如，零的正态多元高斯分布意味着一个恒等式。

零的正态多元高斯分布意味着一个恒等式，矩阵作为协方差矩阵，每个分量乘以，矩阵作为协方差矩阵，每个分量乘以，标准偏差射线，因此您应该在此处熟悉此方程式，标准偏差射线，因此您应该在此处熟悉此方程式。

右上方是重新缩放随机变量epsilon的方式，右上方是重新缩放随机变量epsilon的方式，正常情况下，您必须使用这种修复金属化工艺才能获得，正常情况下，您必须使用这种修复金属化工艺才能获得，高斯。

您知道特定变体中的特定均值，所以再次，高斯，您知道特定变体中的特定均值，所以再次，潜变量Z中的噪声只是在，潜变量Z中的噪声只是在，输入，因此输入中没有噪音，您可以将输入放置在，输入，因此输入中没有噪音。

您可以将输入放置在，编码器，然后当您，编码器，然后当您，从这个分布的样本中，您基本上得到Z以及得到的结果，从这个分布的样本中，您基本上得到Z以及得到的结果，只是您可以将采样部分写成这一部分。

所以问题出在，只是您可以将采样部分写成这一部分，所以问题出在，采样是我们不知道如何通过，采样是我们不知道如何通过，采样模块实际上没有办法通过同一个模块执行反向传播。

采样模块实际上没有办法通过同一个模块执行反向传播，事情，因为这只是生成一个新的集合，所以我们如何获得，事情，因为这只是生成一个新的集合，所以我们如何获得，通过该模块进行渐变以训练编码器，因此可以。

通过该模块进行渐变以训练编码器，因此可以，如果您使用此技巧，即修复金属化技巧，则完成，如果您使用此技巧，即修复金属化技巧，则完成，维修问题是亚洲的把戏，使您可以根据，维修问题是亚洲的把戏，使您可以根据。

你知道加法和乘法，我们可以区分右掷，你知道加法和乘法，我们可以区分右掷，epsilon仅仅是一个附加输入，您知道它来自任何东西，epsilon仅仅是一个附加输入，您知道它来自任何东西，只要没有问题。

我们就不需要通过此输入发送梯度，只要没有问题，我们就不需要通过此输入发送梯度，梯度将通过乘法和通过，梯度将通过乘法和通过，好的，所以只要您有渐变，好的，所以只要您有渐变，训练该系统，梯度下降。

然后在这里我们可以替换，训练该系统，梯度下降，然后在这里我们可以替换，采样模块以及E Plus之间的附加模块，采样模块以及E Plus之间的附加模块，epsilon乘以方差的平方根就可以了。

epsilon乘以方差的平方根就可以了，您知道加法，您知道如何通过加法制作道具，您知道加法，您知道如何通过加法制作道具，因此，您可以获得编码器的梯度，这里是输出梯度，然后，因此，您可以获得编码器的梯度。

这里是输出梯度，然后，您可以计算出您知道有限成本的偏导数，您可以计算出您知道有限成本的偏导数，尊重这个模块中的参数，好吧，只要您知道直觉，尊重这个模块中的参数，好吧，只要您知道直觉。

这个KL的一部分可以让我在潜在空间中增强结构，这个KL的一部分可以让我在潜在空间中增强结构，我们就是这么想的那就是我希望您这样想的。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_6.png)

我们就是这么想的那就是我希望您这样想的，角色，所以让我们实际弄清楚这些东西是如何工作的，所以我们有。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_8.png)

角色，所以让我们实际弄清楚这些东西是如何工作的，所以我们有，在我的钱包中有两个字词，我们有第一个是，在我的钱包中有两个字词，我们有第一个是，重建损失，然后是第二项，重建损失，然后是第二项。

这些KL这个相对熵项还可以，所以在这种情况下，我们有一些Z，这些KL这个相对熵项还可以，所以在这种情况下，我们有一些Z，球形气泡好，在这种情况下为什么会有气泡，因为如果我们添加，球形气泡好。

在这种情况下为什么会有气泡，因为如果我们添加，一些额外的噪音，我们拥有的手段和手段基本上是，一些额外的噪音，我们拥有的手段和手段基本上是，这些点的中心正确，所以您在这里有一个均值在这里有一个均值。

这些点的中心正确，所以您在这里有一个均值在这里有一个均值，意思是在这里1分钟，然后是重建期限，意思是在这里1分钟，然后是重建期限，要做的是以下操作，如果这意味着如果这些气泡重叠，该怎么办。

要做的是以下操作，如果这意味着如果这些气泡重叠，该怎么办，它发生的原因是，如果您在这里有1分钟的时间，而另一个意思是一个气泡，它发生的原因是，如果您在这里有1分钟的时间，而另一个意思是一个气泡。

另一个气泡重叠，并且有一个区域，另一个气泡重叠，并且有一个区域，知道交叉点如何重建这两点，知道交叉点如何重建这两点，稍后在右侧，如果您有气泡，您将无法继续关注您，稍后在右侧，如果您有气泡。

您将无法继续关注您，这里，然后你有另一个气泡这里，这个气泡上的所有点都会，这里，然后你有另一个气泡这里，这个气泡上的所有点都会，在这里被重建为原始输入，所以您从原始点开始，在这里被重建为原始输入。

所以您从原始点开始，你去这里的潜在空间，然后你实际上并没有什么噪音，你去这里的潜在空间，然后你实际上并没有什么噪音，在这里有一个体积，那么你要讲另一点，而这另一点，在这里有一个体积，那么你要讲另一点。

而这另一点，如果这两个家伙重叠，现在在这里重建，如果这两个家伙重叠，现在在这里重建，您能在这里重构点吗，如果这些点在气泡中，我会，您能在这里重构点吗，如果这些点在气泡中，我会，如果这些点在气泡中。

我想回到这里的原始点，如果这些点在气泡中，我想回到这里的原始点，我想去另一点，但如果要点重叠，对不起，我想去另一点，但如果要点重叠，对不起，气泡是重叠的，那么你真的无法弄清楚去哪里，气泡是重叠的。

那么你真的无法弄清楚去哪里，对，那么重建项我们就要做重建，对，那么重建项我们就要做重建，学期将尝试使所有这些气泡尽可能地避免，学期将尝试使所有这些气泡尽可能地避免，重叠，因为如果它们重叠。

那么重建将不会很好，重叠，因为如果它们重叠，那么重建将不会很好，所以现在我们必须解决这个问题，所以有几种方法可以解决这个问题，所以现在我们必须解决这个问题，所以有几种方法可以解决这个问题。

您现在告诉我如何解决这个重叠的问题，为什么不，您现在告诉我如何解决这个重叠的问题，为什么不，我们在普通编码器中有这个重叠的问题，因为没有，我们在普通编码器中有这个重叠的问题，因为没有，方差AHA。

这意味着什么好，您可以翻译不存在的内容吗，方差AHA，这意味着什么好，您可以翻译不存在的内容吗，没有方差意味着球面不是球面，但它们是点，没有方差意味着球面不是球面，但它们是点，正确正确。

所以如果您只有一点，就永远不会正确重叠，正确正确，所以如果您只有一点，就永远不会正确重叠，它们必须是完全相同的点，但是只有在，它们必须是完全相同的点，但是只有在，编码器没有正确设置。

或者您输入的是相同的输入，我认为是，编码器没有正确设置，或者您输入的是相同的输入，我认为是，如果现在没有点，则两点不可能重叠，如果现在没有点，则两点不可能重叠，实际上，您知道音量可以重叠。

因为它们的含义是，实际上，您知道音量可以重叠，因为它们的含义是，无限量就可以了，所以一种选择是，无限量就可以了，所以一种选择是，凯拉方差，所以你有积分，现在这击败了整个变分，凯拉方差，所以你有积分。

现在这击败了整个变分，通过杀掉没有Spacey东西的东西，通过杀掉没有Spacey东西的东西，方差现在您不再知道两点之间发生了什么，方差现在您不再知道两点之间发生了什么，对，因为如果您有足够的空间。

例如他们可以容纳大量物品，则可以四处走走，对，因为如果您有足够的空间，例如他们可以容纳大量物品，则可以四处走走，如果这些都是要点，那么您始终可以找出潜在的潜在空间，如果这些都是要点。

那么您始终可以找出潜在的潜在空间，一旦离开此职位，您将不会有任何想法，一旦离开此职位，您将不会有任何想法，怎么走好吧首先，怎么走好吧首先，可以杀死方差另一种选择，我在这里向您展示，我另一种。

可以杀死方差另一种选择，我在这里向您展示，我另一种，选择是尽可能使这些气泡正确，如果它们尽可能远，选择是尽可能使这些气泡正确，如果它们尽可能远，尽可能在您的Python脚本中发生什么，所以如果这些谷底。

尽可能在您的Python脚本中发生什么，所以如果这些谷底，意味着下雨了他们会走得很远然后会增加很多很多，意味着下雨了他们会走得很远然后会增加很多很多，对，然后的问题是，你将获得无限的权利，对。

然后的问题是，你将获得无限的权利，东西会爆炸，因为所有这些价值都试图尽可能地走，东西会爆炸，因为所有这些价值都试图尽可能地走，这样它们就不会重叠，那就不好了，好吧，让我们，这样它们就不会重叠。

那就不好了，好吧，让我们，找出永恒变化的奥尔顿颜色如何解决此问题，找出永恒变化的奥尔顿颜色如何解决此问题，只是通过把观点分开来澄清你的意思，就像你把，只是通过把观点分开来澄清你的意思，就像你把。

它们在高维空间中不，不，不，因为它们在这里，所以每个如果，它们在高维空间中不，不，不，因为它们在这里，所以每个如果，这里没有所有的圆圈，所有的气泡都没有，这里没有所有的圆圈，所有的气泡都没有，只是指出。

即使我们有一些差异，他们现在也会占用一些空间，只是指出，即使我们有一些差异，他们现在也会占用一些空间，如果两个气泡占据的空间与另一个气泡重叠，则，如果两个气泡占据的空间与另一个气泡重叠，则。

重建错误会增加，因为您不知道如何返回，重建错误会增加，因为您不知道如何返回，到产生公平的原始点，因此网络，到产生公平的原始点，因此网络，编码器有两种选择，以减少这种重建误差，编码器有两种选择。

以减少这种重建误差，选项将是消除方差，以便您获得积分，选项将是消除方差，以便您获得积分，另一个选择是将所有这些点向任意方向发送，另一个选择是将所有这些点向任意方向发送，他们不会重叠好的好的是的。

这样很好，他们不会重叠好的好的是的，这样很好，重建错误，让这些东西飞来飞去，但是接下来让我们，重建错误，让这些东西飞来飞去，但是接下来让我们，介绍第二个学期，所以我真的建议您计算这些，介绍第二个学期。

所以我真的建议您计算这些，高斯分布与正态分布之间的相对熵，例如，高斯分布与正态分布之间的相对熵，例如，可以练习下周，但是如果您计算相对，可以练习下周，但是如果您计算相对，熵，你会得到这些东西。

基本上你会得到四个词，熵，你会得到这些东西，基本上你会得到四个词，每个人都应该了解这些根源，每个人都应该了解这些根源，不行，我只是在开玩笑，我实际上会在解释它，所以我们有，不行，我只是在开玩笑。

我实际上会在解释它，所以我们有，这个表达式让我们尝试更详细地分析它们的作用，这个表达式让我们尝试更详细地分析它们的作用，这些术语代表了您拥有这些变体的第一个术语-对数变体。

这些术语代表了您拥有这些变体的第一个术语-对数变体，-这样一来，如果我们将其绘制成图形，就可以看到一个线性函数，-这样一来，如果我们将其绘制成图形，就可以看到一个线性函数，之后，您知道之后-在x轴上。

然后在其他条件下，之后，您知道之后-在x轴上，然后在其他条件下，减去您减去一个对数，该对数将变为无穷大，就像您，减去您减去一个对数，该对数将变为无穷大，就像您，将负对数相加后等于零的无穷大，否则为。

将负对数相加后等于零的无穷大，否则为，只是你知道衰变，所以如果你将两者相加然后减去一个，就会得到，只是你知道衰变，所以如果你将两者相加然后减去一个，就会得到，这种可爱的功能，如果最小化此功能。

您只会得到一个，这种可爱的功能，如果最小化此功能，您只会得到一个，因此，这些内容向您展示了这些术语以及如何迫使这些领域，因此，这些内容向您展示了这些术语以及如何迫使这些领域，每个方向的半径为1。

因为如果尝试小于，每个方向的半径为1，因为如果尝试小于，你知道上涨的东西是疯狂的，如果这里的涨幅没有上升，你知道上涨的东西是疯狂的，如果这里的涨幅没有上升，像疯了一样，所以他们是一点点。

你至少大概知道所有的方式，像疯了一样，所以他们是一点点，你至少大概知道所有的方式，或您知道一半，但不会更小，因为您知道，或您知道一半，但不会更小，因为您知道，增加很多。

因此在这种情况下我们强制网络不崩溃，增加很多，因此在这种情况下我们强制网络不崩溃，这些气泡是为了使其过度生长，否则，这些气泡是为了使其过度生长，否则，他们在这里仍然受到惩罚。

所以我们在这里还有另一个术语，他们在这里仍然受到惩罚，所以我们在这里还有另一个术语，一切都平方，那是古典问题，那边的最小值，一切都平方，那是古典问题，那边的最小值。

所以这里的这个术语基本上是说它的意思应该被压缩，所以这里的这个术语基本上是说它的意思应该被压缩，趋于零，因此基本上，您会在这里得到这种额外的力，趋于零，因此基本上，您会在这里得到这种额外的力。

紫色的一面，现在您将所有这些气泡挤在一起，紫色的一面，现在您将所有这些气泡挤在一起，这个更大的气泡，所以在这里您可以获得一个，这个更大的气泡，所以在这里您可以获得一个，可变编码器。

这个非常可爱的东西有多可爱你怎么能装更多气泡，这个非常可爱的东西有多可爱你怎么能装更多气泡，这里唯一的参数告诉您变化的力量，这里唯一的参数告诉您变化的力量，编码器，它只是尺寸D，编码器，它只是尺寸D。

因为您知道给定尺寸，所以您总是知道可以有多少个气泡，因为您知道给定尺寸，所以您总是知道可以有多少个气泡，装在一个较大的气泡中，所以它只是您尺寸的函数，装在一个较大的气泡中，所以它只是您尺寸的函数，选择。

然后选择隐藏层，尽管重建是最后一次，选择，然后选择隐藏层，尽管重建是最后一次，第一项黄色术语是实际上推动气泡的术语，第一项黄色术语是实际上推动气泡的术语，距离更远，不会剩下的是什么使他们无法做。

距离更远，不会剩下的是什么使他们无法做，没错，所以重建将推动一切，因为我们拥有这些，没错，所以重建将推动一切，因为我们拥有这些，额外的取货量是正确的，因此，如果我们不取货，额外的取货量是正确的，因此。

如果我们不取货，重建期限不会推销任何东西，因为它不会重叠，重建期限不会推销任何东西，因为它不会重叠，鉴于我们实际上有一些差异，差异将具有这些，鉴于我们实际上有一些差异，差异将具有这些。

点实际上需要一些体积，因此，此重建将尝试，点实际上需要一些体积，因此，此重建将尝试，让那些点消失，所以如果您再次检查那些动画，我会告诉您，让那些点消失，所以如果您再次检查那些动画，我会告诉您。

所以我们一开始就有那些带有额外噪音的地方，所以我们一开始就有那些带有额外噪音的地方，得到的重建就是你知道将一切推开然后你得到，得到的重建就是你知道将一切推开然后你得到，它可以确保您这些小气泡不会崩溃。

然后，它可以确保您这些小气泡不会崩溃，然后，您有最后一个学期，这是春季学期，因为这是二次方，您有最后一个学期，这是春季学期，因为这是二次方，损失中的术语，基本上就是增加了这些额外的压力，例如。

损失中的术语，基本上就是增加了这些额外的压力，例如，所有的小家伙让你知道回到零，但它们不会重叠，所有的小家伙让你知道回到零，但它们不会重叠，因为有重建项，所以没有重叠，因为有重建项，所以没有重叠。

尺寸不小于一个，因为第一部分，尺寸不小于一个，因为第一部分，相对熵，然后将所有这些家伙再次停在二次部分，相对熵，然后将所有这些家伙再次停在二次部分，这是弹簧力，这是一个术语，需要，这是弹簧力。

这是一个术语，需要，像超参数一样进行了调整，因此beta是实际的，像超参数一样进行了调整，因此beta是实际的，此变体的原始版本alt编码没有beta，然后存在，此变体的原始版本alt编码没有beta。

然后存在，是一篇论文，它是编码器的beta版本，只是说您可以，是一篇论文，它是编码器的beta版本，只是说您可以，使用超级参数来更改您知道这两个术语的贡献，使用超级参数来更改您知道这两个术语的贡献。

最终的光泽度，该损失是带有KL的beta的第二个损失项，最终的光泽度，该损失是带有KL的beta的第二个损失项，是的，那么之间的正态分布率是，是的，那么之间的正态分布率是。

设计来自均值II和方差V的高斯，然后是，设计来自均值II和方差V的高斯，然后是，第二项将是这个正态分布，因此该项试图，第二项将是这个正态分布，因此该项试图，使Z尽可能接近空间V中的正态分布。

使Z尽可能接近空间V中的正态分布，维空间好，这个公式是通用的，所以我，维空间好，这个公式是通用的，所以我，建议您拿一支纸和笔，然后尝试写，建议您拿一支纸和笔，然后尝试写，高斯分布与正态分布之间的相对熵。

您应该得到，高斯分布与正态分布之间的相对熵，您应该得到，所有这些术语都是相对熵，是的，这些lkl是相对熵，所有这些术语都是相对熵，是的，这些lkl是相对熵，是的，所以只需查找相对熵的公式即可告诉您。

是的，所以只需查找相对熵的公式即可告诉您，基本上分布到多远，第一个分布到，基本上分布到多远，第一个分布到，是多元高斯，第二个将是正常，是多元高斯，第二个将是正常，分配权是的正态分布是不一样的。

分配权是的正态分布是不一样的，高斯（Gaussian）具有均值向量，而法线的协方差矩阵具有0个均值，高斯（Gaussian）具有均值向量，而法线的协方差矩阵具有0个均值，和协方差矩阵的恒等矩阵。

我们前面说过，尽管Z，和协方差矩阵的恒等矩阵，我们前面说过，尽管Z，不应该有协方差它应该是对角线对是的所以它就是，不应该有协方差它应该是对角线对是的所以它就是，将是对角线，但对角线上的值，将是对角线。

但对角线上的值，V Benson好吧，这是一个偏心的大法线，而不是一个居中的法线，V Benson好吧，这是一个偏心的大法线，而不是一个居中的法线，小法线，因此它不在中心，然后每个方向由缩放，小法线。

因此它不在中心，然后每个方向由缩放，该尺寸的标准偏差右侧，因此如果您的尺寸较大，该尺寸的标准偏差右侧，因此如果您的尺寸较大，一维的标准偏差意味着在那个方向上，一维的标准偏差意味着在那个方向上。

散布很有意义，但是D轴上有一条线，散布很有意义，但是D轴上有一条线，对，因为所有组件都是独立的，是的，对，因为所有组件都是独立的，是的，重建失去了最终输出与像素之间的像素明智距离。

重建失去了最终输出与像素之间的像素明智距离，原始图像我们上周看到的重建损失有两个，原始图像我们上周看到的重建损失有两个，重建的选项之一是二进制数据的二进制，我们，重建的选项之一是二进制数据的二进制。

我们，具有二元交叉熵，而另一个将是，具有二元交叉熵，而另一个将是，一个的实际值，以便您可以正确使用一半或一个DMS MSC，这样，一个的实际值，以便您可以正确使用一半或一个DMS MSC，这样。

这些是我们可以使用的重建损失，例如您与，这些是我们可以使用的重建损失，例如您与，那我的末日好，现在好不好，你也应该和年轻人谈谈，那我的末日好，现在好不好，你也应该和年轻人谈谈。

但是我们应该检查笔记本电脑，以便我们可以看到如何，但是我们应该检查笔记本电脑，以便我们可以看到如何，编码星星，也可以使用分布，因为在此之前，编码星星，也可以使用分布，因为在此之前，要点是。

在我们映射点之前，先映射两个点，然后再映射两个，要点是，在我们映射点之前，先映射两个点，然后再映射两个，现在就指向点，而不是将点映射到空间，然后将空间，现在就指向点，而不是将点映射到空间，然后将空间。

两点，但现在所有的空间都将被这些覆盖，两点，但现在所有的空间都将被这些覆盖，气泡是由于多种因素引起的，如果这些因素之间有一定间隔，气泡是由于多种因素引起的，如果这些因素之间有一定间隔，气泡。

那么您不知道如何从此处的该区域返回输入，气泡，那么您不知道如何从此处的该区域返回输入，正确的空间而不是变化的自动编码器可以让您，正确的空间而不是变化的自动编码器可以让您，表现良好的覆盖范围。

您知道这些潜在空间的覆盖范围还可以，表现良好的覆盖范围，您知道这些潜在空间的覆盖范围还可以，好，我看不到你，你想念你们，好吧，到目前为止，我可以订购问题吗？好，我看不到你，你想念你们，好吧，到目前为止。

我可以订购问题吗？

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_10.png)

希望你能看到我刚刚提供的反馈信息能看到的东西是的，是的，所以，希望你能看到我刚刚提供的反馈信息能看到的东西是的，是的，所以。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_12.png)

工作得到PDL神鹰激活PT和，木星笔记本热潮好吧，所以我现在要覆盖dve，所以现在我要。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_14.png)

木星笔记本热潮好吧，所以我现在要覆盖dve，所以现在我要。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_16.png)

只需执行所有操作，以便这些东西开始训练，然后我要，只需执行所有操作，以便这些东西开始训练，然后我要，可以解释一切，所以一开始我会很重要，可以解释一切，所以一开始我会很重要，像往常一样所有随机的狗屎。

然后我有一个显示例程，我们不在乎不要添加，像往常一样所有随机的狗屎，然后我有一个显示例程，我们不在乎不要添加，它到笔记我有一些随机种子的默认值，这样，它到笔记我有一些随机种子的默认值，这样。

您将得到与我得到的数字相同的数字，然后在这里我只使用M nice数据集，您将得到与我得到的数字相同的数字，然后在这里我只使用M nice数据集，我们从打哈欠的设备在East进行修改。

理论上我可以设置CPU或GPU，我们从打哈欠的设备在East进行修改，理论上我可以设置CPU或GPU，之所以使用GP One，是因为我的Mac实际上具有GPU，然后我有了，之所以使用GP One。

是因为我的Mac实际上具有GPU，然后我有了，变差编码器好了，所以我的变差编码器分为两个部分，变差编码器好了，所以我的变差编码器分为两个部分，这里的编码器让我打开行号，所以我的编码器从784开始。

这里的编码器让我打开行号，所以我的编码器从784开始，这是此正方形的输入边的大小，例如在这种情况下为MD，这是此正方形的输入边的大小，例如在这种情况下为MD，是20，所以400，然后从D平方到2倍T。

那将是一半，是20，所以400，然后从D平方到2倍T，那将是一半，我的意思是一半将用于我的Sigma方差，另一方是，我的意思是一半将用于我的Sigma方差，另一方是，如果其他解码器只选择D。

您可以在这里看到Randy，如果其他解码器只选择D，您可以在这里看到Randy，从D到D平方，然后从这个平方到794，使我们匹配，从D到D平方，然后从这个平方到794，使我们匹配，输入维度。

最后我生病了，输入维度，最后我生病了，我没有S型信号，因为我的输入将从0限制为1，我没有S型信号，因为我的输入将从0限制为1，有从零到一的图像，那么这里有一个称为，有从零到一的图像，那么这里有一个称为。

三只首映式的眼睛，如果我们正在训练，我们将使用三个参数，三只首映式的眼睛，如果我们正在训练，我们将使用三个参数，化部分，您能再说一遍为什么在yeah中使用S形吗，化部分。

您能再说一遍为什么在yeah中使用S形吗，因为我的数据在零到一之间，所以我从，因为我的数据在零到一之间，所以我从，M错过了，他们是像数字的值一样的值，M错过了，他们是像数字的值一样的值，将会是0到1。

所以我想将这个模块输出到我的网络，将会是0到1，所以我想将这个模块输出到我的网络，从负无穷大到正无穷大的东西，从负无穷大到正无穷大的东西，sigmoid，当您说出值时，这些东西会像0到1一样发送信息。

sigmoid，当您说出值时，这些东西会像0到1一样发送信息，您指的是数字停用，您指的是数字停用，所以我使用敌人的数据集，这既是我的输入，也是我的，所以我使用敌人的数据集，这既是我的输入，也是我的。

正确定位，图像和这些图像的值将在一定范围内，正确定位，图像和这些图像的值将在一定范围内，在0到1之间，就像是一个真实值，每个像素可以在0和1之间，是的，我，在0到1之间，就像是一个真实值。

每个像素可以在0和1之间，是的，我，认为实际上输入是二进制的，所以输入都是0或1，但是我，认为实际上输入是二进制的，所以输入都是0或1，但是我，网络将输出介于0和1之间的实际范围。

网络将输出介于0和1之间的实际范围，抱歉，我们有参数化我们在这里做什么，所以我们进行参数化，抱歉，我们有参数化我们在这里做什么，所以我们进行参数化，给出亩和对数方差的解释稍后解释为什么我们使用对数方差。

给出亩和对数方差的解释稍后解释为什么我们使用对数方差，您在训练中知道我们会计算标准差，您在训练中知道我们会计算标准差，将对数方差乘以1/2，然后取指数，然后得到，将对数方差乘以1/2，然后取指数。

然后得到，与对数方差的标准偏差，然后得到我的epsilon，与对数方差的标准偏差，然后得到我的epsilon，只是从正态分布中采样而得，只是从正态分布中采样而得，在这里正确，所以标准偏差我得到一个尺寸。

我创建了一个新的张量，我，在这里正确，所以标准偏差我得到一个尺寸，我创建了一个新的张量，我，用正态分布数据填充它，然后返回epsilon x，用正态分布数据填充它，然后返回epsilon x，在偏差中。

我添加了MU，这是我之前向您展示的内容，如果我不是，在偏差中，我添加了MU，这是我之前向您展示的内容，如果我不是，训练我不必增加噪音，所以我可以简单地将亩退还给我，训练我不必增加噪音。

所以我可以简单地将亩退还给我，该网络以确定的方式转发模式如下，该网络以确定的方式转发模式如下，所以在这里，我们需要编码器获取输入，该输入将被重塑为，所以在这里，我们需要编码器获取输入，该输入将被重塑为。

您知道这些事情，基本上我将图像注册到，您知道这些事情，基本上我将图像注册到，向量，那么编码器将成为某种东西的掠夺输出，我将，向量，那么编码器将成为某种东西的掠夺输出，我将，形状为一个。

这样我的批量大小为2，然后是D，其中D是，形状为一个，这样我的批量大小为2，然后是D，其中D是，均值的维数和方差的维数，那么我有mu，均值的维数和方差的维数，那么我有mu。

均值只是这些D的这些人的第一部分，然后是负载，均值只是这些D的这些人的第一部分，然后是负载，变化将是另一个人，然后我有我的Z，变化将是另一个人，然后我有我的Z，作为我的潜在变量，考虑到我的亩。

这将是这三个参数，作为我的潜在变量，考虑到我的亩，这将是这三个参数，以及负载条为什么我使用负载条你告诉我为什么我使用负载条，以及负载条为什么我使用负载条你告诉我为什么我使用负载条，对对对。

因此假设方差仅在我计算时为正，对对对，因此假设方差仅在我计算时为正，该日志允许您正确输出编码器的完整实际范围，因此您，该日志允许您正确输出编码器的完整实际范围，因此您，可以使用整个真实范围。

然后将模型定义为该VA，然后将其发送，可以使用整个真实范围，然后将模型定义为该VA，然后将其发送，到这里的设备，我定义了优化优化器，到这里的设备，我定义了优化优化器，然后定义损失函数。

它是二进制交叉的两部分之和，然后定义损失函数，它是二进制交叉的两部分之和，输入和重构之间的熵，这就是，输入和重构之间的熵，这就是，IX帽子，然后是X，然后我尝试将它们全部加起来，然后是k KL。

IX帽子，然后是X，然后我尝试将它们全部加起来，然后是k KL，散度，所以我们有一个你知道线性的柱，然后你有，散度，所以我们有一个你知道线性的柱，然后你有，减去R的对数，它是对数向下翻转，然后减去1。

然后我们，减去R的对数，它是对数向下翻转，然后减去1，然后我们，有MU，然后我们尝试将这些东西最小化，有MU，然后我们尝试将这些东西最小化，好的，所以训练脚本非常简单，好的，所以训练脚本非常简单。

所以你有输出预测的模型X Hut让我，所以你有输出预测的模型X Hut让我，让我们在这里看到正向输出解码器MU和日志的输出，让我们在这里看到正向输出解码器MU和日志的输出，var。

所以在这里您可以得到模型，并在输入中得到X帽子m子，var，所以在这里您可以得到模型，并在输入中得到X帽子m子，Akbar您可以使用X hat X mu和dog bar X作为输入来计算损失。

Akbar您可以使用X hat X mu和dog bar X作为输入来计算损失，而且还有目标，然后我们知道，是的，我们为损失添加了项目，而且还有目标，然后我们知道，是的，我们为损失添加了项目。

清理前面步骤中的梯度，执行计算，清理前面步骤中的梯度，执行计算，偏导数，然后您步进，然后在这里我进行测试，偏导数，然后您步进，然后在这里我进行测试。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_18.png)

做一些缓存以备后用，所以我们开始时的初始错误为500，做一些缓存以备后用，所以我们开始时的初始错误为500，涟漪514，这是训练前的准备，任何动作都立即进行，涟漪514，这是训练前的准备。

任何动作都立即进行，下降到200，然后下降到100好的，现在我要向您展示，下降到200，然后下降到100好的，现在我要向您展示。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_20.png)

一些结果，这是我输入到网络和未经训练的输入，一些结果，这是我输入到网络和未经训练的输入。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_22.png)

网络重建当然看起来像是对的，但是好吧，所以，网络重建当然看起来像是对的，但是好吧，所以，我们可以继续前进，第一个纪元就很酷，我们可以继续前进，第一个纪元就很酷，第二个纪元第三个第四纪，以此类推。

看起来越来越好，第二个纪元第三个第四纪，以此类推，看起来越来越好，当然，所以我们现在能做些什么，例如现在我们可以做些什么。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_24.png)

当然，所以我们现在能做些什么，例如现在我们可以做些什么。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_26.png)

可以简单地从正态分布中简化Z，然后我对此进行解码，可以简单地从正态分布中简化Z，然后我对此进行解码，随机的东西，所以这不是来自我们的编码器，我现在向您展示，随机的东西，所以这不是来自我们的编码器。

我现在向您展示，每当您从分布中采样潜在的，每当您从分布中采样潜在的，变量应该在后面，所以这些是如何。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_28.png)

变量应该在后面，所以这些是如何。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_30.png)

从潜在分布中取样，您知道会被解码成某种形式，从潜在分布中取样，您知道会被解码成某种形式。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_32.png)

这里有九个我们到零我们有五个，所以一些地区，这里有九个我们到零我们有五个，所以一些地区。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_34.png)

很好地定义了9到9，但是其他地区喜欢这里，很好地定义了9到9，但是其他地区喜欢这里，或这里的东西或这里的数字14看起来并不像，或这里的东西或这里的数字14看起来并不像。

数字是因为这是为什么我们没有真正解决这里的问题，数字是因为这是为什么我们没有真正解决这里的问题，我刚训练的整个空间一分钟，我刚训练的整个空间一分钟，如果我训练了10分钟，那就可以正常工作了，所以。

如果我训练了10分钟，那就可以正常工作了，所以，在这里那些气泡还没有充满整个空间，而且是一样的，在这里那些气泡还没有充满整个空间，而且是一样的，没有这个的普通输出编码器会出现的问题。

没有这个的普通输出编码器会出现的问题，对编码器来说很正常的变化性东西，你根本不知道，对编码器来说很正常的变化性东西，你根本不知道，一种结构，介于两者之间的区域中任何一种定义好的行为，一种结构。

介于两者之间的区域中任何一种定义好的行为，alt编码器上变化的不同点，我们实际上将，alt编码器上变化的不同点，我们实际上将，空间并强制执行所有这些区域的重建，空间并强制执行所有这些区域的重建。

其实又有意义，所以让我们做一些可爱的事情，然后我。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_36.png)

其实又有意义，所以让我们做一些可爱的事情，然后我。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_38.png)

在这里完成，我只向您展示几个数字。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_40.png)

因此，我们选择其中两个，例如，我们选择三个和八个。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_42.png)

因此，我们选择其中两个，例如，我们选择三个和八个，让我在这里告诉你，所以我们现在想找到一个插值，让我在这里告诉你，所以我们现在想找到一个插值。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_44.png)

在五个到四个之间，这是我的五个重建的，而我们的四个，在五个到四个之间，这是我的五个重建的，而我们的四个，如果我在潜空间中执行线性插值，如果我在潜空间中执行线性插值，然后将其发送到解码器，我们得到这个。

所以五个变成四个。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_46.png)

然后将其发送到解码器，我们得到这个，所以五个变成四个，您可以看到的很慢，但是看起来像废话，让我们尝试获得一些，您可以看到的很慢，但是看起来像废话，让我们尝试获得一些，保持在流形上。

所以让我们举例说明这三个，这将是，保持在流形上，所以让我们举例说明这三个，这将是。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_48.png)

第一，然后让我们说这14，第一，然后让我们说这14，所以我在这里对这些家伙进行插值，您实际上可以看到我的输出编码器，所以我在这里对这些家伙进行插值，您实际上可以看到我的输出编码器，在这里解决了这类问题。

然后您现在可以看到三个人如何解决这些问题。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_50.png)

在这里解决了这类问题，然后您现在可以看到三个人如何解决这些问题，小边缘闭合，看起来像是八个右，所以它们看起来都像，小边缘闭合，看起来像是八个右，所以它们看起来都像，合法的不，这只是三三三三成为。

合法的不，这只是三三三三成为，右八，所以您可以通过潜入空间了解现在，右八，所以您可以通过潜入空间了解现在，可以重建输入空间中看起来合法的东西，可以重建输入空间中看起来合法的东西。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_52.png)

永远不会使用普通的输出编码器，最后我要向您展示，永远不会使用普通的输出编码器，最后我要向您展示，很少能很好地表示这列火车的嵌入方式，很少能很好地表示这列火车的嵌入方式，编码器。

所以在这里我只向您展示您知道的嵌入的集合，编码器，所以在这里我只向您展示您知道的嵌入的集合，测试数据集，然后执行类似降维的操作，然后，测试数据集，然后执行类似降维的操作，然后。

我将向您展示编码器如何将所有均值聚类在，我将向您展示编码器如何将所有均值聚类在。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_54.png)

礼顿空间，这是训练此变化笔记时得到的。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_56.png)

礼顿空间，这是训练此变化笔记时得到的，编码器，因此这是不训练网络的开始，编码器，因此这是不训练网络的开始，您仍然可以看到您知道数字簇，但是当您继续训练时，您仍然可以看到您知道数字簇，但是当您继续训练时。

好吧，至少你知道五本书之后，就得到了这些小组，好吧，至少你知道五本书之后，就得到了这些小组，分开，然后我想如果您继续训练，您应该会喜欢更多，分开，然后我想如果您继续训练，您应该会喜欢更多，分离好吧。

所以这里我基本上是在做测试部分，我得到了所有，分离好吧，所以这里我基本上是在做测试部分，我得到了所有。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_58.png)

意味着我的模型输出X hat mu和lock var right，所以我追加了我的意思，意味着我的模型输出X hat mu和lock var right，所以我追加了我的意思，他们我将所有新闻附加到此。

至少我将所有日志栏附加在此，他们我将所有新闻附加到此，至少我将所有日志栏附加在此，锁定条列表，并且在测试期间我将所有Y附加到这些标签列表中，锁定条列表，并且在测试期间我将所有Y附加到这些标签列表中。

部分正确，所以这是测试，所以我在这里有一个代码列表，部分正确，所以这是测试，所以我在这里有一个代码列表，我有MU日志栏，然后有设备，因此稍后在这里，我有MU日志栏，然后有设备，因此稍后在这里。

将这些列表放在我的字典中，然后在下面的下面计算一个。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_60.png)

将这些列表放在我的字典中，然后在下面的下面计算一个。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_62.png)

时代0，时代5和时代10的降维，所以我用这个，时代0，时代5和时代10的降维，所以我用这个。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_64.png)

TST是一种用于减少代码尺寸的技术，TST是一种用于减少代码尺寸的技术，现在20的尺寸高度是20，所以我适合我得到X，让我们，现在20的尺寸高度是20，所以我适合我得到X，让我们，先说前一千个成分。

然后是平均值的一千个样本，然后我，先说前一千个成分，然后是平均值的一千个样本，然后我，得到这些YZ基本上是这二十个二维投影，得到这些YZ基本上是这二十个二维投影。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_66.png)

维喵，好吧，然后我在此图表中向您展示这些二维，维喵，好吧，然后我在此图表中向您展示这些二维。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_68.png)

投影他们在训练网络之前会先看一个0框，因为这个是，投影他们在训练网络之前会先看一个0框，因为这个是，在第一个培训纪元之前，然后当我预订五个书时，您会看到，在第一个培训纪元之前，然后当我预订五个书时。

您会看到，网络让所有这些混乱都变成了现实，您可以将它更好地放在这里，网络让所有这些混乱都变成了现实，您可以将它更好地放在这里，没有想像出差异，我在想是否可以，没有想像出差异，我在想是否可以，也不确定。

因此这些点中的每一个都代表了，也不确定，因此这些点中的每一个都代表了，在编码器上训练变化后的平均值，在编码器上训练变化后的平均值，我没有代表这些方法实际上可以采取的措施。

我没有代表这些方法实际上可以采取的措施，这意味着应该在X 0处是随机的，随机性在编码器中，这意味着应该在X 0处是随机的，随机性在编码器中，但随后您仍然要向编码器和这些输入数字输入，因此输入。

但随后您仍然要向编码器和这些输入数字输入，因此输入，所有的数字都是相似的权利，所以如果您执行随机，所有的数字都是相似的权利，所以如果您执行随机，那些看起来相似的初始向量的变换。

那些看起来相似的初始向量的变换，您将拥有外观类似的转换版本，但随后，您将拥有外观类似的转换版本，但随后，例如，不一定像大多数人一样将它们组合在一起，例如，不一定像大多数人一样将它们组合在一起。

假设这些曾经让我打开颜色栏，所以我们可以看到，假设这些曾经让我打开颜色栏，所以我们可以看到，东西这么说，这些是零，东西这么说，这些是零，在这里，所以所有的零看起来都一样，因此即使是随机的，在这里。

所以所有的零看起来都一样，因此即使是随机的，这些零的投影将全部组合在一起，您可以看到，这些零的投影将全部组合在一起，您可以看到，而是紫色会散布在右边，所以这意味着力量，而是紫色会散布在右边。

所以这意味着力量，是的，有很多绘画方法，因为您知道有人正确，是的，有很多绘画方法，因为您知道有人正确。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_70.png)

如果您看到的是右侧，则最接近顶部的人不会如此，如果您看到的是右侧，则最接近顶部的人不会如此。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_72.png)

四肢几乎都在这里，接下来只有一小群，四肢几乎都在这里，接下来只有一小群，到九，因为你可以考虑如果你写四，到九，因为你可以考虑如果你写四，像这样，写九个权利非常相似，所以你有这种力量，像这样。

写九个权利非常相似，所以你有这种力量，在这里与九点非常接近，只是因为人们如何绘制，在这里与九点非常接近，只是因为人们如何绘制，特种部队还可以，但是他们仍然聚集在这里，特种部队还可以。

但是他们仍然聚集在这里。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_74.png)

所有这些东西四处散布，所以这很不好，所有这些东西四处散布，所以这很不好，但是他们告诉你，这个图在这里告诉你那里，但是他们告诉你，这个图在这里告诉你那里，整个图的零偏差很小，所以它向您显示。

整个图的零偏差很小，所以它向您显示，就像某种方式有一种特定的模式，它在这里非常集中，但是，就像某种方式有一种特定的模式，它在这里非常集中，但是，这些家伙真的不专心，所以我很好奇。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_76.png)

这些家伙真的不专心，所以我很好奇，其他一些类似动机或变式自动编码器的用法。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_78.png)

其他一些类似动机或变式自动编码器的用法。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_80.png)

就像这样，重点是两周前我在课堂上给你看的时候。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_82.png)

就像这样，重点是两周前我在课堂上给你看的时候，生成模型，您无法拥有经典大声的生成模型。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_84.png)

生成模型，您无法拥有经典大声的生成模型，编码器在这种情况下，我再次在这里训练，如果您，编码器在这种情况下，我再次在这里训练，如果您。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_86.png)

训练更长的时间，您可以在这里获得更好的表现，关键是，训练更长的时间，您可以在这里获得更好的表现，关键是。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_88.png)

我的输入来自这种随机分布，然后，我的输入来自这种随机分布，然后，向此随机数发送一个来自正常的随机数，向此随机数发送一个来自正常的随机数，分发，您在此解码器内部发送了一个，分发。

您在此解码器内部发送了一个，如果这是一个编码器，实际上是一个强大的功能，如果这是一个编码器，实际上是一个强大的功能，解码器，那么这些东西实际上会画出非常漂亮的形状或数字，例如。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_90.png)

解码器，那么这些东西实际上会画出非常漂亮的形状或数字，例如。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_92.png)

例如，这两张图片我向您展示了第一部分中的两个阶段，例如，这两张图片我向您展示了第一部分中的两个阶段，上课的时候，这些仅仅是你从我的随机数中取一个数字，上课的时候，这些仅仅是你从我的随机数中取一个数字。

您将其分配给解码器，解码器将被绘制，您将其分配给解码器，解码器将被绘制，你这幅非常漂亮的图画，无论你训练什么，都可以解码，你这幅非常漂亮的图画，无论你训练什么，都可以解码。

并且您不能使用标准输出编码器来获得此类属性，并且您不能使用标准输出编码器来获得此类属性，因为这里我们再次强制解码器重构有意义的，因为这里我们再次强制解码器重构有意义的，当从这个正态分布中取样时。

它们看起来很漂亮，当从这个正态分布中取样时，它们看起来很漂亮，因此，稍后我们可以从该正态分布中提取样本，因此，稍后我们可以从该正态分布中提取样本，解码器和解码器将生成看起来合法的东西。

解码器和解码器将生成看起来合法的东西，对，如果您没有训练解码器来执行良好的重建，对，如果您没有训练解码器来执行良好的重建，当您从这个正态分布中采样时，您将无法，当您从这个正态分布中采样时，您将无法。

实际上得到了有意义的东西，好了，这是下一次大收获，实际上得到了有意义的东西，好了，这是下一次大收获，我们将普遍看到有关蜂窝网络的一般信息，我们将普遍看到有关蜂窝网络的一般信息。

以及它们如何与我们今天看到的这些东西非常相似，以及它们如何与我们今天看到的这些东西非常相似。

![](img/7ece520824f8709ad0f0a8a4bf5c91c7_94.png)

Alfred哦，我有一个关于黄色气泡黄色的问题，是的，Alfred哦，我有一个关于黄色气泡黄色的问题，是的，每个黄色气泡都来自一个输入示例，是的，所以如果我们有1000个，我就不会。

每个黄色气泡都来自一个输入示例，是的，所以如果我们有1000个，我就不会，知道什么图像或一个想法安培意味着我们有1000个完全黄色，知道什么图像或一个想法安培意味着我们有1000个完全黄色，是的。

气泡和EGL气泡来自easy。we Z，是的，气泡和EGL气泡来自easy。we Z，分布以及添加到潜变量的噪声，因此气泡，分布以及添加到潜变量的噪声，因此气泡，来自这里，让我告诉你，如果我告诉你。

这个还好吗？来自这里，让我告诉你，如果我告诉你，这个还好吗？说好，所以在这里您得到这些X，这些X进入模型内部，说好，所以在这里您得到这些X，这些X进入模型内部，每当您通过模型发送这些X时。

它就会向内前进，因此X会，每当您通过模型发送这些X时，它就会向内前进，因此X会，在这里，然后进入编码器内部，然后从，在这里，然后进入编码器内部，然后从，给我这个moola季度。

我可以从中提取Mew和log栏，所以，给我这个moola季度，我可以从中提取Mew和log栏，所以，到目前为止，一切都像普通的编码器一样，到目前为止，一切都像普通的编码器一样，气泡来了。

所以我的Z现在来自这些自我修复的尝试，气泡来了，所以我的Z现在来自这些自我修复的尝试，如果我们处于自我修复状态，那么参数化将以不同的方式工作，如果我们处于自我修复状态，那么参数化将以不同的方式工作。

训练循环或我们不在训练循环中，因此，如果我们不在，训练循环或我们不在训练循环中，因此，如果我们不在，受训者循环，我只是返回了分钟数，所以当我使用，受训者循环，我只是返回了分钟数，所以当我使用。

再次测试零件，以便我获得编码器可以给我的最佳价值，再次测试零件，以便我获得编码器可以给我的最佳价值，培训相反会发生什么，所以我计算标准，培训相反会发生什么，所以我计算标准，偏离此日志栏。

所以我得到的日志栏除以二，然后取，偏离此日志栏，所以我得到的日志栏除以二，然后取，指数权，所以我有e到一半的木柴射击，这样您就可以得到，指数权，所以我有e到一半的木柴射击，这样您就可以得到。

知道标准偏差，然后知道ε就可以简单地是一个D，知道标准偏差，然后知道ε就可以简单地是一个D，正态分布的维向量样本，所以这是一个，正态分布的维向量样本，所以这是一个，来自此正态分布和正态分布的样本。

来自此正态分布和正态分布的样本，你知道它像一个D维的球体，对，你知道它像一个D维的球体，对，半径将是D的平方根，然后在末尾，半径将是D的平方根，然后在末尾，您只是简单地调整大小，重点是每次您呼叫时。

您只是简单地调整大小，重点是每次您呼叫时，非常参数化参数是函数，我可以得到不同的结果，非常参数化参数是函数，我可以得到不同的结果，epsilon因为epsilon是从正态分布采样的，所以。

epsilon因为epsilon是从正态分布采样的，所以，给一个亩，给一个日志栏，你将每次都变得与众不同，给一个亩，给一个日志栏，你将每次都变得与众不同，Epsilon的，因此这些东西在这里。

如果您称它为一百倍，Epsilon的，因此这些东西在这里，如果您称它为一百倍，会给你100个不同的点，它们都聚集在亩，半径为，会给你100个不同的点，它们都聚集在亩，半径为，您大致知道标准差。

所以这是返回您的直线，您大致知道标准差，所以这是返回您的直线，每次只有一个样本，但是如果在for循环中调用它，您将得到，每次只有一个样本，但是如果在for循环中调用它，您将得到，你知道一个点云。

它们都以亩为中心，你知道一个点云，它们都以亩为中心，半径还可以，所以这就是我们从采样中获得这些气泡的地方，半径还可以，所以这就是我们从采样中获得这些气泡的地方，这些东西对，如果您要100个样本。

我必须运行100次，这些东西对，如果您要100个样本，我必须运行100次，得到100倍，您必须遇到100倍，这些是参数化给出的，得到100倍，您必须遇到100倍，这些是参数化给出的。

您每次都知道一个不同的点，您每次都知道一个不同的点，位置，这类人知道数量，是的，这来自，位置，这类人知道数量，是的，这来自，亚当·你和玛丽·方差来自一个样本一个输入例子。

亚当·你和玛丽·方差来自一个样本一个输入例子，是的，所以我的一个输入X在这里给了我一亩，给了我一个负载棒，是的，所以我的一个输入X在这里给了我一亩，给了我一个负载棒，这个一亩好一本原木三月给我Z。

这是整体的一个样本，这个一亩好一本原木三月给我Z，这是整体的一个样本，分布，如果您在此处运行此功能1，000次，您将获得1，000次，分布，如果您在此处运行此功能1，000次，您将获得1，000次。

Z所有人都将立即取走这个音量，知道了，Z所有人都将立即取走这个音量，知道了，谢谢你，我当然喜欢自动编码器，谢谢你，我当然喜欢自动编码器，视线编码器和解码器总体来说是这样。

视线编码器和解码器总体来说是这样，实施，这在其中相当简单，实施，这在其中相当简单，像它这样的术语就像一对线性层一样，像它这样的术语就像一对线性层一样，乙状结肠最像我以前喜欢的样子，在CODIS中。

乙状结肠最像我以前喜欢的样子，在CODIS中，他们就像他的注意力一样，这是某种东西，他们就像他的注意力一样，这是某种东西，像这样基本，似乎很令人满意，像这样基本，似乎很令人满意，好吧。

他们通常是这个基本或更复杂的吗，我认为，好吧，他们通常是这个基本或更复杂的吗，我认为，垒球对我来说，所以我们在课堂上看到的一切都是我尝试过的东西，垒球对我来说。

所以我们在课堂上看到的一切都是我尝试过的东西，足以代表这些东西可以运行，足以代表这些东西可以运行，因此，您知道我正在笔记本电脑上运行MDS数据集，则可以运行以下几种，因此。

您知道我正在笔记本电脑上运行MDS数据集，则可以运行以下几种，这种测试和播放，所以今天我们已经看到了如何编码，这种测试和播放，所以今天我们已经看到了如何编码，您将其编码为彩色，而您所需的只是三个。

您将其编码为彩色，而您所需的只是三个，一行四行代码，就像之间有什么区别，一行四行代码，就像之间有什么区别，播放山峰代码数组，所以区别在于您需要谴责，播放山峰代码数组，所以区别在于您需要谴责，关于修复。

参数化表示Mitra是模块，关于修复，参数化表示Mitra是模块，方法，然后您就知道这三行了，所以您有了，方法，然后您就知道这三行了，所以您有了，像六行加上相对熵完全是，像六行加上相对熵完全是，不同。

所以它是完全正交的对，一件事会在，不同，所以它是完全正交的对，一件事会在，基于当前输入的架构，您可以使用，基于当前输入的架构，您可以使用，卷积网络，您可以使用循环网络，您可以使用任何网络，卷积网络。

您可以使用循环网络，您可以使用任何网络，想要而另一件事是您转换了确定性的事实，想要而另一件事是您转换了确定性的事实，网络到一个网络中，该网络使您可以采样，然后从，网络到一个网络中，该网络使您可以采样。

然后从，发行版还可以，所以我们从来不需要谈论发行版，发行版还可以，所以我们从来不需要谈论发行版，现在不知道如何用生成模型生成分布，现在不知道如何用生成模型生成分布，您实际上可以生成基本上是。

您实际上可以生成基本上是，用原始高斯弯曲旋转或变换任何东西，用原始高斯弯曲旋转或变换任何东西，对，所以我们有了这个多元高斯，然后解码器接受了这个，对，所以我们有了这个多元高斯，然后解码器接受了这个，球。

然后将其成形以使其看起来像输入，输入可能像，球，然后将其成形以使其看起来像输入，输入可能像，弯曲的东西，你在这里有这个气泡这个很大的气泡，然后，弯曲的东西，你在这里有这个气泡这个很大的气泡，然后。

您将解码器恢复到输入看起来像什么的样子，您将解码器恢复到输入看起来像什么的样子，您需要的全部取决于用于M的特定数据，这是，您需要的全部取决于用于M的特定数据，这是，如果您使用我们的卷积版本就足够了。

也许值得，如果您使用我们的卷积版本就足够了，也许值得，工作得更好，关键是该课程是关于变分编码器的，工作得更好，关键是该课程是关于变分编码器的，知道如何得到疯狂的东西，所有疯狂的东西只是你知道添加。

知道如何得到疯狂的东西，所有疯狂的东西只是你知道添加，到目前为止，我一直在教你这些事情，但是关于，到目前为止，我一直在教你这些事情，但是关于，编码器的变化，我认为这里大部分都涵盖了，编码器的变化。

我认为这里大部分都涵盖了，问题否好的好的，非常感谢您加入我们，问题否好的好的，非常感谢您加入我们，好吧，每个人都差不多离开了70％下周见，好吧，好吧。



![](img/7ece520824f8709ad0f0a8a4bf5c91c7_96.png)