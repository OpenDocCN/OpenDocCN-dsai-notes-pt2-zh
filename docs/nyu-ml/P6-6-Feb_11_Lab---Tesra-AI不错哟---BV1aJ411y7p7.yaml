- en: P6：6.Feb_11_Lab - Tesra-AI不错哟 - BV1aJ411y7p7
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P6：6.Feb_11_Lab - Tesra-AI不错哟 - BV1aJ411y7p7
- en: What kind？
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 什么样的分离器？
- en: '![](img/1bb554aeb454f73babd719beab314227_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1bb554aeb454f73babd719beab314227_1.png)'
- en: '![](img/1bb554aeb454f73babd719beab314227_2.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1bb554aeb454f73babd719beab314227_2.png)'
- en: Abstract stuff。 Where do that come from？ Yeah。 All those equations。 The objective
    function。 Yeah。 but， you know， did you start？ So the goal of this class is going
    to be building up that support vector mission objective function from scratch。
    From the very beginning。 So that at the end of it， if you didn't， you know。 if
    you don't remember in a loss function， you'll be able to just start devising the
    problem itself。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象的东西。那些是从哪里来的？是的。所有那些方程式。目标函数。是的。但你知道，你开始了吗？所以这门课的目标将是从零开始构建支持向量机的目标函数。从一开始就构建。这样，到最后，如果你忘记了，知道，损失函数是什么，你也能开始自己解决问题。
- en: And by that step， I think you'll be able to come up with the loss function by
    yourself。 So what's the main problem？ Why do we need things like support vector
    mission？ Margin？ For what？
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到了这个步骤，我认为你自己就能设计出损失函数了。那么，主要的问题是什么？为什么我们需要像支持向量机这样的东西？边距呢？为了什么？
- en: Optimization。 Optimization for what purpose？ Classification。 Classification。
    When they classify things， we have a bunch of points in the cloud scattered。 When
    they classify them。 So we want to find a separator。 We find a separator that actually
    gives us a good result。 What do we actually want from a separator？
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 优化。优化是为了什么目的？分类。分类。当他们进行分类时，我们有一堆散布在云中的点。然后他们对这些点进行分类。所以我们想找到一个分离器。我们找到了一个实际能给我们带来好结果的分离器。那我们实际需要从分离器中得到什么呢？
- en: What is a good separator？ Because you can have plenty of things that separate
    two different classes or multiple classes as well。 What quantifies a good separator？
    Loss function。 Loss function is just the measure of a cost。 You want to decrease
    it because you want to pay a little cost。 But you can come up with loss functions
    that give you low cost。 Nevertheless。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是一个好的分离器？因为你可以有很多东西来分离两个不同的类别或多个类别。那么，如何量化一个好的分离器呢？损失函数。损失函数就是衡量成本的标准。你想减少它，因为你想付出更少的代价。但你可以设计出一些损失函数，让你付出低代价。然而，
- en: it might be performing bad when it comes to clarifying points。 [inaudible]。
    So you could do statistical comparison if you have input to no。 Okay， that's an
    idea。 Another idea？
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 它在清晰化点时可能表现不佳。[听不清]。所以，如果你有输入，可以做统计比较。好的，这是一个想法。还有其他的想法吗？
- en: Yes。 Yes， you can find a decision boundary。 If the data is separable。 which
    means that their convex halls are not going to intersect。 What's a convex hall？
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。是的，你可以找到一个决策边界。如果数据是可分的。这意味着它们的凸包不会相交。什么是凸包？
- en: The smallest convex body that contains all the data points that I have。 If those
    don't intersect。 that means I can find a hyperplane that separates the two data
    points。 That separates the clusters。 That's going to be my decision boundary。
    Beyond that boundary。 I'm going to assign class A and about the boundary， I'm
    going to assign class B。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 包含所有数据点的最小凸体。如果这些凸体没有相交。这意味着我可以找到一个超平面，分离这两个数据点。分离这些簇。那将是我的决策边界。超出那个边界，我将分配类别A，边界附近，我将分配类别B。
- en: That will be the perfect separation。 If the data is linear separable， that's
    what I want。 In most cases， it won't be linear separable。 But still， that seems
    like it's a good starting point。 So if we have。 Okay， let's see an example。 That's
    a linear separable data。 The convex hall。 do not intersect。 The convex hall of
    this goes from this boundary up here。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是完美的分离。如果数据是线性可分的，那就是我想要的。大多数情况下，它不会是线性可分的。但即便如此，这似乎是一个很好的起点。所以如果我们有数据。好了，让我们来看一个例子。这是一个线性可分的数据。它的凸包不相交。这个凸包从这个边界一直延伸到这里。
- en: And this one has a circle like this。 It seems like the blue cluster has a bunch
    of outliers。 Nevertheless， it's convex hall is still not intersecting。 so I can
    find the decision boundary that perfectly separates those points。 There is plenty
    of such boundaries。 Which one am I going to choose？
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据有一个像这样的圆。看起来蓝色簇中有一些离群点。尽管如此，它的凸包仍然没有相交。所以我可以找到一个完美分离这些点的决策边界。有很多这样的边界。我该选择哪个呢？
- en: Which one seems like a better candidate？ That one doesn't look hard。 This one？
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个看起来是更好的候选者？这个看起来不难。那这个呢？
- en: That one doesn't look too margin。 So what's margin？ You defined it in previous
    class。 Y times F of X。 So what's Y and what's F and what's X？ So margin is Y times
    F of X。 Y is what？
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那个看起来不太像边际。那么，什么是边际呢？你在上节课定义了它。Y 乘以 F 的 X。那么 Y 和 F 和 X 是什么呢？所以边际是 Y 乘以 F 的 X。Y
    是什么？
- en: The actual output。 What values does it take？ Minus one or one。 That's all assumptions。
    All of these things we just make up。 So margin is also something that we defined。
    Now of course we want to define margin as the distance between the two convex
    bodies。 So if I have a cluster like this， the convex body is going to。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的输出。它取什么值？-1 或 1。这些都是假设。我们刚才讲的所有这些都是我们自己定义的。所以边际也是我们定义的。现在，当然我们想定义边际为两个凸包之间的距离。如果我有一个像这样的聚类，那么凸包将会。
- en: the smallest convex body will have this shape。 And for another body。 another
    set of data points is going to be like this。 So we want to find the minimum distance
    between the two and call it the margin。 Y is F of X is the outcome of our particular
    specific formulation。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最小的凸包将具有这种形状。对于另一个体，另一组数据点将是这样的。所以我们想找到它们之间的最小距离，并称之为边际。Y 是 F 的 X，这是我们特定公式的结果。
- en: We designed the problem in such a way that the margin becomes Y times F of X。
    And here X is not an arbitrary point。 X is the point that's closest to the decision
    boundary that I pick。 In the end， after the optimization that's what you will
    find。 And then the midpoint， why midpoint？
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计问题的方式是让边际变成 Y 乘以 F 的 X。这里的 X 不是一个任意点。X 是我选择的距离决策边界最近的点。最后，在优化之后，这就是你会发现的。而且为什么是中点呢？
- en: Because if you move a little further， you're not going to be maximizing the
    boundary。 You have smaller distance to class A than to class B。 And if you move
    into the other direction。 you have smaller distance to class B than class A。 So
    midpoint seems like the intuitively the one that maximizes the margin between
    two clusters。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 因为如果你稍微再移动一点，你就不会在最大化边界了。你离 A 类的距离小于离 B 类的距离。如果你向另一个方向移动，你离 B 类的距离就小于离 A 类的距离。所以中点似乎是直观上最大化两个聚类之间边际的那个点。
- en: It doesn't have to be midpoint if you have more than two clusters。 So how does
    it happen that margin becomes Y times F of X after our design？ Before going that。
    let's start with a hyperplane is how do you represent a hyperplane？ How do you
    represent a line？
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有多个聚类，它不必是中点。那么，在我们的设计之后，为什么边际会变成 Y 乘以 F 的 X？在讨论这个之前，我们先从一个超平面开始，你如何表示一个超平面？你如何表示一条直线？
- en: A line is just a simple precalculus equation。 Y is equal to M times X plus B。
    M is the slope。 And B is the intersection。 The Y-axis intersection。 In a little
    more linear algebraic terms。 we can rewrite this in this matrix model。 In this
    vector dot product。 And we want to generalize this。 So instead of working with
    M and minus one all the time。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一条直线只是一个简单的预备微积分方程。Y 等于 M 乘以 X 加 B。M 是斜率，B 是交点，即 Y 轴交点。用稍微更线性代数的术语，我们可以将其重写为矩阵模型中的这种形式。通过这种向量点积的方式。我们想要将其推广。因此，我们不必一直使用
    M 和 -1。
- en: which seems to be the standard formula precalculus。 we want to write vectors
    in terms of its components。 So those vectors seem to be in R2。 So we'd say W1，
    W2 instead of M and minus one。 And their connection is pretty trivial to calculate。
    But we're writing it in this form。 It allows us to understand what a hyperplane
    is。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎是标准的预备微积分公式。我们想把向量表示成它的分量。因此这些向量看起来是在 R2 空间里。所以我们会说 W1，W2，而不是 M 和 -1。它们的关系非常简单可以计算。但我们以这种形式书写，它使我们能够理解什么是超平面。
- en: So you can generalize it from this equation W1， W2 dot X1， X2。 Take it up to
    N。 Let's say we have vectors in Rn。 Then the equation becomes W dot X plus B。
    And then the hyperplane becomes the level set of this function。 This function
    is just a function that takes a point from a domain and assigns a value to it。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以从这个方程 W1，W2 点乘 X1，X2 推广到 N。假设我们有 Rn 中的向量。那么这个方程就变成了 W 点乘 X 加 B。然后超平面就变成了这个函数的水平集。这个函数只是一个将领域中的一个点映射到一个值的函数。
- en: Remember in the previous one， the rational case， the line was described by a
    little set of function。 namely the function on the right hand side， when that's
    equal to zero。 So all the set of all X's that makes the function on the left hand
    high zero， describes us a line。 similarly the set of all X's that makes our dot
    product plus B zero， describes a hyperplane。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 记住在前面的例子中，理性情况，直线是由一组函数描述的。即右侧的函数，当它等于零时。所有使左侧函数等于零的 X 的集合描述了我们的一条直线。类似地，所有使我们的点积加
    B 等于零的 X 的集合描述了一个超平面。
- en: There are pretty analogous concepts。 The equation is pretty simple to generalize。
    And then what other things do we have？ That V seems to have a special property。
    namely that V in this L of X equals to V dot X plus B is orthogonal to L。 What
    does that mean？
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概念是相当类似的。方程式是非常简单的可以推广的。然后我们还有什么其他东西？这个V似乎有一个特殊的性质。即V在这个L中的X等于V点X加B，它是正交于L的。这意味着什么？
- en: What does orthogonal mean？ Perpendicular？ Perpendicular to what？ Yeah。 So in
    the usual case。 if I have a line here， the V vector is going to be something like
    this。 That's going to be perpendicular to it。 It's going to be perpendicular to
    any V vector I take from L。 But it's a little special because this example passes
    through the origin。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正交是什么意思？垂直？垂直于什么？是的。通常的情况是，如果我这里有一条直线，V向量大概会是这样的。这将是与之垂直的。它将垂直于我从L中选取的任何V向量。但这个例子有点特别，因为它通过了原点。
- en: If it's shifted a little bit， if I have a line that doesn't pass through the
    origin。 what am I going to do？ If I take a vector here， this vector， let's say。
    this is an orthogonal vector V。 And I take a vector on this V prime。 Are they
    orthogonal to each other？ This vector on that vector？ No， they are not。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它稍微偏移了一点，如果我有一条不经过原点的直线，我该怎么做？如果我在这里取一个向量，这个向量，假设是。 这是一个正交向量V。我再取这个V'上的一个向量。它们彼此正交吗？这个向量与那个向量？不，它们不是。
- en: Even though the point was chosen from the line， so it's not enough to choose
    a point from the line。 the vector that I choose should be -- should live in the
    line。 So I have to choose two points。 V and V prime， and subtract them so that
    I get a vector that's aligned with the line。 And then this vector will be orthogonal
    to V。 In the computation。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这个点是从这条线选择的，但仅仅选择一个点是不够的。我选择的向量应该是——应该存在于这条线中。所以我必须选择两个点，V和V'，并相减以得到一个与线对齐的向量。然后这个向量将在计算中与V正交。
- en: that seems to be one of the common trips。 In this picture， it seems clear。 But
    when the computation is a little more attached to it， in higher dimensions。 it
    can be a little more counterintuitive because you have -- you say you're in R3，
    you hit a plane。 And you shift that plane by a little bit。 You mistakenly take
    a point on the plane thinking that that vector lies on it。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎是常见的陷阱之一。在这个图中，看起来很清楚。但当计算稍微复杂一点，特别是在更高维度时，它可能会变得有点反直觉，因为你说你在R3中，遇到了一个平面。然后你把这个平面稍微移动了一下。你错误地在平面上选择了一个点，认为那个向量就位于平面上。
- en: It actually is a point in that， but it's not a vector that lives in it。 It actually
    stands from zero and goes there。 So the whole vector。 if you think of it as the
    line segment， it's outside of that plane。 Then the dot product is not zero， so
    it has to live on there。 That's what orthogonal to me is。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 它实际上是那个点，但它不是一个存在于其中的向量。它实际上是从零点开始并延伸到那里。所以整个向量，如果你把它当作线段来看，它就在那个平面之外。然后点积不为零，所以它必须存在于那里。这就是我所理解的正交。
- en: It's going to be a previous property。 Then since it's a linear function and
    it's described by the zero set。 it's going to assign two different numbers to
    the cluster A here and to the cluster B here。 Or in this notation to the cluster
    C1 and to the cluster C2。 And since it's a linear function。 I can always rescale
    things。 I can always multiply and divide things by numbers as much as I like。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一个先前的性质。然后因为它是一个线性函数，并且由零集描述，它将给这里的集群A和这里的集群B分配两个不同的数字。或者用这个符号，给集群C1和集群C2分配不同的数字。由于它是一个线性函数，我总是可以对它进行重缩放。我总是可以根据需要随意乘除。
- en: So what values do I want L to assign in different clusters？ In this slide。 the
    blue and red comes from this example。 So I just made the dot and said let's assign
    positive values to blue ones and negative values to red ones。 And it's possible
    that this arbitrary I could have chosen the other way around。 Is it possible for
    L to assign the zero value for enough of those points？
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我希望L在不同集群中分配什么值呢？在这一张幻灯片中，蓝色和红色来自这个例子。所以我只是点了一个点，并说让我们给蓝色的分配正值，给红色的分配负值。并且有可能我可以任意选择顺序反过来。L是否有可能为这些点中的足够多的点分配零值？
- en: When does L assign the value zero to the data points？ When it's on the line。
    when the data point is on the line。 So that says like a perfect separation that's
    possible。 that's doable。 And typically I want invariant， the loss function is
    positive。 So I want something that doesn't change with respect to the sign。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 什么时候 L 会给数据点分配零值？当它在这条线上时。当数据点在这条线上的时候。所以这就意味着一个完美的分离是可能的，是可以实现的。通常，我希望不变的，损失函数是正的。所以我希望某些东西在符号上不会改变。
- en: So if I assign the value negative font to the red group and positive font to
    the blue group。 then by looking at the product yi times L of xi will always give
    me a positive value。 Right？ Yes？
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我给红色组分配负值，给蓝色组分配正值，那么通过查看 yi 乘以 L(xi)，它将始终给我一个正值。对吧？是吗？
- en: '[inaudible]， You can use vectors too。 That seems to be the， so for example
    in amnestic character。 handwritten digit classification， you use vectors， ten
    vectors in Rn。 But the numbers are restricted to zero and month outputs and they
    represent the probabilities of the guesses。 So a simple output is like 98% 0。98
    on zero if the input image is zero and it is trained out。'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[听不清]，你也可以使用向量。这似乎是，比如在失忆字符识别中，手写数字分类，你使用的是向量，十个在 Rn 中的向量。但数字被限制为零和月份输出，它们代表猜测的概率。所以一个简单的输出就像是98%
    0。如果输入图像是零，那么它被训练出来了。'
- en: And the rest of the nine entries sum up to 0。02% just making it up to one， sum
    up to one。 Yes？
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的九个条目加起来是 0.02%，只是随便编的，总和为 1。对吧？
- en: '[inaudible]， Yes， I can move B as much as I want， right？ That''s going to be
    part。 that''s going to be a great question。 It''s going to be part of optimization
    process。 So the arbitrary things that I''m going to fix now are going to be the
    things that are flexible。 And the rest of the parameters will be tuned by the
    optimization method itself。'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[听不清]，是的，我可以随意移动 B，对吧？这将是一个部分。那将是一个很好的问题。这将是优化过程的一部分。所以我现在要固定的任意参数，将是灵活的参数。而其余的参数将通过优化方法本身来调节。'
- en: Training will handle that。 So if I know that there's a perfectly linear separable
    data。 then I can find a hyperplane that separates the two。 That hyperplane can
    be described by the little set of a function of a linear function of the sort
    that's described。 And once I have that， y times L of x， which is the same thing
    as L is F here， y times F of x。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 训练将处理这一点。所以如果我知道数据是完全线性可分的，那么我可以找到一个超平面来分开这两个类。这个超平面可以用一个线性函数的集合来描述，正如之前所描述的那样。一旦我有了这个，y
    乘以 L(x)，这与 L = F 在这里是相同的，y 乘以 F(x)。
- en: margin is going to be always positive。 And then I will maximize the margin。
    So the points that are closest to the line， they are going to matter， right？
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 边际将始终是正的。然后我将最大化边际。所以最接近这条线的点，它们会很重要，对吧？
- en: So when you speak about a point close to a line， then we need to talk about
    the distance of a point to a line。 How do you find the distance of a point to
    a line？ Yes？ Yes。 Right， you take the projection。 And you take the projection
    onto what？ Onto the。 Onto the。 When you take the projection onto the line， not
    doing it。 What's this vvector here？ One thing。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当你谈论一个点靠近一条线时，我们需要讨论一个点到这条线的距离。你怎么找到一个点到一条线的距离？是吗？对。对，你取投影。那么你把投影投射到哪里？投射到…
    投射到… 当你把投影投射到这条线上时，为什么不这么做呢？这个向量是什么？有一个东西。
- en: one everything crosses zero， it's easy to calculate。 But one there shifted。
    Say this is zero。 This is the line。 And this is any point given to you。 Let's
    say you know the equation of the line。 which is L of x， which is the value that
    x plus b is zero。 How do you find the projection？
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当一切交叉零时，计算很容易。但当它发生偏移时，假设这是零。这是线。这是给定的任何一点。假设你知道线的方程式，即 L(x)，即 x 加 b 为零。你如何找到投影？
- en: Any guesses？ Let's say I took an arbitrary point on the line。 X prime。 Taking
    x as a vector is not going to work out because that cues me this vector。 This
    doesn't seem to be aligning with anything。 It's like it has not much value。 So
    if I take a point on the line， what I can do is to construct this vector。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有什么猜测吗？假设我取了线上的一个任意点，X'。将 x 作为向量取是不行的，因为那会给我这个向量。这似乎与任何东西都不对齐。就像它没有太多的价值。所以如果我取了线上一个点，我能做的是构建这个向量。
- en: But that was an arbitrary point。 Of course， I can pick any point I like。 So
    this。 the length of this vector will not give me the distance。 How can I find
    the distance of x to L？
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但那是一个任意的点。当然，我可以选择任何我喜欢的点。那么这个向量的长度不会给我距离。那么如何找到 x 到 L 的距离呢？
- en: Yeah。 So one that's orthogonal to it。 This v vector。 So if I take this vector
    and project it onto the w vector， then I'll get the distance desired。 Any other
    questions？ Yes？ Yeah， you could do that。 This way is the robust way to do it。
    It's in coolant。 Sandring things is if you sand through it。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: you'd pretty much pick your point zero and move everything here and pick your
    point zero。 by taking the x vector。 So then they're just in coolant procedures。
    Which one？
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: The capital L or small L？ The small L is the function。 When that function is
    equal to zero。 I get the hyperplane。 But this L is just a function， a linear function
    from R to R。 The zero set of the function describes it with a hyperplane。 But
    since it's defined on the whole of R^n， it assigns all sorts of values。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: But what I know is that since it's a linear function， beyond and above the hyperplane。
    it has different signs。 That's how I was able to separate the points here。 The
    hyperplane was assigning zero values when there is， when the hyperplane。 the values
    of the function are zero。 On the red cluster。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: the values of the function is negative numbers。 On the blue region。 the values
    of the L function is positive numbers。 And since I appropriately chose to classify。
    the red one is negative。 Negative ones。 And the blue one is positive ones。 By
    design。 by that particular choice， by times LI was always positive once I have
    a hyperplane that perfectly separates the data。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Is it clear？ What's a hyperplane and what's the function？
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: The function is just a linear function that's defined on the lower far end。
    And the zero set of which is the hyperplane。 Yes。 [ Inaudible ]， What can we prove？
    Oh， yes。 So far we started with the assumption that we have a separable data。
    And we'll go on to see how we can modify if we don't have a separable data。 Okay。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: With the projection， let's move on to the SBI。 So again。 let's label our data
    that comes in two clusters。 Let's say one of them is C1， then we see two。 And
    as usual， we have the hyperplane that separates the two clusters。 Let's put a
    constraint on the norm of V， which we can do because it's linear。 We can scale
    things。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: And suppose， as mentioned here and previously， suppose I pick the points that
    are nearest to the given line。 to the given hyperplane， and then I calculate the
    distance of those points to the hyperplane。 So those points， of course the distance，
    it can also be calculated by YI， L times XI。 For all points， when I calculate
    YI， L times L of AI。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: that's going to be always larger than the value of the minimum distance of the
    nearest two points。 And this is one reason that when you find the hyperplane that
    maximizes the margin。 it's going to be in the middle of the two points that are
    closest to each other。 Let's call that this as M， once it's in the middle。 So
    this distance is M。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: and this distance will be M2。 The total distance is going to be 2M。 Then we
    can rewrite the procedure of maximizing the margin。 M is defined above with the
    only constraint that norm of V is going to be 1。 So the W parameter is called
    strength-on-disphere。 That's subject to the following condition。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个距离将是M2。总的距离将是2M。然后我们可以重写最大化间隔的过程。M在上面定义，唯一的约束是V的范数将是1。所以W参数被称为球面上的强度。它受以下条件的限制。
- en: YI times the value of the function L once evaluated on the data points is going
    to be larger than M。 Why is it going to be larger than M？ Because it's going to
    be larger than margin at all times because margin is defined as the minimum such
    distance。 So the thing I want to maximize， this distance， so this distance， so
    once I hit the hyperplane。 this distance is going to be M。 And this is when I
    have YI times L of Xi， when Xi is this point。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Yi乘以函数L的值，评估在数据点上的结果将大于M。为什么它会大于M？因为它将始终大于间隔，因为间隔定义为最小的这种距离。所以我要最大化的东西，就是这个距离。所以一旦我碰到超平面，这个距离将是M。这就是当我有Yi乘以L的Xi时，Xi是这个点的情况。
- en: So if I take any other point， it's going to give me a larger number。 That's
    the natural constraint that I counted。 For any other point in this cluster。 YI
    times L of Xi is going to be larger。 So this will be lower bound。 this will be
    my second constraint。 If this is clear。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我取任何其他点，它会给我一个更大的数值。这就是我计算出来的自然约束。对于这个聚类中的任何其他点，Yi乘以L的Xi将会更大。所以这将是下界。这将是我的第二个约束。如果这一点清楚的话。
- en: then the next steps will be just reformulations of this。 So far， we start with
    that assumption。 If they are not separable， then we'll modify the procedure according
    to that assumption。 Yes？
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤将是对这个过程的重新表述。到目前为止，我们从这个假设开始。如果它们不可分，那么我们将根据这个假设修改程序。是吗？
- en: What if we have power-flighter observations in place？ Yes。 that will change
    the lines that will change the cost。 But we have no ones now in the days that
    we have。 Now even if we have outliers in the data。 we assume that we start with
    the perfect separable data。 So very soon in two steps。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有功率飞行器的观测数据会怎样？是的。这将改变线条，也会改变成本。但在目前的数据中我们没有这种情况。即使我们在数据中有异常值，我们仍然假设从完美可分的数据开始。所以很快，经过两步操作。
- en: if we have outliers that actually crosses the boundary， we will allow that。
    We will give some room for this。 For the outliers that actually cross the boundary。
    They are not here at this moment， but they will be very soon。 Yes？
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有越界的异常值，我们会允许这种情况。我们会为此留出一些空间。对于那些确实越过边界的异常值，虽然它们目前不在这里，但它们很快就会出现。是吗？
- en: Is there a meaning to calculate the lower bound we want？ Because it's a linear
    function。 I could scale it as much as I want。 So it's a natural assumption to
    restrict your class of functions。 No， my key is the yi。 The root of the xi will
    be like half of the yi。 Because this is what the L function assigns。 And the observation
    was that if I have a perfect separable data。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 计算我们想要的下界有意义吗？因为这是一个线性函数。我可以根据需要缩放它。所以限制函数类是一个自然的假设。不，我的关键是yi。xi的根将像yi的一半。这就是L函数所赋予的值。观察结果是，如果我有一个完美可分的数据。
- en: yi times L of xi at the data point is going to always have the same sign。 So
    if I drop this yi from here， then I don't have this sign definiteness。 I might
    get negative points as negative values as well， which I don't want。 That function
    is related with the distance of the time difference？ Yes。 So let's keep that in
    mind。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据点上，yi乘以xi的L值将始终保持相同的符号。所以如果我从这里去掉这个yi，那么就没有了这个符号的确定性。我可能会得到负值，这我不希望看到。这个函数与时间差的距离有关？是的。所以让我们记住这一点。
- en: this procedure， and let's modify it。 So if I have any payoff， then we can be。
    So I want to pass from putting a constraint on the。 So I want to pass from putting
    a。 so I want to pass this problem with the constraint on v to maximizing n to
    an equivalent problem of minimum value。 Of minimizing v， releasing that norm 1
    constraint and minimizing v。 How can I make that shift？
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程，让我们修改它。所以如果我有任何收益，那么我们就可以继续。所以我想从给v加约束开始。然后我想从加约束开始。接着我想把这个带约束的问题转换成最大化n的等价问题，转化为最小化v，放松这个范数为1的约束并最小化v。我该如何做这个转换？
- en: I'll use the same reason as I could put the constraint on norm of v， which is
    linear scalability。 Then that will turn things around from a maximization。 a large
    maximization problem to norm-inimization problem。 A norm-inposition problem comes
    from this little tiny trick。 If I take any point w_b。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用与我能够对 v 的范数施加约束的相同理由，这就是线性可扩展性。然后，这将使问题从一个最大化问题转变为一个范数最小化问题。范数最小化问题源自这个小小的技巧。如果我取任何点
    w_b。
- en: then of course I can calculate n。 Then I rescale w_m_g by dividing both of them
    by n。 What happens then， if I plug the new pair， w_prime and v_prime into the
    equation， instead of here。 I divide everything by m， divide by m， this is divided
    by m。 So this inequality will be greater than 1， instead of greater than m。 And
    since in this equation。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后当然我可以计算 n。然后我通过将 w_m_g 除以 n 来重新调整比例。那时会发生什么，如果我将新的成对值 w_prime 和 v_prime 代入方程，而不是这里。我将每个部分都除以
    m，除以 m，这个除以 m。所以这个不等式将大于 1，而不是大于 m。因为在这个方程中。
- en: the norm of w is constrained to 1， maximizing n in the sense translates into
    minimizing v_prime。 Any questions so far？ By just scaling things， scaling the
    w_m_g variables。 I was able to change the problem from this equation 1 and 2 to
    equations 3 and 4。 This is a simple minus step。 Now here， if your observations
    are in order， norm of w_prime。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: w 的范数被限制为 1，最大化 n 从而转化为最小化 v_prime。到目前为止有任何问题吗？通过仅仅对事物进行缩放，缩放 w_m_g 变量。我能够将问题从方程
    1 和 2 改变为方程 3 和 4。这是一个简单的减法步骤。现在这里，如果你的观察顺序正确，w_prime 的范数。
- en: which is going to be our new w， is 1/m。 That's why the maximization problem
    turns into an maximization problem。 Your margin maximization problem turns into
    a norm-inization problem。 The problem is convex。 in quadratic。 And now we'll go
    to the question of the clusters being overlapped。 What happens if we have overlapping
    clusters？ So what will happen is that we will allow some room for each point to
    cross the margin。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们新的 w 将是 1/m。这就是最大化问题为什么会变成一个最大化问题的原因。你的边际最大化问题变成了范数最小化问题。这个问题是凸的。在二次方程中。现在我们将讨论聚类重叠的问题。如果我们有重叠的聚类，会发生什么？所以会发生的情况是，我们将为每个点提供一些空间，让它穿越边界。
- en: Previously we had the clusters， but we didn't allow。 it was a hard restriction。
    it was a hard constraint， that there were going to be at least an distance away
    from the hyperplane that separates them。 So what we had was。 This wide border
    was clear of any points。 Now we'll allow some of them to be sneak through。 So
    if something from the cluster one sneak through here。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们有了聚类，但我们不允许。那是一个严格的限制。那是一个严格的约束，要求它们至少要有一定的距离远离分隔它们的超平面。所以我们当时有的是。这个宽边界是清除任何点的。现在我们允许其中一些点偷偷通过。所以如果聚类一的某个点偷偷通过这里。
- en: how much it will sneak through？ It will have sneak through this amount of。 You
    know， this much。 And let's call this much。 If this is the point i， this distance
    will be ti。 For each data point we will allow how much that point is allowed to
    sneak through。 And that allowance， that little room for each point， will be called
    by ti。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 它会偷偷通过多少？它将偷偷通过这么多。你知道，就是这么多。我们就称这个为这么多。如果这是点 i，这个距离将是 ti。对于每个数据点，我们会允许这个点可以偷偷通过多少。而这个允许的空间，每个点的小余地，将称为
    ti。
- en: They're called slack variables。 We don't want it to be too much。 Otherwise our
    prediction is going to be too off。 But we'll allow the little room for them to
    fall through。 So how can we modify the first formulation using the slack variables？
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 它们被称为松弛变量。我们不希望它们过多。否则我们的预测将偏差太大。但我们会允许它们有一点空间突破。所以我们怎样用松弛变量修改第一个公式？
- en: Remember the first formulation？ Let's keep equation five as it is。 The first
    one。 you don't have to put any ti's in it now。 But the second one， equation six。
    we can represent it as eight by introducing the slack variables。 So instead of
    that function。 that product being constrained from below by m， it's going to be
    constrained from below by m times one minus ti。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 记得第一个公式吗？我们保持方程五不变。第一个。现在你不需要在其中加入任何 ti 了。但第二个，方程六。通过引入松弛变量，我们可以将其表示为八。所以，而不是将那个函数。那个乘积被从下方限制在
    m，我们将它从下方限制在 m 乘以 1 减去 ti。
- en: So that from the original problem， ti in this case is not an additive distance。
    but it's a multiplicative room。 We could have done both。 So just like we did here
    in this setting。 we modified the problem from， bonding things from below by m
    and having a maximization problem。 Remember we changed the maximization problem
    to a minimization problem。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以从原始问题来看，ti在这种情况下不是一个加性距离，而是一个乘法空间。我们本可以做两者的结合。所以就像我们在这个设置中做的那样，我们将问题从下界的m进行了修改，变成了一个最大化问题。记住，我们把最大化问题改为了最小化问题。
- en: Let's do the same thing here。 With the new equation， new equation of overlapping
    clusters。 So once we do the same procedure of finding the equivalent formization
    in terms of norm minimization。 and allugulcly to the previous case， we get the
    ones in the middle。 the modified equivalent procedure。 As you can observe。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里做相同的事情。使用新的方程，重叠聚类的新的方程。因此，一旦我们执行相同的程序，寻找等价的形式化，基于范数最小化，并且与之前的案例类似，我们得到中间的那个，修改后的等价过程。如你所观察到的。
- en: the equations nine and eleven remain the same。 But in the rescaled one。 equation
    ten and twelve are modified from equation ten to allow an additive ti。 room for
    variables to sneak into the margin。 [inaudible]， Yes。 So here。 the nearest point
    had the value m， y i times l of x i。 So for all other data points。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 方程九和方程十一保持不变。但是在重新缩放后的版本中，方程十和方程十二从方程十修改过来，允许添加一个ti，给变量留出空间，以便它们进入边界。[听不清]，是的。
    所以在这里，最近的点的值是m，y i 乘以 x i 的 l 值。所以对于所有其他数据点。
- en: I had this value to be larger than m。 But I want to shrink this value。 I want
    to allow points to have some room。 So instead of them being larger than m。 if
    I multiply with a constant that's less than one， then I actually shrink the margin。
    So the margin maximization problem is the first line。 That remains there。 That's
    the same。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个值大于m。但我想缩小这个值。我希望允许点有一些空间。所以如果它们不再大于m，如果我乘以一个小于1的常数，那么我实际上是在缩小边界。所以边界最大化问题是第一行。它仍然保持不变。就是这样。
- en: The constraint I put on the data points is in the second line。 That's why I
    keep the margin maximization problem the same。 So the margin is still at the same
    place。 The margin borders are still at the same place。 But slightly modifying
    the second equation， I allow some variables to come through。 By how much。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我对数据点施加的约束在第二行。这就是为什么我保持边界最大化问题不变。所以边界仍然在同一个位置。边界的边界仍然在同一个位置。但稍微修改第二个方程，我允许一些变量通过。通过多少？
- en: instead of being larger than m， I allow them to be as close to the line as m
    times one minus ti。 Yes。 Yeah， in this case， no， because it's just a multiplicative
    factor。 So just a second。 Good question。 So what happens if ti is larger than
    one？ If ti is larger than one。 I allow this to be a little negative， but not too
    negative。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 不是大于m，我允许它们尽可能接近直线，接近m乘以一减去ti。是的。对，这种情况下，不， 因为它只是一个乘法因子。稍等一下。很好的问题。那么，如果ti大于一会发生什么？如果ti大于一，我允许它稍微负一点，但不会太负。
- en: So it can actually cross to the other side。 Yes， true。 Yeah。 I think there's
    no optical ti to be less than one。 So it can be more than one。 We can allow clusters
    to pass through the other side。 Yeah， great question。 Any other questions？
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它实际上可以越过另一侧。是的，确实。对，我认为没有规定ti必须小于一。所以它可以大于一。我们可以允许聚类穿过另一边。是的，太好了，问题。还有其他问题吗？
- en: Yes。 [ Inaudible ]， This allows them to be to lie within the margin。 [ Inaudible
    ]。 Too far away from the region？ [ Inaudible ]， I'm not sure I'm perfect to understand
    the question。 but if the data points are on the other extreme， then that's not
    an issue because they are already separate。 So the outliers in the other part
    don't bother me because I'm worried about the boundary between the two。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。[听不清]，这允许它们位于边界内。[听不清]。离区域太远了？[听不清]，我不确定我完全理解这个问题，但如果数据点在另一端，那不是问题，因为它们已经被分开。所以另一部分的异常值不干扰我，因为我关心的是这两个区域之间的边界。
- en: If that answers your question。 Okay。 So now， the overlapping clusters we modified
    procedure。 So equations 11 and 12 are the final versions of the modified problem。
    That is what we obtain after rescaling。 So we modify from margin matzimization
    to norm minimization。 And we change the second constraint so that we allow little
    room for points to sneak。 Okay。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果那回答了你的问题。好的。那么现在，重叠聚类我们修改后的过程。方程11和方程12是修改问题的最终版本。这是我们在重新缩放后得到的。所以我们从边界最大化修改为范数最小化。我们改变了第二个约束，以允许一些空间供数据点进入。好的。
- en: that's so far so good。 But note that since I rescale the W's to W' here in this
    equation 11 and 12。 I don't have to keep using that W' and B' they are just like
    in other points。 I can go back to the original notation of W's and B's。 I can
    forget about M that's in the background。 One side and a subtle bit equations 11
    and 12。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止一切都好。但请注意，由于在方程式 11 和 12 中我将 W 缩放为 W'，所以我不必一直使用 W' 和 B'，它们和其他地方的符号一样。我可以回到原始的
    W 和 B 符号。我可以忽略背景中的 M，方程 11 和 12 的一边和细微部分。
- en: And then I can， I don't want to allow too much of them to go through the other
    side or go B in the margin。 Or the cross， the barrier that they are not supposed
    to cross。 So the constraint I'll introduce is a constraint that bonds the sum
    of those slack variables。 So some of TI is going to be less than C。 That seems
    like another reasonable constraint to put。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我可以，不想让太多点穿越另一侧，或者进入边际外面。或者穿越它们不应该穿越的界限。所以我要引入的约束条件是限制那些松弛变量的和。因此 TI 的和应该小于
    C。这似乎是另一个合理的约束条件。
- en: And I could put the norm minimization problem in combination with the sum of
    slack variables is less than some constant problem。 into one equation to one compact
    form that is introduced in equation 13。 So that optimization。 so minimizing that
    problem one half norm W squared plus C times sum of slack variables will take
    care of。 So I can minimize the norm that I want and it's going to bound the sum
    of the slack variables。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以将范数最小化问题与松弛变量和小于常数的约束问题结合起来，放入一个方程式中，形成方程式 13 中引入的紧凑形式。因此，优化问题。最小化这个问题，即一半的范数
    W 平方加上 C 倍松弛变量和，将会解决。这样我就可以最小化我想要的范数，同时它会限制松弛变量的和。
- en: And the equation 14 is the same as equation 12 except the W's and B's the primes
    are removed。 And of course here in equation 13 we still have W in Rn and， TI's
    are real numbers。 So let's see how this looks like a picture。 We started with
    the subrable case。 This is the first picture on the left。 This picture is taken
    from this book and the notation is just slightly different。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式 14 与方程式 12 相同，除了 W 和 B 的撇号被去掉。当然，在方程式 13 中，我们仍然有 W 在 Rn 中，TI 是实数。所以让我们看看这看起来像什么图。我们从可分情况开始。这是左边的第一张图。这张图取自这本书，符号稍微有些不同。
- en: So there's a reference I wrote here that the beta is going to be the values
    that I've used all along。 So beta not is the B's。 So beta not is the shift and
    W is the norm。 the parameters that we want to minimize。 That whose norm we want
    to minimize。 So if you start with the separable case。 Remember beta was the W's
    and norm of W was 1 over M which is represent the theory as well。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个我写的参考，beta 将是我一直使用的值。所以 beta_0 是 B。beta_0 是平移量，W 是范数。我们想要最小化的参数，那个我们希望最小化范数的参数。所以如果你从可分情况开始。记住，beta
    是 W 的值，W 的范数是 1/M，这在理论中也是如此。
- en: So that seems like a correct transformation that we did。 And the margin is the
    two lines that are equally distant from the hyperplane that we found that separates
    the data completely。 In the first case we don't allow any points to be in the
    margin or to。 But we want them to touch at the border of the margin。 That's because
    of the maximal principle。 Yes？
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这似乎是我们所做的正确转换。边际是两个距离我们找到的完全分隔数据的超平面等距离的直线。在第一个情况下，我们不允许任何点位于边际中。但我们希望它们在边际的边界上触碰。那是因为最大化原则。是吗？
- en: '[ Inaudible ]， Here？ So here in this example it wants to have this point， this
    green point。 There are two green points that touching on the line。 So that kind
    of fixes one line。 If you didn''t have that point， how are we going to take one？'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[听不清]，这里？所以在这个例子中，它希望拥有这个点，这个绿色的点。有两个绿色的点触及到这条线。这就固定了一条线。如果没有那个点，我们要怎么选择呢？'
- en: So in what cases you can have multiple lines that are equally that give you
    equal margin。 It doesn't seem super likely that you'll get equal margin。 You can
    have that。 you can have scenarios in which you have equal margin with different
    lines。 So we need another case。 So in this case the problem is convex so it has
    a unique minimize。 If it has a unique minimize it。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在什么情况下你可以有多条线，它们给你相等的边际？似乎不太可能出现完全相等的边际。但确实可以有这种情况，出现不同的线条却有相等的边际。所以我们需要考虑另一种情况。在这种情况下，问题是凸的，因此有一个唯一的最小值。如果它有一个唯一的最小值的话。
- en: that means you'll actually find a single hyperplane that separates the two parts。
    There is not much room for you to have multiple results of the same optimization
    problem。 There will be cases in which the optimization process will be non-convex。
    And you'll find sort of equivalent results。 Maybe not exactly the same but the
    optimization procedure will give you two。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你实际上会找到一个单一的超平面，将这两个部分分开。你没有太多空间去获得同一优化问题的多个结果。会有一些情况，优化过程会是非凸的，你会得到一些等效的结果。也许不是完全相同，但优化过程会给你两个。
- en: three different hyperplains。 In this case it's going to be a convex but a decision
    boundary is the same。 In this case you don't usually find all of them。 You find
    one of them and you say okay that's fine。 In the non-convex case。 But in this
    case there is one solution actually。 Yes？ Number ten。 Nine and ten。 Nine and ten
    is the same thing。 Nine and ten is just a copy of three and four。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 三个不同的超平面。在这种情况下，它将是一个凸的，但决策边界是相同的。在这种情况下，你通常不会找到所有的。你找到其中一个，然后说，好吧，这就行了。在非凸的情况下。但在这种情况下，实际上有一个解决方案。是吗？第十项。九和十。九和十是一样的。九和十只是三和四的副本。
- en: Three and four is just the rescaling of one and two。 Behind which one？ Three
    and four。 So how are you going to construct the right to tell and start an optimization
    procedure？
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 三和四只是对一和二的重缩放。后者是哪一个？三和四。所以你将如何构建右边的目标，并开始一个优化过程？
- en: It seems a little easier and more convenient from a computational point of view
    to minimize the norm rather than maximize the margin。 Or the point of all of the
    other points。 And then you can find the deviation of one and two and one and two。
    And just to quantify the deviation。 So that's a good question。 Simple algebraic
    transformation that we did from one and two to three and four。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算的角度来看，最小化范数比最大化边界更简单、更方便。或者说，所有其他点的一个点。然后你可以找到一个和两个之间的偏差。仅仅量化这个偏差。这是个很好的问题。我们从1和2到3和4的简单代数变换。
- en: And that simple algebraic modification pretty easily solves the problem。 I'll
    think about it。 I think TI is presented only to negative learning that we either
    underline a lot of the。 technical instances。 Yes？ So they should be dead。 We didn't
    say TI is negative。 If you said can TI be larger than one？ Oh。 If TI is larger
    than one than the y times function that's going to have some negative value。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的代数修改很容易解决这个问题。我会考虑一下。我认为TI只适用于负学习，我们通常会强调一些技术实例。是吗？所以它们应该是无效的。我们并没有说TI是负的。如果你问TI能不能大于1？哦。如果TI大于1，那么y倍的函数就会有一些负值。
- en: So that means in this example， for example， look at C5。 C5 is like TI and that
    has more than。 in this case， it's M。 In the scale version it's going to be more
    than one。 Yes？
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这个例子中，举个例子，看看C5。C5就像TI，并且它比M大。在这个尺度版本中，它将大于1。是吗？
- en: So how much should we see how less theoretical and not to be more than having
    a bigger margin？ Yeah。 So you don't want to control all the margins one by one
    but you want to control some of them。 And a lot of them， they are some to be too
    much。 Which is captured here in the second term of 30。 So I'd like to call options
    between these two。 Yeah。 So if you constrain the sum of them。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们应该怎么看，如何降低理论性而不超过较大的边界？是的。所以你不想一一控制所有的边界，而是想控制其中一些。而且很多情况下，它们会过大。这一点在30的第二项中得到了体现。所以我想在这两者之间进行选择。是的。所以如果你限制它们的总和。
- en: not a single of them can be too much。 Yes？ So we defined them as like a set
    based on the separability。 So that I'm confused like the meaning of them once
    you get into a non-submarine equation。 Good question。 Is it data separable？ So
    you set up the problem， you set up normalization problem。 It's as if the data
    is separable。 But once you get in love some of them to have this T way。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 其中没有任何一个可以过大。是吗？所以我们根据可分性定义它们的集合。让我困惑的是，一旦你进入一个非潜水方程，它们的意义是什么。好问题。数据是可分的吗？所以你设置了这个问题，设置了归一化问题。就好像数据是可分的。但一旦你让一些数据有这个T方式。
- en: it works out the same。 So that's why the picture is the same here。 It's as if
    the margin is there for the separable case， the wide band。 But then the extra
    slack variables is introduced allow them to come in。 So the equation 13 here is
    like margin maximization converted into a norm minimization。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 它的结果是相同的。所以这就是为什么这里的图像是一样的。就像边界存在于可分情况中，宽带。但引入额外的松弛变量允许它们进入。所以这里的方程13就像是将边界最大化转换为范数最小化。
- en: But it has the additional benefit of allowing some of the points to sync in。
    Okay。 I have a few further problems。 If you have some time， please try to think
    about them。 Feel free to come to office hours from ask which discussions。 Thank
    you。 [BLANK_AUDIO]。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 但它还有一个额外的好处，就是可以帮助某些要点得到更好的理解。好吧，我还有一些进一步的问题。如果你有时间，请考虑一下这些问题。如果有任何疑问，欢迎来办公时间咨询讨论。谢谢。[BLANK_AUDIO]。
- en: '![](img/1bb554aeb454f73babd719beab314227_4.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1bb554aeb454f73babd719beab314227_4.png)'
- en: '![](img/1bb554aeb454f73babd719beab314227_5.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1bb554aeb454f73babd719beab314227_5.png)'
