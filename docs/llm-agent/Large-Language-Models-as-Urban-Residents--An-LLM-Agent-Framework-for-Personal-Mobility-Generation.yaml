- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:51:39'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Large Language Models as Urban Residents: An LLM Agent Framework for Personal
    Mobility Generation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14744](https://ar5iv.labs.arxiv.org/html/2402.14744)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Jiawei Wang¹    Renhe Jiang¹ Corresponding author.    Chuang Yang¹    Zengqing
    Wu²    Makoto Onizuka²    Ryosuke Shibasaki¹    Chuan Xiao² ¹The University of
    Tokyo, ²Osaka University
  prefs: []
  type: TYPE_NORMAL
- en: jiawei@g.ecc.u-tokyo.ac.jp, jiangrh@csis.u-tokyo.ac.jp, chuang.yang@csis.u-tokyo.ac.jp,
    wuzengqing@outlook.com, onizuka@ist.osaka-u.ac.jp, shiba@csis.u-tokyo.ac.jp, chuanx@ist.osaka-u.ac.jp
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This paper introduces a novel approach using Large Language Models (LLMs) integrated
    into an agent framework for flexible and efficient personal mobility generation.
    LLMs overcome the limitations of previous models by efficiently processing semantic
    data and offering versatility in modeling various tasks. Our approach addresses
    the critical need to align LLMs with real-world urban mobility data, focusing
    on three research questions: aligning LLMs with rich activity data, developing
    reliable activity generation strategies, and exploring LLM applications in urban
    mobility. The key technical contribution is a novel LLM agent framework that accounts
    for individual activity patterns and motivations, including a self-consistency
    approach to align LLMs with real-world activity data and a retrieval-augmented
    strategy for interpretable activity generation. In experimental studies, comprehensive
    validation is performed using real-world data. This research marks the pioneering
    work of designing an LLM agent framework for activity generation based on real-world
    human activity data, offering a promising tool for urban mobility analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Under the 2030 Sustainable Development Agenda, the United Nations emphasizes
    the crucial role of sustainable cities and human settlements. The study of personal
    mobility like individual activity trajectory can provide valuable semantic insights
    into urban mobility and support this objective. Specifically, modeling personal
    mobility opens up numerous applications for building a sustainable community,
    including proactive traffic management and the design of comprehensive urban development
    strategies Batty et al. ([2012](#bib.bib4)); Batty ([2013](#bib.bib5)); Zheng
    ([2015](#bib.bib38)). In particular, generating reliable activity trajectories
    can be a promising and efficient way to exploit individual activity data. On one
    hand, learning to generate activity trajectory leads to a thorough understanding
    of activity patterns, enabling flexible simulation of urban mobility. On the other
    hand, while individual activity trajectory data is abundant due to advances in
    telecommunications, its practical use is often limited by privacy concerns. In
    this sense, generated data can provide a viable alternative that offers a balance
    between utility and privacy.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c815ba5f537d969863212ef4cee399f9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Personal mobility generation with an LLM agent.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While advanced data-driven learning-based method offer various solutions to
    generate synthetic individual trajectoriesHuang et al. ([2019](#bib.bib13)); Zhang
    et al. ([2020](#bib.bib37)); Feng et al. ([2020](#bib.bib9)); Choi et al. ([2021](#bib.bib7)),
    the generated data only imitates real-world data from the data distribution perspective
    rather than semantics, rendering them less effective in simulating or interpretation
    activities in novel or unforeseen scenarios with a significantly different distribution
    (e.g., a pandemic). Thus, in this study, to explore a more intelligent and efficient
    activity generation, we propose to establish an agent framework by exploiting
    the emerging intelligence of large language models (LLMs), as illustrated by Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Large Language Models as Urban Residents: An LLM
    Agent Framework for Personal Mobility Generation"). LLMs have gained widespread
    usage in furthering our understanding of humans and society in a multitude of
    disciplines, such as political science Argyle et al. ([2023](#bib.bib3)) and economy Aher
    et al. ([2022](#bib.bib1)), and thus have been employed as agents in a variety
    of social simulations Xi et al. ([2023](#bib.bib33)); Wu et al. ([2023](#bib.bib32));
    Gao et al. ([2023](#bib.bib10)). More specifically, LLMs present two significant
    advantages over previous models when applied to activity trajectory generation:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semantic Interpretability. Unlike previous models, which have predominantly
    depended on structured data (e.g., GPS coordinates-based trajectory data) for
    both calibration and simulation Jiang et al. ([2016](#bib.bib14)); Pappalardo
    and Simini ([2018](#bib.bib23)), LLMs exhibit proficiency in interpreting semantic
    data (e.g., activity trajectory data). This advantage significantly broadens the
    scope for incorporating a diverse array of data sources into generation processes,
    thereby enhancing the models’ ability to understand and interact with complex,
    real-world scenarios in a more nuanced and effective manner.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model Versatility. Although other data-driven methods manage to learn such dynamic
    activity patterns for generation, their capacity is limited for generation under
    unseen scenarios. On the contrary, LLMs have shown remarkable versatility in dealing
    with unseen tasks, especially the ability to reason and decide based on available
    information OpenAI ([2022](#bib.bib22)). This competence enables LLMs to offer
    a diverse and rational array of choices, making it a promising and flexible approach
    for modeling personal mobility patterns.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Despite these benefits, ensuring that LLM aligns effectively with real-world
    situations continues to be a significant challenge Xi et al. ([2023](#bib.bib33)).
    This alignment is particularly crucial in the context of urban mobility, where
    the precision and dependability of LLM outputs are essential for the efficacy
    of any urban management derived from them. In this study, our aim is to address
    this challenge by investigating the following research questions: RQ 1: How can
    LLM be effectively aligned with semantically rich data about daily individual
    activities? RQ 2: What are the effective strategies for achieving reliable and
    meaningful activity generation using LLM? RQ 3: What are the potential applications
    of LLM in enhancing urban mobility?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our methodology revolves around two phases: (1) self-consistent activity pattern
    identification and (2) motivation-driven activity generation. In Phase 1, we extract
    and evaluate activity patterns from historical data and semantic analysis, using
    LLM agents to generate diverse and personalized activity scenarios. This process
    involves identifying habitual activity patterns, which are key factors influencing
    individual mobility. In Phase 2, we develop two interpretable retrieval-augmented
    strategies, along with the patterns identified in Phase 1, to instruct LLM agents
    to work out summarized motivations, such as evolving interests or situational
    needs. The patterns and motivations faciliate the agents to generate daily activity
    trajectories. The generation benefits from the LLM’s capability to process extensive
    datasets and semantic richness, allowing for a nuanced simulation of personal
    mobility with considerations for habitual behaviors, situational motivations,
    and temporal dynamics.'
  prefs: []
  type: TYPE_NORMAL
- en: We evaluate the proposed framework using GPT-3.5 APIs over a personal activity
    trajectory dataset of Tokyo. The results demonstrate the capability of our framework
    to align LLM agents with semantically rich data for generating individual daily
    activities, highlighting that our framework excels in temporal aspects of personal
    mobility generation, with spatial-temporal metrics showing its strength in capturing
    the essence of daily routines over mere location accuracy. The comparison with
    baselines like Markov models, LSTM, and DeepMove Feng et al. ([2018](#bib.bib8)),
    underscores the advanced generative performance of our framework. Moreover, the
    application of the framework in simulating urban mobility under specific contexts,
    such as the pandemic scenario, reveals its potential to adapt to external factors
    and generate realistic activity patterns.
  prefs: []
  type: TYPE_NORMAL
- en: '*To the best of our knowledge, this study is one of the pioneering works in
    developing an LLM agent framework for generating activity trajectory based on
    real-world data.* We summarize our contributions as follows: (1) We introduce
    a novel LLM agent framework for urban mobility generation featuring semantic richness.
    (2) Our framework introduces a self-consistency evaluation to ensure that the
    output of the LLM aligns closely with real-world data on daily activities. (3)
    To generate daily activity trajectories, our framework integrates activity patterns
    with summarized motivations, with two interpretable retrieval-augmented strategies
    aimed at producing reliable activity trajectories. (4) By using real-world personal
    activity data, we validate the effectiveness of our framework and explore its
    utility in urban mobility analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 Personal Mobility Generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Activity trajectory generation offers a valuable perspective for understanding
    urban mobility. Benefiting from the advanced communication technologies, recent
    research can explore urban mobility from massive geotagged data. Based on vast
    call detailed records, [Jiang et al.](#bib.bib14) Jiang et al. ([2016](#bib.bib14))
    built a mechanistic modeling framework to generate individual activities in high
    spatial-temporal resolutions, but it is limited to three activity types: work,
    home, and others. [Pappalardo and Simini](#bib.bib23) Pappalardo and Simini ([2018](#bib.bib23))
    enhanced the Exploration and Preferential Return (EPR) model for activity generation,
    which employs Markov modeling to estimate the probability of individuals visiting
    specific locations. Besides, deep learning has become a robust tool for modeling
    the complex dynamics of traffic  Liu et al. ([2018](#bib.bib16)); Huang et al.
    ([2019](#bib.bib13)); Zhang et al. ([2020](#bib.bib37)); Feng et al. ([2020](#bib.bib9));
    Choi et al. ([2021](#bib.bib7)); Luca et al. ([2021](#bib.bib18)). The primary
    challenge involves overcoming data-related obstacles such as randomness, sparsity,
    and irregular patterns Feng et al. ([2018](#bib.bib8)); Yuan et al. ([2023](#bib.bib36),
    [2022](#bib.bib35)); Long et al. ([2023](#bib.bib17)). For example, [Feng et al.](#bib.bib8) Feng
    et al. ([2018](#bib.bib8)) proposed attentional recurrent networks to handle personal
    preference and transition regularities. [Yuan et al.](#bib.bib35) Yuan et al.
    ([2022](#bib.bib35)) leveraged deep learning combined with neural differential
    equations to address the challenges of randomness and sparsity inherent in irregularly
    sampled activities for activity trajectory generation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d45db9d7b1d1498f3262b29321eb2b3e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Illustration of LLMob, the proposed LLM agent framework for personal
    Mobility generation.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 LLM Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How to take advantage of LLMs for real-world tasks has become an attractive
    research topic since the LLMs present human-like intelligence. While some studies Wei
    et al. ([2022](#bib.bib29)); Wang et al. ([2022](#bib.bib27)) focus on exploiting
    their linguistic capabilities, exploring how to treat LLM as autonomous agents
    in specific scenarios can lead to more diverse and promising applications Wang
    et al. ([2023](#bib.bib28)); Xi et al. ([2023](#bib.bib33)); Wu et al. ([2023](#bib.bib32));
    Gao et al. ([2023](#bib.bib10)), hence to address the issues of reliance on parameter
    settings and lack of adaptability in traditional agent-based simulations using
    rules or reinforcement learning Grimm et al. ([2005](#bib.bib11)); Henrich et
    al. ([2010](#bib.bib12)); Ale Ebrahim Dehkordi et al. ([2023](#bib.bib2)). For
    instance, [Park et al.](#bib.bib24) Park et al. ([2023](#bib.bib24)) first established
    an LLM-powered agent framework to simulate human behavior in an interactive scenario.
    This innovative approach demonstrates the potential of LLM to model complex social
    interactions and decision-making processes. Extending beyond the realm of social
    sciences, [Mao et al.](#bib.bib19) Mao et al. ([2023](#bib.bib19)) have adeptly
    utilized LLM to generate driving trajectories in motion planning tasks. In the
    field of natural sciences, [Williams et al.](#bib.bib31) Williams et al. ([2023](#bib.bib31))
    have innovatively integrated LLM with epidemic models to simulate the spread of
    diseases. Furthermore, in financial research, the application of LLM in macroeconomic
    modeling has been explored, providing new insights into financial markets and
    economies Li et al. ([2023](#bib.bib15)). These varied applications highlight
    the versatility and potential of LLM to understand and model various real-world
    dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Problem Description
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We study the generation of individual daily activity trajectories, each representing
    an individual’s activities for the whole day. We focus on the urban context, where
    the activities of each individual are represented as a time-ordered sequence of
    location choices (e.g., location-based activity) Luca et al. ([2021](#bib.bib18)).
    This sequence, $\{(l_{0},t_{0}),(l_{1},t_{1}),\ldots,(l_{n},t_{n})\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By modeling individuals within an urban environment as LLM agents, we present
    LLMob, an LLM Agent Framework for Personal Mobility Generation, as illustrated
    in Fig. [2](#S2.F2 "Figure 2 ‣ 2.1 Personal Mobility Generation ‣ 2 Related Work
    ‣ Large Language Models as Urban Residents: An LLM Agent Framework for Personal
    Mobility Generation"). LLMob is based on the assumption that an individual’s activities
    are primarily influenced by two principal factors: habitual activity patterns
    and current motivations. Habitual activity patterns, which reflect typical movement
    behaviors and preferences, signifying regular travel and location choices Song
    et al. ([2010](#bib.bib26)). Motivations pertain to dynamic and situational factors
    that influence an individual’s decisions at any given moment, such as specific
    needs or external influences during a particular time frame. This consideration
    is vital for capturing and forecasting short-term shifts in mobility patterns Aher
    et al. ([2022](#bib.bib1)). Moreover, by formulating prompts that assume specific
    events of concern, this framework allows us to observe the agents’ activities
    and responses in a variety of situations.'
  prefs: []
  type: TYPE_NORMAL
- en: To construct a pipeline for activity trajectory generation, we design LLM agents
    with action, memory, and planning, in line with Weng ([2023](#bib.bib30)); Wang
    et al. ([2023](#bib.bib28)) except that external tools are not involved. Action
    specifies how an agent interacts with the environment and makes decisions. In
    LLMob, the environment contains the information collected from real-world data,
    and the agents act by identifying habitual activity patterns and generating trajectories.
    Memory includes past actions that need to be prompted to the LLM to invoke the
    next action. In LLMob, memory refers to the active patterns output by the agents.
    Planning formulates a plan or reflects over past actions to handle complex tasks.
    In LLMob, planning refers to the generation of summarized motivations, which are
    used to facilitate trajectory generation. Furthermore, we specify personas to
    the agents to simulate the diversity of real-world individuals Salewski et al.
    ([2023](#bib.bib25)).
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Self-Consistent Activity Pattern Identification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Phase 1 of LLMob focuses on identifying activity patterns from historical data.
    We leverage the extracted activity patterns as essential prior knowledge for the
    generation of daily activities. To effectively identify activity patterns from
    historical data, we introduce the following two steps.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.1 Pattern Extraction from Semantics and Historical Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The first step will use LLM to derive activity patterns based on activity trajectory
    data (e.g. individual check-in data). As illustrated in the left panel of Fig. [2](#S2.F2
    "Figure 2 ‣ 2.1 Personal Mobility Generation ‣ 2 Related Work ‣ Large Language
    Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation"),
    this scheme consists of three aspects: For each person, we start by utilizing
    the LLM to create a variety of personas, providing the inspiring foundation for
    subsequent activity pattern generation. This approach also encourages the diversity
    of the generated activity patterns, as each persona acts as a unique prior for
    the generation process (e.g., [Noulas et al.](#bib.bib20) Noulas et al. ([2011](#bib.bib20))
    demonstrated the significance of user clustering from activity trajectory data
    in producing meaningful distinctions). Meanwhile, we perform data preprocessing
    to extract key information from the extensive historical data. This involves identifying
    usual commuting distances, pinpointing typical start and end times and locations
    of daily trips, and concluding the most frequently visited locations of the person.
    It is important to note that these pieces of information are widely recognized
    as critical features in mobility analysis Jiang et al. ([2016](#bib.bib14)). Following
    this, both semantic elements with historical data are combined in the prompts,
    requiring the LLM to summarize the activity patterns for this person. By doing
    this, we set up a streamline to effectively bridge the gap between semantic persona
    characteristics and concrete historical activity trajectory data, which allows
    for a more personalized and interpretable representation of individual activities
    at one day.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.2 Pattern Evaluation with Self-Consistency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As introduced before, for each person, multiple candidate patterns are generated
    according to the persona and historical data. Following this, the subsequent step
    involves assessing the consistency of these generated activity patterns to identify
    the most plausible one. We implement a scoring mechanism to gauge the alignment
    of these patterns with historical data. To achieve this objective, we define a
    scoring function for each candidate pattern $cp$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $score_{cp}=\sum_{t\in\mathcal{T}_{i}}r_{t}-\sum_{t^{\prime}\in\mathcal{T}_{\sim
    i}}r_{t^{\prime}},$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: 'where we design an evaluation prompt to ask the LLM to generate rating scores
    $r_{t}$ for data from other users. This scheme requires self-consistency in the
    pattern: the activity pattern derived from the activity trajectory data should
    be consistent with the data during the evaluation. The algorithm for this step
    is summarized as shown in Alg. [1](#algorithm1 "In 4.1.2 Pattern Evaluation with
    Self-Consistency ‣ 4.1 Self-Consistent Activity Pattern Identification ‣ 4 Methodology
    ‣ Large Language Models as Urban Residents: An LLM Agent Framework for Personal
    Mobility Generation").'
  prefs: []
  type: TYPE_NORMAL
- en: Input : Number of personas $C$
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 Self-Consistent Activity Pattern Identification
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Motivation-Driven Activity Generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In Phase 2 of LLMob, we focus on the retrieval of motivation and the integration
    of motivation and activity patterns for individual activity trajectory generation.
    Retrieval augmentation has been identified as a crucial factor in boosting the
    performance of LLM Xu et al. ([2023](#bib.bib34)). This enhancement provides additional
    information that aids LLM in more effectively responding to queries. While previous
    studies on activity generation mainly overlook the critical factors of macro temporal
    information (i.e., date) or specific scenarios (i.e., hash weather) Yuan et al.
    ([2022](#bib.bib35)), we propose a more sophisticated activity generation which
    accounts for various conditions by taking advantage of the human-like intelligence
    of LLM. For instance, the activity trajectory at date $d$ can be inferred given
    the motivation of this date and the normal activity pattern as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{T}_{d}=LLM(\mathcal{M}otivation,\mathcal{P}attern).$ |  | (2)
    |'
  prefs: []
  type: TYPE_TB
- en: This activity generation scheme instructs the LLM to simulate a designated individual
    according to a given activity pattern, and then meticulously generate an activity
    trajectory in accordance with the daily motivation. To obtain insightful and reliable
    motivations for the generation, two retrieval schemes are proposed.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Evolving-based Motivation Retrieval
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This scheme is related to the intuitive principle that an individual’s motivation
    on any given day is influenced by her interests and priorities in preceding days Park
    et al. ([2023](#bib.bib24)). Guided by this understanding that new motivations
    often evolve from existing ones, our approach harnesses the intelligence of LLM
    to understand the behavior of daily activities and the underlying motivations.
    As illustrated in Fig. [3](#S4.F3 "Figure 3 ‣ 4.2.1 Evolving-based Motivation
    Retrieval ‣ 4.2 Motivation-Driven Activity Generation ‣ 4 Methodology ‣ Large
    Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility
    Generation"), for a specific day $d$ for which we aim to generate the activity
    trajectory, as well as considering the activities of the past few days, we prompt
    the LLM to act as an individual based on the pattern identified in Section [4.1](#S4.SS1
    "4.1 Self-Consistent Activity Pattern Identification ‣ 4 Methodology ‣ Large Language
    Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation")
    and summarize the motivation behind these activities. Leveraging these identified
    past motivations, the LLM is further prompted to infer potential motivations for
    the subsequent day.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9b558d6ff464e27e976a8a19202aff3c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Evolving-based motivation retrieval.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Learning-based Motivation Retrieval
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this scheme, we hypothesize that individuals tend to establish routines
    in their daily activities, guided by consistent motivations even if the specific
    locations may vary. For example, if someone frequently visits a burger shop on
    weekday mornings, this behavior might suggest a motivation for a quick breakfast.
    Based on this, it is plausible to predict that the same individual might choose
    a different fast food restaurant in the future, motivated by a similar desire
    for convenience and speed during their morning meal. We introduce a learning-based
    scheme to retrieve motivation from historical data. For each new date on which
    to plan activities, the only information available is the date itself. To use
    this clue for planning, we first formulate a relative temporal feature $\boldsymbol{z}_{{d_{c},d_{p}}}$
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: 'where $N_{d}$. Intuitively, there should be more shared locations in the similar
    trajectory pair. Thereafter, positive pair is characterized by the highest similarity
    score, indicative of a greater degree of resemblance between the trajectories.
    Conversely, negative pairs are marked by low similarity scores, reflecting a lesser
    degree of commonality. After obtaining the training dataset from these positive
    and negative pairs, we can train a model to approximate the similarity score between
    any two dates through contrastive learning. Specifically, the procedure involves
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each date $d$.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Forward the positive and negative pairs to $f_{\theta}(\cdot)$ to form:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\text{logits}=\left[f_{\theta}(\boldsymbol{z}_{d,d^{+}}),f_{\theta}(\boldsymbol{z}_{d,d^{-}_{1}}),...,f_{\theta}(\boldsymbol{z}_{d,d^{-}_{k}})\right].$
    |  | (4) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Adopt InfoNCE Oord et al. ([2018](#bib.bib21)) as the contrastive loss function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}(\theta)=\sum_{n=1}^{N}-\log\left(\frac{e^{\text{logits}_{i}}}{\sum^{k+1}_{j=1}e^{\text{logits}_{j}}}\right)_{n},$
    |  | (5) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: where $N$ indicates the index of the positive pair.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Upon training a similarity score approximation model, it can be applied to access
    the similarity between any given query date and historical dates. This enables
    us to retrieve the most similar historical data, which allows the LLM to generate
    a summary of the motivations prevalent at that time. By doing so, we can extrapolate
    a motivation relevant to the query date, providing a basis for the LLM to generate
    a new activity trajectory.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1 Experimental Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dataset. We investigate and validate LLMob over a personal activity trajectory
    dataset from Tokyo. This data set is obtained through the Twitter API and the
    Foursquare API, which covers data from January 2019 to December 2022.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Sample of the personal activity data.'
  prefs: []
  type: TYPE_NORMAL
- en: UserID Latitude Longitude Location Name Category Time 12199425 35.508 139.615
    Convenience Store Shop & Service 8:00 12199425 35.509 139.618 Seafood Restaurant
    Food & Service 8:30
  prefs: []
  type: TYPE_NORMAL
- en: 'The time frame of this data set is insightful as it captures typical daily
    life prior to the COVID-19 pandemic (i.e., normal period) and subsequent alterations
    during the pandemic (i.e., abnormal period). To facilitate an efficient and detailed
    analysis for different periods, we randomly choose 100 users to model their individual
    activity trajectory at a 10-minute interval according to the number of available
    trajectories (sample given in Table [1](#S5.T1 "Table 1 ‣ 5.1 Experimental Setup
    ‣ 5 Experiment ‣ Large Language Models as Urban Residents: An LLM Agent Framework
    for Personal Mobility Generation")). We utilize the category classification in
    Foursquare to determine the activity category for each location. We use 10 candidate
    personas as a prior for subsequent pattern generation, as shown in Table [2](#S5.T2
    "Table 2 ‣ 5.1 Experimental Setup ‣ 5 Experiment ‣ Large Language Models as Urban
    Residents: An LLM Agent Framework for Personal Mobility Generation"), which adequately
    capture a diverse range of activity patterns within the data of this study. For
    the application to other datasets, this style of candidate patterns can be easily
    initialized using an LLM.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Suggested personas and corresponding detailed description.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Student: typically travel to and from educational institutions at similar
    times. |'
  prefs: []
  type: TYPE_TB
- en: '| Teacher: typically travel to and from educational institutions at similar
    times. |'
  prefs: []
  type: TYPE_TB
- en: '| Office worker: have a fixed morning and evening commute, |'
  prefs: []
  type: TYPE_TB
- en: '| often heading to office districts or commercial centers. |'
  prefs: []
  type: TYPE_TB
- en: '| Visitor: tend to travel throughout the day, |'
  prefs: []
  type: TYPE_TB
- en: '| often visit attractions, dining areas, and shopping districts. |'
  prefs: []
  type: TYPE_TB
- en: '| Night shift worker: might travel outside of standard business hours, |'
  prefs: []
  type: TYPE_TB
- en: '| often later in the evening or at night. |'
  prefs: []
  type: TYPE_TB
- en: '| Remote worker: may have non-standard travel patterns, |'
  prefs: []
  type: TYPE_TB
- en: '| often visit coworking spaces or cafes at various times. |'
  prefs: []
  type: TYPE_TB
- en: '| Service industry worker: tend to travel throughout the day, often visit attractions,
    |'
  prefs: []
  type: TYPE_TB
- en: '| dining areas, and shopping districts. |'
  prefs: []
  type: TYPE_TB
- en: '| Public service official: often work in shifts, |'
  prefs: []
  type: TYPE_TB
- en: '| leading to varied travel times throughout the day and night. |'
  prefs: []
  type: TYPE_TB
- en: '| Fitness enthusiast: often travel early in the morning, in the evening, |'
  prefs: []
  type: TYPE_TB
- en: '| or on weekends to fitness centers or parks. |'
  prefs: []
  type: TYPE_TB
- en: '| Retail employee: typically travel to and from educational institutions at
    similar times. |'
  prefs: []
  type: TYPE_TB
- en: 'Metrics. To evaluate the generation performance, various features related to
    individual activity are used as metrics: (1) Step Distance (SD)Yuan et al. ([2022](#bib.bib35)):
    This metric evaluates the spatial pattern of an individual’s activities by measuring
    the distance between two consecutive locations in a trajectory. (2) Step Interval
    (SI)Yuan et al. ([2022](#bib.bib35)): This metric evaluates the temporal pattern
    of an individual’s activities by measuring the time interval between two successive
    locations on an individual’s trajectory. (3) ST-ACT: This metric captures and
    examines the spatial-temporal distribution of activities for each trajectory,
    focusing on the patterns of individual activities characterized by activity type
    and timing (e.g., activity type, time). It provides insight into how activities
    are distributed over space and time. (4) ST-LOC: This metric provides a granular
    perspective on the generated activities by assessing the spatial-temporal distribution
    of visited locations within each trajectory, including geographical coordinates
    and timestamps. It enables a detailed analysis of where and when activities occur.'
  prefs: []
  type: TYPE_NORMAL
- en: After extracting the above features from both the generated and real activity
    trajectory data, Jensen-Shannon divergence (JSD) is employed to quantify the discrepancy
    between the generated and the actual ones. Lower JSD is preferred.
  prefs: []
  type: TYPE_NORMAL
- en: 'Baselines. The following models are implemented to serve as baselines: (1)
    Markov-based mechanic model (MM) Pappalardo and Simini ([2018](#bib.bib23)), (2)
    LSTM-based prediction model (LSTM), (3) Attentional Recurrent Network-based prediction
    model (DeepMove) Feng et al. ([2018](#bib.bib8)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve a balance between capability and cost efficiency, we employ GPT-3.5-Turbo-0613
    as the LLM core. We use “LLMob-L” to denote the framework that incorporates the
    learning-based motivation retrieval scheme (parameter settings appear in Appendix [B](#A2
    "Appendix B Learning-Based Motivation Retrieval ‣ Large Language Models as Urban
    Residents: An LLM Agent Framework for Personal Mobility Generation")), and “LLMob-E”
    to represent the proposal with the evolving-based motivation retrieval scheme.
    To validate the necessity of each module proposed, we conduct ablation studies.
    The configurations “LLMob-L w/o $\mathcal{P}$otivation, allowing for an evaluation
    of the cumulative impact of omitting these modules.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Experimental Results and Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Generative Performance Validation (RQ1, RQ2). The performance evaluation involves
    analyzing generation results in three distinct settings: (1) Generating normal
    trajectories based on normal historical trajectories, specifically using data
    from 2019, a period unaffected by the pandemic. (2) Generating abnormal trajectories
    based on abnormal historical trajectories, utilizing data from 2020, a year marked
    by the pandemic. (3) Generating abnormal trajectories based on normal historical
    trajectories, using data of 2019 and 2021\. Through these settings, the efficiency
    of aligning real-world data, along with the effectiveness of identifying patterns
    and motivations, can be validated. Furthermore, we expect to examine the models’
    generalization capabilities across varying data situations. The results of these
    evaluations are detailed in the metrics reported in Tables [3](#S5.T3 "Table 3
    ‣ 5.2 Experimental Results and Analysis ‣ 5 Experiment ‣ Large Language Models
    as Urban Residents: An LLM Agent Framework for Personal Mobility Generation")
    – [5](#S5.T5 "Table 5 ‣ 5.2 Experimental Results and Analysis ‣ 5 Experiment ‣
    Large Language Models as Urban Residents: An LLM Agent Framework for Personal
    Mobility Generation"). Through the comparison, it can be observed that although
    LLMob may not excel in replicating spatial features precisely (such as SD), it
    demonstrates superior performance in handling temporal aspects. Notably, when
    considering spatial-temporal features (like ST-ACT and ST-LOC), LLMob’s performance
    is markedly better. Specifically, we suggest that the pronounced advantage in
    terms of ST-ACT can be attributed to the LLM agents’ tendency to accurately replicate
    the motivation behind individual activity behaviors. For instance, they may recognize
    patterns like a person’s habits to have breakfast in the morning, without being
    restricted to a specific restaurant. This phenomenon highlights the enhanced semantic
    understanding capabilities of the LLM agents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Performance (JSD) of normal trajectory generation based on normal
    historical data.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Models | SD | SI | ST-ACT | ST-LOC |'
  prefs: []
  type: TYPE_TB
- en: '| MM | 0.018 | 0.276 | 0.644 | 0.681 |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | 0.017 | 0.271 | 0.585 | 0.652 |'
  prefs: []
  type: TYPE_TB
- en: '| DeepMove | 0.008 | 0.153 | 0.534 | 0.623 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-E | 0.053 | 0.046 | 0.125 | 0.559 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-L | 0.049 | 0.054 | 0.136 | 0.570 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-L w/o $\mathcal{P}$ | 0.061 | 0.080 | 0.270 | 0.600 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-E w/o $\mathcal{P}$ | 0.055 | 0.069 | 0.223 | 0.530 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob w/o $\mathcal{P}$ | 0.061 | 0.081 | 0.268 | 0.606 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Performance (JSD) of abnormal trajectory generation based on abnormal
    historical data.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Models | SD | SI | ST-ACT | ST-LOC |'
  prefs: []
  type: TYPE_TB
- en: '| MM | 0.041 | 0.300 | 0.629 | 0.682 |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | 0.016 | 0.286 | 0.563 | 0.655 |'
  prefs: []
  type: TYPE_TB
- en: '| DeepMove | 0.011 | 0.173 | 0.548 | 0.668 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-E | 0.056 | 0.043 | 0.127 | 0.615 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-L | 0.057 | 0.051 | 0.124 | 0.609 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-L w/o $\mathcal{P}$ | 0.072 | 0.081 | 0.286 | 0.641 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-E w/o $\mathcal{P}$ | 0.059 | 0.081 | 0.252 | 0.573 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob w/o $\mathcal{P}$ | 0.068 | 0.086 | 0.287 | 0.635 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Performance (JSD) of abnormal trajectory generation based on normal
    historical data.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Models | SD | SI | ST-ACT | ST-LOC |'
  prefs: []
  type: TYPE_TB
- en: '| MM | 0.039 | 0.307 | 0.644 | 0.681 |'
  prefs: []
  type: TYPE_TB
- en: '| LSTM | 0.035 | 0.282 | 0.585 | 0.653 |'
  prefs: []
  type: TYPE_TB
- en: '| DeepMove | 0.013 | 0.173 | 0.534 | 0.623 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-E | 0.072 | 0.056 | 0.117 | 0.536 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-L | 0.064 | 0.051 | 0.124 | 0.531 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-L w/o $\mathcal{P}$ | 0.073 | 0.091 | 0.248 | 0.580 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob-E w/o $\mathcal{P}$ | 0.065 | 0.079 | 0.209 | 0.561 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMob w/o $\mathcal{P}$ | 0.074 | 0.095 | 0.254 | 0.573 |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/c04791c140b38935bb9269156d8f25cc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Daily activity frequencies comparison.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8f49dae9de58f51a72d40b4964d69617.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Evolving of accumulative counts, Arts & Entertainment.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/13bce89937a860bcb92a440c07968a16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Evolving of accumulative counts, Professional & Other Places.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Explore Real-World Application (RQ3). We are interested in how LLMob can elevate
    the social benefits, particularly in the context of urban mobility. To this end,
    we propose an example of leveraging the flexibility and intelligence of the LLM
    in understanding semantic information. In particular, we enhance the original
    setup by incorporating an additional prompt to provide a context for the LLM agent,
    enabling it to plan activities during specific circumstances. For example, a “pandemic”
    prompt is as follows: Now it is the pandemic period. The government has asked
    residents to postpone travel and events and to telecommute as much as possible.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By integrating this prompt, we introduce an external factor – the pandemic
    situation and the government’s response – into LLMob. In this way, we can observe
    and analyze the impact of external elements, such as the ongoing pandemic and
    the government’s measures, on urban mobility and related social dynamics. We use
    the activity trajectory data during the pandemic (e.g., 2021) as ground truth.
    As shown in Fig. [4](#S5.F4 "Figure 4 ‣ 5.2 Experimental Results and Analysis
    ‣ 5 Experiment ‣ Large Language Models as Urban Residents: An LLM Agent Framework
    for Personal Mobility Generation"), “LLMob-L” serves as the activity trajectory
    generator, and the one augmented with the pandemic prompt is denoted as LLMob-L
    with “Pandemic” Prompt. The influence of the external factor on the simulation
    is clear: there is a significant decrease in activity frequency when the prompt,
    which semantically discourages activities prone to spreading the disease, is applied.
    Additionally, from a spatial-temporal perspective, from spatial-temporal perspective,
    two major activities (e.g., Arts & Entertainment and Professional & Other Places)
    are selected to observe the behavior, as shown in Figs. [5](#S5.F5 "Figure 5 ‣
    5.2 Experimental Results and Analysis ‣ 5 Experiment ‣ Large Language Models as
    Urban Residents: An LLM Agent Framework for Personal Mobility Generation") and
     [6](#S5.F6 "Figure 6 ‣ 5.2 Experimental Results and Analysis ‣ 5 Experiment ‣
    Large Language Models as Urban Residents: An LLM Agent Framework for Personal
    Mobility Generation"). These activities are particularly insightful as they encapsulate
    the impact of the pandemic on the work-life balance and daily routines of residents.'
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, “LLMob-L with Pandemic Prompt” reproduces a more realistic spatial-temporal
    activity pattern. This enhanced realism in the generation is attributed to the
    integration of prior knowledge about the pandemic’s effects and governmental responses,
    allowing the LLM agent to behave in a manner that aligns with actual behavioral
    adaptations. For instance, the reduction in Arts & Entertainment activities reflects
    the closure of venues and social distancing guidelines, while changes in Professional
    & Other Places activities indicate shifts toward remote work and the transformation
    of professional environments. Intuitively, prompting LLM agents to generate activities
    based on various priors shows great potential in real-world applications. The
    utility of such a conditioned generative approach, coupled with the reliable generated
    results, can significantly alleviate the workload of urban managers. We suggest
    that this kind of workflow can simplify the analysis of urban dynamics and aid
    in assessing the potential impact of urban policies.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Contribution. This study is believed to be the first urban mobility simulation
    empowered by LLM on real-world data. Our innovative framework leverages activity
    patterns and motivations to direct LLM agents in emulating urban residents, facilitating
    the generation of interpretable and efficient individual activity trajectory.
    Extensive experimental studies based on real-world data are conducted to validate
    the proposed framework. Further exploration demonstrated the promising capabilities
    of LLM to improve urban mobility management.
  prefs: []
  type: TYPE_NORMAL
- en: Social Impact. Leveraging artificial intelligence to enhance societal benefits
    is increasingly promising, especially with the advent of high-capacity models
    such as LLMs. This study explores one of the potential avenues for applications
    using LLMs as a reliable agent to simulate specific scenarios to assess the effects
    of external factors, such as government policies. The introduced framework offers
    a flexible approach to enhance the reliability and efficiency of LLMs in simulating
    urban mobility.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work is supported by JSPS Kakenhi 22H03903, 23H03406, 23K17456, and JST
    CREST JPMJCR22M2 and SPRING JPMJSP2108.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the use of GPT for polishing the paper, we are responsible for all content.
    The data is anoynimized. To the best of our knowledge, we find no ethical issues.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Aher et al. [2022] Gati Aher, Rosa I Arriaga, and Adam Tauman Kalai. Using large
    language models to simulate multiple humans. arXiv preprint arXiv:2208.10264,
    2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ale Ebrahim Dehkordi et al. [2023] Molood Ale Ebrahim Dehkordi, Jonas Lechner,
    Amineh Ghorbani, Igor Nikolic, Emile Chappin, and Paulien Herder. Using machine
    learning for agent specifications in agent-based models and simulations: A critical
    review and guidelines. Journal of Artificial Societies and Social Simulation,
    26(1), 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Argyle et al. [2023] Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler,
    Christopher Rytting, and David Wingate. Out of one, many: Using language models
    to simulate human samples. Political Analysis, 31(3):337–351, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batty et al. [2012] Michael Batty, Kay W Axhausen, Fosca Giannotti, Alexei Pozdnoukhov,
    Armando Bazzani, Monica Wachowicz, Georgios Ouzounis, and Yuval Portugali. Smart
    cities of the future. The European Physical Journal Special Topics, 214:481–518,
    2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batty [2013] Michael Batty. The new science of cities. MIT press, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2020] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey
    Hinton. A simple framework for contrastive learning of visual representations.
    In International conference on machine learning, pages 1597–1607\. PMLR, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choi et al. [2021] Seongjin Choi, Jiwon Kim, and Hwasoo Yeo. Trajgail: Generating
    urban vehicle trajectories using generative adversarial imitation learning. Transportation
    Research Part C: Emerging Technologies, 128:103091, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feng et al. [2018] Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng,
    Ang Guo, and Depeng Jin. Deepmove: Predicting human mobility with attentional
    recurrent networks. In Proceedings of the 2018 world wide web conference, pages
    1459–1468, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. [2020] Jie Feng, Zeyu Yang, Fengli Xu, Haisu Yu, Mudan Wang, and
    Yong Li. Learning to simulate human mobility. In Proceedings of the 26th ACM SIGKDD
    international conference on knowledge discovery & data mining, pages 3426–3433,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. [2023] Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding,
    Zhilun Zhou, Fengli Xu, and Yong Li. Large language models empowered agent-based
    modeling and simulation: A survey and perspectives. arXiv preprint arXiv:2312.11970,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Grimm et al. [2005] Volker Grimm, Eloy Revilla, Uta Berger, Florian Jeltsch,
    Wolf M Mooij, Steven F Railsback, Hans-Hermann Thulke, Jacob Weiner, Thorsten
    Wiegand, and Donald L DeAngelis. Pattern-oriented modeling of agent-based complex
    systems: lessons from ecology. science, 310(5750):987–991, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Henrich et al. [2010] Joseph Henrich, Steven J Heine, and Ara Norenzayan. The
    weirdest people in the world? Behavioral and brain sciences, 33(2-3):61–83, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. [2019] Dou Huang, Xuan Song, Zipei Fan, Renhe Jiang, Ryosuke Shibasaki,
    Yu Zhang, Haizhong Wang, and Yugo Kato. A variational autoencoder based generative
    model of urban human mobility. In 2019 IEEE conference on multimedia information
    processing and retrieval (MIPR), pages 425–430\. IEEE, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. [2016] Shan Jiang, Yingxiang Yang, Siddharth Gupta, Daniele Veneziano,
    Shounak Athavale, and Marta C González. The timegeo modeling framework for urban
    mobility without travel surveys. Proceedings of the National Academy of Sciences,
    113(37):E5370–E5378, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2023] Nian Li, Chen Gao, Yong Li, and Qingmin Liao. Large language
    model-empowered agents for simulating macroeconomic activities. arXiv preprint
    arXiv:2310.10436, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2018] Xi Liu, Hanzhou Chen, and Clio Andris. trajgans: Using generative
    adversarial networks for geo-privacy protection of trajectory data (vision paper).
    In Location privacy and security workshop, pages 1–7, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. [2023] Qingyue Long, Huandong Wang, Tong Li, Lisi Huang, Kun Wang,
    Qiong Wu, Guangyu Li, Yanping Liang, Li Yu, and Yong Li. Practical synthetic human
    trajectories generation based on variational point processes. In Proceedings of
    the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 4561–4571,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luca et al. [2021] Massimiliano Luca, Gianni Barlacchi, Bruno Lepri, and Luca
    Pappalardo. A survey on deep learning for human mobility. ACM Computing Surveys
    (CSUR), 55(1):1–44, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mao et al. [2023] Jiageng Mao, Yuxi Qian, Hang Zhao, and Yue Wang. Gpt-driver:
    Learning to drive with gpt. arXiv preprint arXiv:2310.01415, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Noulas et al. [2011] Anastasios Noulas, Salvatore Scellato, Cecilia Mascolo,
    and Massimiliano Pontil. Exploiting semantic annotations for clustering geographic
    areas and users in location-based social networks. In Proceedings of the International
    AAAI Conference on Web and Social Media, volume 5, pages 32–35, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oord et al. [2018] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation
    learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI [2022] OpenAI. Introducing chatgpt. https://openai.com/blog/chatgpt,
    2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pappalardo and Simini [2018] Luca Pappalardo and Filippo Simini. Data-driven
    generation of spatio-temporal routines in human mobility. Data Mining and Knowledge
    Discovery, 32(3):787–829, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. [2023] Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra
    of human behavior. arXiv preprint arXiv:2304.03442, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salewski et al. [2023] Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric
    Schulz, and Zeynep Akata. In-context impersonation reveals large language models’
    strengths and biases. arXiv preprint arXiv:2305.14930, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. [2010] Chaoming Song, Tal Koren, Pu Wang, and Albert-László Barabási.
    Modelling the scaling properties of human mobility. Nature physics, 6(10):818–823,
    2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2022] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi,
    Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves
    chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171,
    2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2023] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large
    language model based autonomous agents. arXiv preprint arXiv:2308.11432, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. [2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits
    reasoning in large language models. Advances in Neural Information Processing
    Systems, 35:24824–24837, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weng [2023] Lilian Weng. Llm powered autonomous agents. [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/),
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Williams et al. [2023] Ross Williams, Niyousha Hosseinichimeh, Aritra Majumdar,
    and Navid Ghaffarzadegan. Epidemic modeling with generative agents. arXiv preprint
    arXiv:2307.04986, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. [2023] Zengqing Wu, Run Peng, Xu Han, Shuyuan Zheng, Yixin Zhang,
    and Chuan Xiao. Smart agent-based modeling: On the use of large language models
    in computer simulations. arXiv preprint arXiv:2311.06330, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xi et al. [2023] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential
    of large language model based agents: A survey. arXiv preprint arXiv:2309.07864,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. [2023] Peng Xu, Wei Ping, Xianchao Wu, Lawrence McAfee, Chen Zhu,
    Zihan Liu, Sandeep Subramanian, Evelina Bakhturina, Mohammad Shoeybi, and Bryan
    Catanzaro. Retrieval meets long context large language models. arXiv preprint
    arXiv:2310.03025, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. [2022] Yuan Yuan, Jingtao Ding, Huandong Wang, Depeng Jin, and Yong
    Li. Activity trajectory generation via modeling spatiotemporal dynamics. In Proceedings
    of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages
    4752–4762, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. [2023] Yuan Yuan, Huandong Wang, Jingtao Ding, Depeng Jin, and Yong
    Li. Learning to simulate daily activities via modeling dynamic human needs. In
    Proceedings of the ACM Web Conference 2023, pages 906–916, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2020] Xin Zhang, Yanhua Li, Xun Zhou, Ziming Zhang, and Jun Luo.
    Trajgail: Trajectory generative adversarial imitation learning for long-term decision
    analysis. In 2020 IEEE International Conference on Data Mining (ICDM), pages 801–810\.
    IEEE, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng [2015] Yu Zheng. Trajectory data mining: an overview. ACM Transactions
    on Intelligent Systems and Technology (TIST), 6(3):1–41, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Appendix A Prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '<svg id="A1.p1.pic1" class="ltx_picture" height="124.23" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,124.23) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 15 102.24)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)" color="#000000">Pattern
    generation</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0
    0.0 1.0 21.65 13.78)"><foreignobject width="556.69" height="78.72" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Context: Act as a $<$,…</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'where $<$ in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="A1.p3.pic1" class="ltx_picture" height="105.63" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,105.63) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 15 85.63)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 5.46)"><foreignobject width="123.23" height="10.15" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">$<$ Reason:</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: where $<$ is the daily activities plan for evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="A1.p6.pic1" class="ltx_picture" height="107.78" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,107.78) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 15 85.63)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)" color="#000000">Evolving-based
    motivation reterieval</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject width="556.69" height="62.11" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Context: Act as a person in
    an urban neighborhood and describe the motivation for your activities. $<$ Instructions:
    Describe in one sentence your future motivation today after these activities.
    Highlight any personal interests and needs.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: where $<$ is the historical activities corresponding to the chosen date.
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="A1.p8.pic1" class="ltx_picture" height="91.17" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,91.17) matrix(1 0 0 -1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 15 69.03)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)" color="#000000">Learning-based
    motivation reterieval</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject width="556.69" height="45.51" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Context: Act as a person in
    an urban neighborhood. $<$ Instructions: Try to summarize in one sentence what
    generally motivates you for these plans. Highlight any personal interests and
    needs.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: where $<$ Is replaced by the retrieved historical activities.
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="A1.p10.pic1" class="ltx_picture" height="175.73" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,175.73) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 15 153.59)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)" color="#000000">Daily
    activities generation</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject width="556.69" height="130.07" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Context: Act as a person in
    an urban neighborhood. $<$</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: where $<$ Is replaced by the most frequently visited locations.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="A1.p12.pic1" class="ltx_picture" height="71.88" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,71.88) matrix(1 0 0 -1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 15 52.43)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 4.92)"><text transform="matrix(1 0 0 -1 0 0)" color="#000000">Pandemic</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="556.69" height="28.9" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Now it is the pandemic period. The government has asked residents
    to postpone travel and events and to telecommute as much as possible.</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Learning-Based Motivation Retrieval
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the learning-based motivation retrieval, the score approximator is parameterized
    using a fully connected neural network with the following architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Architecture of the score approximator.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Layer | Input Size | Output Size | Notes |'
  prefs: []
  type: TYPE_TB
- en: '| Input Layer | 3 | 64 | Linear |'
  prefs: []
  type: TYPE_TB
- en: '| Activation | - | - | ReLU |'
  prefs: []
  type: TYPE_TB
- en: '| Output Layer | 64 | 1 | Linear |'
  prefs: []
  type: TYPE_TB
- en: 'We include the day of the year for the query date, whether it shares the same
    weekday as the reference date, and whether both the query and reference dates
    fall within the same month as input features. Settings for the learning process
    are as follows: Adam is used as the optimizer, batch size is 64, learning rate
    is 0.002, and the number of negative samples is 2.'
  prefs: []
  type: TYPE_NORMAL
