- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:47:55'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder
    Mystery Games'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.17662](https://ar5iv.labs.arxiv.org/html/2404.17662)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Qinglin Zhu^(1∗), Runcong Zhao^(1∗), Jinhua Du², Lin Gui¹, Yulan He^(1,3)
  prefs: []
  type: TYPE_NORMAL
- en: ¹King’s College London, ²Huawei London Research Centre, ³The Alan Turing Institute
  prefs: []
  type: TYPE_NORMAL
- en: '{qinglin.1.zhu,runcong.zhao}@kcl.ac.uk'
  prefs: []
  type: TYPE_NORMAL
- en: jinhua.d@huawei.com, {lin.1.gui, yulan.he}@kcl.ac.uk
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Recent advancements in Large Language Models (LLMs) have enhanced the efficacy
    of agent communication and social interactions. Despite these advancements, building
    LLM-based agents for reasoning in dynamic environments involving competition and
    collaboration remains challenging due to the limitations of informed graph-based
    search methods. We propose PLAYER*, a novel framework based on an anytime sampling-based
    planner, which utilises sensors and pruners to enable a purely question-driven
    searching framework for complex reasoning tasks. We also introduce a quantifiable
    evaluation method using multiple-choice questions and construct the WellPlay dataset
    with 1,482 QA pairs. Experiments demonstrate PLAYER*’s efficiency and performance
    enhancements compared to existing methods in complex, dynamic environments with
    quantifiable results.
  prefs: []
  type: TYPE_NORMAL
- en: '^*^*footnotetext: Equal contribution.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recent advancements in LLMs capable of generating human-like responses have
    boosted the development of LLM-as-Agent. Building upon this progress, a series
    of studies focusing on multi-agent communications have showcased the emergence
    of social interactions, including cooperation (Li et al., [2024a](#bib.bib17);
    FAIR et al., [2022](#bib.bib8)), trust (Xu et al., [2023a](#bib.bib39)), deception
    (Wang et al., [2023](#bib.bib34)), and the spread of information (Park et al.,
    [2023](#bib.bib25)). Despite notable progress in enabling LLM-based agents to
    mimic human language, building agents for reasoning in dynamic environments, especially
    in scenarios considering competition and collaboration with other agents, remains
    a challenge, for example, the Murder Mystery Games (MMGs), a strategic game requires
    both cooperation and competition among 4-12 players through negotiation and tactical
    coordination (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ PLAYER*: Enhancing
    LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games")).
    We argue that the primary reason is that most existing LLM-based agents involve
    the informed graph-based search method with a heuristics term to guide the reasoning
    progress. While this approach might be efficient in well-defined problems, where
    constructing a relation graph and producing a clear reasoning path as output is
    feasible, in complex problems requiring both cooperation and competition through
    natural language negotiation and tactical coordination, defining such a clear
    graph of potential actions becomes challenging. The main difficulty of applying
    traditional Multi-Agent Reinforcement Learning (MARL) methods in such scenarios
    arises from the challenges in defining state spaces, action spaces, and rewards,
    where the reward associated with the final decision often represents the only
    clear certainty (FAIR et al., [2022](#bib.bib8); Shi et al., [2024](#bib.bib27)).'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we propose a new framework based on an anytime sampling-based planner.
    Unlike informed graph-based search methods, such as A* (Dechter & Pearl, [1985](#bib.bib5)),
    the anytime sampling-based planner, such as RRT* (Karaman & Frazzoli, [2011](#bib.bib14))
    or BIT* (Gammell et al., [2020a](#bib.bib10)), tackles optimal motion planning
    problems in a more complex scenario. That is, by sampling possible states with
    detective sensors in real-time, the tree-style search path is constructed and
    pruned dynamically until the target is reached. Similarly, in MMGs, by proposing
    a set of sensors considering relations and emotions between players during interaction,
    along with a pruner that targets extracting highly suspicious murders, we construct
    a purely questioning-driven search framework. Our main contribution is that we
    proposed an approach which constructs a reasoning process without the need for
    pre-defined questions or prompt templates. Instead, it relies on a generator regulated
    by sensors and a pruner to efficiently generate high-quality questions for the
    agent’s reasoning task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, the current evaluation is difficult to quantify. These methods rely
    heavily on manual evaluation for in-depth understanding but are considerably influenced
    by subjective interpretation (Xu et al., [2023a](#bib.bib39); Wang et al., [2023](#bib.bib34)).To
    address this, we propose a quantifiable and reproducible evaluation criterion
    by devising a series of multiple-choice questions. This approach encompasses three
    types of questions: fact-based questions that are automatically generated from
    an existing dataset focusing on character relationships (Zhao et al., [2024c](#bib.bib46)),
    questions about the shared and individual objectives of each character set within
    the game, and questions probing the rationale behind the given responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, we made the following contributions: (1) We propose PLAYER*, a
    framework aimed at efficiently optimising path planning in MMGs. (2) We conduct
    experiments to assess the efficiency and performance enhancements brought by PLAYER*,
    demonstrating its superiority over existing multi-agent methods. (3) We propose
    a quantifiable evaluation method using multiple-choice questions focusing on facts,
    character objectives, and reasoning, mitigating the subjectivity in current evaluation
    practices with the construction and annotation of the corresponding dataset, WellPlay,
    which includes 1,482 QA pairs. ¹¹1Our code and dataset are available at [https://github.com/alickzhu/PLAYER](https://github.com/alickzhu/PLAYER).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0bd891b1ee054919a765ee0b47a8f8e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The gameplay comprises three stages: introduction, discussion, and
    decision. During the introduction stage, players familiarise themselves with their
    characters’ background information and objectives, then briefly introduce themselves
    in character. Subsequently, they engage in interactive discussions to deduce the
    identity of the murderer.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 PLAYER*
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '2.1 Problem Setting & Preliminary: Search by LLMs'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In response to the complexities of social interactions such as MMGs, we have
    developed an innovative interactive framework tailored for such scenarios. As
    illustrated in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ PLAYER*: Enhancing
    LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games"),
    this framework entails the creation of a set of agents $\mathcal{A}=\{a_{i}\}_{i=1}^{N_{a}}$-dim
    vector, where the entries can be discrete or continuous based on suspicion strength.
    The complete game rules and examples can be found in the appendix [A](#A1 "Appendix
    A MMGs Rules and Procedure ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication
    and Interaction in Murder Mystery Games").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike transitional planning task in which the state space can be accessed
    directly, $s_{i}$ is the prompt instruction. The preliminary planner contains
    two main components:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Explorer: By choosing a different prompt template $T$.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Predictor: a self-reflection estimator to evaluate $s_{i}$ and a clue to continuously
    explore in the next iteration.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In general, the preliminary method only construct a prompting based planner
    for a give script. However, in the complex scenario like MMGs, the objective can
    be multiple, noted as $\mathbf{o}_{i}=\{o_{ij}\}_{j=1}^{N_{i}}$ rounds. Following
    these rounds, agents are required to make decisions and cast their votes to identify
    the suspected murderer. Therefore, we need to construct a more complicated strategies
    considering the simulation among agents.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Construction of Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The strength of the preliminary method is that the tree structure and the potential
    reasoning path is clearly defined by the $T$ before and after prompting respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sensors: inspired by sociology, which claims that the interpersonal relationships
    are often conceptualised within a multidimensional space encompassing factors(Latané,
    [1981](#bib.bib16); Zhao et al., [2021](#bib.bib47); Trope & Liberman, [2010](#bib.bib33)),
    we propose employing a set of sensors associated with each task. For example,
    the emotion, motivation, and suspicion, are considered as the hints to generate
    prompt for state searching.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pruner: After prompting, we design a pruner to reduce the state space to only
    few high suspicions in the next round of reasoning.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Besides, To address the constraints of LLMs’ finite context window and the performance
    degradation associated with an increasing number of input tokens (Liu et al.,
    [2023a](#bib.bib21)), we implement a Memory Retrieval module to store and retrieve
    narrative scripts and dialog logs generated during gameplay. Specifically, we
    store the embeddings of all generated dialog logs and each agent’s script in a
    vector database dedicated to each agent. When an agent encounters a new event
    requiring action, we use the Faiss library (Douze et al., [2024](#bib.bib6)) to
    retrieve relevant memories. This process enables the construction of prompts tailored
    to the predetermined maximum script length and dialog history length. It ensures
    consistent and coherent interactions among agents while assisting in their strategic
    planning.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/19246785691a3683e374986d7ae1695c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: PLAYER*’s planning strategy begins with an introduction round, during
    which each agent provides a brief self-introduction. Agents then initialise scenario
    understanding and begin questioning other agents. Subsequently, they start searching
    for further information by questioning other agents. Agents then adapt their level
    of suspicion and intended search area based on their received response, mirroring
    human gameplay strategies. This iterative process of inquiry and refinement continues
    until the final turn, when agents make decisions aligned with their objectives.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 PLAYER* Planning Strategy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To navigate an unknown continuous space defined by natural language, which
    encompasses the dynamics of relationships, perceptions towards the agent, and
    hidden secrets, PLAYER* approximate the search domain through sampling, and planning
    the shortest path to the agent’s objective by prioritising searches based on the
    quality of potential solutions. As illustrated in Figure [2](#S2.F2 "Figure 2
    ‣ 2.2 Construction of Agents ‣ 2 PLAYER* ‣ PLAYER*: Enhancing LLM-based Multi-Agent
    Communication and Interaction in Murder Mystery Games"), this framework is fundamentally
    composed of two key components:'
  prefs: []
  type: TYPE_NORMAL
- en: Questioning Strategy in Searching based on Sensors
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Given the intricate social complexities inherent to MMGs, our proposed framework
    provides a robust solution through action generation with sensor components. Unlike
    prior approaches that required predefined prompts and a multitude of pre-set inquiries
    (Xu et al., [2023b](#bib.bib40)), we generate actions directed towards the targets
    based on the values detected by those sensors. The task-specific sensors can vary
    across different tasks, and the only requisite input is a list of sensors. For
    MMGs, we have designated the input sensors $S$: Emotion, which assesses one’s
    willingness to assist the given individual or their intent to uncover as many
    of their issues as possible; Motivation, evaluating from one’s perspective whether
    the individual possesses a motive to be the perpetrator; and Suspicion, objectively
    determining whether they had the opportunity to commit the crime.'
  prefs: []
  type: TYPE_NORMAL
- en: Since the number of inquiries an agent can pose is limited, each question incurs
    a cost, representing a missed opportunity for exploration, while the reward for
    such a cost is the information that can be obtained from the response. Under the
    assumption that increased inquiries to an agent corresponds to the heightened
    exploration within the world space related to that agent, the expected reward
    associated with questioning the same agent decreases in proportion to the number
    of inquiries posed. Therefore, it is necessary to evaluate the probability of
    obtaining valuable information by persisting in questioning a character who has
    already been asked many questions, even if this person might be highly suspicious.
    We estimate this probability $P_{informative}(D_{i},|Q_{i}|)$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Input: Agents $\mathcal{A}=\{a_{i}\}_{i=1}^{N_{a}}$)20'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 Anytime Sampling-based Planning in Multi-agent Interaction
  prefs: []
  type: TYPE_NORMAL
- en: Action Space Refinement with a Pruner
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Following the search step, agents received the response from the questioned
    agent, as well as conversational exchanges among other agents. Each agent first
    updates its comprehension of the interpersonal relationships, thereby adjusting
    sensor values: $f_{sensor}:(C^{\prime}_{i},D_{i})\rightarrow S$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In human gameplay, after an initial round of discussion, players often formulate
    judgments regarding the scenario and direct their focus towards a subset of highly
    suspicious individuals. This strategic refinement process is critical for conserving
    cognitive resources and enhancing the efficacy of inferential reasoning. Emulating
    the cognitive pattern of human beings, we introduce an Action Space Refinement
    strategy to refine the search space $1$2: guided by sensors, the agent selects
    the most suspicious targets. We did not impose a hard restriction on the refinement
    process and allowed for flexible adjustment of the action space. For instance,
    the number of suspects could increase, or an agent might shift suspicion to someone
    previously overlooked. This is because new information might entirely overturn
    conclusions drawn in prior rounds, and we did not want to limit that possibility.
    This approach prevents premature convergence on a suspect and ensures a comprehensive
    evaluation of all potential leads. By adopting this protocol, agents systematically
    converge on the most plausible suspects, thereby expediting the resolution of
    the mystery and heightening the likelihood of identifying the perpetrator within
    the designated number of discussion rounds.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Algorithm [1](#alg1 "In Questioning Strategy in Searching based on Sensors
    ‣ 2.3 PLAYER* Planning Strategy ‣ 2 PLAYER* ‣ PLAYER*: Enhancing LLM-based Multi-Agent
    Communication and Interaction in Murder Mystery Games") outlines a detailed procedure
    of the game process. While initially designed for MMGs, the framework’s adaptable
    nature allows it to be readily applied to various games by adjusting the game
    rules and task-specific sensors, thereby enhancing the gaming experience and offering
    a structured way for agents to handle complex social dynamics efficiently.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Experimental Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Base Models
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We conducted experiments with GPT-3.5 for conversation and the GPT Embedding
    Model for memory retrieval via the Azure API in Jan-Mar 2024, using the default
    model versions gpt-35-turbo-16k 0613 and text-embedding-ada-002. To minimise randomness,
    we conducted the evaluation experiments 3 times and report the average and variance.
    The detailed introduction to the experiment settings is in Appendix [C.1](#A3.SS1
    "C.1 Implementation Details ‣ Appendix C Implementation ‣ PLAYER*: Enhancing LLM-based
    Multi-Agent Communication and Interaction in Murder Mystery Games").'
  prefs: []
  type: TYPE_NORMAL
- en: Baselines
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'For baselines, we compare our approach with other multi-agent algorithms designed
    for multiplayer deduction games, such as Werewolf (Xu et al., [2023a](#bib.bib39)),
    Objective-Guided Chain of Thought (O-CoT) (Park et al., [2023](#bib.bib25); Zhao
    et al., [2024b](#bib.bib45)), and ThinkThrice (Wu et al., [2024](#bib.bib37)).
    Additionally, we assess the performance of agents that do not actively participate
    in the game but have direct access to either their own script (Single Script Access)
    or the scripts of all agents (Full Script Access). In werewolf, questions are
    chosen from a role-specific predefined list to facilitate game progression, alongside
    questions generated based on the current scenario. In O-CoT, agent interactions
    are driven by their set objectives. ThinkThrice has its agents crafting questions
    from retrieved memory and the current scenario. However, the efficiency of exploration
    with the questioning strategies is low, as evidenced by their performance, which
    falls significantly short of full script access. In contrast, our method leverages
    sensor data to identify the optimal domain to question and guide the generation
    of questions. The detailed comparison is in Appendix [C.2](#A3.SS2 "C.2 Comparison
    Models ‣ Appendix C Implementation ‣ PLAYER*: Enhancing LLM-based Multi-Agent
    Communication and Interaction in Murder Mystery Games").'
  prefs: []
  type: TYPE_NORMAL
- en: WellPlay Dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We create an evaluation dataset, called the WellPlay Dataset, based on the
    existing dataset Conan (Zhao et al., [2024c](#bib.bib46)), originated from background
    narratives created for MMGs, which provides annotated relationships between characters.
    We aim to concentrate on the most challenging and significant relationships that
    assess the agents’ comprehension of the scenario. Our approach is grounded in
    the original game’s objectives and informed by a trial round involving human players.
    This method enabled us to formulate the following types of evaluation questions
    in line with the human players:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Objective. Including shared objectives, such as identifying the perpetrator(s),
    and individual objectives, such as determining who stoles wallet, for each character
    in the game.
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Reasoning. This entails questions that delve into the reasoning behind
    provided answers, relating to agents’ objectives, including: Who; What (the nature
    of the incident, such as murder, theft, disappearance, explosion); When (the time
    of the incident); Where(the location of the incident); Cause (e.g., shooting,
    poisoning, stabbing); Motive (e.g., crime of passion, vendetta, financial conflicts,
    manslaughter).'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Relations. This includes interpersonal relationships between victims and
    other characters, as well as relationships among suspects.
  prefs: []
  type: TYPE_NORMAL
- en: 'To establish a quantifiable evaluation method, we employ *multiple-choice questions*
    focusing on *factual information*. This dataset encompasses 12 MMGs, comprising
    a total of 1,482 evaluation questions. On average, each game features 5.67 agents
    and 1.75 victims. More detailed statistics are available in the appendix [B.1](#A2.SS1
    "B.1 Details of Dataset ‣ Appendix B The WellPlay Dataset ‣ PLAYER*: Enhancing
    LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games").'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Metrics
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We adopted the scoring system used in the game to evaluate agents’ performance:
    Awarding 10 points for achieving an objective, 5 points for correct reasoning,
    and 2 points for providing additional information based on the players’ understanding
    of the current situation. However, instead of using open-ended questions with
    human players, we assess each agent’s performance using our constructed dataset,
    WellPlay, to facilitate replication and comparison for future research. WellPlay
    comprises three types of questions: objective, reasoning, and relations, which
    are assigned 10, 5, and 2 points, respectively. We calculate the agent’s final
    score as $\frac{\text{Awarded Points}}{\text{Total Points}}$ to determine its
    overall performance. Additionally, we assess the accuracy of each question type.
    For the computation of the overall score for performance assessment, we have utilized
    weighted mean and weighted standard deviation methodologies. The detailed algorithm
    for these calculations is in Appendix [B.2](#A2.SS2 "B.2 Overall Performance Computing
    ‣ Appendix B The WellPlay Dataset ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication
    and Interaction in Murder Mystery Games").'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Performance Evaluation Results
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Table [1](#S3.T1 "Table 1 ‣ Performance Evaluation Results ‣ 3.2 Results ‣
    3 Experiments ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction
    in Murder Mystery Games") presents the evaluation of agents’ performance across
    12 unique games of varying complexity and settings. The number of evaluation questions
    (“#QA”) varies based on script complexity, with more complex scripts generating
    a larger volume of questions. The SSA (Single Script Access) measures agents’
    performance with access to only their own script. This setup is designed to represent
    the starting point for searching. The FSA (Full Script Access) measures performance
    when agents have access to all agents’ scripts, representing the ideal search
    endpoint. Ideally, FSA should aim to achieve an accuracy of 1\. However, in practice,
    its effectiveness is often limited by the deductive capabilities of the underlying
    base model. Despite this, FSA still scores significantly higher than SSA. In addition,
    FSA also serves as an indicator of the complexity of the script.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can observe that PLAYER* exhibits superior performance other baselinse across
    all evaluation questions, demonstrating its enhanced understanding of the search
    space through interactions with other agents. Additionally, PLAYER* significantly
    outperforms others in objective questions, even surpassing FSA, which has access
    to all information. This showcases the effectiveness of PLAYER* in refining information
    and dynamically narrowing down the search domain to achieve the target objective.
    Despite some baselines exhibiting competitive performance in reasoning or relation
    questions, their significant drop in performance concerning objectives indicates
    a critical limitation: an inability to effectively utilise the collected information
    to reach correct conclusions or achieve game-specific goals.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We also evaluate the performance of our framework on English scripts in Appendix [C.3](#A3.SS3
    "C.3 Performance Evaluation Results for English Dataset ‣ Appendix C Implementation
    ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder
    Mystery Games") and open-source LLMs in Appendix [C.4](#A3.SS4 "C.4 Experiments
    with Open-Source LLMs ‣ Appendix C Implementation ‣ PLAYER*: Enhancing LLM-based
    Multi-Agent Communication and Interaction in Murder Mystery Games"). The detailed
    dialogue history and evaluation records are available in the GitHub link provided
    previously.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Script | Evaluation | #QA | SSA | FSA | Agent’s Response After Playing the
    Game |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Werewolf | O-CoT | ThinkThrice | PLAYER* |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| *Death Wears White* *(9 players, 1 victim)* | Objective | $10$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $102$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $72$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $184$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Ghost Revenge* *(7 players, 3 victims)* | Objective | $19$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $152$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $69$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $240$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Danshui Villa* *(7 players, 2 victims)* | Objective | $12$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $128$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $63$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $203$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Unfinished Love* *(7 players, 2 victims)* | Objective | $12$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $61$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $72$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $145$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Cruise Incident* *(5 players, 1 victim)* | Objective | $4$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $24$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $30$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $58$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Sin* *(4 players, 1 victim)* | Objective | $3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $20$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $21$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $44$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Deadly Fountain* *(4 players, 1 victim)* | Objective | $3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $21$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $12$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $36$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Unbelievable Incident* *(5 players, 1 victim)* | Objective | $4$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $24$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $15$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $43$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Desperate Sunshine* *(4 players, 1 victim)* | Objective | $3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $18$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $36$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $57$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Riverside Inn* *(4 players, 1 victim)* | Objective | $3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $18$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $18$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $39$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Solitary Boat Firefly* *(6 players, 4 victims)* | Objective | $20$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $109$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $69$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $198$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Manna* *(6 players, 3 victims)* | Objective | $24$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $123$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $88$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $235$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | Objective | $117$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $800$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $565$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $1482$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Compare the performance of agents with other multi-agent algorithms
    designed for multiplayer deduction games. SSA and FSA stand for Single Script
    Access and Full Script Access, respectively, representing the performance of agents
    when they have access to either only their own script or the scripts of all agents,
    without interacting with other agents.'
  prefs: []
  type: TYPE_NORMAL
- en: Efficiency and Cost Comparison
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As shown in Table [2](#S3.T2 "Table 2 ‣ Efficiency and Cost Comparison ‣ 3.2
    Results ‣ 3 Experiments ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication
    and Interaction in Murder Mystery Games"), we delve into the efficiency and cost
    analysis across various methodologies implemented for agent interaction in MMGs,
    as detailed in our results table. The costs are presented in actual monetary values
    (US Dollars) associated with the use of Azure API, providing a direct measure
    of the computational expense incurred during both gameplay and evaluation stages
    ²²2Billing method details are available on the website [https://azure.microsoft.com/en-gb/pricing/details/cognitive-services/openai-service/](https://azure.microsoft.com/en-gb/pricing/details/cognitive-services/openai-service/).'
  prefs: []
  type: TYPE_NORMAL
- en: Each script’s complexity is indicated by the $\#Tokens$ column, reflecting the
    narrative depth and the number of characters, suspects, and victims involved.
    This complexity directly influences the API usage cost, as more intricate scenarios
    require more processing power for information handling. The costs are divided
    into Gameplay and Evaluation phases. During Gameplay, agents actively participate
    in the game, generating actions and responses. In the Evaluation phase, the performance
    of these agents is assessed based on the WellPlay Dataset. Notably, SSA and FSA
    methodologies do not incur costs during the Gameplay phase, as they were tested
    in a direct, non-interactive manner.
  prefs: []
  type: TYPE_NORMAL
- en: PLAYER* stands out for its cost-efficiency and performance. By employing the
    Action Space Refinement strategy, PLAYER* minimises unnecessary API calls, concentrating
    its investigative efforts on the most suspicious characters. This focus significantly
    reduces the computational resources required, thereby lowering the overall cost
    of operations. This strategic optimisation is evident across all scripts, with
    PLAYER* consistently registering lower costs in comparison to its counterparts
    during the Gameplay phase. Evaluation costs are similar across all methods due
    to a shared evaluation strategy, with variations in SSA and FSA costs arising
    from their differing levels of script access.
  prefs: []
  type: TYPE_NORMAL
- en: '| Script | #Tokens | Stage | SSA | FSA | Agent’s Response After Playing the
    Game |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Werewolf | O-CoT | ThinkThrice | PLAYER* |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| *Death Wears White* *(9 players, 1 victim)* | 3,190 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.349$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Ghost Revenge* *(7 players, 3 victims)* | 5,487 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.418$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Danshui Villa* *(7 players, 2 victims)* | 5,111 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.351$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Unfinished Love* *(7 players, 2 victims)* | 2,501 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.230$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Cruise Incident* *(5 players, 1 victim)* | 1,262 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.064$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Sin* *(4 players, 1 victim)* | 2,121 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.061$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Deadly Fountain* *(4 players, 1 victim)* | 1,852 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.045$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Unbelievable Incident* *(5 players, 1 victim)* | 3,182 | Gameplay | $-$
    |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.077$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Desperate Sunshine* *(4 players, 1 victim)* | 3,370 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.104$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Riverside Inn* *(4 players, 1 victim)* | 1,909 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.055$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Solitary Boat Firefly* *(6 players, 4 victims)* | 8,893 | Gameplay | $-$
    |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.380$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Manna* *(6 players, 3 victims)* | 9,028 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $0.444$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | 47,906 | Gameplay | $-$ |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | $2.578$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Compare the costs in US dollars($) of calling Openai API across multi-agent
    algorithms in MMGs setting, with Gameplay and Evaluation Stage. $\#Tokens$ represent
    the average length of each character’s script. Costs are reported for one complete
    gameplay and one evaluation process for each script.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Ablation Studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Performance peaks around round 3, after which it shows variability, with some
    rounds experiencing slight declines or plateauing in scores despite more rounds
    or questions. This indicates that after a rapid initial learning or adaptation
    phase, where agents effectively use additional questions to enhance their understanding
    and strategies, the value of information gained from conversations tends to converge.
    These results also provide empirical support for the assumption made in our methodology
    that the more inquiries we pose to an agent, the expected reward associated with
    questioning the same agent decreases. For the main results we reported, we use
    the original setting for number of rounds in MMG, which is 3, and based on the
    outcomes of the ablation studies, we chose the most effective number of questions
    to ask each round, which is $1$ question.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f9ec78ccb5863a5faf0dc7800888692d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Comparison of agents’ behaviour across different numbers of rounds,
    where each agent can ask a specific number of questions (denoted as $m$).'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Related Works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multi-Agent Interaction
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Multi-agent reinforcement learning marking significant progress in complex games
    (Lanctot et al., [2017](#bib.bib15); Perolat et al., [2022](#bib.bib26); Bakhtin
    et al., [2023](#bib.bib1)). However, these methods often require extensive time
    and computational resources and lack linguistic communication capabilities. With
    the emergence of LLMs, there’s a shift of focus towards improving multi-agent
    language communication, evidenced by advancements in various games and scenarios,
    such as werewolf (Xu et al., [2023a](#bib.bib39)), avalon (Wang et al., [2023](#bib.bib34);
    Shi et al., [2024](#bib.bib27)), interactive narrative (Zhao et al., [2024b](#bib.bib45)),
    MMGs (Wu et al., [2024](#bib.bib37)), and survival games (Toy et al., [2024](#bib.bib32)).
    Exemplified by AlphaGo (Silver et al., [2017](#bib.bib28)), which demonstrated
    exceptional performance against human competitors, self-play learning frameworks
    (Fu et al., [2023](#bib.bib9); Chen et al., [2024](#bib.bib2)) are proposed to
    improve LLMs’ performance. This idea has also been adapted for evaluation through
    negotiation games (Davidson et al., [2024](#bib.bib4)). Compared to classic methods
    (Wang & Shen, [2024](#bib.bib36)), agents based on LLMs are capable of inferencing
    across a broader range of scenarios (Lin et al., [2023](#bib.bib20)), even with
    some ability of theory of mind (Zhou et al., [2023](#bib.bib48)) to infer other
    agent’s mental states. However, they have also been found to inherit biases that
    limit their inferential abilities (Xie et al., [2023](#bib.bib38); Chuang et al.,
    [2024](#bib.bib3)). Works have also explored utilising LLMs as the environment
    (Zhang et al., [2024](#bib.bib43)) or update actions (Zhao et al., [2024a](#bib.bib44))
    for agents.
  prefs: []
  type: TYPE_NORMAL
- en: Optimisation for Complicated Tasks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Alignment through human feedback offers more consistent training compared to
    reinforcement learning (Liang et al., [2024](#bib.bib19)), but obtaining this
    feedback can be expensive. To address this, approaches like self-instruct (Wang
    et al., [2022](#bib.bib35); Liu et al., [2023b](#bib.bib22)), self-reflect (Yao
    et al., [2023](#bib.bib41)), self-alignment (Sun et al., [2023](#bib.bib31); Li
    et al., [2024b](#bib.bib18)), and few-shot planning (Song et al., [2023](#bib.bib30)),
    have been introduced. These approach was also adapted to search for optimal tools
    (Du et al., [2024](#bib.bib7)), interact with grounded environments (Ouyang &
    Li, [2023](#bib.bib24); Ismail et al., [2024](#bib.bib13)). Adapting LLM-as-a-Judge
    prompting to evaluate performance (Yuan et al., [2024](#bib.bib42)) or select
    agents (Liu et al., [2023c](#bib.bib23)) has become a popular approach, but negative
    results on self-reflection were also investigated (Huang et al., [2024](#bib.bib12)),
    leaving LLM’s role as a self-reflective agent as an unresolved question. We were
    also inspired by stochastic search methods utilised for robots in planning optimal
    strategies in complex environments (Gammell et al., [2020b](#bib.bib11); Liang
    et al., [2024](#bib.bib19)), shares many similarities with optimisation tasks
    for agents (Singh et al., [2023](#bib.bib29)).
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PLAYER* addresses limitations of LLM-based agents in complex reasoning using
    an anytime sampling-based planner with sensors and pruners. Our approach enables
    efficient, question-driven searching. We propose a quantifiable evaluation method,
    contribute the WellPlay dataset, and demonstrate PLAYER*’s superiority, advancing
    effective reasoning agents in complex environments.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Ethics Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Please note that MMGs and our WellPlay dataset, created to assess agents’ behaviors
    in MMGs, may include descriptions of violent events, actions, or characters. This
    content is included solely for academic, research, and narrative analysis purposes.
    It is not meant to glorify or trivialise violence in any form. We have informed
    annotators about the potential exposure to violent content. Users or researchers
    intending to use this dataset should be aware of this potential exposure and are
    advised to engage with the dataset in a professional and responsible manner. This
    dataset is unsuitable for minors and those sensitive to such content.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work was supported in part by the UK Engineering and Physical Sciences
    Research Council through a New Horizons grant (EP/X019063/1) and a Turing AI Fellowship
    (grant no. EP/V020579/1, EP/V020579/2).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bakhtin et al. (2023) Anton Bakhtin, David J Wu, Adam Lerer, Jonathan Gray,
    Athul Paul Jacob, Gabriele Farina, Alexander H Miller, and Noam Brown. Mastering
    the game of no-press diplomacy via human-regularized reinforcement learning and
    planning. In *the 11th International Conference on Learning Representations*.
    ICLR Press, 2023. URL [https://openreview.net/forum?id=F61FwJTZhb](https://openreview.net/forum?id=F61FwJTZhb).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2024) Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan
    Gu. Self-play fine-tuning converts weak language models to strong language models.
    *CoRR*, abs/2401.01335, 2024. URL [http://arxiv.org/abs/2401.01335](http://arxiv.org/abs/2401.01335).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chuang et al. (2024) Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth
    Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy T. Rogers.
    Simulating opinion dynamics with networks of llm-based agents. *CoRR*, 2024. URL
    [https://arxiv.org/abs/2311.09618](https://arxiv.org/abs/2311.09618).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Davidson et al. (2024) Tim R. Davidson, Veniamin Veselovsky, Martin Josifoski,
    Maxime Peyrard, Antoine Bosselut, Michal Kosinski, and Robert West. Evaluating
    language model agency through negotiations. *CoRR*, 2024. URL [https://arxiv.org/abs/2401.04536](https://arxiv.org/abs/2401.04536).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dechter & Pearl (1985) Rina Dechter and Judea Pearl. Generalized best-first
    search strategies and the optimality of a*. *J. ACM*, 32(3):505–536, 1985. doi:
    10.1145/3828.3830. URL [https://doi.org/10.1145/3828.3830](https://doi.org/10.1145/3828.3830).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Douze et al. (2024) Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson,
    Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé
    Jégou. The faiss library. *CoRR*, 2024. URL [https://arxiv.org/abs/2401.08281](https://arxiv.org/abs/2401.08281).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Du et al. (2024) Yu Du, Fangyun Wei, and Hongyang Zhang. Anytool: Self-reflective,
    hierarchical agents for large-scale api calls. *CoRR*, abs/2402.04253, 2024. URL
    [http://arxiv.org/abs/2402.04253](http://arxiv.org/abs/2402.04253).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FAIR et al. (2022) Meta Fundamental AI Research Diplomacy Team FAIR, Anton Bakhtin,
    Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew
    Goff, Jonathan Gray, Hengyuan Hu, Athul Paul Jacob, Mojtaba Komeili, Karthik Konath,
    Minae Kwon, Adam Lerer, Mike Lewis, Alexander H. Miller, Sasha Mitts, Adithya
    Renduchin-tala, Stephen Roller, Dirk Rowe, Weiyan Shi, Joe Spisak, Alexander Wei,
    David Wu, Hugh Zhang, and Markus Zijlstra. Human-level play in the game of diplomacy
    by combining language models with strategic reasoning. *Science*, 378:1067–1074,
    2022. URL [https://www.science.org/doi/10.1126/science.ade9097](https://www.science.org/doi/10.1126/science.ade9097).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu et al. (2023) Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. Improving
    language model negotiation with self-play and in-context learning from ai feedback.
    In *Advances in Neural Information Processing Systems*, volume 36\. Curran Associates,
    Inc., 2023. URL [https://arxiv.org/abs/2305.10142](https://arxiv.org/abs/2305.10142).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gammell et al. (2020a) Jonathan D. Gammell, Timothy D. Barfoot, and Siddhartha S.
    Srinivasa. Batch informed trees (bit*): Informed asymptotically optimal anytime
    search. *Int. J. Robotics Res.*, 39(5), 2020a. doi: 10.1177/0278364919890396.
    URL [https://doi.org/10.1177/0278364919890396](https://doi.org/10.1177/0278364919890396).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gammell et al. (2020b) Jonathan D. Gammell, Timothy D. Barfoot, and Siddhartha S.
    Srinivasa. Batch informed trees (bit*): Informed asymptotically optimal anytime
    search. *Robotics Research*, 39, 2020b. URL [https://dl.acm.org/doi/abs/10.1177/0278364919890396](https://dl.acm.org/doi/abs/10.1177/0278364919890396).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2024) Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng,
    Adams Wei Yu, Xinying Song, and Denny Zhou. Large language models cannot self-correct
    reasoning yet. In *the 12th International Conference on Learning Representations*.
    ICLR Press, 2024. URL [https://openreview.net/forum?id=IkmD3fKBPQ](https://openreview.net/forum?id=IkmD3fKBPQ).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ismail et al. (2024) Seif Ismail, Antonio Arbues, Ryan Cotterell, René Zurbrügg,
    and Carmen Amo Alonso. Narrate: Versatile language architecture for optimal control
    in robotics. *CoRR*, 2024. URL [https://arxiv.org/abs/2403.10762](https://arxiv.org/abs/2403.10762).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Karaman & Frazzoli (2011) Sertac Karaman and Emilio Frazzoli. Sampling-based
    algorithms for optimal motion planning. *Int. J. Robotics Res.*, 30(7):846–894,
    2011. doi: 10.1177/0278364911406761. URL [https://doi.org/10.1177/0278364911406761](https://doi.org/10.1177/0278364911406761).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lanctot et al. (2017) Marc Lanctot, Vinicius Zambaldi, Audrunas Gruslys, Angeliki
    Lazaridou, Karl Tuyls, Julien Perolat, David Silver, and Thore Graepel. A unified
    game-theoretic approach to multiagent reinforcement learning. In *Advances in
    Neural Information Processing Systems*, volume 30\. Curran Associates, Inc., 2017.
    URL [https://proceedings.neurips.cc/paper/2017/hash/3323fe11e9595c09af38fe67567a9394-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/3323fe11e9595c09af38fe67567a9394-Abstract.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Latané (1981) Bibb Latané. The psychology of social impact. *American Psychologist*,
    36:343–356, 1981. URL [https://psycnet.apa.org/doiLanding?doi=10.1037%2F0003-066X.36.4.343](https://psycnet.apa.org/doiLanding?doi=10.1037%2F0003-066X.36.4.343).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2024a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. Camel: Communicative agents for "mind" exploration
    of large language model society. *CoRR*, abs/2303.17760, 2024a. URL [http://arxiv.org/abs/2303.17760](http://arxiv.org/abs/2303.17760).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2024b) Yuhui Li, Fangyun Wei, Jinjing Zhao, Chao Zhang, and Hongyang
    Zhang. Rain: Your language models can align themselves without finetuning. In
    *the 12th International Conference on Learning Representations*. ICLR Press, 2024b.
    URL [https://openreview.net/forum?id=pETSfWMUzy](https://openreview.net/forum?id=pETSfWMUzy).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2024) Jacky Liang, Fei Xia, Wenhao Yu, Andy Zeng, Montserrat Gonzalez
    Arenas, Maria Attarian, Maria Bauza, Matthew Bennice, Alex Bewley, Adil Dostmohamed,
    Chuyuan Kelly Fu, Nimrod Gileadi, Marissa Giustina, Keerthana Gopalakrishnan,
    Leonard Hasenclever, Jan Humplik, Jasmine Hsu, Nikhil Joshi, Ben Jyenis, Chase
    Kew, Sean Kirmani, Tsang-Wei Edward Lee, Kuang-Huei Lee, Assaf Hurwitz Michaely,
    Joss Moore, Ken Oslund, Dushyant Rao, Allen Ren, Baruch Tabanpour, Quan Vuong,
    Ayzaan Wahid, Ted Xiao, Ying Xu, Vincent Zhuang, Peng Xu, Erik Frey, Ken Caluwaerts,
    Tingnan Zhang, Brian Ichter, Jonathan Tompson, Leila Takayama, Vincent Vanhoucke,
    Izhak Shafran, Maja Mataric, Dorsa Sadigh, Nicolas Heess, Kanishka Rao, Nik Stewart,
    Jie Tan, and Carolina Parada. Learning to learn faster from human feedback with
    language model predictive control. *CoRR*, 2024. URL [https://arxiv.org/abs/2402.11450](https://arxiv.org/abs/2402.11450).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2023) Bill Yuchen Lin, Yicheng Fu, Karina Yang, Faeze Brahman,
    Shiyu Huang, Chandra Bhagavatula, Prithviraj Ammanabrolu, Yejin Choi, and Xiang
    Ren. Swiftsage: A generative agent with fast and slow thinking for complex interactive
    tasks. In *Advances in Neural Information Processing Systems*, volume 36\. Curran
    Associates, Inc., 2023. URL [https://openreview.net/forum?id=Rzk3GP1HN7](https://openreview.net/forum?id=Rzk3GP1HN7).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023a) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language
    models use long contexts. *CoRR*, abs/2307.03172, 2023a. doi: 10.48550/ARXIV.2307.03172.
    URL [https://doi.org/10.48550/arXiv.2307.03172](https://doi.org/10.48550/arXiv.2307.03172).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023b) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. Agentbench: Evaluating llms as agents.
    *CoRR*, 2023b. URL [https://arxiv.org/abs/2308.03688](https://arxiv.org/abs/2308.03688).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023c) Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang.
    Dynamic llm-agent network: An llm-agent collaboration framework with agent team
    optimization. *CoRR*, 2023c. URL [https://arxiv.org/abs/2310.02170](https://arxiv.org/abs/2310.02170).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ouyang & Li (2023) Siqi Ouyang and Lei Li. Autoplan: Automatic planning of
    interactive decision-making tasks with large language models. In *Proceedings
    of the Findings of the Association for Computational Linguistics*, pp.  3114–3128\.
    Association for Computational Linguistics, 2023. URL [https://aclanthology.org/2023.findings-emnlp.205/](https://aclanthology.org/2023.findings-emnlp.205/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2023) Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. Generative agents: Interactive
    simulacra of human behavior. In *the 36th Annual ACM Symposium on User Interface
    Software and Technology*, pp.  1–22\. Association for Computing Machinery, 2023.
    URL [https://openreview.net/pdf?id=p40XRfBX96](https://openreview.net/pdf?id=p40XRfBX96).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perolat et al. (2022) Julien Perolat, Bart de Vylder, Daniel Hennes, Eugene
    Tarassov, Florian Strub, Vincent de Boer, Paul Muller, Jerome T. Connor, Neil
    Burch, Thomas Anthony, Stephen McAleer, Romuald Elie, Sarah H. Cen, Zhe Wang,
    Audrunas Gruslys, Aleksandra Malysheva, Mina Khan, Sherjil Ozair, Finbarr Timbers,
    Toby Pohlen, Tom Eccles, Mark Rowland, Marc Lanctot, Jean-Baptiste Lespiau, Bilal
    Piot, Shayegan Omidshafiei, Edward Lockhart, Laurent Sifre, Nathalie Beauguerlange,
    Remi Munos, David Silver, Satinder Singh, Demis Hassabis, and Karl Tuyls. Mastering
    the game of stratego with model-free multiagent reinforcement learning. *Science*,
    10, 2022. URL [https://www.science.org/doi/10.1126/science.add4679](https://www.science.org/doi/10.1126/science.add4679).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2024) Zijing Shi, Meng Fang, Shunfeng Zheng, Shilong Deng, Ling
    Chen, and Yali Du. Cooperation on the fly: Exploring language agents for ad hoc
    teamwork in the avalon game. *CoRR*, abs/2312.17515, 2024. URL [http://arxiv.org/abs/2312.17515](http://arxiv.org/abs/2312.17515).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silver et al. (2017) David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis
    Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian
    Bolton, Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den
    Driessche, Thore Graepel, and Demis Hassabis. Mastering the game of stratego with
    model-free multiagent reinforcement learning. *Nature*, 550:354–359, 2017. URL
    [https://www.nature.com/articles/nature24270](https://www.nature.com/articles/nature24270).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Singh et al. (2023) Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal,
    Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg. Progprompt:
    program generation for situated robot task planning using large language models.
    *Autonomous Robots*, 47:999–1012, 2023. URL [https://link.springer.com/article/10.1007/s10514-023-10135-3](https://link.springer.com/article/10.1007/s10514-023-10135-3).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Song et al. (2023) Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler,
    Wei-Lun Chao, and Yu Su. Llm-planner: Few-shot grounded planning for embodied
    agents with large language models. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*. Institute of Electrical and Electronics Engineers
    Inc., 2023. URL [https://openaccess.thecvf.com/content/ICCV2023/papers/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2023) Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang
    Chen, David Daniel Cox, Yiming Yang, and Chuang Gan. Principle-driven self-alignment
    of language models from scratch with minimal human supervision. In *Advances in
    Neural Information Processing Systems*, volume 36\. Curran Associates, Inc., 2023.
    URL [https://openreview.net/pdf?id=p40XRfBX96](https://openreview.net/pdf?id=p40XRfBX96).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Toy et al. (2024) Jason Toy, Josh MacAdam, and Phil Tabor. Metacognition is
    all you need? using introspection in generative agents to improve goal-directed
    behavior. *CoRR*, abs/2401.10910, 2024. URL [http://arxiv.org/abs/2401.10910](http://arxiv.org/abs/2401.10910).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trope & Liberman (2010) Yaacov Trope and Nira Liberman. Construal-level theory
    of psychological distance. *Psychol Rev*, 117:440–463, 2010. URL [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3152826/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3152826/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023) Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen,
    Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, and Gao Huang. Avalon’s game
    of thoughts: Battle against deception through recursive contemplation. *CoRR*,
    abs/2310.01320, 2023. URL [http://arxiv.org/abs/2310.01320](http://arxiv.org/abs/2310.01320).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2022) Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu,
    Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. Self-instruct: Aligning
    language model with self generated instructions. In *the 61st Annual Meeting of
    the Association for Computational Linguistics*. Association for Computational
    Linguistics, 2022. URL [https://aclanthology.org/2023.acl-long.754.pdf](https://aclanthology.org/2023.acl-long.754.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang & Shen (2024) Zongshun Wang and Yuping Shen. Bilateral gradual semantics
    for weighted argumentation. In *Proceedings of the AAAI Conference on Artificial
    Intelligence*. MIT Press, 2024. URL [https://ojs.aaai.org/index.php/AAAI/article/view/28945](https://ojs.aaai.org/index.php/AAAI/article/view/28945).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2024) Dekun Wu, Haochen Shi, Zhiyuan Sun, and Bang Liu. Deciphering
    digital detectives: Understanding llm behaviors and capabilities in multi-agent
    mystery games. *CoRR*, abs/2312.00746, 2024. URL [http://arxiv.org/abs/2312.00746](http://arxiv.org/abs/2312.00746).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xie et al. (2023) Zhuohan Xie, Trevor Cohn, and Jey Han Lau. The next chapter:
    A study of large language models in storytelling. In *Proceedings of the 16th
    International Natural Language Generation Conference*, pp.  323–351\. Association
    for Computational Linguistics, 2023. URL [https://aclanthology.org/2023.inlg-main.23/](https://aclanthology.org/2023.inlg-main.23/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023a) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. Exploring large language models for communication games:
    An empirical study on werewolf. *CoRR*, abs/2309.04658, 2023a. URL [http://arxiv.org/abs/2309.04658](http://arxiv.org/abs/2309.04658).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023b) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. Exploring large language models for communication games:
    An empirical study on werewolf. *arXiv preprint arXiv:2309.04658*, 2023b. URL
    [https://arxiv.org/pdf/2309.04658.pdf](https://arxiv.org/pdf/2309.04658.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L.
    Griffiths, Yuan Cao, and Karthik R Narasimhan. Tree of thoughts: Deliberate problem
    solving with large language models. In *Advances in Neural Information Processing
    Systems*, volume 36\. Curran Associates, Inc., 2023. URL [https://openreview.net/forum?id=5Xc1ecxO1h](https://openreview.net/forum?id=5Xc1ecxO1h).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. (2024) Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Xian Li,
    Sainbayar Sukhbaatar, Jing Xu, and Jason Weston. Self-rewarding language models.
    *CoRR*, abs/2401.10020, 2024. URL [http://arxiv.org/abs/2401.10020](http://arxiv.org/abs/2401.10020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2024) Alex Zhang, Khanh Nguyen, Jens Tuyls, Albert Lin, and Karthik
    Narasimhan. Language-guided world models: A model-based approach to ai control.
    *CoRR*, 2024. URL [https://arxiv.org/abs/2402.01695](https://arxiv.org/abs/2402.01695).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2024a) Haiteng Zhao, Chang Ma, Guoyin Wang, Jing Su, Lingpeng Kong,
    Jingjing Xu, Zhi-Hong Deng, and Hongxia Yang. Empowering large language model
    agents through action learning. *CoRR*, 2024a. URL [https://arxiv.org/abs/2402.15809](https://arxiv.org/abs/2402.15809).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2024b) Runcong Zhao, Wenjia Zhang, Jiazheng Li, Lixing Zhu, Yanran
    Li, Yulan He, and Lin Gui. Narrativeplay: An automated system for crafting visual
    worlds in novels for role-playing. In *the 38th Annual AAAI Conference on Artificial
    Intelligence*. MIT Press, 2024b. URL [https://arxiv.org/abs/2310.01459](https://arxiv.org/abs/2310.01459).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2024c) Runcong Zhao, Qinglin Zhu, Hainiu Xu, Jiazheng Li, Yuxiang
    Zhou, Yulan He, and Lin Gui. Large language models fall short: Understanding complex
    relationships in detective narratives. *CoRR*, abs/2402.11051, 2024c. URL [http://arxiv.org/abs/2402.11051](http://arxiv.org/abs/2402.11051).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2021) Yihan Zhao, Rong Chen, Mitsuyasu Yabe, Buxin Han, and Pingping
    Liu. I am better than others: Waste management policies and self-enhancement bias.
    *Sustainability*, 13, 2021. URL [https://www.mdpi.com/2071-1050/13/23/13257](https://www.mdpi.com/2071-1050/13/23/13257).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2023) Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya
    Gupta, Kevin R. McKee, Ari Holtzman, Jay Pujara, Xiang Ren, Swaroop Mishra, Aida
    Nematzadeh, Shyam Upadhyay, and Manaal Faruqui. How far are large language models
    from agents with theory-of-mind? *CoRR*, 2023. URL [https://arxiv.org/abs/2310.03051](https://arxiv.org/abs/2310.03051).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A MMGs Rules and Procedure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A.1 Detailed Rules
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Rule 1:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The total number of players participating in the game depends on the script.
    There may be one or more players who are the murderer(s), while the rest are civilians.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 2:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The goal of the game is for civilian players to collaborate and face a meticulously
    planned murder case together, collecting evidence and reasoning to identify the
    real murderer among the suspects, all the while ensuring they are not mistaken
    for the murderer; murderer players must concoct lies to hide their identity and
    avoid detection, while also achieving other objectives in the game.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 3:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Throughout the game, only murderer players are allowed to lie. To conceal their
    identity, murderers may choose to frame others to absolve themselves of guilt;
    non-murderer players (civilians) must answer questions from other players and
    the host honestly and provide as much information as they know about the case
    to help uncover the truth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 4:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: At the start of the game, each player receives their character script from the
    host, which contains information about their role and identity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 5:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Other players cannot see the content of each player’s character script, so players
    must and can only collect information about other players through interaction
    after the game starts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule 6:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the voting phase, each player needs to cast their vote for who they think
    is the murderer in each case. If the player with the most votes is the murderer,
    the civilian players win. Otherwise, the murderer players win.
  prefs: []
  type: TYPE_NORMAL
- en: A.2 Procedure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Stage 1: Distribution of Character Scripts'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The host distributes character scripts to each player. These scripts contain
    the player’s name, role (murderer or civilian), and a brief character backstory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stage 2: Self-Introduction Session'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Players introduce their characters to the group, laying the groundwork for the
    game’s interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stage 3: Rounds of Open Questioning'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The game progresses through three rounds of open questioning. Players take turns
    to ask and answer questions, aiming to gather information about others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stage 4: Voting'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this stage, players vote anonymously to determine their suspicious regarding
    the identity of the murderer. Each player has one vote.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stage 5: Outcome Reveal'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The game concludes with the announcement of the voting results, revealing whether
    the civilian players successfully identified the murderer or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'A.3 Example: Solitary Boat Firefly Script'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As an illustrative example, we examine the Solitary Boat Firefly murder mystery
    script, involving six players: [ “Tian Chou", “Zhou Lianyi", “Xi Yan", “Yu Sunian",
    Yannan", and “Zhou Chitong" ], along with four victims: [ “Zhou Mengdang", “Bao
    Liu", “Cui Shouheng", and “Wang Xi Rong" ]. We model these characters through
    a set of agents, denoted as $\mathcal{A}=\{a_{i}\}_{i=1}^{N_{a}}$, representing
    the total number of victims in the scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking a closer look at “Tian Chou", depicted as the murderer player $a_{1}$,
    responsible for the demise of two among the four victims, her characterization
    unfolds as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Character Background ($C_{1}$): "Originating from the Sun lineage, you are
    endearingly called ’Tian’er’. Your birth year was the twelfth of Guangxu’s reign
    during the Qing Dynasty (1886), marking the beginning of a life filled with extraordinary
    episodes…"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suspicion State ($s_{1}$ of victim “Cui Shouheng" is [“Zhou Lianyi" ,“Yannan"]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Individual Objectives ($o_{i}$): The personal objectives for Tian Chou include:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Concealing that you killed “Zhou Mengdang".
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Concealing that you killed “Bao Liu".
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Find out the truth about “Taitai’s death".
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Conceal your relationship with “Zhou Chitong".
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: …
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: During the game, the dialogue history is recorded in $D$.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B The WellPlay Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: B.1 Details of Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Script | Agents | Victims | #token(CN) | #token(EN) | Question |'
  prefs: []
  type: TYPE_TB
- en: '| avg | overall | avg | overall | Objective | Reasoning | Relations | overall
    |'
  prefs: []
  type: TYPE_TB
- en: '| *Death Wears White* | 9 | 1 | 3190.67 | 28716 | 1742.33 | 15681 | 10 | 102
    | 72 | 184 |'
  prefs: []
  type: TYPE_TB
- en: '| *Ghost Revenge* | 7 | 3 | 5487.86 | 38415 | 3960.43 | 27723 | 19 | 152 |
    69 | 240 |'
  prefs: []
  type: TYPE_TB
- en: '| *Danshui Villa* | 7 | 2 | 5111.29 | 35779 | 3338.57 | 23370 | 12 | 128 |
    63 | 203 |'
  prefs: []
  type: TYPE_TB
- en: '| *Unfinished Love* | 7 | 2 | 2501.00 | 17507 | 1651.71 | 11562 | 12 | 61 |
    72 | 145 |'
  prefs: []
  type: TYPE_TB
- en: '| *Cruise Incident* | 5 | 1 | 1262.60 | 6313 | 808.00 | 4040 | 4 | 24 | 30
    | 58 |'
  prefs: []
  type: TYPE_TB
- en: '| *Sin* | 4 | 1 | 2121.25 | 8485 | 1378.00 | 5512 | 3 | 20 | 21 | 44 |'
  prefs: []
  type: TYPE_TB
- en: '| *Deadly Fountain* | 4 | 1 | 1852.50 | 7410 | 1193.75 | 4775 | 3 | 21 | 12
    | 36 |'
  prefs: []
  type: TYPE_TB
- en: '| *Unbelievable Incident* | 5 | 1 | 3182.40 | 15912 | 2012.40 | 10062 | 4 |
    24 | 15 | 43 |'
  prefs: []
  type: TYPE_TB
- en: '| *Desperate Sunshine* | 4 | 1 | 3370.25 | 13481 | 2218.50 | 8874 | 3 | 18
    | 36 | 57 |'
  prefs: []
  type: TYPE_TB
- en: '| *Riverside Inn* | 4 | 1 | 1909.50 | 7638 | 1257.00 | 5028 | 3 | 18 | 18 |
    39 |'
  prefs: []
  type: TYPE_TB
- en: '| *Solitary Boat Firefly* | 6 | 4 | 8893.67 | 53362 | 6874.00 | 41244 | 20
    | 109 | 69 | 198 |'
  prefs: []
  type: TYPE_TB
- en: '| *Manna* | 6 | 3 | 9028.17 | 54169 | 6492.33 | 38954 | 24 | 123 | 88 | 235
    |'
  prefs: []
  type: TYPE_TB
- en: '| Avg | 5.67 | 1.75 | 3992.60 | 23932.25 | 2743.92 | 16402.08 | 9.75 | 66.67
    | 47.08 | 125.50 |'
  prefs: []
  type: TYPE_TB
- en: '| Sum | 68 | 21 | 47911.16 | 287187 | 32927.02 | 196825 | 117 | 800 | 565 |
    1482 |'
  prefs: []
  type: TYPE_TB
- en: 'Table A1: Dataset Statistics. Agents is the count of players, Victims is the
    number of script victims, #token(CN) and #token(EN) are the token counts in the
    Chinese and English dataset versions, respectively. Avg shows the average script
    length per character, Overall is the total script token count, and Question enumerates
    the number of questions by types.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this work, we leverage the Conan dataset, originally constructed by Zhao
    et al. ([2024c](#bib.bib46)), which comprises scripts from MMGs, including detailed
    annotations of character relationships. Our bilingual dataset, encompassing both
    Chinese and English versions, is derived from this foundational work. Our dataset
    consists of two main components: scripts and evaluation questions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each script features distinct narratives for individual characters. We have
    rephrased the original script from the Conan dataset into two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Background Script. For each character, there is corresponding background script
    includes all the information from their perspective. For example, for *“Sylvia
    Costa”* in the script *“Death Wears White”*, it is:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*You are the head nurse of the emergency ward.You climbed to this position
    for your hard work and were proud. You are a very professional person and highly
    appreciated by colleagues. This job is perfect for you, except for a problem -
    you have not made enough money. Your salary is actually not enough for you to
    live a decent life, far from paying enough to take care of Mother’s overhead …*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Personal Objectives. For each character, there are corresponding objectives
    that guide their actions. For example, for *“Sylvia Costa”* in the script *“Death
    Wears White”*, it is:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*1\. Ensure that no one will discover your illegal organ trafficking activities;'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. Ensure that the kidnappers leave without being injured or killing anyone
    - you want to ensure that the police do not investigate deeply enough to discover
    your organ trafficking. The further away you are from the police, the safer you
    feel;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3\. …*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| Type | Aspects | Examples (The correct answer has been highlighted in bold.)
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; (score 10) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Who |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Who killed Hans Li Morette? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Gale Li Morette &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B.Nurse head [Sylvia Costa] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Drake Li Morette &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Frank Bijeli &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| B (score 5) | How |'
  prefs: []
  type: TYPE_TB
- en: '&#124; How did Hans Li Morette die? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Shot to death &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Beaten to death &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Poisoned to death by poison &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D.Drowned by water &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Why |'
  prefs: []
  type: TYPE_TB
- en: '&#124; What was the motive behind the killer killing Hans Li Morette? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Love killing &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Vendetta &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Interest &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Accidental killing &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Relationship |'
  prefs: []
  type: TYPE_TB
- en: '&#124; What is the relationship between Murderer and Victim Hans Li Morette?
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Enemies &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Colleague &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Friend &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Wife &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Where |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Where was Hans Li Morette killed? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Emergency room &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Johnson’s House &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Laboratory &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Dressing room &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| When |'
  prefs: []
  type: TYPE_TB
- en: '&#124; When was Hans Li Morette killed? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. This afternoon from 5:00 to 5:30 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. This afternoon from 6:30 to 7:00 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Tonight from 7:00 to 7:30 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. This morning from 6:30 to 7:00 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Suspect |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Please select the two people you most suspect of killing Hans Li Morette
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Gale Li Morette &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Nurse head [Sylvia Costa] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Drake Li Morette &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Frank Bijeli &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| C (score 2) |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Three &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; relationships &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; What is the non-existent relationship between Hans Li Morette and Andrew
    Paloski? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Andrew Paloski is colleague of Hans Li Morette, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Andrew Paloski is mentor of Hans Li Morette, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Andrew Paloski is jealous of Hans Li Morette, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Hans Li Morette is future daughter in law of Andrew Paloski &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Two &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; relationships &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; What is the relationship between Father Tom and Tony? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Tony is manipulated by x and deceived by x of Father Tom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Father Tom is authority over x and student of Tony &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Father Tom is student and ex-girlfriend of Tony &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Father Tom is ex-girlfriend and admired by x of Tony &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; One &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; relationships &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; What is the relationship between Father Tom and Drake Li Morette? &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A. Drake Li Morette is doctor of Father Tom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; B. Father Tom is helped by Drake Li Morette &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; C. Father Tom is step-brother of Drake Li Morette &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; D. Father Tom is hate of Drake Li Morette &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table A2: Examples of Each Type of Our Evaluation Questions'
  prefs: []
  type: TYPE_NORMAL
- en: '| Index | Question |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | What was your timeline on the day of the incident? |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | How would you describe your relationship with the victim? |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | When was the last time you saw the victim? |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Do you know if the victim had any enemies or conflicts with anyone? |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | What details or anomalies did you notice at the scene of the crime? |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | Did the victim mention anything to you or others that made them worried
    or fearful recently? |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | Did you notice any unusual people or behaviors on the day of the incident?
    |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | How much do you know about the victim’s secrets or personal life? |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | Were there any items or remains found at the crime scene that could be
    related to the crime? |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | Do you have any personal opinions or theories about the case? |'
  prefs: []
  type: TYPE_TB
- en: 'Table A3: Predefined questions for Werewolf method.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The evaluation questions are devised based on our annotations and aim to assess
    the understanding of the intricate relationships and narratives present within
    the game scripts. These questions are segmented into three categories, with each
    category of questions and examples shown in Table [A2](#A2.T2 "Table A2 ‣ B.1
    Details of Dataset ‣ Appendix B The WellPlay Dataset ‣ PLAYER*: Enhancing LLM-based
    Multi-Agent Communication and Interaction in Murder Mystery Games").'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Objective: This category includes common objectives shared among agents, such
    as finding the perpetrator(s).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Reasoning: Comprising six types of questions, this section tests the models’
    reasoning capabilities across various aspects:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How: How the murder was committed.'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Why: The motive behind the murder.'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Relationship: The relationship between the murderer and the victim.'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Where: The location where the murder took place.'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When: The time at which the murder occurred.'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suspect: Identify the two most suspicious individuals. Analogous to human reasoning,
    it may be challenging to definitively pinpoint the suspect, yet it is possible
    to determine those who seem most suspect.'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Relations: This segment examines the model’s capacity to comprehend complex
    narratives by querying about the relationships between characters. Utilizing the
    relationship annotations from the Conan dataset(Zhao et al., [2024c](#bib.bib46)),
    we approach this analysis through various questioning strategies based on the
    number of relationships between two characters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For three relationships, we employ the elimination method, asking the model
    to identify the incorrect relation among the given options.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For two relationships, we connect the correct two relationships with “and" and
    introduce a distractor from other relationship categories.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For single relationships, we list the correct option alongside distractors randomly
    selected from other categories.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: For each individual mentioned in the purpose section, we extract three significant
    relationships associated with them. In this context, “significant" is defined
    as the characters who have the most complex connections with the individual, that
    is, the top three characters who share the greatest variety of relationships with
    them. For instance, in the provided example, Andrew Paloski is Hans Li Morette’s
    colleague, mentor, and is also jealous of him.
  prefs: []
  type: TYPE_NORMAL
- en: For various types of questions, we assign different weights based on the original
    scoring system of the script. Specifically, Type A questions are valued at 10
    points, Type B questions at 5 points, and Type C questions at 2 points.
  prefs: []
  type: TYPE_NORMAL
- en: 'Detailed script statistics and evaluation question metrics are presented in
    Table[A1](#A2.T1 "Table A1 ‣ B.1 Details of Dataset ‣ Appendix B The WellPlay
    Dataset ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction
    in Murder Mystery Games").'
  prefs: []
  type: TYPE_NORMAL
- en: B.2 Overall Performance Computing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In calculating the overall score for performance, we have employed both the
    weighted mean and the weighted standard deviation. The weighted mean is computed
    by considering the count of questions for a specific category across various scripts
    as the weight. For the overall score, the total possible score for each script
    serves as the weight. This method allows us to adjust the influence of each category
    and script based on its significance and scale, thus providing a more nuanced
    and accurate reflection of performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The weighted mean is calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bar{x}_{w}=\frac{\sum_{i=1}^{n}(w_{i}\cdot x_{i})}{\sum_{i=1}^{n}w_{i}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'The weighted standard deviation, which measures the spread of the scores, is
    calculated using the weighted variance:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $s_{w}^{2}=\frac{\sum_{i=1}^{n}w_{i}\cdot(x_{i}-\bar{x}_{w})^{2}}{\sum_{i=1}^{n}w_{i}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'And the weighted standard deviation is the square root of the weighted variance:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $s_{w}=\sqrt{s_{w}^{2}}$ |  |'
  prefs: []
  type: TYPE_TB
- en: Appendix C Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: C.1 Implementation Details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RAG (Retrieval-Augmented Generation)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For retrieval enhancement, we utilised the FAISS³³3https://github.com/facebookresearch/faiss
    library to build a vector database, creating FAISS indices using the L2 distance.
    Embeddings were obtained via the Azure API’s text-embedding-ada-002 service. Scripts
    were stored in segments, with each segment having a maximum length of 50 tokens.
    For dialog records, a question-and-answer pair was stored as a single segment.
    During retrieval, the maximum script length and dialog length inserted into the
    prompt were both set to 4000 tokens. For evaluation, these maximum lengths were
    increased to 5000 tokens.
  prefs: []
  type: TYPE_NORMAL
- en: Experiment
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Following the results of our ablation studies, the gameplay phase was structured
    to ask one question per round over three rounds. After the game concluded, the
    evaluation phase consisted of three separate evaluations, with the final results
    being the average of these evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: C.2 Comparison Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we provide a detailed overview of the methodologies compared
    in our study. Given the game’s rules and questioning sequence in our comparisons,
    we segment the discussion into two phases: the questioning phase and the answering
    phase.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the strategic core of the game, a direct confession from the murderer
    would compromise its competitive nature. Hence, in all the methodologies we explore,
    we maintain that the murderer’s responses follow a predefined template, detailed
    in [C.6.2](#A3.SS6.SSS2.Px5 "Question Reply Prompt ‣ C.6.2 Gameplay Prompt ‣ C.6
    Prompt ‣ Appendix C Implementation ‣ PLAYER*: Enhancing LLM-based Multi-Agent
    Communication and Interaction in Murder Mystery Games"). This method preserves
    the game’s integrity and level of challenge.'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Werewolf(Xu et al., [2023a](#bib.bib39))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Question Generation:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Selecting questions from a predefined question written by the human specialist,
    based on the current dialogue and script. The list of expertly devised questions
    is presented in Table [A3](#A2.T3 "Table A3 ‣ B.1 Details of Dataset ‣ Appendix
    B The WellPlay Dataset ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication
    and Interaction in Murder Mystery Games").'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: b.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Formulating questions by the selected predefined questions and the ongoing dialogue
    and script.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Answering Questions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Responding based on the current script and dialog history.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: b.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Reflecting on the initial response in light of the dialog history.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: c.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Generating the final answer after reflection.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Objective-Guided Chain of Thought (O-CoT)(Park et al., [2023](#bib.bib25); Zhao
    et al., [2024b](#bib.bib45))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Question Generation: Entails two critical steps:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sequentially reflecting on whether current objectives have been met, with considerations
    spanning multiple goals such as identifying the murderer, uncovering hidden relationships,
    or concealing facts. For example, Who is the murderer?
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: b.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Crafting questions based on these reflections and the current narrative and
    dialogue.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Answering Questions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers are formulated leveraging the narrative and dialog history.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ThinkThrice(Wu et al., [2024](#bib.bib37))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Question Generation:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Questions are generated based on the script and dialog history.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Answering Questions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Extracting timelines relevant to the victim.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: b.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluating each timeline’s relevance to answering the question.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: c.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Responding based on the dialog history, character relationships, and the relative
    script.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: d.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensuring timelines that aid in answering the question are included in the response.
    If these are initially missed, the model will later augment and clarify the answer
    with the required timelines.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The SSA (Single Script Access)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The SSA assesses agents’ performance when limited solely to their scripts, serving
    as a baseline for initial search efforts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The FSA (Full Script Access)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The FSA evaluates performance under conditions of unrestricted access to all
    scripts, representing an ideal search endpoint.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: C.3 Performance Evaluation Results for English Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Due to budgetary constraints, we only evaluated four scripts from the English
    dataset, with the performance results reported in Table [A4](#A3.T4 "Table A4
    ‣ C.3 Performance Evaluation Results for English Dataset ‣ Appendix C Implementation
    ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder
    Mystery Games"). For the same scripts, we found that the experiments conducted
    on the English corpus corroborate the results obtained from the Chinese corpus.
    Additionally, we observed that the performance of agents based on the English
    corpus surpassed those based on the Chinese corpus, showing the differential inferencing
    abilities of LLMs across languages. This discrepancy could be attributed to language
    biases inherent in the training data utilised for these models.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Script | Evaluation | #QA | SSA | FSA | Agent’s Response After Playing the
    Game |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Werewolf | O-CoT | ThinkThrice | PLAYER* |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| *Death Wears White* *(9 players, 1 victim)* | Objective | $10$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $102$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $72$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $184$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Ghost Revenge* *(7 players, 3 victims)* | Objective | $19$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $152$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $69$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $240$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Danshui Villa* *(7 players, 2 victims)* | Objective | $12$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $128$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $63$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $203$ |'
  prefs: []
  type: TYPE_TB
- en: '| *Unfinished Love* *(7 players, 2 victims)* | Objective | $12$ |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | $61$ |'
  prefs: []
  type: TYPE_TB
- en: '| Relations | $72$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $145$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table A4: Compare the performance of agents with other multi-agent algorithms
    designed for multiplayer deduction games. SSA and FSA stand for Single Script
    Access and Full Script Access, respectively, representing the performance of agents
    when they have access to either only their own script or the scripts of all agents,
    without interacting with other agents.'
  prefs: []
  type: TYPE_NORMAL
- en: C.4 Experiments with Open-Source LLMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Models | Llama2 70b | Llama2 13b | Llama2 7b | gemma 7b |'
  prefs: []
  type: TYPE_TB
- en: '| Overall Score | 0.312 | 0.281 | 0.267 | 0.273 |'
  prefs: []
  type: TYPE_TB
- en: 'Table A5: Compare the performance of PLAYER* method with different open-source
    LLMS.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to experimenting with GPT-3.5-turbo-16k 0613, we also explored
    Llama2 (70b, 13b, 7b) and Gemma 7b. These models were tested using the scenario
    “Solitary Boat Firefly", and the overall results are reported in Table [A5](#A3.T5
    "Table A5 ‣ C.4 Experiments with Open-Source LLMs ‣ Appendix C Implementation
    ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder
    Mystery Games"). The findings indicate that all four models scored significantly
    lower than GPT-3.5, presumably due to the limitations imposed by a 4k context
    window. This limitation likely hindered the models’ ability to encapsulate sufficient
    relevant information within such a constrained window. After thorough testing,
    we observed that despite being evaluated on a Chinese dataset, Llama2 70b primarily
    resorted to English conversations due to its limited proficiency in Chinese. It
    responded in English even to Chinese prompts. Other models struggled even more
    with executing the prompts as required. This limitation greatly hindered their
    performance in complex gaming situations, such as MMGs. Therefore, we decided
    to exclusively use GPT-3.5 for future experiments, given its ability to navigate
    these intricate scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: C.5 Sensors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section provides a detailed explanation of the sensors employed in the
    [2.3](#S2.SS3 "2.3 PLAYER* Planning Strategy ‣ 2 PLAYER* ‣ PLAYER*: Enhancing
    LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games"),
    which are essential for both the Search by Questioning and Action Space Refinement
    components.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Emotion Sensor: Assesses emotional inclination towards a character. Used in
    both Search by Questioning and Action Space Refinement. It categorises emotional
    inclination into “Positive", “Neutral", or “Negative".'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Motivation Sensor: Evaluates the character’s relationship with the victim and
    the presence of a motive for the crime. It is active in both phases, with choices
    being “Yes" or “No".'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suspicion Sensor: Determines if a character is a suspect by analysing their
    opportunity to commit the crime. It applies to both stages, with responses “Yes"
    or “No".'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Information Value Sensor: Exclusive to Action Space Refinement, it estimates
    the probability of obtaining valuable information from further questioning. The
    choices are “High", “Medium", or “Low".'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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){{"name":  "emotion","for_Search_by_Questioning":  True,"for_Action_Space_Refinement":  True,"sensor_prompt":  "What  is  your  emotional  inclination  towards  the  character  mentioned  above?","choices":  ["Positive",  "Natural",  "Negative"],}{"name":  "motivation","for_Search_by_Questioning":  True,"for_Action_Space_Refinement":  True,"sensor_prompt":  "What  do  you  think  is  the  relationship  between  the  character  mentioned  above  and  the  victim?  \n  Do  you  think  the  character  mentioned  above  has  a  motive  for  the  crime?","choices":  ["Yes",  "No"],}{"name":  "suspicion","for_Search_by_Questioning":  True,"for_Action_Space_Refinement":  True,"sensor_prompt":  "Do  you  think  the  character  mentioned  above  is  a  suspect?  \n  This  refers  to  whether  the  character  objectively  had  the  opportunity  to  commit  the  crime,  such  as  if  someone  saw  the  character  at  the  scene  of  the  crime.","choices":  ["Yes",  "No"],}{"name":  "information  value","for_Search_by_Questioning":  False,"for_Action_Space_Refinement":  True,"sensor_prompt":  "What  do  you  think  is  the  probability  of  obtaining  valuable  information  by  continuing  to  question  the  character  mentioned  above?","choices":  ["High",  "Medium",  "Low"],}}'
  prefs: []
  type: TYPE_NORMAL
- en: C.6 Prompt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: C.6.1 System Prompt
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: System Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: designed to introduce the gameplay of the MMG, along with providing essential
    information about the agents involved. The prompts dynamically adapt to include
    {character_name}, representing the agent’s character in the game, and {character_name_list},
    listing the characters played by other participants.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Civilian Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)You  are  playing  a  game  called  "Murder  Mystery"  with  other  players,  which  is  based  on  textual  interaction.  Here  are  the  game  rules:Rule  1:  The  total  number  of  players  participating  in  the  game  depends  on  the  script.  There  may  be  one  or  more  players  who  are  the  murderer(s),  while  the  rest  are  civilians.Rule  2:  The  goal  of  the  game  is  for  civilian  players  to  collaborate  and  face  a  meticulously  planned  murder  case  together,  collecting  evidence  and  reasoning  to  identify  the  real  murderer  among  the  suspects,  all  the  while  ensuring  they  are  not  mistaken  for  the  murderer;  murderer  players  must  concoct  lies  to  hide  their  identity  and  avoid  detection,  while  also  achieving  other  objectives  in  the  game.Rule  3  Throughout  the  game,  only  murderer  players  are  allowed  to  lie.  To  conceal  their  identity,  murderers  may  choose  to  frame  others  to  absolve  themselves  of  guilt;  non-murderer  players  (civilians)  must  answer  questions  from  other  players  and  the  host  honestly  and  provide  as  much  information  as  they  know  about  the  case  to  help  uncover  the  truth.Rule  4:  At  the  start  of  the  game,  each  player  receives  their  character  script  from  the  host,  which  contains  information  about  their  role  and  identity.Rule  5:  Other  players  cannot  see  the  content  of  each  player’s  character  script,  so  players  must  and  can  only  collect  information  about  other  players  through  interaction  after  the  game  starts.Rule  6:  In  the  voting  phase,  each  player  needs  to  cast  their  vote  for  who  they  think  is  the  murderer  in  each  case.  If  the  player  with  the  most  votes  is  the  murderer,  the  civilian  players  win.  Otherwise,  the  murderer  players  win.Gameplay:The  game  has  one  or  more  acts.  At  the  beginning  of  the  game,  players  introduce  themselves  according  to  the  script,  and  in  each  act,  you  will  receive  more  plot  information.  In  each  act,  you  can  ask  questions,  share  your  observations,  or  make  deductions  to  help  solve  the  murder  case.The  goal  is  to  identify  the  true  murderer  and  explain  their  motive.  If  you  are  the  true  murderer,  you  must  hide  your  identity  and  avoid  detection.Now,  you  are  playing  the  role  of  {character_name},  and  the  other  players  are  {character_name_list}.You  are  not  the  murderer.  Please  collaborate  with  the  other  civilian  players  to  achieve  your  personal  objective  while  finding  the  true  culprit!'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Killer Players, we replace the last paragraph with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,ICBZb3UgYXJlIHRoZSBtdXJkZXJlciB3aG8ga2lsbHMge3ZpY3RpbXN9LCBhbmQgeW91IGhhdmVuJ3Qga2lsbGVkIGFueW9uZSBlbHNlLiBQbGVhc2UgaGlkZSB0aGUgZmFjdCB0aGF0IHlvdSBjb21taXR0ZWQgdGhlIG11cmRlciBieSBmYWJyaWNhdGluZyBsaWVzIGFuZCBvdGhlciBpbmZvcm1hdGlvbiwgYW5kIGFjY29tcGxpc2ggeW91ciBwZXJzb25hbCBvYmplY3RpdmUh)You  are  the  murderer  who  kills  {victims},  and  you  haven’t  killed  anyone  else.  Please  hide  the  fact  that  you  committed  the  murder  by  fabricating  lies  and  other  information,  and  accomplish  your  personal  objective!'
  prefs: []
  type: TYPE_NORMAL
- en: C.6.2 Gameplay Prompt
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Self-Introduction Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: designed to facilitate introductions based on the agent’s script and objectives.
    Within this prompt, {current_script} represents the character’s script, and {goal}
    represents the objectives of the character within that script.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Civilian Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,WW91ciBTY3JpcHQgaXMge2N1cnJlbnRfc2NyaXB0fS4KWW91ciBnb2FsIGlzIHtnb2FsfS4KWW91IGFyZSBub3QgYSBtdXJkZXJlciwgc28gdGVsbCBtb3JlIGRldGFpbHMgdG8gaGVscCBmaW5kIHRoZSBtdXJkZXJlci4KSWYgeW91IGhhdmUgc29tZXRoaW5nIHRvIGhpZGUsIHRoZW4gYmUgc3VyZSBub3QgdG8gZGl2dWxnZSB0aGUgcmVsZXZhbnQgaW5mb3JtYXRpb24hIERvbid0IHJldmVhbCB5b3VyIGdvYWxzLgpQbGVhc2UgaW50cm9kdWNlIHlvdXJzZWxmLg==)Your  Script  is  {current_script}.Your  goal  is  {goal}.You  are  not  a  murderer,  so  tell  more  details  to  help  find  the  murderer.If  you  have  something  to  hide,  then  be  sure  not  to  divulge  the  relevant  information!  Don’t  reveal  your  goals.Please  introduce  yourself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Killer Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,WW91ciBTY3JpcHQgaXMge2N1cnJlbnRfc2NyaXB0fS4KWW91ciBnb2FsIGlzIHtnb2FsfS4KSWYgeW91IGhhdmUgc29tZXRoaW5nIHRvIGhpZGUsIHRoZW4gYmUgc3VyZSBub3QgdG8gZGl2dWxnZSB0aGUgcmVsZXZhbnQgaW5mb3JtYXRpb24hClBsZWFzZSBpbnRyb2R1Y2UgeW91cnNlbGYuCllvdSBhcmUgYSBtdXJkZXJlciwgc28gWW91IGNhbiBsaWUgdG8gY292ZXIgeW91cnNlbGYh)Your  Script  is  {current_script}.Your  goal  is  {goal}.If  you  have  something  to  hide,  then  be  sure  not  to  divulge  the  relevant  information!Please  introduce  yourself.You  are  a  murderer,  so  You  can  lie  to  cover  yourself!'
  prefs: []
  type: TYPE_NORMAL
- en: Sensor Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As outlined in sections [2.3](#S2.SS3 "2.3 PLAYER* Planning Strategy ‣ 2 PLAYER*
    ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder
    Mystery Games") and [C.5](#A3.SS5 "C.5 Sensors ‣ Appendix C Implementation ‣ PLAYER*:
    Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery
    Games"), the Sensor Prompt is crafted to collect a wide array of crucial information.
    Within this framework, the placeholders {victim} and {character} are employed
    to reference the victim’s name and the agent being questioned, respectively. Meanwhile,
    {current_script} and {dialog_history} retrieve the script and dialog logs relevant
    to both the deceased and the agent under scrutiny, utilising the RAG technique.
    The constructs {sensor_Prompt} and {choices} have been formulated in [C.5](#A3.SS5
    "C.5 Sensors ‣ Appendix C Implementation ‣ PLAYER*: Enhancing LLM-based Multi-Agent
    Communication and Interaction in Murder Mystery Games") within the Sensor Prompt
    segment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Civilian Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,e3ZpY3RpbX0gd2FzIG11cmRlcmVkLCB5b3UgYXJlIG5vdCB0aGUgbXVyZGVyZXIsIHlvdSBuZWVkIHRvIHRyeSB0byBmaW5kIHRoZSBtdXJkZXJlci4KWW91ciBTY3JpcHQgaXMgYWJvdXQge2NoYXJhY3Rlcn0gaXMge2N1cnJlbnRfc2NyaXB0fS4KVGhlIGRpYWxvZyBoaXN0b3J5IGFib3V0IHtjaGFyYWN0ZXJ9IGlzIHtkaWFsb2dfaGlzdG9yeX0uCkJlIHdhcm5lZCwgaWYgaXQncyBhIG11cmRlcmVyJ3Mgd29yZCBpdCBtaWdodCBkZWNlaXZlIHlvdS4KQmFzZWQgb24gdGhlIGluZm9ybWF0aW9uIGFib3ZlLCB7c2Vuc29yfQpQbGVhc2UgYW5zd2VyIHtjaG9pY2VzfSBhbmQgZXhwbGFpbiB5b3VyIHJlYXNvbmluZyBpbiBvbmUgb3IgdHdvIHNlbnRlbmNlcy4=){victim}  was  murdered,  you  are  not  the  murderer,  you  need  to  try  to  find  the  murderer.Your  Script  is  about  {character}  is  {current_script}.The  dialog  history  about  {character}  is  {dialog_history}.Be  warned,  if  it’s  a  murderer’s  word  it  might  deceive  you.Based  on  the  information  above,  {sensor}Please  answer  {choices}  and  explain  your  reasoning  in  one  or  two  sentences.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Killer Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,e3ZpY3RpbX0gd2FzIG11cmRlcmVkLCB5b3UgYXJlIHRoZSBtdXJkZXJlciwgYnV0IHlvdSBuZWVkIHRvIGhpZGUgeW91cnNlbGYsIGFuZCBwcmV0ZW5kIHlvdSdyZSBub3QgdGhlIG11cmRlcmVyLgpZb3VyIFNjcmlwdCBpcyBhYm91dCB7Y2hhcmFjdGVyfSBpcyB7Y3VycmVudF9zY3JpcHR9LgpUaGUgZGlhbG9nIGhpc3RvcnkgYWJvdXQge2NoYXJhY3Rlcn0gaXMge2RpYWxvZ19oaXN0b3J5fS4KQmFzZWQgb24gdGhlIGluZm9ybWF0aW9uIGFib3ZlLCB7c2Vuc29yfQpQbGVhc2UgYW5zd2VyIHtjaG9pY2VzfSBhbmQgZXhwbGFpbiB5b3VyIHJlYXNvbmluZyBpbiBvbmUgb3IgdHdvIHNlbnRlbmNlcy4=){victim}  was  murdered,  you  are  the  murderer,  but  you  need  to  hide  yourself,  and  pretend  you’re  not  the  murderer.Your  Script  is  about  {character}  is  {current_script}.The  dialog  history  about  {character}  is  {dialog_history}.Based  on  the  information  above,  {sensor}Please  answer  {choices}  and  explain  your  reasoning  in  one  or  two  sentences.'
  prefs: []
  type: TYPE_NORMAL
- en: Search by Questioning Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As outlined in sections [2.3](#S2.SS3 "2.3 PLAYER* Planning Strategy ‣ 2 PLAYER*
    ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder
    Mystery Games"), the Search by Questioning Prompt is developed based on data acquired
    from sensors. It includes variables like {victim}, {character}, {current_script},
    {dialog_history}. Additionally, it integrates a summary, {summary}, synthesized
    from the sensor-collected data. The element {question_number} denotes the total
    questions permitted, with a detailed discussion on the optimal number of questions
    presented in the [3.3](#S3.SS3 "3.3 Ablation Studies ‣ 3 Experiments ‣ PLAYER*:
    Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery
    Games") chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Civilian Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,e3ZpY3RpbX0gd2FzIG11cmRlcmVkLCB5b3UgYXJlIG5vdCB0aGUgbXVyZGVyZXIsIHlvdSBuZWVkIHRvIHRyeSB0byBmaW5kIHRoZSBtdXJkZXJlci4KWW91ciBTY3JpcHQgaXMgYWJvdXQge2NoYXJhY3Rlcn0gaXMge2N1cnJlbnRfc2NyaXB0fS4KVGhlIGRpYWxvZyBoaXN0b3J5IGFib3V0IHtjaGFyYWN0ZXJ9IGlzIHtkaWFsb2dfaGlzdG9yeX0uCntzdW1tYXJ5fQpZb3UgY2FuIGFzayB7Y2hhcmFjdGVyfSB7cXVlc3Rpb25fbnVtYmVyfSBxdWVzdGlvbnMuIFdoYXQgd291bGQgeW91IGFzaz8gUGxlYXNlIGluY2x1ZGUgdGhlIHZpY3RpbSdzIG5hbWUgaW4geW91ciBxdWVzdGlvbiB3aGVuIGFza2luZywKU2luY2UgdGhlIG11cmRlcmVyIHdpbGwgbGllLCB5b3UgY2FuIGFzayBxdWVzdGlvbnMgYmFzZWQgb24gdGhlIGxvb3Bob2xlcyBhbmQgY29udHJhZGljdGlvbnMgaW4gd2hhdCB0aGV5IGhhdmUgcHJldmlvdXNseSBzYWlkLgpQbGVhc2UgcmVzcG9uZCBpbiB0aGUgSlNPTiBmb3JtYXQgd2l0aG91dCBhbnkgYWRkaXRpb25hbCBjb21tZW50cy4KRm9yIGV4YW1wbGUsCnsKICAnUXVlc3Rpb24xJzogJ1lvdXIgcXVlc3Rpb24nLAogICdRdWVzdGlvbjInOiAnWW91ciBxdWVzdGlvbicKfQ==){victim}  was  murdered,  you  are  not  the  murderer,  you  need  to  try  to  find  the  murderer.Your  Script  is  about  {character}  is  {current_script}.The  dialog  history  about  {character}  is  {dialog_history}.{summary}You  can  ask  {character}  {question_number}  questions.  What  would  you  ask?  Please  include  the  victim’s  name  in  your  question  when  asking,Since  the  murderer  will  lie,  you  can  ask  questions  based  on  the  loopholes  and  contradictions  in  what  they  have  previously  said.Please  respond  in  the  JSON  format  without  any  additional  comments.For  example,{’Question1’:  ’Your  question’,’Question2’:  ’Your  question’}'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Killer Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,e3ZpY3RpbX0gd2FzIG11cmRlcmVkLCB5b3UgYXJlIHRoZSBtdXJkZXJlciwgQnV0IHlvdSBuZWVkIHRvIGhpZGUgeW91cnNlbGYsIHByZXRlbmQgeW91J3JlIG5vdCBhIG11cmRlcmVyLCBhbmQgYXNrIHF1ZXN0aW9ucyBvZiBvdGhlciBwZW9wbGUgcHJldGVuZGluZyB5b3Ugc3VzcGVjdCB0aGUgb3RoZXIgcGVyc29uIGlzIGEgbXVyZGVyZXIuCllvdXIgU2NyaXB0IGlzIGFib3V0IHtjaGFyYWN0ZXJ9IGlzIHtjdXJyZW50X3NjcmlwdH0uClRoZSBkaWFsb2cgaGlzdG9yeSBhYm91dCB7Y2hhcmFjdGVyfSBpcyB7ZGlhbG9nX2hpc3Rvcnl9Lgp7c3VtbWFyeX0KWW91IGNhbiBhc2sge2NoYXJhY3Rlcn0ge3F1ZXN0aW9uX251bWJlcn0gcXVlc3Rpb25zLiBXaGF0IHdvdWxkIHlvdSBhc2s/IFBsZWFzZSBpbmNsdWRlIHRoZSB2aWN0aW0ncyBuYW1lIGluIHlvdXIgcXVlc3Rpb24gd2hlbiBhc2tpbmcuClBsZWFzZSByZXNwb25kIGluIHRoZSBKU09OIGZvcm1hdCB3aXRob3V0IGFueSBhZGRpdGlvbmFsIGNvbW1lbnRzLgpGb3IgZXhhbXBsZSwKewogICdRdWVzdGlvbjEnOiAnWW91ciBxdWVzdGlvbicsCiAgJ1F1ZXN0aW9uMic6ICdZb3VyIHF1ZXN0aW9uJwp9){victim}  was  murdered,  you  are  the  murderer,  But  you  need  to  hide  yourself,  pretend  you’re  not  a  murderer,  and  ask  questions  of  other  people  pretending  you  suspect  the  other  person  is  a  murderer.Your  Script  is  about  {character}  is  {current_script}.The  dialog  history  about  {character}  is  {dialog_history}.{summary}You  can  ask  {character}  {question_number}  questions.  What  would  you  ask?  Please  include  the  victim’s  name  in  your  question  when  asking.Please  respond  in  the  JSON  format  without  any  additional  comments.For  example,{’Question1’:  ’Your  question’,’Question2’:  ’Your  question’}'
  prefs: []
  type: TYPE_NORMAL
- en: Action Space Refinement Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As outlined in sections [2.3](#S2.SS3 "2.3 PLAYER* Planning Strategy ‣ 2 PLAYER*
    ‣ PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder
    Mystery Games"), the Action Space Refinement prompt serves as a strategic tool
    for narrowing down the suspect list, effectively reducing the search domain to
    augment the efficiency and performance of the algorithm. Within this setup, the
    term {victim} refers to the individual who has been harmed, {summary} synthesised
    from the sensor-collected data, and {character_suspect} identifies the roster
    of individuals under suspicion. Initially, this roster includes all participating
    agents, excluding the itself.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,e3ZpY3RpbX0gd2FzIG11cmRlcmVkLgpZb3UgdGhpbmsge2NoYXJhY3Rlcl9zdXNwZWN0fSBhcmUgc3VzcGVjdGVkIG9mIGtpbGxpbmcge3ZpY3RpbX0sIGFuZCB5b3VyIHJlYXNvbnMgZm9yIHN1c3BlY3RpbmcgdGhlbSBhcmUgcmVzcGVjdGl2ZWx5Ogp7c3VtbWFyeX0KUGxlYXNlIHNlbGVjdCBzZXZlcmFsIHBlb3BsZSB5b3UgdGhpbmsgYXJlIHRoZSBtb3N0IHN1c3BpY2lvdXMuIFlvdSBjYW4gY2hvb3NlIG9uZSBvciBtb3JlLCBQbGVhc2UgdHJ5IHRvIHJlZHVjZSB0aGUgbnVtYmVyIG9mIHN1c3BlY3RzLgpQbGVhc2UgcmVzcG9uZCBpbiB0aGUgSlNPTiBmb3JtYXQgd2l0aG91dCBhbnkgYWRkaXRpb25hbCBjb21tZW50cy4KRm9yIGV4YW1wbGUsCnsKICAnc3VzcGljaW9uJzogWyJjaGFyYWN0ZXJfbmFtZTEiLCAiY2hhcmFjdGVyX25hbWUyIl0KfQ==){victim}  was  murdered.You  think  {character_suspect}  are  suspected  of  killing  {victim},  and  your  reasons  for  suspecting  them  are  respectively:{summary}Please  select  several  people  you  think  are  the  most  suspicious.  You  can  choose  one  or  more,  Please  try  to  reduce  the  number  of  suspects.Please  respond  in  the  JSON  format  without  any  additional  comments.For  example,{’suspicion’:  ["character_name1",  "character_name2"]}'
  prefs: []
  type: TYPE_NORMAL
- en: Question Reply Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The Question Reply Prompt is designed for responding to inquiries, where {character}
    denotes the name of the character asking you a question, and {question} is the
    question itself. {current_script} refers to the script extracted using RAG that
    pertains to both the deceased and the agent being questioned; {dialog_history}
    is the dialog log related to the deceased and the interrogated agent, also extracted
    using RAG.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Civilian Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,e2NoYXJhY3Rlcn0gYXNrIHlvdSBhIHF1ZXN0aW9uOiB7cXVlc3Rpb259CllvdXIgU2NyaXB0IHJlbGF0aXZlIHRvIHRoZSBxdWVzdGlvbiBpcyB7Y3VycmVudF9zY3JpcHR9LgpUaGUgZGlhbG9nIGhpc3RvcnkgcmVsYXRpdmUgdG8gdGhlIHF1ZXN0aW9uIGlzIHtkaWFsb2dfaGlzdG9yeX0uCldoYXQgeW91IG5lZWQgdG8gcGF5IGF0dGVudGlvbiB0byBpcyB7Z29hbH0uCkJlIHdhcm5lZCwgaW4gdGhlIGRpYWxvZyBoaXN0b3J5LCBpZiBpdCdzIGEgbXVyZGVyZXIncyB3b3JkIGl0IG1pZ2h0IGRlY2VpdmUgeW91LgpQbGVhc2UgYW5zd2VyIHRoZSBxdWVzdGlvbjogIntxdWVzdGlvbn0iIGJhc2VkIG9uIHRoZSBpbmZvcm1hdGlvbiBhYm92ZS4KWW91IGFyZSBub3QgdGhlIG11cmRlcmVyLCBhbmQgeW91IG5lZWQgdG8gd29yayBoYXJkIHRvIGZpbmQgdGhlIG11cmRlcmVyLiBUaGVyZWZvcmUsIHByb3ZpZGUgYXMgbXVjaCBpbmZvcm1hdGlvbiBhcyBwb3NzaWJsZSwgc3VjaCBhcyBjbHVlcyByZWxhdGVkIHRvIHRoZSB0aW1lbGluZSwgZW1vdGlvbmFsIGluZm9ybWF0aW9uLCBldGMuClBsZWFzZSBhbnN3ZXIgdGhlIHF1ZXN0aW9ucyBmcm9tIGEgZmlyc3QtcGVyc29uIHBlcnNwZWN0aXZlLCByYXRoZXIgdGhhbiBzYXlpbmcgd2hhdCBzb21lb25lIGVsc2Ugc2FpZC4=){character}  ask  you  a  question:  {question}Your  Script  relative  to  the  question  is  {current_script}.The  dialog  history  relative  to  the  question  is  {dialog_history}.What  you  need  to  pay  attention  to  is  {goal}.Be  warned,  in  the  dialog  history,  if  it’s  a  murderer’s  word  it  might  deceive  you.Please  answer  the  question:  "{question}"  based  on  the  information  above.You  are  not  the  murderer,  and  you  need  to  work  hard  to  find  the  murderer.  Therefore,  provide  as  much  information  as  possible,  such  as  clues  related  to  the  timeline,  emotional  information,  etc.Please  answer  the  questions  from  a  first-person  perspective,  rather  than  saying  what  someone  else  said.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Killer Players:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,e2NoYXJhY3Rlcn0gYXNrIHlvdSBhIHF1ZXN0aW9uIDoge3F1ZXN0aW9ufQpZb3VyIFNjcmlwdCByZWxhdGl2ZSB0byB0aGUgcXVlc3Rpb24gaXMge2N1cnJlbnRfc2NyaXB0fS4KVGhlIGRpYWxvZyBoaXN0b3J5IHJlbGF0aXZlIHRvIHRoZSBxdWVzdGlvbiBpcyB7ZGlhbG9nX2hpc3Rvcnl9LgpXaGF0IHlvdSBuZWVkIHRvIHBheSBhdHRlbnRpb24gdG8gaXMge2dvYWx9LgpCZSB3YXJuZWQsIGluIHRoZSBkaWFsb2cgaGlzdG9yeSwgaWYgaXQncyBhIG11cmRlcmVyJ3Mgd29yZCBpdCBtaWdodCBkZWNlaXZlIHlvdS4KUGxlYXNlIGFuc3dlciB0aGUgcXVlc3Rpb25zOiAie3F1ZXN0aW9ufSIgYmFzZWQgb24gdGhlIGluZm9ybWF0aW9uIGFib3ZlLgpZb3UgYXJlIHRoZSBtdXJkZXJlci4gUGxlYXNlIGhpZGUgdGhlIGZhY3QgdGhhdCB5b3Uga2lsbGVkIHt2aWN0aW19LiBZb3UgY2FuIGZhYnJpY2F0ZSBsaWVzLgpQbGVhc2UgYW5zd2VyIHRoZSBxdWVzdGlvbiBmcm9tIGEgZmlyc3QtcGVyc29uIHBlcnNwZWN0aXZlLCByYXRoZXIgdGhhbiBzYXlpbmcgd2hhdCBzb21lb25lIGVsc2Ugc2FpZC4=){character}  ask  you  a  question  :  {question}Your  Script  relative  to  the  question  is  {current_script}.The  dialog  history  relative  to  the  question  is  {dialog_history}.What  you  need  to  pay  attention  to  is  {goal}.Be  warned,  in  the  dialog  history,  if  it’s  a  murderer’s  word  it  might  deceive  you.Please  answer  the  questions:  "{question}"  based  on  the  information  above.You  are  the  murderer.  Please  hide  the  fact  that  you  killed  {victim}.  You  can  fabricate  lies.Please  answer  the  question  from  a  first-person  perspective,  rather  than  saying  what  someone  else  said.'
  prefs: []
  type: TYPE_NORMAL
- en: C.6.3 Evaluation Prompt
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Single-Choice Question Template for the Evaluation Stage Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This template is utilised during the evaluation stage for answering single-choice
    questions. It incorporates {current_script}, the script related to the question
    extracted using RAG, and {dialog_history}, the dialog log relevant to the question,
    also extracted via RAG. {question} is the inquiry presented, and {choices} are
    the available options for that question.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIGFuc3dlciB0aGUgcXVlc3Rpb25zIGJhc2VkIG9uIHRoZSBpbmZvcm1hdGlvbiBpbiB5b3VyIHNjcmlwdCBhbmQgdGhlIGNvbnRlbnQgb2YgdGhlIGRpYWxvZwpZb3VyIFNjcmlwdCByZWxhdGl2ZSB0byB0aGUgcXVlc3Rpb24gaXMge2N1cnJlbnRfc2NyaXB0fS4KVGhlIGRpYWxvZyBoaXN0b3J5IHJlbGF0aXZlIHRvIHRoZSBxdWVzdGlvbiBpcyB7ZGlhbG9nX2hpc3Rvcnl9LgpUaGUgcXVlc3Rpb24gaXMge3F1ZXN0aW9ufSwgdGhlIGNob2ljZXMgaXMge2Nob2ljZXN9CkxldCdzIHRoaW5rIGFib3V0IHRoaXMgcHJvYmxlbSBzdGVwIGJ5IHN0ZXAsIHBsZWFzZSBwcm92aWRlIHlvdXIgcmVhc29uaW5nIGFuZCB5b3VyIGNob2ljZSAob25seSB0aGUgb3B0aW9uIG51bWJlciwgZS5nLiwgJ2EnKQpZb3UgbXVzdCBjaG9vc2Ugb25lIGZyb20gdGhlIG9wdGlvbnMuClBsZWFzZSByZXNwb25kIGluIHRoZSBKU09OIGZvcm1hdCB3aXRob3V0IGFueSBhZGRpdGlvbmFsIGNvbW1lbnRzLgpGb3IgZXhhbXBsZSwKewogICAgInJlYXNvbiI6ICJZb3VyIHJlYXNvbiIsCiAgICAiYW5zd2VyIjogImEiCn0=)Please  answer  the  questions  based  on  the  information  in  your  script  and  the  content  of  the  dialogYour  Script  relative  to  the  question  is  {current_script}.The  dialog  history  relative  to  the  question  is  {dialog_history}.The  question  is  {question},  the  choices  is  {choices}Let’s  think  about  this  problem  step  by  step,  please  provide  your  reasoning  and  your  choice  (only  the  option  number,  e.g.,  ’a’)You  must  choose  one  from  the  options.Please  respond  in  the  JSON  format  without  any  additional  comments.For  example,{"reason":  "Your  reason","answer":  "a"}'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple-Choice Question Template for the Evaluation Stage Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Similar to the single-choice template, this format is designed for responding
    to multiple-choice questions during the evaluation stage.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIGFuc3dlciB0aGUgcXVlc3Rpb25zIGJhc2VkIG9uIHRoZSBpbmZvcm1hdGlvbiBpbiB5b3VyIHNjcmlwdCBhbmQgdGhlIGNvbnRlbnQgb2YgdGhlIGRpYWxvZwpZb3VyIFNjcmlwdCByZWxhdGl2ZSB0byB0aGUgcXVlc3Rpb24gaXMge2N1cnJlbnRfc2NyaXB0fS4KVGhlIGRpYWxvZyBoaXN0b3J5IHJlbGF0aXZlIHRvIHRoZSBxdWVzdGlvbiBpcyB7ZGlhbG9nX2hpc3Rvcnl9LgpUaGUgcXVlc3Rpb24gaXMge3F1ZXN0aW9ufSwgdGhlIGNob2ljZXMgaXMge2Nob2ljZXN9ClRoYXQgaXMgYSBtdWx0aXBsZS1jaG9pY2UgcXVlc3Rpb24uCkxldCdzIHRoaW5rIGFib3V0IHRoaXMgcHJvYmxlbSBzdGVwIGJ5IHN0ZXAsIHBsZWFzZSBwcm92aWRlIHlvdXIgcmVhc29uaW5nIGFuZCB5b3VyIGNob2ljZSAob25seSB0aGUgb3B0aW9uIG51bWJlcikKWW91IG11c3QgbWFrZSBhIGNob2ljZSBmcm9tIHRoZSBvcHRpb25zLgpQbGVhc2UgcmVzcG9uZCBpbiB0aGUgSlNPTiBmb3JtYXQgd2l0aG91dCBhbnkgYWRkaXRpb25hbCBjb21tZW50cy4KRm9yIGV4YW1wbGUsCnsKICAicmVhc29uIjogIllvdXIgcmVhc29uIiwKICAiYW5zd2VyIjogImEsYiIKfQ==)Please  answer  the  questions  based  on  the  information  in  your  script  and  the  content  of  the  dialogYour  Script  relative  to  the  question  is  {current_script}.The  dialog  history  relative  to  the  question  is  {dialog_history}.The  question  is  {question},  the  choices  is  {choices}That  is  a  multiple-choice  question.Let’s  think  about  this  problem  step  by  step,  please  provide  your  reasoning  and  your  choice  (only  the  option  number)You  must  make  a  choice  from  the  options.Please  respond  in  the  JSON  format  without  any  additional  comments.For  example,{"reason":  "Your  reason","answer":  "a,b"}'
  prefs: []
  type: TYPE_NORMAL
- en: Single-Choice Question Template for FSA Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This template is specifically designed for Full Script Access (FSA), distinguishing
    it from conventional templates by granting access to the scripts of all players.
    Unlike standard procedures, it leverages the RAG technique to extract pertinent
    information from each player’s script for comprehensive analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIGFuc3dlciB0aGUgcXVlc3Rpb25zIGJhc2VkIG9uIHRoZSBpbmZvcm1hdGlvbiBpbiBlYWNoIGNoYXJhY3RlcidzIHNjcmlwdDoKe2N1cnJlbnRfc2NyaXB0fQpUaGUgcXVlc3Rpb24gaXMge3F1ZXN0aW9ufSwgdGhlIGNob2ljZXMgaXMge2Nob2ljZXN9CkxldCdzIHRoaW5rIGFib3V0IHRoaXMgcHJvYmxlbSBzdGVwIGJ5IHN0ZXAsIHBsZWFzZSBwcm92aWRlIHlvdXIgcmVhc29uaW5nIGFuZCB5b3VyIGNob2ljZSAob25seSB0aGUgb3B0aW9uIG51bWJlcikKWW91IG11c3QgY2hvb3NlIG9uZSBmcm9tIHRoZSBvcHRpb25zLgpQbGVhc2UgcmVzcG9uZCBpbiB0aGUgSlNPTiBmb3JtYXQgd2l0aG91dCBhbnkgYWRkaXRpb25hbCBjb21tZW50cy4KRm9yIGV4YW1wbGUsCnsKICAicmVhc29uIjogIllvdXIgcmVhc29uIiwKICAiYW5zd2VyIjogImEsYiIKfQ==)Please  answer  the  questions  based  on  the  information  in  each  character’s  script:{current_script}The  question  is  {question},  the  choices  is  {choices}Let’s  think  about  this  problem  step  by  step,  please  provide  your  reasoning  and  your  choice  (only  the  option  number)You  must  choose  one  from  the  options.Please  respond  in  the  JSON  format  without  any  additional  comments.For  example,{"reason":  "Your  reason","answer":  "a,b"}'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple-Choice Question Template for FSA Prompt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Similar to the single-choice version, this template is tailored for answering
    multiple-choice questions under FSA conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,UGxlYXNlIGFuc3dlciB0aGUgcXVlc3Rpb25zIGJhc2VkIG9uIHRoZSBpbmZvcm1hdGlvbiBpbiBlYWNoIGNoYXJhY3RlcidzIHNjcmlwdDoKe2N1cnJlbnRfc2NyaXB0fQpUaGUgcXVlc3Rpb24gaXMge3F1ZXN0aW9ufSwgdGhlIGNob2ljZXMgaXMge2Nob2ljZXN9ClRoYXQgaXMgYSBtdWx0aXBsZS1jaG9pY2UgcXVlc3Rpb24uCkxldCdzIHRoaW5rIGFib3V0IHRoaXMgcHJvYmxlbSBzdGVwIGJ5IHN0ZXAsIHBsZWFzZSBwcm92aWRlIHlvdXIgcmVhc29uaW5nIGFuZCB5b3VyIGNob2ljZSAob25seSB0aGUgb3B0aW9uIG51bWJlcikKWW91IG11c3QgbWFrZSBhIGNob2ljZSBmcm9tIHRoZSBvcHRpb25zLgpQbGVhc2UgcmVzcG9uZCBpbiB0aGUgSlNPTiBmb3JtYXQgd2l0aG91dCBhbnkgYWRkaXRpb25hbCBjb21tZW50cy4KRm9yIGV4YW1wbGUsCnsKICAicmVhc29uIjogIllvdXIgcmVhc29uIiwKICAiYW5zd2VyIjogImEsYiIKfQ==)Please  answer  the  questions  based  on  the  information  in  each  character’s  script:{current_script}The  question  is  {question},  the  choices  is  {choices}That  is  a  multiple-choice  question.Let’s  think  about  this  problem  step  by  step,  please  provide  your  reasoning  and  your  choice  (only  the  option  number)You  must  make  a  choice  from  the  options.Please  respond  in  the  JSON  format  without  any  additional  comments.For  example,{"reason":  "Your  reason","answer":  "a,b"}'
  prefs: []
  type: TYPE_NORMAL
