- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:48:21'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:48:21'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AgentCoord：视觉探索LLM基础的多智能体协作协调策略
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.11943](https://ar5iv.labs.arxiv.org/html/2404.11943)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.11943](https://ar5iv.labs.arxiv.org/html/2404.11943)
- en: \onlineid
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \onlineid
- en: '0 \vgtccategoryResearch \vgtcpapertypeApplication/Design Study \authorfooter
    Bo Pan, Jiaying Lu, Ke Wang, Li Zheng, Zhen Wen, Yingchaojie Feng, and Wei Chen
    are with the State Key Lab of CAD&CG, Zhejiang University, and Wei Chen is also
    with the Laboratory of Art and Archaeology Image (Zhejiang University), Ministry
    of Education, China. E-mail: {bopan $|$ chenvis}@zju.edu.cn. Minfeng Zhu is with
    Zhejiang University. E-mail: minfeng_zhu@zju.edu.cn.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 0 \vgtccategoryResearch \vgtcpapertypeApplication/Design Study \authorfooter
    Bo Pan, Jiaying Lu, Ke Wang, Li Zheng, Zhen Wen, Yingchaojie Feng, 和 Wei Chen
    皆来自浙江大学CAD&CG国家重点实验室，Wei Chen 还在中国教育部艺术与考古图像实验室（浙江大学）。电子邮件：{bopan $|$ chenvis}@zju.edu.cn。Minfeng
    Zhu 也在浙江大学。电子邮件：minfeng_zhu@zju.edu.cn。
- en: Bo Pan    Jiaying Lu    Ke Wang    Li Zheng    Zhen Wen    Yingchaojie Feng
       Minfeng Zhu    and Wei Chen
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Bo Pan    Jiaying Lu    Ke Wang    Li Zheng    Zhen Wen    Yingchaojie Feng
       Minfeng Zhu    和 Wei Chen
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The potential of automatic task-solving through Large Language Model (LLM)-based
    multi-agent collaboration has recently garnered widespread attention from both
    the research community and industry. While utilizing natural language to coordinate
    multiple agents presents a promising avenue for democratizing agent technology
    for general users, designing coordination strategies remains challenging with
    existing coordination frameworks. This difficulty stems from the inherent ambiguity
    of natural language for specifying the collaboration process and the significant
    cognitive effort required to extract crucial information (e.g. agent relationship,
    task dependency, result correspondence) from a vast amount of text-form content
    during exploration. In this work, we present a visual exploration framework to
    facilitate the design of coordination strategies in multi-agent collaboration.
    We first establish a structured representation for LLM-based multi-agent coordination
    strategy to regularize the ambiguity of natural language. Based on this structure,
    we devise a three-stage generation method that leverages LLMs to convert a user’s
    general goal into an executable initial coordination strategy. Users can further
    intervene at any stage of the generation process, utilizing LLMs and a set of
    interactions to explore alternative strategies. Whenever a satisfactory strategy
    is identified, users can commence the collaboration and examine the visually enhanced
    execution result. We develop AgentCoord, a prototype interactive system, and conduct
    a formal user study to demonstrate the feasibility and effectiveness of our approach.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型（LLM）的多智能体协作在自动任务解决方面的潜力最近引起了研究界和工业界的广泛关注。虽然利用自然语言来协调多个智能体为普通用户普及智能体技术提供了有前景的途径，但在现有的协调框架中设计协调策略仍然具有挑战性。这种困难源于自然语言在指定协作过程中的固有模糊性，以及在探索过程中从大量文本内容中提取关键信息（例如智能体关系、任务依赖、结果对应）所需的显著认知努力。在这项工作中，我们提出了一个视觉探索框架，以促进多智能体协作中协调策略的设计。我们首先建立了一个结构化的LLM基础的多智能体协调策略表示，以规范自然语言的模糊性。基于这一结构，我们设计了一种三阶段生成方法，利用LLMs将用户的一般目标转换为可执行的初始协调策略。用户可以在生成过程中的任何阶段进一步干预，利用LLMs和一组交互来探索替代策略。当确定了令人满意的策略时，用户可以开始协作并检查视觉增强的执行结果。我们开发了AgentCoord，一个原型交互系统，并进行了一项正式用户研究，以展示我们方法的可行性和有效性。
- en: 'keywords:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '关键词:'
- en: Large language model, LLM-based agent, Multi-agent collaboration, visual exploration,
    natural language interface.\teaser![A view of a city with buildings peeking out
    of the clouds.](img/8d9248529c38cd38a44dbd4913be0755.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型、基于LLM的智能体、多智能体协作、视觉探索、自然语言接口。\teaser![一座城市的景象，建筑物从云层中隐现。](img/8d9248529c38cd38a44dbd4913be0755.png)
- en: 'Our visual exploration framework for coordination strategy design: The user
    first enters a general goal for agent collaboration (a). The system conducts a
    three-stage generation (i.e., Plan Outline Generation (b), Agent Assignment (c),
    and Task Process Generation (d)) to provide an initial strategy. The user interactively
    explores alternative strategies for each stage with the help of LLMs (e, f, g).
    Once satisfied, the user commences the collaboration and examines the visually
    enhanced execution results (h).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的协调策略设计可视化探索框架：用户首先输入代理协作的一般目标（a）。系统进行三阶段生成（即计划大纲生成（b）、代理分配（c）和任务过程生成（d）），以提供初步策略。用户在LLMs的帮助下（e,
    f, g）交互式地探索每个阶段的替代策略。满意后，用户开始协作并检查视觉增强的执行结果（h）。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Large Language Model (LLM) based agents, which are capable of observing, making
    decisions, and performing actions with the reasoning capabilities of LLM, have
    undergone significant improvements, showing great potential in various areas such
    as programming[[12](#bib.bib12), [25](#bib.bib25)], creative writing[[3](#bib.bib3),
    [33](#bib.bib33), [44](#bib.bib44)], and question answering [[39](#bib.bib39),
    [28](#bib.bib28)]. While initial forays into the realm of LLM-based agents focused
    on solitary agent system[[10](#bib.bib10), [42](#bib.bib42)], the concept of multi-agent
    collaboration—mirroring the cooperative interactions among humans—has started
    to pique the interest of the AI research community. Drawing inspiration from the
    synergistic outcomes observed in human teamwork[[7](#bib.bib7), [37](#bib.bib37),
    [20](#bib.bib20)], a burgeoning body of research has been investigating and validating
    the benefits (e.g. expand expertise[[27](#bib.bib27), [28](#bib.bib28)], enhance
    reliability [[2](#bib.bib2), [6](#bib.bib6), [25](#bib.bib25)], encourage divergent
    thinking[[15](#bib.bib15), [45](#bib.bib45)]) brought about by LLM-based multi-agent
    collaboration.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大型语言模型（LLM）的代理能够进行观察、决策和行动，具备LLM的推理能力，已经取得了显著的进展，展示了在编程[[12](#bib.bib12),
    [25](#bib.bib25)]、创意写作[[3](#bib.bib3), [33](#bib.bib33), [44](#bib.bib44)]和问答[[39](#bib.bib39),
    [28](#bib.bib28)]等各个领域的巨大潜力。尽管最初的LLM代理系统主要关注单一代理系统[[10](#bib.bib10), [42](#bib.bib42)]，但多代理协作的概念——类似于人类之间的合作互动——开始引起AI研究界的关注。受到人类团队合作中协同效应的启发[[7](#bib.bib7),
    [37](#bib.bib37), [20](#bib.bib20)]，一系列新兴的研究正在探索和验证LLM基础的多代理协作所带来的好处（例如，扩展专业知识[[27](#bib.bib27),
    [28](#bib.bib28)]、增强可靠性[[2](#bib.bib2), [6](#bib.bib6), [25](#bib.bib25)]、鼓励发散性思维[[15](#bib.bib15),
    [45](#bib.bib45)]）。
- en: 'In order to facilitate the coordination of multi-agent collaboration, the open-source
    community emerges a multitude of frameworks for prototyping LLM-based multi-agent
    systems. Existing multi-agent frameworks can be divided into two categories based
    on how users can specify or intervene in the collaborative process: code-based
    and natural language-based. For code-based frameworks [[12](#bib.bib12), [25](#bib.bib25),
    [38](#bib.bib38), [21](#bib.bib21), [29](#bib.bib29), [4](#bib.bib4)], users need
    to hard-code the coordination strategies (e.g. the division of tasks, the assignment
    of agents, the flow of massages) directly into the code, which requires code skill
    and learning cost. The natural language-based frameworks[[3](#bib.bib3), [38](#bib.bib38)]
    ¹¹1AutoGen [[38](#bib.bib38)] supports both code-based and natural language-based
    paradiam. In its “group chat mode”, the coordination strategy can be expressed
    in free-form natural language and coordinated by a chat manager., which directly
    uses natural languages to specify the coordination strategies, could be a promising
    way to democratize agent technology for broader general users. Additionally, given
    that LLMs inherently possess coordinating capabilities and rich domain knowledge
    across different tasks, the natural language-based frameworks can easily leverage
    LLMs to assist in drafting and refining the coordination strategies represented
    in natural language[[3](#bib.bib3)].'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进多智能体协作的协调，开源社区出现了大量用于原型设计的基于LLM的多智能体系统框架。现有的多智能体框架可以根据用户如何指定或干预协作过程分为两类：基于代码的和基于自然语言的。对于基于代码的框架[[12](#bib.bib12),
    [25](#bib.bib25), [38](#bib.bib38), [21](#bib.bib21), [29](#bib.bib29), [4](#bib.bib4)]，用户需要将协调策略（例如任务分配、代理分配、信息流）硬编码到代码中，这需要编程技能和学习成本。基于自然语言的框架[[3](#bib.bib3),
    [38](#bib.bib38)] ¹¹1AutoGen [[38](#bib.bib38)] 支持基于代码和基于自然语言的范式。在其“群聊模式”下，协调策略可以用自由形式的自然语言表达，并由聊天管理器协调，这直接使用自然语言来指定协调策略，可能是使智能体技术民主化的一种有前途的方法。此外，鉴于LLM本身具有协调能力和丰富的领域知识，基于自然语言的框架可以轻松利用LLM来协助起草和完善用自然语言表示的协调策略[[3](#bib.bib3)]。
- en: 'However, designing coordination strategies remains challenging with existing
    natural language-based frameworks. First, the flexibility of natural language
    could be a double-edged sword: on one hand, it allows users to freely design and
    express their coordination strategies; on the other hand, overly flexible expressions
    can make the devised collaboration strategies ambiguous, often requiring users
    repeatedly engage in remedial specification to ensure the execution of the collaboration
    doesn’t stray from its intended course. Second, representing and exploring coordination
    strategies in pure text format faces challenges as the complexity of the collaboration
    process and team organization rises. Users can easily get lost in the “text jam”
    where important information (e.g. agent relationship, task dependency, result
    correspondence, strategy discrepancy) they care about at certain points during
    exploration is drowned in blocks of text. Therefore, novel approaches are highly
    desirable to enhance the current natural language-based design process.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，利用现有基于自然语言的框架设计协调策略仍然具有挑战性。首先，自然语言的灵活性可能是把双刃剑：一方面，它允许用户自由设计和表达协调策略；另一方面，过于灵活的表达可能使设计出的协作策略模糊不清，通常需要用户反复进行补充说明，以确保协作的执行不偏离其预定方向。其次，随着协作过程和团队组织的复杂性增加，以纯文本格式表示和探索协调策略面临挑战。用户很容易在“文本拥堵”中迷失，其中他们在探索过程中关注的重要信息（例如代理关系、任务依赖、结果对应、策略差异）被淹没在大量文本中。因此，非常需要新的方法来增强当前基于自然语言的设计过程。
- en: 'This work thus presents a visual exploration framework for efficiently designing
    coordination strategies for LLM-based multi-agent collaboration. To exploit the
    flexibility of natural language while incorporating a level of organization to
    regularize its ambiguity, we analyze the common concepts and structures found
    in the description for coordination strategy in a corpus of 25 LLM-based multi-agent
    collaboration papers and 7 high-star projects ²²2The corpus can be found in our
    project repository., based on which we establish a structured representation for
    LLM-based Multi-agent coordination strategy. This structure lays a foundational
    scaffolding for the entire exploration process. Based on this structure, we design
    a generation method that exploits the coordinating capabilities and domain knowledge
    of LLMs to map the general goal provided by users (AgentCoord: Visually Exploring
    Coordination Strategy for LLM-based Multi-Agent Collaboration <svg id="S1.p4.1.pic1"
    class="ltx_picture" height="13.7" overflow="visible" version="1.1" width="13.7"><g
    transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g
    stroke-width="0.9pt" fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0 0.0
    0.0 1.0 -3.46 -2.98)"><foreignobject width="6.92" height="5.96" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#44AAA8">a</foreignobject></g></g></svg>)
    into an executable initial coordination strategy to help users kick off the exploration.
    To ensure coherence among various parts of the generated strategy, we divide the
    generation process into three stages: Plan Outline Generation (AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration <svg id="S1.p4.2.pic2"
    class="ltx_picture" height="13.7" overflow="visible" version="1.1" width="13.7"><g
    transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g
    stroke-width="0.9pt" fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0 0.0
    0.0 1.0 -3.84 -4.8)"><foreignobject width="7.69" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#44AAA8">b</foreignobject></g></g></svg>)
    for an overall collaboration plan to achieve the goal, Agent Assignment (AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration
    <svg id="S1.p4.3.pic3" class="ltx_picture" height="13.7" overflow="visible" version="1.1"
    width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0)
    translate(0,6.85)"><g stroke-width="0.9pt" fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0
    0.0 0.0 1.0 -3.07 -2.98)"><foreignobject width="6.15" height="5.96" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#44AAA8">c</foreignobject></g></g></svg>)
    for each task in the plan outline, and Task Process Generation (AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration <svg id="S1.p4.4.pic4"
    class="ltx_picture" height="13.7" overflow="visible" version="1.1" width="13.7"><g
    transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g
    stroke-width="0.9pt" fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0 0.0
    0.0 1.0 -3.84 -4.8)"><foreignobject width="7.69" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#44AAA8">d</foreignobject></g></g></svg>)
    for specifying how assigned agents collaboratively finish the task. To streamline
    users’ exploration and iterative refinement for alternative strategies, we propose
    a set of interactions (AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration <svg id="S1.p4.5.pic5" class="ltx_picture"
    height="13.7" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g stroke-width="0.9pt"
    fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0 0.0 0.0 1.0 -3.07 -2.98)"><foreignobject
    width="6.15" height="5.96" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#44AAA8">e</foreignobject></g></g></svg> <svg id="S1.p4.6.pic6" class="ltx_picture"
    height="13.7" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g stroke-width="0.9pt"
    fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0 0.0 0.0 1.0 -2.11 -4.8)"><foreignobject
    width="4.23" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#44AAA8">f</foreignobject></g></g></svg> <svg id="S1.p4.7.pic7" class="ltx_picture"
    height="13.7" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g stroke-width="0.9pt"
    fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -1.63)"><foreignobject
    width="6.92" height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#44AAA8">g</foreignobject></g></g></svg>) to help users visually explore
    the design space for each generation stage with the help of LLMs. Whenever users
    are satisfied with a certain strategy, they can initiate the collaboration and
    examine the execution result which is visually enhanced and linked with previous
    stages for efficient verification (AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration <svg id="S1.p4.8.1.pic1" class="ltx_picture"
    height="13.7" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g stroke-width="0.9pt"
    fill="#44AAA8" stroke="#44AAA8" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject
    width="7.69" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#44AAA8">h</foreignobject></g></g></svg>).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'To validate the feasibility and effectiveness of this framework, we developed
    an interactive system called AgentCoord that enables users to visually explore
    coordination strategies for LLM-based multi-agent collaboration, effectively integrating
    the prior of LLMs and users during design. Our user study, involving 12 users
    with a general interest in LLM-based multi-agent collaboration, suggests that
    our approach can effectively facilitate the design process for LLM-based multi-agent
    coordination strategies and has the potential to democratize agent coordination
    for broader users. In summary, our contributions include:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证该框架的可行性和有效性，我们开发了一个名为AgentCoord的互动系统，允许用户可视化探索LLM基多代理协作的协调策略，有效地将LLMs和用户的先验知识整合到设计过程中。我们的用户研究涉及12名对LLM基多代理协作有一般兴趣的用户，表明我们的方法可以有效地促进LLM基多代理协调策略的设计过程，并有可能让更广泛的用户参与代理协调。总之，我们的贡献包括：
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A visual exploration framework that enables general users to efficiently design
    coordination strategy for LLM-based multi-agent collaboration.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个可视化探索框架，使普通用户能够高效设计LLM基多代理协作的协调策略。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'AgentCoord ³³3Project Repository: https://github.com/AgentCoord/AgentCoord,
    an open-source interactive system that instantiates our framework with a set of
    interactions and visual designs to facilitate coordination strategy exploration.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AgentCoord ³³3项目仓库：[https://github.com/AgentCoord/AgentCoord](https://github.com/AgentCoord/AgentCoord)，一个开源的互动系统，体现了我们的框架，提供了一组互动和视觉设计以促进协调策略探索。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A formal user study that demonstrates the feasibility and effectiveness of our
    approach.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个正式的用户研究展示了我们方法的可行性和有效性。
- en: 2 Related Work
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLM-Based Multi-Agent Collaboration
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 基于LLM的多代理协作
- en: Large language models (LLMs) have recently demonstrated impressive capabilities
    as versatile task-solving agents, attracting substantial interest in both industry
    and academia [[32](#bib.bib32), [41](#bib.bib41)]. Since LLMs are trained on natural
    language corpus that is biased toward human thinking [[45](#bib.bib45)] and optimized
    for conversation [[23](#bib.bib23)], LLM-based agents can collaborate through
    natural language in a human-like manner and harness a range of benefits that come
    with collaboration.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）最近展示了作为多功能任务解决代理的令人印象深刻的能力，引起了工业界和学术界的广泛关注 [[32](#bib.bib32), [41](#bib.bib41)]。由于LLMs是在偏向于人类思维的自然语言语料上训练的
    [[45](#bib.bib45)] 并且优化了对话 [[23](#bib.bib23)]，基于LLMs的代理可以通过自然语言以类人方式进行协作，并利用协作带来的多种好处。
- en: Recent works have initiated attempts to coordinate agents with varied expertise
    in order to improve outcomes on a wide spectrum of tasks that benefit from a diversity
    of knowledge. Medagent [[28](#bib.bib28)] collects medical agents with different
    specialties to provide a comprehensive analysis of patient’s conditions and treatment
    options. MetaGPT [[12](#bib.bib12)] and ChatDev [[25](#bib.bib25)] enable agents
    with different roles such as product managers, designers, and programmers to collaborate
    in software development, thereby improving the quality of the software produced.
    MARG[[5](#bib.bib5)] develops a framework for integrating the proficiency of multiple
    expert agents to review scientific papers. AutoAgents[[3](#bib.bib3)] and OKR-Agent[[44](#bib.bib44)]
    demonstrate how creative content tasks, such as creative writing and storyboard
    generation, can benefit from the collaboration of agents with diverse domain backgrounds.
    AgentVerse[[4](#bib.bib4)] showcases a scenario in which multiple experts with
    different backgrounds collaborate to deliver a hydrogen storage station siting
    solution.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究尝试协调具有不同专业知识的代理，以改善广泛任务的结果，这些任务从知识的多样性中受益。Medagent [[28](#bib.bib28)] 收集了不同专业的医疗代理，以提供对患者状况和治疗选项的全面分析。MetaGPT
    [[12](#bib.bib12)] 和 ChatDev [[25](#bib.bib25)] 使得产品经理、设计师和程序员等具有不同角色的代理能够在软件开发中协作，从而提高软件的质量。MARG
    [[5](#bib.bib5)] 开发了一个框架，以整合多个专家代理的专业知识来审阅科学论文。AutoAgents [[3](#bib.bib3)] 和 OKR-Agent
    [[44](#bib.bib44)] 展示了如何通过具有不同领域背景的代理的协作来改进创意内容任务，如创意写作和故事板生成。AgentVerse [[4](#bib.bib4)]
    展示了一个场景，其中背景不同的多个专家协作提供氢气存储站点解决方案。
- en: Additionally, recent studies have discovered that multiple agents can work together
    to foster cognitive synergy [[20](#bib.bib20)] similar to humans. Chan et al.
    request multiple agents to delve into the discussion from diverse perspectives
    to catalyze a comprehensive assessment that is greater than the sum of their separate
    assessments. Liang et al.[[15](#bib.bib15)] and Du et al.[[6](#bib.bib6)] let
    multiple agents to debate with each other to encourage deeper levels of contemplation.
    Zhuge et al.[[45](#bib.bib45)] propose the concept of “mindstorm” to describe
    how multiple agents take multiple rounds of communication to iterate the ideas
    to find a solution that is often superior to any individual solution.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Despite the potential of multi-agent collaboration shown in various fields,
    most works require coding to design coordination strategies for agents, limiting
    accessibility for broader general users. While AutoGen [[38](#bib.bib38)] and
    AutoAgents [[3](#bib.bib3)] support representing coordination strategies in pure
    natural language, users still encounter a series of issues when using natural
    language to explore and design coordination strategies. Our work attempts to address
    these issues with structured generation of coordination strategies and a set of
    visualization approaches to facilitate users’ understanding and exploration of
    the coordination strategies.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Generating Coordination Strategy using LLMs
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although LLM-based agents have shown tremendous potential in collaboratively
    completing tasks, manually designing coordination strategies is often challenging,
    time-consuming, and sometimes requires expertise in specific domain knowledge
    [[14](#bib.bib14)]. Thus, it is highly desirable to leverage LLM’s inherent coordinating
    capabilities and prior knowledge across different tasks to aid in designing coordination
    strategies for agent collaboration.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Many works on multi-agent collaboration leverage the prior knowledge of LLMs
    for the formation and adjustment of agent teams. Wang et al. [[33](#bib.bib33)]
    prompt LLM to dynamically identify a set of agent roles in response to a task
    query. Medagent [[28](#bib.bib28)] prompts LLM to work as a medical expert who
    specializes in categorizing a specific medical scenario into specific areas of
    medicine and gathering corresponding expert agents. DyLAN [[18](#bib.bib18)] leverages
    LLM to score the performance of agents and dynamically optimize the team organization
    during collaboration. The AgentBuilder module of Autogen [[38](#bib.bib38)] prompts
    LLM to generate system prompts for multiple agents based on the current task and
    add them to a group chat for collaboration. AutoAgents [[3](#bib.bib3)] designs
    an LLM-based Agent Observer to check the compliance of the agent with the requirements
    and make suggestions for adjustments.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are also widely utilized to aid in planning the collaboration process of
    multiple agents. For example, AutoAgents [[3](#bib.bib3)] prompt LLMs to draft
    a collaboration plan that specifies the agents involved in each step and the expected
    outputs. In Autogen’s group chat mode [[38](#bib.bib38)], the user can play the
    role of an Admin agent to draft and refine the collaboration plan together with
    an LLM-based Planner agent. OKR-agent [[44](#bib.bib44)] leverage LLMs to recursively
    decompose the tasks for teams of agents. Further, AgentVerse [[4](#bib.bib4)]
    designs a collaborative decision-making stage for multiple LLM-based agents to
    make short-term planning.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLM还广泛用于协助规划多个代理的协作过程。例如，AutoAgents [[3](#bib.bib3)]促使LLM起草一个协作计划，指定每一步涉及的代理及预期输出。在Autogen的群聊模式[[38](#bib.bib38)]中，用户可以扮演管理员代理的角色，与LLM基础的规划代理一起起草和完善协作计划。OKR-agent
    [[44](#bib.bib44)]利用LLM递归分解代理团队的任务。此外，AgentVerse [[4](#bib.bib4)]为多个LLM基础的代理设计了一个协作决策阶段，以进行短期规划。
- en: Our work focuses more on how to leverage LLM to facilitate general users in
    designing their own multi-agent coordination strategy. To achieve this, we propose
    an LLM-based three-stage generation method to generate a structured coordination
    strategy based on the user’s goal. Additionally, we propose a set of interactions
    to assist users in flexibly exploiting the coordination ability of LLMs during
    exploration.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作更侧重于如何利用LLM帮助普通用户设计自己的多代理协调策略。为此，我们提出了一种基于LLM的三阶段生成方法，以根据用户的目标生成结构化的协调策略。此外，我们还提出了一套交互方式，以帮助用户在探索过程中灵活地利用LLM的协调能力。
- en: 2.3 Interface for LLM-based Agents
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 基于LLM的代理接口
- en: During the execution of LLM-based agents, a multitude of intricate information
    is involved, which is hard to digest with a plain text terminal [[35](#bib.bib35),
    [19](#bib.bib19)]. Therefore, it is highly desirable to have some interfaces to
    assist in understanding and intervening in the execution process. Early interfaces
    [[26](#bib.bib26), [40](#bib.bib40), [30](#bib.bib30)] for monitoring single LLM-based
    agents typically feature an outline view that maps out the overall execution process,
    complemented by detailed text blocks enhanced with highlighting and icons. For
    systems[[24](#bib.bib24), [16](#bib.bib16), [43](#bib.bib43), [25](#bib.bib25)]
    that deploys multiple agents in a virtual sandbox environment, a panoramic view
    is usually provided to transform text-form information into concrete visual elements
    (e.g. moving agent avatars, expressive emojis) for easier comprehension of the
    overall process. Topological structures such as trees and graphs are also utilized
    to visualize and manage the execution processes of agents. SPROUT[[17](#bib.bib17)]
    employs a tree structure to assist users in visualizing and controlling the process
    of an agent composing code tutorials. Hong et al. [[11](#bib.bib11)] use a hierarchical
    graph structure to manage the execution process of a data science agent and allow
    users to interactively edit the graph during execution. AutoGen [[38](#bib.bib38)]
    introduces a transition graph to allow users to constrain agent transition to
    mitigate the risk of sub-optimal agent transitions during multi-agent collaboration
    in Group Chat mode. Recently, AgentLens [[19](#bib.bib19)] initiated the first
    attempt to design a visual analysis system to assist users in analyzing the agent
    behaviors in LLM-based multi-agent systems.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行基于LLM的代理时，涉及大量复杂的信息，单靠文本终端难以消化[[35](#bib.bib35), [19](#bib.bib19)]。因此，拥有一些界面来辅助理解和干预执行过程是非常可取的。早期的界面[[26](#bib.bib26),
    [40](#bib.bib40), [30](#bib.bib30)] 通常具有一个概述视图，展示整体执行过程，并辅以详细的文本块，增强了高亮和图标。对于在虚拟沙盒环境中部署多个代理的系统[[24](#bib.bib24),
    [16](#bib.bib16), [43](#bib.bib43), [25](#bib.bib25)]，通常提供全景视图，将文本信息转化为具体的视觉元素（例如移动的代理头像、表情丰富的表情符号），以便更容易理解整体过程。拓扑结构，如树形图和图表，也被用来可视化和管理代理的执行过程。SPROUT[[17](#bib.bib17)]采用树形结构来帮助用户可视化和控制代理编写代码教程的过程。Hong等人[[11](#bib.bib11)]使用层次图结构来管理数据科学代理的执行过程，并允许用户在执行过程中互动编辑图表。AutoGen
    [[38](#bib.bib38)]引入了过渡图，允许用户限制代理的过渡，以减少在Group Chat模式下多代理协作时的次优过渡风险。最近，AgentLens
    [[19](#bib.bib19)]首次尝试设计一个视觉分析系统，以帮助用户分析LLM基础的多代理系统中的代理行为。
- en: Extending this line of work, our work enables general users to visually explore
    coordination strategies for LLM-based multi-agent collaboration.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展这一领域的工作，我们的工作使普通用户能够直观地探索基于LLM的多智能体协作的协调策略。
- en: 3 Formative Study
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 形成性研究
- en: To gain insight into how users use current natural language-based frameworks
    to coordinate multiple LLM-based agents and identify the challenges that exist
    during the exploration process for coordination strategy, we carried out a formative
    study. Based on the findings in the formative study, we formulated four design
    requirements to enhance the process of designing coordination strategies for LLM-based
    multi-agent collaboration.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了深入了解用户如何使用当前的基于自然语言的框架来协调多个基于LLM的智能体，并识别在协调策略的探索过程中存在的挑战，我们进行了形成性研究。根据形成性研究中的发现，我们制定了四个设计要求，以改善基于LLM的多智能体协作的协调策略设计过程。
- en: 3.1 Participants and Procedure
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 参与者与程序
- en: We recruited 8 participants who have experience or general interest in LLM-based
    multi-agent collaboration from the local university and online discussion platforms
    for open-source multi-agent frameworks. Four of them are experienced experts in
    LLM-based multi-agent systems (E1 and E2 are NLP researchers familiar with LLM-based
    multi-agent collaboration, while E3 and E4 are developers having experience in
    constructing multi-agent systems). Another four of them (G1-4) are general users
    who have a basic understanding of LLM-based agents and are interested in building
    their own LLM-based multi-agent collaboration strategy.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从当地大学和开源多智能体框架的在线讨论平台中招募了8名对基于LLM的多智能体协作有经验或一般兴趣的参与者。他们中的四人是具有丰富经验的专家（E1和E2是熟悉基于LLM的多智能体协作的NLP研究人员，而E3和E4是有构建多智能体系统经验的开发者）。另外四人（G1-4）是对基于LLM的智能体有基本了解并对构建自己的基于LLM的多智能体协作策略感兴趣的一般用户。
- en: 'Procedure: In our formative interviews, we initially asked the participants
    about their prior experience with any LLM-based multi-agent framework or system.
    Afterward, we show participants how to use natural language to specify the coordination
    strategy for multi-agent collaboration using AutoAgents [[3](#bib.bib3)] alongside
    a text editor and the “group chat mode” of AutoGen[[38](#bib.bib38)]. After the
    participants got familiar with the usage, they were asked to choose a task that
    could benefit from collaboration among multiple LLM-based agents and construct
    their own coordination strategy with both systems separately. The participants
    can also use ChatGPT to assist them in designing coordination strategies during
    the process. Finally, we gathered feedback on participants’ experience during
    the construction of the coordination strategy and inquiry about the challenges
    they faced during the process. For participants who reported prior experience
    with any LLM-based multi-agent framework at the start of the interview, we also
    asked them to compare the strengths and weaknesses of natural language-based methods
    with previous frameworks they have used.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 程序：在我们的形成性访谈中，我们首先询问了参与者他们之前是否有使用基于LLM的多智能体框架或系统的经验。随后，我们向参与者展示了如何使用自然语言来指定多智能体协作的协调策略，使用工具包括AutoAgents
    [[3](#bib.bib3)]、文本编辑器和AutoGen的“群聊模式”[[38](#bib.bib38)]。在参与者熟悉了使用方法后，我们要求他们选择一个可以从多个基于LLM的智能体协作中受益的任务，并分别利用这两个系统构建他们自己的协调策略。参与者还可以在这个过程中使用ChatGPT来帮助他们设计协调策略。最后，我们收集了参与者在构建协调策略过程中的体验反馈，并询问了他们在过程中遇到的挑战。对于在访谈开始时报告有使用过任何基于LLM的多智能体框架经验的参与者，我们还要求他们比较基于自然语言的方法与他们之前使用过的框架的优缺点。
- en: 3.2 Findings
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 发现
- en: All participants find using natural language to design coordination strategies
    is intuitive and could be a promising approach to democratizing agent coordination
    for a wider general audience. However, several challenges are also identified,
    which hinder the participants’ current exploration process to design coordination
    strategies at their will.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者发现使用自然语言设计协调策略是直观的，并且可能是一个有前途的方法，可以使更广泛的普通用户能够实现智能体协调。然而，也识别出了一些挑战，这些挑战阻碍了参与者在自主设计协调策略时的探索过程。
- en: 'Lack of structure to regularize the ambiguity of natural language. Although
    natural language is easy to understand and highly expressive, it is prone to ambiguity.
    For example, for a high-level cooperation strategy description “Pharmaceutical
    Chemist, Patent Agent, and Clinical Research Scientist collaboratively drafting
    a patent application”, there could be many ambiguous aspects: “Who takes the main
    responsibility for drafting?”, “How are opinions integrated?”… During the formative
    study, we notice that users often start with a generated collaborative strategy
    and then, upon observing the unexpected outcomes, identify areas that were not
    articulated and make remedial enhancements to the original cooperation strategy.
    After several rounds, the collaborative strategy specification “could be lengthy
    and messy to read” (G4), and “sometimes even contain self-conflicts” (G3). Both
    E1 and E4 suggest that “some structures should be provided to regularize the design
    process” (E1, E4), which can “draw on designs from current code-based frameworks”
    (E1).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏结构来规范自然语言的模糊性。虽然自然语言易于理解且表现力强，但它容易产生模糊性。例如，对于“制药化学家、专利代理人和临床研究科学家共同起草专利申请”这样的高层次合作策略描述，可能存在许多模糊的方面：“谁负责主要起草？”、“如何整合意见？”……在形成性研究过程中，我们注意到用户通常从生成的合作策略开始，然后在观察到意外结果后，识别未被明确表达的领域并对原始合作策略进行补救性改进。经过几轮后，合作策略规范“可能会变得冗长且混乱”
    (G4)，“有时甚至包含自我冲突” (G3)。E1和E4都建议“应该提供一些结构来规范设计过程” (E1, E4)，这可以“借鉴当前基于代码的框架中的设计”
    (E1)。
- en: Lost in the vast amount of intricate text. During the process of designing collaborative
    strategies, users need to refer to a substantial amount of text information (e.g.,
    previously designed collaborative strategies, descriptions of different agents,
    input/output of agents, intermediate objects). The vast amount of intricate text
    poses significant cognitive overhead on users during the design process. Many
    participants express the feeling that the quantity of text is “overwhelming” (E3,
    E4, G1-G4). They usually needed to “manually switch back and forth between different
    parts of the texts” (G2) and “sometimes forget where to find” (G3). E3 mentioned
    that “as the complexity of my strategy rises, maintain a clear connection between
    specific execution result and the corresponding part of my strategy become challenging”
    (E3). The Participants also express the need to “have a visual interface that
    helps organize information” (G2, E3).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在大量复杂文本中迷失。在设计合作策略的过程中，用户需要参考大量文本信息（例如，之前设计的合作策略、不同代理的描述、代理的输入/输出、中间对象）。大量复杂的文本在设计过程中给用户带来了显著的认知负担。许多参与者表达了文本数量“令人不堪重负”的感觉
    (E3, E4, G1-G4)。他们通常需要“在不同文本部分之间手动来回切换” (G2) 并且“有时忘记在哪里找到” (G3)。E3提到“随着我的策略复杂性的增加，保持特定执行结果与我策略相应部分的清晰连接变得具有挑战性”
    (E3)。参与者还表达了“拥有一个帮助组织信息的可视化界面”的需求 (G2, E3)。
- en: Lack of interactions support to facilitate exploration. To leverage the powerful
    coordination capabilities of LLMs and deal with “writer’s block”, participants
    often chat with LLMs (e.g. using ChatGPT) to aid them in drafting and exploring
    coordination strategies. However, the linear non-reversible conversation interface
    for chatting is not designed for iterative multi-thread exploration. E2 mentioned
    that “managing exploration history and toggling between different possibilities
    with manual copy & paste is cumbersome” (E2). Additionally, participants also
    mentioned concerns over the fluidity of exploration due to the need for “manually
    craft auxiliary prompts for different exploration purposes” (G2). Moreover, due
    to the stochastic nature of LLM outputs (which is also greatly affected by prompts)
    and diverse possibilities for strategy design, participants express the need for
    “an interface to help systematically explore and compare different outputs by
    LLM” (G1).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏互动支持以促进探索。为了利用LLMs的强大协调能力并解决“写作障碍”，参与者常常与LLMs（例如使用ChatGPT）聊天，以帮助他们起草和探索协调策略。然而，线性的不可逆对话界面并不适合迭代的多线程探索。E2提到“管理探索历史和在不同可能性之间切换需要手动复制和粘贴，非常繁琐”
    (E2)。此外，参与者还提到，由于需要“手动制作不同探索目的的辅助提示”，探索的流畅性也令人担忧 (G2)。而且，由于LLM输出的随机性（也受到提示的巨大影响）和策略设计的多样性，参与者表达了对“一个帮助系统地探索和比较不同LLM输出的界面”的需求
    (G1)。
- en: 3.3 Design Requirement
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 设计需求
- en: 'In response to the problems identified in the formative study, our goal is
    to develop an interactive system to help general users smoothly explore and design
    coordination strategies for LLM-based Multi-agent collaboration. The design requirements
    are summarized as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 针对形成性研究中发现的问题，我们的目标是开发一个互动系统，帮助普通用户顺利探索和设计基于LLM的多智能体协作的协调策略。设计需求总结如下：
- en: 'R1: Generate a structured coordination strategy for the user’s goal. Although
    using natural language to describe a coordination strategy lowers the barrier
    for users and brings a high level of flexibility, users often lack an effective
    way to deal with its ambiguity. Therefore, the system should provide a structure
    of coordination strategy to help regularize the ambiguity inherent in natural
    language and serve as a scaffolding for downstream exploration. Moreover, to help
    the user kick off, the system should be able to generate an initial coordination
    strategy based on the user’s goal leveraging the coordination capability of LLMs.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: R1：为用户的目标生成结构化的协调策略。虽然使用自然语言描述协调策略降低了用户的门槛，并带来了较高的灵活性，但用户往往缺乏有效的方法来处理其模糊性。因此，系统应提供协调策略的结构，以帮助规范自然语言固有的模糊性，并作为下游探索的支架。此外，为了帮助用户启动，系统应能够根据用户的目标生成初步的协调策略，利用大型语言模型（LLMs）的协调能力。
- en: 'R2: Provide an effective visual organization for the strategy. When users are
    devising a coordination strategy, they need to refer to various types of relevant
    information represented in the text. However, at present, users have to flip back
    and forth through a vast amount of plain text to search for target information
    and do verification, which creates a significant cognitive load. Therefore, the
    system should effectively visually organize and enhance the various pieces of
    information involved in the coordination strategy design process to help users
    quickly locate the information they need and provide the relevant context.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: R2：为策略提供有效的视觉组织。当用户制定协调策略时，他们需要参考文本中表示的各种相关信息。然而，目前用户不得不在大量纯文本中来回翻阅以搜索目标信息和进行验证，这造成了显著的认知负担。因此，系统应有效地视觉组织和增强协调策略设计过程中的各种信息，以帮助用户快速定位所需信息并提供相关背景。
- en: 'R3: Support flexible interactions to facilitate strategy exploration. Users
    often need to explore various possible options at different stages of the coordination
    strategy design with the help of LLMs; however, iterative exploration based on
    a linear chat interface with LLMs is cumbersome and unintuitive. Therefore, the
    system should support flexible and intuitive interactions to help users conduct
    multi-thread iterative exploration. Moreover, the system needs to offer assistance
    to help systematically explore and compare different design choices for coordination
    strategies.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: R3：支持灵活的交互以促进策略探索。用户通常需要在协调策略设计的不同阶段，借助LLMs探索各种可能的选项；然而，基于线性交互界面的迭代探索繁琐且不直观。因此，系统应支持灵活而直观的交互，帮助用户进行多线程的迭代探索。此外，系统需要提供帮助，以系统性地探索和比较不同的协调策略设计选择。
- en: 'R4: Provide visual enhancement for the execution result. During the execution
    of collaborative tasks, agents generate a substantial amount of textual information.
    However, at present, both code-based and natural language-based agent coordination
    frameworks only output results through a plain text terminal. Users often have
    to manually switch back and forth between different parts of the coordination
    strategy and the execution results to establish connections, which increases cognitive
    load and decreases analytical efficiency. Therefore, the system needs to provide
    visual enhancements to help users examine execution results.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: R4：提供执行结果的视觉增强。在协作任务的执行过程中，代理生成了大量的文本信息。然而，目前基于代码和自然语言的代理协调框架都仅通过纯文本终端输出结果。用户往往需要手动来回切换协调策略的不同部分和执行结果之间，以建立连接，这增加了认知负担，降低了分析效率。因此，系统需要提供视觉增强，帮助用户检查执行结果。
- en: 4 Structured Coordination Strategy Generation
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结构化协调策略生成
- en: 'In this section, we abstract a structured representation for coordination strategy
    design (Section [4.1](#S4.SS1 "4.1 Structured Representation for Coordination
    Strategy ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")) to
    regularize the ambiguity of natural language (R1). Based on this structure, a
    three-stage generation method (Section [4.2](#S4.SS2 "4.2 Three-stage Strategy
    Generation ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")) has
    been designed to automatically generate an initial coordination strategy based
    on the user’s goal (R1).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Structured Representation for Coordination Strategy
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To maximize the expressiveness of the structure defined for coordination strategy,
    E1-4 and we collaboratively survey a corpus of 25 LLM-based Multi-agent collaboration
    papers and 7 high star open source frameworks [[12](#bib.bib12), [14](#bib.bib14),
    [38](#bib.bib38), [21](#bib.bib21), [3](#bib.bib3), [25](#bib.bib25), [4](#bib.bib4)]
    for Multi-agent coordination. We analyze the common concepts and structures found
    in the description for coordination strategy in those papers and projects, based
    on which we establish a common structure for LLM-based Multi-agent coordination
    strategy.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'We depict the relationship between key concepts involved in the coordination
    strategy structure as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Plan Outline: Provides a blueprint for the overall collaboration, typically
    breaking the objectives down into a sequence of Tasks to be carried out one after
    the other.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Task: Takes Key Objects as input and output its target Key Object. The task
    process specifies how Agents collaboratively finished the task.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Key Object: Important intermediate objects during collaboration.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agent: Intelligent entity that can perform Action according to its observation
    and Instruction.'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Action: The smallest unit of agent behavior observable.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Instruction: Natural language-based specification that tells agent what/how
    to do.'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 4.2 Three-stage Strategy Generation
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To help users kick off the exploration, we design a three-stage generation method
    to provide an initial coordination strategy based on the goal of the user, leveraging
    the coordination capability of LLM. Details of all the prompts used can be found
    in our project repository.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '4.2.1 Stage1: Plan Outline Generation'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Given a general description of the goal $g$ contains the following attributes:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step Name: A clear and concise name summarizing the step.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Task Content: Task description of the current step.'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Input Object List: The input key objects that will be used in the current step.'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Output Object: The output key object of the current step.'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To achieve this, we prompt the LLM to serve as an expert plan outline designer
    to carefully analyze and decompose the goal provided by the user and output the
    plan outline $\mathcal{P}$:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{P}=\text{LLM}(g,\mathcal{I},\texttt{prompt}_{\texttt{stage1}})$
    |  | (1) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{P}=\text{LLM}(g,\mathcal{I},\texttt{prompt}_{\texttt{stage1}})$
    |  | (1) |'
- en: '4.2.2 Stage2: Agent Assignment'
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 阶段2：代理分配
- en: After the plan outline is generated, a team of agents $\mathcal{A}_{i}=\{agent_{1},agent_{2},...,agent_{n\}}$
    can be obtained through role prompting[[42](#bib.bib42)], LLM fine-tuning[[34](#bib.bib34)],
    retrieval-augmented generation (RAG) [[13](#bib.bib13)], or even recruitment from
    an agent store[[1](#bib.bib1), [22](#bib.bib22), [31](#bib.bib31)]. Each agent
    should have a profile to describe its expertise for the coordinator’s reference.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 生成计划大纲后，可以通过角色提示[[42](#bib.bib42)]、LLM微调[[34](#bib.bib34)]、检索增强生成（RAG）[[13](#bib.bib13)]，甚至从代理商店[[1](#bib.bib1)、[22](#bib.bib22)、[31](#bib.bib31)]招聘来获得代理团队$\mathcal{A}_{i}=\{agent_{1},agent_{2},...,agent_{n\}}$。每个代理应有一个档案以描述其专业技能，以供协调者参考。
- en: 'To make suitable agent assignment for each task $t_{i}$:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个任务$t_{i}$进行合适的代理分配：
- en: '|  | $\mathcal{A}_{i}=\text{LLM}(g,t_{i},\mathcal{AB},\texttt{prompt}_{\texttt{stage2}})$
    |  | (2) |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{A}_{i}=\text{LLM}(g,t_{i},\mathcal{AB},\texttt{prompt}_{\texttt{stage2}})$
    |  | (2) |'
- en: '![Refer to caption](img/67a57dd0c38af78c30c02c7a02286a18.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/67a57dd0c38af78c30c02c7a02286a18.png)'
- en: 'Figure 1: System interface of AgentCoord. The first three views (Plan Outline
    View, Agent Assignment View, Task Process View) correspond to the three-stage
    coordination strategy generation process while the last view presents the execution
    result.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：AgentCoord系统界面。前三个视图（计划大纲视图、代理分配视图、任务过程视图）对应三阶段协调策略生成过程，而最后一个视图展示执行结果。
- en: '4.2.3 Stage3: Task Process Generation'
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3 阶段3：任务过程生成
- en: 'Once the team of agents $\mathcal{A}_{i}$. Here each action contains the following
    attributes:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦形成代理团队$\mathcal{A}_{i}$，每个动作包含以下属性：
- en: •
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Agent Name: The name of the agent to conduct this action.'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代理名称：执行此动作的代理名称。
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Instruction: The instruction for this action, tells the agent what/how to do.'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指令：该动作的指令，告知代理如何做。
- en: •
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interaction Type: Classify the action based on cooperative interaction type,
    which can be one of “propose” (propose something that may contribute to the current
    task), “critique” (provide feedback to the action result of other agents), “improve”
    (improve the result of a previous action), and “finalize” (deliver the final result
    for current task based on previous actions).'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 互动类型：根据合作互动类型对动作进行分类，可能是“propose”（提出可能有助于当前任务的建议）、“critique”（对其他代理的动作结果提供反馈）、“improve”（改善前一个动作的结果）和“finalize”（根据之前的动作提供当前任务的最终结果）。
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Important Input: Previous information that is important for performing current
    action, which can be certain action results of other agents or previous key objects.'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要输入：对执行当前动作至关重要的先前信息，可以是其他代理的某些动作结果或之前的关键对象。
- en: Note that although it is enough to use “Agent Name” and “Description” to define
    an action for execution, here we propose two auxiliary attributes (“Interaction
    Type” and “Important Input”) to help articulate its relationship with other actions
    in the context of collaboration.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管使用“Agent Name”和“Description”来定义执行的动作已经足够，但在这里我们建议添加两个辅助属性（“Interaction
    Type”和“Important Input”），以帮助阐明其在协作背景下与其他动作的关系。
- en: 'To generate the specification for the task process $t_{i}$:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为任务过程$t_{i}$生成规格说明：
- en: '|  | $\mathcal{S}_{i}=\text{LLM}(g,t_{i},\mathcal{A}_{i},\texttt{prompt}_{\texttt{stage3}})$
    |  | (3) |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{S}_{i}=\text{LLM}(g,t_{i},\mathcal{A}_{i},\texttt{prompt}_{\texttt{stage3}})$
    |  | (3) |'
- en: 5 AgentCoord System
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 AgentCoord系统
- en: 'In this section, we elaborate on how AgentCoord System visually organizes the
    coordination strategy (Section [5.1](#S5.SS1 "5.1 Visual Organization for Coordination
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration")) to facilitate user’s comprehension
    (R2), provides interactions to assist alternative strategy exploration (R3) (Section
    [5.2](#S5.SS2 "5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord
    System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration")), and visually enhances the text form execution result to aid
    examination (R4) (Section [5.3](#S5.SS3 "5.3 Execution Result Examination ‣ 5
    AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration")). To facilitate understanding of the system usage,
    we illustrate it through an example that coordinates multiple LLM-based agents
    in writing a novel.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们详细阐述了 AgentCoord 系统如何以视觉方式组织协调策略（第 [5.1](#S5.SS1 "5.1 视觉组织协调策略 ‣ 5 AgentCoord
    系统 ‣ AgentCoord: 视觉探索基于 LLM 的多代理协作协调策略") 节）以便用户理解（R2），提供互动以协助替代策略的探索（R3）（第 [5.2](#S5.SS2
    "5.2 替代策略的互动探索 ‣ 5 AgentCoord 系统 ‣ AgentCoord: 视觉探索基于 LLM 的多代理协作协调策略") 节），并通过视觉增强文本形式的执行结果以辅助检查（R4）（第
    [5.3](#S5.SS3 "5.3 执行结果检查 ‣ 5 AgentCoord 系统 ‣ AgentCoord: 视觉探索基于 LLM 的多代理协作协调策略")
    节）。为了便于理解系统的使用，我们通过一个示例来说明如何协调多个基于 LLM 的代理编写小说。'
- en: 5.1 Visual Organization for Coordination Strategy
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 协调策略的视觉组织
- en: 'To first obtain an initial coordination strategy to kick off the exploration,
    the user clicks the ![[Uncaptioned image]](img/23995d64fff5d7848bb95b427d11e5be.png)
    icon in agent board ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2
    Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") ![[Uncaptioned image]](img/830757ef5521764214acc503cf5d6ecb.png))
    to add a pool of candidate agents, and enters “Write a novel about the awakening
    of artificial intelligence” as the general goal for the collaboration. After a
    while, the system returns an initial coordination strategy that specifies how
    several agents selected from the agent board collaboratively reach the given goal.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '为了首先获得初步的协调策略以启动探索，用户点击 ![[未标注的图像]](img/23995d64fff5d7848bb95b427d11e5be.png)
    图标（见 [图 1](#S4.F1 "在 4.2.2 阶段2: 代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord:
    视觉探索基于 LLM 的多代理协作协调策略") ![[未标注的图像]](img/830757ef5521764214acc503cf5d6ecb.png)）在代理板中添加一组候选代理，并将“写一部关于人工智能觉醒的小说”作为协作的一般目标。过一会儿，系统返回一个初步的协调策略，指定了从代理板中选择的多个代理如何协作以实现给定的目标。'
- en: 'As illustrated in [Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2
    Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration"), the generated coordination strategy is visually organized into
    four sub-views. In particular, the first three sub-views— Plan Outline View ([Fig. 1](#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ![[Uncaptioned image]](img/60ade06fec71e4b5d030319f23ac6dc9.png)),
    Agent Board View ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage
    Strategy Generation ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")
    ![[Uncaptioned image]](img/bf39622378b4a0907cc0ef488705a8a3.png)), and Task Process
    View ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy
    Generation ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") ![[Uncaptioned
    image]](img/e2488d371179579dd9cdb06a324619cb.png))—correspond to the three-stage
    coordination strategy generation process described in Section [4.2](#S4.SS2 "4.2
    Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration"). The user can scroll vertically within each view to review the
    respective aspects. Furthermore, when the user gets interested in information
    about a specific task, clicking on it will reveal details and visually connect
    its relevant information across the other views.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图1](#S4.F1 "在4.2.2阶段2：代理分配 ‣ 4.2三阶段策略生成 ‣ 4结构化协调策略生成 ‣ AgentCoord：针对基于LLM的多代理协作的协调策略可视化探索")所示，生成的协调策略被直观地组织为四个子视图。特别是前三个子视图——计划概览视图
    ([图1](#S4.F1 "在4.2.2阶段2：代理分配 ‣ 4.2三阶段策略生成 ‣ 4结构化协调策略生成 ‣ AgentCoord：针对基于LLM的多代理协作的协调策略可视化探索")
    ![[未标注的图片]](img/60ade06fec71e4b5d030319f23ac6dc9.png))，代理面板视图 ([图1](#S4.F1 "在4.2.2阶段2：代理分配
    ‣ 4.2三阶段策略生成 ‣ 4结构化协调策略生成 ‣ AgentCoord：针对基于LLM的多代理协作的协调策略可视化探索") ![[未标注的图片]](img/bf39622378b4a0907cc0ef488705a8a3.png))，以及任务处理视图
    ([图1](#S4.F1 "在4.2.2阶段2：代理分配 ‣ 4.2三阶段策略生成 ‣ 4结构化协调策略生成 ‣ AgentCoord：针对基于LLM的多代理协作的协调策略可视化探索")
    ![[未标注的图片]](img/e2488d371179579dd9cdb06a324619cb.png))——对应于第[4.2节](#S4.SS2 "4.2三阶段策略生成
    ‣ 4结构化协调策略生成 ‣ AgentCoord：针对基于LLM的多代理协作的协调策略可视化探索")中描述的三阶段协调策略生成过程。用户可以在每个视图中垂直滚动以查看相关方面。此外，当用户对特定任务的信息感兴趣时，点击该任务将显示详细信息，并在其他视图中直观地连接其相关信息。
- en: 'Plan Outline View illustrates how the general goal input by the user is decomposed
    into a series of step tasks. To elucidate the dependencies between different tasks,
    we use a bipartite graph to represent the relationship between the set of key
    objects ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage
    Strategy Generation ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")
    ![[Uncaptioned image]](img/bb4cc23d3b1230d9b2f95afe4398937a.png)) and task sequence
    of the whole process ( [Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2
    Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") ![[Uncaptioned image]](img/d80fad8fe625cfa87aac688ad972e357.png)).
    A key object node can be the output of a task node or provided by the user by
    clicking the ![[Uncaptioned image]](img/d23b26a6dcea047b6e18181064418226.png)
    button in [Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage
    Strategy Generation ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")
    ![[Uncaptioned image]](img/01f34974d0167f325b8e3b758f2cfa20.png). A task node
    is connected with its input key objects with edge colored in green, and connected
    with its output key object with edge colored in orange. Furthermore, by clicking
    on a task node ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage
    Strategy Generation ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")
    ![[Uncaptioned image]](img/6c09c4a112cf4a587a92641b140e0f10.png)), the user can
    manually adjust the task content and the dependence it has on other key objects.
    If the user wants to explore alternative plan outlines, they can click on the
    ![[Uncaptioned image]](img/2f75311bc8c8efa46a55cc1549da06af.png) button to invoke
    Plan Outline Exploration View (detailed in Section [5.2.1](#S5.SS2.SSS1 "5.2.1
    Plan Outline Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy
    ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration")).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '计划大纲视图展示了用户输入的一般目标如何被分解为一系列步骤任务。为了阐明不同任务之间的依赖关系，我们使用二分图来表示关键对象集合（[图 1](#S4.F1
    "在 4.2.2 阶段2: 代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord: 视觉化探索 LLM 基于多代理协作的协调策略")
    ![[未标注的图片]](img/bb4cc23d3b1230d9b2f95afe4398937a.png)）与整个过程的任务序列（[图 1](#S4.F1
    "在 4.2.2 阶段2: 代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord: 视觉化探索 LLM 基于多代理协作的协调策略")
    ![[未标注的图片]](img/d80fad8fe625cfa87aac688ad972e357.png)）之间的关系。一个关键对象节点可以是任务节点的输出，或者通过点击[图
    1](#S4.F1 "在 4.2.2 阶段2: 代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord: 视觉化探索 LLM
    基于多代理协作的协调策略") ![[未标注的图片]](img/d23b26a6dcea047b6e18181064418226.png)中的按钮由用户提供。任务节点通过绿色边连接到其输入关键对象，并通过橙色边连接到其输出关键对象。此外，通过点击任务节点（[图
    1](#S4.F1 "在 4.2.2 阶段2: 代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord: 视觉化探索 LLM
    基于多代理协作的协调策略") ![[未标注的图片]](img/6c09c4a112cf4a587a92641b140e0f10.png)），用户可以手动调整任务内容及其对其他关键对象的依赖。如果用户想要探索替代的计划大纲，可以点击
    ![[未标注的图片]](img/2f75311bc8c8efa46a55cc1549da06af.png) 按钮以调用计划大纲探索视图（详见第 [5.2.1](#S5.SS2.SSS1
    "5.2.1 计划大纲探索 ‣ 5.2 替代策略的互动探索 ‣ 5 代理协调系统 ‣ AgentCoord: 视觉化探索 LLM 基于多代理协作的协调策略")
    节）。'
- en: 'Agent Board View exhibits all agents the user can assign during the coordination
    strategy design process. By default, each agent card ([Fig. 1](#S4.F1 "In 4.2.2
    Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ![[Uncaptioned image]](img/601a00e436fc5e2d18504caaf641435d.png))
    presents the agent’s name, avatar, and profile for the user’s reference. If the
    user is currently focused on a specific task, the agents assigned to that task
    will be automatically elevated to the top of the agent board. Additionally, the
    actions planned to be executed by an agent in the current task are aggregated
    and showcased within its agent card ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment
    ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") ![[Uncaptioned image]](img/3ec271e3d0dfe87b583f39bf38dab9bd.png)),
    helping user better understand the role it plays in the current task. If the user
    wants to explore alternative agent assignments for the current task, they can
    click on the ![[Uncaptioned image]](img/409a43810a8086240b02c70e59faa75d.png)
    button to invoke Agent Assignment Exploration View (detailed in Section [5.2.2](#S5.SS2.SSS2
    "5.2.2 Agent Assignment Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration")).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 'Agent Board View 显示了用户在协调策略设计过程中可以分配的所有代理。默认情况下，每个代理卡片（[图 1](#S4.F1 "在 4.2.2
    Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: 视觉化探索基于 LLM 的多代理协作的协调策略") ![[无标题图像]](img/601a00e436fc5e2d18504caaf641435d.png)）展示了代理的姓名、头像和简介供用户参考。如果用户当前专注于某个特定任务，分配给该任务的代理将自动提升到代理板的顶部。此外，计划由代理在当前任务中执行的操作被汇总并展示在其代理卡片内（[图
    1](#S4.F1 "在 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation
    ‣ 4 Structured Coordination Strategy Generation ‣ AgentCoord: 视觉化探索基于 LLM 的多代理协作的协调策略")
    ![[无标题图像]](img/3ec271e3d0dfe87b583f39bf38dab9bd.png)），帮助用户更好地理解其在当前任务中扮演的角色。如果用户想要探索当前任务的替代代理分配，他们可以点击
    ![[无标题图像]](img/409a43810a8086240b02c70e59faa75d.png) 按钮，调用代理分配探索视图（详见第 [5.2.2](#S5.SS2.SSS2
    "5.2.2 代理分配探索 ‣ 5.2 替代策略的互动探索 ‣ 5 AgentCoord 系统 ‣ AgentCoord: 视觉化探索基于 LLM 的多代理协作的协调策略")
    节）。'
- en: 'Task Process View provides a natural language description of how the task processes
    are conducted. To enhance the user’s comprehension of the descriptions, we offer
    a template-based summary ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment ‣
    4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") ![[Uncaptioned image]](img/b4fd4ab0abbd78c8fef5d0d3f527d320.png))
    for each task, in which crucial elements are visually accentuated—input key objects
    are highlighted in green, output key objects in orange, and both agent names and
    task content are set against a grey background. The user can click the template-based
    summary for a task to unveil detailed specifications for the task process ([Fig. 1](#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ![[Uncaptioned image]](img/605b1df148ab76b97dffb90483dbb00c.png)).
    The task process specification is composed of a sequence of descriptions about
    how each agent performs its action to contribute to the task. To facilitate the
    user’s understanding of this process in terms of cooperative interaction, we use
    different colors to highlight the interaction type for each action according to
    the “interaction type” classification criteria explained in Section [4.2.3](#S4.SS2.SSS3
    "4.2.3 Stage3: Task Process Generation ‣ 4.2 Three-stage Strategy Generation ‣
    4 Structured Coordination Strategy Generation ‣ AgentCoord: Visually Exploring
    Coordination Strategy for LLM-based Multi-Agent Collaboration"). Moreover, the
    user is able to manually adjust the instruction for each action. If the user wants
    to explore alternative task process specifications, they can click on the ![[Uncaptioned
    image]](img/f09e92b2f6be5bf4d38be078320827ec.png) button to invoke Task Process
    Exploration View (detailed in Section [5.2.3](#S5.SS2.SSS3 "5.2.3 Task Process
    Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord
    System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration")).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Interactive Exploration for Alternative Strategy
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Upon understanding the current coordination strategy, users can interactively
    explore its alternatives across three specific aspects: Plan Outline (Section
    [5.1](#S5.SS1 "5.1 Visual Organization for Coordination Strategy ‣ 5 AgentCoord
    System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration")), Agent Assignment (Section [5.2](#S5.SS2 "5.2 Interactive Exploration
    for Alternative Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring
    Coordination Strategy for LLM-based Multi-Agent Collaboration")), and Task Process
    (Section [5.3](#S5.SS3 "5.3 Execution Result Examination ‣ 5 AgentCoord System
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration")). For each aspect, we provide an illustrative exploration example
    of the user to showcase the supported interactions.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.1 Plan Outline Exploration
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/38c772323aedb55702e7f500a222fc4c.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: An illustrative example of plan outline exploration.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the plan outline shown in [Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent
    Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy
    Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration"), the user finds most key elements (e.g. “Main Theme”,
    “Character List”) for the novel are determined before the “Plot Development” task
    while the last two tasks (“Writing Draft”, “Review and Editing”) are less interesting
    common routines. Therefore, the user decides to merge the last two tasks into
    one step and explore more possibilities for the tasks before “Plot Development”.
    To achieve this, the user opens the Plan Outline Exploration View ([Fig. 2](#S5.F2
    "In 5.2.1 Plan Outline Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration")). The user first clicks the bottom of
    the “Plot Development” task node to create a branch from this task and enters
    “add a step to finalize” ([Fig. 2](#S5.F2 "In 5.2.1 Plan Outline Exploration ‣
    5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣ AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")
    A). Behind the scenes, an LLM is prompted to complete this branch based on the
    requirement entered by the user. After the new branch is completed, the user clicks
    the starting point of the branch and further enters “adjust steps before Plot
    Development, everything else same as baseline” ([Fig. 2](#S5.F2 "In 5.2.1 Plan
    Outline Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5
    AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration") B). Note that this time the user also selects a branch
    (highlighted with green color) to tell the LLM which branch is the “baseline”
    referred to in the entered requirement and sets the number of created new branches
    as three to explore more possibilities. The system then returns three branches
    with variation before the “Plot Development” step ([Fig. 2](#S5.F2 "In 5.2.1 Plan
    Outline Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5
    AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration") C). Comparing these three choices, the user finally
    selects the middle one as the new plan outline for collaboration.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.2 Agent Assignment Exploration
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ce178e1d43c9f6b298d8401c6a8fbe23.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: An illustrative example of agent assignment exploration.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'The user finds that the “theme selection” step task only involves two agents
    (“Futurist” and “Science Fiction Writer"). However, the user hopes that more agents
    with diverse backgrounds can participate in the brainstorming for themes. For
    instance, the user wishes for someone to inject romantic elements into the stories,
    and someone with a solid tech background to ensure the technical plausibility
    of the themes. To achieve this, the user opens the Agent Assignment Exploration
    View. The exploration view displays the scores for each agent on the agent board
    with a heatmap, based on the LLM’s assessment of three capabilities it deems important
    for completing the current task ([Fig. 3](#S5.F3 "In 5.2.2 Agent Assignment Exploration
    ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣
    AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") A). To help the user focus on agents more likely to be suitable
    for the current task, the system sorts assigned and unassigned agents separately
    in descending order based on their current average scores. The user then further
    enters two aspects (“AI Tech Understanding”, “Love Element Understanding”), and
    selects four aspects they deem important (“Creative Thinking”, “Knowledge of AI
    Ethics”, “AI Tech Understanding”, “Love Element Understanding”) as the new ranking
    criteria ([Fig. 3](#S5.F3 "In 5.2.2 Agent Assignment Exploration ‣ 5.2 Interactive
    Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") B).
    Now the user finds two candidates (“AI Scientist” and “AI Engineer”) with strong
    AI Tech backgrounds. Although both candidates scored 5 for AI Tech Understanding,
    the user finds that the AI scientist overall has higher scores in the likelihood
    of possessing “Creative Thinking” and “Knowledge of AI Ethics”. Therefore, the
    user decides to add the AI scientist to the team. The user also finds that the
    LLM considers the “Poet” and “Cognitive Physiologist” likely to have a deeper
    understanding of the love element. Therefore, the user moves the mouse over the
    corresponding score block to view the reasons for the LLM’s scoring. After incorporating
    the user’s own analysis (believing that understanding love from a poetic rather
    than a psychological perspective is more fitting for creative scenarios), the
    user decides to add the poet to the team for the current task and click ![[Uncaptioned
    image]](img/19ef8588b7f1d33a294c4439cb5c4926.png) to confirm the new agent assignment.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.3 Task Process Exploration
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/190eb8f3fb15a317a51da1d9f3762713.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: An illustrative example of task process exploration.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the final story-writing task has a direct impact on the output of the
    novel, the user decides to intervene at a finer granularity in the task process
    of this step. Particularly, the user wants Isabella (the “Science Fiction Writer”)
    to lead the writing of the final draft and focus on the vividness of the final
    story. To achieve this, the user opens the Task Process Exploration View. The
    user first clicks the starting point of the branch and enters “Isabella takes
    the lead in writing novel while Carlos helps review” ([Fig. 4](#S5.F4 "In 5.2.3
    Task Process Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy
    ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration") A). Behind the scenes, an LLM is prompted
    to generate a new task process based on this requirement. However, the user finds
    that although Isabella indeed takes on most of the writing in the new task process,
    the iterative process did not give sufficient attention to the vividness of the
    story. Therefore, the user selects the current branch as the baseline and creates
    another three branches with the requirement “the improvements for each draft should
    focus on enhancing the vividness of the story” ([Fig. 4](#S5.F4 "In 5.2.3 Task
    Process Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5
    AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration") B). The system returns with three variations of the
    task process that meet the requirement ([Fig. 4](#S5.F4 "In 5.2.3 Task Process
    Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord
    System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") C). The user then chooses the favorite one among the three and
    further iterates on it.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Execution Result Examination
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once the user has completed the design of the coordination strategy, they can
    execute it and examine the outcomes by clicking the ![[Uncaptioned image]](img/02995ee81fc1fefd2cd1e2cbd1d48079.png)
    button in the Execution Result View ([Fig. 1](#S4.F1 "In 4.2.2 Stage2: Agent Assignment
    ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") ![[Uncaptioned image]](img/6f2ad48bb893c00d99a75bca9b5fe68f.png)).
    Instead of presenting the execution result in pure text forms like AuoGen[[38](#bib.bib38)]
    and AutoAgents[[3](#bib.bib3)], AgentCoord enhances the result with visual designs
    consistent with the previous design stages and explicit visual linkages to help
    users establish connections between the execution result and the strategy design.
    To prevent users from being overwhelmed by excessive textual information, we provide
    the option to selectively expand relevant results with a mouse click ([Fig. 1](#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ![[Uncaptioned image]](img/e5d7d0ef37ef2a8e9a6a9eb6530b1010.png)).
    Furthermore, to reduce the cognitive load of analyzing and help reveal connections
    between different execution results, when the user focuses on a particular execution
    result, other results with potential important dependencies (based on the Important
    Input field described in [Section 4.2.3](#S4.SS2.SSS3 "4.2.3 Stage3: Task Process
    Generation ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy
    Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration")) will be visually linked to it.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 6 User Study
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We conduct a user study to evaluate the feasibility and effectiveness of our
    approach in facilitating coordination strategy design for agent collaboration.
    Our evaluation focuses on (1) The effectiveness of the structured coordination
    strategy generation approach. (2) The overall effectiveness and usability of the
    interactive system. (3) the support for coordination strategy design compared
    with two baseline systems based on existing LLM-based multi-agent coordination
    frameworks.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Methodology
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 6.1.1 Participants
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We recruited 12 participants (P1-P12) with a general interest in LLM-based multi-agent
    collaboration for our experiment, 3 females and 9 males, aged 23-28 from the local
    university. To mitigate evaluation bias, all participants had not been involved
    in our formative study or the approach design process. All of the participants
    have ever used ChatGPT in the past. Seven have heard about at least one LLM-based
    multi-agent system or framework. Four have first-hand touch with at least one
    LLM-based multi-agent system or framework.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.2 Experiment Setup
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We set up two additional baseline systems for comparative study [[36](#bib.bib36),
    [9](#bib.bib9), [8](#bib.bib8)] alongside our system. All three systems utilize
    GPT4 as the default LLM model. The users can also use ChatGPT at their will during
    experiments. During the strategy design phase in AgentCoord, we allow users to
    switch to a fast mode that uses Mistral 8$\times$7B model with hardware acceleration⁵⁵5https://groq.com/
    for the first time of generation to strike a balance of response quality and efficiency.
    The agents used in the experiments are generated through role prompting [[42](#bib.bib42)]
    and then converted to the corresponding format required for the three systems.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'Baseline A (AutoAgents with simple UI): provides a set of carefully designed
    prompts to let the LLM generate a step-by-step coordination strategy for collaboration
    based on the goal provided by the user. Each step starts with a list “[name1,
    name2, ..]” to specify the agents involved and uses natural language to specify
    how agents will collaborate. A simple text editor is provided for further editing
    the strategy. Once the user is satisfied, they can click the “execute” button
    to start collaboration. The output of the execution result is shown in the text
    terminal.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Baseline B (AutoGen in Group Chat Mode): allows adding multiple LLM-based agents
    in a group chat and coordinating them using natural language. During the coordination
    strategy design, a planner agent first drafts an initial coordination strategy
    based on the general goal provided by the user and the profile of available agents.
    The user plays the role of an admin agent and refines the coordination strategy
    collaboratively with the planner agent by chatting. Once the user is satisfied
    with the coordination strategy, they can start the collaboration. The output of
    the execution result is shown in the text terminal.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.3 Procedure
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Introduction and Training: We initially briefed the users on the objective
    and relevant context of the experiment. Following that, we gathered basic information
    from the users, along with their exposure to LLM-based multi-agent systems or
    frameworks. Afterward, we demonstrated to the participants how to design coordination
    strategies for agents using the three systems. We allowed the participants adequate
    time to experiment with and familiarize themselves with the systems. During this
    process, they were free to ask questions at any point.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'Task Process: For each system, participants are required to select a general
    goal (e.g. “write an engaging tutorial about bubble sort for kids”, “make a content
    strategy for a local weekend event”) for agent collaboration and design coordination
    strategy for it with the given system. During the design process, the participants
    are required to finish four sub-tasks: 1\. Comprehend and judge the coordination
    strategy generated by the system. 2\. Explore and improve at least three different
    aspects of the generated collaborative strategy. 3\. Execute the collaborative
    strategy at least once and analyze the results. 4\. Improve at least one area
    of the original collaborative strategy based on the execution results. After the
    user meets the requirements for the sub-tasks, they can continue open-ended exploration
    with the system freely without time constraints. The order of the systems was
    counterbalanced.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'Semi-structured interview: We ask participants to fill out a five-point Likert-scale
    questionnaire designed to assess our system’s effectiveness and usability ([Fig. 5](#S6.F5
    "In 6.2.3 Usability ‣ 6.2 Results Analysis ‣ 6 User Study ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")), and
    coordination support comparison for all systems ([Fig. 6](#S6.F6 "In 6.2.3 Usability
    ‣ 6.2 Results Analysis ‣ 6 User Study ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration")). For each question, we encourage
    participants to explain the reasoning for their ratings and provide any opinion.
    In the end, we collect overall feedback about our system from users.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Results Analysis
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 6.2.1 Effectiveness of Structured Strategy Generation
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most of the participants agreed that the structure for coordination strategy
    is expressive and easy to understand (Q1). Users praised that the structure is
    “clear” (P5) and “intuitive” (P2). P5 commented, “it goes from high level to low
    level, which makes sense. The connections between each part are really clear.”
    P7 told us that “the proposed classification for interaction type is very helpful”
    and “hope the later versions of the system support customizing and managing different
    levels of classification granularity”. Most of the participants agreed that the
    structure for coordination strategy facilitates the design process (Q2). The users
    appreciated the structure “provide a clear map for what have been explored and
    what could be explored next” (P11) and “make the exploration process more systematic
    and confident” (P8). P10 told us that “the structure helps increase the predictability
    and my confidence when prompting LLM during exploration”. Most of the participants
    agree that the generated initial strategy is helpful as a starting strategy (Q3).
    The users found the baseline strategy always at least serves a “fair starting
    point” (P6) and sometimes “unexpectedly good” (P3). Some users express the demand
    to “have someplace to enter user’s preference or prior knowledge to affect the
    starting generation” (P5).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 Effectiveness of Interactive System
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Visual Organization for Strategy. Most of the participants agreed that the visual
    organization for coordination strategy facilitates comprehension (Q4). The Plan
    Outline View is regarded helpful for “quickly get an understanding of the overall
    strategy” (P2) and “convenient for navigation” (P9). P11 commented, “I like the
    ‘parallel line design’, the relationship between tasks is clearly illustrated”.
    Users appreciated “the adaptive informative reviling” (P6) in Agent Board View
    while wishing for allowing to “show an agent’s historical performance on need”
    (P5). The text highlighting in Task Process View is widely praised by users for
    aiding fast comprehension. However, some users still found the quantity of text
    to read for task process specification is large and wish to “have a summary for
    each action instruction” (P3). The overall layout is also praised by some users
    in terms of aesthetics and consistency.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'Interactive Exploration for Alternative Strategy. Users generally appreciate
    the exploration interactions supported by our system. Meanwhile, users find the
    organization for exploration histories to be ‘extremely convenient’ (P7) and ‘helpful
    in focusing on exploration’ (P10). Nevertheless, we noted variations in how often
    and how favorably users engaged with the three exploration views (Q5,6,7). While
    both the Plan Outline Exploration View and the Process Exploration View are for
    sequential structure exploration and share a similar design, we find generally
    participants tend to do more exploration in the Plan Outline Exploration View.
    P5 explained: “when deciding the outline for the overall collaboration, I am not
    sure how to do and want to see more possibilities, branching with high-level natural
    language requirement is extremely useful at that phase. On the other hand, the
    task process is for a more detailed level, which I usually do not want to spend
    too much time exploring and just want to directly modify” (P5). The Agent Assignment
    Exploration View is the most popular view for exploration. Most users find using
    head-map to visualize LLM’s prior knowledge for agent assignment “is comprehensive
    and insightful” (P4) and the interactions “flexible and engaging for exploration”
    (P10).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'Execution Result Examination. Most of the participants agreed that the Execution
    Result View facilitates the analysis of the execution result (Q8). The participants
    confirmed that when examining the result, it is easy to connect any part of the
    result with its corresponding strategy design. P7 commented: “when I want to a
    analyze certain result, I just click it, the other views automatically show relevant
    strategy information, reminding me of my previous design process, that’s cool.”
    The trace lines for important action inputs were also found helpful. P9 mentioned
    that he likes starting with the final result of a certain task and leveraging
    the trace lines to help trace back to see how this final result is formed along
    the way to identify possible points for improvement.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 Usability
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most of the participants agreed that our system was easy to learn (Q9) and easy
    to use (Q10). Participants commented that the interface of our system was “intuitive”
    (P2) and “clear” (P5). Several users reported although each feature of the system
    is each to understand, it still requires some time to fully master the system
    in order to use it fluently. All of the participants express their willingness
    to use our system again (Q11). P5 told us that he wish to “use this system to
    coordinate some agents to help maintain my blog in the future” (P5). P1 expressed
    the willingness to use our system to fast prototype some coordination strategies
    for research purposes, indicating its potential to contribute to the research
    community for LLM-based multi-agent systems.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fae8847d6a331fe4bea2f3b985f0dacd.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The results of the questionnaire regarding our system’s effectiveness
    and usability.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3ececef6c3226558d6e08d3bf056f8a3.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The results of the questionnaire comparing the support for coordination
    strategy design across the three systems.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.4 Coordination Support Comparison
  id: totrans-156
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To compare our system against two baselines in aiding the design process for
    coordination strategy, we requested participants to rate three systems across
    three facets (i.e. strategy comprehension, strategy exploration, and result analysis)
    of the design process and their satisfaction with the final result. Overall, our
    system outperforms the baselines for all four aspects. We summarize the user’s
    feedback as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Strategy Comprehension: In Baseline B, the baseline coordination strategy is
    generated and refined by a planner agent without any structure constraints. Therefore,
    during the iteration for strategies, “the format of strategy could fluctuate frequently,
    which makes me inconfident” (P3). In Baseline A, the strategy is generated with
    carefully designed prompts that enforce some formats (e.g. divide into steps,
    and assign agents for each step). However, reading and comparing strategies repented
    in the pure text still makes users “feeling stressed” (P11) and “less confident
    for comprehension” (P8). In contrast, our system makes sure the coordination strategy
    has a consistent structure during the whole design process and provides visual
    organization and enhancement to facilitate comprehension.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'Strategy Exploration: In baseline A, no direct support for strategy exploration
    is provided, users can only use ChatGPT to aid their exploration. However, transferring
    strategies between interfaces and making manual modifications for format and logic
    consistency can be “tedious and error-prone” (P7). Baseline B allows users to
    explore alternative strategies by chatting with the planner agent. However, there
    lack of support for users to flexibly explore different aspects of the strategy
    on need. Moreover, the quantity of texts can be quickly overwhelming for both
    the planner agent and users as the process of exploration gets complicated. Our
    system empowers users with a set of interactions to flexibly explore different
    aspects of the strategies with the help of LLM and helps visually organize the
    exploration history.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: 'Result Analysis: Our system is overall deemed more helpful for execution result
    analysis. In both baseline A and baseline B, the execution result is directly
    output to the text terminal. P9 told us that she has to “sift through the text
    myself repeatedly to trace the dependencies between execution results and previous
    operations” (P9). Instead, in our system, users can easily trace each result back
    to its important influencing precursors and corresponding coordination strategies.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Result Satisfaction: Compared to Baseline A and Baseline B, users are overall
    more satisfied with the results of our system. In Baseline B, due to the ambiguity
    frequently existing in the free-form coordination strategy, the execution process
    often deviates from the user’s expectations midway and strays further and further
    away, sometimes even falling into an infinite loop. In Baseline A, thanks to the
    enforced step-by-step strategy format, there is no infinite loop issue. However,
    the result usually misses some important parts that should appear according to
    the coordination strategy (e.g. the main characters decided in character design
    stages are not shown in the final story). While such problems also exist in the
    result of our system, users usually can successfully trace the cause by analyzing
    the result with our system, and quickly adjust the corresponding part of the strategy
    to fix it.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 7 Discussion
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we reflect on our research, discuss lessons learned and the
    system’s generalizability, followed by limitations and future work.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Lessons Learned
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Benefits of structured strategy representation for human-LLMs co-design process.
    Our evaluation results indicate that having a structured representation for coordination
    strategy is essential for the experience of the design process. The structure
    helps align human and LLMs’ intentions, enforcing both sides to think and communicate
    based on the same set of concepts and abstraction levels, which effectively reduces
    mutual misunderstandings caused by the ambiguity of natural language. Moreover,
    a fixed structure enables the specialized design of visual organization and enhancement,
    facilitating strategy comprehension for humans, allowing them to efficiently explore
    more strategy possibilities generated by LLMs. Additionally, structured representation
    fosters a structured exploration process, making users inclined towards a more
    systematic design process for coordination strategies.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing LLMs’ prior knowledge for agent coordination. While many works directly
    leverage LLMs’ prior knowledge to generate coordination strategy, how to effectively
    extract and visualize this prior knowledge to aid strategy design has not been
    explored. We find that compared to just getting a single answer from LLMs, users
    prefer to have a more panoramic understanding of LLM’s prior knowledge when they
    want to optimize a certain part of the strategy. For example, instead of just
    letting LLM select some agents that might contribute the a certain task, visualizing
    how each agent scores for the capabilities LLMs deem important using an interactive
    heat map would be more insightful and systematic for strategy design.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 System Generalizability
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Besides coordinating agents to collaboratively solve goal-oriented tasks, our
    system has the potential to be generalized to various applications. For example,
    users can use our system to coordinate agents to simulate and analyze human activities
    (e.g. playing Werewolf games, competing in debate tournaments, conducting multi-party
    negotiations) that involve multiple people. Those simulations are not only interesting
    for entertainment but also valuable resources for studying human/AI society and
    evaluating specific capabilities of LLMs. In the future, we plan to extend the
    structure representation of AgentCoord to support more social interaction types
    for more flexible simulation purposes. We also plan to allow users to upload their
    customized interaction types.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Limitations and Future Work
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AgentCoord currently only supports coordinating agents to collaborate in a plain
    text environment, which contains text-form key objects. An interesting future
    work is to support multi-modal key objects in the environment and allow agents
    with multi-model capabilities to collaborate. For example, a writer agent generates
    a story, and an illustrator agent creates corresponding visuals.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'AgentCoord currently only supports static coordination strategy design. In
    some scenarios, users may want to dynamically adjust the strategy during collaboration
    execution to adapt to circumstances. For example, the user may coordinate multiple
    agents to help conduct literature research: when an agent finds a paper that interests
    the user, the user may want to adjust the plan to allocate a group of agents to
    read and discuss it, and allocate another group of agents to investigate the background
    of its authors. Future research can be conducted to help users conduct dynamic
    coordination strategy design.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 8 Conclusion
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This study presents a visual exploration framework to aid in the design of coordination
    strategies for LLM-based multi-agent collaboration, addressing the challenges
    posed by natural language ambiguity and the cognitive effort required for comprehending
    the vast amount of texts during strategy design. We propose a structured representation
    for coordination strategy and a three-stage generation method to transform the
    general goal provided by the user into executable strategies. We visually organize
    the generated strategy to facilitate user comprehension and provide a set of interactions
    to support alternative strategies exploration with LLMs. We also provide visual
    enhancement to help users analyze the execution results. Finally, we conduct a
    formal user study to validate the feasibility and effectiveness of our approach.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Assem. NexusGPT Marketplace. [https://app.gpt.nexus/App/Marketplace/agents](https://app.gpt.nexus/App/Marketplace/agents),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] C.-M. Chan, W. Chen, Y. Su, J. Yu, W. Xue, S. Zhang, J. Fu, and Z. Liu.
    ChatEval: Towards better llm-based evaluators through multi-agent debate. In The
    Twelfth International Conference on Learning Representations, 2024\. [doi: 10 . 48550/arXiv . 2308 . 07201](https://doi.org/10.48550/arXiv.2308.07201)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] G. Chen, S. Dong, Y. Shu, G. Zhang, S. Jaward, K. Börje, J. Fu, and Y. Shi.
    AutoAgents: A framework for automatic agent generation. CoRR, abs/2309.17288,
    Sept. 2023\. [doi: 10 . 48550/arXiv . 2309 . 17288](https://doi.org/10.48550/arXiv.2309.17288)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin,
    Y. Lu, R. Xie, et al. AgentVerse: Facilitating multi-agent collaboration and exploring
    emergent behaviors in agents. CoRR, abs/2308.10848, Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 10848](https://doi.org/10.48550/arXiv.2308.10848)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] M. D’Arcy, T. Hope, L. Birnbaum, and D. Downey. MARG: Multi-agent review
    generation for scientific papers. CoRR, abs/2401.04259, Jan. 2024\. [doi: 10 . 48550/arXiv . 2401 . 04259](https://doi.org/10.48550/arXiv.2401.04259)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch. Improving
    factuality and reasoning in language models through multiagent debate. CoRR, abs/2305.14325,
    May 2023\. [doi: 10 . 48550/arXiv . 2305 . 14325](https://doi.org/10.48550/arXiv.2305.14325)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] D. C. Engelbart. Augmenting human intellect: A conceptual framework. Routledge,
    New York, 1^(st) ed., 2023\. [doi: 10 . 4324/9781003230762](https://doi.org/10.4324/9781003230762)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Y. Feng, X. Wang, B. Pan, K. K. Wong, Y. Ren, S. Liu, Z. Yan, Y. Ma, H. Qu,
    and W. Chen. Xnli: Explaining and diagnosing nli-based visual data analysis. IEEE
    Transactions on Visualization and Computer Graphics, pp. 1–14, 2023\. [doi: 10 . 1109/TVCG . 2023 . 3240003](https://doi.org/10.1109/TVCG.2023.3240003)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, and W. Chen.
    Promptmagician: Interactive prompt engineering for text-to-image creation. IEEE
    Transactions on Visualization and Computer Graphics, 30(1):295–305, 2023\. [doi:
    10 . 1109/TVCG . 2023 . 3327168](https://doi.org/10.1109/TVCG.2023.3327168)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Gravitas. AutoGPT. [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] S. Hong, Y. Lin, B. Liu, B. Wu, D. Li, J. Chen, J. Zhang, J. Wang, L. Zhang,
    M. Zhuge, et al. Data Interpreter: An llm agent for data science. CoRR, abs/2402.18679,
    Feb. 2024\. [doi: 10 . 48550/arXiv . 2402 . 18679](https://doi.org/10.48550/arXiv.2402.18679)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S.
    Yau, Z. Lin, L. Zhou, et al. MetaGpt: Meta programming for multi-agent collaborative
    framework. In The Twelfth International Conference on Learning Representations,
    2024\. [doi: 10 . 48550/arXiv . 2308 . 00352](https://doi.org/10.48550/arXiv.2308.00352)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler,
    M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, and D. Kiela. Retrieval-augmented
    generation for knowledge-intensive nlp tasks. In Advances in Neural Information
    Processing Systems, pp. 9459–9474, 2020\. [doi: 10 . 48550/arXiv . 2005 . 11401](https://doi.org/10.48550/arXiv.2005.11401)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, and B. Ghanem. CAMEL:
    Communicative agents for “mind” exploration of large language model society. In
    Thirty-seventh Conference on Neural Information Processing Systems, 2023\. [doi:
    10 . 48550/arXiv . 2303 . 17760](https://doi.org/10.48550/arXiv.2303.17760)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, and
    S. Shi. Encouraging divergent thinking in large language models through multi-agent
    debate. CoRR, abs/2305.19118, May 2023\. [doi: 10 . 48550/arXiv . 2305 . 19118](https://doi.org/10.48550/arXiv.2305.19118)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] J. Lin, H. Zhao, A. Zhang, Y. Wu, H. Ping, and Q. Chen. AgentSims: An
    open-source sandbox for large language model evaluation. CoRR, abs/2308.04026,
    Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 04026](https://doi.org/10.48550/arXiv.2308.04026)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Y. Liu, Z. Wen, L. Weng, O. Woodman, Y. Yang, and W. Chen. SPROUT: Authoring
    programming tutorials with interactive visualization of large language model generation
    process. CoRR, abs/2312.01801, Dec. 2023\. [doi: 10 . 48550/arXiv . 2312 . 01801](https://doi.org/10.48550/arXiv.2312.01801)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Z. Liu, Y. Zhang, P. Li, Y. Liu, and D. Yang. Dynamic llm-agent network:
    An llm-agent collaboration framework with agent team optimization. CoRR, abs/2310.02170,
    Oct. 2023\. [doi: 10 . 48550/arXiv . 2310 . 02170](https://doi.org/10.48550/arXiv.2310.02170)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] J. Lu, B. Pan, J. Chen, Y. Feng, J. Hu, Y. Peng, and W. Chen. AgentLens:
    Visual analysis for agent behaviors in llm-based autonomous systems. CoRR, abs/2402.08995,
    Feb. 2024\. [doi: 10 . 48550/arXiv . 2402 . 08995](https://doi.org/10.48550/arXiv.2402.08995)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] A. I. Luppi, P. A. Mediano, F. E. Rosas, N. Holland, T. D. Fryer, J. T.
    O’Brien, J. B. Rowe, D. K. Menon, D. Bor, and E. A. Stamatakis. A synergistic
    core for human brain evolution and cognition. Nature Neuroscience, 25(6):771–782,
    May 2022\. [doi: 10 . 1038/s41593-022-01070-0](https://doi.org/10.1038/s41593-022-01070-0)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] J. MouraAbout. CrewAI. [https://github.com/joaomdmoura/crewAI](https://github.com/joaomdmoura/crewAI),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] OpenAI. OpenAI GPT Store. [https://openai.com/blog/introducing-the-gpt-store](https://openai.com/blog/introducing-the-gpt-store),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens,
    A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe. Training language
    models to follow instructions with human feedback. In Advances in Neural Information
    Processing Systems, pp. 27730–27744, 2022\. [doi: 10 . 48550/arXiv . 2203 . 02155](https://doi.org/10.48550/arXiv.2203.02155)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] J. S. Park, J. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein.
    Generative agents: Interactive simulacra of human behavior. In Proceedings of
    the 36th Annual ACM Symposium on User Interface Software and Technology, pp. 1–22,
    2023\. [doi: 10 . 1145/3586183 . 3606763](https://doi.org/10.1145/3586183.3606763)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, and M. Sun.
    Communicative agents for software development. CoRR, abs/2307.07924, July 2023\.
    [doi: 10 . 48550/arXiv . 2307 . 07924](https://doi.org/10.48550/arXiv.2307.07924)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] ReWorkd. AgentGPT. [https://github.com/reworkd/AgentGPT](https://github.com/reworkd/AgentGPT),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] L. Salewski, S. Alaniz, I. Rio-Torto, E. Schulz, and Z. Akata. In-context
    impersonation reveals large language models’ strengths and biases. In Thirty-seventh
    Conference on Neural Information Processing Systems, 2023\. [doi: 10 . 48550/arXiv . 2305 . 14930](https://doi.org/10.48550/arXiv.2305.14930)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] X. Tang, A. Zou, Z. Zhang, Y. Zhao, X. Zhang, A. Cohan, and M. Gerstein.
    MedAgents: Large language models as collaborators for zero-shot medical reasoning.
    CoRR, abs/2311.10537, Nov. 2023\. [doi: 10 . 48550/arXiv . 2311 . 10537](https://doi.org/10.48550/arXiv.2311.10537)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] L. Team. Langroid: Harness llms with multi-agent programming. [https://github.com/langroid/langroid](https://github.com/langroid/langroid),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] S. Team. SuperAGI. [https://github.com/TransformerOptimus/SuperAGI](https://github.com/TransformerOptimus/SuperAGI),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] S. Team. SuperAGI Marketplace. [https://marketplace.superagi.com/](https://marketplace.superagi.com/),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang,
    X. Chen, Y. Lin, et al. A survey on large language model based autonomous agents.
    CoRR, abs/2308.11432, Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 11432](https://doi.org/10.48550/arXiv.2308.11432)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei, and H. Ji. Unleashing the emergent
    cognitive synergy in large language models: A task-solving agent through multi-persona
    self-collaboration. CoRR, abs/2307.05300, July 2023\. [doi: 10 . 48550/arXiv . 2307 . 05300](https://doi.org/10.48550/arXiv.2307.05300)'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M.
    Dai, and Q. V. Le. Finetuned language models are zero-shot learners. In The Tenth
    International Conference on Learning Representations, 2022\. [doi: 10 . 48550/arXiv . 2109 . 01652](https://doi.org/10.48550/arXiv.2109.01652)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] L. Weng, X. Wang, J. Lu, Y. Feng, Y. Liu, and W. Chen. Insightlens: Discovering
    and exploring insights from conversational contexts in large-language-model-powered
    data analysis. arXiv, 2024\. [doi: 10 . 48550/ARXIV . 2404 . 01644](https://doi.org/10.48550/ARXIV.2404.01644)'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] K. K. Wong, X. Wang, Y. Wang, J. He, R. Zhang, and H. Qu. Anchorage: Visual
    analysis of satisfaction in customer service videos via anchor events. IEEE Transactions
    on Visualization and Computer Graphics, 2023\. [doi: 10 . 48550/ARXIV . 2302 . 06806](https://doi.org/10.48550/ARXIV.2302.06806)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] A. W. Woolley, C. F. Chabris, A. Pentland, N. Hashmi, and T. W. Malone.
    Evidence for a collective intelligence factor in the performance of human groups.
    science, 330(6004):686–688, Sept. 2010\. [doi: 10 . 1126/science . 1193147](https://doi.org/10.1126/science.1193147)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, and C. Wang. AutoGen: Enabling next-gen llm applications via multi-agent
    conversation framework. CoRR, abs/2308.08155, Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 08155](https://doi.org/10.48550/arXiv.2308.08155)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Y. Wu, F. Jia, S. Zhang, Q. Wu, H. Li, E. Zhu, Y. Wang, Y. T. Lee, R. Peng,
    and C. Wang. An empirical study on challenging math problem solving with gpt-4.
    CoRR, abs/2306.01337, June 2023\. [doi: 10 . 48550/arXiv . 2306 . 01337](https://doi.org/10.48550/arXiv.2306.01337)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] XAgent Team. XAgent: An autonomous agent for complex task solving. [https://github.com/OpenBMB/XAgent](https://github.com/OpenBMB/XAgent),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin,
    E. Zhou, et al. The rise and potential of large language model based agents: A
    survey. CoRR, abs/2309.07864, Sept. 2023\. [doi: 10 . 48550/arXiv . 2309 . 07864](https://doi.org/10.48550/arXiv.2309.07864)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] B. Xu, A. Yang, J. Lin, Q. Wang, C. Zhou, Y. Zhang, and Z. Mao. ExpertPrompting:
    Instructing large language models to be distinguished experts. CoRR, abs/2305.14688,
    May 2023\. [doi: 10 . 48550/arXiv . 2305 . 14688](https://doi.org/10.48550/arXiv.2305.14688)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu, and
    C. Gan. Building cooperative embodied agents modularly with large language models.
    In The Twelfth International Conference on Learning Representations, 2024\. [doi:
    10 . 48550/arXiv . 2307 . 02485](https://doi.org/10.48550/arXiv.2307.02485)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Y. Zheng, C. Ma, K. Shi, and H. Huang. Agents meet OKR: an object and
    key results driven agent system with hierarchical self-collaboration and self-evaluation.
    CoRR, abs/2311.16542, Nov. 2023\. [doi: 10 . 48550/arXiv . 2311 . 16542](https://doi.org/10.48550/arXiv.2311.16542)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] M. Zhuge, H. Liu, F. Faccio, D. R. Ashley, R. Csordás, A. Gopalakrishnan,
    A. Hamdi, H. A. A. K. Hammoud, V. Herrmann, K. Irie, et al. Mindstorms in natural
    language-based societies of mind. CoRR, abs/2305.17066, May 2023\. [doi: 10 . 48550/arXiv . 2305 . 17066](https://doi.org/10.48550/arXiv.2305.17066)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
