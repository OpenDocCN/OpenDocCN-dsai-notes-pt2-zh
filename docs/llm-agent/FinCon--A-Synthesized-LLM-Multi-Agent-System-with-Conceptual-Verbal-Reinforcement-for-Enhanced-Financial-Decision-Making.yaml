- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:42:13'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.06567](https://ar5iv.labs.arxiv.org/html/2407.06567)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yangyang Yu^(1,⋆),   Zhiyuan Yao^(1,⋆),  Haohang Li^(1,⋆),  Zhiyang Deng^(1,⋆), 
    Yupeng Cao^(1,⋆),  Zhi Chen^(1,⋆)
  prefs: []
  type: TYPE_NORMAL
- en: Jordan W. Suchow¹,  Rong Liu¹,  Zhenyu Cui¹, Denghui Zhang¹  Koduvayur Subbalakshmi¹
  prefs: []
  type: TYPE_NORMAL
- en: Guojun Xiong²,  Yueru He³,  Jimin Huang ³,  Dong Li³,  Qianqian Xie^(3,†)
  prefs: []
  type: TYPE_NORMAL
- en: ¹Stevens Institute of Technology ²Stony Brook University ³The Fin AI
  prefs: []
  type: TYPE_NORMAL
- en: '^⋆These authors contributed equally ^† Corresponding author: qianqian.xie@yale.edu'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large language models (LLMs) have demonstrated notable potential in conducting
    complex tasks and are increasingly utilized in various financial applications.
    However, high-quality sequential financial investment decision-making remains
    challenging. These tasks require multiple interactions with a volatile environment
    for every decision, demanding sufficient intelligence to maximize returns and
    manage risks. Although LLMs have been used to develop agent systems that surpass
    human teams and yield impressive investment returns, opportunities to enhance
    multi-sourced information synthesis and optimize decision-making outcomes through
    timely experience refinement remain unexplored. Here, we introduce the FinCon,
    an LLM-based multi-agent framework with conceptual verbal reinforcement tailored
    for diverse financial tasks. Inspired by effective real-world investment firm
    organizational structures, FinCon utilizes a manager-analyst communication hierarchy.
    This structure allows for synchronized cross-functional agent collaboration towards
    unified goals through natural language interactions and equips each agent with
    greater memory capacity than humans. Additionally, a risk-control component in
    FinCon enhances decision quality by episodically initiating a self-critiquing
    mechanism to update systematic investment beliefs. The conceptualized beliefs
    serve as verbal reinforcement for the future agent’s behavior and can be selectively
    propagated to the appropriate node that requires knowledge updates. This feature
    significantly improves performance while reducing unnecessary peer-to-peer communication
    costs. Moreover, FinCon demonstrates strong generalization capabilities in various
    financial tasks, including single stock trading and portfolio management.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The intricacies and fluctuations of financial markets present substantial challenges
    for making high-quality, sequential investment decisions. In tasks such as single
    stock trading and portfolio management, each intelligent decision is informed
    by multiple market interactions and integrated information characterized by different
    levels of timeliness and modalities [[1](#bib.bib1), [2](#bib.bib2)]. These tasks
    aim to maximize profit while managing current market risks in an open-end environment.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, trading firms often rely on synthesized human teamwork, with an
    organizational structure that typically involves hierarchical communication among
    various functional roles such as data analysts, risk analysts, portfolio managers,
    etc., and careful integration of various resources [[3](#bib.bib3), [4](#bib.bib4)].
    However, the cognitive limitations of human team members can restrict their ability
    to quickly process market signals and achieve optimal investment results [[5](#bib.bib5)].
  prefs: []
  type: TYPE_NORMAL
- en: 'To improve investment returns and overcome human limitations, studies have
    employed methods such as deep reinforcement learning (DRL) to develop agent systems
    that simulate market environments and automate investment strategies [[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)]. Meanwhile, advancements in large language models
    (LLMs) demonstrate potential in complex tasks such as reasoning, tool-using, planning,
    and decision-making [[9](#bib.bib9), [10](#bib.bib10)], promising to surpass existing
    agent architectures. Language agents are known for human-like communication and
    adaptable prompt-based structures tailored for diverse decision-making settings
    [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]. For
    optimal decision-making performance, two key elements need to be considered: 1)
    Organizing agents to promote effective teamwork and efficient communication, and
    2) Enabling agents to continually learn and refine their actions. Studies indicate
    that imitating human organizational structures can effectively coordinate language
    agents for specific tasks [[15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17)].
    Additionally, recent developments in textual gradient-based prompt optimization
    [[18](#bib.bib18), [19](#bib.bib19)] and verbal reinforcement [[20](#bib.bib20),
    [21](#bib.bib21)] have proven to be practical for enhancing the reasoning and
    decision-making abilities of language agents iteratively.'
  prefs: []
  type: TYPE_NORMAL
- en: Language agent systems adapted for financial decision-making, such as FinGPT
    [[22](#bib.bib22)], FinMem [[23](#bib.bib23)] and FinAgent [[24](#bib.bib24)],
    have demonstrated impressive performance. However, these systems exhibit several
    limitations. Firstly, their reliance on the risk preferences of agents based on
    short-term market fluctuations fails to control overall risk exposures over long-term
    trading periods. This oversight can lead to potential losses due to the dismissal
    of fundamental factors driving investment profits. A more effective strategy is
    to quantify investment risks using measures of risk from quantitative finance
    [[25](#bib.bib25), [26](#bib.bib26)]. Secondly, most existing systems are designed
    for single-asset trading tasks and show limited adaptability to other financial
    applications involving multiple assets, such as portfolio management. Thirdly,
    these systems depend on the information understanding and extraction ability of
    a single agent, placing heavy pressure on the language model to comprehend and
    process information within a limited context window. This likely degrades decision
    quality. A multi-agent system that allocates tasks based on data source and modality
    could enhance performance. Even though approaches like StockAgent [[27](#bib.bib27)]
    utilize a multi-agent system for individual stock trading tasks. However, their
    decision-making processes heavily depend on extensive discussions among numerous
    LLM agents, leading to high communication costs and extended processing times.
    Besides, the lack of a clear optimization goal in such systems can compromise
    the effectiveness of the outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In response to these unaddressed issues, we propose FinCon, an LLM-based multi-agent
    framework for critical financial decision-making tasks such as single stock trading
    and portfolio management. Our main contributions are as follows: 1) Inspired by
    real-world investment roles, we designed an innovative Synthesized Manager-Analyst
    hierarchical communication structure and a risk control component. This communication
    structure distributes financial data from various sources and modalities to corresponding
    functional analyst agents, allowing them to focus on distilling essential investment
    insights and indicators from a single source of information. The manager then
    makes trading decisions by consolidating these insights and interacting with the
    risk-control component. The manager and analyst in a synchronous hierarchy to
    effectively enhance overall comprehension and reasoning capabilities. In this
    communication network, messages are conveyed only to the workers who need to be
    informed, eliminating redundant peer-to-peer communication and saving communication
    costs. 2) It is a generalized framework that can conduct not only stock trading
    but also portfolio management. The latter has not been claimed to be tackled by
    other financial language agent frameworks. 3) We innovatively crafted the agents’
    persona using a dual-level risk control component, enabling comprehensive risk
    updates both within and across episodes. Within episodes, risk supervision is
    conducted using a quantile-based risk measure from quantitative finance, the Conditional
    Value at Risk (CVaR) [[28](#bib.bib28)]. For across-episode risk control, we designed
    a unique verbal reinforcement method to update the decision maker’s investment
    beliefs with conceptualized investment insights to guide future decisions. These
    investment beliefs are distilled from underlying reasoning trajectory-level profit
    and loss (PnL) changes and summarized as conceptual perspectives based on the
    functionality of all analyst agents. Investment beliefs can then be selectively
    back-propagated from the manager to the corresponding functional analyst agent.
    Ablation study results illustrate the significant effectiveness of our risk control
    design in managing market risk and improving trading performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLM Agents for Financial Decision Making. There are considerable efforts directed
    towards developing general-purpose LLM agent for sequential decision-making [[29](#bib.bib29),
    [30](#bib.bib30)], and such type of tasks often involve episodic interactions
    with environment and verbal reflections for action refinement, such as coding
    competition [[31](#bib.bib31), [32](#bib.bib32)], software development [[33](#bib.bib33),
    [14](#bib.bib14)], game-playing [[34](#bib.bib34), [35](#bib.bib35)]. Furthermore,
    researchers have started to exploit how LLM agents can perform better in harder
    decision-making tasks from finance [[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)],
    in which there are more volatile environments, leading to that the numerous unpredictable
    elements can obscure an agent’s ability to reflect accurately on the reasons for
    poor decision outcomes. FinMem [[23](#bib.bib23)] enhances single stock trading
    performance by embedding memory modules with LLM agent for reflection-refinement,
    and FinAgent [[24](#bib.bib24)] improved trading profits via using external quantitative
    tool to fight against volatile environment.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Agent System and Communication Structures. In traditional multi-agent
    systems [[39](#bib.bib39), [40](#bib.bib40)], the way for agents’ communication
    is pre-determined, like sharing data or state observations [[41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)]. The emergence
    of large language model brings flexibility for human-understandable communications
    [[46](#bib.bib46), [11](#bib.bib11), [14](#bib.bib14), [47](#bib.bib47)], so some
    work tries to elevate decision-making ability of LLM-based multi-agent system
    by letting agents engage in discussions [[48](#bib.bib48), [12](#bib.bib12)] or
    debates [[49](#bib.bib49), [50](#bib.bib50)]. The similar peer-communication strategy
    was as well utilized by the multi-agent system for financial tasks [[51](#bib.bib51),
    [52](#bib.bib52), [53](#bib.bib53)]. However, such approach are not optimal for
    unified-goal financial tasks that prioritize profits [[54](#bib.bib54)], because
    they suffer from potentially ambiguous optimization objectives and are unable
    to control the unnecessary communication costs [[55](#bib.bib55)].
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Optimization and Verbal Reinforcement. To enhance the reasoning or decision-making
    of LLM agents, many prompt optimization techniques have been proposed, like ReAct
    [[56](#bib.bib56)], Chain of Thought (CoT) [[57](#bib.bib57)], Tree of Thoughts
    (ToT) [[58](#bib.bib58)], ART [[10](#bib.bib10)], intended for that LLM agents
    can automatically generate intermediate reasoning steps as an iterative program.
    In addition, to make LLM agent make decisions like humans and generate more understandable
    reasoning texts, some researchers recommend incorporating cognitive structures
    [[59](#bib.bib59), [60](#bib.bib60), [61](#bib.bib61), [62](#bib.bib62)]. Inspired
    by these previous work and DRL algorithms [[63](#bib.bib63)], verbal reinforcement
    [[20](#bib.bib20), [21](#bib.bib21), [64](#bib.bib64), [15](#bib.bib15)] was developed
    for LLM agents such that they can update actions based on iterative self-reflection
    while integrating additional LLM as a prompt optimizer [[18](#bib.bib18), [19](#bib.bib19)].
  prefs: []
  type: TYPE_NORMAL
- en: 3 Preliminaries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we outline the mathematical notations for the two major financial decision-making
    tasks that will be explicitly discussed in our work. We also formally present
    the generalized modeling formulation using a Partially Observable Markov Decision
    Process (POMDP) [[65](#bib.bib65)] for financial decision-making tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Financial Decision-making Tasks Formulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Single Stock Trading Tasks. FinCon uses analyst agents group $\{M_{pr}^{i}\}_{i=1}^{I}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Portfolio Trading Tasks. In addition to processing multi-modal market information,
    the analyst agents also establish stocks’ pool for portfolio management, regarding
    statistical correlation between stocks’ returns. Then, the manager agent makes
    trading decisions on each stock in the pool. Lastly, the manager agent determines
    the portfolio weights for all stocks through a computational tool, which leverages
    the following mean-variance optimization [[66](#bib.bib66)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $$\max_{\textbf{w}}\langle\textbf{w},\mu\rangle-\langle\textbf{w},\Sigma\textbf{w}\rangle\quad\text{s.t.}~{}w_{n}=\begin{cases}\in[0,1],&amp;\text{``long''''}\\
    \in[-1,0],&amp;\text{``short''''}\\'
  prefs: []
  type: TYPE_NORMAL
- en: =0,&amp;\text{``neutral''}\end{cases},~{}~{}\forall n\in\{1,\cdots,N\}$$ |  |
  prefs: []
  type: TYPE_NORMAL
- en: where $\textbf{w}=(w_{1}\cdots,w_{N})\in\mathbb{R}^{N}$ sample covariance matrix
    of chosen stocks’ daily return sequences respectively [[26](#bib.bib26)]. We note
    that portfolio weights are rebalanced on daily basis. In our implementation, we
    first calculate the portfolio weights by solving the above optimization problem.
    Then, the target position is calculated by linearly scaling the portfolio weights
    from the prior step.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Modeling Quantitative Trading as POMDP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Formally, we model quantitative trading task as an infinite horizon POMDP [[67](#bib.bib67),
    [68](#bib.bib68)] with time index $\mathbb{T}=\{0,1,2,\cdots\}$, which represents
    the information processing outputs from analyst agents group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, our multi-agent system is supposed to learn the policies of all agents:
    the policies of analyst agents $\pi_{\theta^{i}}^{i}:\mathcal{X}\to\mathcal{A}^{i},i\in\{1,\cdots,I\}$)
    such that the system maximizes cumulative trading reward while controlling risk
    [[70](#bib.bib70)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'All policies $\Pi_{\bm{\theta}}=(\{\pi_{\theta^{i}}^{i}\}_{i=1}^{I},\pi_{\theta^{a}})$,
    the optimization objective for the whole system can be written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\max_{\bm{\theta}}\mathbb{E}\Big{[}\sum\limits_{t\in\mathbb{T}}\alpha^{t}R^{\Pi^{\bm{\theta}}}_{t}\Big{]}$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: which is a risk-sensitive optimization problem with respect to textual gradient
    descent, being essentially different from DRL algorithms for POMDP.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Textual Gradient-Descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In an LLM-based prompt optimizer, a meta-prompt [[18](#bib.bib18), [19](#bib.bib19)]
    is used to refine the task prompt for better performance. For example, for a mathematical
    reasoning task, the task prompt might be "Let’s solve the problem," while the
    meta-prompt could be "Improve the prompt to help a model better perform mathematical
    reasoning."
  prefs: []
  type: TYPE_NORMAL
- en: Although prompt optimization lacks explicit gradients to control the update
    direction, we can simulate “textual gradient” by using LLMs’ reflection capabilities.
    By generating feedback from past successes and failures on trading decisions,
    LLMs can produce "semantic" gradient signals that guide the optimization process.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting the optimization process’s direction is crucial, similar to tuning
    the learning rate in traditional parameter optimization. An inappropriate learning
    rate can cause the process to oscillate or converge too slowly. Similarly, without
    proper control, the LLM-based optimizer might overshoot or oscillate during prompt
    optimization.
  prefs: []
  type: TYPE_NORMAL
- en: To mimic learning rate effects, we measure the overlapping percentage between
    trading decision sequences from consecutive iterations. We then directly edit
    the previous task prompt to enhance performance. The meta-prompt instructs the
    LLM to modify the current prompt based on feedback, ensuring a stable and incremental
    improvement process. This method allows for effective exploitation of existing
    prompts, leading to gradual performance enhancement.
  prefs: []
  type: TYPE_NORMAL
- en: Factor Gradient-based model optimizer LLM-based prompt optimizer Upgrade direction
    Model value gradient momentum Prompt reflection trajectory Update method Learning
    rate descent Overlapping percentage of trading decisions
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Analogy between glossaries in model optimizer and prompt optimizer.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 General framework of FinCon
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ac04c2bd6d54be23282b93f7ff50bc74.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The general framework of FinCon.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we present the architecture of FinCon using a two-level hierarchy.
    First, we describe the hierarchical framework for coordinating the agents’ synchronous
    work and communication. Then, we elaborate on the functionalities of each module
    that constitutes each agent in FinCon.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Synthesized Multi-agent Hierarchical Structure Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The agent system of FinCon consists of two main components: the Manager-Analyst
    Agent Group component and the Risk-Control component.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.1 Manager-Analyst Agent Group
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Analogous to human investment teamwork, FinCon establishes a unique hierarchy
    to organize the multi-agent system, synthesizing their efforts to achieve superior
    decision returns. The primary objective is to improve information presentation
    and comprehension while reducing unnecessary communication costs. The detailed
    working mechanism of each agent is explained and illustrated in Figure [2](#S4.F2.1
    "Figure 2 ‣ 4.1.1 Manager-Analyst Agent Group ‣ 4.1 Synthesized Multi-agent Hierarchical
    Structure Design ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making"):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/24cab6a4eaa23471cee8d5af292a939b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The detailed architecture of FinCon contains two key components:
    Manager-Analyst agent group and Risk Control. It also presents the between-component
    interaction of FinCon and decision-making flow.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Analyst Agents. In FinCon, analyst agents distill concise investment insights
    from large volumes of multi-source market information for one specific trading
    target. To ensure high reasoning quality by reducing task load and enhancing analysis
    focus, each agent processes a single information source in a uni-modal manner,
    delivering pre-specified outputs based on prompts. This setup mirrors an effective
    human team structure, where each analyst specializes in a specific function and
    synchronously filters market noise to extract essential insights. These agents
    support the manager agent in making informed decisions by consolidating denoised
    investment information from multiple perspectives. We design seven distinct types
    of analyst agents using LLMs, each producing diverse investment insights, as shown
    in the upper part of Figure [2](#S4.F2.1 "Figure 2 ‣ 4.1.1 Manager-Analyst Agent
    Group ‣ 4.1 Synthesized Multi-agent Hierarchical Structure Design ‣ 4 General
    framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual
    Verbal Reinforcement for Enhanced Financial Decision Making"). Differentiated
    by input modalities, three textual data processing agents distill insights and
    sentiments from daily news and financial reports. An audio agent extracts investment
    tendencies from earnings call recordings using the Whisper API. Additionally,
    a data analysis agent and a stock selection agent compute key financial metrics,
    such as momentum and CVaR, based on tabular time series data. The stock selection
    agent also manages portfolio selection following the classic risk diversification
    method in quantitative finance [[1](#bib.bib1)], as detailed in Appendix. [7.5](#S7.SS5
    "7.5 Portfolio Management ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Manager Agent. In the FinCon system, the manager agent is the sole decision
    maker, generating trading actions for sequential financial tasks. For portfolio
    management, it computes portfolio weights using convex optimization techniques
    constrained by the direction of actions (see Equation. ([3.1](#S3.Ex1 "3.1 Financial
    Decision-making Tasks Formulation ‣ 3 Preliminaries ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"))). Four mechanisms support each decision: 1) Consolidating distilled
    investment insights from multiple analyst agents. 2) Receiving timely risk alerts
    and conceptual investment updates from the risk control component. 3) Refining
    investment beliefs about the impact of various information sources on the manager’s
    decisions regarding a specific trading target. 4) Retrieving self-reflections
    based on the reasoning outcomes of previous trading actions.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.2 Risk-Control Component
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We innovatively design a dual-level risk-control mechanism comprising within-episode
    and over-episode risk management. The within-episode risk control mechanism detects
    market risk within a single training episode, enabling the manager agent to adjust
    trading actions promptly to prevent potential losses, which takes account of short-term
    trading performance and market fluctuations. Additionally, the within-episode
    risk control mechanism also operates during the testing stage. In contrast, the
    over-episode risk control mechanism only functions during the training stage,
    and it provides updating directions for prompt optimization by comparing the trading
    performance of the current episode with the previous one. This reflection helps
    the manager agent update its investment beliefs based on the differences in performance.
    Informed by prior observations of market risk and profitability patterns, these
    two mechanisms can potentially avoid repetitive investment mistakes, thereby enhancing
    gains for future investments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within-Episode Risk Control: . The within-episode risk alert is triggered by
    an instant drop in CVaR value. The rationale of this setting is that Conditional
    Value at Risk (CVaR) typically represents the average of the bottom 1% of past
    daily trading Profits and Losses (PnLs). When the CVaR value decreases on a given
    day, it often means that the PnLs from our trading decisions on the previous day
    (or days) are in the bottom 1%, indicating a potentially high-risk market condition.
    Once the within-episode risk is initiated, the manager agent is instructed to
    adopt a risk-averse attitude for the current day’s trading actions, regardless
    of the prior risk status.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Over-Episode Risk Control: The over-episode investment belief updates facilitate
    timely adjustments in the emphasis placed on the analyst’s information distillation
    and the manager’s action generation. Through the Actor-Critic mechanism, FinCon episodically
    optimizes its investment strategy for a given trading target by deeply reflecting
    on continuous winning and losing actions. The episodic reflection of investment
    beliefs is generated by a unique Conceptual Verbal Reinforcement (CVRF). CVRF
    evaluates the performance of every two adjacent training episodes based on the
    information perspectives provided by analysts and available in the manager’s trading
    reasoning. It then conceptualizes and attributes the evaluation outcomes to these
    aspects. By comparing the conceptualized aspects of investment insights from both
    more profitable and less profitable episodes, the system informs the manager and
    analyst agents about the necessary belief adjustments for each market information
    aspect to prioritize for greater profit, following the steps of Algorithm [1](#alg1
    "Algorithm 1 ‣ 4.1.2 Risk-Control Component ‣ 4.1 Synthesized Multi-agent Hierarchical
    Structure Design ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").
    CVRF utilizes text-based gradient descent to provide optimal conceptual investment
    guidance on a given target asset, substantially refining prompts with the latest
    investment beliefs for the manager agent. The obtained guidance is also meticulously
    organized from perspectives corresponding to insights from specific analyst agents,
    key financial indicators such as historical momentum, or other necessary perspectives.'
  prefs: []
  type: TYPE_NORMAL
- en: These investment belief updates are initially received by the manager agent
    and selectively propagated to relevant agent nodes, thereby minimizing over-communication.
    Additionally, unlike the text-based gradient descent proposed by Tang et al.[[19](#bib.bib19)],
    which uses prompt editing distance as the learning rate, we obtain investment
    belief prompt updates by measuring the overlapping percentage of trading actions
    between two adjacent training trajectories achieved at each investment belief
    update. This approach has proven effective in enhancing the performance of a synthesized
    agent system, where each worker has a clearly defined and specialized responsibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'Algorithm 1 Training Stage Algorithm of FinCon: Conceptual Verbal Reinforcement
    using Textual-based Gradient Descent'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize manager-analysts component $\{M_{pr}^{i}\}^{I}_{i=1}\&amp;M_{a}$  end while
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.3 FinCon Test Stage Workflow
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: During the testing stage, FinCon will utilize the investment beliefs learned
    from the training stage, and the over-episode risk control mechanism will no longer
    operate. However, the within-episode risk control mechanism will still function,
    allowing the manager agent to adjust trading actions in real-time based on short-term
    trading performance and market fluctuations. This ensures that even during testing,
    FinCon can promptly respond to market risks and potentially prevent losses while
    leveraging the knowledge gained during training.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 2 Testing Stage Algorithm of FinCon
  prefs: []
  type: TYPE_NORMAL
- en: Initialize trading start date $s$.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Modular Design of FinCon Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here, we explain the modular design of FinCon agents. Inspired by the recent
    works of Park et al. [[61](#bib.bib61)] and Sumers et al. [[71](#bib.bib71)] on
    developing the cognitive structure of language agents for human-like behavior,
    agents in FinCon integrate four modules to support their necessary functionalities,
    along with a shared general configuration, as detailed in Figure [3](#S4.F3 "Figure
    3 ‣ 4.2 Modular Design of FinCon Agents ‣ 4 General framework of FinCon ‣ FinCon:
    A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for
    Enhanced Financial Decision Making"):'
  prefs: []
  type: TYPE_NORMAL
- en: General Configuration and Profiling Module. The general configuration defines
    the task types (e.g., stock trading, portfolio management) and specifies the trading
    targets, including background information like trading sectors and performance
    overviews. The profiling module outlines the roles and responsibilities of each
    agent in text. The textual content from these two parts is concatenated and used
    to query investment-related events stored in the agents’ memory databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perception Module. This module defines how an agent interacts with the market,
    specifying what they perceive, receive, and send. These aspects of information
    vary among different functional agents, as illustrated in Figure [3](#S4.F3 "Figure
    3 ‣ 4.2 Modular Design of FinCon Agents ‣ 4 General framework of FinCon ‣ FinCon:
    A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for
    Enhanced Financial Decision Making").'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S4.F3.pic1" class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel"
    height="63.71" overflow="visible" version="1.1" width="600"><g transform="translate(0,63.71)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 46.68)"><foreignobject
    width="559.03" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#FFFFFF">General Configuration</foreignobject></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 20.48 7.5)"><foreignobject width="559.03" height="28.9"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">1\. Investment
    task introduction    2\. Trading target background 3\. Trading sectors          4\.
    Historical financial performance overview</foreignobject></g></g></svg><svg id="S4.F3.pic2"
    class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel" height="77.63"
    overflow="visible" version="1.1" width="600"><g transform="translate(0,77.63)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 63.28)"><foreignobject
    width="559.03" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#FFFFFF">Action Module</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 20.48 7.5)"><foreignobject width="559.03" height="45.51" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Manager Agent: 1\. Conduct:
    Trading actions. 2\. Reflect: Trading reasons and analyst agents’ contribution
    assessment.</foreignobject></g></g></svg><svg id="S4.F3.pic3" class="ltx_picture
    ltx_align_left ltx_centering ltx_figure_panel" height="181.48" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,181.48) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 20.48 164.45)"><foreignobject width="559.03"
    height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">Profiling
    Module</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0
    1.0 20.48 7.5)"><foreignobject width="559.03" height="146.67" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Manager Agent: 1\. Role assignment:
    You are an experienced trading manager in the investment firm … 2\. Role description:
    Your responsibilities are to consolidate investment insights from analysts and
    make trading actions on {asset symbols} … Analyst Agents: 1\. Role assignment:
    You are the investment analysts for news/ market data/ Form 10-K (Q)/ ECC audio
    recording … 2\. Role duty description: Your responsibilities are to distill investment
    insights and other indicators like financial sentiment for {asset symbols} …</foreignobject></g></g></svg><svg
    id="S4.F3.pic4" class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel"
    height="163.34" overflow="visible" version="1.1" width="600"><g transform="translate(0,163.34)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 146.3)"><foreignobject
    width="559.03" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#FFFFFF">Perception Module</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 20.48 7.5)"><foreignobject width="559.03" height="128.53" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Manager Agent: 1\. Perceive:
    Investment insights from analyst agents & Risk signal and trajectory-level investment
    belief updates from the risk control component. 2\. Send: Feedback to analyst
    agents about their contribution to significant investment earnings & losses. Analyst
    Agents: 1\. Perceive: Market information from certain information sources. 2\.
    Receive: Feedback from the manager agent.</foreignobject></g></g></svg><svg id="S4.F3.pic5"
    class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel" height="163.34"
    overflow="visible" version="1.1" width="600"><g transform="translate(0,163.34)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 146.3)"><foreignobject
    width="559.03" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#FFFFFF">Memory Module</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 20.48 7.5)"><foreignobject width="559.03" height="128.53" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Manager Agent: 1\. Working:
          - Consolidation          -Refinement 2\. Procedural:    - Trading action
    records    - Reflection records 3\. Episodic:       - Trajectory history Analyst
    Agents: 1\. Working:        - Observation    - Retrieval    - Distillation 2\.
    Procedural:     - Distilled Investment-related insights    - Financial sentiment
    - Investment report recommended actions</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: The detailed modular design of the manager and analyst agents. The
    general configuration and profiling modules generate text-based queries to retrieve
    investment-related information from the agents’ memory databases. The perceptual
    and memory modules interact with LLMs via prompts to extract key investment insights.
    The action module of the manager agent consolidates these insights to facilitate
    informed trading decisions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory Module. The memory module contains three key components: working memory,
    procedural memory, and episodic memory. Similar to how humans process events in
    their working memory [[72](#bib.bib72)], FinCon agents utilize a working memory
    component to perform a series of operations, including observation, distillation,
    and refinement on available memory events, tailored to the agents’ specific roles.
    Procedural memory and episodic memory are essential for recording historical actions,
    outcomes, and reflections during sequential decision-making. Procedural memory
    is created after each decision step within an episode, storing data as memory
    events. For a trading inquiry, top events are retrieved from procedural memory,
    which are ranked based on recency, relevancy, and importance, which is the simplified
    version based on Yu et al. [[23](#bib.bib23)] and detailed in Appendix [7.6](#S7.SS6
    "7.6 Ranking Metrics for Procedural Memory in FinCon ‣ 7 Appendix ‣ FinCon: A
    Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced
    Financial Decision Making"). Different functional analyst agents possesses distinct
    procedural memory decay rates, reflecting the timeliness of various financial
    data sources, which is crucial for aligning multi-type data impacting a specific
    time point and facilitating informed decision-making. The manager agent augments
    the procedural memory of analyst agents by providing feedback through access counter.
    Procedural memory is maintained by both analyst and manager agents, each keeping
    different records, as shown in Figure [3](#S4.F3 "Figure 3 ‣ 4.2 Modular Design
    of FinCon Agents ‣ 4 General framework of FinCon ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").
    The episodic memory, exclusive to the manager agent, retains actions, PnL series
    of the previous episodes and conceptualized updated investment beliefs from the
    risk control component.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Reasearch Questions (RQs). Our experiment addresses three major research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: $\diamond$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ1: Does FinCon demonstrate robustness across multiple financial decision-making
    tasks? We evaluate its performance on two challenging tasks: single-asset trading
    and portfolio management.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\diamond$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ2: Is the within-trajectory risk control mechanism in FinCon’s risk control
    component effective in maintaining superior decision-making performance?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\diamond$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ3: Is the over-trajectory risk control mechanism in FinCon’s risk control
    component effective for timely updating a manager agent’s beliefs and enhancing
    trading performance?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 5.1 Experimental Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Multi-Modal Datasets. We collect a multi-modal dataset from real-world financial
    information to construct a representation of the market environment. It is composed
    of stock price information, daily financial news, company filing reports, and
    ECC audio recordings ranging from August 1, 2020, to August 14, 2023, as detailed
    in Appendix. [7.1](#S7.SS1 "7.1 Raw Data Sources ‣ 7 Appendix ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"). Each data source features distinct timeliness and is assigned
    to separate analyst agents to process. Typically, the time-sensitivity of annual
    filing reports (Form 10K’s) is more persistent, that of quarterly filing reports
    (Form 10Q’s) and ECC are secondary, and the daily financial news is the most instantaneous.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation Metrics. We evaluate the performance of FinCon and compare it with
    other state-of-the-art (SOTA) LLM-based and DRL-based agent systems using three
    standard financial performance metrics: Cumulative Return (CR%) [[73](#bib.bib73)],
    the Sharpe Ratio (SR) [[74](#bib.bib74)] and Max Drawdown (MDD%) [[75](#bib.bib75)].
    Detailed definitions can be found in Appendix [7.3](#S7.SS3 "7.3 Formula of Classic
    Financial Metrics for Risk Estimator ‣ 7 Appendix ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Comparative Methods. For the single stock trading task, we assess FinCon’s
    performance against seven algorithmic agents and the Buy-and-Hold (B & H) strategy,
    a widely accepted baseline. These include three DRL-based agents from the FinRL
    framework [[76](#bib.bib76)]: A2C, PPO, and DQN, and four SOTA LLM-based agents:
    Generative Agent by Park et al. [[11](#bib.bib11)], FinGPT [[77](#bib.bib77)],
    FinMem [[23](#bib.bib23)], and FinAgent [[24](#bib.bib24)]. For the portfolio
    management task, FinCon competes against the classical Markowitz MV portfolio
    selection strategy [[1](#bib.bib1)], the RL-based FinRL-A2C agent [[76](#bib.bib76)]
    and the B & H strategy that is to hold an equal-weighted position in all trading
    assets (so-called equal-weighted ETF). Our focus on classical portfolio strategy,
    RL methods and B & H methods is due to the limited availability of mature LLM
    agents for portfolio management. The detailed experiment parameter configuration
    is detailed articulated in Appendix. [7.7](#S7.SS7 "7.7 Detailed Configurations
    in Experiments ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with
    Conceptual Verbal Reinforcement for Enhanced Financial Decision Making").'
  prefs: []
  type: TYPE_NORMAL
- en: Implementation Details. In our experiments, all large language model (LLM)-based
    agent systems employ GPT-4-Turbo as their backbone algorithm, with the temperature
    parameter set at 0.3 to balance response consistency and reasoning creativity.
    FinCon is trained on financial data from January 3, 2022, to October 4, 2022,
    and is tested with data from October 5, 2022, to June 10, 2023\. Given that deep
    reinforcement learning (DRL) algorithms require extensive training data for convergence,
    we extend the DRL agents’ training period to approximately five years, from January
    1, 2018, to October 14, 2022, ensuring a fair comparison. The testing period remains
    consistent across all models. The performance metrics are reported for the test
    trajectory with the median CR and SR from five repeated epochs. (If the median
    CR and SR do not belong to the same epoch, the performance is based on the trajectory
    with the median CR.)
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Main Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In response to RQ1, we conduct analyses on two types of financial decision-making
    tasks: single-asset trading and portfolio management. The capability of FinCon
    to handle such sequentially complex decisions is thoroughly evaluated in the subsequent
    sections.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.1 Single Asset Trading Task
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the first task, we evaluate the performance of FinCon against other leading
    algorithmic trading models by trading six different stocks. As shown in two tables
    above, FinCon significantly outperforms all the LLM-based and DRL-based approaches
    in terms of two primary metrics – cumulative returns and Sharpe Ratios. The FinCon’s
    Max Drawdown are also mostly among one of the lowest across all the trading assets,
    indicating a well-managed level of investment risk while still achieving the highest
    investment returns.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, even with extended training periods, DRL-based models generally underperform.
    Specifically, the A2C algorithm significantly trails behind other algorithmic
    trading agents. Here, the training periods for Nio Inc (NIO) and Coinbase Global
    Inc (COIN) needs to be clarified. NIO completed its IPOs in September, 2018, so
    its training period is slightly shorter than other tickers. But the DRL algorithms
    for NIO still achieved convergence.The IPO for Coinbase Global, Inc (COIN) was
    completed in April 2021\. With such limited trading data available, DRL algorithms
    struggle to converge, highlighting a significant limitation for DRL agents in
    automated trading of recent IPOs. Consequently, our analysis for COIN includes
    comparisons among FinCon, LLM-based trading agents, and the buy-and-hold strategy.
    In this analysis, FinCon demonstrates substantial performance advantages, achieving
    a cumulative return of over $57\%$. We also note that LLM-based agents, capable
    of utilizing diverse data types and requiring minimal training, effectively address
    the challenges that DRL algorithms face.
  prefs: []
  type: TYPE_NORMAL
- en: '| Categories | Models | TSLA |  | AMZN |  | NIO |'
  prefs: []
  type: TYPE_TB
- en: '| CR$\%\uparrow$ |'
  prefs: []
  type: TYPE_TB
- en: '| Market | B&H | 6.425 | 0.145 | 58.150 |  | 1.914 | 0.067 | 34.317 |  | -77.210
    | -1.449 | 63.975 |'
  prefs: []
  type: TYPE_TB
- en: '| Our Model | FinCon | 82.871 | 1.972 | 29.727 |  | 24.964 | 0.906 | 25.889
    |  | 17.461 | 0.335 | 40.647 |'
  prefs: []
  type: TYPE_TB
- en: '| LLM-based | GA | 16.535 | 0.391 | 54.131 |  | -5.515 | -0.195 | 37.213 |  |
    -3.176 | -1.574 | 3.155 |'
  prefs: []
  type: TYPE_TB
- en: '| FinGPT | 1.549 | 0.044 | 42.400 |  | -29.811 | -1.805 | -29.671 |  | -4.959
    | -0.121 | 37.344 |'
  prefs: []
  type: TYPE_TB
- en: '| FinMem | 34.624 | 1.552 | 15.674 |  | -18.126 | -0.776 | 36.825 |  | -48.437
    | -1.180 | 64.144 |'
  prefs: []
  type: TYPE_TB
- en: '| FinAgent | 11.960 | 0.271 | 55.734 |  | -24.704 | -1.496 | 33.151 |  | 0.933
    | 0.051 | 19.181 |'
  prefs: []
  type: TYPE_TB
- en: '| DRL-based | A2C | -35.644 | -0.805 | 61.502 |  | -12.676 | -0.447 | 37.179
    |  | -91.910 | -1.728 | 68.911 |'
  prefs: []
  type: TYPE_TB
- en: '| PPO | 1.409 | 0.032 | 49.740 |  | 3.863 | 0.137 | 28.085 |  | -72.119 | -1.352
    | 62.093 |'
  prefs: []
  type: TYPE_TB
- en: '| DQN | -1.296 | -0.029 | 58.150 |  | 11.171 | 0.398 | 31.174 |  | -35.419
    | -0.662 | 56.905 |  | Categories | Models | APPL |  | GOOG |  | COIN |'
  prefs: []
  type: TYPE_TB
- en: '| CR$\%\uparrow$ |'
  prefs: []
  type: TYPE_TB
- en: '| Market | B&H | 22.315 | 1.107 | 20.659 |  | 22.420 | 0.891 | 21.191 |  |
    -21.756 | -0.311 | 60.187 |'
  prefs: []
  type: TYPE_TB
- en: '| Our Model | FinCon | 27.352 | 1.597 | 15.266 |  | 25.077 | 1.0521 | 17.5299
    |  | 57.045 | 0.825 | 42.679 |'
  prefs: []
  type: TYPE_TB
- en: '| LLM-based | GA | 5.694 | 0.372 | 14.161 |  | -0.0151 | -0.192 | 8.210 |  |
    19.271 | 0.277 | 67.532 |'
  prefs: []
  type: TYPE_TB
- en: '| FinGPT | 20.321 | 1.161 | 16.759 |  | 0.207 | 0.822 | 21.191 |  | -99.553
    | -1.807 | 74.967 |'
  prefs: []
  type: TYPE_TB
- en: '| FinMem | 12.396 | 0.994 | 11.268 |  | 0.311 | 0.018 | 21.503 |  | 0.811 |
    0.017 | 50.390 |'
  prefs: []
  type: TYPE_TB
- en: '| FinAgent | 20.757 | 1.041 | 19.896 |  | -7.440 | -1.024 | 10.360 |  | -5.971
    | -0.106 | 56.882 |'
  prefs: []
  type: TYPE_TB
- en: '| DRL-based | A2C | 13.781 | 0.683 | 14.226 |  | 8.562 | 0.340 | 21.191 |  |
    - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| PPO | 14.041 | 0.704 | 22.785 |  | 2.434 | -0.097 | 25.202 |  | - | - | -
    |'
  prefs: []
  type: TYPE_TB
- en: '| DQN | 21.125 | 1.048 | 16.131 |  | 20.690 | 0.822 | 21.191 |  | - | - | -
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Comparison of key performance metrics during the testing period for
    the single-asset trading tasks involving six stocks, between FinCon and other
    algorithmic agents. Note that the highest and second highest CRs and SRs have
    been tested and found statistically significant using the Wilcoxon signed-rank
    test. The highest CRs and SRs are highlighted in red, while the second highest
    are marked in blue.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, in alignment with market trends, FinCon consistently exhibits superior
    sequential decision-making quality compared to other LLM-based financial agents,
    irrespective of whether the market conditions are bullish (e.g., GOOG), bearish
    (e.g., NIO), or mixed (e.g., TSLA). We attribute this performance to its high-quality
    distillation process through a synthesized multi-agent collaboration mechanism
    and its dual-functional risk control design, which collectively position FinCon
    as a leader in this space. Compared to FinCon, FinGPT primarily bases its trading
    decisions on the LLMs’ ability to interpret sentiment in financial information.
    This approach does not fully capitalize on the LLMs’ capacity to synthesize nuanced
    investment-related textual insights with numerical financial indicators. GA and
    FinMem, on the other hand, utilize single-agent frameworks that do not incorporate
    sophisticated information distillation processes or a diverse set of tools. This
    lack of complexity places considerable demand on the agent to process and reason
    through multi-sourced information, particularly when faced with large and varied
    data modalities. Additionally, they employ a static or minimal investment belief
    system. As a result, their ability to filter noise from mixed market data is relatively
    weak. As illustrated in Figure [7](#S5.F7 "Figure 7 ‣ 5.3.2 The Efficacy of Over-Episode
    Belief Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making") (a) & (b), this limitation leads them to consistently maintain
    a lower position and exhibit hesitation regarding ‘buy’ or ‘sell’ decisions, ultimately
    resulting in suboptimal performance. FinCon overcomes these limitations through
    its innovative multi-agent synthesis, enabling it to deliver better outcomes.
    While FinAgent positions itself as a foundational framework capable of utilizing
    multi-modal data, its performance is robust with images and tabular data but does
    not exhibit a competitive edge when integrating audio data, such as ECC audio,
    which is crucial in real-world trading. Additionally, its decision-relevant memory
    retrieval process is based on similarity, leading the agent to make current decisions
    based on outdated memories, often resulting in errors. In contrast, the memory
    structure of FinCon is designed to account for the varying timeliness of multi-sourced
    financial data, ultimately delivering significantly superior decision quality.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8e9d56beb232a243b6034550ac7b99ef.png)![Refer to caption](img/1a6777659900384ffa9b525ee3779b68.png)![Refer
    to caption](img/909bc411364430ddffcf2197ad25b2b3.png)![Refer to caption](img/1050c68bf689227beabed36208f8067f.png)![Refer
    to caption](img/42598960cd06797d8e3c91e082a718e5.png)![Refer to caption](img/962953bac0ce93b5a4727bb252d65a1d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: CRs over time for single-asset trading tasks. FinCon outperformed
    other comparative strategies, achieving the highest CRs across all six stocks
    by the end of the testing period, regardless of market conditions.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.2 Portfolio Management Task
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To address the first research question, we compare FinCon’s performance with
    the Markowitz Mean-Variance (MV) portfolio [[78](#bib.bib78)] and FinRL [[76](#bib.bib76)]
    in managing a small portfolio of TSLA, MSFT, and PFE. Those assets are chosen
    by the stock selection agent from 42 stocks with sufficient amount of news data
    (over $800$ new messages in the training and test periods together), referring
    to Figure [9](#S7.F9 "Figure 9 ‣ 7.2 Distribution of Data ‣ 7 Appendix ‣ FinCon:
    A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for
    Enhanced Financial Decision Making") in Appendix [7.2](#S7.SS2 "7.2 Distribution
    of Data ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual
    Verbal Reinforcement for Enhanced Financial Decision Making"). The training &
    testing periods and backbone algorithm are consistent with those used in the single-asset
    trading task. For the Markowitz MV portfolio, we estimate the covariance matrix
    and expected returns using the same training data. For FinRL, we use 5-year training
    data before the test period. Our results, detailed in Table [3](#S5.T3 "Table
    3 ‣ Figure 5 ‣ 5.2.2 Portfolio Management Task ‣ 5.2 Main Results ‣ 5 Experiments
    ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making"), show that FinCon outperforms both the
    Markowitz MV portfolio and FinRL, achieving significantly higher cumulative returns
    and Sharpe Ratio, and lower Maximum Drawdown (MDD).'
  prefs: []
  type: TYPE_NORMAL
- en: However, there are stronger indications of hallucination in the multi-asset
    decision-making task compared to single-asset trading due to increased complexity
    and input length. Although FinCon reduces the workload of individual agents by
    distributing tasks and focusing on essential investment insights, it can still
    occasionally produce incorrect information, such as generating non-existent memory
    IDs and misclassifying action types (e.g., outputting ‘buy’ and ‘sell’ instead
    of ‘long’ and ‘short’). Handling multi-asset decision-making tasks requires intricate
    logic and substantial market information, posing a significant challenge for LLMs
    to comprehend extended contexts. This challenge has left portfolio management
    an untapped field for previous language agent studies. However, FinCon demonstrates
    the potential of constructing agent systems that can address complex financial
    problems through resource optimization, even when managing a relatively compact
    portfolio.
  prefs: []
  type: TYPE_NORMAL
- en: Models CR % $\uparrow$ FinCon 121.018 3.435 16.288 Markowitz MV 32.521 1.423
    20.658 FinRL-A2C 33.479 1.352 27.124 Equal-Weighted ETF 19.983 1.003 22.807
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Key performance metrics comparison among all portfolio management
    strategies. FinCon leads all performance metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cfb78d995cc88a7a23f75c56634026b2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Portfolio value (CR for portfolio) changes over time for all the
    strategies.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Ablation Studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we comprehensively evaluate our unique risk control component
    through two ablation studies. The first study assesses its ability to control
    risk within episodes using conditional value at risk (CVaR). The second study
    highlights the importance of the over-episode risk control mechanism in updating
    the trading manager agent’s beliefs for a holistic understanding of current trading
    circumstances. Consistency in training and testing periods is maintained with
    the main experiments for both single stock trading and portfolio management tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.1 The Effectiveness of Within-Episode Risk Control mechanism via CVaR
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To answer the RQ2, we conduct the first ablation study. We assess the efficacy
    of FinCon’s within-episode risk control mechanisms by monitoring system risk changes
    through CVaR. To demonstrate the robustness of FinCon, we compare the performance
    of FinCon with versus without CVaR implementation across two task types: single-asset
    trading and portfolio management. Furthermore, in single-asset trading tasks,
    we consider assets in both general bullish and bearish market conditions in the
    testing phase for comprehensive consideration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our results demonstrate that implementing CVaR in FinCon is highly effective
    across all financial metrics for both task types, as shown in Table [4](#S5.T4
    "Table 4 ‣ 5.3.1 The Effectiveness of Within-Episode Risk Control mechanism via
    CVaR ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized LLM Multi-Agent
    System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making")
    and Fig [6](#S5.F6 "Figure 6 ‣ 5.3.1 The Effectiveness of Within-Episode Risk
    Control mechanism via CVaR ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A
    Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced
    Financial Decision Making"). For single-asset trading tasks, FinCon without within-episode
    risk control yields negative CRs and significantly higher MDDs, underperforming
    compared to the Buy-and-Hold strategy (CR of GOOG: $22.42\%$ with within-episode
    risk control, demonstrating its effectiveness in risk supervision even amid non-uniform
    market trends.'
  prefs: []
  type: TYPE_NORMAL
- en: Task Assets Market Trend Models CR %$\uparrow$ w/ CVaR 7.981 0.157 40.647 w/o
    CVaR -70.791 -1.383 70.243 Portfolio Management (TSLA, MSFT, PFE) Mixed w/ CVaR
    121.018 3.435 16.288 w/o CVaR 16.994 1.303 17.646
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Key metrics FinCon with vs. without implementing CVaR for within-episode
    risk control. The performance of FinCon with the implementation of CVaR won a
    leading performance in both single-asset trading and portfolio management tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/00f4935630b3b3e59fb46a5825f239b8.png)'
  prefs: []
  type: TYPE_IMG
- en: '(a) [1] Single Stock: General Bullish'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ac47a018e2261fd74e53370b93f12294.png)'
  prefs: []
  type: TYPE_IMG
- en: '(b) [2] Single Stock: General Bearlish'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/57a14282ce4d244bcb6541b27d345fbf.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Multi-Assets
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: CRs of FinCon with vs. without implementing CVaR for within-episode
    risk control show that the CVaR mechanism significantly improves FinCon’s performance.
    This is evident from two metrics: (a) cumulative returns over time for single
    stocks in both bullish and bearish market conditions, and (b) portfolio value
    over time for a multi-asset portfolio. In both cases, FinCon with CVaR demonstrates
    substantially higher cumulative returns.'
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, the success of utilizing CVaR for within-episode risk control
    is evident in both bullish and bearish market environments, as shown in the single
    asset trading case. In bullish markets, CVaR sharply captures immediate market
    shocks and timely informs FinCon to exercise caution, even amidst general optimism.
    Conversely, in bearish markets, CVaR consistently alerts FinCon to significant
    price drops, ensuring awareness of market risks. Moreover, in portfolio trading
    with mixed price trends, our within-episode risk control mechanism performs robustly
    by monitoring the entire portfolio’s value fluctuations, enabling the trading
    manager agent to adjust potentially aggressive operations for each asset promptly.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.2 The Efficacy of Over-Episode Belief Updates Using CVRF
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the second ablation study, to answer RQ3, we use the same assets to examine
    the effectiveness of FinCon’s over-episode risk control mechanisms. This is achieved
    by consistently improving FinCon’s beliefs about market conditions for the targeted
    assets. To ensure consistent belief output for each training episode, we set the
    temperature parameter to 0 specifically for belief generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We collect third-time belief updates over four training episodes using our
    innovative CVRF mechanism. The overlap of trading actions between the last two
    adjacent episodes increases to over $80\%$, and the updated investment beliefs
    are mostly aligned. To illustrate FinCon’s evolving investment beliefs through
    iterative training, we use the GOOG investment belief update as an example, as
    shown in Figure [8](#S5.F8 "Figure 8 ‣ 5.3.2 The Efficacy of Over-Episode Belief
    Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"). Compared to the initial and final belief updates, each conceptual
    aspect, such as historical momentum and news insights, is enriched with executable
    information through our CRVF mechanism, leading to more profitable actions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The results in Table [5](#S5.T5 "Table 5 ‣ 5.3.2 The Efficacy of Over-Episode
    Belief Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making") and Figure [7](#S5.F7 "Figure 7 ‣ 5.3.2 The Efficacy of Over-Episode
    Belief Updates Using CVRF ‣ 5.3 Ablation Studies ‣ 5 Experiments ‣ FinCon: A Synthesized
    LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making") indicate that the over-episode belief update mechanism is more
    critical than within-episode risk control in enhancing FinCon’s decision-making.
    Without this functionality, key metrics like CR, SR, and MDD are lower than without
    the within-episode risk control in single asset trading. Although the CR of $20.677\%$.
    These results demonstrate that using CVRF to update investment beliefs over episodes
    efficiently steers the agent’s investment beliefs towards more profitable directions.
    FinCon achieves superior performance on multiple tasks, with learning gains evident
    after just four training episodes, requiring far fewer episodes than traditional
    RL algorithmic trading agents.'
  prefs: []
  type: TYPE_NORMAL
- en: Task Assets Market Trend Models CR %$\uparrow$ w/ belief 7.981 0.157 40.647
    w/o belief -17.956 -0.356 55.688 Portfolio Management (TSLA, MSFT, PFE) Mixed
    w/ belief 121.018 3.435 16.288 w/o belief 20.677 0.987 23.975
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: Key metrics FinCon with vs. without implementing belief updates for
    over-trajectory risk control. The performance of FinCon with the implementation
    of CVaR won a leading performance in both single-asset trading and portfolio management
    tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cc82eb6b272820b149d212f95da4b459.png)'
  prefs: []
  type: TYPE_IMG
- en: '(a) [1] Single Stock: General Bullish'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/28198ac7164b3a33fe17ba3152bee47c.png)'
  prefs: []
  type: TYPE_IMG
- en: '(b) [2] Single Stock: General Bearlish'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/19129b6932e7b32ad9e513e629f4bd36.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Multi-Assets
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7: CRs of FinCon with vs. without belief updates for over-trajectory
    risk control. (a) The CRs over time for single stocks. The performance of FinCon
    with belief updates consistently leads in both bullish and bearish market conditions.
    (b) The CRs over time for multi-asset portfolio. FinCon’s performance with belief
    updates also won a substantially higher CR.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S5.F8.pic1" class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel"
    height="466.52" overflow="visible" version="1.1" width="600"><g transform="translate(0,466.52)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 449.49)"><foreignobject
    width="559.03" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#FFFFFF">Updated Investment Belief Contents</foreignobject></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 20.48 7.5)"><foreignobject width="559.03" height="431.71"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">First Update:
    {’historical momentum’: ’Enhance the use of momentum indicators by establishing
    systematic rules for entry and exit based on momentum values to improve consistency
    and predictability in trading actions.’, ’news insights’: ’Integrate advanced
    real-time news sentiment analysis to better understand immediate market reactions
    and adjust trading strategies accordingly…’, ’Form 10-Q’: ’Incorporating annual
    report insights (10-K) could provide a comprehensive view of the company’s long-term
    performance and strategic direction, aiding in more informed decision-making.’…,
    ’other aspects’: [’sector trends’, ’technological advancements’], …} Last Update:
    {’historical momentum’: ’The more profitable strategy effectively utilizes negative
    momentum values to make timely sell decisions, avoiding potential losses during
    downward trends, and effectively utilizes positive momentum values to make timely
    buy decisions, facilitating potential gains during upward trends. It is suggested
    to refine the use of momentum indicators, possibly by adjusting thresholds or
    incorporating additional short-term momentum metrics to enhance the timing and
    accuracy of buy/sell decisions.’, ’news insights’: ’It is recommended to further
    develop a systematic approach to quantify the impact of news, especially the sentiment
    scores and regulatory changes, to refine trading decisions.’, ’Form 10-Q’: ’It
    is suggested that even if there is a strong financial performance present 10-Q
    reports, it is better to prioritize immediate market signals. For future strategies,
    it is suggested to balance these aspects more evenly, especially in stable or
    bullish market conditions, to avoid premature exits from potentially profitable
    positions.’,…, ’other aspects’: [’sector trends’, ’technological advancements’,
    ’macroeconomic factors’, ’regulatory risks’], …}</foreignobject></g></g></svg><svg
    id="S5.F8.pic2" class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel"
    height="81.09" overflow="visible" version="1.1" width="600"><g transform="translate(0,81.09)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 64.05)"><foreignobject
    width="559.03" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#FFFFFF">Tradng Action Overlapping Percentages</foreignobject></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 20.48 7.5)"><foreignobject width="559.03" height="46.28"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">1\. Second
    vs. First Training Episode:   $46.939\%$</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: The first time and last time LLM generated investment belief updates
    by CVRF for GOOG.'
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we present FinCon, a novel LLM-based multi-agent framework for
    financial decision-making tasks, including single stock trading and portfolio
    management. Central to FinCon is the Synthesized Manager-Analyst hierarchical
    communication structure and a dual-level risk control component. This communication
    method channels financial data from multiple sources to specialized analyst agents,
    who distill it into key investment insights. The manager agent then synthesizes
    these insights for decision-making. Our experimental evaluations demonstrate the
    efficacy of our risk control mechanism in mitigating investment risks and enhancing
    trading performance. Additionally, the streamlined communication structure reduces
    overhead. The dual-layered risk control component introduces a novel approach
    to defining agent personas, enabling dynamic updates of systematic risk and market
    beliefs within agent communication. A valuable future research direction would
    be to scale FinCon’s framework to manage large-sized portfolios comprising tens
    of assets, while maintaining the impressive decision-making quality demonstrated
    with smaller portfolios. Given the LLM’s input length constraint, a critical challenge
    lies in striking an optimal balance between information conciseness through agent
    distillation and potential performance deterioration when extending the current
    context window. Addressing this will be essential for ensuring quality-assured
    outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Harry Markowitz. Portfolio selection. The Journal of Finance, 7(1):77–91,
    1952.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Xuan-Hong Dang, Syed Yousaf Shah, and Petros Zerfos. " the squawk bot":
    Joint learning of time series and text data modalities for automated financial
    information filtering. arXiv preprint arXiv:1912.10858, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] John L Maginn, Donald L Tuttle, Dennis W McLeavey, and Jerald E Pinto.
    Managing investment portfolios: a dynamic process, volume 3. John Wiley & Sons,
    2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Roy Radner. The organization of decentralized information processing. Econometrica:
    Journal of the Econometric Society, pages 1109–1146, 1993.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] George A Miller. The magical number seven, plus or minus two: Some limits
    on our capacity for processing information. Psychological review, 63(2):81, 1956.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Rundong Wang, Hongxin Wei, Bo An, Zhouyan Feng, and Jun Yao. Commission
    fee is not enough: A hierarchical reinforced framework for portfolio management.
    In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages
    626–633, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Weiguang Han, Boyi Zhang, Qianqian Xie, Min Peng, Yanzhao Lai, and Jimin
    Huang. Select and trade: Towards unified pair trading with hierarchical reinforcement
    learning. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery
    and Data Mining, pages 4123–4134, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Molei Qin, Shuo Sun, Wentao Zhang, Haochong Xia, Xinrun Wang, and Bo An.
    Earnhft: Efficient hierarchical reinforcement learning for high frequency trading.
    In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages
    14669–14676, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao,
    and Yu Su. Llm-planner: Few-shot grounded planning for embodied agents with large
    language models. In Proceedings of the IEEE/CVF International Conference on Computer
    Vision, pages 2998–3009, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi,
    Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning
    and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris,
    Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra
    of human behavior. arXiv preprint arXiv:2304.03442, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen
    llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou,
    Yuchen Eleanor Jiang, Chengfei Lv, and Huajun Chen. Autoact: Automatic agent learning
    from scratch via self-planning. arXiv preprint arXiv:2401.05268, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao
    Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt:
    Meta programming for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia Vélez, Qingyun
    Wu, Huazheng Wang, Thomas L Griffiths, and Mengdi Wang. Embodied llm agents learn
    to cooperate in organized teams. arXiv preprint arXiv:2403.12482, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang,
    Weizhi Ma, and Yang Liu. Agent hospital: A simulacrum of hospital with evolvable
    medical agents. arXiv preprint arXiv:2405.02957, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min
    Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, et al. Agentverse: Facilitating
    multi-agent collaboration and exploring emergent behaviors. In The Twelfth International
    Conference on Learning Representations, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael
    Zeng. Automatic prompt optimization with" gradient descent" and beam search. arXiv
    preprint arXiv:2305.03495, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Xinyu Tang, Xiaolei Wang, Wayne Xin Zhao, Siyuan Lu, Yaliang Li, and Ji-Rong
    Wen. Unleashing the potential of large language models as prompt optimizers: An
    analogical analysis with gradient-based model optimizers. arXiv preprint arXiv:2402.17564,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng,
    Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et al. Retroformer:
    Retrospective large language agents with policy gradient optimization. arXiv preprint
    arXiv:2308.02151, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and
    Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. Advances
    in Neural Information Processing Systems, 36, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. Fingpt: Open-source
    financial large language models. arXiv preprint arXiv:2306.06031, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang,
    Rong Liu, Jordan W Suchow, and Khaldoun Khashanah. Finmem: A performance-enhanced
    llm trading agent with layered memory and character design. arXiv preprint arXiv:2311.13743,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei
    Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, et al. Finagent: A multimodal
    foundation agent for financial trading: Tool-augmented, diversified, and generalist.
    arXiv preprint arXiv:2402.18485, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Freddy Delbaen and Sara Biagini. Coherent risk measures. Springer, 2000.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Frank J Fabozzi, Sergio M Focardi, and Petter N Kolm. Quantitative equity
    investing: Techniques and strategies. John Wiley & Sons, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Xinyi Liu, Chong Zhang, Mingyu Jin, Zhongmou Zhang, Zhenting Wang, Dong
    Shu, Suiyuan Zhu, Sujian Li, Mengnan Du, and Yongfeng Zhang. When ai meets finance
    (stockagent): Large language model-based stock trading in simulated real-world
    environments. 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Keith Kuester, Stefan Mittnik, and Marc S Paolella. Value-at-risk prediction:
    A comparison of alternative strategies. Journal of Financial Econometrics, 4(1):53–89,
    2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous
    agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and
    Gao Huang. Expel: Llm agents are experiential learners. In Proceedings of the
    AAAI Conference on Artificial Intelligence, volume 38, pages 19632–19642, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser,
    Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al.
    Competition-level code generation with alphacode. Science, 378(6624):1092–1097,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang
    Lou, and Weizhu Chen. Codet: Code generation with generated tests. arXiv preprint
    arXiv:2207.10397, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu, and Maosong Sun. Communicative agents for software development. arXiv preprint
    arXiv:2307.07924, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. Language agents with
    reinforcement learning for strategic play in the werewolf game. arXiv preprint
    arXiv:2310.18940, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Weiyu Ma, Qirui Mi, Xue Yan, Yuqiao Wu, Runji Lin, Haifeng Zhang, and
    Jun Wang. Large language models play starcraft ii: Benchmarks and a chain of summarization
    approach. arXiv preprint arXiv:2312.11865, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] J de Curtò, I de Zarzà, Gemma Roig, Juan Carlos Cano, Pietro Manzoni,
    and Carlos T Calafate. Llm-informed multi-armed bandit strategies for non-stationary
    environments. Electronics, 12(13):2814, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu,
    Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, et al. Revolutionizing finance
    with llms: An overview of applications and insights. arXiv preprint arXiv:2401.11641,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Yupeng Cao, Zhi Chen, Qingyun Pei, Fabrizio Dimino, Lorenzo Ausiello,
    Prashant Kumar, KP Subbalakshmi, and Papa Momar Ndiaye. Risklabs: Predicting financial
    risk using large language model based on multi-sources data. arXiv preprint arXiv:2404.07452,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Lorenzo Canese, Gian Carlo Cardarilli, Luca Di Nunzio, Rocco Fazzolari,
    Daniele Giardino, Marco Re, and Sergio Spanò. Multi-agent reinforcement learning:
    A review of challenges and applications. Applied Sciences, 11(11):4948, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] Kaiqing Zhang, Zhuoran Yang, and Tamer Başar. Multi-agent reinforcement
    learning: A selective overview of theories and algorithms. Handbook of reinforcement
    learning and control, pages 321–384, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Jakob Foerster, Ioannis Alexandros Assael, Nando De Freitas, and Shimon
    Whiteson. Learning to communicate with deep multi-agent reinforcement learning.
    Advances in neural information processing systems, 29, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Toru Lin, Jacob Huh, Christopher Stauffer, Ser Nam Lim, and Phillip Isola.
    Learning to ground multi-agent communication with autoencoders. Advances in Neural
    Information Processing Systems, 34:15230–15242, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] Woojun Kim, Jongeui Park, and Youngchul Sung. Communication in multi-agent
    reinforcement learning: Intention sharing. In International Conference on Learning
    Representations, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Changxi Zhu, Mehdi Dastani, and Shihan Wang. A survey of multi-agent reinforcement
    learning with communication. arXiv preprint arXiv:2203.08975, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Zhiyuan Yao, Zheng Li, Matthew Thomas, and Ionut Florescu. Reinforcement
    learning in agent-based market simulation: Unveiling realistic stylized facts
    and behavior. arXiv preprint arXiv:2403.19781, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Kuan Wang, Yadong Lu, Michael Santacroce, Yeyun Gong, Chao Zhang, and
    Yelong Shen. Adapting llm agents through communication. arXiv preprint arXiv:2310.01444,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Zhao Mandi, Shreeya Jain, and Shuran Song. Roco: Dialectic multi-robot
    collaboration with large language models. arXiv preprint arXiv:2307.04738, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B
    Tenenbaum, Tianmin Shu, and Chuang Gan. Building cooperative embodied agents modularly
    with large language models. arXiv preprint arXiv:2307.02485, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch.
    Improving factuality and reasoning in language models through multiagent debate.
    arXiv preprint arXiv:2305.14325, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu, and Zhiyuan Liu. Chateval: Towards better llm-based evaluators
    through multi-agent debate. arXiv preprint arXiv:2308.07201, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Frank Xing. Designing heterogeneous llm agents for financial sentiment
    analysis. arXiv preprint arXiv:2401.05799, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Irene de Zarzà i Cubero, Joaquim de Curtò i Díaz, Gemma Roig, and Carlos T
    Calafate. Optimized financial planning: Integrating individual and cooperative
    budgeting models with llm recommendations. 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] Xiangpeng Wan, Haicheng Deng, Kai Zou, and Shiqi Xu. Enhancing the efficiency
    and accuracy of underlying asset reviews in structured finance: The application
    of multi-agent framework. arXiv preprint arXiv:2405.04294, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] Xinyi Liu, Chong Zhang, Mingyu Jin, Zhongmou Zhang, Zhenting Wang, Dong
    Shu, Suiyuan Zhu, Sujian Li, Mengnan Du, and Yongfeng Zhang. When ai meets finance
    (stockagent): Large language model-based stock trading in simulated real-world
    environments. 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Patrick Bolton and Mathias Dewatripont. The firm as a communication network.
    The Quarterly Journal of Economics, 109(4):809–839, 1994.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv
    preprint arXiv:2210.03629, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
    Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in
    large language models. Advances in neural information processing systems, 35:24824–24837,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan
    Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with
    large language models. Advances in Neural Information Processing Systems, 36,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang,
    and Zhiting Hu. Reasoning with language model is planning with world model. arXiv
    preprint arXiv:2305.14992, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang,
    Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally
    capable agents for open-world enviroments via large language models with text-based
    knowledge and memory. arXiv preprint arXiv:2305.17144, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Theodore Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L. Griffiths.
    Cognitive architectures for language agents, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang,
    Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language
    model based autonomous agents. Frontiers of Computer Science, 18(6):1–26, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Leslie Pack Kaelbling, Michael L Littman, and Andrew W Moore. Reinforcement
    learning: A survey. Journal of artificial intelligence research, 4:237–285, 1996.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang, Zhiwei
    Xu, Dapeng Li, Ziyue Li, Rui Zhao, et al. Controlling large language model-based
    agents for large-scale decision-making: An actor-critic approach. arXiv preprint
    arXiv:2311.13884, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] Matthijs TJ Spaan. Partially observable markov decision processes. In
    Reinforcement learning: State-of-the-art, pages 387–414\. Springer, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Frank J Fabozzi, Harry M Markowitz, and Francis Gupta. Portfolio selection.
    Handbook of finance, 2, 2008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Yang Liu, Qi Liu, Hongke Zhao, Zhen Pan, and Chuanren Liu. Adaptive quantitative
    trading: An imitative deep reinforcement learning approach. In Proceedings of
    the AAAI conference on artificial intelligence, volume 34, pages 2128–2135, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Taylan Kabbani and Ekrem Duman. Deep reinforcement learning approach for
    trading automation in the stock market. IEEE Access, 10:93564–93574, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] Thomas L Griffiths, Jian-Qiao Zhu, Erin Grant, and R Thomas McCoy. Bayes
    in the age of intelligent machines. arXiv preprint arXiv:2311.10206, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] Ashwin Rao and Tikhon Jelvis. Foundations of reinforcement learning with
    applications in finance. Chapman and Hall/CRC, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] Jintian Zhang, Xin Xu, and Shumin Deng. Exploring collaboration mechanisms
    for llm agents: A social psychology view. arXiv preprint arXiv:2310.02124, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] Anthony D Wagner. Working memory contributions to human learning and remembering.
    Neuron, 22(1):19–22, 1999.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] John Hull. Risk Management and Financial Institutions. John Wiley & Sons,
    2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] William F. Sharpe. The sharpe ratio. The Journal of Portfolio Management,
    21(1):49–58, 1994.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Andrew Ang and Joseph Chen. Downside risk. Journal of Portfolio Management,
    29(4):103–112, 2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Xiao-Yang Liu, Hongyang Yang, Qian Chen, Runjia Zhang, Liuqing Yang, Bowen
    Xiao, and Christina Dan Wang. Finrl: A deep reinforcement learning library for
    automated stock trading in quantitative finance. arXiv preprint arXiv:2011.09607,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] Xiao-Yang Liu, Guoxuan Wang, and Daochen Zha. Fingpt: Democratizing internet-scale
    data for financial large language models. arXiv preprint arXiv:2307.10485, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] Harry M Markowitz and G Peter Todd. Mean-variance analysis in portfolio
    choice and capital markets, volume 66. John Wiley & Sons, 2000.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Yu Qin and Yi Yang. What you say and how you say it matters: Predicting
    stock volatility using verbal and vocal cues. In Proceedings of the 57th Annual
    Meeting of the Association for Computational Linguistics, pages 390–401, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Linyi Yang, Tin Lok James Ng, Barry Smyth, and Riuhai Dong. Html: Hierarchical
    transformer-based multi-task learning for volatility prediction. In Proceedings
    of The Web Conference 2020, pages 441–451, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] John C Hull. Options, Futures, and Other Derivatives. Pearson Education,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] Xiao-Yang Liu, Hongyang Yang, Jiechao Gao, and Christina Dan Wang. FinRL:
    Deep reinforcement learning framework to automate trading in quantitative finance.
    ACM International Conference on AI in Finance (ICAIF), 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] Xiao-Yang Liu, Ziyi Xia, Jingyang Rui, Jiechao Gao, Hongyang Yang, Ming
    Zhu, Christina Wang, Zhaoran Wang, and Jian Guo. Finrl-meta: Market environments
    and benchmarks for data-driven financial reinforcement learning. Advances in Neural
    Information Processing Systems, 35:1835–1849, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg
    Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
    Antonoglou, Daan Wierstra, and Martin Riedmiller. Playing atari with deep reinforcement
    learning. arXiv preprint arXiv:1312.5602, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] Jaap MJ Murre and Joeri Dros. Replication and analysis of ebbinghaus’
    forgetting curve. PloS one, 10(7):e0120644, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] Guardrails ai. [https://docs.guardrailsai.com](https://docs.guardrailsai.com).
    Open source library for interacting with Large Language Models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7 Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 7.1 Raw Data Sources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We assessed the performance of FinCon using multi-modal financial data from
    August 15, 2020, to August 15, 2023, sourced from reputable databases and APIs
    including Yahoo Finance (via yfinance), Alpaca News API, and Capital IQ, detailed
    explained in Table. These data, initially stored in the Raw Financial Data Warehouse
    as available observations of the financial market environment, are diverged into
    the corresponding FinCon’s Analysts’ Procedural Memory Databases based on timeliness
    through working memory’s summarization operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Sources News data associated with ticker: News data is sourced from REFINITIV
    REAL-TIME NEWS mainly contains news from Reuters. Form 10-Q, Part 1 Item 2 (Management’s
    Discussion and Analysis of Financial Condition and Results of Operations): Quarterly
    reports (Form 10-Q) are required by the U.S. Securities and Exchange Commission
    (SEC). Form 10-k, Section 7 (Management’s Discussion and Analysis of Financial
    Condition and Results of Operations): Annual reports (Form 10-K) are required
    by the U.S. Securities and Exchange Commission (SEC), sourced from EDGAR, and
    downloaded via SEC API. Historical stock price: Daily open price, high price,
    close price, adjusted close price, and volume data from Yahoo Finance. Zacks Equity
    Research: Zacks Rank: The Zacks Rank is a short-term rating system that is most
    effective over the one- to three-month holding horizon. The underlying driver
    for the quantitatively-determined Zacks Rank is the same as the Zacks Recommendation
    and reflects trends in earnings estimate revisions. Zacks Analyst: Reason to Sell,
    Reason to Buy, and potential risks. Earning Conference Calls (ECC): ECC is a type
    of unstructured financial data (audio) that is crucial for understanding market
    dynamics and investor sentiment. The company executive board delivers ECC about
    recent financial outcomes, future projections, and strategic directions. Recent
    studies have underscored the importance of not only the textual content of these
    calls but also the audio feature. Analyses have revealed that the audio elements—such
    as tone, pace, and inflections—offer significant predictive value regarding company
    performance and stock movements [[79](#bib.bib79), [80](#bib.bib80)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Raw data and memory warehouses of FinCon'
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Distribution of Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1d951e17316978f1069db7ec6b2542a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: The distribution of news from REFINITIV REAL-TIME NEWS for the 42
    stocks in the experiments'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/68c91771a83639e3b1bd77478effe6e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: The distribution of 10k10q from Securities and Exchange Commission
    (SEC) for the 42 stocks in the experiments'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b3ff465ef0c4674e7ce0c04e76008b53.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: The distribution of Analyst Report from Zacks Equity Research for
    the 42 stocks in the experiments'
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Formula of Classic Financial Metrics for Risk Estimator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Profit and Loss (PnL)[[81](#bib.bib81)]: PnL quantifies the net outcome of
    trading activities over a specified period by accounting for the realized gains
    and losses from financial instruments like stocks and derivatives.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Value at Risk (VaR) of PnL[[81](#bib.bib81)]: VaR is a statistical tool used
    to estimate the potential loss in a portfolio, within a defined confidence interval.
    Mathematically, it is defined as Equation [2](#S7.E2 "In 7.3 Formula of Classic
    Financial Metrics for Risk Estimator ‣ 7 Appendix ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{VaR}_{\alpha}(PnL)=\inf\left\{l\in\mathbb{R}:\mathbb{P}(PnL\leq
    l)\geq\alpha\right\}$ |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: where $\alpha$ is the confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conditional Value at Risk (CVaR) of PnL[[81](#bib.bib81)]: CVaR is a statistical
    tool used to estimate the expected potential loss worse than the VaR value in
    a portfolio, within a defined confidence interval. Mathematically, it is defined
    as Equation [3](#S7.E3 "In 7.3 Formula of Classic Financial Metrics for Risk Estimator
    ‣ 7 Appendix ‣ FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal
    Reinforcement for Enhanced Financial Decision Making"):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{CVaR}_{\alpha}(PnL)=\mathbb{E}\Big{\{}PnL&#124;PnL\leq\text{VaR}_{\alpha}(PnL)\Big{\}}$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where $\alpha$ is the confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cumulative Return of PnL [[73](#bib.bib73)]: Cumulative Return is a key trading
    performance metric because it provides a comprehensive insight into investment
    performance, especially for strategies that emphasize long-term growth and reinvestment.
    The effectiveness of different investment strategies is evaluated based on their
    Cumulative Returns, which reflect the total change in value over time. In this
    study, we compute Cumulative Returns over the specified period by summing daily
    logarithmic returns, as outlined in Equation [4](#S7.E4 "In 7.3 Formula of Classic
    Financial Metrics for Risk Estimator ‣ 7 Appendix ‣ FinCon: A Synthesized LLM
    Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial
    Decision Making"). This method is widely accepted in the finance area due to its
    ability to precisely capture minor price fluctuations and symmetrically address
    gains and losses. In essence, a higher Cumulative Return typically indicates a
    more effective strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Cumulative Return | $\displaystyle=\sum_{t=1}^{n}r_{i}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\sum_{t=1}^{n}\left[\ln\left(\frac{p_{t+1}}{p_{t}}\right)\cdot\text{action}_{t}\right],$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $r_{i}$ denotes the trading decision made by the model for that day.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sharpe Ratio of PnL [[74](#bib.bib74)]: Sharpe Ratio is another core metric
    for evaluating investment performance and adjusting returns for risk. It is calculated
    by dividing the portfolio’s average PnL ($R_{p}$), as shown in Equation [5](#S7.E5
    "In 7.3 Formula of Classic Financial Metrics for Risk Estimator ‣ 7 Appendix ‣
    FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making"). This metric adjusts returns for risk,
    with a higher ratio indicating better risk-adjusted performance. Essential in
    comparing different portfolios or strategies, it contextualizes performance against
    similar investments. Although a Sharpe Ratio above 1 is typically considered favorable
    and above 2 as excellent, these benchmarks can vary depending on the context of
    comparison.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textbf{Sharpe Ratio}=\frac{R_{p}-R_{f}}{\sigma_{p}}$ |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: 'Max Drawdown of PnL [[75](#bib.bib75)]: Max Drawdown is a metric for assessing
    risk. It represents the most significant decrease in a portfolio’s value, from
    its highest ($P_{\text{peak}}$) until a new peak emerges, detailed in Equation [6](#S7.E6
    "In 7.3 Formula of Classic Financial Metrics for Risk Estimator ‣ 7 Appendix ‣
    FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement
    for Enhanced Financial Decision Making"). Indicative of investment strategy robustness,
    a smaller Max Drawdown suggests reduced risk.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\textbf{Max Drawdown}=\text{max}(\frac{P_{\text{peak}}-P_{\text{trough}}}{P_{\text{peak}}})$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: 7.4 Baseline and Comparative Models on Single Stock Trading Task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Buy-and-Hold strategy (B&H):'
  prefs: []
  type: TYPE_NORMAL
- en: A passive investment approach, where an investor purchases stocks and holds
    onto them for an extended period regardless of market fluctuations, is commonly
    used as a baseline for comparison of stock trading strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'DRL trading agents:'
  prefs: []
  type: TYPE_NORMAL
- en: As the FinMem is practiced and examined on the basis of single stock trading
    and discrete trading actions, we choose three advanced DRL algorithms fitting
    into the same scenarios according to the previous and shown expressive performance
    in the work of Liu et al [[82](#bib.bib82), [83](#bib.bib83)]. The DRL training
    agents only take numeric features as inputs.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Proximal Policy Optimization (PPO): PPO ([[84](#bib.bib84)]) is employed in
    stock trading due to its stability and efficiency. One salient advantage of PPO
    is that it maintains a balance between exploration and exploitation by bounding
    the policy update, preventing drastic policy changes.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deep Q-Network (DQN): DQN ([[85](#bib.bib85)]) is an adaptation of Q-learning,
    that can be used to optimize investment strategies. Unlike traditional Q-learning
    that relies on a tabular approach for storing Q-values, DQN generalizes Q-value
    estimation across states using deep learning, making it more scalable for complex
    trading environments.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'LLM trading agents:'
  prefs: []
  type: TYPE_NORMAL
- en: We evaluate FinCon against four LLM agents in the context of stock trading.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: General-purpose Generative Agents – GA:The generative AI agent by Park et al.
    [[11](#bib.bib11)], originally intended to simulate realistic human behavior and
    make everyday decisions, has been adapted here for specific stock trading tasks.
    This agent’s architecture includes a memory module that employs recency, relevance,
    and importance metrics to extract pivotal memory events for informed decision-making.
    However, it does not provide a layered memory module to effectively differentiate
    the time sensitivities unique to various types of financial data. Additionally,
    although it features a profiling module to define agent attributes like professional
    background, the model does not specify the agent’s persona. In our experiments,
    we modified the original prompt template created by Park et al., which was intended
    for general daily tasks, to suit financial investment tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FinGPT: A novel open-source LLM framework specialized for converting incoming
    textual and numeric information into informed financial decision-making, introduced
    by Yang et al[[22](#bib.bib22)]. It claims superiority over the traditional buy-and-hold
    strategy.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FinMem:FinMem employs a specialized profiling module and self-adaptive risk
    settings for enhanced market robustness. Its memory module integrates working
    memory and layered long-term memory, enabling effective data processing. This
    allows FinMem to leverage market insights and improve trading decisions [[23](#bib.bib23)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FinAgent:FinAgent developed upon FinMem, which leverages the use of tool-using
    capabilities of LLMs to incorporate multi-modal financial data [[24](#bib.bib24)].
    It claims an further improved trading performance on single asset trading (stocks
    and cryptocurrencies).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7.5 Portfolio Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Markowitz Portfolio Selection: introduced by Harry Markowitz in 1952 [[1](#bib.bib1)],
    is a framework for constructing portfolios that optimize expected return for a
    given level of risk or minimize risk for a given level of expected return. This
    method uses expected returns, variances, and covariances of asset returns to determine
    the optimal asset allocation, thereby balancing risk and return through diversification.'
  prefs: []
  type: TYPE_NORMAL
- en: 'FinRL-A2C: is an RL algorithm proposed to address single stock trading and
    portfolio optimization problems in [[76](#bib.bib76)]. The RL models makes trading
    decisions (i.e., portfolio weights) based on the observation of previous market
    conditions and the brokerage information of the RL-agent. The implementation of
    this algorithm ¹¹1[https://github.com/AI4Finance-Foundation/FinRL-Meta](https://github.com/AI4Finance-Foundation/FinRL-Meta)
    is provided and is used as baselines in our study.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.6 Ranking Metrics for Procedural Memory in FinCon
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Upon receiving an investment inquiry, each agent in FinCon retrieves the top-$K$
    is defined by
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\gamma^{E}=S_{\text{Relevancy}}^{E}+S_{\text{Importance}}^{E}$ |  | (7)
    |'
  prefs: []
  type: TYPE_TB
- en: 'which is adpated from Park et al [[11](#bib.bib11)] but with modified relevancy
    and importance computations, and is scaled to $[0,1]$, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $S_{\text{Relevancy}}^{E}=\frac{\mathbf{m_{E}}\cdot\mathbf{m_{P}}}{\&#124;\mathbf{m_{E}}\&#124;_{2}\times\&#124;\mathbf{m_{P}}\&#124;_{2}}$
    |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: Note that the LLM prompt query inputs trading inquiry and trader characteristics.
    On the other hand, the importance score $S_{\text{Importance}}^{E}$, then the
    importance score is computed via
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $S_{\text{Importance}}^{E}=v^{E}\times\theta^{\delta t}$ |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: Note that the ratio $\theta$.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, an access counter function facilitates memory event augmentation,
    so that critical events impacting trading decisions can be augmented by FinCon,
    while trivial events are gradually faded. This is achieved by using the LLM validation
    tool Guardrails AI [[87](#bib.bib87)] to track critical memory ID. A memory ID
    deemed critical to investment gains receives $+5$. This access counter implementation
    enables FinCon to capture and prioritize crucial events based on type and retrieval
    frequency.
  prefs: []
  type: TYPE_NORMAL
- en: 7.7 Detailed Configurations in Experiments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The training period was chosen to account for the seasonal nature of corporate
    financial reporting and the duration of data retention in FinCon’s memory module.
    The selected training duration ensures the inclusion of at least one publication
    cycle of either Form 10-Q, ECC, or Form 10-K. This strategy ensures that the learned
    conceptualized investment guidance considers a more comprehensive scope of factors.
    Additionally, the training duration allowed FinCon sufficient time to establish
    inferential links between financial news, market indicators, and stock market
    trends, thereby accumulating substantial experience. Furthermore, we set the number
    of top memory events retrieved for each agent at 5\. We ran FinCon. The reported
    performance outcomes are based on the setting that achieved the highest cumulative
    return during the testing phase.
  prefs: []
  type: TYPE_NORMAL
- en: To maintain consistency in the comparison, the training and testing phases for
    the other two LLM-based agents were aligned with those of FinMem. For parameters
    of other LLM-based agents that are not encompassed by FinMem’s configuration,
    they were kept in accordance with their original settings as specified in their
    respective source codes.
  prefs: []
  type: TYPE_NORMAL
- en: FinCon’s performance was benchmarked against that of the most effective comparative
    model, using Cumulative Return and Sharpe Ratio as the primary evaluation metrics.
    The statistical significance of FinCon’s superior performance was ascertained
    through the non-parametric Wilcoxon signed-rank test, which is particularly apt
    for the non-Gaussian distributed data.
  prefs: []
  type: TYPE_NORMAL
