- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:50:06'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability
    in Multi-Agent Environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.11807](https://ar5iv.labs.arxiv.org/html/2403.11807)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Jen-tse Huang^(1,2), Eric John Li¹, Man Ho Lam¹, Tian Liang^(4,2), Wenxuan Wang^(1,2)
  prefs: []
  type: TYPE_NORMAL
- en: Youliang Yuan^(3,2), Wenxiang Jiao², Xing Wang², Zhaopeng Tu², Michael R. Lyu¹
  prefs: []
  type: TYPE_NORMAL
- en: ¹The Chinese University of Hong Kong     ²Tencent AI Lab
  prefs: []
  type: TYPE_NORMAL
- en: ³The Chinese University of Hong Kong, Shenzhen     ⁴Tsinghua University {jthuang,wxwang,lyu}@cse.cuhk.edu.hk
    {ejli,mhlam}@link.cuhk.edu.hk  liangt21@mails.tsinghua.edu.cn youliangyuan@link.cuhk.edu.cn  {joelwxjiao,brightxwang,zptu}@tencent.com
    Wenxiang Jiao is the corresponding author.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Decision-making, a complicated task requiring various types of abilities, presents
    an excellent framework for assessing Large Language Models (LLMs). Our research
    investigates LLMs’ decision-making capabilities through the lens of a well-established
    field, Game Theory. We focus specifically on games that support the participation
    of more than two agents simultaneously. Subsequently, we introduce our framework,
    $\gamma$-Bench, achieving a score of 72.5. Moreover, the increasingly higher scores
    across the three iterations of GPT-3.5 (0613, 1106, 0125) demonstrate marked advancements
    in the model’s intelligence with each update. The code and experimental results
    are made publicly available via [https://github.com/CUHK-ARISE/GAMABench](https://github.com/CUHK-ARISE/GAMABench).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e997ba1ab7521cb48095ff53ca2e175b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: $\gamma$-Bench enables various LLMs and humans to participate in
    multi-agent, multi-round games. The framework includes eight classical games in
    Game Theory, each categorized into one of three groups.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Table 1: Performance (scores) of different LLMs on $\gamma$-Bench.'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\gamma$-Bench Leaderboard | GPT-3.5 | GPT-4 | Gemini-Pro |'
  prefs: []
  type: TYPE_TB
- en: '| 0613 | 1106 | 0125 | 0125 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average | $41.4_{\pm 0.5}$ |'
  prefs: []
  type: TYPE_TB
- en: '| El Farol Bar | $74.8_{\pm 4.5}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Divide the Dollar | $42.4_{\pm 7.7}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Public Goods Game | $82.3_{\pm 1.7}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Diner’s Dilemma | $33.0_{\pm 4.9}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sealed-Bid Auction | $89.8_{\pm 0.4}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Battle Royale | $19.5_{\pm 7.7}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pirate Game | $68.4_{\pm 20.0}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $56.4_{\pm 2.9}$ |'
  prefs: []
  type: TYPE_TB
- en: We have recently witnessed the advancements in Artificial Intelligence (AI)
    made by Large Language Models (LLMs), which have marked a significant breakthrough
    in the field. ChatGPT¹¹1[https://chat.openai.com/](https://chat.openai.com/),
    a leading LLM, has demonstrated its proficiency in a variety of Natural Language
    Processing (NLP) tasks, including machine translation Jiao et al. ([2023](#bib.bib20)),
    sentence revision Wu et al. ([2023a](#bib.bib55)), information retrieval Zhu et al.
    ([2023](#bib.bib60)), and program repair Surameery & Shakor ([2023](#bib.bib50)).
    Beyond the academic sphere, LLMs have entered diverse aspects of our everyday
    life, such as education Baidoo-Anu & Ansah ([2023](#bib.bib6)), legal service Guha
    et al. ([2023](#bib.bib14)), product design Lanzi & Loiacono ([2023](#bib.bib29)),
    and healthcare Johnson et al. ([2023](#bib.bib21)). Given their extensive capabilities,
    evaluating LLMs demands more than simple, isolated tasks. A comprehensive and
    multifaceted approach is highly in demand to assess the efficacy of these advanced
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the broad knowledge encoded in LLMs, their intelligence Liang et al. ([2023b](#bib.bib33)),
    and capabilities in general-purpose task solving Qin et al. ([2023](#bib.bib44)),
    a question emerges: can LLMs assist in everyday decision-making? Decision-making
    is a complex task requiring various abilities: (1) Perception: the ability to
    understand situations, environments, and rules, and extends to long-text understanding
    for LLMs. (2) Planning: the ability to maximize long-term over immediate benefits
    by anticipating potential outcomes. (3) Arithmetic Reasoning: the ability to quantify
    real-world scenarios and perform calculations. (4) ToM Reasoning: the Theory of
    Mind Kosinski ([2023](#bib.bib27)); Bubeck et al. ([2023](#bib.bib8)) refers to
    the ability to infer others’ intentions and beliefs. (5) Critical Thinking: the
    ability to integrate all available information to arrive at the best decision.
    Given these complexities, decision-making poses a significant challenge for intelligent
    agents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To develop a framework to evaluate the decision-making ability of LLMs, we
    draw upon the principles of Game Theory, a well-established field with extensive
    applicability. Our rationale is threefold: (1) Scope: Game theory allows for the
    abstraction of diverse real-life scenarios into simple mathematical models, facilitating
    a broad range of evaluations. (2) Quantifiability: By examining the Nash equilibrium
    within these models, we gain a measurable metric for comparing LLMs’ decision-making
    performance. (3) Variability: The adjustable parameters of these models enable
    the creation of variant scenarios, enhancing the diversity and robustness of our
    assessments. Our framework evaluates LLMs in complex settings involving multi-player,
    multi-action, and multi-round games, incorporating eight classical games extensively
    analyzed in game theory literature.'
  prefs: []
  type: TYPE_NORMAL
- en: The first category in our framework evaluates LLMs’ ability to make optimal
    decisions by understanding game rules and recognizing patterns in other players’
    behavior. A distinctive characteristic of these games is that individual players
    cannot achieve higher gains without cooperation, provided that other participants
    cooperate. Essentially, these games’ Nash equilibrium aligns with maximizing overall
    social welfare. We name such games as Cooperative Games, including (1) Guess 2/3
    of the Average, (2) El Farol Bar, and (3) Divide the Dollar. The second category
    assesses the propensity of LLMs to prioritize self-interest, potentially betraying
    others for greater gains. In contrast to the first category, games in this category
    incentivize higher rewards for participants who betray their cooperative counterparts.
    Typically, the Nash equilibrium in these games leads to reduced social welfare.
    This category is termed Betraying Games, including (4) Public Goods Game, (5)
    Diner’s Dilemma, (6) Sealed-Bid Auction. Last but not least, we focus specifically
    on two games characterized by sequential decision-making processes, distinguishing
    them from the previous six games based on simultaneous decision-making. These
    Sequential Games are the (7) Battle Royale and (8) Pirate Game.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we first instruct ten agents, based on the gpt-3.5-turbo-0125model,
    to engage in the eight games in $\gamma$-Bench, followed by an analysis of the
    results obtained. Subsequently, we assess the model’s robustness against multiple
    runs, temperature parameter alterations, and prompt template variations. Further
    exploration is conducted to ascertain if instructional prompts, such as Chain-of-Thought,
    enhance the model’s decision-making capabilities. Additionally, the model’s capacity
    to generalize across diverse game settings is examined. Finally, the performance
    of LLMs, including GPT-3.5 (0613, 1106, 0125), GPT-4 (0125) and Gemini Pro (1.0),
    is evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contribution of this paper can be summarized as:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper reviews and compares existing literature on the evaluation of LLMs
    using game theory models, emphasizing variations in focus on LLMs, games, and
    other settings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We introduce a novel evaluation perspective of LLMs, i.e., their Gaming Ability
    in Multi-Agent environments, and present our designed framework, GAMA($\gamma$)-Bench.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The $\gamma$-Bench framework is applied to various LLMs, facilitating an in-depth
    analysis of their performance in multi-agent gaming scenarios.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2 Background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 Game Theory
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Formulation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Game theory involves analyzing mathematical models of strategic interactions
    among rational agents Myerson ([2013](#bib.bib36)). A game can be modeled using
    these key elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Players, denoted as $\mathcal{P}=\{1,2,\cdots,N\}$ participants.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Actions, represented as $\mathcal{A}=\{\mathcal{A}_{i}\}$
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Utility functions, denoted as $\mathcal{U}=\{\mathcal{U}_{i}\colon\times_{j=1}^{N}\mathcal{A}_{j}\mapsto\mathbb{R}\}$
    functions that quantify each player’s preferences over all possible outcomes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Information, represented as $\mathcal{I}=\{\mathcal{I}_{i}\}$ sets of information
    available to each player, including other players’ action sets, utility functions,
    historical actions, and other beliefs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Order, indicated by $\mathcal{O}=\mathcal{O}_{1},\mathcal{O}_{2},\cdots,\mathcal{O}_{k}$
    implies that all players take actions simultaneously.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this study, Multi-Player games are defined as those with <math id="S2.SS1.SSS0.Px1.p1.1.m1.1"
    class="ltx_Math" alttext="|\mathcal{P}|></math>. Since every player can see their
    own action, the above condition indicates that all players are visible to the
    complete information set in the game. Conversely, games not meeting this criterion
    are classified as Imperfect Information games, where players have limited knowledge
    of others’ actions.
  prefs: []
  type: TYPE_NORMAL
- en: Nash Equilibrium
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Studying game theory models often involves analyzing their Nash Equilibria (NE) Nash
    ([1950](#bib.bib38)). An NE is a specific set of strategies where no one has anything
    to gain by changing only one’s own strategy. This implies that given one player’s
    choice, the strategies of others are constrained to a specific set, which in turn
    limits the original player’s choice to the initial one. When each player’s strategy
    contains only one action, the equilibrium is identified as a Pure Strategy Nash
    Equilibrium (PSNE) Nash ([1950](#bib.bib38)). However, in certain games, such
    as rock-paper-scissors, an NE exists only when players employ a probabilistic
    approach to their actions. This type of equilibrium is known as a Mixed Strategy
    Nash Equilibrium (MSNE) Nash ([1951](#bib.bib39)), with PSNE being a subset of
    MSNE where probabilities are concentrated on a single action. According to Thm. [2.1](#S2.Thmtheorem1
    "Theorem 2.1 (Nash’s Existence Theorem) ‣ Nash Equilibrium ‣ 2.1 Game Theory ‣
    2 Background ‣ How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’
    Gaming Ability in Multi-Agent Environments") shown below, we can analyze the NE
    of each game and evaluate whether LLMs’ choices align with the NE.
  prefs: []
  type: TYPE_NORMAL
- en: Theorem 2.1 (Nash’s Existence Theorem)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Every game with a finite number of players in which each player can choose from
    a finite number of actions has at least one mixed strategy Nash equilibrium, in
    which each player’s action is determined by a probability distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Human Behaviors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The attainment of NE presupposes participants as Homo Economicus, who are consistently
    rational and narrowly self-interested, aiming at maximizing self goals Persky
    ([1995](#bib.bib41)). However, human decision-making often deviates from this
    ideal. Empirical studies reveal that human choices frequently diverge from what
    the NE predicts Nagel ([1995](#bib.bib37)). This deviation is attributed to the
    complex nature of human decision-making, which involves not only rational analysis
    but also personal values, preferences, beliefs, and emotions. By comparing human
    decision patterns documented in prior studies, together with the NE, we can ascertain
    whether LLMs exhibit tendencies more akin to homo economicus or actual human decision-makers,
    thus shedding light on their alignment with human-like or purely rational decision-making
    processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: A Comparison of existing studies that evaluate LLMs using game theory
    models. T denotes the temperature employed in each experiment. MP refers to a
    multi-player setting, whereas MR indicates multi-round interactions. Role specifies
    whether a specific role is assigned to the LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Paper | Models | T | MP | MR | Role | CoT | Games |'
  prefs: []
  type: TYPE_TB
- en: '| Horton ([2023](#bib.bib18)) | text-davinci-003 | - | ✗ | ✗ | ✗ | ✗ | Dictator
    Game |'
  prefs: []
  type: TYPE_TB
- en: '| Guo ([2023](#bib.bib15)) | gpt-4-1106-preview | 1 | ✗ | ✓ | ✓ | ✓ | Ultimatum
    Game, |'
  prefs: []
  type: TYPE_TB
- en: '| Prisoner’s Dilemma |'
  prefs: []
  type: TYPE_TB
- en: '| Phelps & Russell ([2023](#bib.bib42)) | gpt-3.5-turbo | 0.2 | ✗ | ✓ | ✓ |
    ✗ | Prisoner’s Dilemma |'
  prefs: []
  type: TYPE_TB
- en: '| Akata et al. ([2023](#bib.bib3)) | text-davinci-003, | 0 | ✗ | ✓ | ✗ | ✗
    | Prisoner’s Dilemma, |'
  prefs: []
  type: TYPE_TB
- en: '| gpt-3.5-turbo, gpt-4 | Battle of the Sexes |'
  prefs: []
  type: TYPE_TB
- en: '| Aher et al. ([2023](#bib.bib2)) | text-ada-001, text-babbage-001, | 1 | ✗
    | ✗ | ✓ | ✗ | Ultimatum Game |'
  prefs: []
  type: TYPE_TB
- en: '| text-curie-001, text-davinci-001, |'
  prefs: []
  type: TYPE_TB
- en: '| text-davinci-002, text-davinci-003, |'
  prefs: []
  type: TYPE_TB
- en: '| gpt-3.5-turbo, gpt-4 |'
  prefs: []
  type: TYPE_TB
- en: '| Brookins & DeBacker ([2023](#bib.bib7)) | gpt-3.5-turbo | 1 | ✗ | ✗ | ✗ |
    ✗ | Dictator Game, |'
  prefs: []
  type: TYPE_TB
- en: '| Prisoner’s Dilemma |'
  prefs: []
  type: TYPE_TB
- en: '| Li et al. ([2023](#bib.bib31)) | gpt-3.5-turbo-0613, | - | ✓ | ✓ | ✗ | ✗
    | Public Goods Game |'
  prefs: []
  type: TYPE_TB
- en: '| gpt-4-0613, claude-2.0, |'
  prefs: []
  type: TYPE_TB
- en: '| chat-bison-001 |'
  prefs: []
  type: TYPE_TB
- en: '| Heydari & Lorè ([2023](#bib.bib17)) | gpt-3.5-turbo-16k, gpt-4, | 0.8 | ✗
    | ✗ | ✓ | ✓ | Prisoner’s Dilemma, |'
  prefs: []
  type: TYPE_TB
- en: '| LLaMA-2 | Stag Hunt, Snowdrift, |'
  prefs: []
  type: TYPE_TB
- en: '| Prisoner’s Delight |'
  prefs: []
  type: TYPE_TB
- en: '| Guo et al. ([2023](#bib.bib16)) | GPT-3.5, GPT-4 | - | ✗ | ✓ | ✗ | ✓ | Leduc
    Hold’em |'
  prefs: []
  type: TYPE_TB
- en: '| Chen et al. ([2023](#bib.bib9)) | gpt-3.5-turbo-0613, | 0.7 | ✓ | ✓ | ✓ |
    ✓ | English Auction |'
  prefs: []
  type: TYPE_TB
- en: '| gpt-4-0613, claude-instant-1.2, |'
  prefs: []
  type: TYPE_TB
- en: '| claude-2.0, chat-bison-001 |'
  prefs: []
  type: TYPE_TB
- en: '| Xu et al. ([2023a](#bib.bib57)) | gpt-3.5-turbo, gpt-4, | - | ✓ | ✓ | ✗ |
    ✓ | Cost Sharing, |'
  prefs: []
  type: TYPE_TB
- en: '| llama-2-70b, claude-2.0, | Prisoner’s Dilemma, |'
  prefs: []
  type: TYPE_TB
- en: '| PaLM-2 | Public Goods Game |'
  prefs: []
  type: TYPE_TB
- en: '| Fan et al. ([2023](#bib.bib11)) | text-davinci-003, | 0.7 | ✗ | ✓ | ✗ | ✗
    | Dictator Game, |'
  prefs: []
  type: TYPE_TB
- en: '| gpt-3.5-turbo, gpt-4 | Rock-Paper-Scissors, |'
  prefs: []
  type: TYPE_TB
- en: '| Ring-Network Game |'
  prefs: []
  type: TYPE_TB
- en: '| Duan et al. ([2024](#bib.bib10)) | gpt-3.5-turbo, gpt-4, | 0.2 | ✓ | ✓ |
    ✗ | ✓ | Ten Games |'
  prefs: []
  type: TYPE_TB
- en: '| llama-2-70b, codellama-34b, |'
  prefs: []
  type: TYPE_TB
- en: '| mistral-7b-orca |'
  prefs: []
  type: TYPE_TB
- en: '| This Study | gpt-3.5-turbo, gpt-4 | 0$\sim$1 | ✓ | ✓ | ✓ | ✓ | Eight Games
    |'
  prefs: []
  type: TYPE_TB
- en: '| gemini-pro |'
  prefs: []
  type: TYPE_TB
- en: 2.2 Evaluating LLMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Evaluating LLMs through game theory models has become a popular research direction.
    An overview on recent studies is summarized in Table [2](#S2.T2 "Table 2 ‣ Human
    Behaviors ‣ 2.1 Game Theory ‣ 2 Background ‣ How Far Are We on the Decision-Making
    of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments"). From our
    analysis, several key observations emerge: (1) The majority of these studies are
    concentrated on two-player settings. (2) There is a predominant focus on two-action
    games; notably, half of the studies examine the Prisoner’s Dilemma and the Ultimatum
    Game (the Dictator Game is one of the variants of the Ultimatum Game). (3) A notable
    gap in the literature is the lack of the comparative studies between LLMs’ decision-making
    across multiple rounds and the action probability distributions predicted by the
    MSNE. (4) The studies exhibit variability in the temperatures used, which precludes
    definitive conclusions regarding their impact on LLMs’ performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 $\gamma$-Bench Design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To fill these gaps, we collect eight games well studied in Game Theory and propose
    $\gamma$-Bench.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Cooperative Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: (1) Guess 2/3 of the Average
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Initially introduced by Ledoux ([1981](#bib.bib30)), the game involves players
    independently selecting an integer between 0 and 100 (inclusive). The winner is
    the player(s) choosing the number closest to two-thirds of the group’s average.
    A typical initial strategy might lead players to assume an average of 50, suggesting
    a winning number around $50\times\frac{2}{3}\approx 33$. However, if all participants
    adopt this reasoning, the average shifts to 33, thereby altering the winning number
    to approximately 22. The game possesses a PSNE where all players selecting zero
    results in a collective win.
  prefs: []
  type: TYPE_NORMAL
- en: (2) El Farol Bar
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Proposed by Arthur ([1994](#bib.bib4)) and Huberman ([1988](#bib.bib19)), this
    game requires players to decide to either visit a bar for entertainment or stay
    home without communication. The bar, however, has a limited capacity and can only
    accommodate part of the population. In a classical scenario, the bar becomes overcrowded
    and less enjoyable if more than 60% of the population decides to go there. Conversely,
    if 60% or fewer people are present, the experience is more enjoyable than staying
    home. Imagine that if everyone adopts the same pure strategy, i.e., either everyone
    going to the bar or everyone staying home, then the social welfare is not maximized.
    Notably, the game lacks a PSNE but presents an MSNE, where the optimal strategy
    involves going to the bar with a 60% probability and staying home with a 40% probability.
  prefs: []
  type: TYPE_NORMAL
- en: (3) Divide the Dollar
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Firstly mentioned in Shapley & Shubik ([1969](#bib.bib47)), the game involves
    two players independently bidding up to 100 cents for a dollar. Ashlock & Greenwood
    ([2016](#bib.bib5)) further generalized the game into a multi-player setting.
    If the sum of bids is at most one dollar, each player is awarded their respective
    bid; if the total exceeds a dollar, no player receives anything. The NE of this
    game occurs when each player bids exactly $\frac{100}{N}$ cents.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Betraying Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: (4) Public Goods Game
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Studied since the early 1950s Samuelson ([1954](#bib.bib46)), the game requires
    $N$, which is less than zero. This suggests that the rational strategy for each
    player is to contribute no tokens, which reaches an NE of this game. The game
    serves as a tool to investigate tendencies towards selfish behavior and free-riding
    among participants.
  prefs: []
  type: TYPE_NORMAL
- en: (5) Diner’s Dilemma
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This game is the multi-player variant of the Prisoner’s Dilemma Glance & Huberman
    ([1994](#bib.bib12)). The game involves $N$, which is the utility if all choose
    the cheap one. This game evaluates the agents’ capacity for a long-term perspective
    and capacity to establish sustained cooperation.
  prefs: []
  type: TYPE_NORMAL
- en: (6) Sealed-Bid Auction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Sealed-Bid Auction (SBA) involves players submitting their bids confidentially
    and simultaneously, different from the auctions where bids are made openly in
    a sequential manner. We consider two variants of SBA: the First-Price Sealed-Bid
    Auction (FPSBA) and the Second-Price Sealed-Bid Auction (SPSBA). In FPSBA, also
    known as the Blind Auction, if all players bid their true valuation $v_{i}$ while
    others also gain nothing McAfee & McMillan ([1987](#bib.bib35)). Moreover, the
    highest bidder will discover that to win the auction, it is sufficient to bid
    marginally above the second-highest bid. Driven by these two factors, FPSBA is
    often deemed inefficient in practical scenarios, as bidders are inclined to submit
    bids significantly lower than their actual valuation, resulting in suboptimal
    social welfare. In contrast, SPSBA, commonly called the Vickrey auction, requires
    the winner to pay the second-highest bid, encouraging truthful bidding by all
    players Vickrey ([1961](#bib.bib52)). It can be proven that bidding true valuations
    in SPSBA represents an NE. This auction evaluates agent performance in imperfect
    information games, where agents lack knowledge of other players’ valuations.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Sequential Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: (7) Battle Royale
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Extended from the Truel Kilgour ([1975](#bib.bib24)) involving three players,
    the Battle Royale involves $N$ players shooting at each other. In the widely studied
    form Kilgour & Brams ([1997](#bib.bib23)), players have different probabilities
    of hitting the target, with the turn order set by increasing hit probabilities.
    The game allows for unlimited bullets and the tactical option of intentionally
    missing shots. The objective for each participant is to emerge as the sole survivor,
    with the game ending when only one player remains. While the NE has been identified
    for infinite sequential truels Kilgour ([1977](#bib.bib22)), the complexity of
    these equilibria escalates exponentially with an increased number of players.
  prefs: []
  type: TYPE_NORMAL
- en: (8) Pirate Game
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This game is a multi-player version of the Ultimatum Game Goodin ([1998](#bib.bib13));
    Stewart ([1999](#bib.bib49)). Each player is assigned a “pirate rank”, determining
    their action order. The game involves $N$ golds they have discovered. The most
    senior pirate first proposes a distribution method. If the proposal is approved
    by at least half of the pirates, including the proposer, the game ends, and the
    gold is distributed as proposed. Otherwise, the most senior pirate is thrown overboard,
    and the next in rank assumes the proposer role until the game ends. Each pirate’s
    objectives are prioritized as (1) survival, (2) maximizing their share of gold,
    and (3) the opportunity to eliminate others from the game. Stewart ([1999](#bib.bib49))
    identifies the optimal strategy in this game, where the most senior pirate allocates
    one gold coin to each odd-ranked subordinate and keeps the remainder.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Vanilla Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section presents experiments conducted using the default settings for
    each game on the gpt-3.5-turbo-0125 model. Utilizing this model as a case study,
    we illustrate our methodology for benchmarking an LLM with $\gamma$-Bench include:'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S4.p2.pic1" class="ltx_picture" height="123.95" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,123.95) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 5.32 5.32)"><foreignobject width="589.36" height="113.31"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">Key Findings:
    • The model’s decisions are mainly influenced by the outcomes of the preceding
    round rather than deriving from the reasoning of the optimal strategy. • Although
    initially demonstrating suboptimal performance, the model can learn from historical
    data and enhance its performance over time. • The model demonstrates the ability
    to engage in spontaneous cooperation, leading to increased social welfare beyond
    mere self-interest, without the necessity for explicit communication. • The model
    shows limitations in sequential games characterized by more complicated rules.
    • The aggregate score of the model on $\gamma$.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: The prompt we use for OpenAI GPT models.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Guess 2/3 of the Average |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. Each player selects an integer number between $MIN$, inclusive. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. After all selections are made, the average of all chosen numbers is
    calculated. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The target number is $R$ of this average. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. The winner is the player(s) who selected a number closest to the target
    number. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Game Results for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | Average Number Chosen: $M_{I}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | Target Number ($R$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | Winning Number: $W_{I}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | You chose: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“chosen_number”: “$C_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | [Congratulation you won]/[Unfortunately you lost]. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now round $I$ starts. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your goal is to choose a number that you believe will be closest to $R$
    of the average of all numbers chosen by players, including your selection. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your chosen number in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“chosen_number”: “integer_between_$MIN$“}. |'
  prefs: []
  type: TYPE_TB
- en: 4.1 Cooperative Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: (1) Guess 2/3 of the Average
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The vanilla setting for this game is $MIN=0$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/26983220952c234b04da26713dab7b8b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Performance of gpt-3.5-turbo-0125 in the game of “Guess 2/3 of the
    Average.”'
  prefs: []
  type: TYPE_NORMAL
- en: (2) El Farol Bar
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The vanilla setting for this game is $MIN=0$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4de7d4723276e35fde6b5d1e95006197.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Performance of gpt-3.5-turbo-0125 in the game of “El Farol Bar.”'
  prefs: []
  type: TYPE_NORMAL
- en: (3) Divide the Dollar
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The vanilla setting for this game is $G=100$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5f984773fb0044783c287f75ddba3542.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Performance of gpt-3.5-turbo-0125 in the game of “Divide the Dollar.”'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Betraying Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: (4) Public Goods Game
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The vanilla setting for this game is $R=2$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4023203036176c22145fa8e726b6b33e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Performance of gpt-3.5-turbo-0125 in the “Public Goods Game.”'
  prefs: []
  type: TYPE_NORMAL
- en: (5) Diner’s Dilemma
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The vanilla setting for this game is $P_{h}=20$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9eb02da9fdde35057124a1b1f9f49d1d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Performance of gpt-3.5-turbo-0125 in the game of “Diner’s Dilemma.”'
  prefs: []
  type: TYPE_NORMAL
- en: (6) Sealed-Bid Auction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the vanilla setting in this game, we randomly assign valuations to each
    agent in each round, ranging from $0$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2ae2aaeab6fefe9320e0313c37ce7e26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Performance of gpt-3.5-turbo-0125 in the game of “Sealed-Bid Auction.”'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Sequential Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: (7) Battle Royale
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the vanilla setting in this game, we assign varied hit rates to each agent,
    spanning from $35\%$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3c5707674070b4af1f555f7168ce10e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Performance of gpt-3.5-turbo-0125 in the game of “Battle Royale.”
    (a): Agents’ actions and outcomes of each round. For example, in round $11$ but
    missed.'
  prefs: []
  type: TYPE_NORMAL
- en: (8) Pirate Game
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The vanilla setting for this game is $G=100$ on this game.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Performance of gpt-3.5-turbo-0125 in the “Pirate Game.” Each row shows
    the proposed gold distribution in the specific round and whether each pirate accepts
    (marked in “✓”) or rejects (marked in “✗”) the proposal. $S_{8P}$ shows the score
    of all voters.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Pirate Rank | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | $S_{8P}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
  prefs: []
  type: TYPE_TB
- en: '| Round 1 | 100✓ | 0✗ | 0✗ | 0✗ | 0✗ | 0✗ | 0✗ | 0✗ | 0✗ | 0✗ | $8$ |'
  prefs: []
  type: TYPE_TB
- en: '| Round 2 | - | 99✓ | 0✗ | 1✓ | 0✓ | 0✗ | 0✗ | 0✗ | 0✗ | 0✓ | $6$ |'
  prefs: []
  type: TYPE_TB
- en: '| Round 3 | - | - | 50✓ | 1✓ | 1✓ | 1✓ | 1✓ | 1✓ | 1✓ | 44✓ | $94$ |'
  prefs: []
  type: TYPE_TB
- en: 5 Further Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section explores deeper into several following Research Questions (RQs):'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ1 Robustness: Is there a significant variance in multiple runs? Is the performance
    sensitive to different temperatures and prompt templates?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ2 Reasoning Strategies: Are strategies to enhance reasoning skills applicable
    to game scenarios? This includes implementing Chain-of-Thought (CoT) Kojima et al.
    ([2022](#bib.bib25)); Wei et al. ([2022](#bib.bib54)) reasoning and assigning
    unique personas to LLMs.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ3 Generalizability: How does LLM performance vary with different game settings?
    Do LLMs remember answers learned during the training phase?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ4 Leaderboard: How do various LLMs perform on $\gamma$-Bench?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Unless otherwise specified, we apply the vanilla settings described in §[4](#S4
    "4 Vanilla Experiments ‣ How Far Are We on the Decision-Making of LLMs? Evaluating
    LLMs’ Gaming Ability in Multi-Agent Environments").
  prefs: []
  type: TYPE_NORMAL
- en: '5.1 RQ1: Robustness'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This RQ examines the stability of LLMs’ responses, assessing the impact of
    three critical factors on model performance: (1) randomness introduced by the
    model’s sampling strategy, (2) the temperature parameter setting, and (3) the
    prompt used for game instruction.'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple Runs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Firstly, we run all games five times under the same settings. Fig. [9](#S5.F9
    "Figure 9 ‣ Multiple Runs ‣ 5.1 RQ1: Robustness ‣ 5 Further Experiments ‣ How
    Far Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in
    Multi-Agent Environments") illustrates the average performance across tests, while
    Table [5](#A4.T5 "Table 5 ‣ Appendix D More Quantitative Results ‣ How Far Are
    We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent
    Environments") in the Appendix lists the corresponding scores⁵⁵5The formats are
    consistent across subsequent figures. Hence, their detailed descriptions are omitted..
    The analysis reveals that, except for the two sequential games, the model demonstrates
    a consistent performance, as evidenced by the low variance in scores for each
    game.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/eb187691b7510e8d0a9cc2f138de9bd8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Results of playing the games with the same setting five times. (1)
    Average chosen numbers; (2) Probability of players going to the bar; (3) Average
    proposed golds; (4) Average token contributions; (5) Probability of players choosing
    the cheap dish; (6) Average difference between valuation and bid; (7) Cumulative
    probability of players targeting the player with the highest hit rate; (8) The
    bars at the upper side is the $L_{1}$ distance of the proposal from the optimal
    while the bars at the lower side is the voting accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: Temperatures
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As discussed in our literature review in §[2.2](#S2.SS2 "2.2 Evaluating LLMs
    ‣ 2 Background ‣ How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’
    Gaming Ability in Multi-Agent Environments"), prior research incorporates varying
    temperature parameters from $0$ under vanilla settings. The results, both visual
    and quantitative, are documented in Fig. [10](#S5.F10 "Figure 10 ‣ Temperatures
    ‣ 5.1 RQ1: Robustness ‣ 5 Further Experiments ‣ How Far Are We on the Decision-Making
    of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments") and Table [6](#A4.T6
    "Table 6 ‣ Appendix D More Quantitative Results ‣ How Far Are We on the Decision-Making
    of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments") (in the
    Appendix), respectively. Analysis reveals that, for the majority of games, temperature
    adjustments yield negligible effects. A notable exception is observed in “Guess
    2/3 of the Average,” where increased temperatures correlate with enhanced scores,
    contrasting starkly with the near-random performance at zero temperature.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1c5fba9bc2fb35aff4a20f9f4240a953.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Results of playing the games with temperature parameters ranging
    from $0$.'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Templates
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We also investigate the impact of prompt phrasing on model performance. Leveraging
    GPT-4, we rewrite our default prompt templates described in §[A](#A1 "Appendix
    A Prompt Details ‣ How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’
    Gaming Ability in Multi-Agent Environments"), generating four additional versions.
    We perform a manual checking process on the generated versions to ensure GPT-4’s
    adherence to game rules without altering critical data. The prompt templates can
    be found in §[B](#A2 "Appendix B Rephrased Prompts ‣ How Far Are We on the Decision-Making
    of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments") in the
    appendix. We plot the results of using these templates in Fig. [11](#S5.F11 "Figure
    11 ‣ Prompt Templates ‣ 5.1 RQ1: Robustness ‣ 5 Further Experiments ‣ How Far
    Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent
    Environments") and record the quantitative scores in Table [7](#A4.T7 "Table 7
    ‣ Appendix D More Quantitative Results ‣ How Far Are We on the Decision-Making
    of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments") in the
    Appendix. Notably, our findings indicate that prompt wording can significantly
    affect performance, as evidenced by the declines observed in Fig. [11](#S5.F11
    "Figure 11 ‣ Prompt Templates ‣ 5.1 RQ1: Robustness ‣ 5 Further Experiments ‣
    How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability
    in Multi-Agent Environments")(1), (5), and (6).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cab273771e6b507d8e7fb4abe68e19a8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Results of playing the games using different prompt templates.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S5.SS1.SSS0.Px3.p2.pic1" class="ltx_picture" height="53.46" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,53.46) matrix(1 0 0 -1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 5.32 5.32)"><foreignobject width="589.36" height="42.82" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Answer to RQ1: gpt-3.5-0125
    exhibits consistency in multiple runs and shows robustness against different temperature
    settings. However, inappropriate prompt designs can significantly hurt its performance.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: '5.2 RQ2: Reasoning Strategies'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This RQ focuses on improving the model’s performance through prompt instructions.
    We investigate two strategies: Chain-of-Thought (CoT) prompting Kojima et al.
    ([2022](#bib.bib25)) and persona assignment Kong et al. ([2023](#bib.bib26)).
    We show the visualized results in Fig. [12](#S5.F12 "Figure 12 ‣ Persona ‣ 5.2
    RQ2: Reasoning Strategies ‣ 5 Further Experiments ‣ How Far Are We on the Decision-Making
    of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments") and quantitative
    results in Table [9](#A4.T9 "Table 9 ‣ Appendix D More Quantitative Results ‣
    How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability
    in Multi-Agent Environments") in the appendix.'
  prefs: []
  type: TYPE_NORMAL
- en: CoT
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: According to Kojima et al. ([2022](#bib.bib25)), introducing a preliminary phrase,
    “Let’s think step by step,” encourages the model to sequentially analyze and explain
    its reasoning before presenting its conclusion. This approach has proven beneficial
    in specific scenarios, such as games (1), (3) and (6). In the “(3) Divide the
    Dollar” game, incorporating CoT reduces the model’s propensity to suggest disproportionately
    large allocations. Similarly, in the “(6) Sealed-Bid Auction” game, CoT prompts
    the model to recognize bidding one’s true valuation as the optimal strategy. However,
    in the “(4) Public Goods Game” and “(5) Diner’s Dilemma,” the application of CoT
    inadvertently leads to a more self-serving model behavior, thereby undermining
    overall social welfare.
  prefs: []
  type: TYPE_NORMAL
- en: Persona
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Kong et al. ([2023](#bib.bib26)) demonstrated that assigning specific roles
    to models enhances performance across various downstream tasks. Inspired by this
    discovery, our study initiates with a prompt that specifies the model’s role,
    such as “You are [ROLE],” where the role could be a cooperative and collaborative
    assistant, a selfish and greedy assistant, or a mathematician. Our findings reveal
    that assigning the “cooperative” role significantly enhances model performance
    in games (3), (4), and (5), notably outperforming the CoT method in the “(3) El
    Farol Bar” game. Conversely, the “selfish” role markedly diminishes performance
    in the “(1) Guess the 2/3 of Average” game and results in fluatuated performance
    in “(3) Divide the Dollar” and “(4) Public Goods Game.” The “mathematician” role
    improves the model’s reasoning capabilities, albeit it does not surpass the CoT
    method’s effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d62b60d167995bd842429595725db947.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Results of playing the games using prompt-based improvement methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S5.SS2.SSS0.Px2.p2.pic1" class="ltx_picture" height="56.15" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,56.15) matrix(1 0 0 -1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 5.32 5.32)"><foreignobject width="589.36" height="45.51" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Answer to RQ2: It is possible
    to improve gpt-3.5-0125 through simple prompt instructions. Among the methods
    we explore, the persona assignment of a “cooperative and collaborative assistant”
    performs the best.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: '5.3 RQ3: Generalizability'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Considering the extensive exploration of games in domains such as mathematics,
    economics, and computer science, it is probable that the vanilla settings of these
    games are included within the training datasets of LLMs. To ascertain the presence
    of data contamination in our chosen games, we subjected them to various settings.
    The specifics of the parameters selected for each game are detailed in Table [8](#A4.T8
    "Table 8 ‣ Appendix D More Quantitative Results ‣ How Far Are We on the Decision-Making
    of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments") in the
    appendix, and the experimental outcomes are visually represented in Fig. [13](#S5.F13
    "Figure 13 ‣ 5.3 RQ3: Generalizability ‣ 5 Further Experiments ‣ How Far Are We
    on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent
    Environments"). Our findings indicate variability in model generalizability across
    different games. Specifically, in games (1), (5), (6), (7), and (8), the model
    demonstrated consistent performance under diverse settings. Conversely, the model
    exhibited low generalizability in games (2), (3), and (4). An analysis of the
    game “(2) El Farol Bar” reveals a consistent decision-making pattern by the model,
    opting to participate with approximately a $50\%$), suggesting that higher allocations
    of golds satisfy the demands of all players, illustrating the influence of reward
    distribution on model behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: Nagel ([1995](#bib.bib37)) conducted experiments with $15$ for the same ratios,
    indicating its predictions are more aligned with human behavior than the game’s
    NE.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e77c3b4d82823c9ef3550afbca04037d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Results of playing the games with various game settings.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S5.SS3.p3.pic1" class="ltx_picture" height="89.36" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,89.36) matrix(1 0 0 -1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 5.32 5.32)"><foreignobject width="589.36" height="78.72" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Answer to RQ3: gpt-3.5-0125
    demonstrates variable performance across different game settings, exhibiting notably
    lower efficacy in “(2) El Farol Bar” and “(4) Public Goods Game.” It is noteworthy
    that, $\gamma$-Bench), we can increase the difficulty by varying game settings.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: '5.4 RQ4: Leaderboard'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This RQ investigates the variance in decision-making capabilities among different
    LLMs on $\gamma$-Bench. We analyze OpenAI’s GPT-3.5 across three iterations (i.e.,
    0613, 1106, and 0125), GPT-4 (0125), and Google’s Gemini Pro (1.0). The results
    are organized in Table [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ How Far Are We on
    the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments"),
    with model performance visualized in Fig. [14](#S5.F14 "Figure 14 ‣ 5.4 RQ4: Leaderboard
    ‣ 5 Further Experiments ‣ How Far Are We on the Decision-Making of LLMs? Evaluating
    LLMs’ Gaming Ability in Multi-Agent Environments"). Our findings reveal that GPT-4
    markedly surpasses its counterparts, particularly in games (1), (3), (5), and
    (7). GPT-4’s diminished performance in the “(2) El Farol Bar” game stems from
    a conservative strategy favoring staying home. Its underperformance in the “(4)
    Public Goods Game” is attributed to a preference for individual gain over collective
    benefit. Furthermore, an evaluation of GPT-3.5’s iterations shows marked progress
    from version 0613 to versions 1106 and 0125, especially in the “(3) Divide the
    Dollar” and “(5) Diner’s Dilemma” games. Last but not least, we observe a discrepancy
    between Gemini Pro and GPT-4, primarily due to their performance in sequential
    games.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/010d85f35cba3edd11dcd673c04a1339.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Results of playing the games using different LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S5.SS4.p2.pic1" class="ltx_picture" height="39.55" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,39.55) matrix(1 0 0 -1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 5.32 5.32)"><foreignobject width="589.36" height="28.9" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Answer to RQ4: Currently, gpt-4-0125-preview
    outperforms all other models evaluated in this study, followed by gpt-3.5-turbo-1106.
    gemini-1.0-pro performs closely to gpt-3.5-turbo-0613.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 5.5 LLM vs. Specific Strategies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a2b97d12aafb4c5382f9b152b537deb0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: Performance of gpt-3.5-turbo-0125 playing against two fixed strategies
    in the “Divide the Dollar” and “Public Goods Game.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our framework enables concurrent interaction between LLMs and humans, allowing
    us to investigate LLMs’ behaviors against someone who plays with a fixed strategy.
    There are many possible strategies, here we use two examples: First, we let one
    player consistently bid an amount of $91$ golds in the game of “(3) Divide the
    Dollar,” compelling all other participants to bid a single gold. The objective
    is to ascertain if LLM agents will adjust their strategies in response to dominant
    participants. Additionally, we examine agents’ reactions to a persistent free-rider
    who contributes nothing in the “(4) Public Goods Game” to determine whether agents
    recognize and adjust their cooperation with the free-rider over time. We plot
    the average bids and the contributed tokens of the nine agents in Fig. [15](#S5.F15
    "Figure 15 ‣ 5.5 LLM vs. Specific Strategies ‣ 5 Further Experiments ‣ How Far
    Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent
    Environments"). We find that agents lower their bids in the “(3) Divide the Dollar”
    game in response to a dominant strategy. Contrary to expectations, in the “(4)
    Public Goods Game,” agents increase their contributions, compensating for the
    shortfall caused by the free-rider.'
  prefs: []
  type: TYPE_NORMAL
- en: 6 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 6.1 Specific Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Other than papers listed in Table [2](#S2.T2 "Table 2 ‣ Human Behaviors ‣ 2.1
    Game Theory ‣ 2 Background ‣ How Far Are We on the Decision-Making of LLMs? Evaluating
    LLMs’ Gaming Ability in Multi-Agent Environments") on evaluating LLMs using classical
    games, researchers have explored diverse scenarios involving more complicated
    games. Using the complex and deceptive environments of Avalon game as a test bed,
    recent work focuses on long-horizon multi-party dialogues Stepputtis et al. ([2023](#bib.bib48)),
    social behaviors Lan et al. ([2023](#bib.bib28)), and recursive contemplation Wang
    et al. ([2023](#bib.bib53)) for identifying deceptive information. Other papers
    have investigated the application of LLMs in communication games like Werewolf,
    with a focus on tuning-free frameworks Xu et al. ([2023b](#bib.bib58)) and reinforcement
    learning-powered approaches Xu et al. ([2023c](#bib.bib59)). O’Gara ([2023](#bib.bib40))
    found that advanced LLMs exhibit deception and lie detection capabilities in the
    text-based game, Hoodwinked. Meanwhile, Liang et al. ([2023a](#bib.bib32)) evaluated
    LLMs’ intelligence and strategic communication skills in the word guessing game,
    Who Is Spy? In the game of Water Allocation Challenge, Mao et al. ([2023](#bib.bib34))
    constructed a scenario highlighting unequal competition for limited resources.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Game Benchmarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another line of studies collects games to build more comprehensive benchmarks
    to assess the artificial general intelligence of LLMs. Tsai et al. ([2023](#bib.bib51))
    found that while LLMs, such as ChatGPT, perform competitively in text games, they
    struggle with world modeling and goal inference. GameEval Qiao et al. ([2023](#bib.bib43))
    introduced three goal-driven conversational games (Ask-Guess, SpyFall, and TofuKingdom)
    to effectively assess the problem-solving capabilities of LLMs in cooperative
    and adversarial settings. MAgIC Xu et al. ([2023a](#bib.bib57)) proposed the probabilistic
    graphical modeling method for evaluating LLMs in multi-agent game settings. LLM-Co Agashe
    et al. ([2023](#bib.bib1)) developed the LLM-Coordination framework to assess
    LLMs in multi-agent coordination scenarios, showcasing their capabilities in partner
    intention inference and proactive assistance. [Wu et al.](#bib.bib56) introduced
    SmartPlay, a benchmark for evaluating LLMs as agents across six games, emphasizing
    reasoning, planning, and learning capabilities. These papers focus on games with
    more complex designs, while our study investigates eight classical and essential
    games in game theory.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper presents $\gamma$-Bench leaderboard.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Agashe et al. (2023) Saaket Agashe, Yue Fan, and Xin Eric Wang. Evaluating multi-agent
    coordination abilities in large language models. *arXiv preprint arXiv:2310.03903*,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aher et al. (2023) Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai. Using
    large language models to simulate multiple humans and replicate human subject
    studies. In *International Conference on Machine Learning*, pp.  337–371\. PMLR,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akata et al. (2023) Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh,
    Matthias Bethge, and Eric Schulz. Playing repeated games with large language models.
    *arXiv preprint arXiv:2305.16867*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arthur (1994) W Brian Arthur. Inductive reasoning and bounded rationality. *The
    American economic review*, 84(2):406–411, 1994.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ashlock & Greenwood (2016) Daniel Ashlock and Garrison Greenwood. Generalized
    divide the dollar. In *2016 IEEE Congress on Evolutionary Computation (CEC)*,
    pp.  343–350\. IEEE, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baidoo-Anu & Ansah (2023) David Baidoo-Anu and Leticia Owusu Ansah. Education
    in the era of generative artificial intelligence (ai): Understanding the potential
    benefits of chatgpt in promoting teaching and learning. *Journal of AI*, 7(1):52–62,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brookins & DeBacker (2023) Philip Brookins and Jason Matthew DeBacker. Playing
    games with gpt: What can we learn about a large language model from canonical
    strategic games? *Available at SSRN 4493398*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bubeck et al. (2023) Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
    Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,
    et al. Sparks of artificial general intelligence: Early experiments with gpt-4.
    *arXiv preprint arXiv:2303.12712*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023) Jiangjie Chen, Siyu Yuan, Rong Ye, Bodhisattwa Prasad Majumder,
    and Kyle Richardson. Put your money where your mouth is: Evaluating strategic
    planning and execution of llm agents in an auction arena. *arXiv preprint arXiv:2310.05746*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Duan et al. (2024) Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura,
    Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, and Kaidi Xu. Gtbench:
    Uncovering the strategic reasoning limitations of llms via game-theoretic evaluations.
    *arXiv preprint arXiv:2402.12348*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. (2023) Caoyun Fan, Jindou Chen, Yaohui Jin, and Hao He. Can large
    language models serve as rational players in game theory? a systematic analysis.
    *arXiv preprint arXiv:2312.05488*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Glance & Huberman (1994) Natalie S Glance and Bernardo A Huberman. The dynamics
    of social dilemmas. *Scientific American*, 270(3):76–81, 1994.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodin (1998) Robert E Goodin. *The theory of institutional design*. Cambridge
    University Press, 1998.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guha et al. (2023) Neel Guha, Julian Nyarko, Daniel E Ho, Christopher Re, Adam
    Chilton, Aditya Narayana, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel
    Rockmore, et al. Legalbench: A collaboratively built benchmark for measuring legal
    reasoning in large language models. In *Thirty-seventh Conference on Neural Information
    Processing Systems Datasets and Benchmarks Track*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo (2023) Fulin Guo. Gpt agents in game theory experiments. *arXiv preprint
    arXiv:2305.05516*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. (2023) Jiaxian Guo, Bo Yang, Paul Yoo, Bill Yuchen Lin, Yusuke Iwasawa,
    and Yutaka Matsuo. Suspicion-agent: Playing imperfect information games with theory
    of mind aware gpt-4. *arXiv preprint arXiv:2309.17277*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heydari & Lorè (2023) Babak Heydari and Nunzio Lorè. Strategic behavior of
    large language models: Game structure vs. contextual framing. *Contextual Framing
    (September 10, 2023)*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Horton (2023) John J Horton. Large language models as simulated economic agents:
    What can we learn from homo silicus? Technical report, National Bureau of Economic
    Research, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huberman (1988) Bernardo A. Huberman. *The Ecology of Computation*. North-Holland,
    1988.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiao et al. (2023) Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and
    Zhaopeng Tu. Is chatgpt a good translator? a preliminary study. *arXiv preprint
    arXiv:2301.08745*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Johnson et al. (2023) Douglas Johnson, Rachel Goodman, J Patrinely, Cosby Stone,
    Eli Zimmerman, Rebecca Donald, Sam Chang, Sean Berkowitz, Avni Finn, Eiman Jahangir,
    et al. Assessing the accuracy and reliability of ai-generated medical responses:
    an evaluation of the chat-gpt model. *Research square*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kilgour (1977) D Marc Kilgour. Equilibrium points of infinite sequential truels.
    *International Journal of Game Theory*, 6:167–180, 1977.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kilgour & Brams (1997) D Marc Kilgour and Steven J Brams. The truel. *Mathematics
    Magazine*, 70(5):315–326, 1997.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kilgour (1975) D Mark Kilgour. The sequential truel. *International Journal
    of Game Theory*, 4:151–174, 1975.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. *Advances
    in neural information processing systems*, 35:22199–22213, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kong et al. (2023) Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi
    Sun, and Xin Zhou. Better zero-shot reasoning with role-play prompting. *arXiv
    preprint arXiv:2308.07702*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kosinski (2023) Michal Kosinski. Theory of mind might have spontaneously emerged
    in large language models. *arXiv preprint arXiv:2302.02083*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lan et al. (2023) Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye,
    Peilin Zhao, Ee-Peng Lim, Hui Xiong, and Hao Wang. Llm-based agent society investigation:
    Collaboration and confrontation in avalon gameplay. *arXiv preprint arXiv:2310.14985*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lanzi & Loiacono (2023) Pier Luca Lanzi and Daniele Loiacono. Chatgpt and other
    large language models as evolutionary engines for online interactive collaborative
    game design. *arXiv preprint arXiv:2303.02155*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ledoux (1981) Alain Ledoux. Concours résultats complets. les victimes se sont
    plu à jouer le 14 d’atout. *Jeux & Stratégie*, 2(10):10–11, 1981.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023) Jiatong Li, Rui Li, and Qi Liu. Beyond static datasets: A
    deep interaction approach to llm evaluation. *arXiv preprint arXiv:2309.04369*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2023a) Tian Liang, Zhiwei He, Jen-tes Huang, Wenxuan Wang, Wenxiang
    Jiao, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi, and Xing Wang. Leveraging
    word guessing games to assess the intelligence of large language models. *arXiv
    preprint arXiv:2310.20499*, 2023a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2023b) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. Encouraging divergent thinking
    in large language models through multi-agent debate. *arXiv preprint arXiv:2305.19118*,
    2023b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mao et al. (2023) Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang,
    Fengyi Wang, Tao Ge, and Furu Wei. Alympics: Language agents meet game theory.
    *arXiv preprint arXiv:2311.03220*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McAfee & McMillan (1987) R Preston McAfee and John McMillan. Auctions and bidding.
    *Journal of economic literature*, 25(2):699–738, 1987.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Myerson (2013) Roger B Myerson. *Game theory*. Harvard university press, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nagel (1995) Rosemarie Nagel. Unraveling in guessing games: An experimental
    study. *The American economic review*, 85(5):1313–1326, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nash (1950) John F Nash. Equilibrium points in n-person games. *Proceedings
    of the national academy of sciences*, 36(1):48–49, 1950.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nash (1951) John F Nash. Non-cooperative games. *Annals of Mathematics*, 54(2):286–295,
    1951.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'O’Gara (2023) Aidan O’Gara. Hoodwinked: Deception and cooperation in a text-based
    game for language models. *arXiv preprint arXiv:2308.01404*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Persky (1995) Joseph Persky. Retrospectives: The ethology of homo economicus.
    *Journal of Economic Perspectives*, 9(2):221–231, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phelps & Russell (2023) Steve Phelps and Yvan I Russell. Investigating emergent
    goal-like behaviour in large language models using experimental economics. *arXiv
    preprint arXiv:2305.07970*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiao et al. (2023) Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, and Nan Duan.
    Gameeval: Evaluating llms on conversational games. *arXiv preprint arXiv:2308.10032*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. (2023) Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro
    Yasunaga, and Diyi Yang. Is chatgpt a general-purpose natural language processing
    task solver? *arXiv preprint arXiv:2302.06476*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rubinstein (2007) Ariel Rubinstein. Instinctive and cognitive reasoning: A
    study of response times. *The Economic Journal*, 117(523):1243–1259, 2007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Samuelson (1954) Paul A Samuelson. The pure theory of public expenditure. *The
    review of economics and statistics*, 36(4):387–389, 1954.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shapley & Shubik (1969) Lloyd S Shapley and Martin Shubik. Pure competition,
    coalitional power, and fair division. *International Economic Review*, 10(3):337–362,
    1969.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stepputtis et al. (2023) Simon Stepputtis, Joseph Campbell, Yaqi Xie, Zhengyang
    Qi, Wenxin Sharon Zhang, Ruiyi Wang, Sanketh Rangreji, Michael Lewis, and Katia
    Sycara. Long-horizon dialogue understanding for role identification in the game
    of avalon with large language models. *arXiv preprint arXiv:2311.05720*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stewart (1999) Ian Stewart. A puzzle for pirates. *Scientific American*, 280(5):98–99,
    1999.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Surameery & Shakor (2023) Nigar M Shafiq Surameery and Mohammed Y Shakor. Use
    chat gpt to solve programming bugs. *International Journal of Information Technology
    & Computer Engineering (IJITC) ISSN: 2455-5290*, 3(01):17–22, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tsai et al. (2023) Chen Feng Tsai, Xiaochen Zhou, Sierra S Liu, Jing Li, Mo Yu,
    and Hongyuan Mei. Can large language models play text games well? current state-of-the-art
    and open questions. *arXiv preprint arXiv:2304.02868*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vickrey (1961) William Vickrey. Counterspeculation, auctions, and competitive
    sealed tenders. *The Journal of finance*, 16(1):8–37, 1961.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023) Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen,
    Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, and Gao Huang. Avalon’s game
    of thoughts: Battle against deception through recursive contemplation. *arXiv
    preprint arXiv:2310.01320*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2023a) Haoran Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang Jiao, and Michael
    Lyu. Chatgpt or grammarly? evaluating chatgpt on grammatical error correction
    benchmark. *arXiv preprint arXiv:2303.13648*, 2023a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2023b) Yue Wu, Xuan Tang, Tom M Mitchell, and Yuanzhi Li. Smartplay:
    A benchmark for llms as intelligent agents. *arXiv preprint arXiv:2310.01557*,
    2023b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023a) Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt
    Keutzer, and Jiashi Feng. Magic: Investigation of large language model powered
    multi-agent in cognition, adaptability, rationality and collaboration. *arXiv
    e-prints*, pp.  arXiv–2311, 2023a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023b) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. Exploring large language models for communication games:
    An empirical study on werewolf. *arXiv preprint arXiv:2309.04658*, 2023b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2023c) Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. Language
    agents with reinforcement learning for strategic play in the werewolf game. *arXiv
    preprint arXiv:2310.18940*, 2023c.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2023) Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan
    Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. Large language models for information
    retrieval: A survey. *arXiv preprint arXiv:2308.07107*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Prompt Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Design Method
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We adopt a cohesive approach to ensure the prompt design is systematic and
    not arbitrary. Game descriptions are gathered from verified sources, including
    academic papers referenced in §[3](#S3 "3 𝛾-Bench Design ‣ How Far Are We on the
    Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent Environments")
    and Wikipedia entries. Using these descriptions, we instruct GPT-4 to generate
    prompts to guide LLMs in engaging in the specified games. These prompts are structured
    to encompass four essential elements: the rules of the game, objectives for the
    players, a template for announcing game outcomes (for displaying historical results),
    and instructions for formatting responses in JSON. A manual checking process is
    conducted to ascertain that GPT-4’s comprehension of the game descriptions is
    correct. The prompts are detailed in the rest part of this section.'
  prefs: []
  type: TYPE_NORMAL
- en: A.1 Cooperative Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For “Guess 2/3 of the Average,” please refer to Table [3](#S4.T3 "Table 3 ‣
    4 Vanilla Experiments ‣ How Far Are We on the Decision-Making of LLMs? Evaluating
    LLMs’ Gaming Ability in Multi-Agent Environments") in §[4](#S4 "4 Vanilla Experiments
    ‣ How Far Are We on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability
    in Multi-Agent Environments").
  prefs: []
  type: TYPE_NORMAL
- en: '| El Farol Bar |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. Every round, you and the other players decide independently whether
    to go to a bar. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. If equal to or less than $R$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. If more than $R$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. Everyone who stays home receives a utility of $HOME$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Game Results for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | (Only for Explicit) $G_{I}$ of the players went to the bar. |'
  prefs: []
  type: TYPE_TB
- en: '|  | It was [less]/[more] fun to go to the bar this round. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You chose: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“decision”: “$D_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | You gained $G_{IJ}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now round $I$ starts. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your goal is to maximize your fun. Choose to go to the bar when you predict
    fewer than $R$ of the players will go, and choose to stay home otherwise. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your decision in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“decision”: “go_or_stay”}. |'
  prefs: []
  type: TYPE_TB
- en: '| Divide the Dollar |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. You are dividing $G$ golds. Each player independently proposes a bid.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. If the sum of all bids does not exceed $G$, each player receives their
    bid amount. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. If the sum exceeds $G$, all players receive nothing. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Game Results for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your bid amount was: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“bid_amount”: “$B_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | The sum of all bids was $S_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The sum [does not exceed]/[exceeds] $G$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You received [$B_{IJ}$] golds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now round $I$ starts. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your goal is to maximize your individual gain without causing the total
    sum of bids to exceed $G$ golds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your bid amount in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“bid_amount”: “integer_between_0_and_$G$”}. |'
  prefs: []
  type: TYPE_TB
- en: A.2 Betraying Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Public Goods Game |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. In each round, you, as a player, must decide how many of your private
    tokens you wish to contribute secretly to the public pot. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. The total tokens in this pot will be multiplied by the factor $R$
    to create the “public good” payoff. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. This payoff will then be evenly divided among all players, regardless
    of their individual contribution. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. Any tokens you do not contribute will be retained in your private
    collection. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Game Results for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | Contributed tokens of each player: $C_{I1},C_{I2},\cdots,C_{IN}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | You contributed: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“tokens_contributed”: “$C_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | Tokens in the public pot: $S_{I}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your gain: $g_{IJ}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your tokens after round $I$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | Tokens of each player after round $I$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now round $I$ starts. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your goal is to maximize your total token count by the end of the game.
    Currently you have $T_{I-1J}$ tokens. You need to decide the number of tokens
    to be contributed to the public pot. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide the number of tokens in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“tokens_contributed”: “integer_between_0_and_$T_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| Diner’s Dilemma |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. Each player must choose to order either a costly dish or a cheap dish.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. The price of the costly dish is $P_{h}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The costly dish brings you a utility of $U_{h}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. The costly dish is tastier than the cheap dish, but not sufficiently
    to justify its price when dining alone. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 5\. At the end of each round, the total cost of all dishes ordered is
    split equally among all players. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Game Results for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | $N_{h}$ chose the cheap dish. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The total cost is $S_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You chose: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“chosen_dish”: “$D_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | Your utility is $u_{IJ}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now round $I$ starts. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your goal is to maximize your overall satisfaction, balancing the quality
    of the dish and the cost shared. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your chosen dish in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“chosen_dish”: “costly_or_cheap”} |'
  prefs: []
  type: TYPE_TB
- en: '| Sealed-Bid Auction |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. Each player has a private valuation for the item in each round. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. Without knowing the bids and valuations of other players, each player
    submits a written bid for the item. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The highest bidder wins the item and pays the price of the [highest]/[second
    highest] bid. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. If you win, your utility for that round is your valuation minus the
    price paid. If you lose, your utility is zero. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Game Results for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your valuation for this round’s item was $v_{IJ}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your bid was: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“bid”: “$b_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | The winning bid was: $W_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The price paid was: $P_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You [won]/[lost]. Your utility is [$u_{IJ}$]/[0]. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now round $I$ starts. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your goal is to maximize your total utility. Your valuation for this round’s
    item is $v_{IJ}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your bid in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“bid”: “integer_between_0_and_$v_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: A.3 Sequential Games
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Battle Royale |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. You are in a survival game where only one can survive and win. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. Players take turns shooting at others in a predetermined order based
    on their hit rates, from the lowest to the highest. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. Players’ names and hit rates ranked by shooting order are {“$ID_{1}$-th
    to shoot. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. You have an unlimited number of bullets. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 5\. You may choose to intentionally miss your shot on your turn. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Game Results for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your action: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | (Only for the player itself) {“target”: “$t_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | $NAME_{J}$ but missed]. |'
  prefs: []
  type: TYPE_TB
- en: '|  | There are $N_{I}$ players left. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now round $I$ starts. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your goal is to eliminate other players to survive until the end and win
    the game. The remaining players’ names and hit rates ranked by shooting order
    are: {“$ID_{1}$-th to shoot. Please decide whether to shoot at a player or intentionally
    miss. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your action in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“target”: “playerID_or_null”} |'
  prefs: []
  type: TYPE_TB
- en: '| Pirate Game |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You are participating in a game played by $N$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Game Rules: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. You are pirates who have found $G$ gold coins. You are deciding how
    to distribute these coins among yourselves. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. The pirates will make decisions in strict order of seniority. You
    are the $RANK_{J}$-th most senior pirate. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The most senior pirate proposes a plan to distribute the $G$ gold
    coins. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. All pirates, including the proposer, vote on the proposed distribution.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 5\. If the majority accepts the plan, each pirate receives the gold coins
    as the most senior pirate proposed. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 6\. If the majority rejects the plan, the proposer is thrown overboard,
    and the next senior pirate proposes a new plan. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 7\. The game ends when a plan is accepted or only one pirate remains.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | The $I$”}. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $A_{I}$ pirates chose to accept the distribution. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You chose: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“decision”: “$D_{I}J$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | Less than half of the pirates accepted the plan. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The $I$-th most senior pirate was thrown overboard and eliminated from
    the game. The game continues. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Now the $I$-th most senior pirate needs to propose a plan. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your primary goal is to survive. If you survive, your next goal is to
    maximize the number of gold coins you receive. You may also prefer to throw another
    pirate overboard if it does not negatively impact your other goals. |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashlineFor voters | The proposed plan is {“$I$ golds from this plan. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your decision on the current proposal in the following
    JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“decision”: “accept_or_reject”} |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashlineFor proposer | You need to propose a plan to divide $G$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your proposal of the golds distributed to each pirate from
    the you to the $I$-th most senior in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {”proposal”: {“$I$”}} |'
  prefs: []
  type: TYPE_TB
- en: Appendix B Rephrased Prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '§[5.1](#S5.SS1 "5.1 RQ1: Robustness ‣ 5 Further Experiments ‣ How Far Are We
    on the Decision-Making of LLMs? Evaluating LLMs’ Gaming Ability in Multi-Agent
    Environments") involves testing the gpt-3.5-turbo-0125’s robustness against different
    prompt templates. This section shows the prompts we use for this analysis. We
    include only the prompts for the game “Guess 2/3 of the Average,” while the five
    prompt templates of seven other games can be found in our GitHub ([https://github.com/CUHK-ARISE/GAMABench](https://github.com/CUHK-ARISE/GAMABench)).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Guess 2/3 of the Average (V2) |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You’re participating in a game involving $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The rules of the game are as follows: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. Every participant must choose an integer within the range of $MIN$,
    both included. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. Once everyone has chosen their numbers, the mean of all these numbers
    is computed. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The goal number becomes $R$ times this average. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. The person or people who picked a number closest to the goal number
    are declared the winners. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | The outcomes of the game for Round $I$ are as follows: |'
  prefs: []
  type: TYPE_TB
- en: '|  | The average number selected was $M_{I}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | The target number, which is $R$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | The number that won was $W_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your selection was: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“chosen_number”: “$C_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | [Congratulation you won]/[Unfortunately you lost]. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Commencing with round $I$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your target should be to select a number that in your opinion will align
    most closely with $R$ of the total average of all the player’s numbers selected,
    your choice included. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your chosen number in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“chosen_number”: “integer_between_$MIN$”}. |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average (V3) |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You’re engaged in a game, involving $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Rules of the Game: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. An integer number is chosen by every player, within the range of $MIN$,
    both numbers included. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. Once each player has chosen, the average is determined from all the
    selected numbers. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The average is multiplied by $R$ to find the target number. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. The individual or individuals whose chosen number is nearest to the
    target number are declared the winners. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Results of Round $I$ Game: |'
  prefs: []
  type: TYPE_TB
- en: '|  | Chosen number’s average: $M_{I}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | The target percentage ($R$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | The winning number is: $W_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You chose: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“chosen_number”: “$C_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | [Congratulation you won]/[Unfortunately you lost]. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | The commencement of round $I$ is now. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The objective is to select a number that you think will be nearest to
    $R$ times the average of all the digits chosen by the participants, your choice
    included. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your chosen number in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“chosen_number”: “integer_between_$MIN$”}. |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average (V4) |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You’re involved in a game which brings $N$ rounds. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The guidelines of the game are as follows: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. All players have to pick a whole number anywhere from $MIN$, both
    numbers included. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. The chosen numbers are then gathered and their mean is computed. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The number to aim for, or the target number, is $R$ of the calculated
    average. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4.The victorious player(s) are those whose chosen number is closest to
    the target number. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | The outcomes for Round $I$ are as follows: |'
  prefs: []
  type: TYPE_TB
- en: '|  | The average number selected was $M_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your choice was: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“chosen_number”: “$C_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | [Congratulation you won]/[Unfortunately you lost]. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | The commencement of round $I$ is now. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You are tasked with selecting a number that, in your estimation, will
    be as close as possible to $R$ times the average of numbers chosen by all players,
    your own choice included. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your chosen number in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“chosen_number”: “integer_between_$MIN$”}. |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average (V5) |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| System | You will be engaging in a game that is played over $K$ players.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | The Instructions of the Game: |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1\. Every player is supposed to pick an integer that is within the range
    of $MIN$, both numbers inclusive. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2\. The median of all the numbers chosen by the players is then determined
    after all choices have been made. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3\. The number that players are aiming for is $R$ times the calculated
    average. |'
  prefs: []
  type: TYPE_TB
- en: '|  | 4\. The player or players who opt for the number closest to this target
    are declared the winners. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | Results of the Game for Round $I$: |'
  prefs: []
  type: TYPE_TB
- en: '|  | The chosen average number is: $M_{I}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | The target number ($R$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | The number that won: $W_{I}$. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Your selection was: |'
  prefs: []
  type: TYPE_TB
- en: '| Assistant | {“chosen_number”: “$C_{IJ}$”} |'
  prefs: []
  type: TYPE_TB
- en: '| User | [Congratulation you won]/[Unfortunately you lost]. |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\cdots$ |'
  prefs: []
  type: TYPE_TB
- en: '| User | The commencement of round $I$ is now. |'
  prefs: []
  type: TYPE_TB
- en: '|  | You are challenged to select a number which you conjecture will be nearest
    to $R$ times the mean of all numbers picked by the players, inclusive of your
    own choice. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Please provide your chosen number in the following JSON format: |'
  prefs: []
  type: TYPE_TB
- en: '|  | {“chosen_number”: “integer_between_$MIN$”}. |'
  prefs: []
  type: TYPE_TB
- en: Appendix C Rescale Method for Raw Scores
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '|  | $$\begin{split}S_{1}&amp;=\begin{cases}\frac{MAX-S_{1}}{MAX-MIN}*100,&amp;R<1\\
    \frac{\lvert 2S_{1}-(MAX-MIN)\rvert}{MAX-MIN}*100,&amp;R=1\\'
  prefs: []
  type: TYPE_NORMAL
- en: \frac{S_{1}}{MAX-MIN}*100,&amp;R>1\end{cases},\\
  prefs: []
  type: TYPE_NORMAL
- en: S_{2}&amp;=\frac{\max(R,1-R)-S_{2}}{\max(R,1-R)}*100,\\
  prefs: []
  type: TYPE_NORMAL
- en: S_{3}&amp;=\frac{G-S_{3}}{G}*100,\\
  prefs: []
  type: TYPE_NORMAL
- en: S_{4}&amp;=\begin{cases}\frac{T-S_{4}}{T}*100,&amp;R\leq 1\\
  prefs: []
  type: TYPE_NORMAL
- en: \frac{S_{4}}{T}*100,&amp;R>1\end{cases},\\
  prefs: []
  type: TYPE_NORMAL
- en: S_{5}&amp;=S_{5}*100,\\
  prefs: []
  type: TYPE_NORMAL
- en: S_{6}&amp;=100-S_{6},\\
  prefs: []
  type: TYPE_NORMAL
- en: S_{7}&amp;=S_{7}*100,\\
  prefs: []
  type: TYPE_NORMAL
- en: S_{8}&amp;=\frac{2*G-S_{8P}}{2*G}*50+S_{8V}*50.\\
  prefs: []
  type: TYPE_NORMAL
- en: \end{split}$$ |  | (1) |
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D More Quantitative Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Table 5: Quantitative results of playing the games with the same setting five
    times.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Tests | T1 (Default) | T2 | T3 | T4 | T5 | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average | $65.4$ |'
  prefs: []
  type: TYPE_TB
- en: '| El Farol Bar | $73.3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Divide the Dollar | $68.1$ |'
  prefs: []
  type: TYPE_TB
- en: '| Public Goods Game | $58.8$ |'
  prefs: []
  type: TYPE_TB
- en: '| Diner’s Dilemma | $96.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sealed-Bid Auction | $88.3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Battle Royale | $20.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pirate Game | $80.5$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $68.8$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: Quantitative results of playing the games with temperature parameters
    ranging from $0$.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Temperatures | 0.0 | 0.2 | 0.4 | 0.6 | 0.8 | 1.0 (Default) | $Avg_{\pm Std}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average | $48.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| El Farol Bar | $55.8$ |'
  prefs: []
  type: TYPE_TB
- en: '| Divide the Dollar | $69.3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Public Goods Game | $84.8$ |'
  prefs: []
  type: TYPE_TB
- en: '| Diner’s Dilemma | $100.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sealed-Bid Auction | $88.1$ |'
  prefs: []
  type: TYPE_TB
- en: '| Battle Royale | $28.6$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pirate Game | $75.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $68.7$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7: Quantitative results of playing the games using different prompt templates.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Prompt Versions | V1 (Default) | V2 | V3 | V4 | V5 | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average | $65.4$ |'
  prefs: []
  type: TYPE_TB
- en: '| El Farol Bar | $73.3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Divide the Dollar | $68.1$ |'
  prefs: []
  type: TYPE_TB
- en: '| Public Goods Game | $58.8$ |'
  prefs: []
  type: TYPE_TB
- en: '| Diner’s Dilemma | $96.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sealed-Bid Auction | $88.3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Battle Royale | $20.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pirate Game | $80.5$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 8: Quantitative results of playing the games with various game settings.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Guess 2/3 of the Average | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$R=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $79.1$ |'
  prefs: []
  type: TYPE_TB
- en: '| El Farol Bar | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$R=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $53.5$ |'
  prefs: []
  type: TYPE_TB
- en: '| Divide the Dollar | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$G=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $73.2$ |'
  prefs: []
  type: TYPE_TB
- en: '| Public Goods Game | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$R=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $42.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Diner’s Dilemma | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$(P_{l},U_{l},P_{h},U_{h})=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $96.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sealed-Bid Auction | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$Range=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $86.9$ |'
  prefs: []
  type: TYPE_TB
- en: '| Battle Royale | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$Range=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $28.6$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pirate Game | $Avg_{\pm Std}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| \hdashline$G=$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $73.8$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 9: Quantitative results of playing the games using prompt-based improvement
    methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Improvements | Default | CoT | Cooperative | Selfish | Mathematician |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Guess 2/3 of the Average | $65.4$ |'
  prefs: []
  type: TYPE_TB
- en: '| El Farol Bar | $73.3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Divide the Dollar | $68.1$ |'
  prefs: []
  type: TYPE_TB
- en: '| Public Goods Game | $58.8$ |'
  prefs: []
  type: TYPE_TB
- en: '| Diner’s Dilemma | $69.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sealed-Bid Auction | $88.3$ |'
  prefs: []
  type: TYPE_TB
- en: '| Battle Royale | $20.0$ |'
  prefs: []
  type: TYPE_TB
- en: '| Pirate Game | $80.5$ |'
  prefs: []
  type: TYPE_TB
- en: '| Overall | $68.8$ |'
  prefs: []
  type: TYPE_TB
