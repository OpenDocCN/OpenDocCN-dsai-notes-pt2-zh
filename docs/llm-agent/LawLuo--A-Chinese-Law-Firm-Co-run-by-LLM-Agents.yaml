- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:41:02'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'LawLuo: A Chinese Law Firm Co-run by LLM Agents'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.16252](https://ar5iv.labs.arxiv.org/html/2407.16252)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Jingyun Sun¹, Chengxiao Dai², Zhongze Luo¹, Yangbo Chang³, Yang Li^(1,∗)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Large Language Models (LLMs) demonstrate substantial potential in delivering
    legal consultation services to users without a legal background, attributed to
    their superior text comprehension and generation capabilities. Nonetheless, existing
    Chinese legal LLMs limit interaction to a single model-user dialogue, unlike the
    collaborative consultations typical of law firms, where multiple staff members
    contribute to a single consultation. This limitation prevents an authentic consultation
    experience. Additionally, extant Chinese legal LLMs suffer from critical limitations:
    (1) insufficient control over the quality of instruction fine-tuning data; (2)
    increased model hallucination resulting from users’ ambiguous queries; and (3)
    a reduction in the model’s ability to follow instructions over multiple dialogue
    turns. In response to these challenges, we propose a novel legal dialogue framework
    that leverages the collaborative capabilities of multiple LLM agents, termed LawLuo.
    This framework encompasses four agents: a receptionist, a lawyer, a secretary,
    and a boss, each responsible for different functionalities, collaboratively providing
    a comprehensive legal consultation to users. Additionally, we constructed two
    high-quality legal dialogue datasets, KINLED and MURLED, and fine-tuned ChatGLM-3-6b
    using these datasets. We propose a legal query clarification algorithm called
    ToLC. Experimental results demonstrate that LawLuo outperforms baseline LLMs,
    including GPT-4, across three dimensions: lawyer-like language style, the usefulness
    of legal advice, and the accuracy of legal knowledge. Our code and datasets are
    available at [https://github.com/NEFUJing/LawLuo](https://github.com/NEFUJing/LawLuo)'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the release of ChatGPT, the development of Chinese Large Language Models
    (LLMs) has advanced rapidly, resulting in the emergence of several influential
    base models, including ChatGLM (Du et al. [2022](#bib.bib2)), LLaMa (Touvron et al.
    [2023a](#bib.bib12)), and BaiChuan (Yang et al. [2023](#bib.bib24)). These models
    excel in fluent Chinese dialogue and comprehension of complex contexts and user
    intentions. Additionally, domain-specific Chinese LLMs such as Medical LLMs (Yang
    et al. [2024](#bib.bib25); Zhang et al. [2023a](#bib.bib27)), Legal LLMs (Zhou
    et al. [2024](#bib.bib31); Huang et al. [2023](#bib.bib5)), and Financial LLMs
    (Zhang and Yang [2023](#bib.bib29)) have emerged, showcasing exceptional domain-specific
    conversational abilities and meeting diverse user needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chinese Legal LLMs offer users without a legal background timely, accurate,
    and clear solutions to legal issues, effectively addressing the shortage of legal
    resources. Recently, notable Chinese Legal LLMs such as LawGPT (Zhou et al. [2024](#bib.bib31))
    and lawyer-llama (Huang et al. [2023](#bib.bib5)) have emerged. They leverage
    extensive Chinese legal dialogue datasets to fine-tune Chinese base large models,
    resulting in LLMs equipped with comprehensive Chinese legal knowledge and the
    capability to engage in legal consultation dialogues. Nevertheless, a standalone
    legal LLM fall short in simulate the Standard Operating Procedure (SOP) of real-world
    legal consultations, thus failing to deliver an authentic consulting experience
    to users. Additionally, existing LLMs encounter several issues: (1) Users consulting
    these models often lack a legal background, leading to vague and imprecise queries
    that exacerbate models’ tendency to produce hallucinations; (2) Despite utilizing
    large datasets for instruction fine-tuning, current legal LLMs do not sufficiently
    control for data quality; (3) Existing models employ single-turn legal dialogue
    data for fine-tuning, neglecting multi-turn dialogue data, which undermines models’
    ability to follow instructions after multi-turn conversation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5907f0309c262a20fc1b514c0c3a4a8b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: To simulate a realistic legal consultation Standard Operating Procedure
    (SOP), we introduce the LawLuo framework, which encompasses four distinct agents:
    a receptionist, lawyers, the boss, and a secretary. Each of these agents is driven
    by language models: the receptionist by RoBERTa, the lawyers by our fine-tuned
    ChatGLM, the secretary by the base ChatGLM, and the boss by a reward model. These
    agents work in concert to provide a comprehensive and high-quality legal consultation
    experience.'
  prefs: []
  type: TYPE_NORMAL
- en: To address the aforementioned issues, we propose a novel legal dialogue framework,
    termed LawLuo, grounded in LLM multi-agents. Initially, we fine-tune the Chinese
    base LLM, ChatGLM-3-6b, leveraging our meticulously constructed high-quality legal
    dialogue dataset, KINLED, alongside the multi-turn legal consultation dataset,
    MURLED. Contrary to other models of employing extensive datasets, our findings
    indicate that fine-tuning with a smaller, high-quality legal dialogue dataset
    yields superior performance. Subsequently, we design multiple agents—receptionist,
    lawyer, secretary, and boss—based on the SOP of actual law firms. We design a
    collaborative framework wherein these agents synergistically handle a user’s legal
    consultation, thereby enhancing the user consultation experience. We further specialize
    the roles of lawyer agents via role enhancement (Wang et al. [2023b](#bib.bib17);
    Shao et al. [2023](#bib.bib9)), according to different consultation domains. For
    instance, a corporate lawyer is designated to engage with users seeking advice
    on corporate law, whereas a traffic accident lawyer is dedicated to consultations
    concerning traffic accidents. Moreover, to address users’ imprecise and ambiguous
    queries, we draw inspiration from the Tree of Clarification (ToC) (Kim et al.
    [2023](#bib.bib6)) and propose a novel Tree of Legal Clarification (ToLC) algorithm.
    ToLC employs a retrieve-generate-active choosing process to guide users in refining
    their legal queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Experiment results demonstrate that LawLuo significantly outperforms the baselines
    across three key dimensions: lawyer-like language style, the utility of legal
    advice, and the accuracy of legal knowledge. Specifically, LawLuo exhibits a winning
    rate of 72% against ChatGLM-3-6b, the base LLM we utilized, which underscores
    the efficacy of our instruction fine-tuning. Remarkably, LawLuo achieves superior
    performance compared to other legal LLMs while utilizing fewer instruction fine-tuning
    data, emphasizing the critical role of data quality over quantity. Additionally,
    our experimental results indicate that LawLuo consistently generates high-quality
    responses even after multiple dialogue turns, highlighting the importance of using
    real multi-turn legal consultation data for instruction fine-tuning. Lastly, we
    confirmed the contribution of each component through a comprehensive ablation
    study.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, our primary contributions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We propose a legal dialogue framework, LawLuo, based on the collaboration of
    multiple LLM agents.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We construct a high-quality dataset, KINLED, for legal LLM instruction fine-tuning.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We develop a real-world multi-turn legal consultation dataset, MURLED.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We introduce a algorithm for clarifying legal queries, ToLD.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. Related work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Legal Question Answering. Legal Question Answering (LQA) is considered one
    of the most challenging tasks in legal artificial intelligence due to its flexible
    input-output requirements. In this task, users ask legal questions, and systems
    provide detailed answers that meet their expectations. Early LQA systems fall
    into three main categories: retrieval-based LQA systems (Yoshioka, Aoki, and Suzuki
    [2021](#bib.bib26)), knowledge-based LQA systems (Taniguchi and Kano [2017](#bib.bib10)),
    and machine reading comprehension-based LQA systems (Xiao et al. [2021](#bib.bib22)).
    Significant advancements in Chinese LQA have been driven by datasets like the
    Chinese Judicial Reading Comprehension dataset (CJRC) (Duan et al. [2019](#bib.bib3))
    and the Judicial Examination Chinese QA dataset (JEC-QA) (Zhong et al. [2020](#bib.bib30)).
    However, early methods struggle to personalize answers. Additionally, many legal
    consultations require multi-turn dialogues rather than a single question and answer
    exchange.'
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, applying LLM to LQA has shown great promise. Compared to traditional
    LQA models, LLMs generate personalized responses based on user queries and support
    multi-turn dialogues for more precise legal inquiry resolution. LawGPT (Zhou et al.
    [2024](#bib.bib31)) continuing pre-trains and instruction fine-tunes Chinese-LLaMa-7B
    (Touvron et al. [2023a](#bib.bib12)), a Chinese base model, with publicly available
    legal documents and judicial examination data, thereby enhancing its understanding
    and execution of legal content. LexiLaw¹¹1[https://github.com/CSHaitao/LexiLaw](https://github.com/CSHaitao/LexiLaw)
    fine-tunes ChatGLM-6B with data from Huazhi.com²²2[https://www.66law.cn/](https://www.66law.cn/),
    judicial examination data, and Q&A data with legal references, using Freeze, Lora,
    and P-Tuning-V2 techniques to boost training efficiency. LawGPT_zh fine-tunes
    ChatGLM-6B using existing legal datasets and scenario-based Q&A data with statutory
    references, while lawyer-llama (Huang et al. [2023](#bib.bib5)) uses judicial
    examination data to fine-tune Chinese-LLaMA-13, enhancing its application of legal
    knowledge to dialogue scenarios. However, these models only use a single LLM for
    legal consultations, unlike real-world law firms where multiple staff collaborate
    on a user’s consultation. This limitation fails to provide users with the most
    realistic and expected LQA experience. Additionally, while current legal LLMs
    use numerous fine-tuning datasets, their quality varies significantly, contradicting
    recent findings that in large model instruction fine-tuning, “less is more” (i.e.,
    data quality is more important than quantity) (Wei et al. [2023b](#bib.bib19);
    Xia et al. [2024](#bib.bib21)).
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Agent Collaboration. In LLM-based multi-agent systems, an agent is defined
    as an autonomous entity capable of perceiving, thinking, learning, making decisions,
    and interacting with other agents (Xi et al. [2023](#bib.bib20)). Research shows
    that breaking complex tasks into simpler subtasks and tackling these with agents
    that have diverse functions can significantly enhance the problem-solving capabilities
    of LLMs. (Wang et al. [2024](#bib.bib14)). Fundamentally, Retrieval-Augmented
    Generation (RAG) based on LLMs constitutes a straightforward multi-agent system
    wherein a retrieval agent is tasked with sourcing relevant knowledge from a vector
    database, while an LLM agent is responsible for generating responses based on
    the query and associated knowledge (Louis, van Dijck, and Spanakis [2024](#bib.bib7)).
    Furthermore, some works have developed more complex multi-agent collaborative
    systems to address intricate challenges. For instance, (Qian et al. [2023](#bib.bib8))
    designed a multi-agent collaborative workflow in which agents assuming roles such
    as CTO, programmer, designer, and tester work closely together to complete software
    development and document the development process. (Hemmer et al. [2022](#bib.bib4))
    have facilitated the construction of machine learning models through collaboration
    between multiple agents and humans. Additionally, LLM-based multi-agent systems
    can also be employed for realistic environment simulation. For example, (Wang
    et al. [2023a](#bib.bib15)) utilized multiple generative LLM agents in a sandbox
    environment to simulate consumer behavior in merchandise recommendation scenarios,
    (Wei et al. [2023a](#bib.bib18)) assigned various roles to agents for the collection
    and evaluation of multi-party dialogue data, and (Du et al. [2023](#bib.bib1))
    leveraged debates among agents with different personalities to enhance the factual
    accuracy of LLM reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. LawLuo Framework for LQA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In real-world scenarios, a consultation in law firms is conducted through the
    collaboration of multiple staff members, whereas existing legal LLMs generally
    engage with a user in isolation. To bridge this gap, we introduce a multi-agent
    collaborative legal dialogue framework, named LawLuo.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we perform LoRA fine-tuning on ChatGLM-3-6b using knowledge-intensive
    dialogue data and real multi-turn dialogue data from a Chinese law firm, resulting
    in a multi-turn dialogue LLM with a legal background, denoted as $LLM_{Legal}:(s_{0},U_{1:T})\mapsto
    R_{1:T}$ represents the initial dialogue state.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we design various agents with different roles, including a receptionist
    agent responsible for allocating lawyers from different fields based on user queries,
    lawyer agents for conducting multi-turn LQA with users, a secretary agent for
    organizing the dialogue between users and lawyers into consultation reports, and
    a boss agent supervising other agents. Finally, we construct a collaborative framework
    to guide interactions among these agents, thereby providing users with a high-quality
    LQA experience.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Instruction Fine-tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Existing LLMs in the legal domain, despite leveraging a substantial volume
    of dialogue data during the instruction fine-tuning process, frequently contend
    with quality deficiencies. Figure [2](#Sx3.F2 "Figure 2 ‣ 3.1 Instruction Fine-tuning
    ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents")
    presents the lawyer consultation data³³3[https://github.com/liuhuanyong/CrimeKgAssitant](https://github.com/liuhuanyong/CrimeKgAssitant)
    utilized by LawGPT_zh and the Baidu Zhidao Q&A data⁴⁴4[https://pan.baidu.com/s/18Lwq16VBo6wBD_qLb3i33g](https://pan.baidu.com/s/18Lwq16VBo6wBD_qLb3i33g)
    employed by LexiLaw. It is apparent that the questions’ clarity and the responses’
    professionalism in these dialogues are suboptimal, impairing models’ instruction
    follow capabilities in LQA.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/225108e775af39240c4f69eff6619207.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Examples of dialogue data used for instruction fine-tuning of existing
    Chinese legal LLMs. The upper section shows legal consultation data used by LawGPT_zh,
    while the lower section displays Q&A data from Baidu Zhidao used by LexiLaw. It
    is evident from these examples that the professionalism of both the questions
    and answers is relatively low.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recent studies indicate that utilizing fewer but higher-quality data can significantly
    enhance the instruction-following capabilities of LLMs (Wei et al. [2023b](#bib.bib19);
    Xia et al. [2024](#bib.bib21)). Consequently, we developed a smaller but higher-quality
    dataset, termed Knowledge-INtensive LEgal Dialogue (KINLED) dataset. Firstly,
    we screened existing legal dialogue datasets, discarding lower-quality dialogues
    and retaining those of higher-quality. Moreover, to enhance the model’s application
    of critical legal terminologies, we constructed legal term and explanation dialogue
    data. Additionally, to improve the model’s understanding of significant charges
    and legal provisions, we created legal judgment dialogue and judicial interpretation
    dialogue. The KINLED dataset construction employed the self-instruct strategy,
    with specific construction details provided in Appendix A. Table [1](#Sx3.T1 "Table
    1 ‣ 3.1 Instruction Fine-tuning ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese
    Law Firm Co-run by LLM Agents") presents the statistical information of the KINLED
    dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Composition | No. Dialogue Entries |'
  prefs: []
  type: TYPE_TB
- en: '| Legal Term Explanation Dialogue | 3,125 |'
  prefs: []
  type: TYPE_TB
- en: '| Legal Judgment Dialogue | 533 |'
  prefs: []
  type: TYPE_TB
- en: '| Judicial Interpretation Dialogue | 4,382 |'
  prefs: []
  type: TYPE_TB
- en: '| Scenario Q&A Based on Legal Grounds | 3,026 |'
  prefs: []
  type: TYPE_TB
- en: '| Single-Turn Legal Dialogue | 995 |'
  prefs: []
  type: TYPE_TB
- en: '| Judicial Examination Dialogue | 985 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Statistical information of the Knowledge-INtensive LEgal Dialogue
    (KINLED) dataset we constructed. The legal term and explanation dialogues, legal
    judgment dialogues, as well as judicial interpretation dialogues, were created
    by us, while the other dialogues were selected from existing works.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The existing legal LLMs have all been fine-tuned using single-turn dialogue
    data, which hinders their ability to follow instructions in multi-turn dialogue
    scenarios. To address this limitation, we constructed a fine-tuning dataset based
    on 3,260 anonymized multi-turn legal consultations from a law firm, termed MUltiple
    Rounds LEgal Dialogue (MURLED). Figure [3](#Sx3.F3 "Figure 3 ‣ 3.1 Instruction
    Fine-tuning ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese Law Firm Co-run
    by LLM Agents") presents an example of a multi-turn dialogue from MURLED, demonstrating
    the clarity of the questions and the professionalism of the responses.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dc4f2d21ccb412893b8ab7ebacdd4095.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: An example dialogue from the MUltiple Rounds LEgal Dialogue (MURLED)
    dataset. As can be seen, the user’s inquiries are clear, and the lawyer’s responses
    are professional.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use KINLED and MURLED to fine-tune ChatGLM-3-6b, a Chinese base LLM. To
    mitigate the risk of overfitting, we incorporated general conversational data
    from Alpaca-GPT4⁵⁵5[https://www.modelscope.cn/datasets/AI-ModelScope/alpaca-gpt4-data-zh/summary](https://www.modelscope.cn/datasets/AI-ModelScope/alpaca-gpt4-data-zh/summary),
    which comprises 52,000 generic Chinese dialogues, into the instruction fine-tuning
    process. To expedite the fine-tuning of the model and reduce reliance on computational
    resources, we employed the LoRA fine-tuning strategy, as illustrated in Equation
    [1](#Sx3.E1 "In 3.1 Instruction Fine-tuning ‣ 3\. LawLuo Framework for LQA ‣ LawLuo:
    A Chinese Law Firm Co-run by LLM Agents"):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $\theta$ represents LoRA fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Agent Definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We define the following agents based on the Standard Operating Procedures (SOP)
    of law firms: 1) Receptionist, responsible for assigning lawyers to users based
    on the queries they present. 2) Lawyers, engage in multiple rounds dialogue to
    resolve users’ legal issues. 3) Secretary, responsible for compiling the dialogues
    between users and lawyers into consultation reports, and then submitting them
    to both the users and the boss. 4) Boss, charged with evaluating the lawyers and
    the secretary. Subsequently, we will provide a detailed exposition of these agents.'
  prefs: []
  type: TYPE_NORMAL
- en: Receptionist
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Given the user’s initial question $u_{1}$, as shown in Equation [2](#Sx3.E2
    "In Receptionist ‣ 3.2 Agent Definition ‣ 3\. LawLuo Framework for LQA ‣ LawLuo:
    A Chinese Law Firm Co-run by LLM Agents"):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Rec:(u_{1},s_{0})\mapsto d\in\mathcal{D}$ |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: 'where the set $\mathcal{D}$ represents our predefined consultation domains.
    We adhere to the classification of legal consultation domains as outlined on the
    HuLaw website⁶⁶6[https://www.66law.cn/](https://www.66law.cn/), encompassing a
    total of 16 domains, as depicted in Figure [4](#Sx3.F4 "Figure 4 ‣ Receptionist
    ‣ 3.2 Agent Definition ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese Law
    Firm Co-run by LLM Agents"). Of these, 15 are common consultation fields, while
    other less common consultation areas are collectively categorized under “Others”.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/985979f56f59bd1abece45a457875e51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Predefined legal consultation domains and statistical information'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use a contrastive trained RoBERTa as the secretary agent. We first crawled
    35,060 legal questions with domain tags from HuaLaw web, with the number of questions
    in each domain illustrated in Figure [4](#Sx3.F4 "Figure 4 ‣ Receptionist ‣ 3.2
    Agent Definition ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese Law Firm Co-run
    by LLM Agents"). Subsequently, we used the current question as the anchor, questions
    from the same domain as positive examples, and questions from different domains
    as negative examples. We optimized the semantic distance between samples using
    contrastive loss, as depicted in Equation [3](#Sx3.E3 "In Receptionist ‣ 3.2 Agent
    Definition ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese Law Firm Co-run
    by LLM Agents").'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}=\frac{1}{N}\sum_{n=1}^{N}\left[\left\&#124;\vec{a}_{i}-\vec{p}_{i}\right\&#124;^{2}+\max\left(0,\alpha-\left\&#124;\vec{a}_{i}-\vec{n}_{i}\right\&#124;\right)^{2}\right]$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where $\vec{a}_{i}$ denotes the Euclidean distance. We utilize Lawformer (Xiao
    et al. [2021](#bib.bib22)) as the embedding model.
  prefs: []
  type: TYPE_NORMAL
- en: Lawyers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We utilize the $LLM_{Legal}$, as shown in Equation [4](#Sx3.E4 "In Lawyers
    ‣ 3.2 Agent Definition ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese Law
    Firm Co-run by LLM Agents")'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Lawyer_{d}\leftarrow RE_{d}(LLM_{Legal})$ |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $RE_{d}(\cdot)$ represents the prompt function used for role enhancement.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, existing legal LLMs overlook a critical challenge in LQA: the
    legal questions posed by users are often rough and ambiguous. Directly inputting
    such questions into the LLM makes it difficult to obtain the desired answers.
    By contrast, in real-world practice, lawyers typically guide users to clarify
    their questions, resulting in clear and detailed inquiries. Therefore, we propose
    the Tree of Legal Clarifications (ToLC) algorithm, which builds on the Tree of
    Clarifications (ToC) proposed by (Kim et al. [2023](#bib.bib6)). The ToC uses
    top-K articles from Wikipedia to guide LLM in generating clarification questions.
    We adapted this by searching for top-K relevant cases from a legal case database
    to guide LLM in generating necessary legal clarifications. The ToC prunes unhelpful
    nodes through LLM’s self-verification, while we altered this process to involve
    active Yes/No answering by users. We believe users understand their own cases
    better than any language model or external knowledge. In other words, lawyers
    should guide users in clarifying legal facts, not fabricate the facts involved.
    Algorithm [1](#alg1 "Algorithm 1 ‣ Lawyers ‣ 3.2 Agent Definition ‣ 3\. LawLuo
    Framework for LQA ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents") describes
    the implementation of ToLC.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 Tree of Legal Clarifications (ToLC)
  prefs: []
  type: TYPE_NORMAL
- en: 1:User’s query in the $t$ Lawyer agent generates a response
  prefs: []
  type: TYPE_NORMAL
- en: Secretary
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The duty of the secretary agent is organizing the dialogue between the user
    and the lawyer into a consultation report and then submitting it to both the user
    and the boss, as shown in Equation [5](#Sx3.E5 "In Secretary ‣ 3.2 Agent Definition
    ‣ 3\. LawLuo Framework for LQA ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents").'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Sec:(s_{0},U_{1:T},R_{1:T})\mapsto r$ |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $r$ denotes the consultation report generated by the secretary agent.
    We utilize ChatGLM-3-6b as the secretary agent and employ In-Context Learning
    (ICL) to guide the model in producing consultation reports that meet expectations.
    We have constructed four standard consultation report samples, as shown in Appendix
    B, to serve as demonstrations in ICL reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: Boss
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The boss agent is responsible for evaluating the lawyer and secretary agents.
    Essentially, the boss agent is a Reward Model (RM). We first train a binary evaluation
    RM, $RM:o\mapsto y$, categorized into “better” and “worse”. The training objective
    of the RM is to minimize the following loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathcal{L}_{RM}=-\frac{1}{N}\sum_{i=1}^{N}$ |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle\left.+(1-y_{i})\cdot\log\left(1-\hat{y}_{i}(o_{i};\theta_{RM})\right)\right]$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $y_{i}$ as “better.”
  prefs: []
  type: TYPE_NORMAL
- en: We employed the PPO algorithm (Wang, He, and Tan [2020](#bib.bib16)) during
    the reinforcement learning phase, an efficient reinforcement learning method that
    utilizes RM’s evaluation outcomes to guide the updates of the LLM. This approach
    further aligns the LLM’s performance with the preferences of human experts (the
    boss agent).
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the definitions of the agents, we constructed a collaborative pipeline
    designed to imitate the SOP of legal consultations in real law firms, as illustrated
    in Figure [5](#Sx3.F5 "Figure 5 ‣ Boss ‣ 3.2 Agent Definition ‣ 3\. LawLuo Framework
    for LQA ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents"). The pipeline begins
    with the user initiating a consultation. Subsequently, the receptionist agent
    refers the user to an appropriate lawyer agent based on the user’s inquiry. The
    lawyer agent then engages in a dialogue with the user, utilizing the ToLC algorithm
    to clarify any ambiguous inquiries. Once the consultation concludes, the secretary
    agent compiling the conversation records between the user and the lawyer agent
    into a consultation report and submitting it to the user and the boss. The boss
    agent evaluate the responses generated by the lawyer agent and the reports generated
    by the secretary agent to optimize the their subsequent outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/14219b06d7be4df07c2805b2845a33d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Collaborative workflow of agents designed according to Standard Operating
    Procedures (SOP) of actual law firms'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Experimental Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All our experiments were conducted on a 40G A100 GPU. The PyTorch 2.3.0 and
    the HuggingFace Transformers 4.40.0 were used. The learning rate for LoRA fine-tuning
    was set to 0.00005, with a training batch size of 2, over a total of 3 epochs,
    and model weights were saved every 1,000 steps. Additionally, the rank of LoRA
    was set to 16, the alpha parameter was set to 32, and the dropout rate was set
    to 0.05\. The case database used in the ToLC algorithm was sourced from the China
    Judgments Online website.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Results and Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1 Results on Single-turn Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We follow the current mainstream evaluation methods for large models to assess
    our LawLuo (Thirunavukarasu et al. [2023](#bib.bib11); Xiong et al. [2023](#bib.bib23);
    Zhang et al. [2023b](#bib.bib28)). We engaged both human experts and GPT-4o to
    evaluate the model’s performance based on the following criteria: lawyer-like
    language style, usefulness of legal advice, and accuracy of legal knowledge. We
    employed pairwise evaluation, where given a response from LawLuo and a baseline
    response, the better one is selected. Figure [6](#Sx5.F6 "Figure 6 ‣ 5.1 Results
    on Single-turn Questions ‣ 5\. Results and Analysis ‣ LawLuo: A Chinese Law Firm
    Co-run by LLM Agents") shows the win rate of LawLuo compared to baselines. Overall,
    LawLuo significantly outperforms the baselines. Additionally, as seen in the figure,
    LawLuo achieved a 72% win rate against ChatGLM-3-6b, demonstrating the effectiveness
    of our instruction fine-tuning process, given that LawLuo was fine-tuned on ChatGLM-3-6b.
    Furthermore, the figure indicates that LawLuo outperforms the other two legal
    large models, LawGPT and LawyerLLaMa. Lastly, even when compared to GPT-4, LawLuo
    still exhibits a significant advantage.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/59f836fc9fbdb142bb14c4e5169358d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Win rate of LawLuo compared to the baselines'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Results on Multi-turn Dialogues
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section aims to analyze the advantages of LawLuo in multi-turn dialogue
    scenarios. We employed GPT-4o to rate the responses generated by the model in
    each turn of the dialogue, assessing the quality variation of the responses as
    the number of dialogue turns increased. We set a scoring range of 1-10, using
    the criteria of lawyer-like language style, the usefulness of legal advice, and
    the accuracy of legal knowledge as mentioned in Section 5.1\. The prompt driving
    GPT-4o’s scoring is provided in Appendix C. As shown in Figure [7](#Sx5.F7 "Figure
    7 ‣ 5.2 Results on Multi-turn Dialogues ‣ 5\. Results and Analysis ‣ LawLuo: A
    Chinese Law Firm Co-run by LLM Agents"), LawLuo’s responses maintain a high score
    as the number of dialogue turns increases. This result is primarily attributed
    to our use of multi-turn dialogue data, enhanced by ChatGPT and sourced from actual
    law firms, for instruction fine-tuning, as opposed to other legal LLMs that only
    use single-turn dialogue data.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f154a9ec8a0c60f211039a68842e7c38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The variation in the quality of model-generated responses with increasing
    dialogue turns'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Ablation Study
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section aims to validate the contributions of each component within the
    framework. We continue to use GPT-4o as the evaluator to assess the win rate of
    LawLuo over ChatGPT after ablation, as illustrated in Figure [8](#Sx5.F8 "Figure
    8 ‣ 5.3 Ablation Study ‣ 5\. Results and Analysis ‣ LawLuo: A Chinese Law Firm
    Co-run by LLM Agents"). From the figure, it is evident that the win rate of LawLuo
    over ChatGPT decreases by 3% after ablating the receptionist agent and role enhancement.
    This result validates our hypothesis that legal LLMs should be assigned different
    domain-specific roles to provide more targeted answers based on the user’s consultation
    field. Additionally, the figure shows that the boss agent also contributes to
    LawLuo’s performance, as it can optimize the responses generated by the lawyer.
    Finally, we observe a significant decline in model performance after removing
    the ToLD module. This indicates that clarifying users’ vague and ambiguous queries
    is crucial for generating high-quality responses in legal question-answering.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ad6e30cec051f8dff16b7d93deb8638d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Results of Ablation Experiments'
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Case Study of ToLD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This section elucidates the contributions of ToLD through a specific case study.
    We take the query “ 我要离婚，该怎么办？(I want a divorce, what should I do?)” as an example
    initiated by a user. The left side of Figure 9 displays the clarifying questions
    generated by the ToLD algorithm. The results after the user actively marked Yes/No
    are shown on the right side of Figure [9](#Sx5.F9 "Figure 9 ‣ 5.4 Case Study of
    ToLD ‣ 5\. Results and Analysis ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/119ec07bab5a722511fb38b061ccd08e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Subfigure (a) presents the clarification tree generated by the ToLD
    algorithm, while subfigure (b) depicts the outcome after the user has marked the
    nodes on the tree with Yes/No.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, the first row of Table [2](#A1.T2 "Table 2 ‣ D. Case Study of
    ToLC ‣ Appendix A Appendix ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents")
    in Appendix D presents the answer generated by LawLuo without ToLD, while the
    second row shows the answer generated by LawLuo with ToLD. It can be observed
    that ToLD assists legal LLMs in generating more accurate and personalized responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Enlightenment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This study has provided us with several intriguing insights. Firstly, we discovered
    that omitting continue pre-training and directly conducting instruction fine-tuning
    does not impact the effectiveness of the legal LLM. This indicates that the Chinese
    base model has already acquired a certain degree of legal knowledge during the
    pre-training phase, obviating the need for additional pre-training with legal
    corpora. In fact, the pre-training corpora used by many Chinese base models are
    extraordinarily large and likely encompass a substantial amount of legal text.
    We also found that the instruction fine-tuning phase does not require tens of
    thousands or even hundreds of thousands of dialogue data; approximately thousands
    high-quality legal dialogue data are sufficient to elicit the model’s legal knowledge
    application capabilities in dialogue scenarios. This paves a new path for the
    future fine-tuning of legal LLMs. Lastly, the effectiveness of role enhancement
    and multi-agent collaboration in our method validated our hypothesis that a legal
    consultation should not be a mere conversational process but a complex task involving
    multiple business processes.
  prefs: []
  type: TYPE_NORMAL
- en: Limitation and Future Work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although we observed that the receptionist agent achieved a question classification
    accuracy rate exceeding 98% in our experiments, any misclassification leads to
    the lawyer agent continuing the interaction based on the initial error (a matrimonial
    lawyer could handle legal inquiries related to traffic accidents, albeit with
    reduced effectiveness). In the future, we plan to design a dynamic receptionist
    mechanism that reallocates the user to the appropriate lawyer based on conversation
    content whenever a domain mismatch is detected during the interaction with the
    legal LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Despite introducing the concept of multi-agent collaboration, not every agent
    is an LLM, resulting in limited thinking and decision-making capabilities. In
    the future, we intend to develop a collaborative framework in which all agents
    are LLMs, thereby enhancing the overall framework’s cognitive and decision-making
    abilities.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We propose a multi-agent collaboration framework for legal dialogue, termed
    LawLuo. Experimental results demonstrate that LawLuo outperforms baseline LLMs
    in three dimensions: lawyer-like language style, the usefulness of legal advice,
    and the accuracy of legal knowledge. Moreover, it continues to produce high-quality
    answer even after multiple rounds of dialogue. We contribute two high-quality
    datasets for legal LLM instruction fine-tuning, KINLED and MURLED. Experimental
    results indicate that using these datasets can fine-tune more effective legal
    LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work is supported by “the Fundamental Research Funds for the Central Universities,
    xxxx”
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Du et al. (2023) Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; and Mordatch,
    I. 2023. Improving factuality and reasoning in language models through multiagent
    debate. *arXiv preprint arXiv:2305.14325*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Du et al. (2022) Du, Z.; Qian, Y.; Liu, X.; Ding, M.; Qiu, J.; Yang, Z.; and
    Tang, J. 2022. GLM: General Language Model Pretraining with Autoregressive Blank
    Infilling. In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, 320–335.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Duan et al. (2019) Duan, X.; Wang, B.; Wang, Z.; Ma, W.; Cui, Y.; Wu, D.; Wang,
    S.; Liu, T.; Huo, T.; Hu, Z.; et al. 2019. Cjrc: A reliable human-annotated benchmark
    dataset for chinese judicial reading comprehension. In *Chinese Computational
    Linguistics: 18th China National Conference, CCL 2019, Kunming, China, October
    18–20, 2019, Proceedings 18*, 439–451\. Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hemmer et al. (2022) Hemmer, P.; Schellhammer, S.; Vössing, M.; Jakubik, J.;
    and Satzger, G. 2022. Forming Effective Human-AI Teams: Building Machine Learning
    Models that Complement the Capabilities of Multiple Experts. In *Proceedings of
    the Thirty-First International Joint Conference on Artificial Intelligence*, 2478.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2023) Huang, Q.; Tao, M.; Zhang, C.; An, Z.; Jiang, C.; Chen,
    Z.; Wu, Z.; and Feng, Y. 2023. Lawyer llama technical report. *arXiv preprint
    arXiv:2305.15062*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2023) Kim, G.; Kim, S.; Jeon, B.; Park, J.; and Kang, J. 2023.
    Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented
    Large Language Models. In *Proceedings of the 2023 Conference on Empirical Methods
    in Natural Language Processing*, 996–1009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Louis, van Dijck, and Spanakis (2024) Louis, A.; van Dijck, G.; and Spanakis,
    G. 2024. Interpretable long-form legal question answering with retrieval-augmented
    large language models. In *Proceedings of the AAAI Conference on Artificial Intelligence*,
    volume 38, 22266–22275.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qian et al. (2023) Qian, C.; Cong, X.; Yang, C.; Chen, W.; Su, Y.; Xu, J.; Liu,
    Z.; and Sun, M. 2023. Communicative agents for software development. *arXiv preprint
    arXiv:2307.07924*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shao et al. (2023) Shao, Y.; Li, L.; Dai, J.; and Qiu, X. 2023. Character-LLM:
    A Trainable Agent for Role-Playing. In *Proceedings of the 2023 Conference on
    Empirical Methods in Natural Language Processing*, 13153–13187.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Taniguchi and Kano (2017) Taniguchi, R.; and Kano, Y. 2017. Legal yes/no question
    answering system using case-role analysis. In *New Frontiers in Artificial Intelligence:
    JSAI-isAI 2016 Workshops, LENLS, HAT-MASH, AI-Biz, JURISIN and SKL, Kanagawa,
    Japan, November 14-16, 2016, Revised Selected Papers*, 284–298\. Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thirunavukarasu et al. (2023) Thirunavukarasu, A. J.; Ting, D. S. J.; Elangovan,
    K.; Gutierrez, L.; Tan, T. F.; and Ting, D. S. W. 2023. Large language models
    in medicine. *Nature medicine*, 29(8): 1930–1940.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023a) Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; et al. 2023a.
    Llama 2: Open foundation and fine-tuned chat models. *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023b) Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; et al. 2023b.
    Llama 2: Open foundation and fine-tuned chat models. *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2024) Wang, L.; Ma, C.; Feng, X.; Zhang, Z.; Yang, H.; Zhang,
    J.; Chen, Z.; Tang, J.; Chen, X.; Lin, Y.; et al. 2024. A survey on large language
    model based autonomous agents. *Frontiers of Computer Science*, 18(6): 186345.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023a) Wang, L.; Zhang, J.; Chen, X.; Lin, Y.; Song, R.; Zhao,
    W. X.; and Wen, J.-R. 2023a. Recagent: A novel simulation paradigm for recommender
    systems. *arXiv preprint arXiv:2306.02552*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang, He, and Tan (2020) Wang, Y.; He, H.; and Tan, X. 2020. Truly proximal
    policy optimization. In *Uncertainty in artificial intelligence*, 113–122\. PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023b) Wang, Z. M.; Peng, Z.; Que, H.; Liu, J.; Zhou, W.; Wu,
    Y.; Guo, H.; Gan, R.; Ni, Z.; Zhang, M.; et al. 2023b. Rolellm: Benchmarking,
    eliciting, and enhancing role-playing abilities of large language models. *arXiv
    preprint arXiv:2310.00746*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wei et al. (2023a) Wei, J.; Shuster, K.; Szlam, A.; Weston, J.; Urbanek, J.;
    and Komeili, M. 2023a. Multi-party chat: Conversational agents in group settings
    with humans and models. *arXiv preprint arXiv:2304.13835*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wei et al. (2023b) Wei, L.; Jiang, Z.; Huang, W.; and Sun, L. 2023b. Instructiongpt-4:
    A 200-instruction paradigm for fine-tuning minigpt-4. *arXiv preprint arXiv:2308.12067*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xi et al. (2023) Xi, Z.; Chen, W.; Guo, X.; He, W.; Ding, Y.; Hong, B.; Zhang,
    M.; Wang, J.; Jin, S.; Zhou, E.; et al. 2023. The rise and potential of large
    language model based agents: A survey. *arXiv preprint arXiv:2309.07864*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xia et al. (2024) Xia, M.; Malladi, S.; Gururangan, S.; Arora, S.; and Chen,
    D. 2024. Less: Selecting influential data for targeted instruction tuning. *arXiv
    preprint arXiv:2402.04333*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiao et al. (2021) Xiao, C.; Hu, X.; Liu, Z.; Tu, C.; and Sun, M. 2021. Lawformer:
    A pre-trained language model for chinese legal long documents. *AI Open*, 2: 79–84.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiong et al. (2023) Xiong, H.; Wang, S.; Zhu, Y.; Zhao, Z.; Liu, Y.; Huang,
    L.; Wang, Q.; and Shen, D. 2023. Doctorglm: Fine-tuning your chinese doctor is
    not a herculean task. *arXiv preprint arXiv:2304.01097*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023) Yang, A.; Xiao, B.; Wang, B.; Zhang, B.; Bian, C.; Yin,
    C.; Lv, C.; Pan, D.; Wang, D.; Yan, D.; et al. 2023. Baichuan 2: Open large-scale
    language models. *arXiv preprint arXiv:2309.10305*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2024) Yang, S.; Zhao, H.; Zhu, S.; Zhou, G.; Xu, H.; Jia, Y.;
    and Zan, H. 2024. Zhongjing: Enhancing the chinese medical capabilities of large
    language model through expert feedback and real-world multi-turn dialogue. In
    *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 38, 19368–19376.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yoshioka, Aoki, and Suzuki (2021) Yoshioka, M.; Aoki, Y.; and Suzuki, Y. 2021.
    Bert-based ensemble methods with data augmentation for legal textual entailment
    in coliee statute law task. In *Proceedings of the eighteenth international conference
    on artificial intelligence and law*, 278–284.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023a) Zhang, H.; Chen, J.; Jiang, F.; Yu, F.; Chen, Z.; Chen,
    G.; Li, J.; Wu, X.; Zhiyi, Z.; Xiao, Q.; et al. 2023a. HuatuoGPT, Towards Taming
    Language Model to Be a Doctor. In *Findings of the Association for Computational
    Linguistics: EMNLP 2023*, 10859–10885.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023b) Zhang, H.; Chen, J.; Jiang, F.; Yu, F.; Chen, Z.; Chen,
    G.; Li, J.; Wu, X.; Zhiyi, Z.; Xiao, Q.; et al. 2023b. HuatuoGPT, Towards Taming
    Language Model to Be a Doctor. In *Findings of the Association for Computational
    Linguistics: EMNLP 2023*, 10859–10885.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang and Yang (2023) Zhang, X.; and Yang, Q. 2023. Xuanyuan 2.0: A large chinese
    financial chat model with hundreds of billions parameters. In *Proceedings of
    the 32nd ACM international conference on information and knowledge management*,
    4435–4439.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhong et al. (2020) Zhong, H.; Xiao, C.; Tu, C.; Zhang, T.; Liu, Z.; and Sun,
    M. 2020. JEC-QA: a legal-domain question answering dataset. In *Proceedings of
    the AAAI conference on artificial intelligence*, volume 34, 9701–9708.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2024) Zhou, Z.; Shi, J.-X.; Song, P.-X.; Yang, X.-W.; Jin, Y.-X.;
    Guo, L.-Z.; and Li, Y.-F. 2024. LawGPT: A Chinese Legal Knowledge-Enhanced Large
    Language Model. *arXiv preprint arXiv:2406.04614*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A. Construction of the KINLED Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The KINLED dataset consists of six parts: legal term and explanation dialogues,
    legal judgment dialogues, judicial interpretation dialogues, scenario-based question-and-answer
    dialogues with legal grounds, single-round legal consultation dialogues and judicial
    examination dialogues.'
  prefs: []
  type: TYPE_NORMAL
- en: legal Term and Explanation Dialogue
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We first obtained 625 legal terms and their corresponding explanations from
    the Chinese Legal Terminology Compilation website, covering various legal fields
    such as civil law, criminal law, and jurisprudence. Subsequently, we called the
    official API of Moonshot AI, using the moonshot-v1-8k model to generate scenario
    dialogues related to these legal term explanations. To ensure the diversity of
    the dialogue data, we generated five different contextual question-and-answer
    pairs for each legal term and its corresponding explanation. The prompts we designed
    is as shown in Figure [10](#A1.F10 "Figure 10 ‣ legal Term and Explanation Dialogue
    ‣ A. Construction of the KINLED Dataset ‣ Appendix A Appendix ‣ LawLuo: A Chinese
    Law Firm Co-run by LLM Agents"):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7bf80e68374ec484a270844e30518d6f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Prompt template to guide the moonshot-v1-8k model in generating
    legal term and explanation dialogues'
  prefs: []
  type: TYPE_NORMAL
- en: Legal Judgment Dialogue
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We obtained 200 representative legal judgments from the China Judgments Online
    database and performed data cleaning. These documents cover three different types
    of cases: civil, criminal, and administrative. Subsequently, we utilized the official
    API of Moonshot AI, employing the moonshot-v1-128k model to generate question-answer
    dialogues based on these 200 judgment documents. After human expert review, we
    produced 533 high-quality question-answer dialogues. To ensure diversity in the
    dialogues, multiple sets of question-answer pairs were generated for each judgment
    document. The prompts we designed is as shown in Figure [11](#A1.F11 "Figure 11
    ‣ Legal Judgment Dialogue ‣ A. Construction of the KINLED Dataset ‣ Appendix A
    Appendix ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents"):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/06c6c5f3a16806a7ef8fe5e797e85c9b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Prompt template to guide the moonshot-v1-8k model in generating
    legal judgment dialogues'
  prefs: []
  type: TYPE_NORMAL
- en: Judicial Interpretation dialogue
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We obtained 1,000 judicial interpretations from the official website of the
    Supreme People’s Court of China, covering various laws and categories. Utilizing
    the official API of Moonshot AI, we employed the moonshot-v1-128k large language
    model to generate and refine 4,382 high-quality judicial interpretation dialogues
    based on these interpretations, with human experts conducting the screening. To
    ensure the diversity and professionalism of the question-answer data, multiple
    sets of question-answer dialogues were constructed for each judicial interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario-based Q&A Dialogue with Legal Grounds
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The scenario-based Q&A data with legal references was generated by (Zhou et al.
    [2024](#bib.bib31)) using ChatGPT, based on the most essential 9,000 legal provisions
    from the Chinese Legal Handbook. The original dataset comprised 92,000 dialogue
    samples. We invited human experts to manually screen these samples, resulting
    in a final collection of 3,026 high-quality scenario-based Q&A pairs.
  prefs: []
  type: TYPE_NORMAL
- en: Single-round Legal Consultation Dialogue
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The single single-round legal consultation dialogues are derived from real legal
    consultation questions and relevant legal provisions collected by (Huang et al.
    [2023](#bib.bib5)). These inputs were processed through GPT-4 to generate single-turn
    legal consultation dialogues, resulting in a total of 1,000 dialogue samples.
    We invited human experts to further refine these dialogues, ultimately yielding
    995 high-quality dialogue samples.
  prefs: []
  type: TYPE_NORMAL
- en: Judicial Examination Dialogue
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The judicial examination dialogue data was constructed by (Huang et al., 2023)
    based on the Chinese judicial examination dataset JEC-QA. They input the questions
    and answers from JEC-QA into ChatGPT, allowing the model to generate detailed
    explanations for each answer, ultimately resulting in 1,000 dialogue samples.
    We invited human experts to screen these dialogue data, and 985 high-quality dialogue
    samples were obtained.
  prefs: []
  type: TYPE_NORMAL
- en: B. Sample Consulting Report
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figure [12](#A1.F12 "Figure 12 ‣ B. Sample Consulting Report ‣ Appendix A Appendix
    ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents") is a sample consultation report,
    serving as a demonstration for ICL. This consultation report comprises nine sections:
    report number, consultation date, client, subject of consultation, purpose of
    consultation, facts and background, legal analysis, legal advice, and risk warnings.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/25a4859de7757fa92c8e1b0f553c83d5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: A sample consulting report for in-context learning'
  prefs: []
  type: TYPE_NORMAL
- en: C. Prompt Template for Guiding GPT-4o in Scoring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figure [13](#A1.F13 "Figure 13 ‣ C. Prompt Template for Guiding GPT-4o in Scoring
    ‣ Appendix A Appendix ‣ LawLuo: A Chinese Law Firm Co-run by LLM Agents") is a
    prompt template for guiding GPT-4o in scoring.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7f69efb8a364ebc49330a3240aee310d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Prompt template for guiding GPT-4o in scoring'
  prefs: []
  type: TYPE_NORMAL
- en: D. Case Study of ToLC
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| w/ ToLD | 首先，收集对方出轨的证据，这可能包括通信记录、照片或证人证言等。接着，对你们的共同财务状况进行彻底审计，明确债务的性质、金额和责任分配。尝试与对方协商离婚条件，包括财产分割和债务处理，如果协商失败，准备必要的法律文件，如离婚申请书和财产清单，并向法院提交离婚申请。如果对方不同意离婚，法院可能会介入调解，调解失败则进入正式的法庭程序。在法庭审理中，法官会根据法律规定和你们的具体情况，决定财产和债务的分割方式。一旦法院作出离婚判决，遵守判决内容，处理财产分割和债务偿还等后续事宜。在整个过程中，保持冷静和理智，避免情绪化决策，并确保在专业法律人士的帮助下保护自己的权益。
    (First, gather evidence of the partner’s infidelity, which may include communication
    records, photos, or witness testimonies. Then, conduct a thorough audit of your
    joint financial situation to clarify the nature, amount, and allocation of debts.
    Attempt to negotiate divorce terms with the partner, including property division
    and debt handling. If negotiations fail, prepare the necessary legal documents,
    such as the divorce petition and property inventory, and file for divorce in court.
    If the partner disagrees with the divorce, the court may intervene for mediation.
    If mediation fails, the case will proceed to a formal court hearing. During the
    trial, the judge will decide the division of property and debts based on legal
    provisions and your specific circumstances. Once the court issues a divorce decree,
    comply with the decree’s contents and handle subsequent matters such as property
    division and debt repayment. Throughout the process, remain calm and rational,
    avoid emotional decisions, and ensure the protection of your rights with the help
    of professional legal experts.) |'
  prefs: []
  type: TYPE_TB
- en: '| w/o ToLD | 离婚是一个重要的决定，涉及到情感、法律和财务等多个方面。以下是一些基本步骤，但请注意，具体情况可能因地区和个人情况而异，最好咨询专业的法律顾问：沟通与协商：首先尝试与配偶进行沟通，看是否能够就离婚达成共识，包括财产分割、子女抚养等问题。咨询律师：在正式提出离婚前，咨询专业的离婚律师，了解你所在地区的具体法律规定和程序。准备文件：根据律师的建议，准备必要的文件，如离婚协议书、财产清单等。提交申请：向法院或相关部门提交离婚申请，并按照要求提供相应的证据和文件。等待审理：法院将对离婚申请进行审理，可能包括调解程序。财产分割和子女抚养：根据法院的判决或双方的协议，进行财产分割和确定子女的抚养权。离婚证明：一旦离婚判决生效，你将获得离婚证明。后续调整：离婚后可能需要进行一些后续的调整，如更改个人文件、处理财务事务等。(Getting
    a divorce is an important decision involving multiple aspects such as emotions,
    legalities, and finances. The following are some basic steps, but please note
    that the specifics may vary depending on the region and individual circumstances.
    It is best to consult a professional legal advisor: 1\. Communication and negotiation:
    First, try to communicate with your spouse to see if a consensus on divorce can
    be reached, including issues like property division and child custody. 2\. Consult
    a lawyer: Before formally filing for divorce, consult a professional divorce lawyer
    to understand the specific legal regulations and procedures in your area. 3\.
    Prepare documents: According to the lawyer’s advice, prepare the necessary documents,
    such as a divorce agreement and a property list. 4\. Submit the application: Submit
    the divorce application to the court or relevant department, and provide the required
    evidence and documents as requested. 5\. Wait for the hearing: The court will
    review the divorce application, which may include mediation procedures. 6\. Property
    division and child custody: Based on the court’s judgment or the agreement between
    the parties, proceed with the property division and determine child custody. 7\.
    Divorce certificate: Once the divorce decree takes effect, you will receive a
    divorce certificate. 8\. Post-divorce adjustments: After the divorce, some follow-up
    adjustments may be needed, such as updating personal documents and handling financial
    matters.) |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: The first row presents the answer generated by LawLuo with (w/) ToLD,
    while the second row presents the answer generated by LawLuo without (w/o) ToLD.'
  prefs: []
  type: TYPE_NORMAL
