- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:38:41'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale
    LLM Agent Systems'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.09955](https://ar5iv.labs.arxiv.org/html/2408.09955)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Qian Wang\equalcontrib¹, Tianyu Wang\equalcontrib², Qinbin Li³, Jingsheng Liang⁴,
    Bingsheng He¹
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: With the emergence of large language models (LLMs), LLM-powered multi-agent
    systems (LLM-MA systems) have been proposed to tackle real-world tasks. However,
    their agents mostly follow predefined Standard Operating Procedures (SOPs) that
    remain unchanged across the whole interaction, lacking autonomy and scalability.
    Additionally, current solutions often overlook the necessity for effective agent
    cooperation. To address the above limitations, we propose MegaAgent, a practical
    framework designed for autonomous cooperation in large-scale LLM Agent systems.
    MegaAgent leverages the autonomy of agents to dynamically generate agents based
    on task requirements, incorporating features such as automatically dividing tasks,
    systematic planning and monitoring of agent activities, and managing concurrent
    operations. In addition, MegaAgent is designed with a hierarchical structure and
    employs system-level parallelism to enhance performance and boost communication.
    We demonstrate the effectiveness of MegaAgent through Gobang game development,
    showing that it outperforms popular LLM-MA systems; and national policy simulation,
    demonstrating its high autonomy and potential to rapidly scale up to 590 agents
    while ensuring effective cooperation among them. Our results indicate that MegaAgent
    is the first autonomous large-scale LLM-MA system with no pre-defined SOPs, high
    effectiveness and scalability, paving the way for further research in this field.
    Our code is at https://anonymous.4open.science/r/MegaAgent-81F3.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given the impressive planning and cognitive abilities of LLMs (Touvron et al.
    [2023](#bib.bib25); Zhu et al. [2023](#bib.bib34)), there is growing interest
    research interest in LLM-MA systems (Wu et al. [2023](#bib.bib28); Chen et al.
    [2023b](#bib.bib6); Hong et al. [2023](#bib.bib11)) due to their abilities to
    tackle complex tasks. For instance, MetaGPT introduces a meta-programming framework
    that effectively simulates the software development process (Hong et al. [2023](#bib.bib11)).
    Furthermore, recent works leverage LLMs’ cognitive abilities to simulate more
    complex scenarios, known as world simulations (Guo et al. [2024](#bib.bib9)).
    For example, Simulacra (Park et al. [2023](#bib.bib21)) simulates social behaviors
    among 25 LLM-empowered agents living in a town where each agent can plan and schedule
    what to do in the daily life.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, real-world simulations require far more than 25 LLM agents. For example,
    S3 utilizes LLM-empowered agents to simulate 26,058 users in a social network,
    enabling the analysis of opinions on gender discrimination (Gao et al. [2023](#bib.bib7)).
    Moreover, certain complex world simulation scenarios, such as policy-making (Tesfatsion
    [2023](#bib.bib24)), war simulation (Hua et al. [2023](#bib.bib12)), and alien
    civilizations simulation (Jin et al. [2024](#bib.bib14)), can only be realistically
    simulated using a large number of LLM agents. As reliance on large-scale LLM-MA
    systems continues to grow, there is an urgent need for scalable, autonomous frameworks
    that can handle large-scale agent interactions.
  prefs: []
  type: TYPE_NORMAL
- en: However, the majority of current LLM-MA frameworks primarily emphasize the AI
    aspects while neglecting the crucial infrastructure needed to support large-scale
    cooperation among LLM agents. This oversight leads to three significant limitations.
    First, they do not consider the management of large-scale agents (Hong et al.
    [2023](#bib.bib11); Chen et al. [2023b](#bib.bib6)). Second, these systems demonstrate
    limited cooperation, thus hinders their effectiveness and applicability in solving
    multi-disciplinary complex tasks (Chan et al. [2024](#bib.bib3); Chen et al. [2023b](#bib.bib6);
    Wu et al. [2023](#bib.bib28); Pan et al. [2024](#bib.bib20)). Third, they rely
    on predefined SOPs and prompts to dictate how agents respond to specific situations
    or inputs (Hong et al. [2023](#bib.bib11)). This approach not only stifles creativity
    but also becomes impractical when implementing SOPs for hundreds or even thousands
    of agents.
  prefs: []
  type: TYPE_NORMAL
- en: Addressing the above limitations presents two key challenges. First, organizing
    communication among agents and with external services, such as code and text files,
    becomes increasingly complex on a large scale with parallelism included, especially
    when different agents are involved in different rounds of communication (Zhang
    et al. [2024a](#bib.bib32)). Second, currently existing agents have inadequate
    autonomic capabilities. Manually crafting predefined SOPs becomes impractical
    at large scales, and the inherent instability of LLM agent outputs (Lu et al.
    [2023](#bib.bib18)) necessitates maintaining a degree of control over each agent’s
    actions while still allowing for flexibility and creativity. Therefore, ensuring
    sufficient agent autonomy is crucial for problems at larger scales.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address these limitations, we propose MegaAgent, a practical framework designed
    to manage large-scale LLM-MA systems and facilitate effective, autonomous agent
    communication. We anticipate that MegaAgent will serve as the foundational infrastructure
    for future large-scale LLM-MA systems, effectively functioning as the operating
    system (OS) for LLM-MA. The core idea of MegaAgent is to divide the large task
    into multiple hierarchical sub-tasks, and each sub-task is finished by a group
    of agents. Communications can be done either within the agent group or between
    agent groups. The overview of MegaAgent is in Figure [1](#Sx1.F1 "Figure 1 ‣ Introduction
    ‣ MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM
    Agent Systems").'
  prefs: []
  type: TYPE_NORMAL
- en: 'To address the first challenge, we introduce a hierarchical mechanism: a boss
    agent receives the prompt, divides the task into sub-tasks, and assigns each sub-task
    to a corresponding sub-task admin. The admin agent then generates a group of agents
    to complete the task. If an agent cannot complete the task on its own, it can
    generate another group of agents at the next level. Each agent group run in parallel
    to ensure the high effectiveness.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To address the second challenge, we implement three mechanisms: First, the
    OS agent is employed to monitor the agent groups’ output to ensure they chat in
    the right format; second, the admin agent in each group monitors the status of
    individual agents inside this group; third, each agent maintains a checklist to
    track its actions. The workflow of MegaAgent is as follows: First, it accepts
    natural language prompts from users; then, it splits the tasks into multiple sub-tasks,
    each completed by a group of agents monitored by admin agents. At the same time,
    the OS agent monitors the progress of each agent group. These groups interact
    with external services through a data retriever, where they retrieve databases,
    code files, and checklists for each agent.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/37f5d732627f22add442e96d729da1ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: MegaAgent starts by accepting prompts, which it automatically divides
    into tasks for multiple agent groups. OS Agent monitors the agents’ progress,
    while the action module interacts with the storage module through a data retriever.'
  prefs: []
  type: TYPE_NORMAL
- en: We then conduct two experiments to demonstrate the effectiveness and autonomy
    of MegaAgent. The first experiment, a Gobang game against an AI opponent, highlights
    MegaAgent’s superior autonomy and efficiency over all previous baselines, with
    MegaAgent being the only model to complete the task within 800 seconds. The second
    experiment, an industry-wide national policy simulation, demonstrates MegaAgent’s
    large-scale autonomy and scalability by successfully generating and coordinating
    about 590 agents to produce the expected policies within 3000 seconds. In stark
    contrast, the baseline models can coordinate fewer than 10 agents and fail to
    produce the expected policies. Finally, we provide insights gained from these
    experiments and discuss future research directions for managing scaling to larger
    numbers of LLM-MA systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, our contributions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We propose MegaAgent, a practical framework designed for autonomous cooperation
    in large-scale LLM-MA systems, enabling dynamic task splitting and parallel communication
    among LLM agents.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We validate MegaAgent’s effectiveness through experiments in Gobang game development
    and national policy simulation, demonstrating its autonomy and scalability.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We provide insights into the challenges and potential future research directions
    for scaling LLM-MA systems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The remainder of this paper is organized as follows: Section 2 reviews related
    work in LLM-MA systems. Section 3 provides details of the MegaAgent framework.
    Section 4 presents two experiments that demonstrate MegaAgent’s practicality.
    Section 5 discusses future research directions for LLM-MA systems, and Section
    6 concludes the paper.'
  prefs: []
  type: TYPE_NORMAL
- en: Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we review LLM-MA systems and the cooperation between agents
    within these systems. Due to space constraints, we only include the most relevant
    work here, with additional related work provided in the appendix.
  prefs: []
  type: TYPE_NORMAL
- en: LLM-MA Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the emergence of powerful LLMs (Achiam et al. [2023](#bib.bib1); Team et al.
    [2023](#bib.bib23)), recent research on LLM-based multi-agent systems has investigated
    how multiple agents can accomplish tasks through cooperation, utilizing elements
    such as personas (Chen et al. [2024](#bib.bib4); Chan et al. [2024](#bib.bib3)),
    planning (Chen et al. [2023a](#bib.bib5); Zhang et al. [2024b](#bib.bib33); Yuan
    et al. [2023](#bib.bib30)), and memory (Zhang et al. [2023](#bib.bib31); Hatalis
    et al. [2023](#bib.bib10)). Unlike systems relying on a single LLM-based agent,
    multi-agent systems demonstrate superiority in tackling challenging tasks. Recent
    works, such as MetaGPT (Hong et al. [2023](#bib.bib11)), AutoGen (Wu et al. [2023](#bib.bib28)),
    and AgentVerse (Chen et al. [2023b](#bib.bib6)), design multiple specific roles
    to achieve a task.
  prefs: []
  type: TYPE_NORMAL
- en: However, most popular LLM-MA systems heavily rely on handcrafted prompts and
    expert design. For instance, MetaGPT (Hong et al. [2023](#bib.bib11)) requires
    users to pre-design roles like product manager and software engineer. Another
    limitation is these systems utilize a sequential pipeline without considering
    parallel execution of agents (Li et al. [2023](#bib.bib15)). Although AgentScope
    (Pan et al. [2024](#bib.bib20)) does consider this, its implementation follows
    a fixed trajectory in different rounds of interaction, prohibiting changes in
    communication partners, thus limiting performance improvement as the number of
    agents scales up.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, in the real world, when many software developers are employed,
    they may first work on different files simultaneously, and then focus on one specific
    file when difficulties are encountered, sparking creative ideas to overcome challenges
    by cooperation. Additionally, existing LLM-MA systems are restricted by their
    small scale and have not been applied in large-scale scenarios with complex cooperation
    involved. We compare current popular LLM-MA systems with MegaAgent in Table [1](#Sx2.T1
    "Table 1 ‣ LLM-MA Systems ‣ Related Work ‣ MegaAgent: A Practical Framework for
    Autonomous Cooperation in Large-Scale LLM Agent Systems"). We can see from the
    table that MegaAgent stands out for its high autonomy, multi-file support, parallelism,
    and scalability.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | No Predefined SOP | Multi-file Support | Parallelism | Scalability
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AutoGen (Wu et al. [2023](#bib.bib28)) | ✗ | ✗ | ✗ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| MetaGPT (Hong et al. [2023](#bib.bib11)) | ✗ | ✓ | ✗ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| CAMEL (Li et al. [2023](#bib.bib15)) | ✗ | ✗ | ✗ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| AgentVerse (Chen et al. [2023b](#bib.bib6)) | ✓ | ✗ | ✗ | ✗ |'
  prefs: []
  type: TYPE_TB
- en: '| MegaAgent | ✓ | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Comparison of Popular LLM-MA Systems with MegaAgent'
  prefs: []
  type: TYPE_NORMAL
- en: Cooperation between LLM-based Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The coordination between LLM-based agents is critical infrastructure for supporting
    LLM-MA systems (Guo et al. [2024](#bib.bib9)). There are three main coordination
    paradigms: cooperative, debate, and competitive. MegaAgent focuses on the cooperation
    paradigm, aiming to have agents work together toward a shared goal. Within the
    cooperative paradigm are three main structures: layered, decentralized, and centralized.
    Layered communication is organized hierarchically, with agents at each level having
    distinct roles and each layer interacting with adjacent layers (Liu et al. [2023b](#bib.bib17)).
    Decentralized communication operates on a peer-to-peer basis among agents. Centralized
    communication involves a central agent or a group of central agents coordinating
    the system’s communication, with other agents primarily connecting to the central
    agent. A shared message pool, as proposed in MetaGPT (Hong et al. [2023](#bib.bib11)),
    maintains a shared message pool where agents publish and subscribe to relevant
    messages, boosting communication efficiency.'
  prefs: []
  type: TYPE_NORMAL
- en: MegaAgent Framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As illustrated in Figure [1](#Sx1.F1 "Figure 1 ‣ Introduction ‣ MegaAgent:
    A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems"),
    MegaAgent consists of five key components: (1) Multi-Level Task Splitting, which
    accepts the prompt and divides the task into several agent groups for completion;
    (2) Action Module, composed of multiple agent groups, each responsible for completing
    a specific subtask; (3) Storage Module, composed of database, files, and checklists;
    (4) Monitor Mechanism, which includes OS agent, admin agent, and each agent’s
    checklist to monitor agents’ actions; and (5) Communication Mechanism including
    the communication between agents and between agents and external services. We
    now discuss each component in detail.'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Level Task Splitting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To address the impossibility of predefined SOPs in large-scale LLM-MA systems,
    we creatively assign the boss agent to perform task splitting. To ensure each
    subtask is completed correctly, we creatively designate an admin agent for each
    group to oversee the group’s progress. The boss agent assigns the big task into
    several admin agents where each admin is in charge of a sub-task. Each admin has
    a name representing its role, formatted as the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: <employee name=”MinisterHealth”>You are MinisterHealth, the Health Policy Minister
    of the Health Department. Your job is to develop a comprehensive health policy
    document (’policy_health.txt’) according to … You will collaborate with …(omitted
    here) </employee>
  prefs: []
  type: TYPE_NORMAL
- en: Admin agents can either work independently or recruit other agents to form a
    group. Recruited agents can further decompose sub-tasks into smaller tasks, assume
    the role of an admin agent, recruit additional agents, and form new subordinate
    groups. When agents determine that a task needs further subdivision but cannot
    complete it independently, they create a new level and generate more agents to
    address this need. This process is done iteratively and implemented through function
    calls. We choose a hierarchical design as it allows tasks to be efficiently distributed
    and managed across different levels, ensuring that as the MegaAgent grows, it
    can handle increasing complexity without overwhelming a central agent. This multi-level
    task splitting makes the MegaAgent both practical and autonomous, particularly
    when handling complex tasks that require numerous LLM agents.
  prefs: []
  type: TYPE_NORMAL
- en: Action Module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To execute a sub-task, each agent group admin divides the task into smaller
    components and generates several agents to complete them. Each agent then creates
    a checklist based on its assigned task. Throughout the task completion process,
    agents communicate and coordinate their work within the group, updating and completing
    their checklists until the boss agent marks the task as ’finished.’ Meanwhile,
    the OS agent ensures proper input and output formats and serializes the API message
    calls of individual agents. This allows multiple agents to work on the same task
    without compromising data consistency and enhances development efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'To support this process, we introduce a data retriever as an interface between
    action module and storage module. A data retriever manages function calls—including
    file reading and writing, checklists, and Python execution—and relays them to
    the storage module. The list of available function calls is provided to the data
    retriever agents at the beginning. Then, The data retrievers determine which function
    calls to generate and execute based on the specific needs of the agents, ensuring
    the system operates automatically.This process is illustrated in Figure [1](#Sx1.F1
    "Figure 1 ‣ Introduction ‣ MegaAgent: A Practical Framework for Autonomous Cooperation
    in Large-Scale LLM Agent Systems").'
  prefs: []
  type: TYPE_NORMAL
- en: Building on the previously established process, the action module ensures scalability
    by allowing each agent group to operate simultaneously and independently. This
    parallel execution capability significantly reduces the overall task completion
    time compared to the linear operating mechanisms used in other baselines, such
    as MetaGPT (Hong et al. [2023](#bib.bib11)).
  prefs: []
  type: TYPE_NORMAL
- en: Storage Module
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To facilitate data communication between the LLM agents and external files,
    we introduce a storage module. This storage module includes agent execution logs,
    a memory database, a task monitor, Python code and interactive Python execution
    support, files, and checklists for each agent.
  prefs: []
  type: TYPE_NORMAL
- en: We introduce Git to support file management in storage module. As each agent
    requires considerable time to edit a file after reading it, during which the file
    may change, a mechanism to keep data consistency is required. When an agent reads
    a file, it also retrieves its Git commit hash. Upon writing, the agent must provide
    that hash to the file agent, which commits the changes to the previous commit,
    merges them to the latest HEAD, and requests the agent to resolve any merge conflicts
    if necessary. All Git operations are serialized using a global mutex lock.
  prefs: []
  type: TYPE_NORMAL
- en: The memory database is used for long-term memory summarization as LLMs would
    forget prior conversations. The output of each round is encoded using language
    models into embeddings to be stored in the vector database, so that the agent
    can fetch the most similar message into its memory by cosine similarity metric.
    Therefore, agents fetch the checklist and the prior summarization to dynamically
    track and update their progress at each step.
  prefs: []
  type: TYPE_NORMAL
- en: The task monitor is designed to verify the existence of output files, report
    their content to the supervising agent, and, if necessary, assign rework to the
    subordinate agent. Additionally, when there are no active tasks, the task monitor
    prompts the OS agent to review all generated files and determine the next steps
    or, if appropriate, terminate the process. The task monitor acts as a safeguard,
    ensuring the task progresses gradually and consistently.
  prefs: []
  type: TYPE_NORMAL
- en: Monitor Mechanism
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To ensure effective monitoring and minimize hallucination propagation in a large-scale
    LLM-MA system, we introduce OS agent to oversee the output format of each agent
    group and verify whether the output meets the expected standards. If not, an error
    message is added to the agent’s memory and the OS system tries to generate again.
    In addition, each agent maintains an updated checklist to track its actions and
    ensure they align with expectations. Once the work within an agent group is completed,
    the admin agent reviews each agent’s checklist and results to confirm full completion.
    If the results are unexpected, the OS agent would return an error message explaining
    the discrepancies, prompting the agent to retry. However, each agent has a maximum
    number of allowed retries per round, a hyperparameter we have set to thirty.
  prefs: []
  type: TYPE_NORMAL
- en: Communication Mechanism
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To ensure effective communication, agents are organized into distinct hierarchies.
    They can communicate only with their direct superiors, their direct subordinates,
    within their own group. File operation and code execution are also regarded as
    communication. Their communication format is specified in a instructional paragraph,
    which is detailed in our source code. It enables agents to simultaneously dispatch
    distinct messages through function call in a specified format. The complete communication
    patterns are provided in the appendix. Here, we present an example:'
  prefs: []
  type: TYPE_NORMAL
- en: <talk_goal=“Carol”>  Carol, please provide ‘ai.py’ once you have developed the
    AI for the Gobang game.</talk>
  prefs: []
  type: TYPE_NORMAL
- en: <talk_goal=“David”>  David, please provide ‘game_logic.py’ once you have developed
    the game logic for the Gobang game.</talk>
  prefs: []
  type: TYPE_NORMAL
- en: The OS agent then delivers these messages to the designated agents, who respond
    in parallel to ensure both effectiveness and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we aim to evaluate MegaAgent’s capabilities by addressing
    the following two research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'RQ1: Can MegaAgent complete a task requiring extensive cooperation without
    a predefined SOP? How do other baselines compare?'
  prefs: []
  type: TYPE_NORMAL
- en: 'RQ2: Can MegaAgent be applied to a more complex task requiring significantly
    more agents, demonstrating its scalability? How about other baselines?'
  prefs: []
  type: TYPE_NORMAL
- en: Gobang Game with AI Opponent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Gobang is a strategic board game played between two participants, who alternate
    placing black and white pieces on a grid. The objective is to be the first to
    align five consecutive pieces horizontally, vertically, or diagonally ¹¹1https://en.wikipedia.org/wiki/Gomoku.
    We conduct this experiment to evaluate MegaAgent’s cooperation, autonomy, and
    parallelism in completing the development of this game without predefined SOPs.
  prefs: []
  type: TYPE_NORMAL
- en: Experiment Setup
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We conduct this experiment with the GPT-4o API ²²2https://openai.com/index/hello-gpt-4o/,
    setting the ‘temperature’ parameter to $0$ to ensure more deterministic responses
    (Achiam et al. [2023](#bib.bib1)). At the beginning, we feed the meta prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: You are Bob, the leader of a software development club. Your club’s current
    goal is to develop a Gobang game with an AI, and can be executed by running ’main.py’.
  prefs: []
  type: TYPE_NORMAL
- en: For comparative analysis, we utilize AutoGen, MetaGPT, CAMEL, and AgentVerse
    to perform the same task. We manually adapt their underlying large language models
    to GPT-4o or to GPT-4 ³³3https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4
    when GPT-4o is incompatible with their code settings. Details of the those API
    costs of each model can be found in the appendix.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure fairness in our experiment, we use exactly the same prompt: Develop
    a Gobang game with an AI for all baselines, as well as following the guidelines
    specified in each baseline’s paper to determine the appropriate testing methods.
    The full experiment settings of these baselines are in our appendix due to the
    space limit.'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Metrics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To evaluate the generated Gobang game, we establish the following evaluation
    metrics: (1) error-free execution, which assesses the program’s ability to run
    without errors; (2) user move functionality, which evaluates the user’s ability
    to make a move; (3) AI move functionality, which measures the AI’s ability to
    make a move; and (4) correct game termination, which ensures the game’s ability
    to end correctly when there are five consecutive pieces.'
  prefs: []
  type: TYPE_NORMAL
- en: Experiment Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Model | Completed Metrics | Number of Agents | Time |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AutoGen (Wu et al. [2023](#bib.bib28)) | (1) (2) | 2 | 120s |'
  prefs: []
  type: TYPE_TB
- en: '| MetaGPT (Hong et al. [2023](#bib.bib11)) | (1) (2) | 6 | 480s |'
  prefs: []
  type: TYPE_TB
- en: '| CAMEL (Li et al. [2023](#bib.bib15)) | Program not executable | 2 | 1830s
    |'
  prefs: []
  type: TYPE_TB
- en: '| AgentVerse (Chen et al. [2023b](#bib.bib6)) | Incomplete program | 4 | 1980s*
    |'
  prefs: []
  type: TYPE_TB
- en: '| MegaAgent | (1) (2) (3) (4) | 7 | 800s |'
  prefs: []
  type: TYPE_TB
- en: '*We allowed AgentVerse to run for 10 rounds, but it was still unable to complete
    the program after 1,980 seconds.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Gobang Experiment Results'
  prefs: []
  type: TYPE_NORMAL
- en: 'To provide a comprehensive comparison, Table [2](#Sx4.T2 "Table 2 ‣ Experiment
    Results ‣ Gobang Game with AI Opponent ‣ Experiments ‣ MegaAgent: A Practical
    Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems") presents
    performance of various state-of-the-art models for large-scale LLM multi-agents.
    We analyze each of them individually as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoGen: AutoGen uses two agents to produces an mini-max AI with no prone,
    which takes infinite time to think, and will never produce a move. In another
    trial, AutoGen generates a program ending with # To be continued.. after about
    two minutes, and gets stuck when trying to execute it. The possible reason for
    its failure is that its SOP is too simple, and does not include enough communication
    (like code review) between agents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'MetaGPT: None of the trials are able to produce an AI move, even after generating
    six agents. The major errors are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code is not executable, and raises an error. The possible reason is that
    MetaGPT does not have external tools to execute and debug the produced code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The produced program is not a Gobang game (for example, a tic-tac-toe game instead).
    The possible reason for failure is that its SOP is too simple, and the requirement
    for communication between agents is not sufficient.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI falls into an infinite loop. The possible reason is that MetaGPT does not
    have external tools to execute and debug the produced code, and the current ChatGPT
    API is not capable of developing the AlphaBeta algorithm without errors by itself.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1afb85462495578e032b42d5b8aacd6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: CAMEL fails to generate the needed files that are required in its
    planning stage.'
  prefs: []
  type: TYPE_NORMAL
- en: 'CAMEL: We find that CAMEL can only produce code segments using two agents.
    For example, as shown in Figure [2](#Sx4.F2 "Figure 2 ‣ Experiment Results ‣ Gobang
    Game with AI Opponent ‣ Experiments ‣ MegaAgent: A Practical Framework for Autonomous
    Cooperation in Large-Scale LLM Agent Systems"), CAMEL forgets to write ui.py,
    which is included in game.py. The possible reason for this is that its planning
    and contextual ability is weak.'
  prefs: []
  type: TYPE_NORMAL
- en: 'AgentVerse: AgentVerse generates four agents to finish this task. However,
    we find that, in the first and second trial, the agent keeps rejecting the result
    for all the ten rounds; as for the third trial, although the agent accepts the
    result, the code still presents many placeholders, and cannot be executed. An
    incomplete code blocks may look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The possible failing reason for AgentVerse is that the outline from its planning
    state is too strict, while current LLMs are unable to meet that demand.
  prefs: []
  type: TYPE_NORMAL
- en: 'MegaAgent: The MegaAgent system autonomously devises an SOP integrating seven
    agents, leading to the successful execution of the designated task. It autonomously
    develops a functional Gobang game interfaced with a naive AI, capable of:'
  prefs: []
  type: TYPE_NORMAL
- en: i.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Allowing player input for row and column selections to execute moves.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ii.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enabling AI to respond with its move on the board.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: iii.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeating this interaction until a player aligns five consecutive pieces.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These functionalities fulfill criteria (1) through (4) of our requirements.
    MegaAgent’s ability to produce a fully operational game itself is an unprecedented
    achievement compared to the above LLM-MA systems, whose result either consists
    of unfinished placeholders, or fails to include an AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, MegaAgent successfully produces a runnable Gobang game with a naive
    AI, whose interface is shown in Figure [5](#A1.F5 "Figure 5 ‣ Results ‣ Gobang
    Game Experiment Setup and Result ‣ Appendix A Appendix ‣ MegaAgent: A Practical
    Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems"). The complete
    log and program of this experiment can be found in our source code.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d20fcfb69a7a0f0ebfd7f4148669986d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Interface of MegaAgent’s Gobang Demo'
  prefs: []
  type: TYPE_NORMAL
- en: Ablation Study
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To validate the effectiveness of the parallel design in MegaAgent, we conduct
    an ablation study by running MegaAgent without parallel mechanism of each agent
    group, and we present the results in Table [3](#Sx4.T3 "Table 3 ‣ Ablation Study
    ‣ Gobang Game with AI Opponent ‣ Experiments ‣ MegaAgent: A Practical Framework
    for Autonomous Cooperation in Large-Scale LLM Agent Systems").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Mechanism | Completed Metrics | Number of Agents | Time |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| w/o parallelism | (1) (2) (3) (4) | 7 | 4505s |'
  prefs: []
  type: TYPE_TB
- en: '| with parallelism | (1) (2) (3) (4) | 7 | 800s |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Gobang Ablation Study Results'
  prefs: []
  type: TYPE_NORMAL
- en: When MegaAgent operates without parallel execution, it takes 4505 seconds to
    complete the task using 7 agents. In contrast, with parallelism enabled, the same
    task is completed in just 800 seconds. Both configurations successfully achieve
    all the specified metrics, but the drastic reduction in time highlights the efficiency
    of the parallel design.
  prefs: []
  type: TYPE_NORMAL
- en: Industry-Wise Nation Policy Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We propose a more challenging experiment: formulating industry-specific national
    policies, which requires numerous agents performing various tasks across complex
    domains such as education, health, and finance. This experiment can evaluate the
    autonomy, scalability, and cooperation capabilities of MegaAgent.'
  prefs: []
  type: TYPE_NORMAL
- en: Experiment Setup
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Due to budget constraints, we use the GPT-4o-mini API⁴⁴4https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/
    for this experiment by MegaAgent. For comparative analysis, we utilize AutoGen,
    MetaGPT, CAMEL, and AgentVerse to perform the same task. Details of API costs
    are in the appendix. We manually adapt their underlying large language models
    to GPT-4o or to GPT-4 when GPT-4o is incompatible with their code settings. The
    prompt we feed into these frameworks are:'
  prefs: []
  type: TYPE_NORMAL
- en: You are NationLeader, the leader of a pioneering nation. You want to develop
    the best detailed policy for your cutting-edge country in ’policy_department.txt’.
    You are now recruiting ministers and assigning work to them. For each possible
    minister, please write a prompt. ……
  prefs: []
  type: TYPE_NORMAL
- en: The full prompt is in the appendix due to the space limit.
  prefs: []
  type: TYPE_NORMAL
- en: Experiment Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We present the results in Table [4](#Sx4.T4 "Table 4 ‣ Experiment Results ‣
    Industry-Wise Nation Policy Simulation ‣ Experiments ‣ MegaAgent: A Practical
    Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Outputs | Number of Agents | Time |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AutoGen (Wu et al. [2023](#bib.bib28)) | Outline | 1 | 40s |'
  prefs: []
  type: TYPE_TB
- en: '| MetaGPT (Hong et al. [2023](#bib.bib11)) | Python Program | 6 | 580s |'
  prefs: []
  type: TYPE_TB
- en: '| CAMEL (Li et al. [2023](#bib.bib15)) | Plans | 2 | 1380s |'
  prefs: []
  type: TYPE_TB
- en: '| AgentVerse (Chen et al. [2023b](#bib.bib6)) | None | 4 | 510s |'
  prefs: []
  type: TYPE_TB
- en: '| MegaAgent | Complete Policies | 590 | 2991s |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Industry-Wise Nation Policy Simulation Results. The result is for
    a single test, and may vary as LLM’s output is unstable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoGen: It produces merely an outline for each aspect and responses in a single
    output without amendment. This trial takes about 40 seconds and includes only
    a single agent.'
  prefs: []
  type: TYPE_NORMAL
- en: 'MetaGPT: It takes 580 seconds and seven agents to produce a Python program,
    which is not what we need.'
  prefs: []
  type: TYPE_NORMAL
- en: 'CAMEL: It takes 1380 seconds and uses only two agents in this trial. It takes
    lots of time to provide a plan, overall strategy, implementation methods, and
    potential risks, which is not what we want.'
  prefs: []
  type: TYPE_NORMAL
- en: 'AgentVerse: After 510 seconds, AgentVerse consistently rejects the solution
    across all ten rounds and is unable to provide a viable policy with four agents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'MegaAgent: MegaAgent successfully recruits nine minister agents by the boss
    agent, each responsible for different sectors such as health (“MinisterHealth”).
    Each minister agent works simultaneously, drafts a policy, and recruits dozens
    of subordinate citizen testers to simulate and provide feedback. About 590 agents
    are involved in one experiment, forming a three-level hierarchy, as illustrated
    in Figure [4](#Sx4.F4 "Figure 4 ‣ Experiment Results ‣ Industry-Wise Nation Policy
    Simulation ‣ Experiments ‣ MegaAgent: A Practical Framework for Autonomous Cooperation
    in Large-Scale LLM Agent Systems"). MegaAgent completes this experiment in 2991
    seconds, even with 590 agents, demonstrating its high efficiency and scalability.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6ecd05b02a8438a006a787be5cb12416.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: An example of the generated hierarchy for the policy making experiment'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, MegaAgent presents a comprehensive policy addressing all seventeen
    ministries of the simulated nation, including detailed instructions and amendments,
    as follows: \dirtree.1 /project. .2 policy_health.txt. .3 feedback_health.txt.
    .2 policy_education.txt. .3 feedback_education.txt. .2 ….'
  prefs: []
  type: TYPE_NORMAL
- en: The complete version is in the appendix. The autonomy and scalability of MegaAgent
    are demonstrated by its ability to enable agents to communicate with different
    objectives across multiple rounds and recruit new agents as needed.
  prefs: []
  type: TYPE_NORMAL
- en: Ablation Study
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To validate the effectiveness of the parallel design in MegaAgent, we also
    conduct an ablation study by running this simulation without parallel mechanism,
    shown in Table [5](#Sx4.T5 "Table 5 ‣ Ablation Study ‣ Industry-Wise Nation Policy
    Simulation ‣ Experiments ‣ MegaAgent: A Practical Framework for Autonomous Cooperation
    in Large-Scale LLM Agent Systems").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Mechanism | Outputs | Number of Agents | Time |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| w/o parallelism | Incomplete Policies | >100 | >14400s |'
  prefs: []
  type: TYPE_TB
- en: '| with parallelism | Complete Policies | 590 | 2991s |'
  prefs: []
  type: TYPE_TB
- en: '*We terminate the execution without parallelism'
  prefs: []
  type: TYPE_NORMAL
- en: after 14400 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: Industry-Wise Nation Policy Simulation Ablation Study Results'
  prefs: []
  type: TYPE_NORMAL
- en: After 14400 seconds, the MegaAgent without parallelism design still can not
    finish the policies generation. It has generated more than 100 agents, and the
    admin agents in the first level are still recruiting agents and drafting plans.
    We find that in the single-threaded environment, admin agents recruited fewer
    subordinates and produced simpler policies with minimal testing. This is because
    they must serially execute multiple function calls to recruit multiple agents
    for a complete testing procedure, which current LLMs struggle to manage effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, this observation highlights a key limitation of current LLMs: their
    inefficiency in handling complex, serialized tasks. The performance of the non-parallelized
    MegaAgent demonstrates that parallelism is not just beneficial, but essential
    for LLM-based systems to manage complex tasks like comprehensive policy generation
    and evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: Scalability Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In MegaAgent, for $n$ as they run serially, which becomes impractical with the
    number of LLM agents increasing much. The above theoretical analysis is validated
    by industry-wide national policy simulation results, where MegaAgent completes
    the cooperation of 590 agents in just 2991 seconds, while the best-performing
    CAMEL requires 1380 seconds to complete the planning with only 2 agents. Thus,
    MegaAgent is a practical framework for autonomous cooperation within large-scale
    LLM-MA systems, offering the ability to scale effectively with an increasing number
    of LLM agents.
  prefs: []
  type: TYPE_NORMAL
- en: Research Directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mitigating hallucination. Occasional hallucinations have been observed in our
    experiments, such as the output format not meeting the specified requirements.
    To address this, MegaAgent maintains an updated checklist for each agent to monitor
    its actions and ensure adherence to format guidelines. However, the checklist
    is also generated by LLM which may be wrong. Recent works propose leveraging on
    an expert external knowledge base before (Peng et al. [2023](#bib.bib22)), during
    (Cao et al. [2023](#bib.bib2)) or after (Gao et al. [2022](#bib.bib8)) the generation
    of LLMs to guide the LLM’s outputs which may be a potential direction.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating different LLMs. In our experiments, we observe that the API costs
    for GPT-4 are quite high. Given that many LLMs cheaper than GPT-4 specialize in
    different domains, utilizing different LLMs for specific roles within the entire
    LLM-MA system could be an effective way to enhance efficiency while reducing costs
    (Touvron et al. [2023](#bib.bib25); Jiang et al. [2024](#bib.bib13); Yang et al.
    [2024](#bib.bib29)). Additionally, finding effective methods for data sharing
    between these LLMs presents a valuable research direction (Wu and Fard [2024](#bib.bib27)).
  prefs: []
  type: TYPE_NORMAL
- en: Increasing Effectiveness. The primary bottleneck in MegaAgent is the planning
    time and communication between LLM agents, specifically in translating code into
    prompts, managing checklists, maintaining the framework, and debugging. This issue
    is exacerbated as the number of communication rounds and agents increases, resulting
    in a significant number of input and output tokens throughout the process (Wang
    et al. [2024](#bib.bib26)). Previous research suggests using summarization compression
    and semantic compression to condense lengthy conversations from earlier rounds
    (Liu et al. [2023a](#bib.bib16)). In MegaAgent, we summarize previous conversations
    between agents and store them in an external vector database for efficient retrieval.
    Future work could further enhance communication efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We introduce MegaAgent, a practical framework designed for autonomous cooperation
    in large-scale LLM-MA systems. Through a Gobang game development experiment, we
    demonstrate MegaAgent’s superior autonomy and cooperation compared to baseline
    models. Additionally, we conduct a national policy simulation to highlight MegaAgent’s
    scalability. With its hierarchical and adaptive design, MegaAgent has the potential
    to serve as the foundational OS for future LLM-MA systems. Moreover, we identify
    key research directions emerging from the MegaAgent experiments, providing guidance
    for future research. We encourage the research community to focus on enhancing
    the effective cooperation of LLM agents to meet the growing demands of large-scale
    LLM-MA systems.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Achiam et al. (2023) Achiam, J.; Adler, S.; Agarwal, S.; Ahmad, L.; Akkaya,
    I.; Aleman, F. L.; Almeida, D.; Altenschmidt, J.; Altman, S.; Anadkat, S.; et al.
    2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cao et al. (2023) Cao, H.; An, Z.; Feng, J.; Xu, K.; Chen, L.; and Zhao, D.
    2023. A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question
    Decomposition with Large Language Models. *arXiv preprint arXiv:2311.07491*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chan et al. (2024) Chan, X.; Wang, X.; Yu, D.; Mi, H.; and Yu, D. 2024. Scaling
    Synthetic Data Creation with 1,000,000,000 Personas. *arXiv preprint arXiv:2406.20094*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2024) Chen, J.; Wang, X.; Xu, R.; Yuan, S.; Zhang, Y.; Shi, W.;
    Xie, J.; Li, S.; Yang, R.; Zhu, T.; et al. 2024. From persona to personalization:
    A survey on role-playing language agents. *arXiv preprint arXiv:2404.18231*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023a) Chen, J.; Yuan, S.; Ye, R.; Majumder, B. P.; and Richardson,
    K. 2023a. Put your money where your mouth is: Evaluating strategic planning and
    execution of llm agents in an auction arena. *arXiv preprint arXiv:2310.05746*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023b) Chen, W.; Su, Y.; Zuo, J.; Yang, C.; Yuan, C.; Qian, C.;
    Chan, C.-M.; Qin, Y.; Lu, Y.; Xie, R.; et al. 2023b. Agentverse: Facilitating
    multi-agent collaboration and exploring emergent behaviors in agents. *arXiv preprint
    arXiv:2308.10848*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2023) Gao, C.; Lan, X.; Lu, Z.; Mao, J.; Piao, J.; Wang, H.; Jin,
    D.; and Li, Y. 2023. S3: Social-network Simulation System with Large Language
    Model-Empowered Agents. *arXiv preprint arXiv:2307.14984*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2022) Gao, L.; Dai, Z.; Pasupat, P.; Chen, A.; Chaganty, A. T.;
    Fan, Y.; Zhao, V. Y.; Lao, N.; Lee, H.; Juan, D.-C.; et al. 2022. Rarr: Researching
    and revising what language models say, using language models. *arXiv preprint
    arXiv:2210.08726*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. (2024) Guo, T.; Chen, X.; Wang, Y.; Chang, R.; Pei, S.; Chawla,
    N. V.; Wiest, O.; and Zhang, X. 2024. Large language model based multi-agents:
    A survey of progress and challenges. *arXiv preprint arXiv:2402.01680*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hatalis et al. (2023) Hatalis, K.; Christou, D.; Myers, J.; Jones, S.; Lambert,
    K.; Amos-Binks, A.; Dannenhauer, Z.; and Dannenhauer, D. 2023. Memory Matters:
    The Need to Improve Long-Term Memory in LLM-Agents. In *Proceedings of the AAAI
    Symposium Series*, volume 2, 277–280.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2023) Hong, S.; Zheng, X.; Chen, J.; Cheng, Y.; Wang, J.; Zhang,
    C.; Wang, Z.; Yau, S. K. S.; Lin, Z.; Zhou, L.; et al. 2023. Metagpt: Meta programming
    for multi-agent collaborative framework. *arXiv preprint arXiv:2308.00352*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hua et al. (2023) Hua, W.; Fan, L.; Li, L.; Mei, K.; Ji, J.; Ge, Y.; Hemphill,
    L.; and Zhang, Y. 2023. War and peace (waragent): Large language model-based multi-agent
    simulation of world wars. *arXiv preprint arXiv:2311.17227*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2024) Jiang, A. Q.; Sablayrolles, A.; Roux, A.; Mensch, A.; Savary,
    B.; Bamford, C.; Chaplot, D. S.; Casas, D. d. l.; Hanna, E. B.; Bressand, F.;
    et al. 2024. Mixtral of experts. *arXiv preprint arXiv:2401.04088*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jin et al. (2024) Jin, M.; Wang, B.; Xue, Z.; Zhu, S.; Hua, W.; Tang, H.; Mei,
    K.; Du, M.; and Zhang, Y. 2024. What if LLMs Have Different World Views: Simulating
    Alien Civilizations with LLM-based Agents. *arXiv preprint arXiv:2402.13184*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023) Li, G.; Hammoud, H.; Itani, H.; Khizbullin, D.; and Ghanem,
    B. 2023. Camel: Communicative agents for” mind” exploration of large language
    model society. *Advances in Neural Information Processing Systems*, 36: 51991–52008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023a) Liu, J.; Li, L.; Xiang, T.; Wang, B.; and Qian, Y. 2023a.
    Tcra-llm: Token compression retrieval augmented large language model for inference
    cost reduction. *arXiv preprint arXiv:2310.15556*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023b) Liu, Z.; Zhang, Y.; Li, P.; Liu, Y.; and Yang, D. 2023b.
    Dynamic llm-agent network: An llm-agent collaboration framework with agent team
    optimization. *arXiv preprint arXiv:2310.02170*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2023) Lu, Q.; Qiu, B.; Ding, L.; Xie, L.; and Tao, D. 2023. Error
    analysis prompting enables human-like translation evaluation in large language
    models: A case study on chatgpt.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mei et al. (2024) Mei, K.; Li, Z.; Xu, S.; Ye, R.; Ge, Y.; and Zhang, Y. 2024.
    Llm agent operating system. *arXiv preprint arXiv:2403.16971*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan et al. (2024) Pan, X.; Gao, D.; Xie, Y.; Wei, Z.; Li, Y.; Ding, B.; Wen,
    J.-R.; and Zhou, J. 2024. Very Large-Scale Multi-Agent Simulation in AgentScope.
    *arXiv preprint arXiv:2407.17789*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2023) Park, J. S.; O’Brien, J.; Cai, C. J.; Morris, M. R.; Liang,
    P.; and Bernstein, M. S. 2023. Generative agents: Interactive simulacra of human
    behavior. In *Proceedings of the 36th annual acm symposium on user interface software
    and technology*, 1–22.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2023) Peng, B.; Galley, M.; He, P.; Cheng, H.; Xie, Y.; Hu, Y.;
    Huang, Q.; Liden, L.; Yu, Z.; Chen, W.; et al. 2023. Check your facts and try
    again: Improving large language models with external knowledge and automated feedback.
    *arXiv preprint arXiv:2302.12813*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Team et al. (2023) Team, G.; Anil, R.; Borgeaud, S.; Wu, Y.; Alayrac, J.-B.;
    Yu, J.; Soricut, R.; Schalkwyk, J.; Dai, A. M.; Hauth, A.; et al. 2023. Gemini:
    a family of highly capable multimodal models. *arXiv preprint arXiv:2312.11805*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tesfatsion (2023) Tesfatsion, L. 2023. Agent-based computational economics:
    Overview and brief history. *Artificial intelligence, learning and computation
    in economics and finance*, 41–58.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,
    M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; et al. 2023.
    Llama: Open and efficient foundation language models. *arXiv preprint arXiv:2302.13971*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2024) Wang, J.; Jain, S.; Zhang, D.; Ray, B.; Kumar, V.; and Athiwaratkun,
    B. 2024. Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning
    Strategies. *arXiv preprint arXiv:2406.06461*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu and Fard (2024) Wu, J. J.; and Fard, F. H. 2024. Benchmarking the Communication
    Competence of Code Generation for LLMs and LLM Agent. *arXiv preprint arXiv:2406.00215*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2023) Wu, Q.; Bansal, G.; Zhang, J.; Wu, Y.; Zhang, S.; Zhu, E.;
    Li, B.; Jiang, L.; Zhang, X.; and Wang, C. 2023. Autogen: Enabling next-gen llm
    applications via multi-agent conversation framework. *arXiv preprint arXiv:2308.08155*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2024) Yang, A.; Yang, B.; Hui, B.; Zheng, B.; Yu, B.; Zhou, C.;
    Li, C.; Li, C.; Liu, D.; Huang, F.; et al. 2024. Qwen2 technical report. *arXiv
    preprint arXiv:2407.10671*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. (2023) Yuan, S.; Chen, J.; Fu, Z.; Ge, X.; Shah, S.; Jankowski,
    C. R.; Xiao, Y.; and Yang, D. 2023. Distilling script knowledge from large language
    models for constrained language planning. *arXiv preprint arXiv:2305.05252*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023) Zhang, K.; Zhao, F.; Kang, Y.; and Liu, X. 2023. Memory-augmented
    llm personalization with short-and long-term memory coordination. *arXiv preprint
    arXiv:2309.11696*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2024a) Zhang, Y.; Yang, S.; Bai, C.; Wu, F.; Li, X.; Li, X.; and
    Wang, Z. 2024a. Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration.
    *arXiv preprint arXiv:2405.14314*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2024b) Zhang, Y.; Yuan, S.; Hu, C.; Richardson, K.; Xiao, Y.;
    and Chen, J. 2024b. Timearena: Shaping efficient multitasking language agents
    in a time-aware simulation. *arXiv preprint arXiv:2402.05733*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2023) Zhu, D.; Chen, J.; Shen, X.; Li, X.; and Elhoseiny, M. 2023.
    Minigpt-4: Enhancing vision-language understanding with advanced large language
    models. *arXiv preprint arXiv:2304.10592*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Experimental Environment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All experiments are conducted using an NVIDIA A100-80G Tensor Core GPU, utilizing
    Tier 5 APIs for both ChatGPT-4o and ChatGPT-4o mini ⁵⁵5https://platform.openai.com/docs/guides/rate-limits/usage-tiers?context=tier-five.
  prefs: []
  type: TYPE_NORMAL
- en: Supplementary Related Work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Management of LLM-based Agents
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Research on the management of LLM-based agents is limited. Popular LLM-based
    multi-agent systems, such as MetaGPT (Hong et al. [2023](#bib.bib11)), AgentVerse
    (Chen et al. [2023b](#bib.bib6)), and AutoGen (Wu et al. [2023](#bib.bib28)),
    typically divide tasks into smaller sub-tasks and allocate multiple agents to
    complete them. However, their approaches to planning are sequential, lacking strategic
    management. In contrast, AIOS (Mei et al. [2024](#bib.bib19)) introduces an LLM
    agent operating system that provides module isolation and integrates LLM and OS
    functions. It employs various managers, including Agent Scheduler, Context Manager,
    Memory Manager, Storage Manager, Tool Manager, and Access Manager, to effectively
    handle numerous agents. However, AIOS manually organizes different applications,
    such as a math problem-solving agent and a travel planning agent, rather than
    multiple agents within the same application. This approach represents a different
    type of SOP and is not applicable to large-scale LLM-MA systems, as it is impractical
    for humans to write every SOP and prompt for each agent when the scale reaches
    thousands or even millions.
  prefs: []
  type: TYPE_NORMAL
- en: Gobang Game Experiment Setup and Result
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We use ChatGPT-4o API for this experiment. The ‘temperature’ parameter is set
    to 0.
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The total cost is $6.9.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First, the Boss agent receives the following initial hand-written meta-prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '1You  are  Bob,  the  leader  of  a  software  development  club.  Your  club’s  current  goal  is  to  develop  a  Gobang  game  with  a  very  strong  AI,  no  frontend,  and  can  be  executed  by  running  ’main.py’.  You  are  now  recruiting  employees  and  assigning  work  to  them.  For  each  employee(including  yourself),  please  write  a  prompt.  Please  specify  his  name(one  word,  no  prefix),  his  job,  what  kinds  of  work  he  needs  to  do.  You  MUST  clarify  all  his  possible  collaborators’  names  and  their  jobs  in  the  prompt.  The  format  should  be  like  (The  example  is  for  Alice  in  another  novel  writing  project):23<employee  name="Alice">4You  are  Alice,  a  novelist.  Your  job  is  to  write  a  single  chapter  of  a  novel  with  1000  words  according  to  the  outline  (outline.txt)  from  Carol,  the  architect  designer,  and  pass  it  to  David  (chapter_x.txt),  the  editor.  Please  only  follow  this  routine.  Your  collarborators  include  Bob(the  Boss),  Carol(the  architect  designer)  and  David(the  editor).5</employee>67Please  note  that  every  employee  is  lazy,  and  will  not  care  anything  not  mentioned  by  your  prompt.  To  ensure  the  completion  of  your  project,  the  work  of  each  employee  should  be  **non-divisable**,  detailed  in  specific  action(like  what  file  to  write.  Only  txt  and  python  files  are  supported)  and  limited  to  a  simple  and  specific  instruction.  All  the  employees  (including  yourself)  should  cover  the  whole  SOP  (for  example,  first  deciding  all  the  features  to  develop  is  recommended).  Speed  up  the  process  by  adding  more  employees  to  divide  the  work.89After  the  designation  process,  please  specify  an  employee’s  name  to  initiate  the  whole  project,  in  the  format  <beginner>Name</beginner>.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In one trial, the model generates the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '1<employee  name="Bob">2You  are  Bob,  the  leader  of  the  software  development  club.  Your  job  is  to  decide  all  the  features  to  develop  for  the  Gobang  game  and  write  them  down  in  a  file  named  ’features.txt’.  Your  collaborators  include  Alice  (the  game  designer),  Carol  (the  AI  developer),  David  (the  game  logic  developer),  and  Eve  (the  integrator).3</employee>45<employee  name="Alice">6You  are  Alice,  a  game  designer.  Your  job  is  to  design  the  game  rules  and  user  interactions  based  on  the  features  listed  in  ’features.txt’  from  Bob,  and  write  them  down  in  a  file  named  ’game_design.txt’.  Your  collaborators  include  Bob  (the  leader),  Carol  (the  AI  developer),  David  (the  game  logic  developer),  and  Eve  (the  integrator).7</employee>89<employee  name="Carol">10You  are  Carol,  an  AI  developer.  Your  job  is  to  develop  the  AI  for  the  Gobang  game  based  on  the  game  design  in  ’game_design.txt’  from  Alice,  and  write  the  AI  code  in  a  file  named  ’ai.py’.  Your  collaborators  include  Bob  (the  leader),  Alice  (the  game  designer),  David  (the  game  logic  developer),  and  Eve  (the  integrator).11</employee>1213<employee  name="David">14You  are  David,  a  game  logic  developer.  Your  job  is  to  develop  the  game  logic  for  the  Gobang  game  based  on  the  game  design  in  ’game_design.txt’  from  Alice,  and  write  the  game  logic  code  in  a  file  named  ’game_logic.py’.  Your  collaborators  include  Bob  (the  leader),  Alice  (the  game  designer),  Carol  (the  AI  developer),  and  Eve  (the  integrator).15</employee>1617<employee  name="Eve">18You  are  Eve,  an  integrator.  Your  job  is  to  integrate  the  AI  code  from  ’ai.py’  by  Carol  and  the  game  logic  code  from  ’game_logic.py’  by  David,  and  write  the  integration  code  in  a  file  named  ’main.py’  to  ensure  the  Gobang  game  can  be  executed  by  running  ’main.py’.  Your  collaborators  include  Bob  (the  leader),  Alice  (the  game  designer),  Carol  (the  AI  developer),  and  David  (the  game  logic  developer).19</employee>2021<beginner>Bob</beginner>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, our program utilizes these initial prompts as the system message to create
    agents, with an additional hand-written prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '1Your  club’s  current  goal  is  to  develop  a  Gobang  game  with  a  very  strong  AI,  no  frontend,  and  can  by  executed  by  running  ’main.py’.  The  project  should  be  executable  in  files.23You  MUST  use  exactly  <talk  goal="Name">TalkContent</talk>  format  to  talk  to  others,  like:45<talk  goal="Alice">Alice,  I  have  completed  ’a.txt’.  Please  check  it  for  your  work  and  talk  to  me  again  if  needed.  </talk>.67Otherwise,  they  will  not  receive  your  message,  and  the  conversation  will  terminate.  "Name"  should  only  be  ONE  specific  employee.  If  there  are  more  than  one  talk  goal,  please  use  multiple  <talk></talk>,  and  they  will  move  on  IN  THE  SAME  TIME.89You  must  use  function  calls  in  JSON  for  file  operations.1011Leave  a  remarkable  TODO  wherever  there  is  an  unfinished  task.  Please  keep  updating  your  TODO  list  until  everything  is  done.  In  that  case,  you  should  clear  your  TODO  list  txt  file(write  nothing  into  it)  and  output  "TERMINATE"  to  end  the  project.'
  prefs: []
  type: TYPE_NORMAL
- en: The initial prompt and the additional prompt are the only prompts that are written
    by hand, showcasing our framework’s autonomy.
  prefs: []
  type: TYPE_NORMAL
- en: Then, Bob, the beginner, will be activated first. Other agents will be activated
    after receiving a message. After activation, each agent will update its own TODO
    list, utilize function calls to complete its tasks, or talk to other agents, until
    it clears its TODO list and marks its task as ’Done’. If an agent wants to talk
    to others, the talk content will be added to the corresponding agents simultaneously,
    and they will be called in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'We provide the following function calls for agents:'
  prefs: []
  type: TYPE_NORMAL
- en: '1{2  "name":  "exec_python_file",3  "description":  "Execute  a  Python  file  and  get  the  result.  Cannot  detect  bugs.  Be  sure  to  review  the  code  first.  If  the  program  requires  user  input,  please  use  this  function  first,  and  then  use  ’input’  function  to  pass  your  input.",4  "parameters":  {5  "type":  "object",6  "properties":  {7  "filename":  {8  "type":  "string",9  "description":  "The  filename  of  the  Python  file  to  be  executed."10  }11  }12  }13},14{15  "name":  "input",16  "description":  "Input  a  string  to  the  running  Python  code.  Only  available  after  exec_python_file  is  called.",17  "parameters":  {18  "type":  "object",19  "properties":  {20  "content":  {21  "type":  "string",22  "description":  "The  string  to  be  input."23  }24  }25  }26},27{28  "name":  "read_file",29  "description":  "Read  the  content  of  a  file.  Return  file  content  and  file  hash.  To  modify  a  file,  please  first  read  it,  then  write  it(using  the  same  hash)."  if  written_files  else  "No  existing  files  are  available.  All  the  files  are  empty.",30  "parameters":  {31  "type":  "object",32  "properties":  {33  "filename":  {34  "type":  "string",35  "description":  "The  filename  to  be  read."36  }37  }38  },39  "required":  [40  "filename"41  ]42},43{44  "name":  "write_file",45  "description":  f"Write  raw  content  to  a  file.  If  the  file  exists,  only  overwrite  when  overwrite  =  True  and  hash  value  (get  it  from  read_file)  is  correct.  ",46  "parameters":  {47  "type":  "object",48  "properties":  {49  "filename":  {50  "type":  "string",51  "description":  "The  filename  to  be  written."52  },53  "content":  {54  "type":  "string",55  "description":  r"The  content  to  be  written.  Use  \n  instead  of  \\n  for  a  new  line."56  },57  "overwrite":  {58  "type":  "boolean",59  "description":  "Optional.  Whether  to  overwrite  the  file  if  it  exists.  Default  is  False.  If  True,  base_commit_hash  is  required."60  },61  "base_commit_hash":  {62  "type":  "string",63  "description":  "Optional.  The  hash  value  of  the  file  to  be  modified(get  it  from  read_file).  Required  when  overwrite  =  True."64  }65  }66  },67  "required":  [68  "filename",69  "content"70  ]71},72{73  "name":  "add_agent",74  "description":  "Recruit  an  agent  to  the  conversation  as  your  subordinate.  Return  the  real  name.  To  add  multiple  agents,  please  call  this  function  multiple  times.  After  that,  you  MUST  talk  to  them  using  the  <talk  goal=\"Name\">Content</talk>  format.  ",75  "parameters":  {76  "type":  "object",77  "properties":  {78  "name":  {79  "type":  "string",80  "description":  "The  name  of  the  agent  to  be  added.  Do  not  use  space.  To  ensure  the  uniqueness  of  the  name,  the  real  name  will  be  returned  later.  Please  use  names  like  EcoTester7x"81  },82  "description":  {83  "type":  "string",84  "description":  "The  description  of  the  agent,  for  your  reference."85  },86  "initial_prompt":  {87  "type":  "string",88  "description":  ’’’89  The  initial  prompt  and  memory  of  that  agent.  Please  specify  his  name(one  word,  no  prefix),  his  job,  what  kinds  of  work  he  needs  to  do.  You  MUST  clarify  all  his  possible  collaborators’  EXACT  names  and  their  jobs  in  the  prompt,  and  all  the  files  he  can  write.  The  format  should  be  like  (The  example  is  for  Alice  in  another  novel  writing  project):90  You  are  Alice,  a  novelist.  Your  job  is  to  write  a  single  chapter  of  a  novel  with  1000  words  according  to  the  outline  (outline.txt)  from  Carol,  the  architect  designer,  and  pass  it  to  David  (chapter_x.txt),  the  editor.  Please  only  follow  this  routine.  Your  collarborators  include  Bob(the  Boss),  Carol(the  architect  designer)  and  David(the  editor).91  Please  note  that  every  agent  is  lazy,  and  will  not  care  anything  not  mentioned  by  your  prompt.  To  ensure  the  completion  of  the  project,  the  work  of  each  minister  should  be  non-divisable(please  cover  all  the  ministries  concerning  all  the  aspects  of  the  country),  detailed  in  specific  action(like  what  file  to  write.  Only  txt  files  are  supported)  and  limited  to  a  simple  and  specific  instruction(For  instance,  instead  of  "align  with  the  overall  national  policies",  please  specify  those  policies).92  ’’’93  }94  }95  },96  "required":  [97  "name",98  "description",99  "initial_prompt"100  ]101},102{103  "name":  "talk",104  "description":  "Leave  a  message  to  specific  agents  for  feedback.  They  will  reply  to  you  later  on.",105  "parameters":{106  "type":  "object",107  "properties":  {108  "messages":  {109  "type":  "string",110  "description":  "All  the  messages  to  be  sent.  The  format  must  look  like:  <talk  goal=\"Name\">TalkContent</talk><talk  goal=\"Name\">TalkContent</talk>"111  }112  }113  },114  "required":  [115  "messages"116  ]117},118{119  "name":  "TERMINATE",120  "description":  "End  your  current  conversation.  Please  ensure  all  your  tasks  have  been  done."121}'
  prefs: []
  type: TYPE_NORMAL
- en: The communication content and function call results are added directly into
    the corresponding agent’s memory. Each function call is implemented according
    to its description, and can be found in our source code. In this experiment, we
    disable the add_agent function for efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: The memory of each agent is implemented by a chroma vector database ⁶⁶6https://www.trychroma.com/.
    It returns the last message’s most relevant message, as well as the six latest
    messages (in this experiment), upon each memory retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our experiment, the framework successfully produces a runnable Gobang game
    with a naive AI upon the first trial, whose interface is shown in Figure [5](#A1.F5
    "Figure 5 ‣ Results ‣ Gobang Game Experiment Setup and Result ‣ Appendix A Appendix
    ‣ MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM
    Agent Systems"). This trial takes 800 seconds and $6.9 to complete. The complete
    log and program of this trial can be found in our github repository. This may
    vary as LLM’s output is unstable.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d20fcfb69a7a0f0ebfd7f4148669986d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Interface of Gobang demo produced by MegaAgent'
  prefs: []
  type: TYPE_NORMAL
- en: Human-written SOP for Gobang Game
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the human-written SOP for the Gobang Game, intended to compare its performance
    with that of the MegaAgent-generated SOP.
  prefs: []
  type: TYPE_NORMAL
- en: '1<employee  name="Bob">2You  are  Bob,  the  boss  of  the  software  development  team.  You  are  responsible  for  monitoring  the  progress  of  the  project.  You  must  ensure  that  the  project  can  be  executed  by  running  the  main.py  file  in  the  end.  Your  team  members  are  Alan(responsible  for  the  game  logic  design),  Alice(responsible  for  board.py),  Charlie(responsible  for  main.py),  David(responsible  for  ai.py),  and  Emily(responsible  for  testing)3</employee>45<employee  name="Alan">6You  are  Alan,  an  architect  designer.  Your  job  is  to  design  the  game  logic  of  the  Gobang  game,  and  possible  implementation  of  AI.  You  need  to  write  the  game  logic  in  design.txt  and  pass  it  to  your  teammates.  Your  collaborators  include  Bob(the  Boss),  Alice(responsible  for  board.py),  Charlie(responsible  for  main.py),  and  David(responsible  for  ai.py).7</employee>89<employee  name="Alice">10You  are  Alice,  a  software  developer.  Your  job  is  to  implement  the  board.py  file  according  to  the  design  from  Alan  in  design.txt.  Your  collaborators  include  Bob(the  Boss),  Alan(responsible  for  the  game  logic  design),  Charlie(responsible  for  main.py),  David(responsible  for  ai.py),  and  Emily(responsible  for  testing).11</employee>1213<employee  name="Charlie">14You  are  Charlie,  a  software  developer.  Your  job  is  to  implement  the  main.py  file  according  to  the  design  from  Alan  in  design.txt.  Ensure  it  can  cooperate  with  board.py(by  Alice)  and  ai.py(by  David).  You  can  also  write  the  test.py  file  for  testing.  Your  collaborators  include  Bob(the  Boss),  Alan(responsible  for  the  game  logic  design),  Alice(responsible  for  board.py),  David(responsible  for  ai.py),  and  Emily(responsible  for  testing).15</employee>1617<employee  name="David">18You  are  David,  a  AI  developer.  Your  job  is  to  implement  a  naive  ai.py  file,  just  making  random  moves.  Try  to  make  the  AI  as  simple  and  quickly  as  possible.  Your  collaborators  include  Bob(the  Boss),  Alan(responsible  for  the  game  logic  design),  Alice(responsible  for  board.py),  Charlie(responsible  for  main.py),  and  Emily(responsible  for  testing).19</employee>2021<employee  name="Emily">22You  are  Emily,  a  tester.  Your  job  is  to  test  the  correctness  and  efficiency  of  the  Gobang  game.  You  need  to  write  the  test.py  file  for  testing.  You  need  to  ensure  that  the  game  can  be  executed  correctly  by  running  the  main.py  file.  You  need  to  test  throughly  until  the  game  ends.  Your  collaborators  include  Bob(the  Boss),  Alan(responsible  for  the  game  logic  design),  Alice(responsible  for  board.py),  Charlie(responsible  for  main.py),  and  David(responsible  for  ai.py).23</employee>2425<beginner>Bob</beginner>'
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of Gobang Game Experiment with other LLM-MA Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We conduct the same Gobang game task experiment on state-of-the-art LLM-MA systems
    as of July 2024.
  prefs: []
  type: TYPE_NORMAL
- en: AutoGen Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We test AutoGen v1.0.16 based on its multi-agent coding demo. We only fill
    in the API key and change its prompt to: Develop a Gobang game with an AI , and
    leave everything else unchanged. We do not allow runtime human input.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in Figure [6](#A1.F6 "Figure 6 ‣ AutoGen Setup and Result ‣ Comparison
    of Gobang Game Experiment with other LLM-MA Systems ‣ Appendix A Appendix ‣ MegaAgent:
    A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems")
    and Figure [7](#A1.F7 "Figure 7 ‣ AutoGen Setup and Result ‣ Comparison of Gobang
    Game Experiment with other LLM-MA Systems ‣ Appendix A Appendix ‣ MegaAgent: A
    Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems"),
    It turns out that AutoGen generates a program ending with # To be continued..
    after about two minutes, and gets stuck when trying to execute it. The possible
    reason for its failure is that its SOP is too simple, and does not include enough
    communication (like code review) between agents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We try three times, which all end with similar results. In another one trial,
    as shown in Figure [8](#A1.F8 "Figure 8 ‣ AutoGen Setup and Result ‣ Comparison
    of Gobang Game Experiment with other LLM-MA Systems ‣ Appendix A Appendix ‣ MegaAgent:
    A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems")
    and Figure [9](#A1.F9 "Figure 9 ‣ AutoGen Setup and Result ‣ Comparison of Gobang
    Game Experiment with other LLM-MA Systems ‣ Appendix A Appendix ‣ MegaAgent: A
    Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems"),
    AutoGen successfully produces an AI with mini-max algorithm, but no pruning. This
    is impossible to execute in a limited time, as the state space of Gobang game
    is very large. We try another prompt: Develop a Gobang game with a very strong
    AI, no frontend, and can be executed by running ’main.py’ , and get similar results.'
  prefs: []
  type: TYPE_NORMAL
- en: By the time it gets stuck, AutoGen has cost $0.1 and 120 seconds. Since AutoGen
    cannot complete this task, we are unable to count the overall cost.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7b3847bca9e66afcac803bb549ad346f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Code Produced by AutoGen'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/51007c01d5457f20a7b56a425cb446fc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Execution Result of AutoGen'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9eb9031000bc3ebb1bf29f9bc37d821c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Code Produced by AutoGen in Another Trial'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/17e15945913529acad9519f5c0501f4a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Execution Result of AutoGen in Another Trial. AI will keep thinking
    for almost infinite time.'
  prefs: []
  type: TYPE_NORMAL
- en: MetaGPT Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We test MetaGPT v0.8.1 by feeding the prompt: Develop a Gobang game with an
    AI. We fill in the API key and leave everything else unchanged. It produces results
    like Figure [10](#A1.F10 "Figure 10 ‣ MetaGPT Setup and Result ‣ Comparison of
    Gobang Game Experiment with other LLM-MA Systems ‣ Appendix A Appendix ‣ MegaAgent:
    A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems"),
    and its execution time is around eight minutes. We try three times, and find none
    of them can produce an AI move. The major errors are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code is not executable, and raises an error. The possible reason is that
    MetaGPT does not have external tools to execute and debug the produced code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The produced program is not a Gobang game (for example, a tic-tac-toe game instead).
    The possible reason for failure is that its SOP is too simple, and the requirement
    for communication between agents is not sufficient.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI falls into an infinite loop. The possible reason is that MetaGPT does not
    have external tools to execute and debug the produced code, and the current ChatGPT
    API is not capable of developing the AlphaBeta algorithm without errors by itself.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/91d1b27ffa8fb0ddb3277f1a156d81d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Execution Result of the Code Produced by MetaGPT'
  prefs: []
  type: TYPE_NORMAL
- en: CAMEL Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We use the CAMEL v0.1.6.0 Jupiter Notebook demo in Colab. We fill in the API
    key, change the task prompt to: Develop a Gobang game with an AI, and leave everything
    else unchanged. We try three times. It turns out that CAMEL can only produce code
    segments. For example, in one trial, as shown in Figure [11](#A1.F11 "Figure 11
    ‣ CAMEL Setup and Result ‣ Comparison of Gobang Game Experiment with other LLM-MA
    Systems ‣ Appendix A Appendix ‣ MegaAgent: A Practical Framework for Autonomous
    Cooperation in Large-Scale LLM Agent Systems"), CAMEL forgets to write ui.py,
    which is included in game.py. The possible reason for this is that its planning
    and contextual ability is weak. The total cost of one trial is $0.76.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4682b906625c389eb4bc65713f579eae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: An example of CAMEL’s output. It forgot to write ui.py in this trial.'
  prefs: []
  type: TYPE_NORMAL
- en: AgentVerse Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We test AgentVerse v0.1.8.1 based on its tasksolving/pythoncalculator scenario.
    We fill in the API key, change the max_turn parameter from 3 to 10 to allow more
    rounds for better results, and modify the task description to: develop a Gobang
    game with an AI using Python3. We leave everything else unchanged and try three
    times. We find that, in the first and second trial, the agent keeps rejecting
    the result for all the ten rounds, as shown in Figure [12](#A1.F12 "Figure 12
    ‣ AgentVerse Setup and Result ‣ Comparison of Gobang Game Experiment with other
    LLM-MA Systems ‣ Appendix A Appendix ‣ MegaAgent: A Practical Framework for Autonomous
    Cooperation in Large-Scale LLM Agent Systems"); as for the third trial, although
    the agent accepts the result, the code as shown in Figure [13](#A1.F13 "Figure
    13 ‣ AgentVerse Setup and Result ‣ Comparison of Gobang Game Experiment with other
    LLM-MA Systems ‣ Appendix A Appendix ‣ MegaAgent: A Practical Framework for Autonomous
    Cooperation in Large-Scale LLM Agent Systems") still presents many placeholders,
    and cannot be executed. Given that ten rounds significantly exceed the default
    setting, we conclude that AgentVerse is unlikely to successfully complete the
    Gobang task even with additional rounds and opportunities. One trial costs about
    $8.07, and 1980 seconds.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6ac5b52f0a6daa47f424bd191f53db59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: A rejected trial of AgentVerse after ten rounds.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c171fc7ff4e66840cdca7299dcfd5e69.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: An accepted trial of AgentVerse. The code still contains many placeholders,
    and is not executable.'
  prefs: []
  type: TYPE_NORMAL
- en: To sum up, our MegaAgent framework is likely to be the first and only LLM-MA
    system to solve the Gobang task successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Industry-Wise Nation Policy Simulation Setup and Result
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Setup
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We use the ChatGPT-4o mini API for this experiment. The ‘temperature’ parameter
    is set to default. The memory of each agent returns the most relevant message,
    as well as ten latest messages in this experiment. In this experiment, we disable
    the exec_python_file function for efficiency, which would not be used even if
    enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The total cost of this experiment is $3.3.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Boss agent receives the following initial hand-written meta-prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '1You  are  NationLeader,  the  leader  of  a  pioneering  nation.  You  want  to  develop  the  best  detailed  policy  for  your  cutting-edge  country  in  ’policy_{department}.txt’.  You  are  now  recruiting  ministers  and  assigning  work  to  them.  For  each  possible  minister,  please  write  a  prompt.  Please  specify  his  name(no  space),  his  job,  what  kinds  of  work  he  needs  to  do.  Note  that  each  of  them  can  recruit  subordinates  and  do  tests  on  them  based  on  your  policy.  You  MUST  clarify  all  his  possible  collaborators’  names  and  their  jobs  in  the  prompt.  The  format  should  be  like  (The  example  is  for  Alice  in  another  novel  writing  project):23<employee  name="MinisterName">4You  are  MinisterName,  the  {job_title}  of  {specific_department}.  Your  job  is  to  develop  a  comprehensive  policy  document  (’{file_name}.txt’)  according  to  the  guidelines  provided  in  ’policy_{department}.txt’.  You  will  collaborate  with  {collaborator1_name}  (the  {collaborator1_role}),  {collaborator2_name}  (the  {collaborator2_role}),  and  pass  the  final  document  to  {collaborator3_name}  (the  {collaborator3_role}).  You  can  recruit  lots  of  citizens  for  testings.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  {list_of_collaborators}.5</employee>67Also,  write  a  prompt  for  NationLeader  (yourself).  Please  note  that  every  minister  is  lazy,  and  will  not  care  anything  not  mentioned  by  your  prompt.  To  ensure  the  completion  of  your  project,  the  work  of  each  minister  should  be  non-divisable(please  cover  ALL  the  ministries  concerning  ALL  the  aspects  of  the  country),  detailed  in  specific  action(like  what  file  to  write.  Only  txt  files  are  supported)  and  limited  to  a  simple  and  specific  instruction.  All  the  minister  (including  yourself)  should  cover  the  whole  SOP  to  develop  a  policy.  They  should  simultaneously  create  the  citizens  and  test  on  them.  Speed  up  the  process  by  adding  more  ministers  to  divide  the  work.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In one trial, the model generates the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '1‘‘‘xml2<employee  name="MinisterEducation">3You  are  MinisterEducation,  the  Minister  of  Education.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_education.txt’)  according  to  the  guidelines  provided  in  ’policy_education.txt’.  You  will  collaborate  with  MinisterTraining  (the  Minister  of  Workforce  Development),  MinisterHealth  (the  Minister  of  Health),  and  pass  the  final  document  to  MinisterFinance  (the  Minister  of  Finance).  You  can  recruit  lots  of  citizens  for  testing  educational  programs.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterTraining,  MinisterHealth,  and  MinisterFinance.4</employee>56<employee  name="MinisterHealth">7You  are  MinisterHealth,  the  Minister  of  Health.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_health.txt’)  according  to  the  guidelines  provided  in  ’policy_health.txt’.  You  will  collaborate  with  MinisterEducation  (the  Minister  of  Education),  MinisterFinance  (the  Minister  of  Finance),  and  pass  the  final  document  to  MinisterInfrastructure  (the  Minister  of  Infrastructure).  You  can  recruit  lots  of  citizens  for  testing  health  initiatives.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterEducation,  MinisterFinance,  and  MinisterInfrastructure.8</employee>910<employee  name="MinisterFinance">11You  are  MinisterFinance,  the  Minister  of  Finance.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_finance.txt’)  according  to  the  guidelines  provided  in  ’policy_finance.txt’.  You  will  collaborate  with  MinisterHealth  (the  Minister  of  Health),  MinisterEducation  (the  Minister  of  Education),  and  pass  the  final  document  to  MinisterEconomy  (the  Minister  of  Economy).  You  can  recruit  lots  of  citizens  for  testing  financial  literacy  programs.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterHealth,  MinisterEducation,  and  MinisterEconomy.12</employee>1314<employee  name="MinisterEconomy">15You  are  MinisterEconomy,  the  Minister  of  Economy.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_economy.txt’)  according  to  the  guidelines  provided  in  ’policy_economy.txt’.  You  will  collaborate  with  MinisterFinance  (the  Minister  of  Finance),  MinisterTrade  (the  Minister  of  Trade),  and  pass  the  final  document  to  MinisterInnovation  (the  Minister  of  Innovation).  You  can  recruit  lots  of  citizens  for  testing  economic  initiatives.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterFinance,  MinisterTrade,  and  MinisterInnovation.16</employee>1718<employee  name="MinisterTrade">19You  are  MinisterTrade,  the  Minister  of  Trade.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_trade.txt’)  according  to  the  guidelines  provided  in  ’policy_trade.txt’.  You  will  collaborate  with  MinisterEconomy  (the  Minister  of  Economy),  MinisterInnovation  (the  Minister  of  Innovation),  and  pass  the  final  document  to  MinisterInfrastructure  (the  Minister  of  Infrastructure).  You  can  recruit  lots  of  citizens  for  testing  trade  policies.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterEconomy,  MinisterInnovation,  and  MinisterInfrastructure.20</employee>2122<employee  name="MinisterInnovation">23You  are  MinisterInnovation,  the  Minister  of  Innovation.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_innovation.txt’)  according  to  the  guidelines  provided  in  ’policy_innovation.txt’.  You  will  collaborate  with  MinisterTrade  (the  Minister  of  Trade),  MinisterEconomy  (the  Minister  of  Economy),  and  pass  the  final  document  to  MinisterTechnology  (the  Minister  of  Technology).  You  can  recruit  lots  of  citizens  for  testing  innovative  solutions.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterTrade,  MinisterEconomy,  and  MinisterTechnology.24</employee>2526<employee  name="MinisterTechnology">27You  are  MinisterTechnology,  the  Minister  of  Technology.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_technology.txt’)  according  to  the  guidelines  provided  in  ’policy_technology.txt’.  You  will  collaborate  with  MinisterInnovation  (the  Minister  of  Innovation),  MinisterInfrastructure  (the  Minister  of  Infrastructure),  and  pass  the  final  document  to  MinisterEnvironment  (the  Minister  of  Environment).  You  can  recruit  lots  of  citizens  for  testing  technological  advancements.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterInnovation,  MinisterInfrastructure,  and  MinisterEnvironment.28</employee>2930<employee  name="MinisterInfrastructure">31You  are  MinisterInfrastructure,  the  Minister  of  Infrastructure.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_infrastructure.txt’)  according  to  the  guidelines  provided  in  ’policy_infrastructure.txt’.  You  will  collaborate  with  MinisterHealth  (the  Minister  of  Health),  MinisterTechnology  (the  Minister  of  Technology),  and  pass  the  final  document  to  MinisterEnvironment  (the  Minister  of  Environment).  You  can  recruit  lots  of  citizens  for  testing  infrastructure  projects.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterHealth,  MinisterTechnology,  and  MinisterEnvironment.32</employee>3334<employee  name="MinisterEnvironment">35You  are  MinisterEnvironment,  the  Minister  of  Environment.  Your  job  is  to  develop  a  comprehensive  policy  document  (’policy_environment.txt’)  according  to  the  guidelines  provided  in  ’policy_environment.txt’.  You  will  collaborate  with  MinisterTechnology  (the  Minister  of  Technology),  MinisterInfrastructure  (the  Minister  of  Infrastructure),  and  pass  the  final  document  to  MinisterEducation  (the  Minister  of  Education).  You  can  recruit  lots  of  citizens  for  testing  environmental  policies.  Ensure  adherence  to  the  specified  routine  only.  Your  collaborators  include  MinisterTechnology,  MinisterInfrastructure,  and  MinisterEducation.36</employee>3738<employee  name="NationLeader">39You  are  NationLeader,  the  leader  of  the  nation.  Your  job  is  to  oversee  the  development  of  all  comprehensive  policy  documents  (’policy_{department}.txt’)  according  to  the  guidelines  provided  in  ’policy_{department}.txt’.  You  will  ensure  that  each  minister  collaborates  effectively  with  their  respective  teams  and  adheres  to  the  specified  routines.  You  will  review  the  final  documents  submitted  by  each  minister  and  ensure  they  are  aligned  with  the  nation’s  vision.  Your  ministers  include  MinisterEducation,  MinisterHealth,  MinisterFinance,  MinisterEconomy,  MinisterTrade,  MinisterInnovation,  MinisterTechnology,  MinisterInfrastructure,  and  MinisterEnvironment.  Ensure  that  all  policies  are  developed  efficiently  and  that  citizens  are  recruited  for  testing  across  all  departments.40</employee>41‘‘‘42<beginner>NationLeader</beginner>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Every agent is created with an additional hand-written prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '1Your  nation’s  current  goal  is  to  develop  the  best  detailed  policy  for  your  cutting-edge  country  in  ’policy_{department}.txt’.  The  policy  should  be  devided  into  smaller  parts.  After  the  policy  is  drafted,  if  you  are  a  minister,  you  may  recruit,  and  test  on  no  more  than  5  citizens(by  talking  to  them),  revising  these  files  according  to  citizens’  feedbacks.  Please  focus  on  the  completion  and  quality  of  the  policy,  detailed  in  specific  laws  and  actions.23You  MUST  use  only  function  calls  to  work  and  communicate  with  other  agents.  Do  not  output  directly!  For  amendments  to  the  policy,  please  talk  to  the  corresponding  minister,  instead  of  the  tester.45Leave  a  remarkable  TODO  wherever  there  is  an  unfinished  task.  Please  keep  updating  your  TODO  list(todo_yourname.txt)  until  everything  is  done.  In  that  case,  you  should  clear  your  TODO  list  txt  file(write  nothing  into  it)  and  output  "TERMINATE"  to  end  the  your  part.'
  prefs: []
  type: TYPE_NORMAL
- en: After that, NationLeader spontaneously engages in conversations with the minister
    agents. Each minister then utilizes the add_agent function call to draft their
    policies and create citizen agents to test and refine these policies. Citizen
    testers discuss their feedback among themselves and also communicate with their
    superiors to provide feedback. Moreover, ministers engage in discussions with
    one another to enhance cooperation across ministries.
  prefs: []
  type: TYPE_NORMAL
- en: The file system manages each agent’s todo list, records the citizens’ feedback,
    and maintains the most recent version of each ministry’s policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a todo list for a citizen tester might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '1-  Specify  the  frequency  and  scope  of  health  impact  assessments.2-  Include  specific  targets  and  timelines  for  air  quality  standards.3-  Add  metrics  for  success  in  active  transportation  promotion.4-  Include  incentives  for  businesses  to  support  active  transportation.5-  Outline  specific  safety  measures  for  transportation  safety.6-  Include  a  plan  for  regular  safety  audits  of  public  transportation  systems.7-  Mention  accessibility  considerations  in  urban  space  design.8-  Include  partnerships  with  local  health  organizations  for  mental  health  initiatives.9-  Emphasize  community  involvement  in  the  planning  process.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the health testers’ discussions, the feedback on the education policy
    might appear as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '1#  Feedback  on  Infrastructure  Policy  Draft23##  General  Observations4-  The  policy  provides  a  comprehensive  framework  for  infrastructure  development,  with  a  strong  emphasis  on  health,  technology,  and  environmental  sustainability.56##  Health  Infrastructure7###  Accessibility8-  The  focus  on  improving  access  to  healthcare  facilities  through  public  transport  and  active  transportation  is  commendable.  However,  it  would  be  beneficial  to  include  specific  metrics  or  targets  for  accessibility  improvements.910###  Health  Impact  Assessments11-  The  inclusion  of  health  impact  assessments  is  crucial.  It  is  recommended  to  specify  the  types  of  health  outcomes  that  will  be  measured  and  how  these  assessments  will  influence  project  planning  and  design.12-  Consider  establishing  a  timeline  for  conducting  these  assessments  to  ensure  they  are  integrated  into  the  project  lifecycle.1314###  Stakeholder  Engagement15-  Engaging  health  professionals  and  community  members  is  essential.  It  may  be  useful  to  outline  specific  methods  for  this  engagement,  such  as  surveys,  public  forums,  or  focus  groups.1617##  Technology  Integration18-  The  integration  of  technology  in  infrastructure  projects  is  well-addressed.  However,  it  would  be  beneficial  to  include  examples  of  innovative  technologies  that  could  be  utilized  to  enhance  health  outcomes.1920##  Environmental  Considerations21-  The  environmental  section  is  robust,  but  it  should  explicitly  connect  how  sustainable  practices  can  positively  impact  public  health,  such  as  reducing  pollution  and  promoting  healthier  living  environments.2223##  Conclusion24-  Overall,  the  policy  is  well-structured  and  aligns  with  national  goals.  Further  detailing  in  specific  areas,  particularly  around  health  metrics  and  stakeholder  engagement,  will  enhance  its  effectiveness.2526##  Recommendations271.  Include  specific  metrics  for  accessibility  improvements  in  healthcare.282.  Specify  health  outcomes  to  be  measured  in  health  impact  assessments.293.  Outline  methods  for  stakeholder  engagement  in  health  assessments.304.  Provide  examples  of  innovative  technologies  that  can  improve  health  outcomes.315.  Connect  sustainable  practices  to  public  health  benefits  more  explicitly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'And the final version of the health policy might be presented as:'
  prefs: []
  type: TYPE_NORMAL
- en: '1#  Health-Related  Aspects  of  Urban  Development  Policy23##  1.  Health  Impact  Assessments4-  Conduct  health  impact  assessments  for  all  urban  development  projects  exceeding  a  specified  budget  threshold  (to  be  defined).5-  Assessments  should  be  conducted  at  the  planning  stage  and  include  evaluations  of  potential  health  risks  and  benefits.6-  Frequency  of  assessments  to  be  determined  based  on  project  size  and  scope.78##  2.  Accessibility  Guidelines9-  Ensure  all  urban  designs  adhere  to  accessibility  guidelines  for  individuals  with  disabilities.10-  Include  specific  metrics  for  evaluating  accessibility  improvements  over  time,  such  as  the  percentage  of  public  spaces  meeting  accessibility  standards.1112##  3.  Collaboration  with  Health  Organizations13-  Outline  specific  roles  and  responsibilities  for  local  health  organizations  in  community  health  initiatives.14-  Establish  regular  communication  channels  between  urban  planners  and  health  organizations  to  ensure  alignment  of  goals.1516##  4.  Safety  Measures17-  Implement  regular  safety  audits  for  public  transportation  systems  to  assess  the  effectiveness  of  safety  measures  such  as  surveillance  cameras  and  emergency  call  buttons.18-  Develop  a  plan  for  continuous  improvement  based  on  audit  findings,  including  a  timeline  for  conducting  safety  audits  and  implementing  improvements.1920##  5.  Community  Health  Initiatives21-  Promote  community  health  initiatives  in  collaboration  with  local  health  organizations,  focusing  on  preventive  care  and  health  education.22-  Engage  community  members  in  the  planning  process  to  ensure  their  health  needs  are  addressed.23-  Expand  on  the  community  engagement  process  in  health  initiatives  to  include  diverse  populations  and  ensure  their  voices  are  heard.2425##  6.  Monitoring  and  Evaluation26-  Establish  a  framework  for  monitoring  and  evaluating  the  health-related  aspects  of  urban  development  policies  over  time.27-  Include  metrics  for  success,  such  as  reductions  in  health  disparities  and  improvements  in  community  health  outcomes.28-  Enhance  evaluation  metrics  for  community  health  initiatives  to  include  specific  targets  for  health  outcomes  and  community  engagement  levels.2930##  7.  Mental  Health  Support31-  **Resource  Allocation  and  Funding**:  Allocate  funding  for  mental  health  support  through  government  budgets,  grants,  and  partnerships  with  private  organizations.  Ensure  that  resources  are  distributed  equitably  across  urban  areas,  focusing  on  underserved  communities.32-  **Partnerships  with  Local  Health  Organizations**:  Collaborate  with  local  mental  health  organizations,  community  health  centers,  and  non-profits  to  provide  comprehensive  mental  health  services.  Define  specific  roles  for  each  partner,  such  as  outreach,  counseling,  and  education.33-  **Evaluation  Plan**:  Develop  a  plan  to  evaluate  the  effectiveness  of  mental  health  initiatives,  including  metrics  such  as  the  number  of  individuals  served,  improvements  in  mental  health  outcomes,  and  community  feedback.  Conduct  regular  assessments  to  adapt  programs  based  on  findings.3435##  8.  Community  Engagement  Strategies36-  Implement  interactive  methods  for  community  involvement,  such  as  online  forums  and  feedback  sessions,  to  ensure  diverse  voices  are  heard.37-  Establish  a  follow-up  mechanism  to  inform  the  community  about  how  their  feedback  has  influenced  decisions.3839##  9.  Health  Metrics  Integration40-  Establish  specific  health  metrics  to  monitor  changes  in  access  to  healthcare  facilities,  reduction  in  air  pollution,  and  increased  physical  activity  levels  among  residents  as  a  result  of  public  transportation  improvements.41-  Collaborate  with  health  organizations  to  gather  data  on  health  outcomes  related  to  transportation  access.42-  Integrate  more  preventive  health  measures  into  community  health  initiatives  to  promote  overall  well-being.43-  Include  health-related  metrics,  such  as  the  impact  of  active  transportation  on  public  health,  in  policy_health.txt.4445##  10.  Reducing  Air  Pollution46-  Implement  stricter  emissions  standards  for  construction  vehicles  and  promote  the  use  of  electric  vehicles  in  urban  development  projects.47-  Increase  green  spaces  and  urban  forests  to  improve  air  quality  and  provide  recreational  areas  for  residents.48-  Encourage  the  use  of  public  transportation  and  carpooling  to  reduce  traffic  congestion  and  associated  air  pollution.4950##  11.  Promoting  Active  Transportation51-  Develop  dedicated  bike  lanes  and  pedestrian  pathways  to  encourage  walking  and  cycling.52-  Implement  safety  measures  such  as  improved  lighting  and  signage  in  areas  frequented  by  pedestrians  and  cyclists.53-  Launch  public  awareness  campaigns  to  promote  the  health  benefits  of  active  transportation  and  provide  incentives  for  using  these  modes  of  transport.5455##  12.  Budget  Thresholds  for  Health  Impact  Assessments56-  Define  specific  budget  thresholds  for  conducting  health  impact  assessments,  ensuring  that  projects  with  significant  potential  health  impacts  are  evaluated.5758##  13.  Additional  Metrics  for  Accessibility  Improvements59-  Propose  additional  metrics  for  evaluating  accessibility  improvements,  such  as  user  satisfaction  surveys  and  the  number  of  accessibility  complaints  received.6061##  14.  Strategies  for  Collaboration  with  Health  Organizations62-  Recommend  strategies  for  enhancing  collaboration  with  health  organizations,  including  joint  training  programs  and  shared  resources.6364##  15.  Safety  Audit  Metrics  for  Public  Transportation65-  Suggest  specific  safety  audit  metrics  for  public  transportation  systems,  such  as  incident  response  times  and  user  perceptions  of  safety.6667##  16.  Community  Health  Initiatives  Promotion68-  Identify  potential  community  health  initiatives  that  could  be  promoted,  focusing  on  nutrition  education  and  physical  activity  programs.6970##  17.  Monitoring  and  Evaluation  Framework71-  Develop  a  detailed  monitoring  and  evaluation  framework  for  health-related  urban  policies,  including  timelines  and  responsible  parties.7273##  18.  Funding  Sources  for  Mental  Health  Support74-  Propose  additional  funding  sources  for  mental  health  support  initiatives,  such  as  corporate  sponsorships  and  crowdfunding  campaigns.'
  prefs: []
  type: TYPE_NORMAL
- en: Other nine policies have the similar format which can be found in the github
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: In this experiment, 590 agents form a three-level hierarchy, which can indeed
    extend further, while human input is just the meta-prompt. This showcases the
    scalability and autonomy of our MegaAgent framework.
  prefs: []
  type: TYPE_NORMAL
- en: One trial in this experiment costs about $3.3 and 2991 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of Policy Simulation Experiment with other LLM-MA Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AutoGen Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Similar to the setup of Gobang Game, we change the prompt to: Develop a best
    detailed policy for a cutting-edge country, which is the same as that of MegaAgent’s,
    except for the agent recruitment part. It only outputs an outline for each industry,
    with no policy details provided, as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '1Excellent,  let’s  start  with  developing  the  policy  then.23**Title:  National  Policy  for  Artificial  intelligence  and  Digital  Technologies**45**1.  Preamble:**67The  national  policy  for  Artificial  Intelligence  (AI)  and  Digital  Technologies  is  a  strategic  directive  aimed  at  positioning  our  country  as  a  world  leader  in  the  development,  adoption,  and  regulation  of  AI  and  digital  technologies.  Through  this  endeavor,  we  are  committed  to  fostering  a  digital  ecosystem  that  enables  innovation  while  promoting  the  ethical  use  of  technology  and  safeguarding  public  interest.89**2.  Objectives:**1011The  primary  objective  of  this  policy  is  to  advance  our  national  capacity  in  AI  and  digital  technologies.  This  includes:12i)  Strengthening  education  and  research  in  AI  and  related  fields.13ii)  Encouraging  innovation  and  entrepreneurship.14iii)  Ensuring  data  protection  and  privacy.15iv)  Fortifying  our  cybersecurity  measures.16v)  Upholding  ethical  standards  in  technological  advancements.17vi)  Integrating  AI  in  public  sector  services  for  efficiency  and  effectiveness.18vii)  Actively  seeking  and  promoting  International  collaborations  and  partnerships.1920**3.  Strategies  and  Actions:**21223.1  Education  and  Research:23Establish  centers  of  excellence  in  AI  and  digital  technologies  in  educational  institutions.  Encourage  and  fund  research  in  AI,  Machine  Learning,  and  other  emerging  technologies.24253.2  Infrastructure  Development:26Support  infrastructure  required  for  digital  technologies  including  high-speed  internet  access,  cloud  platforms,  and  advanced  computing  resources.27283.3  Innovation  and  Entrepreneurship:29Institute  a  supportive  regulatory  environment  for  technology  start-ups  and  provide  seed  funding.30313.4  Data  Protection:32Enforce  stringent  data  protection  regulations  to  prevent  unauthorized  data  access  and  usage.  Create  awareness  on  data  privacy  among  citizens  and  enforce  penalties  for  breaches.33343.5  Cybersecurity:35Develop  national  resilience  against  cyber  threats  through  proactive  and  reactive  measures.  This  includes  creating  a  dedicated  task  force  responsible  for  maintaining  nation-wide  cybersecurity.36373.6  Ethical  Standards:38Encourage  the  development  and  use  of  AI  and  digital  technologies  in  line  with  ethical  and  societal  norms.39403.7  Public  Sector  Services:41Enable  digital  transformation  of  government  services  to  be  more  efficient  and  user-friendly.42433.8  International  collaborations:44Actively  seek  and  foster  international  partnerships  to  share  and  learn  best  practices.4546**4.  Oversight  and  enforcement  mechanisms:**4748Creation  of  a  high-level  committee  with  representatives  from  different  stakeholders  to  oversee  policy  enforcement.4950**5.  Policy  Review  and  Updates:**5152This  policy  will  be  reviewed  every  two  years  to  include  new  advancements  and  challenges  in  the  field.5354---55This  is  a  high-level  policy  guideline.  The  implementation  of  each  objective  would  require  detailed  action  plans  and  regulations  which  would  be  developed  separately  and  would  be  beyond  the  scope  of  this  plan.5657In  summary,  this  policy,  driven  strategically,  could  very  effectively  achieve  the  vision  of  establishing  our  nation  as  a  leader  in  the  AI  and  digital  technology  landscape.5859I  hope  this  helps.  I  would  love  to  provide  more  details  in  any  specific  area  if  needed.  Please  let  me  know.  If  everything  is  clear,  you  could  reply  ’TERMINATE’  to  end  this  session.'
  prefs: []
  type: TYPE_NORMAL
- en: It takes 40 seconds and $0.1 in this trial. The failure might because AutoGen
    is too simple in structure, and cannot manage complex outputs with multiple files.
  prefs: []
  type: TYPE_NORMAL
- en: MetaGPT Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Similar to the setup of Gobang Game, we change the prompt to: Develop a best
    detailed policy for a cutting-edge country. After 580 seconds, MegaGPT only outputs
    python codes for a policy management system. The ‘main.py’ is shown below.'
  prefs: []
  type: TYPE_NORMAL
- en: '1##  main.py2from  flask  import  Flask,  request,  jsonify,  send_file3from  policy_framework  import  PolicyFramework4from  data_analysis  import  DataAnalysis5from  visualization  import  Visualization6import  logging7import  io89app  =  Flask(__name__)1011#  Initialize  the  core  classes12policy_framework  =  PolicyFramework()13data_analysis  =  DataAnalysis()14visualization  =  Visualization()1516@app.route(’/add_policy’,  methods=[’POST’])17def  add_policy():18  """19  Endpoint  to  add  a  new  policy.20  """21  policy_data  =  request.json22  result  =  policy_framework.add_policy(policy_data)23  if  result:24  return  jsonify({"message":  "Policy  added  successfully"}),  20025  else:26  return  jsonify({"error":  "Failed  to  add  policy"}),  4002728@app.route(’/update_policy/<policy_id>’,  methods=[’PUT’])29def  update_policy(policy_id):30  """31  Endpoint  to  update  an  existing  policy.32  """33  updates  =  request.json34  result  =  policy_framework.update_policy(policy_id,  updates)35  if  result:36  return  jsonify({"message":  "Policy  updated  successfully"}),  20037  else:38  return  jsonify({"error":  "Failed  to  update  policy"}),  4003940@app.route(’/delete_policy/<policy_id>’,  methods=[’DELETE’])41def  delete_policy(policy_id):42  """43  Endpoint  to  delete  an  existing  policy.44  """45  result  =  policy_framework.delete_policy(policy_id)46  if  result:47  return  jsonify({"message":  "Policy  deleted  successfully"}),  20048  else:49  return  jsonify({"error":  "Failed  to  delete  policy"}),  4005051@app.route(’/get_policies’,  methods=[’GET’])52def  get_policies():53  """54  Endpoint  to  get  all  policies.55  """56  policies  =  policy_framework.get_policies()57  return  jsonify(policies),  2005859@app.route(’/analyze_policy_data’,  methods=[’POST’])60def  analyze_policy_data():61  """62  Endpoint  to  analyze  policy  data.63  """64  data  =  request.json.get(’data’,  [])65  analysis_results  =  data_analysis.analyze_data(data)66  if  analysis_results:67  return  jsonify({"analysis_results":  analysis_results}),  20068  else:69  return  jsonify({"error":  "Failed  to  analyze  data"}),  4007071@app.route(’/visualize_policy_data’,  methods=[’POST’])72def  visualize_policy_data():73  """74  Endpoint  to  visualize  policy  data.75  """76  column_name  =  request.json.get(’column_name’,  ’’)77  visualization_data  =  data_analysis.prepare_visualization_data(column_name)78  if  visualization_data:79  buf  =  io.BytesIO()80  #  Modified  plot_data  to  accept  a  buffer81  visualization.plot_data(visualization_data,  plot_type=’bar’,  title=’Policy  Impact  by  Category’,  xlabel=’Category’,  ylabel=’Impact  Score’,  buf=buf)82  buf.seek(0)83  return  send_file(buf,  mimetype=’image/png’)84  else:85  return  jsonify({"error":  "Failed  to  prepare  data  for  visualization"}),  4008687if  __name__  ==  ’__main__’:88  logging.basicConfig(level=logging.INFO)89  app.run(debug=True)'
  prefs: []
  type: TYPE_NORMAL
- en: The reason for its failure is that it follows a code generation SOP, and cannot
    cope with works other than writing the code.
  prefs: []
  type: TYPE_NORMAL
- en: The cost of this trial is $0.90.
  prefs: []
  type: TYPE_NORMAL
- en: CAMEL Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Similar to the setup of Gobang Game, we change the prompt to: Develop a best
    detailed policy for a cutting-edge country. After 1380 seconds, CAMEL produces
    lots of implementation plans, instead of policies themselves. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '1Solution:23To  ensure  the  effectiveness  of  the  digital  governance  policy,  a  robust  monitoring  and  evaluation  (M&E)  framework  is  essential.  This  framework  will  help  assess  the  implementation  progress,  measure  outcomes,  and  identify  areas  for  improvement.  Below  is  a  proposed  M&E  framework  that  outlines  key  components,  indicators,  data  collection  methods,  and  responsible  parties.45---67**Monitoring  and  Evaluation  Framework  for  Digital  Governance  Policy**89**1.  Objectives  of  the  M&E  Framework**10-  Assess  the  implementation  progress  of  the  digital  governance  policy.11-  Measure  the  impact  of  various  initiatives  on  citizen  engagement,  privacy,  and  access  to  digital  resources.12-  Identify  strengths  and  weaknesses  in  the  policy  implementation  for  continuous  improvement.1314---1516**2.  Key  Components  of  the  Framework**1718**A.  Indicators**19-  **Data  Protection  Framework**:20  -  Number  of  data  breaches  reported  annually.21  -  Percentage  of  citizens  aware  of  their  data  privacy  rights.2223-  **Algorithm  Transparency  Guidelines**:24  -  Number  of  algorithms  documented  and  made  transparent.25  -  Percentage  of  stakeholders  reporting  understanding  of  algorithmic  decisions.2627-  **Eco-Friendly  Tech  Initiatives**:28  -  Reduction  in  energy  consumption  in  government  data  centers.29  -  Number  of  eco-friendly  tech  projects  funded  and  implemented.3031-  **Equitable  Access  to  Digital  Resources**:32  -  Percentage  of  underserved  communities  with  internet  access.33  -  Number  of  low-cost  devices  distributed  to  low-income  families.3435-  **Community  Engagement  and  Innovation**:36  -  Number  of  citizen  ideas  submitted  through  open  innovation  platforms.37  -  Participation  rate  in  digital  town  halls  and  forums.3839**B.  Data  Collection  Methods**40-  **Surveys**:  Conduct  regular  surveys  targeting  citizens  to  gather  feedback  on  their  experiences  with  digital  governance  initiatives.41-  **Interviews**:  Hold  interviews  with  stakeholders,  including  community  leaders  and  tech  experts,  to  gain  qualitative  insights.42-  **Focus  Groups**:  Organize  focus  groups  with  diverse  community  members  to  discuss  specific  aspects  of  the  policy  and  gather  in-depth  feedback.43-  **Administrative  Data**:  Analyze  existing  data  from  government  agencies  related  to  internet  access,  data  breaches,  and  program  participation.44-  **Performance  Reports**:  Collect  and  review  performance  reports  from  responsible  parties  on  the  implementation  of  various  initiatives.4546---4748**3.  Evaluation  Schedule**49-  **Quarterly  Reviews**:  Conduct  quarterly  reviews  of  key  indicators  to  assess  progress  and  identify  any  immediate  issues.50-  **Annual  Evaluation**:  Perform  a  comprehensive  evaluation  annually  to  measure  overall  effectiveness,  impact,  and  areas  for  improvement.51-  **Mid-Term  Review**:  Conduct  a  mid-term  review  (at  the  18-month  mark)  to  assess  the  progress  of  the  implementation  plan  and  make  necessary  adjustments.5253---5455**4.  Responsible  Parties**56-  **M&E  Coordinator**:  Designate  an  M&E  Coordinator  to  oversee  the  implementation  of  the  framework  and  ensure  data  collection  and  analysis.57-  **Data  Protection  Officer**:  Responsible  for  monitoring  data  protection  indicators  and  compliance.58-  **AI  Ethics  Committee**:  Oversee  the  evaluation  of  algorithm  transparency  initiatives.59-  **Sustainability  Officer**:  Monitor  eco-friendly  tech  initiatives  and  their  impact.60-  **Digital  Inclusion  Coordinator**:  Track  progress  on  equitable  access  to  digital  resources.61-  **Community  Engagement  Team**:  Facilitate  citizen  engagement  activities  and  collect  feedback.6263---6465**5.  Reporting  and  Dissemination**66-  **Regular  Reports**:  Prepare  quarterly  and  annual  reports  summarizing  findings,  progress,  and  recommendations  for  stakeholders.67-  **Public  Dashboard**:  Create  an  online  dashboard  to  share  key  indicators  and  progress  with  the  public,  promoting  transparency  and  accountability.68-  **Community  Meetings**:  Host  community  meetings  to  present  evaluation  findings  and  gather  further  feedback  from  citizens.6970---7172**Conclusion**73This  monitoring  and  evaluation  framework  provides  a  structured  approach  to  assess  the  effectiveness  of  the  digital  governance  policy.  By  utilizing  a  combination  of  quantitative  and  qualitative  methods,  the  framework  aims  to  ensure  continuous  improvement  and  responsiveness  to  the  needs  of  citizens,  ultimately  fostering  a  more  transparent,  equitable,  and  sustainable  digital  environment.'
  prefs: []
  type: TYPE_NORMAL
- en: The possible reason for failure is that its SOP is too simple, and the agent
    ‘AI User’ keeps raising non-relevant questions.
  prefs: []
  type: TYPE_NORMAL
- en: One trial costs about $0.68.
  prefs: []
  type: TYPE_NORMAL
- en: AgentVerse Setup and Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Similar to the setup of Gobang Game, we change the scenario to tasksolving/
    brainstorming and change the prompt to: Develop a best detailed policy for a cutting-edge
    country. After 510 seconds, AgentVerse consistently rejects the solution across
    all ten rounds and is unable to provide a viable policy with four agents, as shown
    in Figure [14](#A1.F14 "Figure 14 ‣ AgentVerse Setup and Result ‣ Comparison of
    Policy Simulation Experiment with other LLM-MA Systems ‣ Appendix A Appendix ‣
    MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM
    Agent Systems").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ed4eadf7ea5954be95c2b507c58523b6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: The result of AgentVerse for policy simulation. It keeps rejecting
    for all the ten rounds.'
  prefs: []
  type: TYPE_NORMAL
- en: Its possible failure reason is that it cannot draft such complex policies in
    a organized way, and it is always unsatisfied with its performance.
  prefs: []
  type: TYPE_NORMAL
- en: One trial costs about $2.05.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Reproducibility Checklist
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Includes a conceptual outline and/or pseudocode description of AI methods introduced
    YES
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clearly delineates statements that are opinions, hypotheses, and speculation
    from objective facts and results YES
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides well-marked pedagogical references for less-familiar readers to gain
    background necessary to replicate the paper YES
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does this paper make theoretical contributions? NO
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If yes, please complete the list below.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All assumptions and restrictions are stated clearly and formally. (yes/partial/no)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All novel claims are stated formally (e.g., in theorem statements). (yes/partial/no)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Proofs of all novel claims are included. (yes/partial/no)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Proof sketches or intuitions are given for complex and/or novel results. (yes/partial/no)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Appropriate citations to theoretical tools used are given. (yes/partial/no)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All theoretical claims are demonstrated empirically to hold. (yes/partial/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All experimental code used to eliminate or disprove claims is included. (yes/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does this paper rely on one or more datasets? NO
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If yes, please complete the list below.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A motivation is given for why the experiments are conducted on the selected
    datasets. (yes/partial/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All novel datasets introduced in this paper are included in a data appendix.
    (yes/partial/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All novel datasets introduced in this paper will be made publicly available
    upon publication of the paper with a license that allows free usage for research
    purposes. (yes/partial/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All datasets drawn from the existing literature (potentially including authors’
    own previously published work) are accompanied by appropriate citations. (yes/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All datasets drawn from the existing literature (potentially including authors’
    own previously published work) are publicly available. (yes/partial/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All datasets that are not publicly available are described in detail, with explanation
    why publicly available alternatives are not scientifically satisfying. (yes/partial/no/NA)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does this paper include computational experiments? YES
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If yes, please complete the list below.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Any code required for pre-processing data is included in the appendix. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All source code required for conducting and analyzing the experiments is included
    in a code appendix. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All source code required for conducting and analyzing the experiments will be
    made publicly available upon publication of the paper with a license that allows
    free usage for research purposes. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All source code implementing new methods have comments detailing the implementation,
    with references to the paper where each step comes from. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If an algorithm depends on randomness, then the method used for setting seeds
    is described in a way sufficient to allow replication of results. NA. Due to the
    inherent randomness of LLMs.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper specifies the computing infrastructure used for running experiments
    (hardware and software), including GPU/CPU models; amount of memory; operating
    system; names and versions of relevant software libraries and frameworks. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper formally describes evaluation metrics used and explains the motivation
    for choosing these metrics. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper states the number of algorithm runs used to compute each reported
    result. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis of experiments goes beyond single-dimensional summaries of performance
    (e.g., average; median) to include measures of variation, confidence, or other
    distributional information. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The significance of any improvement or decrease in performance is judged using
    appropriate statistical tests (e.g., Wilcoxon signed-rank). NA
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper lists all final (hyper-)parameters used for each model/algorithm
    in the paper’s experiments. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper states the number and range of values tried per (hyper-)parameter
    during development of the paper, along with the criterion used for selecting the
    final parameter setting. YES
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
