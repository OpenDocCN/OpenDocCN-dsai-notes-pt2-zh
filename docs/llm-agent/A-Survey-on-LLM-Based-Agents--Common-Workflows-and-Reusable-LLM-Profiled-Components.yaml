- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:45:07'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:45:07
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于基于LLM的智能体的调查：常见工作流程和可重用的LLM配置组件
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.05804](https://ar5iv.labs.arxiv.org/html/2406.05804)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.05804](https://ar5iv.labs.arxiv.org/html/2406.05804)
- en: Xinzhe Li
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Xinzhe Li
- en: School of IT, Deakin University, Australia
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 澳大利亚迪肯大学信息技术学院
- en: lixinzhe@deakin.edu.au
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: lixinzhe@deakin.edu.au
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recent advancements in Large Language Models (LLMs) have catalyzed the development
    of sophisticated frameworks for developing LLM-based agents. However, the complexity
    of these frameworks r poses a hurdle for nuanced differentiation at a granular
    level, a critical aspect for enabling efficient implementations across different
    frameworks and fostering future research. Hence, the primary purpose of this survey
    is to facilitate a cohesive understanding of diverse recently proposed frameworks
    by identifying common workflows and reusable LLM-Profiled Components (LMPCs).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）的进展推动了用于开发基于LLM的智能体的复杂框架的发展。然而，这些框架的复杂性在细粒度层面上造成了障碍，这是实现不同框架高效实施和促进未来研究的关键方面。因此，本次调查的主要目的是通过识别共同的工作流程和可重用的LLM配置组件（LMPCs），来促进对最近提出的各种框架的统一理解。
- en: 'A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 关于基于LLM的智能体的调查：常见工作流程和可重用的LLM配置组件
- en: Xinzhe Li School of IT, Deakin University, Australia lixinzhe@deakin.edu.au
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Xinzhe Li 澳大利亚迪肯大学信息技术学院 lixinzhe@deakin.edu.au
- en: '![Refer to caption](img/6bf7748a40c6d44bf2e54fbc8675ae89.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/6bf7748a40c6d44bf2e54fbc8675ae89.png)'
- en: (a) Policy-Only Workflows.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 仅政策工作流程。
- en: '![Refer to caption](img/6d50dbc6cf630a0fea8da76d86a89414.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/6d50dbc6cf630a0fea8da76d86a89414.png)'
- en: (b) Search Workflows.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 搜索工作流程。
- en: '![Refer to caption](img/d5c3508514f409c449f1ca3ba1228666.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d5c3508514f409c449f1ca3ba1228666.png)'
- en: (c) Feedback-Learning Workflows.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 反馈学习工作流程。
- en: 'Figure 1: Eight Common Workflows based on Three LLM-profiled Components (Policy,
    Evaluator and Dynamic Model) under Task or/and Tool-Use Environments.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：基于三种LLM配置组件（政策、评估器和动态模型）的八种常见工作流程，在任务或/和工具使用环境下。
- en: 1 Introduction
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Generative Large Language Models (GLMs or LLMs) have acquired extensive general
    knowledge and human-like reasoning capabilities (Santurkar et al., [2023](#bib.bib15);
    Wang et al., [2022](#bib.bib23); Zhong et al., [2022](#bib.bib33), [2023](#bib.bib32)),
    positioning them as pivotal in constructing AI agents known as LLM-based agents.
    In the context of this survey, LLM-based agents are defined by their ability to
    interact actively with external tools (such as Wikipedia) or environments (such
    as householding environments) and are designed to function as integral components
    of agency, including acting, planning, and evaluating.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型大型语言模型（GLMs或LLMs）已获得广泛的通用知识和类似人类的推理能力（Santurkar et al., [2023](#bib.bib15);
    Wang et al., [2022](#bib.bib23); Zhong et al., [2022](#bib.bib33), [2023](#bib.bib32)），使其在构建称为LLM基础的智能体的人工智能中占据关键地位。在本次调查中，LLM基础的智能体被定义为能够与外部工具（如维基百科）或环境（如家庭环境）进行积极互动的智能体，并被设计为代理的整体组成部分，包括行动、规划和评估。
- en: Purpose of the Survey
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调查目的
- en: 'The motivation behind this survey stems from the observation that many LLM-based
    agents incorporate similar workflows and components, despite the presence of a
    wide variety of technical and conceptual challenges, e.g., search algorithms (Yao
    et al., [2023a](#bib.bib29)), tree structures (Hao et al., [2023](#bib.bib7)),
    and Reinforcement Learning (RL) components (Shinn et al., [2023](#bib.bib16)).
    (Wu et al., [2023](#bib.bib27)) offer a modular approach but lack integration
    with prevalent agentic workflows. Wang et al. ([2024](#bib.bib21)) provide a comprehensive
    review of LLM agents, exploring their capabilities across profiling, memory, planning,
    and action. In contrast, our survey does not attempt to cover all components of
    LLM-based agents comprehensively. Instead, we concentrate on the involvement of
    LLMs within agentic workflows and aim to clarify the roles of LLMs in agent implementations.
    We create common workflows incorporating reusable LLM-Profiled Components (LMPCs),
    as depicted in Figure [1](#S0.F1 "Figure 1 ‣ A Survey on LLM-Based Agents: Common
    Workflows and Reusable LLM-Profiled Components").'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '本次调查的动机源于观察到，尽管存在各种技术和概念挑战，例如搜索算法（Yao et al., [2023a](#bib.bib29)），树形结构（Hao
    et al., [2023](#bib.bib7)），以及强化学习（RL）组件（Shinn et al., [2023](#bib.bib16)），许多基于LLM的代理仍然采用类似的工作流程和组件。（Wu
    et al., [2023](#bib.bib27)）提供了一种模块化的方法，但缺乏与流行代理工作流程的整合。Wang et al. ([2024](#bib.bib21))
    对LLM代理进行了全面的综述，探讨了它们在概况、记忆、规划和行动方面的能力。相比之下，我们的调查并未尝试全面覆盖基于LLM的代理的所有组件。相反，我们专注于LLM在代理工作流程中的参与，并旨在阐明LLM在代理实现中的角色。我们创建了包含可重用LLM-概况组件（LMPCs）的通用工作流程，如图
    [1](#S0.F1 "Figure 1 ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components") 所示。'
- en: Contributions
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 贡献
- en: 'This survey offers the following contributions. 1) Alleviating the understanding
    of complex frameworks: The complexity of existing frameworks can be simplified
    into implementable workflows, especially when they are extracted for specific
    tasks. This survey emphasizes reusable workflows and LMPCs across popular frameworks,
    such as ReAct (Yao et al., [2023b](#bib.bib30)), Reflexion (Shinn et al., [2023](#bib.bib16))
    and Tree-of-Thoughts (Yao et al., [2023a](#bib.bib29)). Specifically, based on
    the interaction environments (§[2](#S2 "2 Task Environments And Tool Environments
    ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components"))
    and the use of common LMPCs (§[3](#S3 "3 LLM-Profiled Components ‣ A Survey on
    LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components")), we
    categorize and detail various workflows, e.g., tool-use workflows, search workflows,
    and feedback-learning workflows. Many existing frameworks are composed of these
    workflows and LMPCs, along with some specific non-LLM components. 2) Helping researchers/practitioners
    assess current frameworks at a more granular and cohesive level: Section [4](#S4
    "4 Workflows of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components") categorizes prominent frameworks and demonstrates
    how they are assembled by the common workflows and LMPCs, as summarized in Table [2](#S3.T2
    "Table 2 ‣ Task-Dependent LLM-Profiled Components ‣ 3 LLM-Profiled Components
    ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components")
    ¹¹1A more detailed summarization is demonstrated in Appendix [A](#A1 "Appendix
    A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components"). 3) Facilitating further extensions of
    existing frameworks: Existing frameworks could be modified by changing the implementations
    of LMPCs. To enable this, we not only summarize implementations of LMPCs but also
    their applicability across diverse workflows and tasks in Section [5](#S5 "5 Implementations
    of LMPCs ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components").'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查提供了以下贡献。 1) 缓解对复杂框架的理解：现有框架的复杂性可以简化为可实施的工作流，尤其是当它们被提取用于特定任务时。本调查强调了可重用的工作流和LMPCs（大型语言模型配置组件），涵盖了流行的框架，如
    ReAct (Yao et al., [2023b](#bib.bib30))，Reflexion (Shinn et al., [2023](#bib.bib16))
    和 Tree-of-Thoughts (Yao et al., [2023a](#bib.bib29))。具体而言，基于交互环境 (§[2](#S2 "2
    任务环境与工具环境 ‣ 基于LLM的代理：常见工作流与可重用LLM配置组件的调查")) 和常见LMPCs的使用 (§[3](#S3 "3 LLM配置组件 ‣
    基于LLM的代理：常见工作流与可重用LLM配置组件的调查"))，我们对各种工作流进行了分类和详细描述，例如，工具使用工作流、搜索工作流和反馈学习工作流。许多现有框架由这些工作流和LMPCs
    以及一些特定的非LLM组件组成。2) 帮助研究人员/从业者以更细致和连贯的方式评估当前框架：第 [4](#S4 "4 基于LLM的代理的工作流 ‣ 基于LLM的代理：常见工作流与可重用LLM配置组件的调查")
    节对主要框架进行了分类，并演示了它们如何通过常见的工作流和LMPCs 组装，详见表 [2](#S3.T2 "表 2 ‣ 任务相关的LLM配置组件 ‣ 3 LLM配置组件
    ‣ 基于LLM的代理：常见工作流与可重用LLM配置组件的调查") ¹¹1 更详细的总结见附录 [A](#A1 "附录 A 基于LLM的代理的框架 ‣ 基于LLM的代理：常见工作流与可重用LLM配置组件的调查")。3)
    促进对现有框架的进一步扩展：现有框架可以通过改变LMPCs 的实现进行修改。为此，我们不仅总结了LMPCs 的实现，还总结了它们在各种工作流和任务中的适用性，第
    [5](#S5 "5 LMPCs 的实现 ‣ 基于LLM的代理：常见工作流与可重用LLM配置组件的调查") 节中进行了详细描述。
- en: '| Env Types | Entities Interacted With by Agent | Action Properties | Examples
    of Action Instances | Examples of Env Instances |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 环境类型 | 代理交互的实体 | 动作属性 | 动作实例示例 | 环境实例示例 |'
- en: '| Task Environments |  |  |  |  |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 任务环境 |  |  |  |  |'
- en: '| Gaming Environments | Virtual game elements (objects, avatars, other characters),
    and possibly other players or game narratives | Discrete, Executable,'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '| 游戏环境 | 虚拟游戏元素（对象、化身、其他角色），可能还有其他玩家或游戏叙事 | 离散，可执行，'
- en: Deterministic | Move(Right) | BlocksWorld, CrossWords |
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性 | 移动（右） | BlocksWorld, CrossWords |
- en: '| Embodied Environments | Physical world (through sensors and actuators) |
    Discrete, Executable,'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '| 具身环境 | 物理世界（通过传感器和执行器） | 离散，可执行，'
- en: Deterministic | Pick_Up[Object] | AlfWorld (Shridhar et al., [2021](#bib.bib17)),
    VirtualHome,
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性 | 拾取_对象 | AlfWorld (Shridhar et al., [2021](#bib.bib17))，VirtualHome,
- en: Minecraft (Fan et al., [2022](#bib.bib3)) |
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Minecraft (Fan et al., [2022](#bib.bib3)) |
- en: '| NLIEs | Humans (through conversation or text) | Free-form, Discrete,'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '| NLIEs | 人类（通过对话或文本） | 自由形式，离散，'
- en: Deterministic
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性
- en: (Single-step QA)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: （单步骤问答）
- en: Stochastic
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 随机
- en: (Multi-step) | The answer is Answer Finish[Answer] | GSM8K, HotpotQA |
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: (多步骤) | 答案是 Answer Finish[Answer] | GSM8K, HotpotQA |
- en: '| Tool Environments ( Nested with Task Environments) |  |  |  |  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 工具环境（嵌套在任务环境中） |  |  |  |  |'
- en: '| Retrieval | Retrieval | Discrete, Executable,'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '| 检索 | 检索 | 离散，可执行，'
- en: Deterministic,
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性，
- en: Non-State-Altering | Wiki_Search[Entity] | A Wikipedia API (Goldsmith, [2023](#bib.bib4))
    (used by ReAct (Yao et al., [2023b](#bib.bib30))) |
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 非状态改变 | Wiki_Search[实体] | 一个 Wikipedia API (Goldsmith，[2023](#bib.bib4))（由 ReAct
    (Yao 等，[2023b](#bib.bib30))) 使用）|
- en: '| Calculator | Calculator | Executable, Deterministic,'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '| 计算器 | 计算器 | 可执行，确定性，'
- en: Non-State-Altering | 2 x 62 = << Calculator >> | Python’s eval function (used
    by MultiTool-CoT (Inaba et al., [2023](#bib.bib9))) |
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 非状态改变 | 2 x 62 = << 计算器 >> | Python 的 eval 函数（由 MultiTool-CoT (Inaba 等，[2023](#bib.bib9)))
    使用）|
- en: 'Table 1: Common task environments and tool-use environments. We categorize
    all the benchmarks existing in the work of the 12 agentic workflows into four
    environment types. An action instance is commonly formalized by action predicates
    and action arguments. Tool use can be considered internal environments of an agent
    and commonly defined for QA tasks under NLIEs.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1：常见任务环境和工具使用环境。我们将 12 个代理工作流中的所有基准分类为四种环境类型。一个行动实例通常通过行动谓词和行动参数形式化。工具使用可以被视为代理的内部环境，并且通常在
    NLIEs 下为 QA 任务定义。 '
- en: 2 Task Environments And Tool Environments
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 任务环境与工具环境
- en: 'This section explores task environments and tool environments, which present
    different settings compared to traditional AI and reinforcement learning (RL)
    agent frameworks (Russell and Norvig, [2010](#bib.bib14); Sutton and Barto, [2018](#bib.bib18))
    . After a brief overview of standard logic-based gaming and simulated embodied
    environments, we focus on two specific areas: Natural Language Interaction Environments
    (NLIEs) and Tool Environments.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了任务环境和工具环境，这些环境相比于传统的 AI 和强化学习（RL）代理框架（Russell 和 Norvig，[2010](#bib.bib14);
    Sutton 和 Barto，[2018](#bib.bib18)）展示了不同的设置。在简要概述了基于逻辑的游戏和模拟具身环境后，我们专注于两个特定领域：自然语言交互环境（NLIEs）和工具环境。
- en: 2.1 Typical Task Environments
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 典型任务环境
- en: 'Typically, there are two common types of task environments: 1) Rule-Based Gaming
    Environments: These environments, which are deterministic and fully observable,
    include a variety of abstract strategy games like Chess and Go, and logic puzzles
    such as the Game of 24 (Yao et al., [2023a](#bib.bib29)) and Blocksworld (Hao
    et al., [2023](#bib.bib7)). They demand deep logical reasoning and strategic planning
    to navigate and solve. 2) Simulated Embodied Environments: These settings simulate
    real-world physical interactions and spatial relationships. They require agents
    to engage in navigation, object manipulation, and other complex physical tasks,
    reflecting changes in the physical environment.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，任务环境有两种常见类型：1) 基于规则的游戏环境：这些环境是确定性且完全可观察的，包括各种抽象策略游戏，如国际象棋和围棋，以及逻辑谜题，如 24
    点游戏（Yao 等，[2023a](#bib.bib29)）和 Blocksworld（Hao 等，[2023](#bib.bib7)）。它们要求进行深度逻辑推理和战略规划。2)
    模拟具身环境：这些设置模拟现实世界的物理互动和空间关系。它们要求代理进行导航、物体操作和其他复杂的物理任务，反映了物理环境的变化。
- en: 2.2 Natural Language Interaction Environments
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 自然语言交互环境
- en: With the rise of LLM agents, there is a growing trend among NLP researchers
    to recontextualize typical NLP tasks as agentic environments (Yao et al., [2023b](#bib.bib30);
    Hao et al., [2023](#bib.bib7); Yao et al., [2023a](#bib.bib29)). These settings
    are referred to as Natural Language Interaction Environments in our survey.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 LLM 代理的兴起，NLP 研究人员越来越倾向于将典型的 NLP 任务重新定义为代理环境（Yao 等，[2023b](#bib.bib30); Hao
    等，[2023](#bib.bib7); Yao 等，[2023a](#bib.bib29)）。这些设置在我们的调查中被称为自然语言交互环境。
- en: In NLIEs, the environment remains static until the agent acts. Unlike typical
    task environments where natural language serves as an intermediary, in NLIEs,
    both the states and actions are defined linguistically, making the states conceptual
    and the actions often ambiguous and broadly defined.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在 NLIEs 中，环境在代理采取行动之前保持静态。与典型的任务环境中自然语言作为中介不同，在 NLIEs 中，状态和行动都是用语言定义的，使得状态是概念性的，行动通常是模糊和广泛定义的。
- en: Single-Step NLIEs for Question Answering
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 单步 NLIEs 用于问题回答
- en: Many works (Yao et al., [2023b](#bib.bib30); Shinn et al., [2023](#bib.bib16))
    formulate the traditional QA setup as a single-step decision-making process, where
    the agent generates an answer in response to a question. The process starts with
    the question as the initial state and concludes when the answer is provided as
    an action.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究（Yao et al., [2023b](#bib.bib30); Shinn et al., [2023](#bib.bib16)）将传统的问答设置表述为一个单步骤决策过程，其中代理生成一个回答来回应一个问题。这个过程以问题作为初始状态开始，并在提供答案作为行动时结束。
- en: Deliberate Multi-step NLIEs
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 深思熟虑的多步骤自然语言推理（NLIE）
- en: For tasks where "intermediate steps are not explicitly defined", several studies
    have transformed NLP tasks into a Markov Decision Process to facilitate agentic
    workflows. For example, Hao et al. ([2023](#bib.bib7)) reformulate subquestions
    in QA tasks as actions, enabling responses to user queries through a multi-step
    process. This approach allows the initial question to serve as the beginning of
    a series of state transitions. Actions may vary from providing direct, free-form
    answers in single-step QA to strategically formulating subquestions that navigate
    the agent through sequential updates toward a comprehensive solution. This method
    aligns more closely with a sequential decision-making process, making it apt for
    deployment in planning-based agent systems. Additionally, Wan et al. ([2024](#bib.bib20))
    suggest that "splitting an output sequence into tokens might be a good choice"
    for defining multi-step NLIEs methodically. Furthermore, Yao et al. ([2023a](#bib.bib29))
    formulate two-step NLIEs for creative writing by segmenting the problem-solving
    process into distinct planning and execution phases.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“中间步骤没有明确定义”的任务，一些研究将自然语言处理（NLP）任务转化为马尔可夫决策过程，以促进代理工作流。例如，Hao et al. ([2023](#bib.bib7))
    将问答任务中的子问题重新表述为行动，通过多步骤过程来回应用户查询。这种方法允许初始问题作为一系列状态转移的开始。行动可能从在单步骤问答中提供直接的自由形式答案，到战略性地制定子问题，使代理通过顺序更新导航到一个全面的解决方案。这种方法更接近于序列决策过程，使其适用于规划基础的代理系统。此外，Wan
    et al. ([2024](#bib.bib20)) 建议“将输出序列拆分为标记可能是一个好的选择”，以系统地定义多步骤NLIE。此外，Yao et al.
    ([2023a](#bib.bib29)) 通过将问题解决过程划分为不同的规划和执行阶段，制定了用于创作写作的两步骤NLIE。
- en: 2.3 Tool Environments
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 工具环境
- en: Modern LLM agents are often enhanced with external tools that improve their
    problem-solving capabilities (Inaba et al., [2023](#bib.bib9); Yao et al., [2023b](#bib.bib30)).
    The design and integration of these tools add complexity, requiring careful consideration
    of how LLMs interact not only with the task environments but also with these auxiliary
    tools. Typically, actions in tool environments involve interactions with resources
    that remain unaffected by these interactions. For instance, retrieving data from
    Wikipedia constitutes a "read-only" action, which does not modify the Wikipedia
    database. This feature distinguishes such tool-use actions from those in conventional
    task environments or typical reinforcement learning (RL) settings, where actions
    generally alter the environmental state. Nevertheless, it is important to recognize
    that tool environment can be dynamic that can undergo changes externally. This
    aspect reflects the nature that tools should be considered external environments
    rather than the agent’s internal processes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现代大型语言模型（LLM）代理通常通过外部工具来增强其解决问题的能力（Inaba et al., [2023](#bib.bib9); Yao et al.,
    [2023b](#bib.bib30)）。这些工具的设计和集成增加了复杂性，需要仔细考虑LLM如何不仅与任务环境互动，还与这些辅助工具互动。通常，工具环境中的行动涉及与资源的互动，而这些资源不受这些互动的影响。例如，从维基百科检索数据构成一个“只读”操作，这不会修改维基百科数据库。这一特征将此类工具使用行动与传统任务环境或典型强化学习（RL）设置中的行动区分开来，后者中的行动通常会改变环境状态。然而，重要的是要认识到工具环境可能是动态的，可能会发生外部变化。这一方面反映了工具应该被视为外部环境，而不是代理的内部过程。
- en: Nested NLIE-QA + Tool Environments
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 嵌套的NLIE-QA + 工具环境
- en: Tool environments are frequently established along with NLIEs to aid in solving
    QA tasks. Shinn et al. ([2023](#bib.bib16)); Yao et al. ([2023b](#bib.bib30))
    incorporate tools to enhance the factuality of responses. They define command-like
    actions such as “Search” and “LookUp” to interact with Wikipedia, with “Search”
    suggesting the top-5 similar entities from the relevant wiki page, and “LookUp”
    simulating the Ctrl+F functionality in a browser. Beyond simple retrieval, Thoppilan
    et al. ([2022](#bib.bib19)) include a language translator and a calculator for
    dialog tasks. Similarly, Inaba et al. ([2023](#bib.bib9)) employ a calculator,
    implemented using the Python eval function, to resolve numerical queries within
    the NumGLUE benchmark.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 工具环境通常与 NLIEs 一起建立，以帮助解决 QA 任务。Shinn 等（[2023](#bib.bib16)）；Yao 等（[2023b](#bib.bib30)）引入了工具来增强响应的真实性。他们定义了类似命令的操作，如“搜索”和“查找”，以与维基百科互动，其中“搜索”从相关维基页面中建议前
    5 个类似实体，而“查找”则模拟浏览器中的 Ctrl+F 功能。除了简单的检索外，Thoppilan 等（[2022](#bib.bib19)）还包括了用于对话任务的语言翻译器和计算器。同样，Inaba
    等（[2023](#bib.bib9)）使用 Python eval 函数实现的计算器来解决 NumGLUE 基准中的数值查询。
- en: 3 LLM-Profiled Components
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 LLM-配置组件
- en: This section explores common agentic roles for which LLMs are typically profiled.
    The components leverage the internal commonsense knowledge and reasoning abilities
    of LLMs to generate actions, plans, estimate values ²²2Values refer to the estimated
    rewards (a quantitative measure of the success or desirability of the outcomes)
    associated with taking a certain action in a state, widely used in typical RL
    and MDP settings to learn policy models that perform desirable behaviors., and
    infer subsequent states.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了 LLM 通常配置的常见代理角色。这些组件利用 LLM 的内部常识知识和推理能力来生成行动、计划、估计值²²2值指的是在某一状态下采取特定行动所估计的奖励（对结果的成功或期望的定量衡量），广泛用于典型的
    RL 和 MDP 设置中，以学习执行期望行为的策略模型。以及推断后续状态。
- en: Universal LLM-Profiled Components
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通用 LLM-配置组件
- en: Specifically, the following task-agnostic components are profiled and commonly
    used across various workflows. *1) LLM-Profiled Policy $\text{glm}_{\text{policy}}$.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，以下任务无关组件是经过配置并广泛用于各种工作流程中的。*1）LLM-配置策略 $\text{glm}_{\text{policy}}$。
- en: Task-Dependent LLM-Profiled Components
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 任务相关的 LLM-配置组件
- en: In addition to the universal components, certain LLM-profiled components are
    tailored to specific tasks. For instance, verbalizers are crucial in embodied
    environments but unnecessary in NLIEs. A verbalizer translates actions and observations
    into inputs for planners; for example, in the Planner-Actor-Reporter workflow
    (Wang et al., [2023a](#bib.bib22)), a fine-tuned Visual Language Model (VLM) along
    with $\text{glm}_{\text{planner}}$ (Shinn et al., [2023](#bib.bib16)), often guide
    descriptions according to specified criteria.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通用组件外，某些 LLM-配置组件被量身定制以适应特定任务。例如，语言生成器在体现环境中至关重要，但在 NLIEs 中则不必要。语言生成器将行动和观察转换为规划器的输入；例如，在
    Planner-Actor-Reporter 工作流程中（Wang 等，[2023a](#bib.bib22)），经过微调的视觉语言模型（VLM）与 $\text{glm}_{\text{planner}}$（Shinn
    等，[2023](#bib.bib16)）通常根据指定的标准指导描述。
- en: '| Workflows | Related Frameworks | LMPCs | Applicable Environments |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 工作流程 | 相关框架 | LMPCs | 适用环境 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Policy-only | Base | LLM Planner (Huang et al., [2022](#bib.bib8)), DEPS
    (Wang et al., [2023b](#bib.bib24)), Planner-Actor-Reporter (Dasgupta et al., [2022](#bib.bib2)),
    Plan-and-solve (Wang et al., [2023a](#bib.bib22)), ReAct (Yao et al., [2023b](#bib.bib30))
    | $\text{glm}_{\text{planner}}$ (Optional for Embodied Env),'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '| 仅政策 | 基础 | LLM 规划器（Huang 等，[2022](#bib.bib8)），DEPS（Wang 等，[2023b](#bib.bib24)），Planner-Actor-Reporter（Dasgupta
    等，[2022](#bib.bib2)），Plan-and-solve（Wang 等，[2023a](#bib.bib22)），ReAct（Yao 等，[2023b](#bib.bib30)）
    | $\text{glm}_{\text{planner}}$（适用于 Embodied Env 的可选组件），'
- en: $\text{glm}_{\text{verbalizer}}$ (Optional for Embodied Env) | Embodied Env,
    NLIEs-Writing, NLIE-QA |
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: $\text{glm}_{\text{verbalizer}}$（适用于 Embodied Env 的可选组件） | Embodied Env，NLIEs-写作，NLIE-QA
    |
- en: '|  | Tool-Use | MultiTool-CoT (Inaba et al., [2023](#bib.bib9)), ReAct (Yao
    et al., [2023b](#bib.bib30)), Reflexion (Shinn et al., [2023](#bib.bib16)) | $\text{glm}_{\text{actor}}$
    | NLIEs |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '|  | 工具使用 | MultiTool-CoT（Inaba 等，[2023](#bib.bib9)），ReAct（Yao 等，[2023b](#bib.bib30)），Reflexion（Shinn
    等，[2023](#bib.bib16)） | $\text{glm}_{\text{actor}}$ | NLIEs |'
- en: '| Search | Traversal & Heuristic | Tree-of-Thoughts (ToT) (Yao et al., [2023a](#bib.bib29)),
    Tree-BeamSearch (Xie et al., [2023](#bib.bib28)), Boost-of-Thoughts (Chen et al.,
    [2024](#bib.bib1)) | $\text{glm}_{\text{actor}}$ | Gaming, NLIEs-Writing, NLIE-QA
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 搜索 | 遍历与启发式 | 思维树（ToT）(Yao et al., [2023a](#bib.bib29)), 树形束搜索 (Xie et al.,
    [2023](#bib.bib28)), 思维提升 (Chen et al., [2024](#bib.bib1)) | $\text{glm}_{\text{actor}}$
    | 游戏，NLIEs-写作，NLIE-QA |'
- en: '|  | MCTS | RAP (Hao et al., [2023](#bib.bib7)), Wan et al. ([2024](#bib.bib20))
    | $\text{glm}_{\text{actor}}$ | Gaming, NLIEs-QA |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|  | MCTS | RAP (Hao et al., [2023](#bib.bib7)), Wan et al. ([2024](#bib.bib20))
    | $\text{glm}_{\text{actor}}$ | 游戏，NLIEs-QA |'
- en: '| Feedback Learning | from $\text{glm}_{\text{eval}}$ | NLIEs-QA |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 反馈学习 | 来源于 $\text{glm}_{\text{eval}}$ | NLIEs-QA |'
- en: '|  | from $\text{glm}_{\text{eval}}$ | Embodied Env |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|  | 来源于 $\text{glm}_{\text{eval}}$ | 具身环境 |'
- en: '|  | from Tools & Humans | Guan et al. ([2023](#bib.bib6)) | $\text{glm}_{\text{planner}}$
    | Embodied Env |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|  | 来源于工具与人类 | Guan et al. ([2023](#bib.bib6)) | $\text{glm}_{\text{planner}}$
    | 具身环境 |'
- en: '|  | from Tools & $\text{glm}_{\text{eval}}$ | NLIEs |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '|  | 来源于工具与 $\text{glm}_{\text{eval}}$ | NLIEs |'
- en: 'Table 2: Workflows of LLM-Based Agents and Related Frameworks. We summarize
    LLM-Profiled Components (LMPCs) and applicable environments based on the original
    papers of the listed frameworks, although other possibilities exist, e.g., using
    $\text{glm}_{\text{planner}}$ within the tool-use workflow and applying the base
    workflow to gaming environments.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：基于LLM的智能体工作流及相关框架。我们根据所列框架的原始论文总结了LLM配置组件（LMPCs）和适用环境，尽管还存在其他可能性，例如在工具使用工作流中使用
    $\text{glm}_{\text{planner}}$ 和将基础工作流应用于游戏环境。
- en: 4 Workflows of LLM-Based Agents
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 基于LLM的智能体工作流
- en: 'This section explores different workflows and the utilization of various LLM-Profiled
    Components (LMPCs), as illustrated in Figure [1](#S0.F1 "Figure 1 ‣ A Survey on
    LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components"). Specifically,
    we will aggregate proposed frameworks based on workflow types, as demonstrated
    in Table [2](#S3.T2 "Table 2 ‣ Task-Dependent LLM-Profiled Components ‣ 3 LLM-Profiled
    Components ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components"). This section delves into diverse workflows and the application of
    distinct LLM-Profiled Components (LMPCs), as visualized in Figure [1](#S0.F1 "Figure
    1 ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components").
    We categorize and consolidate the related frameworks according to the workflows,
    exemplified in Table [2](#S3.T2 "Table 2 ‣ Task-Dependent LLM-Profiled Components
    ‣ 3 LLM-Profiled Components ‣ A Survey on LLM-Based Agents: Common Workflows and
    Reusable LLM-Profiled Components"). It is noteworthy that one framework could
    employ distinct workflows according to tasks or environments. More details of
    the frameworks are summarized in Appendix [A](#A1 "Appendix A Frameworks of LLM-Based
    Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components").'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了不同的工作流和各种LLM配置组件（LMPCs）的使用，如图[1](#S0.F1 "图 1 ‣ 基于LLM的智能体调查：常见工作流和可重用的LLM配置组件")所示。具体而言，我们将根据工作流类型汇总提议的框架，如表[2](#S3.T2
    "表 2 ‣ 任务依赖的LLM配置组件 ‣ 3 LLM配置组件 ‣ 基于LLM的智能体调查：常见工作流和可重用的LLM配置组件")中所示。本节深入探讨了多种工作流和不同LLM配置组件（LMPCs）的应用，如图[1](#S0.F1
    "图 1 ‣ 基于LLM的智能体调查：常见工作流和可重用的LLM配置组件")所示。我们根据工作流对相关框架进行分类和整合，如表[2](#S3.T2 "表 2
    ‣ 任务依赖的LLM配置组件 ‣ 3 LLM配置组件 ‣ 基于LLM的智能体调查：常见工作流和可重用的LLM配置组件")所示。值得注意的是，一个框架可能会根据任务或环境使用不同的工作流。更多框架的详细信息总结在附录[A](#A1
    "附录 A 基于LLM的智能体框架 ‣ 基于LLM的智能体调查：常见工作流和可重用的LLM配置组件")中。
- en: 4.1 Policy-Only Workflows
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 仅政策工作流
- en: Base and tool-use workflows only require LLMs to be profiled as policy models.
    In the realm of embodied tasks, many projects deploy base workflows with $\text{glm}_{\text{planner}}$
    is always applied to NLIEs like ReAct (Yao et al., [2023b](#bib.bib30)), Reflexion
    (Shinn et al., [2023](#bib.bib16)), and MultiTool-CoT (Inaba et al., [2023](#bib.bib9)).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 基础和工具使用工作流仅需要将LLM配置为政策模型。在具身任务领域，许多项目部署基础工作流，其中$\text{glm}_{\text{planner}}$通常应用于如ReAct
    (Yao et al., [2023b](#bib.bib30)), Reflexion (Shinn et al., [2023](#bib.bib16)),
    和MultiTool-CoT (Inaba et al., [2023](#bib.bib9))等NLIEs。
- en: 4.2 Search Workflows
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 搜索工作流
- en: Unlike base agents with $\text{glm}_{\text{planner}}$, which generates a sequence
    of actions for a plan at one generation, actions in search workflows are organized
    into tree (Yao et al., [2023a](#bib.bib29); Hao et al., [2023](#bib.bib7)) and
    graph (Liu et al., [2023](#bib.bib11)) for exploration. Planning or search algorithms
    can explore sequential decisions in a non-linear manner. During the process, the
    tree (or solution) is constructed by adding nodes, each representing a partial
    solution with the input and the sequence of thoughts/actions so far. Data structures
    such as trees enable strategic searches over actions derived from multiple reasoning
    paths. This is accomplished using algorithms like beam search (Xie et al., [2023](#bib.bib28)),
    depth-first and breadth-first search (DFS and BFS) (Yao et al., [2023a](#bib.bib29)),
    and Monte-Carlo Tree Search (MCTS) (Hao et al., [2023](#bib.bib7)).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 与生成一个计划的基本代理 $\text{glm}_{\text{planner}}$ 不同，搜索工作流中的动作被组织成树（Yao et al., [2023a](#bib.bib29);
    Hao et al., [2023](#bib.bib7)）和图（Liu et al., [2023](#bib.bib11)）进行探索。规划或搜索算法可以以非线性方式探索顺序决策。在此过程中，树（或解决方案）通过添加节点来构建，每个节点代表一个部分解决方案，包括输入和目前的思路/动作序列。树等数据结构使得可以在从多个推理路径得出的动作上进行策略性搜索。这是通过使用诸如束搜索（Xie
    et al., [2023](#bib.bib28)）、深度优先和广度优先搜索（DFS 和 BFS）（Yao et al., [2023a](#bib.bib29)）以及蒙特卡罗树搜索（MCTS）（Hao
    et al., [2023](#bib.bib7)）等算法实现的。
- en: Generally, LMPCs are used to explore the path towards the goal. Instead of directly
    applying actions on external environments within policy-only workflows, $\text{glm}_{\text{policy}}$
    is used to calculate values for action/state evaluation during exploration (Yao
    et al., [2023a](#bib.bib29); Chen et al., [2024](#bib.bib1)) or as a reward model
    (Hao et al., [2023](#bib.bib7)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，LMPCs 用于探索达到目标的路径。在仅使用策略的工作流中，$\text{glm}_{\text{policy}}$ 用于计算在探索过程中对动作/状态的评估值（Yao
    et al., [2023a](#bib.bib29); Chen et al., [2024](#bib.bib1)），或作为奖励模型（Hao et al.,
    [2023](#bib.bib7)）。
- en: Search via Traversal and Heuristic
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过遍历和启发式搜索
- en: The Tree-of-Thoughts (ToT) workflow (Yao et al., [2023a](#bib.bib29)) uses $\text{glm}_{\text{policy}}$
    most promising nodes. ⁴⁴4Typically, BFS does not use a utility model to decide
    which nodes to expand because it systematically explores all possible nodes at
    each depth.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 思维树（ToT）工作流（Yao et al., [2023a](#bib.bib29)）使用 $\text{glm}_{\text{policy}}$
    最有前景的节点。⁴⁴4通常，BFS 不使用效用模型来决定扩展哪些节点，因为它系统地探索每一层的所有可能节点。
- en: Simulated-Based Search via MCTS
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于模拟的搜索通过 MCTS
- en: The RAP workflow (Hao et al., [2023](#bib.bib7)) also builds a tree through
    searching and includes $\text{glm}_{\text{policy}}$, iteratively simulating the
    trajectory.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: RAP 工作流（Hao et al., [2023](#bib.bib7)）也通过搜索建立树，并包含 $\text{glm}_{\text{policy}}$，迭代地模拟轨迹。
- en: 4.3 Feedback-Learning Workflows
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 反馈学习工作流
- en: 'There are primarily four main sources of feedback: $\text{glm}_{\text{eval}}$
    (internal feedback), humans, task environments, and tools.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有四种反馈来源：$\text{glm}_{\text{eval}}$（内部反馈）、人类、任务环境和工具。
- en: Reflexion (Shinn et al., [2023](#bib.bib16)) and Self-Refine (Madaan et al.,
    [2023](#bib.bib12)) utilize $\text{glm}_{\text{eval}}$, as noted by the workflow
    from Guan et al. ([2023](#bib.bib6)).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Reflexion（Shinn et al., [2023](#bib.bib16)）和 Self-Refine（Madaan et al., [2023](#bib.bib12)）利用
    $\text{glm}_{\text{eval}}$，正如 Guan et al.（[2023](#bib.bib6)）的工作流所指出的。
- en: '|  | Prompting | Example Works | Example Prompts (in Appendix) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | 提示 | 示例有效性 | 示例提示（见附录） |'
- en: '| $\text{glm}_{\text{actor}}$ | Few-shot | ReAct (Yao et al., [2023b](#bib.bib30)),
    Reflexion (Shinn et al., [2023](#bib.bib16)), RAP (Hao et al., [2023](#bib.bib7)),
    MultiTool-CoT (Inaba et al., [2023](#bib.bib9)) | Table [8](#A1.T8 "Table 8 ‣
    Appendix A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common
    Workflows and Reusable LLM-Profiled Components"), [10](#A1.T10 "Table 10 ‣ Appendix
    A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components") |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| $\text{glm}_{\text{actor}}$ | 少量示例 | ReAct (Yao et al., [2023b](#bib.bib30)),
    Reflexion (Shinn et al., [2023](#bib.bib16)), RAP (Hao et al., [2023](#bib.bib7)),
    MultiTool-CoT (Inaba et al., [2023](#bib.bib9)) | 表 [8](#A1.T8 "Table 8 ‣ 附录 A
    基于 LLM 的代理框架 ‣ LLM 基于代理的调查：常见工作流和可重用的 LLM 配置组件")， [10](#A1.T10 "Table 10 ‣ 附录
    A 基于 LLM 的代理框架 ‣ LLM 基于代理的调查：常见工作流和可重用的 LLM 配置组件") |'
- en: '| $\text{glm}_{\text{planner}}$ | Zero-shot | Plan-and-Solve (Wang et al.,
    [2023a](#bib.bib22)), LLM Planner (Huang et al., [2022](#bib.bib8)) | Table [6](#A1.T6
    "Table 6 ‣ Appendix A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents:
    Common Workflows and Reusable LLM-Profiled Components") |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| $\text{glm}_{\text{planner}}$ | 零-shot | 计划与解决（Wang 等， [2023a](#bib.bib22)），LLM
    规划器（Huang 等， [2022](#bib.bib8)） | 表 [6](#A1.T6 "表 6 ‣ 附录 A 基于 LLM 的代理框架 ‣ 关于基于
    LLM 的代理的调查：常见工作流程和可重用的 LLM 配置组件") |'
- en: '|  | Few-shot | DEPS (Wang et al., [2023b](#bib.bib24)), Planner-Actor-Reporter
    (Dasgupta et al., [2022](#bib.bib2)) |  |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | 少-shot | DEPS（Wang 等， [2023b](#bib.bib24)），规划者-演员-报告者（Dasgupta 等， [2022](#bib.bib2)）
    |  |'
- en: '| $\text{glm}_{\text{evaluator}}$ | Few-shot | RAP (Hao et al., [2023](#bib.bib7)),
    Tree-BeamSearch (Xie et al., [2023](#bib.bib28)), Reflexion (Shinn et al., [2023](#bib.bib16)),
    CRITIC (Gou et al., [2024](#bib.bib5)) | Table [12](#A2.T12 "Table 12 ‣ B.2 Prompts
    for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based Agents:
    Common Workflows and Reusable LLM-Profiled Components"), [13](#A2.T13 "Table 13
    ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based
    Agents: Common Workflows and Reusable LLM-Profiled Components") |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| $\text{glm}_{\text{evaluator}}$ | 少-shot | RAP（Hao 等， [2023](#bib.bib7)），树-光束搜索（Xie
    等， [2023](#bib.bib28)），反思（Shinn 等， [2023](#bib.bib16)），CRITIC（Gou 等， [2024](#bib.bib5)）
    | 表 [12](#A2.T12 "表 12 ‣ B.2 LLM 评估器的提示 ‣ 附录 B 示例提示 ‣ 关于基于 LLM 的代理的调查：常见工作流程和可重用的
    LLM 配置组件")， [13](#A2.T13 "表 13 ‣ B.2 LLM 评估器的提示 ‣ 附录 B 示例提示 ‣ 关于基于 LLM 的代理的调查：常见工作流程和可重用的
    LLM 配置组件") |'
- en: '| $\text{glm}_{\text{dynamic}}$ | Few-shot | RAP (Hao et al., [2023](#bib.bib7))
    | Table [16](#A2.T16 "Table 16 ‣ B.3 Prompts as Dynamic Models ‣ Appendix B Examples
    Prompts ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components") |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| $\text{glm}_{\text{dynamic}}$ | 少-shot | RAP（Hao 等， [2023](#bib.bib7)） |
    表 [16](#A2.T16 "表 16 ‣ B.3 作为动态模型的提示 ‣ 附录 B 示例提示 ‣ 关于基于 LLM 的代理的调查：常见工作流程和可重用的
    LLM 配置组件") |'
- en: 'Table 3: Prompting Methods of LLM-Profiled Components'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：LLM 配置组件的提示方法
- en: '| Task Formulation | Feedback Types | Applicable Workflows | Example Works
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 任务制定 | 反馈类型 | 适用工作流程 | 示例工作 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Text Generation | Free-form reflection | Feedback-learning workflows | Self-Refine
    (Madaan et al., [2023](#bib.bib12)), Reflexion (Shinn et al., [2023](#bib.bib16)),
    CRITIC (Gou et al., [2024](#bib.bib5)) |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 文本生成 | 自由形式反思 | 反馈学习工作流程 | 自我精炼（Madaan 等， [2023](#bib.bib12)），反思（Shinn 等，
    [2023](#bib.bib16)），CRITIC（Gou 等， [2024](#bib.bib5)） |'
- en: '| Binary/Multi-class Classification | Discrete values | Search workflows |
    RAP (Hao et al., [2023](#bib.bib7)), Tree-BeamSearch (Xie et al., [2023](#bib.bib28))
    ToT (Yao et al., [2023a](#bib.bib29)) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 二元/多类分类 | 离散值 | 搜索工作流程 | RAP（Hao 等， [2023](#bib.bib7)），树-光束搜索（Xie 等， [2023](#bib.bib28)）ToT（Yao
    等， [2023a](#bib.bib29)） |'
- en: '| Binary Classification | Continuous values (logits) | Search workflow via
    MCTS | RAP (Hao et al., [2023](#bib.bib7)) |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 二元分类 | 连续值（logits） | 通过 MCTS 的搜索工作流程 | RAP（Hao 等， [2023](#bib.bib7)） |'
- en: '| Multi-choice QA | Choices of top-N actions | Search workflows via traversal
    and heuristic | ToT (Yao et al., [2023a](#bib.bib29)) |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 多选 QA | 前 N 个动作的选择 | 通过遍历和启发式的搜索工作流程 | ToT（Yao 等， [2023a](#bib.bib29)） |'
- en: 'Table 4: Workflow-Specific LLM-Profiled Evaluators According to Task Formulation
    and Feedback Types'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：根据任务制定和反馈类型的工作流程特定 LLM 评估器
- en: 5 Implementations of LMPCs
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 LMPCs 的实施
- en: In this section, we explore different implementation approaches for LMPCs, covering
    strategies that are independent of specific workflows and tasks, implementations
    specifically designed for certain tasks, and those tailored to particular workflows.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了 LMPCs 的不同实施方法，包括那些独立于特定工作流程和任务的策略，专门为某些任务设计的实现，以及针对特定工作流程量身定制的实现。
- en: 5.1 Universal Implementations
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 通用实施
- en: 'LLMs are normally profiled by leveraging Chain-of-Thought (CoT) prompting to
    transcend basic input-output inference, facilitating the creation of intermediate
    reasoning steps. This is achieved through two techniques: Zero-shot CoT integrates
    a CoT trigger, such as “Let’s think step-by-step” (Kojima et al., [2022](#bib.bib10)),
    within task instructions, while while few-shot CoT incorporates handcrafted reasoning
    steps within provided examples for in-context learning (Wei et al., [2022](#bib.bib25)).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 通常通过利用链式思维（CoT）提示来超越基本的输入-输出推理，从而促进中间推理步骤的创建。这是通过两种技术实现的：零-shot CoT 在任务指令中集成了
    CoT 触发器，如“让我们一步一步来思考”（Kojima 等， [2022](#bib.bib10)），而少-shot CoT 则在提供的示例中融入了手工制作的推理步骤，以进行上下文学习（Wei
    等， [2022](#bib.bib25)）。
- en: 'As shown in Table [3](#S4.T3 "Table 3 ‣ 4.3 Feedback-Learning Workflows ‣ 4
    Workflows of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components"), some studies (Wang et al., [2023a](#bib.bib22))
    employ zero-shot CoT prompting, but most (Yao et al., [2023b](#bib.bib30); Shinn
    et al., [2023](#bib.bib16); Hao et al., [2023](#bib.bib7)) implement LLM policy
    models via few-shot CoT. Zero-shot CoT implementation of $\text{glm}_{\text{planner}}$
    often fails to produce long-horizon plans, unlike few-shot CoT prompting (Wang
    et al., [2023b](#bib.bib24)). While effective, few-shot prompting requires manual
    compilation of demonstrations with reasoning sequences, leading to increased manual
    work and computational resource use. Methods like Auto CoTs (Zhang et al., [2023](#bib.bib31))
    that automatically generate few-shot demonstrations could mitigate this challenge.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[3](#S4.T3 "Table 3 ‣ 4.3 Feedback-Learning Workflows ‣ 4 Workflows of LLM-Based
    Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components")所示，一些研究（Wang等，[2023a](#bib.bib22)）采用零-shot CoT 提示，但大多数（Yao等，[2023b](#bib.bib30)；Shinn等，[2023](#bib.bib16)；Hao等，[2023](#bib.bib7)）通过few-shot
    CoT实现LLM策略模型。与few-shot CoT提示不同，零-shot CoT实现的$\text{glm}_{\text{planner}}$通常无法生成长期计划（Wang等，[2023b](#bib.bib24)）。尽管有效，few-shot
    提示需要手动编制带有推理序列的示例，这会增加手动工作和计算资源的使用。像Auto CoTs（Zhang等，[2023](#bib.bib31)）这样能够自动生成few-shot示例的方法可以缓解这个挑战。'
- en: 5.2 Workflow-Specific Implementations
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 工作流特定的实现
- en: $\text{glm}_{\text{policy}}$ Implementations
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: $\text{glm}_{\text{policy}}$ 实现
- en: Two distinct implementations can be employed to enable $\text{glm}_{\text{policy}}$
    to trigger tool usage within tool-use and feedback learning workflows (receiving
    feedback from tools).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 可以采用两种不同的实现方式来使$\text{glm}_{\text{policy}}$在工具使用和反馈学习工作流中触发工具使用（接收来自工具的反馈）。
- en: '1.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Using In-Generation Triggers: Tools could be invoked during the reasoning generation
    process, e.g., MultiTool-CoT (Inaba et al., [2023](#bib.bib9)). The agent program
    monitors each token produced, pausing text generation when a tool trigger is detected.
    This pause allows for the invocation of tools, whose outputs are then inserted
    into the prompt to complete the reasoning. The triggers for these tools are defined
    either through tool descriptions, few-shot demonstrations ⁵⁵5In-generation triggers
    via few-shot demos: see an example prompt in Table [15](#A2.T15 "Table 15 ‣ B.2
    Prompts for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based
    Agents: Common Workflows and Reusable LLM-Profiled Components")), or a combination
    of both ⁶⁶6In-generation triggers via descriptions and few-shot demos: see an
    example prompt in Table [8](#A1.T8 "Table 8 ‣ Appendix A Frameworks of LLM-Based
    Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components")).'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '使用生成中触发器：在推理生成过程中可以调用工具，例如MultiTool-CoT（Inaba等，[2023](#bib.bib9)）。代理程序监控每个生成的标记，当检测到工具触发器时暂停文本生成。这一暂停允许调用工具，然后将工具的输出插入提示中以完成推理。这些工具的触发器通过工具描述、few-shot示例⁵⁵5生成中的触发器：请参见表[15](#A2.T15
    "Table 15 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey
    on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components")中的示例提示，或两者结合⁶⁶6生成中的触发器通过描述和few-shot示例：请参见表[8](#A1.T8
    "Table 8 ‣ Appendix A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents:
    Common Workflows and Reusable LLM-Profiled Components")中的示例提示来定义。'
- en: '2.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Reasoning-Acting (ReAct) Strategy for Tool Use: Introduced by Yao et al. ([2023b](#bib.bib30)),
    each reasoning or acting step is separately verbalized via a complete generation.
    Although the ReAct framework (Yao et al., [2023b](#bib.bib30)) unifies tool actions
    within the tool-use workflow and task-specific actions within the base workflow,
    we argue that the strategies for tool actions and task-specific actions should
    be distinguished. Because tool actions and task-specific actions are triggered
    differently, an aspect that will be emphasized further in the subsequent section
    about task-specific implementations.'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工具使用的推理-行动（ReAct）策略：由Yao等（[2023b](#bib.bib30)）提出，每个推理或行动步骤通过完整生成单独表达。尽管ReAct框架（Yao等，[2023b](#bib.bib30)）在工具使用工作流中统一了工具操作，在基础工作流中统一了任务特定操作，但我们认为工具操作和任务特定操作的策略应该加以区分。因为工具操作和任务特定操作的触发方式不同，这一点将在关于任务特定实现的后续章节中进一步强调。
- en: $\text{glm}_{\text{eval}}$ Implementations
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: $\text{glm}_{\text{eval}}$ 实现
- en: 'Commonly, different workflows require distinct feedback types and task formulations.
    There are four scenarios regarding the two perspectives, as summarized in Table
    [4](#S4.T4 "Table 4 ‣ 4.3 Feedback-Learning Workflows ‣ 4 Workflows of LLM-Based
    Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components"): 1) Generating free-form reflection: This reflective output is frequently
    integrated into the prompt of $\text{glm}_{\text{policy}}$ is designed to reflect
    on previous states and actions within feedback-learning workflows. Depending on
    specific feedback-learning workflows, it could incorporate external inputs from
    task or tool environments to enrich the reflection process. 2) Binary/Multiclass
    Classification: Feedback is obtained from discrete output tokens, commonly "no"
    or "yes." These can be converted into 0/1 values for search workflows. This scalar
    values can be employed as reward signals within Monte Carlo Tree Search (MCTS)
    simulations (Hao et al., [2023](#bib.bib7)), or they may be employed directly
    to guide decision-making at each step of tree traversal (Yao et al., [2023a](#bib.bib29)).
    3) Binary classification with scalar values: This approach differs from the previous
    one by employing the logit values of tokens to calculate scalar feedback values.
    For instance, the probability of a “yes” response is computed using the formula:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '通常，不同的工作流需要不同的反馈类型和任务表述。根据两个视角，有四种情况，如表 [4](#S4.T4 "Table 4 ‣ 4.3 Feedback-Learning
    Workflows ‣ 4 Workflows of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common
    Workflows and Reusable LLM-Profiled Components") 中总结：1）生成自由形式的反思：这种反思输出通常集成到 $\text{glm}_{\text{policy}}$
    的提示中，用于在反馈学习工作流中反思之前的状态和动作。根据具体的反馈学习工作流，它可以结合来自任务或工具环境的外部输入，以丰富反思过程。2）二分类/多分类：反馈来自离散输出标记，通常是“no”或“yes”。这些可以转换为
    0/1 值用于搜索工作流。这些标量值可以在蒙特卡洛树搜索（MCTS）模拟中用作奖励信号（Hao et al., [2023](#bib.bib7)），或者直接用于指导树遍历过程中的每一步决策（Yao
    et al., [2023a](#bib.bib29)）。3）带标量值的二分类：这种方法与前一种方法不同，它使用标记的 logit 值来计算标量反馈值。例如，“yes”
    响应的概率通过以下公式计算：'
- en: '|  | $v=\text{probs}_{\text{&quot;yes&quot;}}=\frac{e^{l_{\text{&quot;yes&quot;}}}}{e^{l_{\text{&quot;yes&quot;}}}+e^{l_{\text{&quot;no&quot;}}}},$
    |  |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | $v=\text{probs}_{\text{&quot;yes&quot;}}=\frac{e^{l_{\text{&quot;yes&quot;}}}}{e^{l_{\text{&quot;yes&quot;}}}+e^{l_{\text{&quot;no&quot;}}}},$
    |  |'
- en: 'where $l_{\text{&quot;yes&quot;}}$ are not accessible via black-box LLMs. These
    scalar values can then be utilized as rewards in search workflows for MCTS. 4)
    Multi-choice QA: Employed in settings where a selection from multiple choices
    is required, supporting tasks that involve choosing from top-N possible actions,
    as utilized in search workflows for action selection (Yao et al., [2023a](#bib.bib29)).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $l_{\text{&quot;yes&quot;}}$ 在黑箱 LLM 中不可访问。这些标量值可以用作 MCTS 搜索工作流中的奖励。4）多选
    QA：用于需要从多个选项中选择的场景，支持选择前 N 个可能动作的任务，如在行动选择的搜索工作流中使用（Yao et al., [2023a](#bib.bib29)）。
- en: 5.3 Task-Specific Implementations
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 特定任务的实现
- en: $\text{glm}_{\text{policy}}$ Implementations
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: $\text{glm}_{\text{policy}}$ 实现
- en: 'The noteworthy details include: 1) Multi-Step Generation: For tasks that inherently
    involve sequential decision-making (e.g., “put a cool tomato in the microwave”),
    post-processing steps are often required for $\text{glm}_{\text{policy}}$ are
    not explicitly implemented to generate plans, it may autonomously formulate plans
    during the reasoning phase before deciding on the current action (Shinn et al.,
    [2023](#bib.bib16); Yao et al., [2023b](#bib.bib30)) ⁹⁹9Implicit Planning: See
    an example prompt in Table [7](#A1.T7 "Table 7 ‣ Appendix A Frameworks of LLM-Based
    Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components"). These generated plans are maintained as internal states and do not
    serve as communication signals with other components.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '需要注意的细节包括：1）多步骤生成：对于那些本质上涉及顺序决策的任务（例如，“把一个凉的番茄放进微波炉”），通常需要后处理步骤，$\text{glm}_{\text{policy}}$
    未显式实现生成计划的功能，它可能会在推理阶段自主制定计划，然后再决定当前的动作（Shinn et al., [2023](#bib.bib16)；Yao et
    al., [2023b](#bib.bib30)）⁹⁹9隐性规划：见表 [7](#A1.T7 "Table 7 ‣ Appendix A Frameworks
    of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components") 中的示例提示。这些生成的计划作为内部状态保持，不作为与其他组件的通信信号。'
- en: ReAct Implementation of $\text{glm}_{\text{actor}}$
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ReAct 的 $\text{glm}_{\text{actor}}$ 实现
- en: 'The ReAct framework (Yao et al., [2023b](#bib.bib30)) unifies tool actions
    within the tool-use workflow and task-specific actions within the base workflow.
    However, the sequence in which reasoning and action outputs alternate is task-dependent.
    For question answering (QA), the generations of reasoning steps and tool actions
    are fixed, with alternating prompts for thinking and acting. ^(10)^(10)10Reasoning-Acting
    Strategy (QA tasks): See an example prompt in Table [10](#A1.T10 "Table 10 ‣ Appendix
    A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components"). In contrast, for embodied tasks, the decision
    whether to proceed with thinking or acting in the next step is autonomously determined
    by $\text{glm}_{\text{policy}}$ ^(11)^(11)11Reasoning-Acting Strategy (embodied
    tasks): See an example prompt in Table [7](#A1.T7 "Table 7 ‣ Appendix A Frameworks
    of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components").'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 'ReAct框架（Yao等，[2023b](#bib.bib30)）统一了工具使用工作流中的工具动作和基本工作流中的任务特定动作。然而，推理和行动输出交替的顺序依赖于任务。对于问题回答（QA），推理步骤和工具动作的生成是固定的，思考和行动的提示交替进行。^(10)^(10)10推理-行动策略（QA任务）：见附表[10](#A1.T10
    "Table 10 ‣ Appendix A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based
    Agents: Common Workflows and Reusable LLM-Profiled Components")中的示例提示。相比之下，对于具身任务，是否继续思考或行动的决定由$\text{glm}_{\text{policy}}$自主决定。^(11)^(11)11推理-行动策略（具身任务）：见附表[7](#A1.T7
    "Table 7 ‣ Appendix A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents:
    Common Workflows and Reusable LLM-Profiled Components")中的示例提示。'
- en: $\text{glm}_{\text{eval}}$ Implementations
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: $\text{glm}_{\text{eval}}$ 实现
- en: '$\text{glm}_{\text{eval}}$ can be configured to assess different task-specific
    perspectives, with specific agentic prompts determining the evaluation criteria.
    Generally, usefulness could be used to evaluate any actions (Hao et al., [2023](#bib.bib7))
    ^(12)^(12)12Evaluation Criteria (Usefulness): See an example prompt in Table [12](#A2.T12
    "Table 12 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey
    on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components").
    In NLIE-QA scenarios, a common metric is the factuality (truthfulness) of responses
    (Gou et al., [2024](#bib.bib5)) ^(13)^(13)13Evaluation Criteria (Factuality/Truthfulness):
    See example prompts in Table [14](#A2.T14 "Table 14 ‣ B.2 Prompts for LLM Evaluators
    ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components") and [15](#A2.T15 "Table 15 ‣ B.2 Prompts
    for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based Agents:
    Common Workflows and Reusable LLM-Profiled Components").'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '$\text{glm}_{\text{eval}}$可以配置为评估不同任务特定的视角，具体的代理提示决定了评估标准。一般来说，有用性可以用来评估任何动作（Hao等，[2023](#bib.bib7)）。^(12)^(12)12评估标准（有用性）：见附表[12](#A2.T12
    "Table 12 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey
    on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components")中的示例提示。在NLIE-QA场景中，一个常见的度量是回应的事实性（真实性）（Gou等，[2024](#bib.bib5)）。^(13)^(13)13评估标准（事实性/真实性）：见附表[14](#A2.T14
    "Table 14 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey
    on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components")和[15](#A2.T15
    "Table 15 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey
    on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components")中的示例提示。'
- en: 6 Future Work
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 未来工作
- en: As we delve deeper into LMPCs and agentic workflows, several key directions
    for future research are identified to advance the development of fully autonomous
    agents across various tasks.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们对LMPCs和代理工作流的深入探讨，确定了几个关键方向用于未来研究，以推进在各种任务中完全自主代理的发展。
- en: Universal Tool Use
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通用工具使用
- en: 'One direction is to move beyond predefined tool use for specific tasks and
    develop strategies that enable LLMs to autonomously determine tool usage based
    on the specific requirements of the task at hand. Another direction is to integrate
    tool use for both policy models and evaluators. In other words, LLMs could reason
    over the use of the tool across various tasks and flexibly jump between different
    roles. The insight of its potential is detailed in Appendix [C](#A3 "Appendix
    C Creation of a Task-Agnostic Tool Environment ‣ A Survey on LLM-Based Agents:
    Common Workflows and Reusable LLM-Profiled Components").'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '一个方向是超越预定义工具的特定任务使用，发展策略使得LLMs能够根据当前任务的具体要求自主决定工具使用。另一个方向是将工具使用整合到政策模型和评估模型中。换句话说，LLMs可以在不同任务间推理工具的使用，并灵活地在不同角色之间跳转。其潜力的见解详细阐述在附录[C](#A3
    "Appendix C Creation of a Task-Agnostic Tool Environment ‣ A Survey on LLM-Based
    Agents: Common Workflows and Reusable LLM-Profiled Components")中。'
- en: Unified Frameworks Across Tasks
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 跨任务统一框架
- en: 'As detailed in §[5](#S5 "5 Implementations of LMPCs ‣ A Survey on LLM-Based
    Agents: Common Workflows and Reusable LLM-Profiled Components"), despite many
    frameworks are presented with integrated conceptual workflows, many components
    are task-specific. For example, ReAct seeks to harmonize tool actions and task-specific
    actions. However, these workflows and specific implementations of LMPCs are different
    across tasks, such as hardcoded reasoning and acting steps in NLIE-QA versus autonomously
    determined reasoning and acting steps in embodied environments. Similarly, although
    the feedback-learning loop in Reflexion is theoretically unified, in practice,
    external feedback is generated only in embodied environments, not in NLIE-QA.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如第[5节](#S5 "5 LMPC的实现：基于LLM的智能体的常见工作流和可重用LLM概要化组件")所述，尽管有许多框架呈现了集成的概念性工作流，但许多组件是特定于任务的。例如，ReAct旨在协调工具操作和特定任务操作。然而，这些工作流和LMPC的特定实现在不同任务中是不同的，例如在NLIE-QA中的硬编码推理和操作步骤与在具象环境中自主确定的推理和操作步骤。类似地，尽管Reflexion中的反馈学习循环在理论上是统一的，但在实践中，只在具象环境中生成外部反馈，而不在NLIE-QA中。
- en: Reducing Bandwidth
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 减少带宽
- en: 'There are several potential strategies for reducing the bandwidth required
    for LLM inference ^(14)^(14)14Here, bandwidth refers to the volume of information
    processed during a single LLM generation, including using Stochastic $\text{glm}_{\text{actor}}$
    (Details in Appendix [D](#A4 "Appendix D Stochastic "glm"_"actor" ‣ A Survey on
    LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components")).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种潜在策略可以降低LLM推理所需的带宽^(14)^(14)14这里，带宽是指在单个LLM生成过程中处理的信息量，包括使用随机的$\text{glm}_{\text{actor}}$（详见附录[D](#A4
    "附录 D 随机“glm”_"actor"：基于LLM的智能体的常见工作流和可重用LLM概要化组件")）。
- en: 7 Conclusion
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: This survey provides a summary of common workflows and LLM-Profiled Components
    to encourage the reuse of these components and the expansion of existing workflows
    through the integration of both task-specific LMPCs and non-LLM components. This
    approach aims to foster the development and reproducibility of agentic workflows.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这份调查报告提供了常见工作流和LLM概要化组件的摘要，以鼓励重用这些组件和通过集成特定任务的LMPC和非LLM组件扩展现有工作流。这种方法旨在促进智能工作流的开发和可重复性。
- en: Limitations
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: 'This survey omits discussions on memory design ^(15)^(15)15Appendix [E](#A5
    "Appendix E Memory ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components") provides a brief discussion on memory in LLM-based agents
    and the integration of peripheral components into agentic workflows ^(16)^(16)16These
    are concisely summarized in Appendix [A](#A1 "Appendix A Frameworks of LLM-Based
    Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components"), as our focus is on the details of common LLM-profiled components
    within agentic workflows to facilitate the implementation of reusable components
    and extensible workflows. This distinctly sets our work apart from other surveys.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这份调查报告忽略了关于内存设计的讨论^(15)^(15)15附录[E](#A5 "附录 E 内存调查：基于LLM的智能体的常见工作流和可重用LLM概要化组件")提供了有关LLM智能体内存和周边组件整合的简要讨论^(16)^(16)16这在附录[A](#A1
    "附录 A 基于LLM的智能体框架：基于LLM的智能体的常见工作流和可重用LLM概要化组件调查")中进行了简明概述，因为我们的重点是通用LLM概要化组件详细信息，以促进可重用组件和可扩展工作流程的实现。这使得我们的工作与其他调查报告有了明显的不同。
- en: References
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Chen et al. (2024) Sijia Chen, Baochun Li, and Di Niu. 2024. [Boosting of thoughts:
    Trial-and-error problem solving with large language models](https://openreview.net/forum?id=qBL04XXex6).
    In *The Twelfth International Conference on Learning Representations*.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2024）Sijia Chen，Baochun Li和Di Niu。2024年。[思想的提升：使用大型语言模型的试错问题解决](https://openreview.net/forum?id=qBL04XXex6)。发表于*第十二届国际学习表示会议*。
- en: Dasgupta et al. (2022) Ishita Dasgupta, Christine Kaeser-Chen, Kenneth Marino,
    Arun Ahuja, Sheila Babayan, Felix Hill, and Rob Fergus. 2022. [Collaborating with
    language models for embodied reasoning](https://openreview.net/forum?id=YoS-abmWjJc).
    In *Second Workshop on Language and Reinforcement Learning*.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dasgupta等人（2022）Ishita Dasgupta，Christine Kaeser-Chen，Kenneth Marino，Arun Ahuja，Sheila
    Babayan，Felix Hill和Rob Fergus。2022年。[与语言模型合作进行具象推理](https://openreview.net/forum?id=YoS-abmWjJc)。发表于*语言和强化学习第二工作坊*。
- en: 'Fan et al. (2022) Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong
    Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. 2022.
    [Minedojo: Building open-ended embodied agents with internet-scale knowledge](https://openreview.net/forum?id=rc8o_j8I8PX).
    In *Thirty-sixth Conference on Neural Information Processing Systems Datasets
    and Benchmarks Track*.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fan et al. (2022) **Linxi Fan**, **Guanzhi Wang**, **Yunfan Jiang**, **Ajay
    Mandlekar**, **Yuncong Yang**, **Haoyi Zhu**, **Andrew Tang**, **De-An Huang**,
    **Yuke Zhu**, 和 **Anima Anandkumar**。2022年。[Minedojo: 利用互联网规模的知识构建开放式具身代理](https://openreview.net/forum?id=rc8o_j8I8PX)。在
    *第36届神经信息处理系统会议数据集和基准追踪* 上。'
- en: 'Goldsmith (2023) Jonathan Goldsmith. 2023. [Wikipedia: A python library that
    makes it easy to access and parse data from wikipedia](https://pypi.org/project/wikipedia/).
    Python Package Index.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Goldsmith (2023) **Jonathan Goldsmith**。2023年。[Wikipedia: 一个方便访问和解析维基百科数据的
    Python 库](https://pypi.org/project/wikipedia/)。Python 软件包索引。'
- en: 'Gou et al. (2024) Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen, Yujiu
    Yang, Nan Duan, and Weizhu Chen. 2024. [CRITIC: Large language models can self-correct
    with tool-interactive critiquing](https://openreview.net/forum?id=Sx038qxjek).
    In *The Twelfth International Conference on Learning Representations*.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gou et al. (2024) **Zhibin Gou**, **Zhihong Shao**, **Yeyun Gong**, **Yelong
    Shen**, **Yujiu Yang**, **Nan Duan**, 和 **Weizhu Chen**。2024年。[CRITIC: 大型语言模型可以通过工具交互式批评自我纠正](https://openreview.net/forum?id=Sx038qxjek)。在
    *第十二届国际学习表征会议* 上。'
- en: Guan et al. (2023) Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao
    Kambhampati. 2023. [Leveraging pre-trained large language models to construct
    and utilize world models for model-based task planning](https://openreview.net/forum?id=zDbsSscmuj).
    In *Thirty-seventh Conference on Neural Information Processing Systems*.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan et al. (2023) **Lin Guan**, **Karthik Valmeekam**, **Sarath Sreedharan**,
    和 **Subbarao Kambhampati**。2023年。[利用预训练的大型语言模型构建和利用世界模型进行基于模型的任务规划](https://openreview.net/forum?id=zDbsSscmuj)。在
    *第37届神经信息处理系统会议* 上。
- en: Hao et al. (2023) Shibo Hao, Yi Gu, Haodi Ma, Joshua Hong, Zhen Wang, Daisy
    Wang, and Zhiting Hu. 2023. [Reasoning with language model is planning with world
    model](https://aclanthology.org/2023.emnlp-main.507). In *Proceedings of the 2023
    Conference on Empirical Methods in Natural Language Processing*, pages 8154–8173,
    Singapore. Association for Computational Linguistics.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hao et al. (2023) **Shibo Hao**, **Yi Gu**, **Haodi Ma**, **Joshua Hong**, **Zhen
    Wang**, **Daisy Wang**, 和 **Zhiting Hu**。2023年。[与语言模型推理等同于与世界模型规划](https://aclanthology.org/2023.emnlp-main.507)。在
    *2023年自然语言处理会议论文集*，页面 8154–8173，新加坡。计算语言学协会。
- en: 'Huang et al. (2022) Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.
    2022. Language models as zero-shot planners: Extracting actionable knowledge for
    embodied agents. In *International Conference on Machine Learning*, pages 9118–9147\.
    PMLR.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2022) **Wenlong Huang**, **Pieter Abbeel**, **Deepak Pathak**,
    和 **Igor Mordatch**。2022年。语言模型作为零-shot 规划者：为具身代理提取可操作知识。在 *国际机器学习会议*，页面 9118–9147。PMLR。
- en: 'Inaba et al. (2023) Tatsuro Inaba, Hirokazu Kiyomaru, Fei Cheng, and Sadao
    Kurohashi. 2023. [MultiTool-CoT: GPT-3 can use multiple external tools with chain
    of thought prompting](https://doi.org/10.18653/v1/2023.acl-short.130). In *Proceedings
    of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
    2: Short Papers)*, pages 1522–1532, Toronto, Canada. Association for Computational
    Linguistics.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Inaba et al. (2023) **Tatsuro Inaba**, **Hirokazu Kiyomaru**, **Fei Cheng**,
    和 **Sadao Kurohashi**。2023年。[MultiTool-CoT: GPT-3 可以通过链式思维提示使用多个外部工具](https://doi.org/10.18653/v1/2023.acl-short.130)。在
    *第61届计算语言学协会年会（卷2：短论文）*，页面 1522–1532，多伦多，加拿大。计算语言学协会。'
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://openreview.net/forum?id=e2TBb5y0yFf).
    In *Advances in Neural Information Processing Systems*.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima et al. (2022) **Takeshi Kojima**, **Shixiang Shane Gu**, **Machel Reid**,
    **Yutaka Matsuo**, 和 **Yusuke Iwasawa**。2022年。[大型语言模型是零-shot 推理者](https://openreview.net/forum?id=e2TBb5y0yFf)。在
    *神经信息处理系统进展*。
- en: 'Liu et al. (2023) Hanmeng Liu, Zhiyang Teng, Leyang Cui, Chaoli Zhang, Qiji
    Zhou, and Yue Zhang. 2023. [Logicot: Logical chain-of-thought instruction-tuning](http://arxiv.org/abs/2305.12147).'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2023) **Hanmeng Liu**, **Zhiyang Teng**, **Leyang Cui**, **Chaoli
    Zhang**, **Qiji Zhou**, 和 **Yue Zhang**。2023年。[Logicot: 逻辑链式思维指令调整](http://arxiv.org/abs/2305.12147)。'
- en: 'Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    et al. 2023. Self-refine: Iterative refinement with self-feedback. *arXiv preprint
    arXiv:2303.17651*.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Madaan et al. (2023) **Aman Madaan**, **Niket Tandon**, **Prakhar Gupta**,
    **Skyler Hallinan**, **Luyu Gao**, **Sarah Wiegreffe**, **Uri Alon**, **Nouha
    Dziri**, **Shrimai Prabhumoye**, **Yiming Yang** 等。2023年。Self-refine: 自我反馈的迭代精炼。*arXiv
    预印本 arXiv:2303.17651*。'
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark JF Gales. 2023.
    Selfcheckgpt: Zero-resource black-box hallucination detection for generative large
    language models. *arXiv preprint arXiv:2303.08896*.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Manakul 等人（2023） Potsawee Manakul, Adian Liusie 和 Mark JF Gales. 2023. Selfcheckgpt:
    Zero-resource black-box hallucination detection for generative large language
    models. *arXiv preprint arXiv:2303.08896*.'
- en: Russell and Norvig (2010) Stuart J Russell and Peter Norvig. 2010. *Artificial
    intelligence a modern approach*. London.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russell 和 Norvig（2010） Stuart J Russell 和 Peter Norvig. 2010. *Artificial intelligence
    a modern approach*. 伦敦。
- en: Santurkar et al. (2023) Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo
    Lee, Percy Liang, and Tatsunori Hashimoto. 2023. Whose opinions do language models
    reflect? *arXiv preprint arXiv:2303.17548*.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Santurkar 等人（2023） Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee,
    Percy Liang 和 Tatsunori Hashimoto. 2023. Whose opinions do language models reflect?
    *arXiv preprint arXiv:2303.17548*.
- en: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath,
    Karthik Narasimhan, and Shunyu Yao. 2023. [Reflexion: Language agents with verbal
    reinforcement learning](http://arxiv.org/abs/2303.11366).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn 等人（2023） Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath,
    Karthik Narasimhan 和 Shunyu Yao. 2023. [Reflexion: Language agents with verbal
    reinforcement learning](http://arxiv.org/abs/2303.11366).'
- en: 'Shridhar et al. (2021) Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote, Yonatan
    Bisk, Adam Trischler, and Matthew Hausknecht. 2021. [{ALFW}orld: Aligning text
    and embodied environments for interactive learning](https://openreview.net/forum?id=0IOX0YcCdTn).
    In *International Conference on Learning Representations*.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shridhar 等人（2021） Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote, Yonatan
    Bisk, Adam Trischler 和 Matthew Hausknecht. 2021. [{ALFW}orld: Aligning text and
    embodied environments for interactive learning](https://openreview.net/forum?id=0IOX0YcCdTn).
    在 *国际学习代表大会* 中发表。'
- en: 'Sutton and Barto (2018) Richard S Sutton and Andrew G Barto. 2018. *Reinforcement
    learning: An introduction*. MIT press.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sutton 和 Barto（2018） Richard S Sutton 和 Andrew G Barto. 2018. *Reinforcement
    learning: An introduction*. MIT 出版社。'
- en: 'Thoppilan et al. (2022) Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam
    Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker,
    Yu Du, et al. 2022. Lamda: Language models for dialog applications. *arXiv preprint
    arXiv:2201.08239*.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Thoppilan 等人（2022） Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer,
    Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu
    Du, 等。2022. Lamda: Language models for dialog applications. *arXiv preprint arXiv:2201.08239*。'
- en: Wan et al. (2024) Ziyu Wan, Xidong Feng, Muning Wen, Ying Wen, Weinan Zhang,
    and Jun Wang. 2024. [Alphazero-like tree-search can guide large language model
    decoding and training](https://openreview.net/forum?id=fLO9VaAb3B).
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan 等人（2024） Ziyu Wan, Xidong Feng, Muning Wen, Ying Wen, Weinan Zhang 和 Jun
    Wang. 2024. [Alphazero-like tree-search can guide large language model decoding
    and training](https://openreview.net/forum?id=fLO9VaAb3B).
- en: Wang et al. (2024) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2024. A survey on
    large language model based autonomous agents. *Frontiers of Computer Science*,
    18(6):1–26.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2024） Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, 等。2024. A survey on large
    language model based autonomous agents. *Frontiers of Computer Science*, 18(6):1–26.
- en: 'Wang et al. (2023a) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, and Ee-Peng Lim. 2023a. [Plan-and-solve prompting: Improving zero-shot
    chain-of-thought reasoning by large language models](https://doi.org/10.18653/v1/2023.acl-long.147).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 2609–2634, Toronto, Canada. Association
    for Computational Linguistics.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人（2023a） Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy
    Ka-Wei Lee 和 Ee-Peng Lim. 2023a. [Plan-and-solve prompting: Improving zero-shot
    chain-of-thought reasoning by large language models](https://doi.org/10.18653/v1/2023.acl-long.147).
    在 *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)* 中，页面2609–2634，多伦多，加拿大。计算语言学协会。'
- en: 'Wang et al. (2022) Siyuan Wang, Zhongkun Liu, Wanjun Zhong, Ming Zhou, Zhongyu
    Wei, Zhumin Chen, and Nan Duan. 2022. [From lsat: The progress and challenges
    of complex reasoning](https://doi.org/10.1109/TASLP.2022.3164218). *IEEE/ACM Trans.
    Audio, Speech and Lang. Proc.*, 30:2201–2216.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人（2022） Siyuan Wang, Zhongkun Liu, Wanjun Zhong, Ming Zhou, Zhongyu Wei,
    Zhumin Chen 和 Nan Duan. 2022. [From lsat: The progress and challenges of complex
    reasoning](https://doi.org/10.1109/TASLP.2022.3164218). *IEEE/ACM Trans. Audio,
    Speech and Lang. Proc.*, 30:2201–2216.'
- en: 'Wang et al. (2023b) Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian
    Ma, and Yitao Liang. 2023b. [Describe, explain, plan and select: Interactive planning
    with LLMs enables open-world multi-task agents](https://openreview.net/forum?id=KtvPdGb31Z).
    In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 (2023b) Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma,
    和 Yitao Liang. 2023b. [描述、解释、计划和选择：LLMs 实现开放世界多任务代理的交互式规划](https://openreview.net/forum?id=KtvPdGb31Z).
    在 *第三十七届神经信息处理系统会议*。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian
    ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. 2022. [Chain of thought
    prompting elicits reasoning in large language models](https://openreview.net/forum?id=_VjQlMeSB_J).
    In *Advances in Neural Information Processing Systems*.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等 (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter,
    Fei Xia, Ed H. Chi, Quoc V Le, 和 Denny Zhou. 2022. [链式思维提示在大型语言模型中引发推理](https://openreview.net/forum?id=_VjQlMeSB_J).
    在 *神经信息处理系统进展*。
- en: Willard and Louf (2023) Brandon T Willard and Rémi Louf. 2023. Efficient guided
    generation for llms. *arXiv preprint arXiv:2307.09702*.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Willard 和 Louf (2023) Brandon T Willard 和 Rémi Louf. 2023. 高效引导生成用于 llms. *arXiv
    预印本 arXiv:2307.09702*。
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. *arXiv preprint
    arXiv:2308.08155*.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等 (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, 和 Chi Wang. 2023. Autogen: 通过多代理对话框架实现下一代
    llm 应用。*arXiv 预印本 arXiv:2308.08155*。'
- en: Xie et al. (2023) Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan,
    Junxian He, and Qizhe Xie. 2023. [Self-evaluation guided beam search for reasoning](https://openreview.net/forum?id=Bw82hwg5Q3).
    In *Thirty-seventh Conference on Neural Information Processing Systems*.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 (2023) Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian
    He, 和 Qizhe Xie. 2023. [自我评估引导的束搜索用于推理](https://openreview.net/forum?id=Bw82hwg5Q3).
    在 *第三十七届神经信息处理系统会议*。
- en: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L.
    Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a. [Tree of thoughts: Deliberate
    problem solving with large language models](http://arxiv.org/abs/2305.10601).'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等 (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths,
    Yuan Cao, 和 Karthik Narasimhan. 2023a. [思想树：与大型语言模型的深思熟虑问题解决](http://arxiv.org/abs/2305.10601)。
- en: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R Narasimhan, and Yuan Cao. 2023b. [React: Synergizing reasoning and acting
    in language models](https://openreview.net/forum?id=WE_vluYUL-X). In *The Eleventh
    International Conference on Learning Representations*.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等 (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik
    R Narasimhan, 和 Yuan Cao. 2023b. [React: 语言模型中的推理与行动协同](https://openreview.net/forum?id=WE_vluYUL-X).
    在 *第十一届国际学习表征会议*。'
- en: Zhang et al. (2023) Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2023.
    Automatic chain of thought prompting in large language models. In *The Eleventh
    International Conference on Learning Representations (ICLR 2023)*.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 (2023) Zhuosheng Zhang, Aston Zhang, Mu Li, 和 Alex Smola. 2023. 在大型语言模型中自动链式思维提示。在
    *第十一届国际学习表征会议 (ICLR 2023)*。
- en: 'Zhong et al. (2023) Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai
    Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. 2023. Agieval: A human-centric
    benchmark for evaluating foundation models. *arXiv preprint arXiv:2304.06364*.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhong 等 (2023) Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu,
    Yanlin Wang, Amin Saied, Weizhu Chen, 和 Nan Duan. 2023. Agieval: 一个以人为本的基准测试用于评估基础模型。*arXiv
    预印本 arXiv:2304.06364*。'
- en: 'Zhong et al. (2022) Wanjun Zhong, Siyuan Wang, Duyu Tang, Zenan Xu, Daya Guo,
    Yining Chen, Jiahai Wang, Jian Yin, Ming Zhou, and Nan Duan. 2022. [Analytical
    reasoning of text](https://doi.org/10.18653/v1/2022.findings-naacl.177). In *Findings
    of the Association for Computational Linguistics: NAACL 2022*, pages 2306–2319,
    Seattle, United States. Association for Computational Linguistics.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong 等 (2022) Wanjun Zhong, Siyuan Wang, Duyu Tang, Zenan Xu, Daya Guo, Yining
    Chen, Jiahai Wang, Jian Yin, Ming Zhou, 和 Nan Duan. 2022. [文本的分析推理](https://doi.org/10.18653/v1/2022.findings-naacl.177).
    在 *计算语言学协会会议论文集：NAACL 2022*，第2306–2319页，美国西雅图。计算语言学协会。
- en: Appendix A Frameworks of LLM-Based Agents
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A LLM 基于代理的框架
- en: 'Table [5](#A1.T5 "Table 5 ‣ Appendix A Frameworks of LLM-Based Agents ‣ A Survey
    on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components") demonstrates
    the workflow(s), LMPCs, and non-LMPC components of each framework.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [5](#A1.T5 "表 5 ‣ 附录 A 基于 LLM 的代理框架 ‣ 关于 LLM 基于代理的调查：常见工作流和可重用的 LLM 组件") 展示了每个框架的工作流程、LMPCs
    和非 LMPC 组件。
- en: '|  | Involved Workflows | LMPCs | Non-LMPC Components | Applied Environments
    |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '|  | 涉及的工作流 | LMPCs | 非 LMPC 组件 | 应用环境 |'
- en: '| Tree-of-Thoughts (ToT) (Yao et al., [2023a](#bib.bib29)) | Search via Traversal
    & Heuristic | $\text{glm}_{\text{actor}}$ (only for NLIEs-Writing) | Search Tree
    | Gaming; NLIEs-Writing |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 思维树（ToT）（Yao 等， [2023a](#bib.bib29)） | 通过遍历和启发式搜索 | $\text{glm}_{\text{actor}}$（仅用于
    NLIEs-写作） | 搜索树 | 游戏；NLIEs-写作 |'
- en: '| Tree-BeamSearch (Xie et al., [2023](#bib.bib28)) | Search-based via Traversal
    & Heuristic | $\text{glm}_{\text{actor}}$ | Search Tree | NLIE-QA |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Tree-BeamSearch（Xie 等， [2023](#bib.bib28)） | 基于搜索的遍历与启发式 | $\text{glm}_{\text{actor}}$
    | 搜索树 | NLIE-QA |'
- en: '| RAP (Hao et al., [2023](#bib.bib7)) | Search via MCTS | $\text{glm}_{\text{actor}}$
    | Search Tree | Gaming; NLIEs-QA |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| RAP（Hao 等， [2023](#bib.bib7)） | 通过 MCTS 搜索 | $\text{glm}_{\text{actor}}$
    | 搜索树 | 游戏；NLIEs-QA |'
- en: '| LLM Planner (Huang et al., [2022](#bib.bib8)) | Base | $\text{glm}_{\text{planner}}$
    | MLM for action translation | Embodied Env |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| LLM 规划器（Huang 等， [2022](#bib.bib8)） | 基础 | $\text{glm}_{\text{planner}}$
    | 用于动作翻译的 MLM | 具身环境 |'
- en: '| DEPS (Wang et al., [2023b](#bib.bib24)) | Base | $\text{glm}_{\text{planner}}$
    | Immediate actor, VLM+GLM as verbalizer | Embodied Env |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| DEPS（Wang 等， [2023b](#bib.bib24)） | 基础 | $\text{glm}_{\text{planner}}$ |
    即时演员，VLM+GLM 作为语言转换器 | 具身环境 |'
- en: '| Planner-Actor-Reporter (Dasgupta et al., [2022](#bib.bib2)) | Base | $\text{glm}_{\text{planner}}$
    | RL actor, Trained classifier+Hard code as verbalizer | Embodied Env |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 规划者-演员-报告员（Dasgupta 等， [2022](#bib.bib2)） | 基础 | $\text{glm}_{\text{planner}}$
    | RL 演员，训练分类器+硬编码作为语言转换器 | 具身环境 |'
- en: '| Plan-and-solve (Wang et al., [2023a](#bib.bib22)) | Base | $\text{glm}_{\text{planner}}$
    | / | NLIEs-QA |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 计划与解决方案（Wang 等， [2023a](#bib.bib22)） | 基础 | $\text{glm}_{\text{planner}}$
    | / | NLIEs-QA |'
- en: '| MultiTool-CoT (Inaba et al., [2023](#bib.bib9)) | Tool-Use | $\text{glm}_{\text{actor}}$
    | / | NLIEs |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| MultiTool-CoT（Inaba 等， [2023](#bib.bib9)） | 工具使用 | $\text{glm}_{\text{actor}}$
    | / | NLIEs |'
- en: '| ReAct (Yao et al., [2023b](#bib.bib30)) | Tool-Use | $\text{glm}_{\text{actor}}$
    | / | NLIEs |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| ReAct（Yao 等， [2023b](#bib.bib30)） | 工具使用 | $\text{glm}_{\text{actor}}$ |
    / | NLIEs |'
- en: '|  | Base | $\text{glm}_{\text{actor}}$ | / | Embodied Env |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '|  | 基础 | $\text{glm}_{\text{actor}}$ | / | 具身环境 |'
- en: '| Guan et al. ([2023](#bib.bib6)) | Feedback Learning (from Tools & Humans)
    | $\text{glm}_{\text{planner}}$ | Domain Experts, Domain-independent Planner |
    Embodied Env |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Guan 等（[2023](#bib.bib6)） | 反馈学习（来自工具与人类） | $\text{glm}_{\text{planner}}$
    | 领域专家，领域独立规划器 | 具身环境 |'
- en: '| CRITIC (Gou et al., [2024](#bib.bib5)) | Feedback Learning (from Tool & $\text{glm}_{\text{eval}}$
    | / | NLIEs |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| CRITIC（Gou 等， [2024](#bib.bib5)） | 反馈学习（来自工具和 $\text{glm}_{\text{eval}}$
    | / | NLIEs |'
- en: '| Self-refine (Madaan et al., [2023](#bib.bib12)) | Feedback Learning (from
    $\text{glm}_{\text{eval}}$, | / | NLIEs |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 自我优化（Madaan 等， [2023](#bib.bib12)） | 反馈学习（来自 $\text{glm}_{\text{eval}}$ |
    / | NLIEs |'
- en: '| Reflexion (Shinn et al., [2023](#bib.bib16)) | Feedback Learning (from $\text{glm}_{\text{eval}}$
    ),'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '| Reflexion（Shinn 等， [2023](#bib.bib16)） | 反馈学习（来自 $\text{glm}_{\text{eval}}$）,'
- en: Tool-Use | $\text{glm}_{\text{actor}}$, | / | NLIEs-QA |
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 工具使用 | $\text{glm}_{\text{actor}}$ | / | NLIEs-QA |
- en: '|  | Feedback Learning (from Task Env & $\text{glm}_{\text{eval}}$ | Embodied
    Env |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  | 反馈学习（来自任务环境和 $\text{glm}_{\text{eval}}$ | 具身环境 |'
- en: 'Table 5: Frameworks for LLM-based Agents. MLM: Masked Language Model.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：基于 LLM 的代理框架。MLM：掩码语言模型。
- en: '| Q: In a dance class of 20 students, $20\%$ of the remaining enrolled in jazz
    dance, and the rest enrolled in hip-hop dance. What percentage of the entire students
    enrolled in hip-hop dance? A: Let’s first understand the problem and devise a
    plan to solve the problem.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '| 问：在一个有 20 名学生的舞蹈班中，$20\%$ 的剩余学生报名了爵士舞，其余学生报名了街舞。整个班级中有多少百分比的学生报名了街舞？答：首先理解问题并制定解决问题的计划。'
- en: Then, let’s carry out the plan and solve the problem step by step.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们按照计划逐步解决问题。
- en: 'Plan: <svg id="A1.T6.3.3.3.3.p1.pic1" class="ltx_picture" height="192.22" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,192.22) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="163.28" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Step 1: Calculate the total number of students who enrolled in
    contemporary and jazz dance.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 计划：<svg id="A1.T6.3.3.3.3.p1.pic1" class="ltx_picture" height="192.22" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,192.22) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="163.28" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">步骤 1：计算报名参加当代舞蹈和爵士舞的学生总数。
- en: 'Step 2: Calculate the total number of students who enrolled in hiphop dance.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2：计算报名参加街舞的学生总数。
- en: 'Step 3: Calculate the percentage of students who enrolled in hiphop dance.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 3：计算报名参加街舞的学生比例。
- en: 'Solution:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案：
- en: 'Step 1: $20\%$ of the remaining 16 students is 4 students. So, a total of 8
    students enrolled in contemporary and jazz dance.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 1：剩下的 16 名学生中 $20\%$ 是 4 名学生。所以，总共有 8 名学生报名了当代舞蹈和爵士舞。
- en: 'Step 2: The remaining 12 students enrolled in hip-hop dance.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2：剩下的 12 名学生报名了街舞。
- en: 'Step 3: The percentage of students who enrolled in hip-hop dance is $12/20=60\%$.</foreignobject></g></g></svg>
    Therefore, the answer (arabic numerals) is <svg id="A1.T6.4.4.4.4.p2.pic1" class="ltx_picture"
    height="40.09" overflow="visible" version="1.1" width="603.94"><g transform="translate(0,40.09)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">60%</foreignobject></g></g></svg> |'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 3：报名参加街舞的学生比例是 $12/20=60\%$。</foreignobject></g></g></svg> 因此，答案（阿拉伯数字）是
    <svg id="A1.T6.4.4.4.4.p2.pic1" class="ltx_picture" height="40.09" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,40.09) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">60%</foreignobject></g></g></svg> |
- en: 'Table 6: An LLM Planner under NLIE-QA, implemented by the zero-shot CoT method.
    The CoT trigger is highlighted in red font. The content in shadow box is generated
    by LLM. Source from Wang et al. ([2023a](#bib.bib22))'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：在 NLIE-QA 下的 LLM 规划器，通过零-shot CoT 方法实现。CoT 触发器用红色字体标出。阴影框中的内容由 LLM 生成。来源于
    Wang et al. ([2023a](#bib.bib22))
- en: '| Interact with a household to solve a task. Here are two examples. You are
    in the middle of a room. Looking quickly around you, you see a cabinet 9, a cabinet
    8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet
    2, a cabinet 1, a coffeemachine 1, a countertop 3, a countertop 2, a countertop
    1, a drawer 9, a drawer 8, a drawer 7, a drawer 6, a drawer 5, a drawer 4, a drawer
    3, a drawer 2, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf
    3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner
    2, a stoveburner 1, and a toaster 1\. Your task is to: put a cool mug in shelf.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '| 与家用物品互动以完成任务。这里有两个示例。你在房间的中央。快速环顾四周，你可以看到一个橱柜 9、一个橱柜 8、一个橱柜 7、一个橱柜 6、一个橱柜
    5、一个橱柜 4、一个橱柜 3、一个橱柜 2、一个橱柜 1、一个咖啡机 1、一个台面 3、一个台面 2、一个台面 1、一个抽屉 9、一个抽屉 8、一个抽屉
    7、一个抽屉 6、一个抽屉 5、一个抽屉 4、一个抽屉 3、一个抽屉 2、一个抽屉 1、一个冰箱 1、一个垃圾桶 1、一个微波炉 1、一个架子 3、一个架子
    2、一个架子 1、一个洗涤槽 1、一个炉灶 4、一个炉灶 3、一个炉灶 2、一个炉灶 1 和一个烤面包机 1。你的任务是：把一个凉的杯子放到架子上。'
- en: 'think: To solve the task, I need to find and take a mug, then cool it with
    fridge, then put it in shelf.'
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 思考：为了完成任务，我需要找到并拿一个杯子，然后用冰箱将其冷却，最后把它放到架子上。
- en: OK.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。
- en: 'think: First I need to find a mug. A mug is more likely to appear in countertop
    (1-3), coffeemachine (1), cabinet (1-9), shelf (1-3), drawer (1-9). I can check
    one by one, starting with countertop 1\.'
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 思考：首先我需要找到一个杯子。杯子更有可能出现在台面（1-3）、咖啡机（1）、橱柜（1-9）、架子（1-3）、抽屉（1-9）。我可以一个一个地检查，从台面
    1 开始。
- en: OK.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。
- en: go to countertop 1
  id: totrans-210
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 前往台面 1
- en: On the countertop 1, you see a knife 1, a pan 2, a pan 1, and a plate 1\.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在台面 1 上，你可以看到一把刀 1、一只锅 2、一只锅 1 和一个盘子 1。
- en: …
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: 'think: Now I cool the mug. Next, I need to put it in/on shelf 1. OK.'
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 思考：现在我把杯子弄凉了。接下来，我需要把它放到架子 1 上。好的。
- en: go to shelf 1
  id: totrans-214
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 前往架子 1
- en: On the shelf 1, you see a cup 2, a cup 1, a peppershaker 1, and a saltshaker
    1\.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在架子 1 上，你可以看到一个杯子 2、一个杯子 1、一个胡椒瓶 1 和一个盐瓶 1。
- en: put mug 3 in/on shelf 1
  id: totrans-216
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 把杯子 3 放到架子 1 上
- en: 'You put the mug 3 in/on the shelf 1\. Here is the task: You are in the middle
    of a room. Looking quickly around you, you see a cabinet 6, a cabinet 5, a cabinet
    4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 3, a
    countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a fridge 1,
    a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1,
    a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster
    1\.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你把杯子 3 放在/放在架子 1 上。任务是：你在一个房间的中间。快速环顾四周，你看到一个柜子 6，一个柜子 5，一个柜子 4，一个柜子 3，一个柜子
    2，一个柜子 1，一个咖啡机 1，一个台面 3，一个台面 2，一个台面 1，一个抽屉 3，一个抽屉 2，一个抽屉 1，一个冰箱 1，一个垃圾桶 1，一个微波炉
    1，一个架子 3，一个架子 2，一个架子 1，一个水槽 1，一个炉灶 4，一个炉灶 3，一个炉灶 2，一个炉灶 1，还有一个烤面包机 1。
- en: 'Your task is to: put a cool tomato in microwave.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你的任务是：将一个酷番茄放入微波炉中。
- en: '<svg id="A1.T7.1.1.1.1.p1.pic1" class="ltx_picture" height="55.16" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,55.16) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="26.21" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">think: To solve the task, I need to find a tomato, then cool it
    with the fridge, and finally put it in the microwave.</foreignobject></g></g></svg>
    OK.'
  id: totrans-219
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <svg id="A1.T7.1.1.1.1.p1.pic1" class="ltx_picture" height="55.16" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,55.16) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="26.21" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">思考：要解决这个任务，我需要找到一个番茄，然后用冰箱冷却它，最后把它放进微波炉中。</foreignobject></g></g></svg>
    好的。
- en: '<svg id="A1.T7.2.2.2.2.p2.pic1" class="ltx_picture" height="73.76" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,73.76) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="44.82" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">think: First, I need to find a tomato. A tomato is more likely
    to be found on the countertop (1-3), cabinet (1-6), drawer (1-3), shelf (1-3),
    or the sinkbasin. I can start by checking the countertop 1.</foreignobject></g></g></svg>
    OK. > <svg id="A1.T7.3.3.3.3.p3.pic1" class="ltx_picture" height="40.55" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,40.55) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="11.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">go to countertop 1</foreignobject></g></g></svg> On the countertop
    1, you see a dishsponge 1, and a mug 2. … |'
  id: totrans-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <svg id="A1.T7.2.2.2.2.p2.pic1" class="ltx_picture" height="73.76" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,73.76) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="44.82" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">思考：首先，我需要找到一个番茄。一个番茄更可能在台面 (1-3)、柜子 (1-6)、抽屉 (1-3)、架子 (1-3) 或水槽中。我可以从检查台面
    1 开始。</foreignobject></g></g></svg> 好的。 > <svg id="A1.T7.3.3.3.3.p3.pic1" class="ltx_picture"
    height="40.55" overflow="visible" version="1.1" width="603.94"><g transform="translate(0,40.55)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="11.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">去台面 1</foreignobject></g></g></svg> 在台面 1 上，你看到一个洗碗海绵 1 和一个杯子
    2。… |
- en: 'Table 7: An LLM Actor within Base Workflow under the Alfred World Benchmark,
    implemented by the few-shot CoT method. The content in the shadow box is generated
    by LLM. Source from (Yao et al., [2023b](#bib.bib30)).'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：一个在 Alfred World Benchmark 中基于 Base Workflow 的 LLM Actor，采用少样本 CoT 方法实现。阴影框中的内容由
    LLM 生成。来源于 (Yao et al., [2023b](#bib.bib30))。
- en: '| Use the following tools at your disposal and answer some questions: |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 使用以下工具并回答一些问题： |'
- en: '| - <<Calculator>> |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| - <<计算器>> |'
- en: '| - <<Chemical reaction predictor>> |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| - <<化学反应预测器>> |'
- en: '| - <<Molar mass list>> |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| - <<摩尔质量列表>> |'
- en: '| Q: Find the amount of $\mathrm{H}2\mathrm{CO}3$. |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| Q: 找出 $\mathrm{H}2\mathrm{CO}3$ 的量。 |'
- en: '| A: First, use the chemical reaction predictor to determine the chemical equation
    for the reaction. |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| A: 首先，使用化学反应预测器来确定反应的化学方程式。 |'
- en: '| Reactants: $2\mathrm{CO}2,2\mathrm{H}2\mathrm{O}$ |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 反应物：$2\mathrm{CO}2,2\mathrm{H}2\mathrm{O}$ |'
- en: '| Products: ?$\mathrm{H}2\mathrm{CO}3$ |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 产物：？$\mathrm{H}2\mathrm{CO}3$ |'
- en: '| <<Chemical reaction predictor>> |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| <<化学反应预测器>> |'
- en: '| $2\mathrm{CO}2+2\mathrm{H}2\mathrm{O}\rightarrow 2\mathrm{H}2\mathrm{CO}3$
    |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| $2\mathrm{CO}2+2\mathrm{H}2\mathrm{O}\rightarrow 2\mathrm{H}2\mathrm{CO}3$
    |'
- en: '| Second, use the molar mass list to determine the molar mass of $\mathrm{H}2\mathrm{CO}3$
    |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 第二，使用摩尔质量表确定$\mathrm{H}2\mathrm{CO}3$的摩尔质量 |'
- en: '| Third, use the calculator to calculate the amount of 2 moles of $\mathrm{H}2\mathrm{CO}3$
    |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 第三，使用计算器计算2摩尔的$\mathrm{H}2\mathrm{CO}3$的量 |'
- en: '| Therefore, $124\mathrm{~{}g}$ is formed. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 因此，生成了$124\mathrm{~{}g}$。 |'
- en: '| Q: Find the amount of Calcium hydroxide that is required to react with 2
    moles of Carbon dioxide to form 2 moles of Calcium carbonate along with 2 moles
    of Water. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| Q: 计算反应2摩尔的二氧化碳形成2摩尔的碳酸钙和2摩尔水所需的氢氧化钙的量。 |'
- en: '| A: |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| A: |'
- en: 'Table 8: An LLM actor with tool use implemented by MultiTool-CoT (Inaba et al.,
    [2023](#bib.bib9)).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 'Table 8: 由MultiTool-CoT（Inaba等，[2023](#bib.bib9)）实现的工具使用的LLM演员。'
- en: '| Q: Julie is reading a 120-page book. Yesterday, she was able to read 12 pages
    and today, she read twice as many pages as yesterday. If she wants to read half
    of the remaining pages tomorrow, how many pages should she read? A: Julie read
    twice as many pages as yesterday, so she read 12 * 2 = 24 pages today. Since yesterday,
    Julie read 12 + 24 = 36 pages. So, there are 120 - 36 = 84 pages left to be read.
    Since she wants to read half of the remaining pages, she should read 84 / 2 =
    42 pages. The answer is 42.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '| Q: **Julie**正在读一本120页的书。昨天她读了12页，今天读的页数是昨天的两倍。如果她明天想读剩下页面的一半，她应该读多少页？ A:
    **Julie**今天读了12 * 2 = 24页。自昨天以来，**Julie**读了12 + 24 = 36页。所以，还剩120 - 36 = 84页未读。由于她想读剩余页面的一半，她应该读84
    / 2 = 42页。答案是42。'
- en: 'Q: Ken created a care package to send to his brother, who was away at boarding
    school. Ken placed a box on a scale, and then he poured into the box enough jelly
    beans to bring the weight to 2 pounds. Then, he added enough brownies to cause
    the weight to triple. Next, he added another 2 pounds of jelly beans. And finally,
    he added enough gummy worms to double the weight once again. What was the final
    weight of the box of goodies, in pounds?'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: **Ken**为他在寄宿学校的弟弟准备了一个保健包。**Ken**将一个箱子放在称上，然后往箱子里倒入足够的糖果豆，使重量达到2磅。接着，他添加了足够的布朗尼，使重量增加三倍。接下来，他又加了2磅的糖果豆。最后，他添加了足够的果冻虫，使重量再次翻倍。这个好东西箱子的最终重量是多少磅？'
- en: 'A: Ken poured jelly beans into the box until the weight was 2 pounds, so the
    weight of the box was 2 pounds at first. Then Ken added enough brownies to cause
    the weight to triple, so the weight of the box was 2 * 3 = 6 pounds. After Ken
    added another 2 pounds of jelly beans, the weight of the box was 6 + 2 = 8 pounds.
    Finally, he added enough gummy worms to double the weight once again, so the weight
    of the box was 8 * 2 = 16 pounds. The answer is 16.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: **Ken**将糖果豆倒入箱子中直到重量达到2磅，因此箱子最初的重量为2磅。接着**Ken**添加了足够的布朗尼，使重量增加三倍，因此箱子的重量为2
    * 3 = 6磅。之后**Ken**又加了2磅的糖果豆，箱子的重量变为6 + 2 = 8磅。最后，他添加了足够的果冻虫，使重量再次翻倍，因此箱子的重量为8
    * 2 = 16磅。答案是16。'
- en: 'Q: James writes a 3-page letter to 2 different friends twice a week. How many
    pages does he write a year?'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: **James**每周给两个不同的朋友写3页的信。他每年写多少页？'
- en: 'A: James writes a 3-page letter to 2 different friends twice a week, so he
    writes 3 * 2 * 2 = 12 pages every week. There are 52 weeks in a year, so he writes
    12 * 52 = 624 pages a year. The answer is 624.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: **James**每周给两个不同的朋友写3页的信，写信的频率是每周两次，所以他每周写3 * 2 * 2 = 12页信。每年有52周，因此他每年写12
    * 52 = 624页信。答案是624。'
- en: 'Q: Natalia sold clips to 48 of her friends in April, and then she sold half
    as many clips in May. How many clips did Natalia sell altogether in April and
    May?'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: **Natalia**在四月给她的48个朋友卖夹子，然后她在五月卖了同样数量的一半。**Natalia**在四月和五月总共卖了多少个夹子？'
- en: 'A: Natalia sold 48 clips in April and half as many clips in May, so she sold
    48 / 2 = 24 clips in May. Altogether, she sold 48 + 24 = 72 clips. The answer
    is 72.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: **Natalia**在四月卖出了48个夹子，五月份卖出了48 / 2 = 24个夹子，因此她总共卖出了48 + 24 = 72个夹子。答案是72。'
- en: 'Q: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning
    and bakes muffins for her friends every day with four. She sells the remainder
    at the farmers’ market daily for $2 per fresh duck egg. How much in dollars does
    she make every day at the farmers’ market?'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 'Q: **Janet**的鸭子每天产16个蛋。她每天早晨吃三个，用四个做松饼给朋友。她每天在农贸市场上以每个2美元的价格出售剩余的鸭蛋。她每天在农贸市场上赚多少钱？'
- en: 'A:" <svg id="A1.T9.1.1.1.1.p1.pic1" class="ltx_picture" height="91.82" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,91.82) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="62.88" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Janet’s ducks lay 16 eggs per day. She eats three for breakfast
    every morning and bakes muffins for her friends every day with four, so she uses
    3 + 4 = <<3+4=7>>7 eggs daily. Thus, she sells 16 - 7 = <<16-7=9>>9 eggs at the
    farmers’ market daily. Therefore, she makes 9 * $2 = $<<9*2=18>>18 every day at
    the farmers’ market. Answer: 18.</foreignobject></g></g></svg> |'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: A:" <svg id="A1.T9.1.1.1.1.p1.pic1" class="ltx_picture" height="91.82" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,91.82) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="62.88" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">珍妮特的鸭子每天产 16 个蛋。她每天早晨吃 3 个蛋作为早餐，并每天用 4 个蛋为朋友们烘焙松饼，所以她每天使用 3 +
    4 = <<3+4=7>>7 个蛋。因此，她每天在农贸市场上销售 16 - 7 = <<16-7=9>>9 个蛋。因此，她每天在农贸市场上赚取 9 * $2
    = $<<9*2=18>>18。答案：18。</foreignobject></g></g></svg> |
- en: 'Table 9: An LLM Actor within Tool-Use Workflow under NLIE-QA, implemented by
    the few-Shot CoT method. The content in the shadow box is generated by LLM.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：在 NLIE-QA 下的工具使用工作流程中的 LLM 演员，由少量样本 CoT 方法实现。阴影框中的内容由 LLM 生成。
- en: '| Solve a question answering task by having a Thought, then Finish with your
    answer. Thought can reason about the current situation. Finish[answer] returns
    the answer and finishes the task. |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 通过思考来解决一个问答任务，然后用你的答案结束。思考可以推理当前的情况。Finish[answer] 返回答案并完成任务。 |'
- en: '| Here are some examples: |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 以下是一些示例： |'
- en: '| Question 1: What is the elevation range for the area that the eastern sector
    of the Colorado orogeny extends into? |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1：科罗拉多造山带的东部区域延伸到的区域的海拔范围是多少？ |'
- en: '| Thought: Let’s think step by step. The eastern sector of Colorado orogeny
    extends into the High Plains. High Plains rise in elevation from around 1,800
    to 7,000 ft, so the answer is 1,800 to 7,000 ft. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 思考：让我们一步步来考虑。科罗拉多造山带的东部区域延伸到高原。高原的海拔从大约 1,800 英尺上升到 7,000 英尺，因此答案是 1,800
    到 7,000 英尺。 |'
- en: '| Action: Finish[1,800 to 7,000 ft] |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 操作：Finish[1,800 到 7,000 英尺] |'
- en: '| … |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| … |'
- en: '| Question 6: Were Pavel Urysohn and Leonid Levin known for the same type of
    work? |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 问题 6：帕维尔·乌里索夫和列昂尼德·列文是否以相同类型的工作闻名？ |'
- en: '| Thought: Let’s think step by step. Pavel Urysohn is a mathematician. Leonid
    Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin
    have the same type of work. |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 思考：让我们一步步来考虑。帕维尔·乌里索夫是数学家。列昂尼德·列文是数学家和计算机科学家。所以帕维尔·乌里索夫和列昂尼德·列文从事相同类型的工作。
    |'
- en: '| Action: Finish[Yes] |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 操作：Finish[是] |'
- en: '| END OF EXAMPLES) |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 示例结束) |'
- en: '| Question: VIVA Media AG changed itś name in 2004\. What does their new acronym
    stand for? |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 问题：VIVA Media AG 在 2004 年更改了名称。它们的新首字母缩略词代表什么？ |'
- en: '| Thought: <svg id="A1.T10.1.1.1.1.p1.pic1" class="ltx_picture" height="92.59"
    overflow="visible" version="1.1" width="603.94"><g transform="translate(0,92.59)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="63.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Let’s think step by step. VIVA Media AG changed its name in 2004\.
    The new acronym must stand for the new name they adopted. To find the answer,
    we need to research the new name of VIVA Media AG after 2004.Action: Finish[Further
    research is needed to determine the new acronym.]</foreignobject></g></g></svg>
    |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 思考：<svg id="A1.T10.1.1.1.1.p1.pic1" class="ltx_picture" height="92.59" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,92.59) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="63.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">让我们一步步来考虑。VIVA Media AG 在 2004 年更改了名称。新的首字母缩略词必须代表他们采用的新名称。要找到答案，我们需要研究
    VIVA Media AG 在 2004 年之后的新名称。操作：Finish[进一步的研究是确定新首字母缩略词所需的。]</foreignobject></g></g></svg>
    |'
- en: '| Action: <svg id="A1.T10.3.3.1.1.p1.pic1" class="ltx_picture" height="42.78"
    overflow="visible" version="1.1" width="603.94"><g transform="translate(0,42.78)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Finish[Further research is needed to determine the new acronym.]</foreignobject></g></g></svg>
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 操作：<svg id="A1.T10.3.3.1.1.p1.pic1" class="ltx_picture" height="42.78" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,42.78) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">完成[需要进一步研究以确定新的缩写。]</foreignobject></g></g></svg> |'
- en: 'Table 10: An LLM Actor within tool-use workflow for the HotPot-QA Benchmark,
    implemented by few-Shot CoT. The content in the shadow box is generated by LLM.
    Source from Yao et al. ([2023b](#bib.bib30)).'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：在 HotPot-QA 基准测试中，工具使用工作流程下的 LLM Actor，由 few-Shot CoT 实现。阴影框中的内容由 LLM 生成。来源于
    Yao 等人 ([2023b](#bib.bib30))。
- en: '| Given a question, please decompose it into sub-questions. For each sub-question,
    please answer it in a complete sentence, ending with "The answer is". When the
    original question is answerable, please start the subquestion with "Now we can
    answer the question:" |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 给定一个问题，请将其分解为子问题。对于每个子问题，请用完整的句子回答，并以“答案是”结束。当原始问题可以回答时，请以“现在我们可以回答问题”开头。
    |'
- en: '| Question 1: James writes a 3-page letter to 2 different friends twice a week.
    How many pages does he write a year? |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1：詹姆斯每周给 2 个不同的朋友写 3 页的信。每年他写多少页？ |'
- en: '| Question 1.1: How many pages does he write every week? |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1.1：他每周写多少页？ |'
- en: '| Answer 1.1: James writes a 3-page letter to 2 different friends twice a week,
    so he writes 3 * 2 * 2 = 12 pages every week. The answer is 12. |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 答案 1.1：詹姆斯每周给 2 个不同的朋友写 3 页的信，所以他每周写 3 * 2 * 2 = 12 页。答案是 12。 |'
- en: '| Question 1.2: How many weeks are there in a year? |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1.2：一年有多少周？ |'
- en: '| Answer 1.2: There are 52 weeks in a year. The answer is 52. |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 答案 1.2：一年有 52 周。答案是 52。 |'
- en: '| Question 1.3: Now we can answer the question: How many pages does he write
    a year? |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1.3：现在我们可以回答问题：他每年写多少页？ |'
- en: '| Answer 1.3: James writes 12 pages every week, so he writes 12 * 52 = 624
    pages a year. The answer is 624. |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 答案 1.3：詹姆斯每周写 12 页，所以他每年写 12 * 52 = 624 页。答案是 624。 |'
- en: '| … |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| … |'
- en: '| Question 5: Janet’s ducks lay 16 eggs per day. She eats three for breakfast
    every morning and bakes muffins for her friends every day with four. She sells
    the remainder at the farmers’ market daily for $2 per fresh duck egg. How much
    in dollars does she make every day at the farmers’ market? |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 问题 5：珍妮特的鸭子每天产 16 个蛋。她每天早上吃三个，并用四个做松饼给朋友们。她每天将剩余的蛋以每个 2 美元的价格在农贸市场上出售。她每天在农贸市场上赚多少钱？
    |'
- en: '| Question 5.1: <svg id="A1.T11.1.1.1.1.p1.pic1" class="ltx_picture" height="55.16"
    overflow="visible" version="1.1" width="603.94"><g transform="translate(0,55.16)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="26.21" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">How many eggs does Janet have left after eating three for breakfast
    and baking muffins with four?</foreignobject></g></g></svg> |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 问题 5.1：<svg id="A1.T11.1.1.1.1.p1.pic1" class="ltx_picture" height="55.16"
    overflow="visible" version="1.1" width="603.94"><g transform="translate(0,55.16)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="26.21" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">珍妮特在吃掉三个做早餐并用四个做松饼后还剩多少个蛋？</foreignobject></g></g></svg> |'
- en: 'Table 11: An LLM Actor under the GSM8K Benchmark. The content in the shadow
    box is generated by LLM. Source from Hao et al. ([2023](#bib.bib7)).'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11：在 GSM8K 基准测试下的 LLM Actor。阴影框中的内容由 LLM 生成。来源于 Hao 等人 ([2023](#bib.bib7))。
- en: Appendix B Examples Prompts
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 示例提示
- en: B.1 LLM-Profiled Policy Models
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 LLM-简介政策模型
- en: '1) Base Workflow: A planner for the NLIE-QA and an actor for the householding
    environment (ALFRED) are demonstrated in Table [6](#A1.T6 "Table 6 ‣ Appendix
    A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components") and [7](#A1.T7 "Table 7 ‣ Appendix A Frameworks
    of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components"), respectively. 2) Tool-Use Workflow: Actors under NLIE-QA
    is demonstrated in Table [8](#A1.T8 "Table 8 ‣ Appendix A Frameworks of LLM-Based
    Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components"), [9](#A1.T9 "Table 9 ‣ Appendix A Frameworks of LLM-Based Agents
    ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components"),
    and [10](#A1.T10 "Table 10 ‣ Appendix A Frameworks of LLM-Based Agents ‣ A Survey
    on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled Components").
    The first two tables show the implementation of in-generation triggers, while
    the last one demonstrates the ReAct implementation. 3) Search Workflow: An actor
    is required during the expansion stage of MCTS in the RAP workflow. The prompts
    and expected generations are shown in Table [11](#A1.T11 "Table 11 ‣ Appendix
    A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components").'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '1) 基础工作流程：NLIE-QA的规划器和家庭环境（ALFRED）的执行者分别展示在表[6](#A1.T6 "Table 6 ‣ Appendix
    A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components")和[7](#A1.T7 "Table 7 ‣ Appendix A Frameworks
    of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components")中。 2) 工具使用工作流程：NLIE-QA下的执行者展示在表[8](#A1.T8 "Table 8 ‣
    Appendix A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common
    Workflows and Reusable LLM-Profiled Components")、[9](#A1.T9 "Table 9 ‣ Appendix
    A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components")和[10](#A1.T10 "Table 10 ‣ Appendix A Frameworks
    of LLM-Based Agents ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components")中。前两张表展示了生成触发器的实现，而最后一张展示了ReAct的实现。 3) 搜索工作流程：在RAP工作流程的扩展阶段需要一个执行者。提示和期望生成结果展示在表[11](#A1.T11
    "Table 11 ‣ Appendix A Frameworks of LLM-Based Agents ‣ A Survey on LLM-Based
    Agents: Common Workflows and Reusable LLM-Profiled Components")中。 |'
- en: B.2 Prompts for LLM Evaluators
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 LLM评估员的提示
- en: 'Table [12](#A2.T12 "Table 12 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B
    Examples Prompts ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components") and [13](#A2.T13 "Table 13 ‣ B.2 Prompts for LLM Evaluators
    ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based Agents: Common Workflows
    and Reusable LLM-Profiled Components") show LLM evaluators that are profiled as
    classification tasks, while Table [15](#A2.T15 "Table 15 ‣ B.2 Prompts for LLM
    Evaluators ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based Agents: Common
    Workflows and Reusable LLM-Profiled Components") demonstrates another to general
    free-form text.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '表[12](#A2.T12 "Table 12 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix B Examples
    Prompts ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components")和[13](#A2.T13 "Table 13 ‣ B.2 Prompts for LLM Evaluators ‣ Appendix
    B Examples Prompts ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable
    LLM-Profiled Components")展示了被配置为分类任务的LLM评估员，而表[15](#A2.T15 "Table 15 ‣ B.2 Prompts
    for LLM Evaluators ‣ Appendix B Examples Prompts ‣ A Survey on LLM-Based Agents:
    Common Workflows and Reusable LLM-Profiled Components")展示了另一种通用自由形式文本。'
- en: '| Given a question and some sub-questions, determine whether the last sub-question
    is useful to answer the question. Output ’Yes’ or ’No’, and a reason. |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 给定一个问题和一些子问题，确定最后一个子问题是否对回答问题有用。输出‘是’或‘否’，并给出理由。 |'
- en: '| Question 1: Four years ago, Kody was only half as old as Mohamed. If Mohamed
    is currently twice as 30 years old, how old is Kody? |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 问题1：四年前，Kody只有Mohamed年龄的一半。如果Mohamed现在是30岁，那么Kody几岁？ |'
- en: '| Question 1.1: How old is Mohamed? |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 问题1.1：Mohamed多大岁数？ |'
- en: '| Question 1.2: How old was Mohamed four years ago? |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 问题1.2：四年前Mohamed多大岁数？ |'
- en: '| New question 1.3: How old was Kody four years ago? |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 新问题1.3：四年前Kody多大岁数？ |'
- en: '| Is the new question useful? Yes. We need the answer to calculate how old
    is Kody now. |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 新问题有用吗？是的。我们需要答案来计算现在Kody几岁。 |'
- en: '| … |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| … |'
- en: '| Question 5: Janet’s ducks lay 16 eggs per day. She eats three for breakfast
    every morning and bakes muffins for her friends every day with four. She sells
    the remainder at the farmers’ market daily for $2 per fresh duck egg. How much
    in dollars does she make every day at the farmers’ market? |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 问题5：Janet的鸭子每天下16个蛋。她每天早晨吃三个，并用四个做蛋糕给她的朋友们。她每天在农贸市场以每个2美元的价格出售剩余的鸭蛋。她每天在农贸市场赚多少钱？
    |'
- en: '| New question 5.1: Now we can answer the question: How much in dollars does
    she make every day at the farmers’ market? |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 新问题 5.1: 现在我们可以回答这个问题：她在农贸市场每天赚多少钱？ |'
- en: '| Is the new question useful? |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 新问题有用吗？ |'
- en: 'Table 12: An LLM Evaluator within RAP Workflow under NLIE-QA, implemented by
    few-Shot CoT prompting. It assesses the usefulness of new sub-questions in solving
    the original question. Source from Hao et al. ([2023](#bib.bib7))'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '表 12: 在 NLIE-QA 下 RAP 工作流程中的 LLM 评估器，由少量样本的 CoT 提示实现。它评估新子问题在解决原始问题中的有用性。来源于
    Hao 等人 ([2023](#bib.bib7))'
- en: '| Evaluate if given numbers can reach 24 (sure/likely/impossible) 10 14'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '| 评估给定的数字是否可以达到 24（确定/可能/不可能） 10 14'
- en: 10 + 14 = 24
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 10 + 14 = 24
- en: sure
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 确定
- en: …
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: 1 3 3
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 1 3 3
- en: 1 * 3 * 3 = 9
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 1 * 3 * 3 = 9
- en: (1 + 3) * 3 = 12
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: (1 + 3) * 3 = 12
- en: 1 3 3 are all too small
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 1 3 3 都太小
- en: impossible
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 不可能
- en: 11, 12 |
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 11, 12 |
- en: 'Table 13: An LLM Evaluator within Tree-of-Thought Workflow under Game 24, implemented
    by few-Shot CoT prompting. The LLM is profiled for multi-class classification.
    Source from Yao et al. ([2023a](#bib.bib29)).'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '表 13: 在 Game 24 下 Tree-of-Thought 工作流程中的 LLM 评估器，由少量样本的 CoT 提示实现。该 LLM 适用于多类别分类。来源于
    Yao 等人 ([2023a](#bib.bib29)).'
- en: '| Context: … Sentence: …'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '| 上下文: … 句子: …'
- en: Is the sentence supported by the context above?
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 句子是否得到上述上下文的支持？
- en: 'Answer Yes or No: |'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '回答是或否: |'
- en: 'Table 14: An LLM Evaluator, implemented by zero-Shot CoT prompting. The LLM
    is profiled for multi-class classification. Source from Manakul et al. ([2023](#bib.bib13)).'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '表 14: 一个 LLM 评估器，由零样本 CoT 提示实现。该 LLM 适用于多类别分类。来源于 Manakul 等人 ([2023](#bib.bib13)).'
- en: '| … |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| … |'
- en: '| Question: Serianna is a band of what genre that combines elements of heavy
    metal and hardcore punk? |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 问题: Serianna 是什么类型的乐队，它结合了重金属和硬核朋克的元素？ |'
- en: '| Proposed Answer: Let’s think step by step. Serianna is a band of metalcore
    genre. Metalcore is a subgenre of heavy metal and hardcore punk. So Serianna is
    a band of heavy metal and hardcore punk. So the answer is: heavy metal and hardcore
    punk. |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 提议的答案: 让我们一步一步思考。Serianna 是一支金属核类型的乐队。金属核是重金属和硬核朋克的一个子流派。因此，Serianna 是一支重金属和硬核朋克的乐队。所以答案是：重金属和硬核朋克。
    |'
- en: '| 1\. Plausibility: <svg id="A2.T15.1.1.1.1.p1.pic1" class="ltx_picture" height="138.72"
    overflow="visible" version="1.1" width="603.94"><g transform="translate(0,138.72)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="109.78" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">The question asks for the genre that combines elements of heavy
    metal and hardcore punk, and the answer is "heavy metal and hardcore punk", simply
    repeat the question. So it’s not plausible. 2\. Truthfulness: Let’s search the
    question in google: > Search Query: Serianna is a band of what genre that combines
    elements of heavy metal and hardcore punk? site: wikipedia.org > Evidence:</foreignobject></g></g></svg>
    [Metalcore - Wikipedia] Metalcore is a fusion music genre that combines elements
    of extreme metal and hardcore punk. |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 1\. 合理性: <svg id="A2.T15.1.1.1.1.p1.pic1" class="ltx_picture" height="138.72"
    overflow="visible" version="1.1" width="603.94"><g transform="translate(0,138.72)
    matrix(1 0 0 -1 0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="109.78" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">这个问题询问了结合重金属和硬核朋克元素的流派，答案是“重金属和硬核朋克”，只是重复了问题。因此，这不合理。 2\. 真实性:
    让我们在谷歌中搜索这个问题: > 搜索查询: Serianna 是什么类型的乐队，它结合了重金属和硬核朋克的元素？ site: wikipedia.org
    > 证据:</foreignobject></g></g></svg> [金属核 - 维基百科] 金属核是一种结合了极端金属和硬核朋克元素的融合音乐流派。
    |'
- en: '| <svg id="A2.T15.4.4.1.1.p1.pic1" class="ltx_picture" height="91.06" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,91.06) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="62.11" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">The evidence suggests that metalcore is a genre that combines
    elements of extreme metal and hardcore punk, as stated in the proposed answer.
    Let’s search the proposed answer in google: > Search Query: Serianna is a band
    of metalcore genre. site: wikipedia.org > Evidence:</foreignobject></g></g></svg>
    [Serianna - Wikipedia] Serianna was a metalcore band from Madison, Wisconsin.
    The band formed in 2006… |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| <svg id="A2.T15.4.4.1.1.p1.pic1" class="ltx_picture" height="91.06" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,91.06) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="62.11" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">证据表明，metalcore 是一个将极端金属和硬核朋克元素结合的流派，如所提答案所述。让我们在 Google 上搜索所提的答案：
    > 搜索查询：Serianna 是一支 metalcore 流派的乐队。 site: wikipedia.org > 证据：</foreignobject></g></g></svg>
    [Serianna - Wikipedia] Serianna 是一支来自威斯康星州麦迪逊的 metalcore 乐队。该乐队成立于 2006 年… |'
- en: '| <svg id="A2.T15.7.7.1.1.p1.pic1" class="ltx_picture" height="107.66" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,107.66) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="78.72" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">The evidence suggests Serianna is a metalcore band, the proposed
    answer is correct about this. Above all, the proposed answer correctly identifies
    that Serianna is a band of the metalcore genre, which combines elements of heavy
    metal and hardcore punk. However, the final answer is not plausible since it just
    lists the genres that metalcore combines.</foreignobject></g></g></svg> |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| <svg id="A2.T15.7.7.1.1.p1.pic1" class="ltx_picture" height="107.66" overflow="visible"
    version="1.1" width="603.94"><g transform="translate(0,107.66) matrix(1 0 0 -1
    0 0) translate(0,3.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 12.5)"><foreignobject
    width="559.25" height="78.72" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">证据表明 Serianna 是一支 metalcore 乐队，所提答案在这方面是正确的。总的来说，所提答案正确地识别了 Serianna
    是 metalcore 流派的乐队，这个流派结合了重金属和硬核朋克元素。然而，最终答案不太可信，因为它只是列出了 metalcore 结合的流派。</foreignobject></g></g></svg>
    |'
- en: 'Table 15: An LLM Evaluator Within Feedback-Learning Workflow (Tools), implemented
    with few-shot demonstrations. The content in the shadow box is generated by LLM.
    We omit some demonstrations for brevity. Source from Gou et al. ([2024](#bib.bib5)).'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 表 15：反馈学习工作流程中的 LLM 评估器（工具），通过少量示范实现。阴影框中的内容由 LLM 生成。为了简洁，我们省略了一些示范。来源于 Gou
    等（[2024](#bib.bib5)）。
- en: B.3 Prompts as Dynamic Models
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 作为动态模型的提示
- en: 'Table [16](#A2.T16 "Table 16 ‣ B.3 Prompts as Dynamic Models ‣ Appendix B Examples
    Prompts ‣ A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled
    Components") is profiled as a dynamic model.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [16](#A2.T16 "表 16 ‣ B.3 作为动态模型的提示 ‣ 附录 B 示例提示 ‣ 基于 LLM 的代理调查：常见工作流程和可重用的
    LLM 配置组件") 被描述为动态模型。
- en: '| Given a question, please decompose it into sub-questions. For each sub-question,
    please answer it in a complete sentence, ending with "The answer is". When the
    original question is answerable, please start the subquestion with "Now we can
    answer the question: ". |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 给定一个问题，请将其分解为子问题。对于每个子问题，请用完整的句子回答，并以“答案是”结尾。当原始问题可回答时，请以“现在我们可以回答这个问题：”开头。
    |'
- en: '| Question 1: Weng earns $12 an hour for babysitting. Yesterday, she just did
    50 minutes of babysitting. How much did she earn? |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1：翁每小时赚$12做保姆。昨天，她只做了50分钟的保姆工作。她赚了多少？ |'
- en: '| Question 1.1: How much does Weng earn per minute? |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1.1：翁每分钟赚多少钱？ |'
- en: '| Answer 1.1: Since Weng earns $12 an hour for babysitting, she earns $12 /
    60 = $0.2 per minute. The answer is 0.2. |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 答案 1.1：由于翁每小时赚$12做保姆，所以她每分钟赚$12 / 60 = $0.2。答案是 0.2。 |'
- en: '| Question 1.2: Now we can answer the question: How much did she earn? |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1.2：现在我们可以回答这个问题：她赚了多少？ |'
- en: '| Answer 1.2: Working 50 minutes, she earned $0.2 x 50 = $10\. The answer is
    10. |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 答案 1.2：工作了 50 分钟，她赚了 $0.2 x 50 = $10。答案是 10。 |'
- en: '| … |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| … |'
- en: '| Question 5: Janet’s ducks lay 16 eggs per day. She eats three for breakfast
    every morning and bakes muffins for her friends every day with four. She sells
    the remainder at the farmers’ market daily for $2 per fresh duck egg. How much
    in dollars does she make every day at the farmers’ market? |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 问题 5: Janet 的鸭子每天产 16 个鸡蛋。她每天早上吃三个鸡蛋，并用四个鸡蛋为朋友烤松饼。她每天在农贸市场以每个新鲜鸭蛋 2 美元的价格出售剩余的鸡蛋。她每天在农贸市场上赚多少钱？
    |'
- en: '| Question 5.1: How many eggs does Janet have left after eating three for breakfast
    and using four for muffins? |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 问题 5.1: Janet 吃掉三个鸡蛋作为早餐并用四个鸡蛋做了松饼后，还剩下多少个鸡蛋？ |'
- en: '| Answer 5.1: |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 答案 5.1: |'
- en: 'Table 16: An LLM-Profiled Dynamic Model.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '表 16: 一个 LLM 配置的动态模型。'
- en: Appendix C Creation of a Task-Agnostic Tool Environment
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 任务无关工具环境的创建
- en: Previous work always limits tools to specific applications like NLIE-QA, future
    work should aim to establish a comprehensive tool environment that encompasses
    a wide array of tools suitable for various tasks. A major challenge here is adapting
    a single actor to utilize such an environment effectively. While in-generation
    strategies are constrained as triggers are typically only straightforward for
    basic tools with simple arguments, a reasoning-acting strategy might offer more
    promise. Nonetheless, defining tools remains a challenge, especially in terms
    of efficient in-context learning or fine-tuning for tool utilization.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 以往的工作总是将工具限制在特定应用中，如 NLIE-QA，未来的工作应旨在建立一个涵盖各种任务的全面工具环境。一个主要挑战是调整单一演员以有效利用这样的环境。虽然生成策略受到限制，因为触发器通常仅对具有简单参数的基本工具有效，但推理-行动策略可能更具前景。然而，定义工具仍然是一个挑战，特别是在高效的上下文学习或工具利用的微调方面。
- en: Appendix D Stochastic $\text{glm}_{\text{actor}}$
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 随机 $\text{glm}_{\text{actor}}$
- en: Typically, a single action is sampled from the output of glmactor. Exploring
    a stochastic glmactor, which provides a distribution over possible actions, can
    enhance the stochastic nature of the glmpolicy and improve efficiency. This approach
    could include investigating constrained generation techniques (Willard and Louf,
    [2023](#bib.bib26)). Additionally, using such a distribution could efficiently
    serve as rewards for all possible actions, potentially eliminating the need for
    a separate glmeval to model rewards in certain workflows. This method allows for
    the simultaneous expansion of multiple potential nodes in one generation step,
    rather than expanding each node individually in search-based workflows (Hao et al.,
    [2023](#bib.bib7)).
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，从 glmactor 的输出中采样一个单一的动作。探索提供可能动作分布的随机 glmactor 可以增强 glmpolicy 的随机性质并提高效率。这种方法可能包括调查受限生成技术（Willard
    和 Louf，[2023](#bib.bib26)）。此外，使用这种分布可以有效地为所有可能的动作提供奖励，从而可能消除在某些工作流程中单独使用 glmeval
    来建模奖励的需求。这种方法允许在一个生成步骤中同时扩展多个潜在节点，而不是在基于搜索的工作流程中逐个扩展每个节点（Hao 等，[2023](#bib.bib7)）。
- en: Appendix E Memory
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 记忆
- en: The implementations of memory in the reviewed works are typically straightforward
    and arbitrary. Commonly, static information (e.g., profiling messages) is manually
    constructed and stored, whereas dynamic information (e.g., feedback) is handled
    via runtime data structures during interactions within each workflow. While the
    management of hybrid memory systems—requiring the explicit processing and management
    of short-term and long-term memory—is extensively discussed in a previous survey
    by Wang et al. ([2024](#bib.bib21)), such memory management aspects are beyond
    the focus of this survey, which centers on LLM-based workflows.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查的工作中，记忆的实现通常是直接且任意的。通常，静态信息（例如，配置消息）是手动构建并存储的，而动态信息（例如，反馈）则通过每个工作流程中的运行时数据结构进行处理。尽管混合记忆系统的管理——需要明确处理和管理短期和长期记忆——在
    Wang 等人的早期调查中被广泛讨论过（[2024](#bib.bib21)），这些记忆管理方面超出了本调查的范围，本调查重点关注基于 LLM 的工作流程。
