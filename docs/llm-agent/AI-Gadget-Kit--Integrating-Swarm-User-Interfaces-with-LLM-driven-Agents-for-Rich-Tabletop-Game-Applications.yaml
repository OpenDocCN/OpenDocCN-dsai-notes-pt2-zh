- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:40:44'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:40:44
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'AI-Gadget Kit: 将群体用户界面与基于LLM的智能体集成以丰富桌面游戏应用'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.17086](https://ar5iv.labs.arxiv.org/html/2407.17086)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.17086](https://ar5iv.labs.arxiv.org/html/2407.17086)
- en: Yijie Guo Tsinghua UniversityBeijingChina [guoyijie.sh@gmail.com](mailto:guoyijie.sh@gmail.com)
    ,  Zhenhan Huang University of TsukubaTsukubaJapan [zhenhan.email.jp@gmail.com](mailto:zhenhan.email.jp@gmail.com)
    ,  Ruhan Wang Tsinghua UniversityBeijingChina [wangrh22@mails.tsinghua.edu.cn](mailto:wangrh22@mails.tsinghua.edu.cn)
    ,  Zhihao Yao Tsinghua University30 Shuangqing RdBeijingChina [yaozh˙h@outlook.com](mailto:yaozh%CB%99h@outlook.com)
    ,  Tianyu Yu Tsinghua UniversityBeijingChina [yty21@mails.tsinghua.edu.cn](mailto:yty21@mails.tsinghua.edu.cn)
    ,  Zhiling Xu Tsinghua UniversityBeijingChina [xzl23@mails.tsinghua.edu.cn](mailto:xzl23@mails.tsinghua.edu.cn)
    ,  Xinyu Zhao Tsinghua UniversityBeijingChina [xyzhao23@mails.tsinghua.edu.cn](mailto:xyzhao23@mails.tsinghua.edu.cn)
    ,  Xueqing Li Tsinghua UniversityBeijingChina [li-xq23@mails.tsinghua.edu.cn](mailto:li-xq23@mails.tsinghua.edu.cn)
     and  Haipeng Mi Tsinghua UniversityBeijingChina [mhp@tsinghua.edu.cn](mailto:mhp@tsinghua.edu.cn)(2018;
    20 February 2007; 12 March 2009; 5 June 2009)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yijie Guo Tsinghua UniversityBeijingChina [guoyijie.sh@gmail.com](mailto:guoyijie.sh@gmail.com)
    , Zhenhan Huang University of TsukubaTsukubaJapan [zhenhan.email.jp@gmail.com](mailto:zhenhan.email.jp@gmail.com)
    , Ruhan Wang Tsinghua UniversityBeijingChina [wangrh22@mails.tsinghua.edu.cn](mailto:wangrh22@mails.tsinghua.edu.cn)
    , Zhihao Yao Tsinghua University30 Shuangqing RdBeijingChina [yaozh˙h@outlook.com](mailto:yaozh%CB%99h@outlook.com)
    , Tianyu Yu Tsinghua UniversityBeijingChina [yty21@mails.tsinghua.edu.cn](mailto:yty21@mails.tsinghua.edu.cn)
    , Zhiling Xu Tsinghua UniversityBeijingChina [xzl23@mails.tsinghua.edu.cn](mailto:xzl23@mails.tsinghua.edu.cn)
    , Xinyu Zhao Tsinghua UniversityBeijingChina [xyzhao23@mails.tsinghua.edu.cn](mailto:xyzhao23@mails.tsinghua.edu.cn)
    , Xueqing Li Tsinghua UniversityBeijingChina [li-xq23@mails.tsinghua.edu.cn](mailto:li-xq23@mails.tsinghua.edu.cn)
    和 Haipeng Mi Tsinghua UniversityBeijingChina [mhp@tsinghua.edu.cn](mailto:mhp@tsinghua.edu.cn)(2018；2007年2月20日；2009年3月12日；2009年6月5日)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: While Swarm User Interfaces (SUIs) have succeeded in enriching tangible interaction
    experiences, their limitations in autonomous action planning have hindered the
    potential for personalized and dynamic interaction generation in tabletop games.
    Based on the AI-Gadget Kit we developed, this paper explores how to integrate
    LLM-driven agents within tabletop games to enable SUIs to execute complex interaction
    tasks. After defining the design space of this kit, we elucidate the method for
    designing agents that can extend the meta-actions of SUIs to complex motion planning.
    Furthermore, we introduce an add-on prompt method that simplifies the design process
    for four interaction behaviors and four interaction relationships in tabletop
    games. Lastly, we present several application scenarios that illustrate the potential
    of AI-Gadget Kit to construct personalized interaction in SUI tabletop games.
    We expect to use our work as a case study to inspire research on multi-agent-driven
    SUI for other scenarios with complex interaction tasks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然群体用户界面（SUIs）在丰富触觉交互体验方面取得了成功，但其在自主行动规划方面的局限性阻碍了个性化和动态交互生成在桌面游戏中的潜力。基于我们开发的AI-Gadget
    Kit，本文探讨了如何将基于大型语言模型（LLM）的智能体集成到桌面游戏中，以使SUIs能够执行复杂的交互任务。在定义了该工具包的设计空间之后，我们阐述了设计智能体的方法，这些智能体能够将SUIs的元操作扩展到复杂的运动规划。此外，我们介绍了一种附加提示方法，该方法简化了四种交互行为和四种交互关系在桌面游戏中的设计过程。最后，我们展示了几个应用场景，这些场景说明了AI-Gadget
    Kit在SUI桌面游戏中构建个性化交互的潜力。我们期望以我们的工作作为案例研究，激发对多智能体驱动的SUI在其他复杂交互任务场景中的研究。
- en: 'Personalization; Tangible UIs; LLM-Based Agent; Tabletop Game; Swarm User Interface^†^†copyright:
    acmcopyright^†^†journalyear: 2018^†^†doi: XXXXXXX.XXXXXXX^†^†conference: Make
    sure to enter the correct conference title from your rights confirmation emai;
    June 03–05, 2018; Woodstock, NY^†^†price: 15.00^†^†isbn: 978-1-4503-XXXX-X/18/06^†^†ccs:
    Human-centered computing Interaction devices![Refer to caption](img/6e1b6d0564cb53324b804cf0b8463959.png)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 个性化；触觉用户界面；基于LLM的智能体；桌面游戏；群体用户界面^†^†版权：acmcopyright^†^†期刊年份：2018^†^†doi：XXXXXXX.XXXXXXX^†^†会议：确保输入正确的会议标题，来自您的版权确认邮件；2018年6月3日至5日；纽约伍德斯托克^†^†价格：15.00^†^†ISBN：978-1-4503-XXXX-X/18/06^†^†CCS：以人为中心的计算
    交互设备![参见说明](img/6e1b6d0564cb53324b804cf0b8463959.png)
- en: Figure 1\. Building a tabletop game with a multi-agent system enabled by AI-Gaget
    Kit. a) Extend the meta actions of SUIs to gadgets’ complex motion planning, b)
    interaction behavior generation, c) interaction relationship management. d) Robotic
    gadget plays a turn-based strategy game with a human player.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 利用AI-Gaget Kit构建一个多代理系统的桌面游戏。a) 扩展SUIs的元动作至小工具的复杂运动规划，b) 互动行为生成，c) 互动关系管理。d)
    机器人小工具与人类玩家进行回合制策略游戏。
- en: \Description
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: Building a tabletop game with a multi-agent system enabled by AI-Gaget Kit.
    a) Extend the meta actions of SUIs to gadgets’ complex motion planning, b) interaction
    behavior generation, c) interaction relationship management. d) Robotic gadget
    plays a turn-based strategy game with a human player.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 利用AI-Gaget Kit构建一个多代理系统的桌面游戏。a) 扩展SUIs的元动作至小工具的复杂运动规划，b) 互动行为生成，c) 互动关系管理。d)
    机器人小工具与人类玩家进行回合制策略游戏。
- en: 1\. Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: Swarm User Interface (SUI) as an emerging interface has garnered significant
    attention from researchers. Researchers have explored multiple application scenarios
    of SUI, such as data physicalization(Suzuki et al., [2019](#bib.bib29)), remote
    collaboration(Ihara et al., [2023](#bib.bib10)), and educational purposes(Kaimoto
    et al., [2022](#bib.bib13)), based on the unique tangible interaction behaviors
    of SUI, such as collaborative motion, objects actuation, or self-shape changes.
    However, most existing SUIs utilize a pre-programmed set of action planning rules
    to execute different interaction tasks during use, i.e., users need to program
    the action each time they face a new interaction task. This approach struggles
    to adapt to real-world tasks that are usually more complex, dynamic, and possibly
    changeable beyond the pre-programmed scope.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 蜂群用户界面（SUI）作为一种新兴界面，已经引起了研究人员的广泛关注。研究人员探索了SUI的多个应用场景，如数据物化（Suzuki等，[2019](#bib.bib29)）、远程协作（Ihara等，[2023](#bib.bib10)）和教育目的（Kaimoto等，[2022](#bib.bib13)），基于SUI独特的可触摸互动行为，如协作运动、物体驱动或自我形状变化。然而，大多数现有的SUI利用预编程的动作规划规则来执行不同的互动任务，即用户每次面对新的互动任务时都需要编程这些动作。这种方法难以适应通常更复杂、动态且可能超出预编程范围的现实任务。
- en: In recent years, Large Language Models (LLM) have shown benefits for robotic
    motion control and planning. Based on the embedded knowledge of LLMs, they are
    capable of understanding and reasoning about the complex contexts in different
    tasks, thus dynamically generating responses, e.g., motion planning, based on
    the contexts in the tasks. Traditional methods for robotic motion planning included
    using one-decision models, which relied on the prediction of every step of the
    robot’s movement(Gan et al., [2020](#bib.bib5); Wang et al., [2020](#bib.bib32)).
    Recent research has explored using LLMs, particularly LLM-driven agents, to conduct
    robotic motion planning for more complex interaction tasks. For instance, DiscussNav(Long
    et al., [2023](#bib.bib18)) has used multiple LLM agents with different expertise
    to make decisions for robotic navigation in a complex interior scenario. Nevertheless,
    most of these works focused on single-robot systems. Research on multiple-robot
    systems, e.g., SUI, and how to use LLMs to assist the motion planning of these
    systems for complex interaction tasks still remains unexplored.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLM）在机器人运动控制和规划中显示出了益处。基于LLMs的嵌入知识，它们能够理解和推理不同任务中的复杂上下文，从而动态生成响应，例如，根据任务中的上下文进行运动规划。传统的机器人运动规划方法包括使用单一决策模型，这依赖于对机器人每一步运动的预测（Gan等，[2020](#bib.bib5)；Wang等，[2020](#bib.bib32)）。近期研究探索了使用LLMs，特别是LLM驱动的代理，来进行更复杂互动任务的机器人运动规划。例如，DiscussNav（Long等，[2023](#bib.bib18)）利用多种具有不同专业知识的LLM代理在复杂室内场景中进行机器人导航决策。然而，这些工作大多集中在单机器人系统上。关于多机器人系统（如SUI）以及如何使用LLMs来辅助这些系统在复杂互动任务中的运动规划的研究仍未得到探讨。
- en: Among the various applications of SUI, the tabletop game is a typical scenario
    that contains versatile complex interaction tasks. Existing research has explored
    the application of tangible and swarm user interfaces in tabletop games to enhance
    interactivity and enjoyment, such as using robots to facilitate embodied AI players(Matuszek
    et al., [2011](#bib.bib19); van Breemen et al., [2005](#bib.bib30)), robotic game
    masters (Gillet et al., [2020](#bib.bib6)), and automated gadgets(Brock et al.,
    [2021](#bib.bib2); Jariyavajee et al., [2018](#bib.bib11)). However, the action
    planning for robots in these studies still relies on pre-programmed rules, which
    makes it challenging to execute the complex interaction tasks in tabletop games,
    such as understanding and reacting to complex game narratives, improvised decisions
    of players, or emotional expressions from players.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种 SUI 应用中，桌面游戏是一个典型的场景，包含多种复杂的互动任务。现有研究已经探讨了在桌面游戏中应用可触摸和群体用户界面，以增强互动性和趣味性，例如使用机器人来促进具身
    AI 玩家（Matuszek et al., [2011](#bib.bib19); van Breemen et al., [2005](#bib.bib30)），机器人游戏主持人（Gillet
    et al., [2020](#bib.bib6)），以及自动化小工具（Brock et al., [2021](#bib.bib2); Jariyavajee
    et al., [2018](#bib.bib11)）。然而，这些研究中的机器人行动规划仍依赖于预编程规则，这使得在桌面游戏中执行复杂的互动任务变得具有挑战性，例如理解和回应复杂的游戏叙事、玩家的即兴决策或玩家的情感表达。
- en: In this paper, we aimed to use the tabletop game as a case study to explore
    the application of LLMs on action planning of SUI in scenarios with complex interaction
    tasks. We proposed AI-gadget Kit, a multi-agent SUI tabletop gaming system, which
    is designed to facilitate dynamic and complex interaction tasks in tabletop games.
    We first introduced the system architecture of the AI-gadget Kit, which includes
    a set of swarm robots based on existing platforms to perform the gadget behaviors,
    and a multi-agent system responsible for executing the game and generating action
    plans for the swarm robots. We then elaborated the design of the multi-agent system,
    comprising a series of meta-motions for individual robots, two LLM-based agents
    for complex action planning, and a set of add-on prompts aimed at reinforcing
    the understanding and reacting capabilities of the agents. At last, we demonstrate
    four application examples using AI-gadget Kit to showcase the effect of the multi-agent-driven
    SUI on executing complex interaction tasks in tabletop games. Through this work,
    we aim to inspire the research of multi-agent-driven SUI on other scenarios with
    complex interaction tasks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们旨在使用桌面游戏作为案例研究，以探讨 LLM 在 SUI 行动规划中在复杂互动任务场景中的应用。我们提出了 AI-gadget Kit，这是一种多智能体
    SUI 桌面游戏系统，旨在促进桌面游戏中的动态和复杂互动任务。我们首先介绍了 AI-gadget Kit 的系统架构，包括一组基于现有平台的群体机器人，用于执行小工具行为，以及一个负责执行游戏并为群体机器人生成行动计划的多智能体系统。然后，我们详细阐述了多智能体系统的设计，包括一系列针对单个机器人的元动作、两个基于
    LLM 的代理用于复杂行动规划，以及一组旨在强化代理理解和反应能力的附加提示。最后，我们展示了使用 AI-gadget Kit 的四个应用示例，以展示多智能体驱动的
    SUI 在桌面游戏中执行复杂互动任务的效果。通过这项工作，我们希望激发对多智能体驱动的 SUI 在其他复杂互动任务场景中的研究。
- en: 'In summary, the contribution of this paper includes:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本文的贡献包括：
- en: (1)
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: AI-gadget Kit, a multi-agent SUI tabletop gaming system, which consists of a
    series of meta-motions for individual robots, two LLM-based agents for complex
    action planning, and a series of add-on prompts tailored to the tabletop gaming
    scenario to enhance the understanding capability of the multi-agent system.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AI-gadget Kit 是一个多智能体 SUI 桌面游戏系统，由一系列针对单个机器人的元动作、两个基于 LLM 的代理用于复杂的行动规划，以及一系列针对桌面游戏场景量身定制的附加提示组成，以增强多智能体系统的理解能力。
- en: (2)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: A set of application examples using AI-gadget Kit on tabletop games, which demonstrates
    the effect of agent-driven swarm robots as gadgets in tabletop games for complex
    interaction tasks.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用 AI-gadget Kit 在桌面游戏中的一组应用示例，展示了代理驱动的群体机器人作为小工具在桌面游戏中处理复杂互动任务的效果。
- en: 2\. Related work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 相关工作
- en: 2.1\. Swarm User Interface
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 群体用户界面
- en: Compared to traditional Tangible User Interfaces (TUI), Swarm User Interfaces
    (SUI) introduce multiple moving robots that enable collaborative motion, providing
    a flexible and extensive physical interaction space and multi-modal interaction
    experiences.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的可触摸用户界面 (TUI) 相比，群体用户界面 (SUI) 引入了多个移动的机器人，能够实现协作运动，提供了灵活而广泛的物理互动空间和多模态互动体验。
- en: Researchers in Human-Computer Interaction (HCI) have explored various applications
    of SUI. For instance, SwarmHaptic(Kim and Follmer, [2019](#bib.bib14)) utilized
    small wheeled swarm robots moving on a flat surface to construct a novel tactile
    interface. Rovables(Dementyev et al., [2016](#bib.bib3)) provided a series of
    robots that were capable of autonomous movement on wearable clothing, proposing
    an interaction space for sensing and actuation on wearables. ShapeBots(Suzuki
    et al., [2019](#bib.bib29)) enabled a group of self-deforming robots to individually
    or collectively change their configuration to display information in physical
    space. Additionally, Holobots(Ihara et al., [2023](#bib.bib10)) proposed a mixed-reality
    remote collaboration system augmenting holographic telepresence with synchronized
    mobile robots. Out of academia, SUIs have also demonstrated extensive application
    prospects in education and entertainment scenarios. Sony employs programmable
    small robots called Toio¹¹1https://toio.io/ to engage learners from elementary
    to adult in logical thinking and learning programming Thymo²²2https://www.thymio.org/
    robots provide STEM education for learners of all ages.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 人机交互（HCI）领域的研究人员探索了 SUI 的各种应用。例如，SwarmHaptic（Kim 和 Follmer，[2019](#bib.bib14)）利用在平面上移动的小型轮式群体机器人来构建一种新颖的触觉界面。Rovables（Dementyev
    等，[2016](#bib.bib3)）提供了一系列能够在可穿戴服装上自主移动的机器人，提出了一种在可穿戴设备上进行传感和执行的交互空间。ShapeBots（Suzuki
    等，[2019](#bib.bib29)）使一组自我变形的机器人能够单独或集体地改变其配置，以在物理空间中显示信息。此外，Holobots（Ihara 等，[2023](#bib.bib10)）提出了一种混合现实远程协作系统，通过同步移动机器人增强全息远程存在感。除了学术界，SUI
    在教育和娱乐场景中也展现了广泛的应用前景。索尼采用了名为 Toio¹¹1https://toio.io/ 的可编程小型机器人，以吸引从小学生到成人的学习者进行逻辑思维和编程学习；Thymo²²2https://www.thymio.org/
    机器人为各年龄段的学习者提供 STEM 教育。
- en: However, most existing SUIs utilize a pre-programmed set of action planning
    rules to execute different interaction tasks during use. For example, although
    Holobots creatively proposed six interaction types for remote collaboration, constrained
    by predetermined programming, they struggled to dynamically generate personalized
    tactile feedback based on users’ flexible needs during actual usage. Thus, a system
    that is capable of understanding and reacting to complex interaction tasks will
    significantly improve the generalizability of interaction behaviors of SUIs in
    these works.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数现有的 SUIs 使用预设的一组行动规划规则来执行不同的交互任务。例如，尽管 Holobots 创造性地提出了六种远程协作的交互类型，但由于受限于预先设定的编程，他们在实际使用中很难根据用户的灵活需求动态生成个性化的触觉反馈。因此，能够理解和应对复杂交互任务的系统将显著提高这些作品中
    SUIs 交互行为的普遍适应性。
- en: 2.2\. Agents for Action Planning
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2. 行动规划的代理
- en: In the domain of robotics, researchers aim to issue high-level instructions
    to robotic agents. These agents automatically translate the instructions into
    low-level actions for execution by robots, eliminating the need for humans to
    manually program. The Skill Transformer(Huang et al., [2023a](#bib.bib9)), leveraging
    a neural network model based on the Transformer architecture(Vaswani et al., [2017](#bib.bib31)),
    predicts low-level actions for robots, enabling them to accomplish embodied tasks
    of moving objects to specified targets and locations in complex environments.
    With the advent of Large Language Models (LLMs), researchers have sought to harness
    LLMs’ robust natural language understanding capabilities to process generalized,
    natural language-based embodied instructions. For example, March in Chat(Qiao
    et al., [2023](#bib.bib22)) interacts with agents, LLMs, and VLMs to navigate
    daily activity scenes based on vague natural language instructions. VoxPoser(Huang
    et al., [2023b](#bib.bib8)) estimates the potential benefits and losses of objects
    in a scene towards fulfilling an instruction using LLMs, generating a 3D value
    map of the scene to derive the robot’s trajectory.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器人领域，研究人员旨在向机器人代理发布高级指令。这些代理自动将指令转换为低级动作以供机器人执行，从而无需人工编程。Skill Transformer（Huang
    et al., [2023a](#bib.bib9)）利用基于Transformer架构（Vaswani et al., [2017](#bib.bib31)）的神经网络模型，预测机器人的低级动作，使其能够完成将物体移动到复杂环境中的指定目标和位置的任务。随着大型语言模型（LLMs）的出现，研究人员试图利用LLMs强大的自然语言理解能力来处理基于自然语言的通用指令。例如，Chat中的March（Qiao
    et al., [2023](#bib.bib22)）通过与代理、LLMs和VLMs的交互，根据模糊的自然语言指令来导航日常活动场景。VoxPoser（Huang
    et al., [2023b](#bib.bib8)）利用LLMs估计场景中物体对完成指令的潜在收益和损失，生成场景的3D价值图以推导机器人的轨迹。
- en: Researchers have also recognized that collaborative decision-making among multiple
    agents for a robot’s actions can enable adaptation to more complex scenarios compared
    to decisions made by a single agent alone. DiscussNav(Long et al., [2023](#bib.bib18))
    is used to address navigation problems in complex scenes, where robots take each
    step with the involvement of multiple LLM/VLM agents with different specialties,
    enhancing the robots’ generalization ability in navigation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员还认识到，多代理的协作决策可以使机器人适应比单一代理所做的决策更复杂的场景。DiscussNav（Long et al., [2023](#bib.bib18)）用于解决复杂场景中的导航问题，其中机器人每一步都涉及多个具有不同专长的LLM/VLM代理，从而增强机器人的导航泛化能力。
- en: Despite existing research has shown feasible performance in action planning
    and robotic control for embodied agents, their validation of task planning for
    embodied tasks has been primarily confined to operational tasks in daily routine
    scenes (Huang et al., [2023a](#bib.bib9), [b](#bib.bib8)) and navigation tasks(Long
    et al., [2023](#bib.bib18)) with less emphasis on other certain genres of task
    scenarios, e.g., fictional narrative settings. Moreover, its interaction planning
    capabilities in user interfaces driven by multiple robots also require validation.
    Exploring the integration of LLM-based agents with SUI will broaden the application
    scenarios and interaction cases for related work in robotics.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现有研究在行动规划和机器人控制方面已显示出对体现代理的可行性，但对体现任务的任务规划验证主要限于日常常规场景（Huang et al., [2023a](#bib.bib9),
    [b](#bib.bib8)）和导航任务（Long et al., [2023](#bib.bib18)），而对其他特定任务场景，如虚构叙事设置，则关注较少。此外，其在由多个机器人驱动的用户界面中的交互规划能力也需要验证。探索基于LLM的代理与SUI的集成将拓宽机器人相关工作的应用场景和交互案例。
- en: 2.3\. Robots in Tabletop Game
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 桌面游戏中的机器人
- en: In recent years, researchers have explored the application of tangible and swarm
    user interfaces in tabletop games to enhance interactivity and enjoyment.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，研究人员探索了在桌面游戏中应用有形和群体用户界面，以增强互动性和趣味性。
- en: With the emerging trend of robots being small and versatile, more and more robots
    are used as embodied AI players or gadgets in tabletop games. For example, Brock
    et al.(Brock et al., [2021](#bib.bib2)) utilized the robot Haru to simulate the
    behavior of remote human players. Researchers also used robots to serve as robotic
    gadgets in the game, such as creating chess that can move automatically to enable
    novel and compelling interaction experiences(Jariyavajee et al., [2018](#bib.bib11)).
    Sparkybot(Guo et al., [2023](#bib.bib7)) allowed children to use mobile robots
    as different actors in storytelling games to enhance children’s creativity.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器人越来越小巧且多功能，越来越多的机器人被用作桌面游戏中的具身 AI 玩家或小工具。例如，Brock 等人（Brock et al., [2021](#bib.bib2)）利用机器人
    Haru 模拟远程人类玩家的行为。研究人员还使用机器人作为游戏中的机器人小工具，例如创建可以自动移动的棋盘，以实现新颖且引人入胜的交互体验（Jariyavajee
    et al., [2018](#bib.bib11)）。Sparkybot（Guo et al., [2023](#bib.bib7)）允许孩子们在讲故事游戏中使用移动机器人作为不同的角色，以增强孩子们的创造力。
- en: These works, that use SUI for tabletop games, provide rich user interaction
    spaces. However, the action planning for robots in these studies still relies
    on pre-programmed rules, which makes it challenging to execute the complex interaction
    tasks in tabletop games, such as understanding and reacting to complex game narratives,
    improvised decisions of players, or emotional expressions from players. In this
    work, we aimed to leverage LLM-based agents to assist action planning for SUI,
    in order to execute complex interaction behaviors of the gadgets in tabletop games.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些使用 SUI 进行桌面游戏的工作提供了丰富的用户交互空间。然而，这些研究中的机器人行动规划仍依赖于预编程规则，这使得执行桌面游戏中的复杂交互任务具有挑战性，例如理解和响应复杂的游戏叙事、玩家的即兴决定或玩家的情感表达。在这项工作中，我们旨在利用基于
    LLM 的智能体来协助 SUI 的行动规划，以便执行桌面游戏中小工具的复杂交互行为。
- en: 3\. System Architecture of AI-Gaget Kit
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. AI-Gadget Kit 的系统架构
- en: 'The system architecture of AI-Gadget Kit, shown in Figure[2](#S3.F2 "Figure
    2 ‣ 3\. System Architecture of AI-Gaget Kit ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications"),
    consists of an SUI platform, a localization system, a server, and a LLM-based
    multi-agent system. The SUI platform includes multiple independent robots, which
    are used to actuate various gadget behaviors in tabletop games. The localization
    system comprises a camera and multiple on-robot markers, used to obtain the position
    and orientation of each robot. The server obtains users’ text or verbal input
    commands, as well as robots’ position and orientation data, and then sends them
    to the LLM-based multi-agent system for information processing. The server also
    receives the actuations generated by the multi-agent system, playing sound effects,
    or sending action sequences to the robots in the SUI platform. The LLM-based multi-agent
    system is responsible for the execution of the core game interactions. Based on
    the game’s rules and knowledge, the multi-agent system responds to user commands,
    reasons the gadget behaviors in the game, and then generates the action sequences
    to control the SUI robots.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'AI-Gadget Kit 的系统架构如图[2](#S3.F2 "图 2 ‣ 3\. AI-Gadget Kit 的系统架构 ‣ AI-Gadget
    Kit: 将集群用户界面与基于 LLM 的智能体整合用于丰富的桌面游戏应用")所示，由一个 SUI 平台、一个定位系统、一个服务器和一个基于 LLM 的多智能体系统组成。SUI
    平台包括多个独立的机器人，这些机器人用于在桌面游戏中驱动各种小工具行为。定位系统包括一个摄像头和多个机器人上的标记，用于获取每个机器人的位置和方向。服务器获取用户的文本或语音输入命令，以及机器人的位置和方向数据，然后将其发送到基于
    LLM 的多智能体系统进行信息处理。服务器还接收由多智能体系统生成的动作，播放声音效果，或将动作序列发送到 SUI 平台上的机器人。基于 LLM 的多智能体系统负责核心游戏交互的执行。根据游戏的规则和知识，多智能体系统响应用户命令，推理游戏中的小工具行为，然后生成动作序列以控制
    SUI 机器人。'
- en: In this project, we utilized a 1m*1m tabletop as the interaction space. The
    space was divided into a 30*30 coordinate system, with the east and north directions
    serving as the positive directions of x and y axes, respectively. We used Sony’s
    Toio robots as the SUI platform. Each individual robot has dimensions of 3.2*3.2*2.5cm.
    We used a PC as the server, which communicates with Toio robots via Bluetooth
    and communicates with the LLM via WiFi. In our localization system, we employed
    an imx415 network IP camera, positioned 1m above the tabletop, and we used ArUco
    codes as the localization markers on the robots. The server retrieves the video
    stream from the camera using the RTSP protocol and uses the Python OpenCV to track
    the position and orientation of each robot. We developed the multi-agent system
    based on GPT4 LLM. The design of the multi-agent system is introduced as follows.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们使用了一个1m*1m的桌面作为交互空间。该空间被划分为一个30*30的坐标系统，东和北方向分别作为x轴和y轴的正方向。我们使用了Sony的Toio机器人作为SUI平台。每个机器人尺寸为3.2*3.2*2.5cm。我们使用PC作为服务器，通过蓝牙与Toio机器人通信，通过WiFi与LLM通信。在我们的定位系统中，我们使用了一个imx415网络IP摄像头，摄像头位置在桌面上方1m处，并且使用了ArUco代码作为机器人上的定位标记。服务器通过RTSP协议从摄像头检索视频流，并使用Python
    OpenCV跟踪每个机器人的位置和方向。我们基于GPT4 LLM开发了多智能体系统。多智能体系统的设计如下介绍。
- en: '![Refer to caption](img/78a4871fae79948792920f1a2fedff80.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/78a4871fae79948792920f1a2fedff80.png)'
- en: Figure 2\. System Architecture of AI-Gadget Kit.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. AI-Gadget Kit的系统架构。
- en: 4\. Multi-agent system
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 多智能体系统
- en: In the AI-Gadget Kit, we utilized a multi-agent system to compute the core interaction
    of the game. Based on the rules, and knowledge of the game, the system responds
    to the user’s command, reasons the gadget behaviors within the game, and then
    generates the action sequences to control the SUI robots.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI-Gadget Kit中，我们利用多智能体系统计算游戏的核心交互。根据规则和游戏知识，系统响应用户的命令，推理游戏中的小工具行为，然后生成控制SUI机器人的动作序列。
- en: To build the multi-agent system, we first defined a set of meta-actions for
    each single robot, and then designed a two-agent system, including a Coordinator
    agent and a Controller agent, to learn and use those meta-actions for complex
    motion planning. We also designed a set of add-on prompts, including prompts for
    Interaction behavior planning and Interaction relationship planning, to enhance
    the agents to understand and react to complex interactions during the game.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建多智能体系统，我们首先为每个单独的机器人定义了一组元动作，然后设计了一个包括协调器代理和控制器代理的双智能体系统，以学习和使用这些元动作进行复杂的运动规划。我们还设计了一组附加提示，包括互动行为规划和互动关系规划的提示，以增强代理对游戏中复杂交互的理解和反应能力。
- en: '![Refer to caption](img/e7a626717ec12a88e880af8a3749fe5d.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e7a626717ec12a88e880af8a3749fe5d.png)'
- en: Figure 3\. Design space for SUI action planning in tabletop game scenarios through
    our kit. The kit includes a two-agent system(d) that can generate action sequences
    for gadgets to complete interaction tasks based on eight meta-actions (a), four
    types of interaction behaviors (b), and four types of interaction relationships
    (c).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. 通过我们的工具包在桌面游戏场景中设计SUI动作规划的设计空间。该工具包包括一个可以根据八种元动作（a）、四种类型的互动行为（b）和四种类型的互动关系（c）生成小工具动作序列的双智能体系统（d）。
- en: 4.1\. Meta-action for Individual Robot
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 单个机器人的元动作
- en: 'To leverage the LLM-based agents for planning and generating complex actions
    for our SUI, we first defined the primitive movement patterns of an individual
    robot, i.e., meta-actions (Figure [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system
    ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications")a). An individual Toio robot moves by controlling
    the motors of the two wheels. Thus, in this work, we controlled the robot’s meta-action
    by controlling the rotation direction (clockwise by default or anti-clockwise),
    speed (three levels - 10, 20, or 30³³3Speed values in Toio platform), and the
    duration (x seconds) of each motor.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '为了利用基于LLM的代理进行规划和生成复杂动作，我们首先定义了单个机器人的原始运动模式，即元动作（见图[3](#S4.F3 "Figure 3 ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")a）。单个Toio机器人通过控制两个轮子的电机来移动。因此，在本工作中，我们通过控制电机的旋转方向（默认顺时针或逆时针）、速度（三个级别
    - 10、20 或 30³³3速度值在Toio平台中）和每个电机的持续时间（x秒）来控制机器人的元动作。'
- en: 'We categorized the robot’s meta-actions into two types of movements: translation
    and rotation, defined as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将机器人的元动作分为两种类型的运动：平移和旋转，定义如下：
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Rotation:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 旋转：
- en: –
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: 'Rotation A: The robot rotates around its center, by spinning its wheels in
    opposite directions at the same speed for a specified seconds, achieving a precise
    angle of rotation.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 旋转 A：机器人围绕其中心旋转，通过以相同速度在指定时间内使车轮朝相反方向旋转，实现精确的旋转角度。
- en: –
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: 'Rotation B: The robot rotates around one side of itself, by spinning only one
    wheel for a specified seconds, achieving a specific angle of rotation.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 旋转 B：机器人围绕自身的一侧旋转，通过在指定时间内仅使一个车轮旋转，实现特定的旋转角度。
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Translation: The robot adjusts its orientation to the desired direction through
    Rotation A, followed by spinning both wheels in the same direction and speed for
    a few seconds to achieve linear translation over a specific distance.'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平移：机器人通过旋转 A 调整其方向至期望方向，然后以相同方向和速度旋转两个车轮几秒钟，实现沿特定距离的线性平移。
- en: During each movement, the server determines the duration based on a simple calculation
    of expected translation or rotation displacement and official kinematic data⁴⁴4https://toio.github.io/toio-spec/en/docs/hardware_components.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次运动中，服务器根据对预期平移或旋转位移的简单计算和官方运动学数据⁴⁴4https://toio.github.io/toio-spec/en/docs/hardware_components
    确定持续时间。
- en: 'Furthermore, considering interactions between multiple robots, we designed
    another type of meta-action to adjust their relative orientations, including face-to-face,
    back-to-back, face-to-back, parallel, and counter-parallel, defined and illustrated
    in Figure [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")a.
    The two robots conducting one of these meta-actions adjust their orientations
    by executing Rotation A for a time.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，考虑到多个机器人之间的互动，我们设计了另一种类型的元动作来调整它们的相对方向，包括面对面、背对背、面对背面、平行和反平行，定义并在图 [3](#S4.F3
    "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications")a 中进行了说明。这两台机器人执行这些元动作之一，通过执行旋转
    A 来调整其方向。'
- en: By repeatedly calling and combining these three types of meta-actions with custom
    parameters, the agents in the AI-Gadget kit could generate multiple actions in
    sequences to facilitate the complex motion planning of these robots in SUI.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重复调用和组合这三种类型的元动作以及自定义参数，AI-Gadget 套件中的代理能够生成多个动作序列，以促进这些机器人在 SUI 中的复杂运动规划。
- en: 4.2\. Complex Motion Planning
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 复杂运动规划
- en: 'To facilitate the complex motion planning for SUI to execute the gadget behaviors
    in tabletop games, we developed an LLM-based two-agent system, that aims to understand
    and react to the game contexts and then generate the action sequences for the
    robots (Figure [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit:
    Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game
    Applications")d). Specifically, we proposed two agents in the system with expert
    prompts: Coordinator and Controller:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '为了促进 SUI 执行桌面游戏中的小工具行为的复杂运动规划，我们开发了一个基于 LLM 的双代理系统，该系统旨在理解和响应游戏上下文，然后生成机器人的动作序列（图
    [3](#S4.F3 "Figure 3 ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")d）。具体而言，我们在系统中提出了两个专家代理：协调者和控制者：'
- en: (1) Coordinator Agent. The operation in a tabletop game typically involves the
    user’s commands and the processing of context information. Taking chess as an
    example, if the user inputs a command of ”move the queen to A1”, the execution
    of this command involves the actual movement of the queen, and processing of context
    information such as the dimensions of the chessboard, the queen’s movement rules,
    and whether an opponent’s piece can be captured. Hence, we designed a Coordinator
    agent to respond by processing the players’ commands and the game context information,
    then reasoning the commands for each gadget within this interaction step. In the
    prompts for Coordinator, we asked the agent to act as administrator, coordinator,
    and referee in the game. We added the description of a series of duties to the
    prompts, such as explaining rules, coordinating actions, and updating game states.
    We also inputted the game’s environmental settings to the prompts, including the
    size of the map and the coordinate system.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 协调器代理。桌面游戏中的操作通常涉及用户的命令和上下文信息的处理。以国际象棋为例，如果用户输入“将皇后移动到A1”的命令，那么执行该命令包括皇后的实际移动，以及处理上下文信息如棋盘的尺寸、皇后的移动规则以及是否可以吃掉对方棋子。因此，我们设计了一个协调器代理，通过处理玩家的命令和游戏上下文信息来响应，然后推理在该交互步骤中每个小工具的命令。在协调器的提示中，我们要求代理在游戏中充当管理员、协调员和裁判的角色。我们在提示中增加了一系列职责的描述，例如解释规则、协调动作和更新游戏状态。我们还将游戏的环境设置输入到提示中，包括地图的大小和坐标系统。
- en: Note that, to allow the Coordinator agent to focus on game operations, we employed
    a ”reality-agnostic” approach. Specifically, the Coordinator only facilitates
    the execution of the game, without dealing with the physical parameters of the
    SUI robots, such as their locations or next movements. We aim to use this method
    to enhance the Coordinator’s understanding and reaction capabilities through efficient
    prompting of LLM. The prompts of the Coordinator are detailed in Supplementary
    Material.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，为了让协调器代理专注于游戏操作，我们采用了“与现实无关”的方法。具体而言，协调器仅促进游戏的执行，而不处理SUI机器人的物理参数，例如它们的位置或下一步的动作。我们的目标是通过有效地提示LLM来增强协调器的理解和反应能力。协调器的提示详见补充材料。
- en: '(2) Controller Agent. To use SUI in tabletop games, we require the robots to
    plan their motion according to the gadget behaviors in the game. To this end,
    we proposed a Controller agent in our system, which is responsible for embodying
    characters and generating the action sequence of each robot that represents these
    characters. The Controller agent is designed to gather information from two sources:
    the gadget commands outputted by the Coordinator agent, along with the physical
    location data of the robots at the given time. Next, we asked the Controller to
    generate the action sequences for the robots using the meta-actions, while simultaneously
    considering the logical flow of the game and the gameplay experience.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 控制器代理。为了在桌面游戏中使用SUI，我们要求机器人根据游戏中的小工具行为来规划其动作。为此，我们在系统中提出了一个控制器代理，负责体现角色并生成代表这些角色的每个机器人的动作序列。控制器代理设计为从两个来源收集信息：由协调器代理输出的小工具命令，以及在给定时间机器人所在的物理位置数据。接下来，我们要求控制器使用元动作生成机器人的动作序列，同时考虑游戏的逻辑流程和游戏体验。
- en: 'To ensure these action sequences are properly formatted for the robot actuation,
    we designed a Chain-of-Thought (CoT) prompting (Wei et al., [2022](#bib.bib33))
    for the Controller. The CoT prompting of the Controller unfolds as follows: (1)
    Output a textual description of the action sequence of the robots that will move,
    along with the current location information of these robots; (2) Generate an action
    sequence based on the aforementioned textural description in the form of a Python
    dictionary. This Python dictionary encompasses ID for the robots, as well as details
    for each subsequent meta-action, including destination locations/angles, speeds,
    types of movement, etc. Furthermore, we utilized in-context learning and few-shot
    learning approaches(Liu et al., [2021](#bib.bib17)), which provide specific examples
    in the prompts to demonstrate the process of the aforementioned CoT prompting,
    to assist the agent in effectively learning how to generate and plan the motion
    sequences.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保这些动作序列格式正确，以便机器人能够执行，我们为控制器设计了链式思维（CoT）提示（Wei et al., [2022](#bib.bib33)）。控制器的
    CoT 提示展开如下：（1）输出将移动的机器人的动作序列的文本描述，以及这些机器人的当前位置；（2）根据上述文本描述生成一个 Python 字典格式的动作序列。该
    Python 字典包括机器人的 ID 以及每个后续元动作的详细信息，包括目标位置/角度、速度、运动类型等。此外，我们还利用了上下文学习和少量学习方法（Liu
    et al., [2021](#bib.bib17)），在提示中提供具体示例，以展示上述 CoT 提示的过程，帮助代理有效地学习如何生成和规划运动序列。
- en: During use, users first input the game’s description and rules to the system,
    in order to declare the game to play. The system then understands and initiates
    the game based on the inherent knowledge of LLMs. Then, users continuously input
    the game commands to the system to engage with the game. The two agents in the
    system analyze these commands and the ongoing contextual information of the game,
    reasoning the gadget behaviors in the game, and then generating the action sequences
    to actuate the motion of SUI robots, embodying the interactions of the gadgets
    with users.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用过程中，用户首先将游戏的描述和规则输入系统，以声明要玩的游戏。系统随后根据 LLM 的固有知识理解并启动游戏。接着，用户不断向系统输入游戏命令以参与游戏。系统中的两个代理分析这些命令和游戏的持续上下文信息，推理游戏中的设备行为，然后生成动作序列以驱动
    SUI 机器人的运动，体现设备与用户的互动。
- en: '![Refer to caption](img/b95d3e75026b66e3e7fd855d573f8093.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b95d3e75026b66e3e7fd855d573f8093.png)'
- en: 'Figure 4\. An example using our kit: (a) Users can declare the game they are
    playing through an introduction and rules entry. (b) Then, they input game commands
    based on the scenario to interact with the gadget. The gadget generates corresponding
    action sequences based on a two-agent system within the kit.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 使用我们的套件的示例：（a）用户可以通过介绍和规则输入来声明他们正在玩的游戏。（b）然后，他们根据场景输入游戏命令与设备互动。设备基于套件内的双代理系统生成相应的动作序列。
- en: 'Here we presented a specific case of using the two-agent system to play a chess
    game. The comprehensive process of the interaction was illustrated in Figure [4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications"), including the initiation step of the game and a typical step
    during one round of the game. In the initiation step, the user first inputted
    the game name and a piece of introduction to the system (see Supplementary Material).
    The Coordinator then initialized the game based on the user’s input and outputted
    the response as shown in Figure [4](#S4.F4 "Figure 4 ‣ 4.2\. Complex Motion Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")a. Note that in this step,
    since the user did not input any specific game commands, the Controller agent
    did not generate specific action sequences, either. Subsequently, as the game
    started, the user continuously gave commands to the system. For instance, in the
    first round, the user inputted a command: ”Move the pawn from d2 to d4”. Next,
    the Coordinator responded to the command and informed the Controller of the gadget
    behavior of the pawn actuated by the user, as shown in the middle block in [4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")b. The Controlled then received the gadget behavior of the
    pawn, along with the actual location data (shown in [4](#S4.F4 "Figure 4 ‣ 4.2\.
    Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")c)
    of the robot that represented the pawn gadget, proceeding to generate the corresponding
    action sequence for the pawn robot through the CoT process. The output action
    sequence of the pawn robot is shown in the right block in [4](#S4.F4 "Figure 4
    ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")b.
    The server in the system then decoded the action sequence from the Controller,
    sent the motion commands to the pawn gadget, and then actuated the movement of
    the pawn gadget, shown in [4](#S4.F4 "Figure 4 ‣ 4.2\. Complex Motion Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")d.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，我们展示了一个使用双代理系统进行国际象棋游戏的具体案例。互动的综合过程在图[4](#S4.F4 "Figure 4 ‣ 4.2\. Complex
    Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User
    Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")中进行了说明，包括游戏的启动步骤和游戏轮中的典型步骤。在启动步骤中，用户首先输入了游戏名称和系统介绍（见补充材料）。然后，协调器根据用户的输入初始化了游戏，并输出了如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")a所示的响应。请注意，在此步骤中，由于用户没有输入任何具体的游戏命令，控制代理也没有生成具体的动作序列。随后，随着游戏的开始，用户不断向系统发出指令。例如，在第一轮中，用户输入了一条命令：“将兵从d2移动到d4”。接下来，协调器响应了命令，并将用户操作的兵的设备行为通知给控制器，如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")b中间的框所示。控制器随后接收了兵的设备行为以及实际位置数据（见图[4](#S4.F4 "Figure 4 ‣ 4.2\.
    Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")c），该数据代表了表示兵设备的机器人，并通过CoT过程生成了相应的动作序列。兵机器人的输出动作序列如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")b右侧的框所示。系统中的服务器随后解码了来自控制器的动作序列，向兵设备发送了运动指令，然后使兵设备移动，如图[4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")d所示。'
- en: 4.3\. Interactive Behavior Planning
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 交互行为规划
- en: Generally, in the context of utilizing SUI for tabletop games, depending on
    the specific game scenario, SUI often needs to control the movements of robots
    and translate various game operations into tangible interactive behaviors(Nakagaki
    et al., [2020](#bib.bib20)). However, in practice, we have found that due to the
    complexity and specificity of various interactive behaviors, the agents in our
    system, particularly the Controller, may not be able to rely solely on the generic
    prompts to realize all of these tangible interactive behaviors. To address this
    challenge, we have enhanced the Controller’s capability by incorporating several
    sets of additional prompts (add-on prompts) following a one/few-shot learning
    scheme. This approach aids the Controller in comprehending certain specific robotic
    operations (abilities) applied to different contexts. We anticipate that these
    add-on prompts will optimize the system’s ability to generate action sequences
    for Gadgets across various game scenarios.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，在利用 SUI 进行桌面游戏的背景下，根据具体的游戏场景，SUI 通常需要控制机器人的运动，并将各种游戏操作转化为具体的互动行为（Nakagaki
    et al., [2020](#bib.bib20)）。然而，实际上我们发现，由于各种互动行为的复杂性和特异性，我们系统中的代理，特别是控制器，可能无法仅依靠通用提示来实现所有这些具体的互动行为。为了解决这个挑战，我们通过结合几个额外提示（附加提示）来增强控制器的能力，这些提示采用了一对/少次学习的方案。这种方法有助于控制器理解适用于不同上下文的特定机器人操作（能力）。我们预计这些附加提示将优化系统在各种游戏场景中为小工具生成动作序列的能力。
- en: To determine which interactive behaviors required the design of additional prompts,
    we referenced past work in SUI (Nakagaki et al., [2020](#bib.bib20); Suzuki et al.,
    [2019](#bib.bib29); Ihara et al., [2023](#bib.bib10); Guo et al., [2023](#bib.bib7);
    Peng et al., [2020](#bib.bib21); Yu et al., [2023](#bib.bib35); Li et al., [2022](#bib.bib16))
    and recruited five designers with a background in Human-Computer Interaction (HCI)
    and experience in tabletop games for an informal interview and brainstorming session.
    During this process, we identified four common types of interaction behavior related
    to Gadget operations in tabletop games, including Objective Actuation, Symbol
    Visualization, Non-verbal Expression, and Scene Interaction. After that, we designed
    additional prompts for the Controller based on each type of interaction behavior,
    as detailed below.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定哪些互动行为需要设计额外提示，我们参考了 SUI 的相关研究（Nakagaki et al., [2020](#bib.bib20); Suzuki
    et al., [2019](#bib.bib29); Ihara et al., [2023](#bib.bib10); Guo et al., [2023](#bib.bib7);
    Peng et al., [2020](#bib.bib21); Yu et al., [2023](#bib.bib35); Li et al., [2022](#bib.bib16)），并邀请了五位具有人机交互（HCI）背景且拥有桌面游戏经验的设计师进行非正式访谈和头脑风暴。在这一过程中，我们确定了与桌面游戏中小工具操作相关的四种常见互动行为，包括目标驱动、符号可视化、非语言表达和场景互动。之后，我们根据每种互动行为的类型为控制器设计了额外的提示，具体如下。
- en: 4.3.1\. Object Actuation
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1. 物体驱动
- en: In tabletop games based on SUI, the ability of the system to automatically manipulate
    objects on the table using robotic gadgets (Ihara et al., [2023](#bib.bib10))
    enables the automation of game prop operations or simulates interactions between
    players and AI opponents or remote players. To this end, we added a set of additional
    prompts for the controller to assist in generating action sequences for our Gadgets
    to ”actuate objects”. In these prompts, we specify that the Controller should
    focus on the speed and trajectory of robot movement to achieve object movement
    along a prescribed path and simulate the properties of objects, such as weight.
    We also included a specific example in the prompts, which involves the task of
    pushing a heavy box to a designated location and the expected action sequence
    generated by the Controller.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于 SUI 的桌面游戏中，系统通过机器人小工具自动操控桌面上的物体（Ihara et al., [2023](#bib.bib10)）的能力，实现了游戏道具操作的自动化，或模拟玩家与
    AI 对手或远程玩家之间的互动。为此，我们为控制器添加了一组额外提示，以帮助生成小工具的动作序列来“驱动物体”。在这些提示中，我们指定控制器应关注机器人运动的速度和轨迹，以实现物体沿指定路径的运动，并模拟物体的特性，如重量。我们还在提示中包括了一个具体示例，即将重箱子推到指定位置的任务以及控制器生成的预期动作序列。
- en: 'After incorporating the add-on prompt for object actuation into the Controller’s
    original prompt, we test the after-modified effectiveness by using the Controller
    to actuate the Gadgets in scenarios involving pushing heavy objects. We tested
    the effectiveness of using the controller to actuate the Gadgets in pushing light
    objects. For instance, it was stipulated that the Gadgets start at a position
    (1, 1) and need to kick a light plastic soccer ball located at (3, 3). The outcome
    of the Gadget’s movement and the action sequences generated by the controller
    are depicted in Figure [5](#S4.F5 "Figure 5 ‣ 4.3.1\. Object Actuation ‣ 4.3\.
    Interactive Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating
    Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")a-b.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '在将附加提示用于物体驱动整合到控制器的原始提示中后，我们通过使用控制器驱动在推重物体的场景中测试了修改后的效果。我们还测试了使用控制器驱动在推轻物体的效果。例如，规定Gadgets从位置(1,
    1)开始，需要踢一个位于(3, 3)的轻塑料足球。Gadget的移动结果和控制器生成的动作序列如图[5](#S4.F5 "Figure 5 ‣ 4.3.1\.
    Object Actuation ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent system
    ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications")a-b所示。'
- en: 'Also, in another example, two gadgets are initially located at (1, 1) and (3,
    1), and we require the gadgets to push the two very heavy doors to (1, 4) (3,
    4) from (1, 3) and (3, 3). The demonstration of the movements of the Gadgets and
    the action sequence generated by the Controller is shown in Figure [5](#S4.F5
    "Figure 5 ‣ 4.3.1\. Object Actuation ‣ 4.3\. Interactive Behavior Planning ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")c-d.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，在另一个示例中，两台Gadgets初始位置分别为(1, 1)和(3, 1)，我们要求这两台Gadgets将两个非常重的门从(1, 3)和(3,
    3)推到(1, 4)和(3, 4)。Gadgets的移动演示和控制器生成的动作序列如图[5](#S4.F5 "Figure 5 ‣ 4.3.1\. Object
    Actuation ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")c-d所示。'
- en: '![Refer to caption](img/ea718382e3920a7aac8a36a3d2db1a96.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ea718382e3920a7aac8a36a3d2db1a96.png)'
- en: 'Figure 5\. The gadget starts at position (1,1) and needs to kick a light plastic
    soccer ball located at (3,3). a) Gadget: Moves northeast at speed 3 to approach
    the soccer ball’s location b)Kicks the soccer ball, simulating the action by moving
    east to (3,3). c-d) Two gadgets open a door together by moving towards it.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图5\. Gadget从位置(1,1)开始，需要踢一个位于(3,3)的轻塑料足球。a) Gadget：以速度3向东北移动以接近足球的位置 b)踢足球，通过向东移动到(3,3)模拟该动作。c-d)
    两个Gadgets一起打开门，通过移动到门的位置。
- en: 4.3.2\. Symbol Visualization
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2\. 符号可视化
- en: 'In SUI-based tabletop games, the system’s ability to use robotic gadgets to
    visualize certain graphic symbols can enhance the presentation of textual or graphical
    information in the game [74]. For this purpose, we added a set of add-on prompts
    for the Controller to assist in generating action sequences for swarm robots (the
    Gadgets) for Symbol Visualization. Specifically, we designed two methods for visualizing
    graphic symbols: ”trajectory tracing” and ”robotic formation,” along with corresponding
    prompts for each method. To make this visualization function more consistent,
    we also added certain rules, such as ”not inverting the symbols vertically” and
    ”using uppercase letters for English alphabets”. We also provided an example for
    each visualization method in the add-on prompt, including a description of a natural
    language task for visualizing the letters ”HCI,” along with the expected action
    sequence the Controller should generate. Detailed prompts are provided in the
    Supplementary Material.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于SUI的桌面游戏中，系统使用机器人小工具可视化某些图形符号的能力可以增强游戏中文本或图形信息的呈现[74]。为此，我们为控制器添加了一组附加提示，以协助生成用于符号可视化的群体机器人（Gadgets）的动作序列。具体来说，我们设计了两种可视化图形符号的方法：“轨迹追踪”和“机器人编队”，并为每种方法提供了相应的提示。为了使这种可视化功能更一致，我们还添加了一些规则，例如“不要垂直翻转符号”和“使用大写字母表示英文字母”。我们还在附加提示中提供了每种可视化方法的示例，包括描述可视化字母“HCI”的自然语言任务，以及控制器应生成的预期动作序列。详细提示请参见补充材料。
- en: 'After incorporating the add-on prompt for symbol visualization into the Controller,
    we tested its effectiveness by using the Controller to drive certain Gadgets in
    visualizing ”UIST.” For the ”tracing” method, the Controller successfully determined
    to utilize four Gadgets and generated appropriate trajectories of movement for
    each Gadget. The trajectory patterns and the action sequences that formed these
    trajectories are illustrated in Figure [6](#S4.F6 "Figure 6 ‣ 4.3.2\. Symbol Visualization
    ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit:
    Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game
    Applications")a-g.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '在将符号可视化的附加提示纳入控制器后，我们通过使用控制器驱动某些设备来测试其有效性，以可视化“UIST”。对于“追踪”方法，控制器成功决定使用四个设备，并生成了每个设备的适当运动轨迹。轨迹模式和形成这些轨迹的动作序列如图[6](#S4.F6
    "Figure 6 ‣ 4.3.2\. Symbol Visualization ‣ 4.3\. Interactive Behavior Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")a-g所示。'
- en: 'For the ”formation” method, the Controller determined to utilize multiple robots
    to separately form the shapes of the letters ”H” and ”I.” The effectiveness of
    the robotic forming these letters and the action sequences used are illustrated
    in Figure [6](#S4.F6 "Figure 6 ‣ 4.3.2\. Symbol Visualization ‣ 4.3\. Interactive
    Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications")h-i.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '对于“形成”方法，控制器决定利用多个机器人分别形成字母“H”和“I”的形状。机器人形成这些字母的效果以及使用的动作序列如图[6](#S4.F6 "Figure
    6 ‣ 4.3.2\. Symbol Visualization ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")h-i所示。'
- en: '![Refer to caption](img/70d8fcb8dabab63f3a0562bb8b0c0219.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/70d8fcb8dabab63f3a0562bb8b0c0219.png)'
- en: Figure 6\. The gadgets were asked to present the word ’UIST’ or ’HI’. a-d) Agents
    generated trajectories of four gadgets, which were arranged to form ’U’, ’I’,
    ’S’. e-f) A detailed demonstration of how one of the gadgets presents the letter
    ”T” through its movement trajectory. h-i) Agents make each letter composed of
    multiple gadgets, using 7 and 3 gadgets to form the letters ’H’ and ’I’ respectively.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图6\. 这些设备被要求展示单词“UIST”或“HI”。a-d) 代理生成了四个设备的轨迹，这些设备被排列成“U”、“I”、“S”。e-f) 展示了其中一个设备如何通过其运动轨迹展示字母“T”的详细过程。h-i)
    代理通过使用7个和3个设备分别形成字母“H”和“I”，使每个字母由多个设备组成。
- en: 4.3.3\. Non-Verbal Expression
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.3\. 非语言表达
- en: 'In SUI-based tabletop games, the ability of the system to use robotic gadgets
    for non-verbal expressions, such as displaying characters’ emotions, can significantly
    enhance the narrative expressiveness of tabletop games (Peng et al., [2020](#bib.bib21)).
    To this end, we incorporate a set of add-on prompts for the Controller to assist
    in generating action sequences for swarm robots for ”non-verbal expression.” Specifically,
    we designed two methods of non-verbal expression: ”mood expression” and ”social
    expression,” along with corresponding prompts for each method. We also provided
    an example for each method in the prompts, along with the expected action sequences
    the Controller should generate. The examples include asking the Gadget to express
    sadness and a greeting between two Gadgets. Related prompts are detailed in the
    Supplementary Material.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于SUI的桌面游戏中，系统使用机器人设备进行非语言表达的能力，例如展示角色的情感，可以显著增强桌面游戏的叙事表现力（Peng et al., [2020](#bib.bib21)）。为此，我们为控制器设计了一组附加提示，以帮助生成用于“非语言表达”的群体机器人动作序列。具体来说，我们设计了两种非语言表达方法：“情绪表达”和“社交表达”，以及每种方法对应的提示。我们还在提示中提供了每种方法的示例，以及控制器应该生成的预期动作序列。这些示例包括要求设备表达悲伤和两个设备之间的问候。相关提示详见补充材料。
- en: 'After incorporating the add-on prompt for non-verbal expression into the Controller,
    we first tested the effectiveness of using the controller to drive a single Gadget
    to express excitement. The demonstration of this expression and the corresponding
    action sequences are illustrated in the Figure [7](#S4.F7 "Figure 7 ‣ 4.3.3\.
    Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")a-b.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '在将非语言表达的附加提示纳入控制器后，我们首先测试了使用控制器驱动单个设备表达兴奋的效果。此表达及其相应的行动序列如图 [7](#S4.F7 "Figure
    7 ‣ 4.3.3\. Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")a-b 所示。'
- en: 'Next, we tested the effectiveness of using the controller to drive two Gadgets
    to express a disputing social behavior. The demonstration of this expression and
    the corresponding action sequences are illustrated in the Figure [7](#S4.F7 "Figure
    7 ‣ 4.3.3\. Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\.
    Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications")c-e.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '接下来，我们测试了使用控制器驱动两个设备表达争论社交行为的效果。此表达及其相应的行动序列如图 [7](#S4.F7 "Figure 7 ‣ 4.3.3\.
    Non-Verbal Expression ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")c-e 所示。'
- en: '![Refer to caption](img/784fe69c67f56f3238b1d0a896e25c5d.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/784fe69c67f56f3238b1d0a896e25c5d.png)'
- en: Figure 7\. a-b) A single gadget expresses excitement, the gadgets move upward
    a little and rotate for a circle. c-e) Two gadgets express an argument, they move
    toward each other, each rotates for a circle during the argument, and each retreats
    when the argument is over.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7\. a-b) 单个设备表达兴奋，设备稍微向上移动并旋转一圈。c-e) 两个设备表达争论，它们向彼此靠近，在争论过程中每个设备旋转一圈，争论结束时每个设备后退。
- en: 4.3.4\. Scene Interaction
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.4\. 场景互动
- en: In SUI-based tabletop games, as it is expected that a robotic gadget should
    be able to perform actions such as storytelling within a scene, the gadget’s behavior
    may need to interact with the settings of map environment (Guo et al., [2023](#bib.bib7)).
    To this end, we incorporate a set of add-on prompts for the Controller to assist
    in generating action sequences for swarm robots for ”scene interaction.” Specifically,
    we proposed that the Controller possesses a ”global perspective” in the Gadget’s
    action planning, taking into account additional map information, scene props,
    and even the positions or statuses of other Gadgets among other factors. We also
    provided an example for each method in the prompts, along with the expected action
    sequences the Controller should generate. The add-on prompt includes an example
    demonstrating a Gadget navigating around an obstacle of a certain length to reach
    the other side of the obstacle. Related prompts are specified in the Supplementary
    Material.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于 SUI 的桌面游戏中，由于预期机器人设备应能在场景中执行诸如讲故事等操作，因此该设备的行为可能需要与地图环境的设置互动（Guo 等，[2023](#bib.bib7)）。为此，我们为控制器添加了一组附加提示，以帮助生成“场景互动”中的群体机器人行动序列。具体来说，我们提出控制器在设备的行动规划中应具备“全球视角”，考虑额外的地图信息、场景道具，甚至其他设备的位置或状态等因素。我们还为每种方法提供了一个示例，并展示了控制器应生成的预期行动序列。附加提示包括一个示例，展示了一个设备绕过一定长度的障碍物以到达障碍物另一侧的过程。相关提示在补充材料中说明。
- en: 'After incorporating the add-on prompt for scene interaction into the Controller,
    we tested it with an example of navigating a Gadget around an obstacle formed
    by three other Gadgets. The demonstration of this expression and the corresponding
    action sequences are illustrated in Figure [8](#S4.F8 "Figure 8 ‣ 4.3.4\. Scene
    Interaction ‣ 4.3\. Interactive Behavior Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications").'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '在将场景互动的附加提示纳入控制器后，我们用一个设备绕过由其他三个设备形成的障碍物的示例进行了测试。此表达及其相应的行动序列如图 [8](#S4.F8
    "Figure 8 ‣ 4.3.4\. Scene Interaction ‣ 4.3\. Interactive Behavior Planning ‣
    4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")所示。'
- en: '![Refer to caption](img/8174c79b2fc75625ca7de8fa6b2bea06.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/8174c79b2fc75625ca7de8fa6b2bea06.png)'
- en: Figure 8\. The gadget goes around a wall consisting of three other gadgets,
    approaching the obstacle before moving to the south side of the obstacle and moving
    east to get over the obstacle.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8\. 小工具绕过由其他三个小工具组成的墙，在移动到障碍物的南侧后，继续向东移动以越过障碍物。
- en: 4.4\. Interaction Relationship Planning
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 互动关系规划
- en: 'Within the multiple interaction rounds in a game, it is crucial for agents
    to reflect upon the relational structure underpinning their engagements with players.
    This encompasses scenarios where agents may either confront or collaborate with
    players, or independently modulate their responses in alignment with the unfolding
    narrative, thereby contributing to the thematic ambiance. Drawing from this premise,
    researchers’ investigations have distilled the potential stances an agent might
    assume into four distinct categories: Apprentice, Competitor, Teammate, or Designer
    (Zhu et al., [2021](#bib.bib36)). To enable agents to grasp the relationship between
    human-computer interaction relationships and the generation of interactive behaviors
    within the game, we have augmented the Controller with the additional prompt (add-on
    prompt) to understand the varying interaction relationships.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在游戏中的多次互动回合中，代理必须反思其与玩家互动的关系结构。这包括代理可能与玩家对抗、协作，或独立调整其反应以符合情节发展，从而增强主题氛围。基于这一前提，研究人员的调查将代理可能采取的立场提炼为四个不同的类别：学徒、竞争者、队友或设计者（Zhu
    et al., [2021](#bib.bib36)）。为了使代理理解人机互动关系与游戏中互动行为的生成，我们为控制器增加了额外的提示（附加提示），以理解不同的互动关系。
- en: 4.4.1\. Apprentice
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.1\. 学徒
- en: Within the context of most tabletop gaming environments, Gadgets in our system
    typically embody the player’s avatar or operate as player-controlled entities
    ⁵⁵5http://scruffygrognard.com/. We believe that the ability of the system to act
    as an ”apprentice,” autonomously and precisely modifying the actions of robotic
    gadgets in response to users’ suggestions, would significantly enhance personalized
    interactive behaviors. To achieve this, we established a set of additional prompts
    for the Controller, enabling it to refer to and adjust its action planning as
    much as possible according to the user’s guidance. The specific prompts are detailed
    in the Supplementary Material.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数桌面游戏环境中，我们系统中的小工具通常代表玩家的化身或作为玩家控制的实体 ⁵⁵5http://scruffygrognard.com/。我们认为，系统能够作为“学徒”自主且精确地根据用户的建议调整机器人小工具的动作，这将显著提升个性化的互动行为。为实现这一目标，我们为控制器建立了一组额外的提示，使其能够尽可能根据用户的指导来参考和调整其行动计划。具体提示详见补充材料。
- en: After incorporating the add-on prompt for ”apprentice” into the Controller,
    we tested it with an example of requesting to ”speed up Gadgets”. The following
    is an example of an action sequence generated by the Controller controlling a
    Gadget to move from (5,5) to (10,10) on the grid map. The translation (movement)
    speed is set to 2.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在将“学徒”附加提示纳入控制器后，我们用请求“加速小工具”的示例进行了测试。以下是控制器控制小工具从网格地图上的 (5,5) 移动到 (10,10) 的动作序列示例。移动（翻译）速度设置为
    2。
- en: 'Following this, if we then request the Gadget to move faster, the Controller
    updates and generates the following sequence of actions as Figure [9](#S4.F9 "Figure
    9 ‣ 4.4.1\. Apprentice ‣ 4.4\. Interaction Relationship Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '随后，如果我们要求小工具加快移动速度，控制器会更新并生成下列动作序列，如图 [9](#S4.F9 "Figure 9 ‣ 4.4.1\. Apprentice
    ‣ 4.4\. Interaction Relationship Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications") 所示'
- en: '![Refer to caption](img/eaf504308ac4a5160b8ec19ee70c0617.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/eaf504308ac4a5160b8ec19ee70c0617.png)'
- en: Figure 9\. The gadget was asked to move from (5, 5) to (10, 10), and after being
    asked to speed up, the gadget moved faster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. 小工具被要求从 (5, 5) 移动到 (10, 10)，在被要求加速后，小工具移动得更快。
- en: 4.4.2\. Opponent
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.2\. 对手
- en: Many tabletop games feature the roles of opponents not controlled by players,
    engaging in competitive activities with the players. We believe it can enrich
    the gaming experience of tabletop games if our system comprehends the concept
    of ”opponent”, establishes non-player-controlled opponent roles, and uses the
    Gadgets to materialize their interactions. To facilitate this, we have established
    a set of additional prompts for the Controller, helping it generate and enact
    the roles of single or multiple opponents for competition or matches in games.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 许多桌面游戏中有对手角色，这些对手不由玩家控制，而是与玩家进行竞争活动。我们认为，如果我们的系统能够理解“对手”的概念，建立非玩家控制的对手角色，并使用小工具实现他们的互动，这将丰富桌面游戏的体验。为此，我们为控制器制定了一套额外的提示，帮助其生成并实施单个或多个对手角色，用于游戏中的竞争或比赛。
- en: We specify in the prompt the planning about the principles and duties that the
    Controller should adhere to when generating ”Opponent” roles (Raman et al., [2022](#bib.bib23)).
    For example, we set the goal of the opponent ”… to challenge the opponent characters
    through strategy and decision-making while keeping the game fair and enjoyable.”
    Furthermore, we have defined a mechanism for the Controller how to analyze player
    behavior and dynamically formulate challenging interaction strategies. For example,
    we specify in the prompt that the Controller ”… formulate challenging strategies
    based on the current state of the game and the behaviors of opponent characters.”
    The prompts are specified in the Supplementary Material.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在提示中指定了生成“对手”角色时控制器应遵循的原则和职责（Raman et al., [2022](#bib.bib23)）。例如，我们设定了对手的目标是“…通过战略和决策挑战对手角色，同时保持游戏公平和愉快。”此外，我们还为控制器定义了一种机制，用于分析玩家行为并动态制定具有挑战性的互动策略。例如，我们在提示中指定控制器“…根据游戏的当前状态和对手角色的行为制定具有挑战性的策略。”提示详见补充材料。
- en: 'After incorporating the add-on prompt for ”opponent” into the Controller, we
    tested it with an example of using Gadgets for combat behavior. In this example,
    one gadget embodies the role of a Monster1 commanded by the user (with action
    sequences generated by the Controller), while another gadget was controlled by
    the system, acting as an opponent Monster2. After the Monster1 is commanded to
    use Thunderbolt to attack, the Controller generates the action sequence of their
    battle as Figure [10](#S4.F10 "Figure 10 ‣ 4.4.2\. Opponent ‣ 4.4\. Interaction
    Relationship Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm
    User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications").'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在将“对手”附加提示纳入控制器后，我们使用了一个小工具进行战斗行为的示例测试。在这个示例中，一个小工具体现了由用户指挥的Monster1角色（由控制器生成行动序列），而另一个小工具则由系统控制，作为对手Monster2。Monster1被指挥使用雷电攻击后，控制器生成了他们战斗的行动序列，如图[10](#S4.F10
    "图10 ‣ 4.4.2\. 对手 ‣ 4.4\. 互动关系规划 ‣ 4\. 多代理系统 ‣ AI-Gadget工具包：将集群用户界面与基于LLM的智能体集成用于丰富的桌面游戏应用")。
- en: '![Refer to caption](img/02fcc02463c3a8d292f1185f71a508b3.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/02fcc02463c3a8d292f1185f71a508b3.png)'
- en: Figure 10\. Monster1 is asked to attack Monster2, and Monster2 responds being
    attacked.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图10\. Monster1被要求攻击Monster2，Monster2回应被攻击。
- en: 4.4.3\. Teammate
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.3\. 队友
- en: Similar to opponents, in tabletop gaming, there exist numerous non-player controlled
    characters that support the player by collaborating to accomplish tasks or combat
    adversaries. Enriching the gaming experience becomes more feasible if our system
    can comprehend the ”teammate (ally)” relationship, autonomously establish these
    non-player controlled teammate roles, and materialize interactions using the Gadgets.
    To achieve this, we have also developed a set of add-on prompts for the Controller,
    fostering it in generating and embodying one or multiple teammate roles. We specify
    in the prompt the planning about the principles and duties that the Controller
    should adhere to when generating ”Teammate” roles (Raman et al., [2022](#bib.bib23)).
    For example, we set a goal for the teammate ”… is to support teammate characters
    through effective collaboration and strategy, ensuring the success of the entire
    team and the enjoyment of the game…” Furthermore, we have established guidelines
    in the prompts for how Controllers can support teammate roles through effective
    collaboration and strategic planning, such as ”providing necessary support to
    help teammate characters overcome challenges while ensuring not to overshadow
    them, maintaining the game’s balance and interest.”, to ensure the success of
    the entire team and enhance the enjoyment of the game. The prompts are specified
    in the Supplementary Material.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于对手，在桌面游戏中，存在大量非玩家控制的角色，这些角色通过合作来完成任务或对抗敌人。如果我们的系统能够理解“teammate (ally)”关系，自动建立这些非玩家控制的队友角色，并利用Gadgets实现互动，那么丰富游戏体验就会变得更加可行。为此，我们还为控制器开发了一套附加提示，促进其生成和体现一个或多个队友角色。我们在提示中具体说明了控制器生成“Teammate”角色时应遵循的原则和职责（Raman
    et al., [2022](#bib.bib23)）。例如，我们为队友设定的目标是“通过有效的合作和策略支持队友角色，确保整个团队的成功和游戏的乐趣”。此外，我们在提示中建立了控制器如何通过有效的合作和战略规划来支持队友角色的指南，例如“提供必要的支持以帮助队友角色克服挑战，同时确保不掩盖他们，保持游戏的平衡和趣味性”，以确保整个团队的成功并提升游戏的乐趣。提示在补充材料中说明。
- en: 'After incorporating the add-on prompt for ”teammate” into the Controller, we
    tested it with an example of using Gadgets for collaborative combat behavior as
    Figure [11](#S4.F11 "Figure 11 ‣ 4.4.3\. Teammate ‣ 4.4\. Interaction Relationship
    Planning ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications"). In this scenario,
    one Gadget embodies the role of a Monster1 commanded by the user (with action
    sequences generated by the Controller), while two other Gadgets, generated and
    governed by the Controller, take on the roles of a teammate Monster2 and an opponent
    Monster3, respectively.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '在将“teammate”附加提示整合到控制器之后，我们用一个示例测试了使用Gadgets进行协作战斗行为，如图 [11](#S4.F11 "Figure
    11 ‣ 4.4.3\. Teammate ‣ 4.4\. Interaction Relationship Planning ‣ 4\. Multi-agent
    system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents
    for Rich Tabletop Game Applications")所示。在这个场景中，一个Gadget扮演由用户指挥的Monster1角色（由控制器生成行动序列），而另外两个由控制器生成和管理的Gadgets分别扮演队友Monster2和对手Monster3的角色。'
- en: '![Refer to caption](img/1ff985d576f6cbb6398f5a2c5c402b8d.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1ff985d576f6cbb6398f5a2c5c402b8d.png)'
- en: Figure 11\. Gadgets that can generate collaborative behavior act as a teammate
    of the user and attack the enemy together.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11\. 可以生成协作行为的Gadgets作为用户的队友共同攻击敌人。
- en: 4.4.4\. Designer
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.4\. 设计师
- en: In tabletop games, more roles that serve to enhance the narrative, such as NPCs
    (Non-Player Characters) or props, may also be present. For instance, upon the
    players and their teammates defeating adversaries, villager NPCs can be configured
    to celebrate players’ victory. If the Controller can act as a ”designer,” generating
    these roles based on the game’s narrative and materializing their actions through
    gadgets, then it would elevate the dramatic effect and overall experience of the
    game. To facilitate this, we have developed a set of add-on prompts for the Controller,
    enabling it to ”… spontaneously generate new characters, NPCs, items, or plots,
    as well as the corresponding robotic action sequences, to advance the game storyline.”
    Related prompts are detailed in the Supplementary Material.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在桌面游戏中，可能还存在更多用于增强叙事的角色，如 NPC（非玩家角色）或道具。例如，在玩家和队友击败对手后，村民 NPC 可以被配置为庆祝玩家的胜利。如果控制器能作为一个“设计师”，根据游戏叙事生成这些角色，并通过小工具实现它们的动作，那么这将提升游戏的戏剧效果和整体体验。为此，我们开发了一套控制器的附加提示，使其能够“……自发生成新的角色、NPC、物品或情节，以及相应的机器人动作序列，以推进游戏故事情节。”相关提示详细信息见补充材料。
- en: 'After incorporating the add-on prompt for ”designer” into the Controller, we
    tested it with an example focusing on a pivotal narrative moment following a battle
    victory. Specifically, when the user-controlled Monster1 and the teammate Monster2
    defeated Monster3, the Controller generated a storyline in which villager NPCs
    appeared to celebrate the victory. To bring this celebratory behavior to life,
    the Controller then invoked three new Gadgets designed for this purpose as Figure
    [12](#S4.F12 "Figure 12 ‣ 4.4.4\. Designer ‣ 4.4\. Interaction Relationship Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications").'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '在将“设计师”附加提示整合到控制器后，我们用一个聚焦于战斗胜利后关键叙事时刻的示例进行了测试。具体来说，当用户控制的 Monster1 和队友 Monster2
    击败 Monster3 后，控制器生成了一个故事情节，其中村民 NPC 出现以庆祝胜利。为了使这种庆祝行为栩栩如生，控制器随后调用了三个为此目的设计的新小工具，如图
    [12](#S4.F12 "Figure 12 ‣ 4.4.4\. Designer ‣ 4.4\. Interaction Relationship Planning
    ‣ 4\. Multi-agent system ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with
    LLM-driven Agents for Rich Tabletop Game Applications")。'
- en: '![Refer to caption](img/5f231f0d77403a035b48b13d81ef29c4.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5f231f0d77403a035b48b13d81ef29c4.png)'
- en: Figure 12\. Three new NPCs generated by the agent celebrate the user’s victory
    together, they surround the player, each taking a step forward and expressing
    excitement by spinning.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12\. 三个由智能体生成的新 NPC 们共同庆祝用户的胜利，它们围绕着玩家，每个 NPC 向前迈出一步，并通过旋转来表达兴奋之情。
- en: 5\. Example Application
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 示例应用
- en: 'We designed several different tabletop games using the AI-Gadget Kit to demonstrate
    its capabilities with a two-agent system and the effectiveness of the eight add-on
    prompts (comprising four Interaction Behaviors and four Interaction Relationships).
    For each game played, we followed the procedure outlined in Figure [4](#S4.F4
    "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications"), beginning with giving the game’s introduction and rules to
    the AI-Gadget Kit (details provided in the Supplementary Material). This initial
    step involved declaring the game being played. Subsequently, based on the game
    scenario, we provide game commands to interact with the Gadgets, engaging in an
    interactive gameplay experience.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用 AI-Gadget Kit 设计了几种不同的桌面游戏，以展示其在双代理系统中的能力以及八个附加提示（包括四种互动行为和四种互动关系）的有效性。对于每个游戏，我们按照图
    [4](#S4.F4 "Figure 4 ‣ 4.2\. Complex Motion Planning ‣ 4\. Multi-agent system
    ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications") 中概述的程序进行，首先向 AI-Gadget Kit 提供游戏介绍和规则（详细信息见补充材料）。这一初始步骤涉及声明正在进行的游戏。随后，根据游戏情景，我们提供游戏命令与小工具进行互动，体验互动游戏玩法。'
- en: 5.1\. Soccer-Ball-Shooting Game
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 足球射门游戏
- en: 'Using the AI-Gadget Kit, we implemented a soccer-ball-shooting game, as illustrated
    in the Figure [13](#S5.F13 "Figure 13 ‣ 5.1\. Soccer-Ball-Shooting Game ‣ 5\.
    Example Application ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications"). The setup includes a stationary
    goal on the tabletop, with players and a Gadget taking turns to shoot the ball.
    Players propel the ball using two fingers, while the Gadget executes its shots
    by striking the ball. We began by providing the game rules into the system (details
    in the Supplementary Material). Once the Coordinator comprehended the rules, it
    assumed the roles of both host and referee within the game. It then tasked the
    Controller with deploying an opponent role to control the action sequences of
    the Gadget. The Kit shall leverage the capability through the ”object actuation”
    add-on prompt of the Controller to simulate and execute collision planning based
    on the position of the goal and the ball. When it is the Gadget turn to take a
    shot, Controller generates the opponent’s direction and speed by considering factors
    such as the distance of the ball from the goal, the ball’s orientation relative
    to the goal, and the speed required to propel the ball.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AI-小工具套件，我们实现了一个足球射门游戏，如图[13](#S5.F13 "图 13 ‣ 5.1\. 足球射门游戏 ‣ 5\. 示例应用 ‣ AI-小工具套件：将群体用户界面与LLM驱动的代理集成，用于丰富的桌面游戏应用")所示。该设置包括一个固定在桌面上的球门，玩家和小工具轮流射门。玩家使用两个手指推动球，而小工具通过击打球来完成射门。我们首先将游戏规则输入系统（详细信息见附录）。一旦协调器理解了规则，它就承担了游戏中的主持人和裁判的角色。然后，它指派控制器部署一个对手角色来控制小工具的动作序列。该套件将利用控制器的“物体驱动”附加提示的能力，根据球门和球的位置来模拟和执行碰撞规划。当轮到小工具射门时，控制器会通过考虑球与球门的距离、球相对于球门的朝向以及推动球所需的速度等因素来生成对手的方向和速度。
- en: 'Figure [13](#S5.F13 "Figure 13 ‣ 5.1\. Soccer-Ball-Shooting Game ‣ 5\. Example
    Application ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven
    Agents for Rich Tabletop Game Applications") demonstrates the performance of the
    system in this gaming scenario, highlighting the Gadget acting as the opponent.
    After the player takes a shot, the Gadget autonomously aims for the kickoff spot,
    moves towards the ball, and pushes it towards the goal.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图[13](#S5.F13 "图 13 ‣ 5.1\. 足球射门游戏 ‣ 5\. 示例应用 ‣ AI-小工具套件：将群体用户界面与LLM驱动的代理集成，用于丰富的桌面游戏应用")展示了系统在这种游戏场景中的表现，突出了小工具作为对手的角色。在玩家进行射门后，小工具会自主瞄准开球点，移动到球的位置，并将其推向球门。
- en: '![Refer to caption](img/e3c6f0c63b75329f75acac7d5808772e.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/e3c6f0c63b75329f75acac7d5808772e.png)'
- en: Figure 13\. Human player and AI player play soccer games together.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13\. 人类玩家与AI玩家一起进行足球比赛。
- en: Additionally, the Controller monitors past scores to adjust strategies to enhance
    gameplay and competitiveness. For instance, in a single game session, if the player
    fails to score consecutively over multiple attempts, the opponent’s accuracy will
    be dynamically lowered in subsequent rounds. This adjustment is designed to enrich
    the users’ gaming experience by maintaining a competitive balance and ensuring
    that the game remains engaging and challenging without becoming discouragingly
    difficult.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，控制器监测过去的得分，以调整策略以增强游戏体验和竞争性。例如，在一次游戏会话中，如果玩家在多次尝试中未能连续得分，对手的准确度将在随后的回合中动态降低。这一调整旨在通过保持竞争平衡来丰富用户的游戏体验，并确保游戏保持吸引力和挑战性，而不会变得令人沮丧地困难。
- en: 5.2\. Turn-Based Strategy Game
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 回合制战略游戏
- en: 'Within the Turn-Based Strategy (TBS) game scenarios, the system is designed
    to support battles between players whose commands are embodied through Gadget
    controlling (Player vs. Player, or PVP) as well as battles where the Gadget itself
    acts as the opponent (Player vs. Environment, or PVE). During gameplay, robotic
    gadgets assume roles as combatants, generating robotic action commands based on
    the attack targets and skills released as designated by the players. Following
    the game rules outlined, the Coordinator updates and transmits game information
    during interactions, such as the status and capabilities of the gadgets. The Controller
    then synthesizes this information to produce corresponding sequences of actions.
    In combat scenarios, our Kit primarily relies on an apprentice, opponent, and
    non-verbal expression add-on prompts. It adheres to the players’ interaction commands
    (such as attack/defense, skill deployment, etc.) to generate corresponding interactive
    behaviors. As illustrated in the figure[14](#S5.F14 "Figure 14 ‣ 5.2\. Turn-Based
    Strategy Game ‣ 5\. Example Application ‣ AI-Gadget Kit: Integrating Swarm User
    Interfaces with LLM-driven Agents for Rich Tabletop Game Applications"), when
    a player commands their character to ”attack the enemy with the power of thunderbolt,”
    the kit generates an attack action directed at the opposing Gadget. Considering
    the characteristics of ”thunderbolt,” the kit is designed with actions for the
    attacking gadget that simulate the buildup of electrical charge followed by a
    swift charge forward, and for the opponent gadget, it simulates the motion of
    being electrocuted with on-the-spot swaying movements. Moreover, through the add-on
    prompts of teammates and designers within our kit, TBS games can accommodate a
    larger number of gadgets for combat or interaction. This can complement the combat
    theater in existing Dungeons and Dragons (D&D) type games.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '在回合制策略（TBS）游戏场景中，系统设计旨在支持玩家之间的战斗，通过小工具控制（玩家对玩家，或 PVP）来体现指令，也支持小工具本身作为对手的战斗（玩家对环境，或
    PVE）。在游戏过程中，机器人小工具充当战斗者，基于攻击目标和玩家指定的技能释放生成机器人动作指令。根据游戏规则，协调员在互动过程中更新并传递游戏信息，如小工具的状态和能力。控制器然后综合这些信息，生成相应的动作序列。在战斗场景中，我们的套件主要依赖学徒、对手和非语言表达附加提示符。它遵循玩家的互动指令（如攻击/防御、技能部署等），生成相应的互动行为。如图[14](#S5.F14
    "Figure 14 ‣ 5.2\. Turn-Based Strategy Game ‣ 5\. Example Application ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")所示，当玩家命令角色“以雷电的力量攻击敌人”时，套件生成一个针对对手小工具的攻击动作。考虑到“雷电”的特点，套件为攻击的小工具设计了模拟电荷积累后的迅速冲刺的动作，对于对手小工具，模拟被电击的同时伴随的现场摆动动作。此外，通过我们套件中的队友和设计师附加提示符，TBS
    游戏可以容纳更多的小工具进行战斗或互动。这可以补充现有《龙与地下城》（D&D）类游戏中的战斗剧场。'
- en: '![Refer to caption](img/bef59b971e1e8f281602697cc42c274a.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bef59b971e1e8f281602697cc42c274a.png)'
- en: Figure 14\. Robotic gadget plays turn-based strategy games with human players.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14\. 机器人小工具与人类玩家进行回合制策略游戏。
- en: 5.3\. Yes Or No?
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 是还是否？
- en: In many games, there are moments where a system provides Yes or No responses,
    such as ability checks and answering questions within the narrative in Dungeons
    and Dragons (D&D) games. Our kit enhances the presentation of Yes and No answers
    in these instances, making them more engaging.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多游戏中，系统会提供“是”或“否”的回答，例如能力检查和在《龙与地下城》（D&D）游戏中的叙事回答。我们的套件在这些情况下增强了“是”和“否”回答的呈现，使其更加吸引人。
- en: 'For instance, we have designed a quiz game[15](#S5.F15 "Figure 15 ‣ 5.3\. Yes
    Or No? ‣ 5\. Example Application ‣ AI-Gadget Kit: Integrating Swarm User Interfaces
    with LLM-driven Agents for Rich Tabletop Game Applications") (its rules are detailed
    in the Supplementary Material) where the Coordinator accepts questions raised
    by users and provides corresponding answers.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，我们设计了一个测验游戏[15](#S5.F15 "Figure 15 ‣ 5.3\. Yes Or No? ‣ 5\. Example Application
    ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications")（其规则详细说明见补充材料），协调员接受用户提出的问题，并提供相应的答案。'
- en: The Controller, equipped with designer capabilities, utilizes add-on prompts
    for symbol visualization to control a Gadget. This Gadget writes out Y (Yes) or
    N (No) on paper, responding affirmatively or negatively to the users’ queries.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器具备设计师能力，利用附加提示符进行符号可视化，以控制一个小工具。这个小工具在纸上写出 Y（是）或 N（否），对用户的提问做出肯定或否定的回答。
- en: To mitigate the impact of friction between the pen tip and paper on the robotic
    gadget’s movement, we employed two gadgets to hold a pen jointly for drawing.
    This design is intended to offer users a more suspenseful and immersive gaming
    experience.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少笔尖与纸张之间摩擦对机器人设备移动的影响，我们使用两个设备共同持笔进行绘图。这一设计旨在为用户提供更具悬念和沉浸感的游戏体验。
- en: '![Refer to caption](img/d5c01bc55d2ab1c715545f60190eb44c.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d5c01bc55d2ab1c715545f60190eb44c.png)'
- en: Figure 15\. Robotic gadgets answer ’Yes’ or ’No’ to user questions by driving
    a pen to write on paper.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15\. 机器人设备通过在纸上书写来回答用户的问题，“是”或“否”。
- en: 5.4\. Improvisational Theater
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4\. 即兴戏剧
- en: Improvisational theater is a form of group drama without a fixed script, where
    most of the content is spontaneously created by the performers during the performance(Johnstone,
    [2012](#bib.bib12)). Integrating AI-Gadget Kit, we have designed an application
    for users to perform improvisational theater in collaboration with the Gadgets.
    In this setup, Gadgets act as performers, with one of the Gadgets representing
    the user. We require the Gadgets to adhere to the core principle of improvisational
    theater, ”Yes, and,” which means freely generating subsequent performance content,
    including voice and action sequences, based on the previous performer’s contribution
    and randomly selecting the next performer from among the users and other Gadgets.
    The Coordinator is responsible for assigning roles to all parties, recording and
    transmitting the content of the performance, and coordinating the turns of the
    performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 即兴戏剧是一种没有固定剧本的团体戏剧形式，其中大部分内容是由演员在表演过程中即兴创作的（Johnstone, [2012](#bib.bib12)）。通过整合AI-Gadget
    Kit，我们设计了一个应用，允许用户与设备一起进行即兴戏剧表演。在这种设置中，设备充当演员，其中一个设备代表用户。我们要求设备遵循即兴戏剧的核心原则“是的，而且”，这意味着基于前一个演员的贡献自由生成后续表演内容，包括声音和动作序列，并从用户和其他设备中随机选择下一个演员。协调员负责为所有参与方分配角色，记录和传输表演内容，并协调表演的轮次。
- en: 'After integrating non-verbal expression add-on prompts, the Controller is capable
    of generating dialogue that fits the characters’ identities and the plot development,
    while also endowing robots with non-verbal ”mood” expressions to convey the characters’
    emotional states. Moreover, by assigning specific scene information to different
    areas of the venue, the scene interaction capability add-on prompt enables the
    Controller to consider information such as the performance location when generating
    action sequences. In one of our improvisational theater tests set in the world
    of ”Hamlet” (detailed game rules can be found in the Supplementary Material),
    our Kit initially assigns identities to a cluster of Gadgets(Figure [16](#S5.F16
    "Figure 16 ‣ 5.4\. Improvisational Theater ‣ 5\. Example Application ‣ AI-Gadget
    Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop
    Game Applications")), several following the original characters of the drama and
    others being original characters based on user commands.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '在整合非语言表达附加提示后，控制器能够生成符合角色身份和情节发展的对话，同时赋予机器人非语言的“情绪”表达，以传达角色的情感状态。此外，通过将特定的场景信息分配给场馆的不同区域，场景互动能力附加提示使控制器在生成动作序列时能够考虑诸如表演地点的信息。在我们的一次设置在《哈姆雷特》世界中的即兴戏剧测试中（详细的游戏规则可以在附录材料中找到），我们的套件最初为一组设备分配身份（见图
    [16](#S5.F16 "Figure 16 ‣ 5.4\. Improvisational Theater ‣ 5\. Example Application
    ‣ AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for
    Rich Tabletop Game Applications")），其中一些设备沿用了戏剧中的原始角色，而其他则是基于用户命令的原创角色。'
- en: Once the performance starts, the Controller coordinates with the user, taking
    into account the pre-set information of the performance site, to continue the
    act. For example, when the robot playing Hamlet utters ”To be or not to be, that
    is the question,” in complete contrast to the original story, the user, who is
    consoled by a robot as Hamlet’s friend (an original character), expresses his
    comfort and informs Hamlet that Ophelia is waiting on the terrace. Based on the
    lines entered by the user for the performance, the Controller Agent directs the
    user’s robot to express emotion through a non-verbal sequence of actions. Hamlet
    then moved to the area representing the terrace based on the venue information
    and engaged in a dialog and performance with Ophelia.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦表演开始，控制器会与用户协调，考虑到表演场地的预设信息，继续进行演出。例如，当扮演哈姆雷特的机器人说出“生存还是毁灭，这是一个问题”时，与原故事完全相反，用户（作为哈姆雷特的朋友，一个原创角色）表示安慰，并告知哈姆雷特奥菲利亚正在露台上等他。根据用户为表演输入的台词，控制器代理会指示用户的机器人通过非语言的动作序列表达情感。随后，哈姆雷特根据场地信息移动到代表露台的区域，并与奥菲利亚进行对话和表演。
- en: It is not difficult to see that AI-Gadget has the ability to respond to high
    degree-of-freedom user input in performance scenarios. We also tested completely
    original story contexts in which AI-Gadget similarly demonstrated the ability
    to receive feedback on improvised content. As the art form of improvisational
    theater is gaining traction in the areas of imagination and creativity stimulation,
    mental health, and social-emotional education (Sawyer, [2000](#bib.bib26))(Schwenke
    et al., [2021](#bib.bib27))(Felsman et al., [2019](#bib.bib4)), combined with
    a more specialized Emergent Story Generation strategy, AI-Gadget has the potential
    to provide users with a richer interactive and emotional experience.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 不难看出，AI-Gadget在表演场景中具有响应高自由度用户输入的能力。我们还测试了完全原创的故事情境，其中AI-Gadget同样展示了接收即兴内容反馈的能力。由于即兴剧艺术形式在想象力和创造力激发、心理健康和社会情感教育领域的影响力日益增强（Sawyer,
    [2000](#bib.bib26)）（Schwenke et al., [2021](#bib.bib27)）（Felsman et al., [2019](#bib.bib4)），结合更专业的突现故事生成策略，AI-Gadget有潜力为用户提供更丰富的互动和情感体验。
- en: '![Refer to caption](img/bd90b8f00fa575ee76a456e49ae07b82.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bd90b8f00fa575ee76a456e49ae07b82.png)'
- en: Figure 16\. In Hamlet-themed improvisational theater, the gadget playing Hamlet
    flexibly reacts to the user’s words outside of the script.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图16. 在以哈姆雷特为主题的即兴剧中，扮演哈姆雷特的设备灵活地响应用户脚本之外的话语。
- en: 6\. Discussion
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6. 讨论
- en: 6.1\. Limitation and Future Works
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1. 限制与未来工作
- en: In this study, we employed the Sony Toio robots as our Robotic Gadget. However,
    due to the Toio robots’ movement being reliant on motor differential speed control,
    the performance of the motors themselves can impact the robots’ action performance.
    This imposes limitations on the AI-Gadget Kit’s functionality. For instance, in
    practice, the Toio robots exhibited random deviations when executing users’ movement
    commands, a situation exacerbated by a shift in the center of gravity due to additional
    attachments to the casing.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们使用了Sony Toio机器人作为我们的机器人设备。然而，由于Toio机器人的运动依赖于电机差速控制，电机自身的性能会影响机器人的动作表现。这对AI-Gadget套件的功能性构成了限制。例如，在实际操作中，Toio机器人在执行用户运动指令时出现了随机偏差，这种情况因外壳上附加物品导致重心变化而加剧。
- en: To mitigate the challenges faced by the Gadget due to the aforementioned factors,
    we are considering several optimizations to the system architecture. Firstly,
    a more precise movement correction algorithm on the robot side could support the
    robots’ movement performance. With the anticipated action sequences of the Gadget,
    coupled with real-time positioning information based on ArUCo from cameras, the
    robots are capable of precise closed-loop control during action, enabling real-time
    adjustments. Furthermore, inspired by works such as Swarm Haptics(Kim and Follmer,
    [2019](#bib.bib14)) and Hermits(Nakagaki et al., [2020](#bib.bib20)), mechanical
    modifications to the robots (like increasing tire friction) could address the
    limitations in the Gadget’s linear driving capability and performance due to the
    mass and speed of swarm robots in scenarios such as object propulsion.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解Gadget因上述因素而面临的挑战，我们正在考虑对系统架构进行若干优化。首先，机器人端更精确的运动修正算法可以支持机器人的运动性能。结合Gadget的预期动作序列和基于ArUCo的实时定位信息，机器人能够在动作过程中进行精确的闭环控制，实现实时调整。此外，受到Swarm
    Haptics(Kim and Follmer, [2019](#bib.bib14))和Hermits(Nakagaki et al., [2020](#bib.bib20))等工作的启发，对机器人进行机械改进（如增加轮胎摩擦）可以解决Gadget在物体推进等场景中由于群体机器人质量和速度而导致的线性驱动能力和性能的限制。
- en: Beyond optimizing the robots’ movement capabilities, we also recognize that
    the current provision of meta-actions by the robot side is insufficient to meet
    the demand for a broader range of complex movements. For the Gadget, diverse movement
    modes (such as curved motion) are expected to improve the robots’ interactive
    experience and expressiveness. Therefore, the encapsulation and provision of more
    movement modes will assist the Robotic Gadget in achieving interactions with complex
    and rich semantics in tabletop games.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 除了优化机器人运动能力外，我们还认识到，目前机器人端提供的元动作不足以满足更广泛复杂动作的需求。对于Gadget来说，期望通过多样的运动模式（如曲线运动）来改善机器人的互动体验和表达能力。因此，封装和提供更多运动模式将帮助机器人Gadget在桌面游戏中实现复杂而丰富的语义互动。
- en: On the other hand, in this study, when confronted with complex board game scenarios,
    such as ”Improvisational Theater,” the LLM (i.e., GPT-4) which the agents rely
    on, may encounter performance bottlenecks due to the utilization of multiple add-ons
    prompts and numerous game rounds, leading to complications in processing lengthy
    contexts. This can result in inaccuracies and errors or the so-called ”hallucination”
    phenomenon of LLM, where the model generates content with inaccuracies related
    to the game’s rules and scenario descriptions. In such cases, the model’s output
    may require additional testing (e.g., The Needle In a Haystack Test) to verify
    its accuracy and reliability.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在本研究中，当面对复杂的棋盘游戏场景（如“即兴戏剧”）时，代理人所依赖的LLM（即GPT-4）可能会因多次使用附加提示和众多游戏回合而遇到性能瓶颈，从而导致处理长篇上下文时的复杂性。这可能导致不准确性和错误，或者LLM的所谓“幻觉”现象，即模型生成与游戏规则和场景描述相关的不准确内容。在这种情况下，模型的输出可能需要额外的测试（例如，干草堆中的针测试）来验证其准确性和可靠性。
- en: To address this challenge and enhance the agents’ performance in complex scenarios,
    several strategies can be considered for the future. Firstly, introducing a more
    powerful LLM represents a direct solution. By enhancing the model’s capability
    to understand and retrieve long contexts, we can directly improve agents’ performance
    in complex interaction scenarios. However, this approach depends on external technological
    advancements.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这一挑战并提升代理人在复杂场景中的表现，可以考虑若干未来策略。首先，引入更强大的LLM代表了一种直接的解决方案。通过提升模型理解和检索长篇上下文的能力，我们可以直接改善代理人在复杂互动场景中的表现。然而，这种方法依赖于外部技术的进步。
- en: Furthermore, drawing inspiration from AutoGen(Wu et al., [2023](#bib.bib34)),
    we can introduce multiple specialized agents to handle specific contextual challenges.
    These specialized agents could be designed to perform distinct functions, such
    as generating game rules and action sequences and analyzing the consequences of
    players’ moves. By isolating specific contexts, these specialized agents facilitate
    interaction among the main agents. They can work together to provide more accurate,
    efficient, and coherent content generation. For example, by distributing specific
    parts of the context and isolating the others, a certain agent can specialize
    in tracking the logical relationship between game states and player actions, while
    other agents may focus on generating descriptions and reactions that align with
    the specific game environment or scenario and action sequences of the Gadgets.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，受到 AutoGen（Wu et al., [2023](#bib.bib34)）的启发，我们可以引入多个专门的代理来处理特定的情境挑战。这些专门的代理可以被设计成执行不同的功能，如生成游戏规则和行动序列，分析玩家移动的后果。通过隔离特定的情境，这些专门的代理可以促进主要代理之间的互动。它们可以协同工作，提供更准确、高效且连贯的内容生成。例如，通过分配特定的情境部分并隔离其他部分，某个代理可以专注于追踪游戏状态与玩家行动之间的逻辑关系，而其他代理则可能专注于生成与特定游戏环境或场景及
    Gadget 的行动序列相符的描述和反应。
- en: Through such a two-agent collaboration system, we can not only enhance the agents’
    performance in complex game scenarios, improve content generation speed, and reduce
    token consumption to lower inference costs but also allow each agent to provide
    deep and precise processing within their areas of expertise. This enables the
    entire SUI system to better understand and reflect the complex logic of games
    and player interactions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种双代理协作系统，我们不仅可以提升代理在复杂游戏场景中的表现，改善内容生成速度，减少 token 消耗以降低推理成本，还可以让每个代理在其专业领域内提供深入而精准的处理。这使得整个
    SUI 系统能够更好地理解和反映游戏和玩家互动的复杂逻辑。
- en: 6.2\. Beyond Action Planning
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 超越行动规划
- en: This paper primarily focuses on the integration of SUI (Spatial User Interface)
    with LLM-based (Large Language Model-based) agents in tabletop game scenarios.
    However, the HCI (Human-Computer Interaction) field has already introduced many
    instances where SUI is combined with other interactive scenarios, including AR
    (Augmented Reality) games (Kaimoto et al., [2022](#bib.bib13)), serious games
    (Peng et al., [2020](#bib.bib21)), and remote interactions (Ihara et al., [2023](#bib.bib10)).
    This reveals the potential for our AI-Gadget Kit to inspire further research and
    applications of SUI in scenarios with complex interaction tasks. In this paper,
    we take the first step by incorporating LLM-based agents for automated action
    planning in SUI. Future expansions of our kit could enhance understanding and
    generation of SUI’s other interactive modalities. For instance, by integrating
    Add-ons like the Mechanical Shell (Nakagaki et al., [2020](#bib.bib20)), our kit
    could transform SUI action planning into planning for other interactivities (e.g.,
    Multi-DoF, Aggregation). Similarly, by generating virtual information, our kit
    could extend SUI action planning into dynamic interactions that blend virtual
    and real elements (Suzuki et al., [2020](#bib.bib28)). Moving forward, we aim
    to explore more LLM-generated SUI interaction modalities, advancing research and
    application of SUI in scenarios with complex interaction tasks.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 本文主要关注将 SUI（空间用户界面）与基于 LLM（大型语言模型）的代理整合于桌面游戏场景。然而，HCI（人机交互）领域已经引入了许多将 SUI 与其他互动场景结合的实例，包括
    AR（增强现实）游戏（Kaimoto et al., [2022](#bib.bib13)）、严肃游戏（Peng et al., [2020](#bib.bib21)）和远程互动（Ihara
    et al., [2023](#bib.bib10)）。这揭示了我们的 AI-Gadget Kit 有潜力激发进一步研究和应用 SUI 于复杂互动任务场景的可能性。本文通过将基于
    LLM 的代理用于 SUI 的自动化行动规划，迈出了第一步。未来我们可能通过增强对 SUI 其他互动模式的理解和生成来扩展我们的工具包。例如，通过整合如机械外壳（Nakagaki
    et al., [2020](#bib.bib20)）等附加组件，我们的工具包可以将 SUI 行动规划转变为其他互动性（如 Multi-DoF，聚合）的规划。同样，通过生成虚拟信息，我们的工具包可以将
    SUI 行动规划扩展为融合虚拟与现实元素的动态互动（Suzuki et al., [2020](#bib.bib28)）。未来，我们计划探索更多由 LLM
    生成的 SUI 互动模式，推动 SUI 在复杂互动任务场景中的研究和应用。
- en: 6.3\. Availability and Applicability
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3\. 可用性与适用性
- en: Our proposed AI-Gadget Kit aims to assist researchers, board game designers,
    and players in creatively designing interactive experiences with automated gadgets
    using natural language. By leveraging the two-agent system and various add-on
    prompts included in the kit, users can easily modify the rules for generating
    sequences of interactive actions (for example, testing can be conducted directly
    on the OpenAI GPT-4 web client).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的 AI-Gadget Kit 旨在帮助研究人员、桌游设计师和玩家使用自然语言创造性地设计互动体验。通过利用套件中的双代理系统和各种附加提示，用户可以轻松修改生成交互动作序列的规则（例如，测试可以直接在
    OpenAI GPT-4 网络客户端上进行）。
- en: However, we have identified obstacles encountered when attempting to rapidly
    debug the dynamic effects of action sequences generated by the Kit. Users must
    either conduct live tests with a corresponding number of gadgets for different
    scenarios or plot the trajectories on a coordinate system based on the content
    of the action sequences to evaluate the agent-generated content. This impedes
    the visualization of creative interactive ideas of the users.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们已经发现了在尝试快速调试由套件生成的动作序列动态效果时遇到的障碍。用户必须进行现场测试，使用不同场景所需数量的设备，或者基于动作序列内容在坐标系统中绘制轨迹以评估代理生成的内容。这阻碍了用户创意互动想法的可视化。
- en: Recently, WRLKits(Saberpour Abadian et al., [2023](#bib.bib24)) demonstrated
    a tool based on the interactive computational design approach, which visually
    assists designers in rapidly building personalized prototypes. Similarly, works
    like Habitat-Sim(Savva et al., [2019](#bib.bib25)) and AI2-THOR(Kolve et al.,
    [2022](#bib.bib15)) have proven the viability of simulation platforms for robot
    interaction design. In the future, we plan to develop simulation and design tools
    for the AI-Gadget Kit, enabling visualizations on web or client platforms for
    designing personalized interactions, thus making it more accessible and usable
    by many.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，WRLKits（Saberpour Abadian 等，[2023](#bib.bib24)）展示了一种基于互动计算设计方法的工具，该工具可以直观地帮助设计师快速构建个性化原型。类似地，Habitat-Sim（Savva
    等，[2019](#bib.bib25)）和 AI2-THOR（Kolve 等，[2022](#bib.bib15)）等工作也证明了用于机器人互动设计的仿真平台的可行性。未来，我们计划开发
    AI-Gadget Kit 的仿真和设计工具，以便在网络或客户端平台上进行可视化设计个性化交互，从而使其更具可及性和实用性。
- en: In addition, we have noted that the hardware costs associated with SUI capable
    of driving gadgets for interaction may hinder the widespread adoption of this
    work in board game scenarios. This is because most board game café may find it
    challenging to afford the costs of bulk purchasing expensive hardware platforms,
    such as the Sony Toio platform. To further promote our work, we will explore the
    development of lower-cost hardware platforms for the AI-Gadget Kit in the future.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们注意到，驱动设备进行互动的 SUI 硬件成本可能会阻碍该工作在桌游场景中的广泛采用。这是因为大多数桌游咖啡馆可能会发现很难负担大量采购昂贵硬件平台（例如
    Sony Toio 平台）的成本。为了进一步推广我们的工作，我们将探索未来开发低成本的 AI-Gadget Kit 硬件平台。
- en: 7\. Conclusion
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 结论
- en: While Swarm User Interfaces (SUIs) have succeeded in enriching tangible interaction
    experiences, their limitations in autonomous action planning have hindered the
    potential for personalized and dynamic interaction generation in tabletop games.
    In this paper, We proposed an AI-Gadget Kit, a multi-agent SUI tabletop gaming
    system, which is designed to facilitate dynamic and complex interaction tasks
    in tabletop games. We first introduced the system architecture of the AI-gadget
    Kit, which includes a set of swarm robots to perform the gadget behaviors, and
    a multi-agent system responsible for executing the game and generating action
    plans for the swarm robots. We then elaborated the design of the multi-agent system,
    comprising a series of meta-motions for individual robots, two LLM-based agents
    for complex action planning, and a set of add-on prompts aimed at reinforcing
    the understanding and reacting capabilities of the agents. At last, we demonstrate
    four application examples using AI-gadget Kit to showcase the effect of the multi-agent-driven
    SUI on executing complex interaction tasks in tabletop games. We aimed to use
    our work as a case study to explore and inspire the application of LLMs on action
    planning of SUI in multiple scenarios with complex interaction tasks.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然群体用户界面（SUIs）在丰富实际互动体验方面取得了成功，但它们在自主行动规划方面的局限性阻碍了在桌面游戏中个性化和动态互动生成的潜力。本文提出了一种
    AI-Gadget Kit，一个多代理 SUI 桌面游戏系统，旨在促进桌面游戏中的动态和复杂互动任务。我们首先介绍了 AI-gadget Kit 的系统架构，包括一组群体机器人来执行小工具行为，以及一个负责执行游戏并为群体机器人生成行动计划的多代理系统。然后，我们详细说明了多代理系统的设计，包括一系列个体机器人元运动，两个基于
    LLM 的代理用于复杂的行动规划，以及一组附加提示，旨在增强代理的理解和反应能力。最后，我们展示了使用 AI-gadget Kit 的四个应用示例，以展示多代理驱动的
    SUI 在执行桌面游戏中的复杂互动任务的效果。我们的目标是将我们的工作作为一个案例研究，以探索和激发 LLM 在复杂互动任务的多种场景中对 SUI 的行动规划应用。
- en: References
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Brock et al. (2021) Heike Brock, Selma Šabanović, and Randy Gomez. 2021. Remote
    You, Haru and Me: Exploring Social Interaction in Telepresence Gaming With a Robotic
    Agent. In *Companion of the 2021 ACM/IEEE International Conference on Human-Robot
    Interaction* (Boulder, CO, USA) *(HRI ’21 Companion)*. Association for Computing
    Machinery, New York, NY, USA, 283–287. [https://doi.org/10.1145/3434074.3447177](https://doi.org/10.1145/3434074.3447177)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Brock et al. (2021) Heike Brock, Selma Šabanović 和 Randy Gomez，2021年。Remote
    You, Haru and Me: 探索通过机器人代理在远程存在游戏中的社交互动。在 *Companion of the 2021 ACM/IEEE International
    Conference on Human-Robot Interaction*（美国科罗拉多州博尔德） *(HRI ’21 Companion)* 期刊中。计算机协会，纽约，NY，美国，283–287。
    [https://doi.org/10.1145/3434074.3447177](https://doi.org/10.1145/3434074.3447177)'
- en: 'Dementyev et al. (2016) Artem Dementyev, Hsin-Liu (Cindy) Kao, Inrak Choi,
    Deborah Ajilo, Maggie Xu, Joseph A. Paradiso, Chris Schmandt, and Sean Follmer.
    2016. Rovables: Miniature On-Body Robots as Mobile Wearables. In *Proceedings
    of the 29th Annual Symposium on User Interface Software and Technology* (Tokyo,
    Japan) *(UIST ’16)*. Association for Computing Machinery, New York, NY, USA, 111–120.
    [https://doi.org/10.1145/2984511.2984531](https://doi.org/10.1145/2984511.2984531)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dementyev et al. (2016) Artem Dementyev, Hsin-Liu (Cindy) Kao, Inrak Choi,
    Deborah Ajilo, Maggie Xu, Joseph A. Paradiso, Chris Schmandt 和 Sean Follmer，2016年。Rovables:
    微型穿戴式机器人作为移动可穿戴设备。在 *Proceedings of the 29th Annual Symposium on User Interface
    Software and Technology*（日本东京） *(UIST ’16)* 期刊中。计算机协会，纽约，NY，美国，111–120。 [https://doi.org/10.1145/2984511.2984531](https://doi.org/10.1145/2984511.2984531)'
- en: Felsman et al. (2019) Peter Felsman, Colleen M. Seifert, and Joseph A. Himle.
    2019. The use of improvisational theater training to reduce social anxiety in
    adolescents. *The Arts in Psychotherapy* 63 (2019), 111–117. [https://doi.org/10.1016/j.aip.2018.12.001](https://doi.org/10.1016/j.aip.2018.12.001)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Felsman et al. (2019) Peter Felsman, Colleen M. Seifert 和 Joseph A. Himle，2019年。使用即兴戏剧训练来减少青少年的社交焦虑。在
    *The Arts in Psychotherapy* 期刊中，63（2019），111–117。 [https://doi.org/10.1016/j.aip.2018.12.001](https://doi.org/10.1016/j.aip.2018.12.001)
- en: 'Gan et al. (2020) Chuang Gan, Yiwei Zhang, Jiajun Wu, Boqing Gong, and Joshua B
    Tenenbaum. 2020. Look, listen, and act: Towards audio-visual embodied navigation.
    In *2020 IEEE International Conference on Robotics and Automation (ICRA)*. IEEE,
    9701–9707.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gan et al. (2020) Chuang Gan, Yiwei Zhang, Jiajun Wu, Boqing Gong 和 Joshua B
    Tenenbaum，2020年。看，听，行动：面向视听具身导航。在 *2020 IEEE International Conference on Robotics
    and Automation (ICRA)* 期刊中。IEEE，9701–9707。
- en: 'Gillet et al. (2020) Sarah Gillet, Wouter van den Bos, Iolanda Leite, et al.
    2020. A social robot mediator to foster collaboration and inclusion among children..
    In *Robotics: Science and Systems*.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gillet et al. (2020) Sarah Gillet, Wouter van den Bos, Iolanda Leite 等人，2020年。社交机器人调解员以促进儿童之间的合作与包容。在
    *Robotics: Science and Systems* 期刊中。'
- en: Guo et al. (2023) Yijie Guo, Zhenhan Huang, Ruhan Wang, Chih-Heng Li, Ruoyu
    Wu, Qirui Sun, Zhihao Yao, Haipeng Mi, and Yu Peng. 2023. Sparkybot:An Embodied
    AI Agent-Powered Robot with Customizable Characters andInteraction Behavior for
    Children. In *Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface
    Software and Technology* (¡conf-loc¿, ¡city¿San Francisco¡/city¿, ¡state¿CA¡/state¿,
    ¡country¿USA¡/country¿, ¡/conf-loc¿) *(UIST ’23 Adjunct)*. Association for Computing
    Machinery, New York, NY, USA, Article 90, 3 pages. [https://doi.org/10.1145/3586182.3615804](https://doi.org/10.1145/3586182.3615804)
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo 等 (2023) Yijie Guo, Zhenhan Huang, Ruhan Wang, Chih-Heng Li, Ruoyu Wu,
    Qirui Sun, Zhihao Yao, Haipeng Mi 和 Yu Peng. 2023. Sparkybot: 一种由具身AI代理驱动的机器人，具有可定制的角色和互动行为，专为儿童设计。见
    *第36届ACM用户界面软件与技术年会附录论文集*（会议地点：美国加利福尼亚州旧金山）*(UIST ’23 附录)*。计算机协会，纽约，NY，美国，文章90，3页。
    [https://doi.org/10.1145/3586182.3615804](https://doi.org/10.1145/3586182.3615804)'
- en: 'Huang et al. (2023b) Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun
    Wu, and Li Fei-Fei. 2023b. Voxposer: Composable 3d value maps for robotic manipulation
    with language models. *arXiv preprint arXiv:2307.05973* (2023).'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等 (2023b) Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu
    和 Li Fei-Fei. 2023b. Voxposer: 用于机器人操控的可组合3D价值图，结合语言模型。*arXiv预印本 arXiv:2307.05973*
    (2023)。'
- en: 'Huang et al. (2023a) Xiaoyu Huang, Dhruv Batra, Akshara Rai, and Andrew Szot.
    2023a. Skill transformer: A monolithic policy for mobile manipulation. In *Proceedings
    of the IEEE/CVF International Conference on Computer Vision*. 10852–10862.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等 (2023a) Xiaoyu Huang, Dhruv Batra, Akshara Rai 和 Andrew Szot. 2023a.
    Skill transformer: 用于移动操控的单一策略。见 *IEEE/CVF国际计算机视觉会议论文集*。10852–10862。'
- en: 'Ihara et al. (2023) Keiichi Ihara, Mehrad Faridan, Ayumi Ichikawa, Ikkaku Kawaguchi,
    and Ryo Suzuki. 2023. HoloBots: Augmenting Holographic Telepresence with Mobile
    Robots for Tangible Remote Collaboration in Mixed Reality. In *Proceedings of
    the 36th Annual ACM Symposium on User Interface Software and Technology* (¡conf-loc¿,
    ¡city¿San Francisco¡/city¿, ¡state¿CA¡/state¿, ¡country¿USA¡/country¿, ¡/conf-loc¿)
    *(UIST ’23)*. Association for Computing Machinery, New York, NY, USA, Article
    119, 12 pages. [https://doi.org/10.1145/3586183.3606727](https://doi.org/10.1145/3586183.3606727)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ihara 等 (2023) Keiichi Ihara, Mehrad Faridan, Ayumi Ichikawa, Ikkaku Kawaguchi
    和 Ryo Suzuki. 2023. HoloBots: 增强全息远程协作的移动机器人在混合现实中的应用。见 *第36届ACM用户界面软件与技术年会论文集*（会议地点：美国加利福尼亚州旧金山）*(UIST
    ’23)*。计算机协会，纽约，NY，美国，文章119，12页。 [https://doi.org/10.1145/3586183.3606727](https://doi.org/10.1145/3586183.3606727)'
- en: Jariyavajee et al. (2018) Chattriya Jariyavajee, Arnon Visavakitcharoen, Preeyaphond
    Sirimaha, Booncharoen Sirinaovakul, and Jumpol Polvichai. 2018. A Practical interactive
    chess board with automatic movement control. In *2018 Global Wireless Summit (GWS)*.
    IEEE, 246–250.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jariyavajee 等 (2018) Chattriya Jariyavajee, Arnon Visavakitcharoen, Preeyaphond
    Sirimaha, Booncharoen Sirinaovakul 和 Jumpol Polvichai. 2018. 一种具有自动移动控制的实用互动棋盘。见
    *2018全球无线峰会 (GWS)*。IEEE，246–250。
- en: 'Johnstone (2012) Keith Johnstone. 2012. *Impro: Improvisation and the theatre*.
    Routledge.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Johnstone (2012) Keith Johnstone. 2012. *Impro: 即兴创作与戏剧*。Routledge。'
- en: 'Kaimoto et al. (2022) Hiroki Kaimoto, Kyzyl Monteiro, Mehrad Faridan, Jiatong
    Li, Samin Farajian, Yasuaki Kakehi, Ken Nakagaki, and Ryo Suzuki. 2022. Sketched
    reality: Sketching bi-directional interactions between virtual and physical worlds
    with ar and actuated tangible ui. In *Proceedings of the 35th Annual ACM Symposium
    on User Interface Software and Technology*. 1–12.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaimoto 等 (2022) Hiroki Kaimoto, Kyzyl Monteiro, Mehrad Faridan, Jiatong Li,
    Samin Farajian, Yasuaki Kakehi, Ken Nakagaki 和 Ryo Suzuki. 2022. 草图现实：使用增强现实和驱动式触觉用户界面在虚拟和物理世界之间进行双向交互。见
    *第35届ACM用户界面软件与技术年会论文集*。1–12。
- en: 'Kim and Follmer (2019) Lawrence H. Kim and Sean Follmer. 2019. SwarmHaptics:
    Haptic Display with Swarm Robots. In *Proceedings of the 2019 CHI Conference on
    Human Factors in Computing Systems* (Glasgow, Scotland Uk) *(CHI ’19)*. Association
    for Computing Machinery, New York, NY, USA, 1–13. [https://doi.org/10.1145/3290605.3300918](https://doi.org/10.1145/3290605.3300918)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim 和 Follmer (2019) Lawrence H. Kim 和 Sean Follmer. 2019. SwarmHaptics: 利用群体机器人进行触觉显示。见
    *2019年CHI人机交互系统会议论文集*（英国格拉斯哥）*(CHI ’19)*。计算机协会，纽约，NY，美国，1–13。 [https://doi.org/10.1145/3290605.3300918](https://doi.org/10.1145/3290605.3300918)'
- en: 'Kolve et al. (2022) Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt,
    Luca Weihs, Alvaro Herrasti, Matt Deitke, Kiana Ehsani, Daniel Gordon, Yuke Zhu,
    Aniruddha Kembhavi, Abhinav Gupta, and Ali Farhadi. 2022. AI2-THOR: An Interactive
    3D Environment for Visual AI. arXiv:1712.05474 [cs.CV]'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kolve 等人 (2022) Eric Kolve、Roozbeh Mottaghi、Winson Han、Eli VanderBilt、Luca Weihs、Alvaro
    Herrasti、Matt Deitke、Kiana Ehsani、Daniel Gordon、Yuke Zhu、Aniruddha Kembhavi、Abhinav
    Gupta和Ali Farhadi。2022. AI2-THOR：一个可视化人工智能的交互式3D环境。arXiv:1712.05474 [cs.CV]
- en: 'Li et al. (2022) Jiannan Li, Maurício Sousa, Chu Li, Jessie Liu, Yan Chen,
    Ravin Balakrishnan, and Tovi Grossman. 2022. ASTEROIDS: Exploring Swarms of Mini-Telepresence
    Robots for Physical Skill Demonstration. In *Proceedings of the 2022 CHI Conference
    on Human Factors in Computing Systems* (¡conf-loc¿, ¡city¿New Orleans¡/city¿,
    ¡state¿LA¡/state¿, ¡country¿USA¡/country¿, ¡/conf-loc¿) *(CHI ’22)*. Association
    for Computing Machinery, New York, NY, USA, Article 111, 14 pages. [https://doi.org/10.1145/3491102.3501927](https://doi.org/10.1145/3491102.3501927)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2022) 李建楠、莫里西奥·苏萨、李楚、刘杰、陈燕、拉文·巴拉克里斯南和托维·格罗斯曼。2022. ASTEROIDS：探索迷你远程传真机器人群在物理技能演示中的应用。在*2022年人机交互计算系统CHI大会论文集*
    (¡conf-loc¿, ¡city¿新奥尔良¡/city¿, ¡state¿LA¡/state¿, ¡country¿美国¡/country¿, ¡/conf-loc¿)
    *(CHI ’22)*。计算机协会，纽约，纽约州，美国，第111篇，14 页。[https://doi.org/10.1145/3491102.3501927](https://doi.org/10.1145/3491102.3501927)
- en: Liu et al. (2021) Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence
    Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-$3$?
    *arXiv preprint arXiv:2101.06804* (2021).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2021) 刘家昌、沈鼎翰、张毅哲、比尔·多兰、劳伦斯·卡林和陈伟竹。2021.  什么构成了 GPT-$3$ 的良好上下文示例？*arXiv
    preprint arXiv:2101.06804* (2021).
- en: 'Long et al. (2023) Yuxing Long, Xiaoqi Li, Wenzhe Cai, and Hao Dong. 2023.
    Discuss before moving: Visual language navigation via multi-expert discussions.
    *arXiv preprint arXiv:2309.11382* (2023).'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long 等人 (2023) 龙宇星、李晓奇、蔡文哲和董浩。2023. 移动前讨论：通过多专家讨论进行视觉语言导航。*arXiv preprint arXiv:2309.11382*
    (2023).
- en: 'Matuszek et al. (2011) Cynthia Matuszek, Brian Mayton, Roberto Aimi, Marc Peter
    Deisenroth, Liefeng Bo, Robert Chu, Mike Kung, Louis LeGrand, Joshua R Smith,
    and Dieter Fox. 2011. Gambit: An autonomous chess-playing robotic system. In *2011
    IEEE international conference on robotics and automation*. IEEE, 4291–4297.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Matuszek 等人 (2011) 辛西娅·马图谢克、布赖恩·梅顿、罗伯托·艾米、马克·彼得·代森罗斯、利芬·波、罗伯特·楚、麦克·孔、路易斯·勒格兰德、约书亚·史密斯和迪特尔·福克斯。2011.
    Gambit: 一种自主的国际象棋机器人系统。在*2011 IEEE国际机器人与自动化大会*。IEEE，4291–4297.'
- en: 'Nakagaki et al. (2020) Ken Nakagaki, Joanne Leong, Jordan L. Tappa, João Wilbert,
    and Hiroshi Ishii. 2020. HERMITS: Dynamically Reconfiguring the Interactivity
    of Self-propelled TUIs with Mechanical Shell Add-ons. In *Proceedings of the 33rd
    Annual ACM Symposium on User Interface Software and Technology* (Virtual Event,
    USA) *(UIST ’20)*. Association for Computing Machinery, New York, NY, USA, 882–896.
    [https://doi.org/10.1145/3379337.3415831](https://doi.org/10.1145/3379337.3415831)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nakagaki 等人 (2020) 仲垣健、琼安·李昂、乔丹·L. 塔帕、华娜·威尔伯特和石井博。2020. HERMITS：动态重构自推进TUI的互动性与机械外壳附件。在*第33届年度ACM用户界面软件与技术研讨会论文集*
    (虚拟活动，美国) *(UIST ’20)*。计算机协会，纽约，纽约州，美国，882–896。[https://doi.org/10.1145/3379337.3415831](https://doi.org/10.1145/3379337.3415831)
- en: 'Peng et al. (2020) Yu Peng, Yuan-Ling Feng, Nan Wang, and Haipeng Mi. 2020.
    How children interpret robots’ contextual behaviors in live theatre: Gaining insights
    for multi-robot theatre design. In *2020 29th IEEE International Conference on
    Robot and Human Interactive Communication (RO-MAN)*. IEEE, 327–334.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等人 (2020) 彭宇、冯远玲、王楠和米海鹏。2020. 孩子如何解释剧场中机器人的上下文行为：为多机器人剧场设计获得洞见。在*2020年第29届IEEE国际机器人与人类互动通信大会(RO-MAN)*。IEEE，327–334.
- en: 'Qiao et al. (2023) Yanyuan Qiao, Yuankai Qi, Zheng Yu, Jing Liu, and Qi Wu.
    2023. March in chat: Interactive prompting for remote embodied referring expression.
    In *Proceedings of the IEEE/CVF International Conference on Computer Vision*.
    15758–15767.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiao 等人 (2023) 乔艳远、齐远凯、俞铮、刘靖和吴奇。2023. 聊中行：远程体态指称的互动提示。在*IEEE/CVF国际计算机视觉会议论文集*。15758–15767.
- en: Raman et al. (2022) Shreyas Sundara Raman, Vanya Cohen, Eric Rosen, Ifrah Idrees,
    David Paulius, and Stefanie Tellex. 2022. Planning with large language models
    via corrective re-prompting. In *NeurIPS 2022 Foundation Models for Decision Making
    Workshop*.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raman 等人 (2022) Shreyas Sundara Raman、Vanya Cohen、Eric Rosen、Ifrah Idrees、David
    Paulius和Stefanie Tellex。2022. 通过纠正重新提示来进行大规模语言模型的规划。在*NeurIPS 2022决策模型基础研讨会*。
- en: Saberpour Abadian et al. (2023) Artin Saberpour Abadian, Ata Otaran, Martin
    Schmitz, Marie Muehlhaus, Rishabh Dabral, Diogo Luvizon, Azumi Maekawa, Masahiko
    Inami, Christian Theobalt, and Jürgen Steimle. 2023. Computational Design of Personalized
    Wearable Robotic Limbs. In *Proceedings of the 36th Annual ACM Symposium on User
    Interface Software and Technology* (¡conf-loc¿, ¡city¿San Francisco¡/city¿, ¡state¿CA¡/state¿,
    ¡country¿USA¡/country¿, ¡/conf-loc¿) *(UIST ’23)*. Association for Computing Machinery,
    New York, NY, USA, Article 68, 13 pages. [https://doi.org/10.1145/3586183.3606748](https://doi.org/10.1145/3586183.3606748)
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saberpour Abadian et al. (2023) Artin Saberpour Abadian, Ata Otaran, Martin
    Schmitz, Marie Muehlhaus, Rishabh Dabral, Diogo Luvizon, Azumi Maekawa, Masahiko
    Inami, Christian Theobalt, 和 Jürgen Steimle. 2023. 个性化可穿戴机器人肢体的计算设计。载于 *第36届年度ACM用户界面软件和技术研讨会论文集*（¡conf-loc¿，¡city¿旧金山¡/city¿，¡state¿CA¡/state¿，¡country¿美国¡/country¿，¡/conf-loc¿）*(UIST
    ’23)*。计算机协会，纽约，NY，美国，文章68，13页。 [https://doi.org/10.1145/3586183.3606748](https://doi.org/10.1145/3586183.3606748)
- en: 'Savva et al. (2019) Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili
    Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra
    Malik, et al. 2019. Habitat: A platform for embodied ai research. In *Proceedings
    of the IEEE/CVF international conference on computer vision*. 9339–9347.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Savva et al. (2019) Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili
    Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra
    Malik, 等. 2019. Habitat: 一个用于具身人工智能研究的平台。载于 *IEEE/CVF国际计算机视觉会议论文集*。9339–9347.'
- en: 'Sawyer (2000) R. Keith Sawyer. 2000. Improvisational Cultures: Collaborative
    Emergence and Creativity in Improvisation. *Mind, Culture, and Activity* 7, 3
    (2000), 180–185. [https://doi.org/10.1207/S15327884MCA0703_05](https://doi.org/10.1207/S15327884MCA0703_05)
    arXiv:https://doi.org/10.1207/S15327884MCA0703_05'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sawyer (2000) R. Keith Sawyer. 2000. 即兴文化：即兴创作中的协作性出现和创造力。*心智、文化与活动* 7, 3 (2000),
    180–185. [https://doi.org/10.1207/S15327884MCA0703_05](https://doi.org/10.1207/S15327884MCA0703_05)
    arXiv:https://doi.org/10.1207/S15327884MCA0703_05
- en: 'Schwenke et al. (2021) Diana Schwenke, Maja Dshemuchadse, Lisa Rasehorn, Dominik
    Klarholter, and Stefan Scherbaum. 2021. Improv to Improve: The Impact of Improvisational
    Theater on Creativity, Acceptance, and Psychological Well-Being. *Journal of Creativity
    in Mental Health* 16, 1 (2021), 31–48. [https://doi.org/10.1080/15401383.2020.1754987](https://doi.org/10.1080/15401383.2020.1754987)
    arXiv:https://doi.org/10.1080/15401383.2020.1754987'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schwenke et al. (2021) Diana Schwenke, Maja Dshemuchadse, Lisa Rasehorn, Dominik
    Klarholter, 和 Stefan Scherbaum. 2021. 即兴表演的影响：即兴剧对创造力、接受度和心理健康的影响。*心理健康创造力杂志*
    16, 1 (2021), 31–48. [https://doi.org/10.1080/15401383.2020.1754987](https://doi.org/10.1080/15401383.2020.1754987)
    arXiv:https://doi.org/10.1080/15401383.2020.1754987
- en: 'Suzuki et al. (2020) Ryo Suzuki, Rubaiat Habib Kazi, Li-yi Wei, Stephen DiVerdi,
    Wilmot Li, and Daniel Leithinger. 2020. RealitySketch: Embedding Responsive Graphics
    and Visualizations in AR through Dynamic Sketching. In *Proceedings of the 33rd
    Annual ACM Symposium on User Interface Software and Technology* (Virtual Event,
    USA) *(UIST ’20)*. Association for Computing Machinery, New York, NY, USA, 166–181.
    [https://doi.org/10.1145/3379337.3415892](https://doi.org/10.1145/3379337.3415892)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzuki et al. (2020) Ryo Suzuki, Rubaiat Habib Kazi, Li-yi Wei, Stephen DiVerdi,
    Wilmot Li, 和 Daniel Leithinger. 2020. RealitySketch：通过动态草图在增强现实中嵌入响应式图形和可视化。载于
    *第33届年度ACM用户界面软件和技术研讨会论文集*（虚拟会议，美国）*(UIST ’20)*。计算机协会，纽约，NY，美国，166–181. [https://doi.org/10.1145/3379337.3415892](https://doi.org/10.1145/3379337.3415892)
- en: 'Suzuki et al. (2019) Ryo Suzuki, Clement Zheng, Yasuaki Kakehi, Tom Yeh, Ellen
    Yi-Luen Do, Mark D. Gross, and Daniel Leithinger. 2019. ShapeBots: Shape-changing
    Swarm Robots. In *Proceedings of the 32nd Annual ACM Symposium on User Interface
    Software and Technology* (New Orleans, LA, USA) *(UIST ’19)*. Association for
    Computing Machinery, New York, NY, USA, 493–505. [https://doi.org/10.1145/3332165.3347911](https://doi.org/10.1145/3332165.3347911)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzuki et al. (2019) Ryo Suzuki, Clement Zheng, Yasuaki Kakehi, Tom Yeh, Ellen
    Yi-Luen Do, Mark D. Gross, 和 Daniel Leithinger. 2019. ShapeBots：形状改变的群体机器人。载于
    *第32届年度ACM用户界面软件和技术研讨会论文集*（新奥尔良，LA，美国）*(UIST ’19)*。计算机协会，纽约，NY，美国，493–505. [https://doi.org/10.1145/3332165.3347911](https://doi.org/10.1145/3332165.3347911)
- en: 'van Breemen et al. (2005) Albert van Breemen, Xue Yan, and Bernt Meerbeek.
    2005. iCat: an animated user-interface robot with personality. In *Proceedings
    of the Fourth International Joint Conference on Autonomous Agents and Multiagent
    Systems* (The Netherlands) *(AAMAS ’05)*. Association for Computing Machinery,
    New York, NY, USA, 143–144. [https://doi.org/10.1145/1082473.1082823](https://doi.org/10.1145/1082473.1082823)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van Breemen 等人（2005）Albert van Breemen、Xue Yan 和 Bernt Meerbeek。2005。iCat：一个具有个性的动画用户界面机器人。在
    *第四届国际自主代理与多代理系统联合会议*（荷兰）*(AAMAS ’05)* 中。计算机协会，纽约，NY，USA，143–144。 [https://doi.org/10.1145/1082473.1082823](https://doi.org/10.1145/1082473.1082823)
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is all you need. *Advances in neural information processing systems* 30 (2017).
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等人（2017）Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion
    Jones、Aidan N Gomez、Łukasz Kaiser 和 Illia Polosukhin。2017。注意力机制就是你所需要的一切。*神经信息处理系统进展*
    30（2017）。
- en: 'Wang et al. (2020) Xin Eric Wang, Vihan Jain, Eugene Ie, William Yang Wang,
    Zornitsa Kozareva, and Sujith Ravi. 2020. Environment-agnostic multitask learning
    for natural language grounded navigation. In *Computer Vision–ECCV 2020: 16th
    European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXIV 16*.
    Springer, 413–430.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2020）Xin Eric Wang、Vihan Jain、Eugene Ie、William Yang Wang、Zornitsa Kozareva
    和 Sujith Ravi。2020。环境无关的多任务学习用于自然语言基础的导航。在 *计算机视觉–ECCV 2020：第十六届欧洲会议，英国格拉斯哥，2020年8月23–28日，论文集，第
    XXIV 部分 16* 中。Springer，413–430。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in neural information processing
    systems* 35 (2022), 24824–24837.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022）Jason Wei、Xuezhi Wang、Dale Schuurmans、Maarten Bosma、Fei Xia、Ed Chi、Quoc
    V Le、Denny Zhou 等。2022。链式思维提示在大型语言模型中引发推理。*神经信息处理系统进展* 35（2022），24824–24837。
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. *arXiv preprint
    arXiv:2308.08155* (2023).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2023）Qingyun Wu、Gagan Bansal、Jieyu Zhang、Yiran Wu、Shaokun Zhang、Erkang
    Zhu、Beibin Li、Li Jiang、Xiaoyun Zhang 和 Chi Wang。2023。Autogen：通过多代理对话框架启用下一代 llm
    应用。*arXiv 预印本 arXiv:2308.08155*（2023）。
- en: 'Yu et al. (2023) Lilith Yu, Chenfeng Gao, David Wu, and Ken Nakagaki. 2023.
    AeroRigUI: Actuated TUIs for Spatial Interaction using Rigging Swarm Robots on
    Ceilings in Everyday Space. In *Proceedings of the 2023 CHI Conference on Human
    Factors in Computing Systems*. 1–18.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人（2023）Lilith Yu、Chenfeng Gao、David Wu 和 Ken Nakagaki。2023。AeroRigUI：在日常空间中使用吊装群体机器人进行空间交互的驱动
    TUI。在 *2023 年计算机系统人因学会议论文集* 中。1–18。
- en: 'Zhu et al. (2021) Jichen Zhu, Jennifer Villareale, Nithesh Javvaji, Sebastian
    Risi, Mathias Löwe, Rush Weigelt, and Casper Harteveld. 2021. Player-AI interaction:
    What neural network games reveal about AI as play. In *Proceedings of the 2021
    CHI Conference on Human Factors in Computing Systems*. 1–17.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等人（2021）Jichen Zhu、Jennifer Villareale、Nithesh Javvaji、Sebastian Risi、Mathias
    Löwe、Rush Weigelt 和 Casper Harteveld。2021。玩家与 AI 的互动：神经网络游戏揭示了 AI 作为游戏的本质。在 *2021
    年计算机系统人因学会议论文集* 中。1–17。
