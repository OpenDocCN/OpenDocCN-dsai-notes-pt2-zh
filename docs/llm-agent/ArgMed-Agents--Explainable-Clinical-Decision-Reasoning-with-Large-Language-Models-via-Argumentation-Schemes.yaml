- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:50:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:50:30'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language
    Models via Argumentation Schemes'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'ArgMed-Agents: 使用大语言模型通过论证方案进行可解释的临床决策推理'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.06294](https://ar5iv.labs.arxiv.org/html/2403.06294)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.06294](https://ar5iv.labs.arxiv.org/html/2403.06294)
- en: Shengxin Hong¹ Liang Xiao²    Xin Zhang¹&Jianxia Chen²
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Shengxin Hong¹ Liang Xiao²    Xin Zhang¹&Jianxia Chen²
- en: ¹Detroit Green Technology Institute, Hubei University of Technology, China
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹中国湖北工业大学底特律绿色技术研究所
- en: ²School of Computer Science, Hubei University of Technology, China seikin.shengxinhong@gmail.com,
    lx@mail.hbut.edu.cn
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²中国湖北工业大学计算机科学学院 seikin.shengxinhong@gmail.com, lx@mail.hbut.edu.cn
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: There are two main barriers to using large language models (LLMs) in clinical
    reasoning. Firstly, while LLMs exhibit significant promise in Natural Language
    Processing (NLP) tasks, their performance in complex reasoning and planning falls
    short of expectations. Secondly, LLMs use uninterpretable methods to make clinical
    decisions that are fundamentally different from the clinician’s cognitive processes.
    This leads to user distrust. In this paper, we present a multi-agent framework
    called ArgMed-Agents, which aims to enable LLM-based agents to make explainable
    clinical decision reasoning through interaction. ArgMed-Agents performs self-argumentation
    iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism
    for modeling cognitive processes in clinical reasoning), and then constructs the
    argumentation process as a directed graph representing conflicting relationships.
    Ultimately, Reasoner(a symbolic solver) identify a series of rational and coherent
    arguments to support decision. ArgMed-Agents enables LLMs to mimic the process
    of clinical argumentative reasoning by generating explanations of reasoning in
    a self-directed manner. The setup experiments show that ArgMed-Agents not only
    improves accuracy in complex clinical decision reasoning problems compared to
    other prompt methods, but more importantly, it provides users with decision explanations
    that increase their confidence.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大语言模型（LLMs）进行临床推理有两个主要障碍。首先，尽管LLMs在自然语言处理（NLP）任务中展示了巨大的潜力，但在复杂推理和规划中的表现仍未达到预期。其次，LLMs使用的不可解释的方法来做出临床决策与临床医生的认知过程根本不同，这导致用户的不信任。在本文中，我们提出了一个名为ArgMed-Agents的多智能体框架，旨在通过互动使基于LLM的智能体能够进行可解释的临床决策推理。ArgMed-Agents通过临床决策论证方案（用于建模临床推理中的认知过程的推理机制）进行自我论证迭代，然后将论证过程构建为一个表示冲突关系的有向图。最终，Reasoner（一个符号求解器）识别出一系列理性且连贯的论点以支持决策。ArgMed-Agents使LLMs能够通过自我导向的方式生成推理解释，从而模拟临床论证推理的过程。设置实验表明，与其他提示方法相比，ArgMed-Agents不仅在复杂临床决策推理问题中提高了准确性，更重要的是，它为用户提供了决策解释，从而增加了他们的信心。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Large Language Models (LLMs) OpenAI ([2023](#bib.bib25)) have received a lot
    of attention for their human-like performance in a variety of domains. In the
    medical field especially, preliminary studies have shown that LLMs can be used
    as clinical assistants for tasks such as writing clinical texts Nayak et al. ([2023](#bib.bib22)),
    providing biomedical knowledge Singhal et al. ([2022](#bib.bib33)) and drafting
    responses to patients’ questions Ayers et al. ([2023](#bib.bib1)). However, the
    following barriers to building an LLM-based clinical decision-making system still
    exist: (i) LLMs still struggle to provide secure, stable answers when faced with
    highly complex clinical reasoning tasks Pal et al. ([2023](#bib.bib26)). (ii)
    There is a perception that LLMs use unexplainable methods to arrive at clinical
    decisions (known as black boxes), which may have led to user distrust Eigner and
    Händler ([2024](#bib.bib11)).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）OpenAI ([2023](#bib.bib25))因其在人类语言处理（NLP）任务中的显著表现而受到广泛关注。尤其在医学领域，初步研究表明，LLMs可以作为临床助手用于撰写临床文本
    Nayak et al. ([2023](#bib.bib22))、提供生物医学知识 Singhal et al. ([2022](#bib.bib33))
    和起草对患者问题的回应 Ayers et al. ([2023](#bib.bib1))。然而，基于LLM的临床决策系统仍面临以下障碍：（i）LLMs在面对高度复杂的临床推理任务时仍难以提供安全、稳定的答案
    Pal et al. ([2023](#bib.bib26))。（ii）存在LLMs采用不可解释的方法来得出临床决策（即黑箱）的看法，这可能导致用户的不信任
    Eigner and Händler ([2024](#bib.bib11))。
- en: To address these barriers, exploring the capabilities of LLMs in argumentative
    reasoning is a promising direction. Argumentation is a means of conveying a compelling
    point of view that can increase user acceptance of a position. Its considered
    a fundamental requirement for building Human-Centric AI Dietz et al. ([2022](#bib.bib9)).
    As computational argumentation has become a growing area of research in Natural
    Language Processing (NLP) Dietz et al. ([2021](#bib.bib8)), researchers have begun
    to apply argumentation to a wide range of clinical reasoning applications, including
    analysis of clinical discussions Qassas et al. ([2015](#bib.bib29)), clinical
    decision making Hong et al. ([2023](#bib.bib14)); Zeng et al. ([2020](#bib.bib43));
    Sassoon et al. ([2021](#bib.bib30)), address clinical conflicting Čyras et al.
    ([2018](#bib.bib6)). In the recent past, some work has assessed the ability of
    LLMs in argumentation reasoning Chen et al. ([2023](#bib.bib4)); Castagna et al.
    ([2024](#bib.bib3)) or non-monotonic reasoning Xiu et al. ([2022](#bib.bib42)).
    Although LLMs show some potential for computational argumentation, more results
    show that LLMs perform poorly in logical reasoning tasks Xie et al. ([2024](#bib.bib41)),
    and better ways to utilise LLMs for non-monotonic reasoning tasks need to be explored.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些障碍，探索 LLM 在论证推理中的能力是一个有前景的方向。论证是一种传达有说服力观点的手段，可以增加用户对某一立场的接受度。它被视为构建以人为本的
    AI 的基本要求 Dietz 等人（[2022](#bib.bib9)）。随着计算论证成为自然语言处理（NLP）领域的一个重要研究方向 Dietz 等人（[2021](#bib.bib8)），研究人员开始将论证应用于广泛的临床推理应用，包括临床讨论分析
    Qassas 等人（[2015](#bib.bib29)）、临床决策制定 Hong 等人（[2023](#bib.bib14)）；Zeng 等人（[2020](#bib.bib43)）；Sassoon
    等人（[2021](#bib.bib30)）、解决临床冲突 Čyras 等人（[2018](#bib.bib6)）。最近，一些工作评估了 LLM 在论证推理中的能力
    Chen 等人（[2023](#bib.bib4)）；Castagna 等人（[2024](#bib.bib3)）或非单调推理 Xiu 等人（[2022](#bib.bib42)）。尽管
    LLM 在计算论证方面显示出一定的潜力，但更多结果表明 LLM 在逻辑推理任务中表现不佳 Xie 等人（[2024](#bib.bib41)），需要探索更好的方法来利用
    LLM 进行非单调推理任务。
- en: Meanwhile, LLM as agent studies have been surprisingly successful Zhang et al.
    ([2023](#bib.bib44)); Wang et al. ([2023](#bib.bib38)); Shi et al. ([2024](#bib.bib32)).
    These methods use LLMs as computational engines for autonomous agents, and optimise
    the reasoning, planning capabilities of LLMs through external tools (e.g. symbolic
    solvers, APIs, retrieval tools, etc.) Pan et al. ([2023](#bib.bib27)); Shi et
    al. ([2024](#bib.bib32)), multi-agent interactions Tang et al. ([2024](#bib.bib35))
    and novel algorithmic frameworks Gandhi et al. ([2023](#bib.bib13)). Through this
    design, LLMs agents can interact with the environment and generate action plans
    through intermediate reasoning steps that can be executed sequentially to obtain
    an effective solution.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，LLM 作为代理的研究取得了令人惊讶的成功 Zhang 等人（[2023](#bib.bib44)）；Wang 等人（[2023](#bib.bib38)）；Shi
    等人（[2024](#bib.bib32)）。这些方法将 LLM 作为自主代理的计算引擎，并通过外部工具（例如符号求解器、API、检索工具等）Pan 等人（[2023](#bib.bib27)）；Shi
    等人（[2024](#bib.bib32)）、多代理交互 Tang 等人（[2024](#bib.bib35)）以及新颖的算法框架 Gandhi 等人（[2023](#bib.bib13)）来优化
    LLM 的推理和规划能力。通过这种设计，LLM 代理可以与环境互动，并通过中间推理步骤生成可以顺序执行的行动计划，以获得有效的解决方案。
- en: 'Motivated by these concepts, we present ArgMed-Agents, a multi-agent framework
    designed for explainable clinical decision reasoning. We formalised the cognitive
    process of clinical reasoning using an argumentation scheme for clinical decision
    (ASCD) as a prompt strategy for interactive reasoning by LLM agents. There are
    three types of agents in ArgMed-Agents: the Generator, the Verifier, and the Reasoner.
    the Generator generates arguments to support clinical decisions based on the argumentation
    scheme; the Verifier checks the arguments for legitimacy based on the critical
    question, and if not legitimate, it asks the Generator to generate attack arguments;
    Reasoner is a symbolic solver that identifies reasonable, non-contradictory arguments
    in the resulting directed argumentation graph as decision support.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 受这些概念的启发，我们提出了 ArgMed-Agents，一个旨在解释性临床决策推理的多代理框架。我们使用临床决策论证方案（ASCD）作为 LLM 代理进行交互式推理的提示策略，形式化了临床推理的认知过程。ArgMed-Agents
    中有三种类型的代理：生成器、验证器和推理器。生成器根据论证方案生成支持临床决策的论据；验证器根据关键问题检查论据的合法性，如果不合法，则要求生成器生成攻击性论据；推理器是一个符号求解器，在结果导向论证图中识别合理且不矛盾的论据作为决策支持。
- en: In our method, we do not expect every proposed argument or detection of Generator
    or Verifier to be correct, instead we consider their generation as a assumption.
    The LLM agents are induced to recursively iterate in a self-argumentative manner
    through the prompt strategy , while the newly proposed assumptions always contradict
    the old ones, and eventually the Reasoner eliminates unreasonable assumptions
    and identifies coherent arguments, leading to consistent reasoning results. ArgMed-Agents
    enables LLMs to explain its own outputs in terms of self-cognitive profiling by
    modelling their own generation as a prompt for question recursion. The generative
    process derives the attack relations of the arguments are determined based on
    the ASCD prompt strategy. For example, when there exist two decisions as arguments
    $a$, they attack each other based on the decision exclusivity defined in ASCD.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的方法中，我们不期望每个提出的论点或生成器或验证器的检测都是正确的，相反，我们将它们的生成视为一种假设。LLM 代理通过提示策略以自我论证的方式递归迭代，而新提出的假设总是与旧的假设相矛盾，最终推理器会排除不合理的假设并识别一致的论点，从而得出一致的推理结果。ArgMed-Agents
    使 LLM 能够通过将自身生成建模为问题递归的提示，以自我认知分析的方式解释其输出。生成过程中的攻击关系是基于 ASCD 提示策略来确定的。例如，当存在两个作为论点
    $a$ 的决策时，它们基于 ASCD 中定义的决策排他性相互攻击。
- en: Our experiment was divided into two parts, evaluating accuracy and explainability
    of ArgMed-Agents clinical reasoning, respectively. First, we conducted experiments
    on two datasets, including MedQA Jin et al. ([2020](#bib.bib17)) and PubMedQA
    Jin et al. ([2019](#bib.bib16)). To better align with real-world application scenarios,
    our study focused on a zero-shot setting. Second, we used predictability and traceability
    as measures of explainability by manually assessing whether the clinical reasoning
    process of ArgMed-Agents is meaningful in terms of explanation for users. The
    results show that ArgMed-Agents achieves better performance in both accuracy and
    explainability compared to direct generation and Chain of Thought (CoT).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验分为两个部分，分别评估 ArgMed-Agents 临床推理的准确性和可解释性。首先，我们在两个数据集上进行实验，包括 MedQA Jin et
    al. ([2020](#bib.bib17)) 和 PubMedQA Jin et al. ([2019](#bib.bib16))。为了更好地与实际应用场景对接，我们的研究集中于零样本设置。其次，我们通过手动评估
    ArgMed-Agents 的临床推理过程在解释用户方面是否有意义，以可预测性和可追溯性作为可解释性的衡量标准。结果显示，与直接生成和思维链（CoT）相比，ArgMed-Agents
    在准确性和可解释性方面都表现更好。
- en: 2 Preliminaries
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 基础知识
- en: 2.1 Abstract Argumentation Framework
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 抽象论证框架
- en: 'Abstract Argumentation (AA) frameworks Dung ([1995](#bib.bib10)) are pair $\langle\mathcal{A},\mathcal{R}\rangle$.
    On top of that, Dung defines some notions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 抽象论证（AA）框架 Dung ([1995](#bib.bib10)) 是一个对 $\langle\mathcal{A},\mathcal{R}\rangle$。在此基础上，Dung
    定义了一些概念：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists a\in\mathcal{A}$.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists a\in\mathcal{A}$。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A set of arguments is conflict-free if there is no attack between its arguments.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果一组论点之间没有攻击，则该组论点是无冲突的。
- en: In order to decide whether a single parameter can be accepted or whether multiple
    parameters can be accepted at the same time, the argumentation system allows for
    the use of various semantics to compute the set of parameters (called extensions).
    For example, Given an AA framework $\langle\mathcal{A},\mathcal{R}\rangle$.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定单个参数是否可以接受或是否可以同时接受多个参数，论证系统允许使用各种语义来计算参数集（称为扩展）。例如，给定一个 AA 框架 $\langle\mathcal{A},\mathcal{R}\rangle$。
- en: 2.2 Argumentation Scheme
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 论证方案
- en: 'The concept of Argumentation Scheme (AS) originated within the domain of informal
    logic, stemming from the seminal works of Walton et al. ([2008](#bib.bib36));
    Walton ([1996](#bib.bib37)). Argumentation Scheme serves as a semi-formalized
    framework for capturing and analyzing human reasoning patterns. Formally defined
    as $AS=\langle P,c,V\rangle$). A pivotal aspect of the argumentation scheme is
    the delineation of Critical Questions (CQs) pertinent to AS. Failure to address
    them prompts a challenge to both the premises and the conclusion posited by the
    scheme. Consequently, the role of CQs is to instigate argument generation; when
    an AS is contested, it engenders the formulation of a counter-argument in response
    to the initial AS. This iterative process culminates in the construction of an
    attack argument graph, facilitating a nuanced understanding of argumentative dynamics.
    Figure [1](#S3.F1 "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes") illustrates three templates of argumentation schemes.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '论证方案（AS）的概念起源于非正式逻辑领域，源于 Walton 等人 ([2008](#bib.bib36)) 和 Walton ([1996](#bib.bib37))
    的开创性工作。论证方案作为一个半形式化的框架，用于捕捉和分析人类推理模式。形式上定义为 $AS=\langle P,c,V\rangle$。论证方案的一个关键方面是界定与
    AS 相关的关键问题（CQs）。未能回答这些问题会对方案提出的前提和结论构成挑战。因此，关键问题的作用是激发论证生成；当一个 AS 受到质疑时，会产生一个反论证来回应最初的
    AS。这一迭代过程最终形成一个攻击论证图，从而有助于对论证动态的深刻理解。图 [1](#S3.F1 "Figure 1 ‣ 3 Argumentation
    Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning
    with Large Language Models via Argumentation Schemes") 展示了三种论证方案模板。'
- en: 3 Argumentation Scheme for Clinial Decision
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 临床决策的论证方案
- en: 'In the past, numerous studies Oliveira et al. ([2018](#bib.bib24)); Sassoon
    et al. ([2021](#bib.bib30)); Qassas et al. ([2015](#bib.bib29)) have explored
    the application of argumentation in the clinical domain. In this section, we provide
    a summary of these endeavors, focusing on the development of Argumentation Schemes
    for Clinical Decision (ASCD). ASCD encapsulate various argumentation scheme tailored
    for clinical decision-making processes and the reasoning process. Additionally,
    we propose to refine and adapt these schemes to enhance their suitability for
    LLM. ASCD consists of three argumentation schemes which are Argumentation Scheme
    for Decision (ASD), Argumentation Scheme for Side Effect (ASSE) and Argumentation
    Scheme for Better Decision (ASBD). Figure [1](#S3.F1 "Figure 1 ‣ 3 Argumentation
    Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning
    with Large Language Models via Argumentation Schemes") includes the components
    of the three argumentation schemes and the derivations between them.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '过去，Oliveira 等人 ([2018](#bib.bib24))、Sassoon 等人 ([2021](#bib.bib30))、Qassas
    等人 ([2015](#bib.bib29)) 进行了大量研究，探讨了论证在临床领域的应用。在本节中，我们总结了这些努力，重点介绍了临床决策的论证方案（ASCD）的发展。ASCD
    包含了针对临床决策过程和推理过程的各种论证方案。此外，我们提议对这些方案进行完善和调整，以提高其对大型语言模型（LLM）的适用性。ASCD 包括三个论证方案，即决策论证方案（ASD）、副作用论证方案（ASSE）和更好决策论证方案（ASBD）。图
    [1](#S3.F1 "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes") 显示了这三个论证方案的组成部分及其之间的推导关系。'
- en: '![Refer to caption](img/bdec46be281a957e88faa4649cb70708.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/bdec46be281a957e88faa4649cb70708.png)'
- en: 'Figure 1: The derivation rules between the argumentation schemes in ASCD.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：ASCD 中论证方案之间的推导规则。
- en: 'ASCD formalizes the decision-making process for clinicians. Clinical decision
    reasoning begins with ASD, where decisions are related to clinical goals. Formally,
    in Figure [1](#S3.F1 "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣
    ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models
    via Argumentation Schemes") we model the derivation of CQs. When the CQs are rejected,
    new ASs are generated as arguments to refute the first proposed AS based on the
    derivation relation. It is worth noting that when a CQ without a derivation relationship
    (e.g., ASD.CQ1, ASSE.CQ1) is rejected, the AS will be refuted by itself (on the
    grounds of the CQ’s answer). We illustrate how to reason using ASCD with an example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 'ASCD 形式化了临床医生的决策过程。临床决策推理始于ASD，其中决策与临床目标相关。正式地，在图 [1](#S3.F1 "Figure 1 ‣ 3
    Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable Clinical
    Decision Reasoning with Large Language Models via Argumentation Schemes")中，我们建模了CQ的推导。当CQ被拒绝时，生成新的AS作为论据来驳斥第一个提出的AS，基于推导关系。值得注意的是，当没有推导关系的CQ（例如，ASD.CQ1，ASSE.CQ1）被拒绝时，AS将基于CQ的回答被自我驳斥。我们通过一个示例来说明如何使用ASCD进行推理：'
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Joey is a 50 year old male patient who has suffered a stroke and has high blood
    pressure. For Joey, the goal is to control his blood pressure;
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Joey是一名50岁的男性患者，曾经中风且有高血压。对于Joey，目标是控制他的血压；
- en: First, we represent the initial ASD reasoning result as $ASD_{1}(joey,control\_blood\_pressure,ACEI)\rightarrow
    ACEI$. Notably, since we set exclusivity between ASD, in order for ASD.CQ1 and
    ASD.CQ3 to be valid, when these two CQs are rejected, that ASD first refutes itself
    (forming a closed loop) and then generates a new ASD.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将初始ASD推理结果表示为 $ASD_{1}(joey,control\_blood\_pressure,ACEI)\rightarrow ACEI$。值得注意的是，由于我们设置了ASD之间的排他性，为了使ASD.CQ1和ASD.CQ3有效，当这两个CQ被拒绝时，该ASD首先自我驳斥（形成一个闭环），然后生成一个新的ASD。
- en: '![Refer to caption](img/f669a371d121b588b822a291d8c84bea.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f669a371d121b588b822a291d8c84bea.png)'
- en: 'Figure 2: An example from the MedQA USMLE dataset, with the entire process
    of ArgMed-Agents reasoning about the clinical problem. Notably, the letters in
    the argumentation framework correspond to the serial numbers of the four generators
    on the right, representing the premises and conclusion generated by that generator.
    In the argumentation framework, the red nodes ($A$) represent arguments in support
    of the beliefs.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：来自MedQA USMLE数据集的示例，展示了ArgMed-Agents对临床问题的整个推理过程。值得注意的是，论证框架中的字母对应右侧四个生成器的序列号，表示该生成器生成的前提和结论。在论证框架中，红色节点（$A$）代表支持信念的论据。
- en: '4 ArgMed-Agents: a Multi-LLM-Agents Framework'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 ArgMed-Agents：一个多LLM-Agents框架
- en: 'In Section [3](#S3 "3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes"), we discussed Argumentation Schemes for clinical decision(ASCD). ASCD
    is a semi-formal reasoning template for clinical decision making by defining the
    logical structure and the reasoning mechanism in the clinical reasoning process.
    However, the clinical decision support systems based on argumentation scheme in
    the past Sassoon et al. ([2021](#bib.bib30)); Qassas et al. ([2015](#bib.bib29))
    have often been implemented through knowledge-based approaches, which rely on
    expert knowledge to build knowledge bases and rule. In this section, we propose
    a multi-agent framework called ArgMed-Agents, which supports the seamless integration
    of prompt strategy designed based on ASCD into agent interactions. Our approach
    enhances LLMs to be able to perform explainable clinical decision reasoning without
    the need for expert involvement in knowledge encoding.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '在章节 [3](#S3 "3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")中，我们讨论了用于临床决策的论证方案（ASCD）。ASCD
    是一个半正式的推理模板，通过定义临床推理过程中的逻辑结构和推理机制来进行临床决策。然而，基于论证方案的临床决策支持系统在过去的Sassoon等（[2021](#bib.bib30)）；Qassas等（[2015](#bib.bib29)）中，通常通过基于知识的方法实现，这些方法依赖于专家知识来构建知识库和规则。在本节中，我们提出了一个名为ArgMed-Agents的多代理框架，它支持基于ASCD设计的提示策略在代理交互中的无缝集成。我们的方法增强了LLMs，使其能够执行可解释的临床决策推理，而不需要专家参与知识编码。'
- en: 4.1 ASCD-based Multi-agent Interaction
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 基于ASCD的多代理交互
- en: 'ArgMed-Agents framework includes three distinct types of LLMs agent:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ArgMed-Agents框架包括三种不同类型的LLM代理：
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Generator(s): Instantiate the AS according to the current situation.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成器：根据当前情况实例化AS。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Verifier: Whenever Generator generates an instantiation of an AS, Verifier
    checks the accuracy of the instantiation of that AS via CQ. When the CQ validation
    is rejected, return to the generator the reason why the CQ rejected, so that the
    generator generates a new AS based on the derivation rules of that CQ. The process
    iterates until no more new AS are generated.'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Verifier: 每当 Generator 生成一个 AS 的实例时，Verifier 通过 CQ 检查该 AS 实例的准确性。当 CQ 验证被拒绝时，将拒绝原因返回给生成器，以便生成器根据
    CQ 的推导规则生成新的 AS。这个过程会迭代，直到不再生成新的 AS。'
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reasoner: A symbolic solver for computational argumentation. At the end of
    the iteration, the arguments presented by the generator constitute a complete
    argumentation framework, and it identifies a subset of coherent and reasonable
    arguments within that argumentation framework.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Reasoner: 一个用于计算论证的符号求解器。在迭代结束时，由生成器提出的论点构成一个完整的论证框架，并在该论证框架中识别出一组连贯且合理的论点。'
- en: 'We convert ASCD into a step-by-step reasoning interaction protocol as a prompt
    strategy and define the interaction behavior between LLM agents based on ASCD
    prompt strategy, which describes the specification of the interaction behavior
    between different types of agents under the ASCD reasoning mechanism. Figure [2](#S3.F2
    "Figure 2 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")
    depicts how ArgMed-Agents interacts. In this example, $Generator_{A}$ would attack
    itself. The Verifier facilitates an iterative process of mutual debate between
    Generators, which forms an argumentation framework that can be solved by the symbolic
    Reasonner. We provide a formal description of the interaction process in Appendix
    A.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将 ASCD 转换为逐步推理交互协议作为提示策略，并基于 ASCD 提示策略定义 LLM 代理之间的交互行为，这描述了在 ASCD 推理机制下不同类型代理之间交互行为的规范。图
    [2](#S3.F2 "Figure 2 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes") 描述了 ArgMed-Agents 的交互方式。在这个例子中，$Generator_{A}$ 会对自己进行攻击。Verifier 促进生成器之间的相互辩论的迭代过程，形成一个可以通过符号
    Reasonner 解决的论证框架。我们在附录 A 中提供了交互过程的正式描述。'
- en: In ArgMed-Agents, we do not expect single generation or single verification
    to be correct. ArgMed-Agents uses generation as a assumption to recursively prompt
    the model with critical questions, identifying conflicting and erroneous arguments
    in an iterative process. Ultimately, such mutually attacking arguments are converted
    into a formal framework that solves for a subset of reasonably coherent arguments
    via Reasoner.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ArgMed-Agents 中，我们不期望单次生成或单次验证是正确的。ArgMed-Agents 使用生成作为假设，通过递归地向模型提出关键问题，识别出矛盾和错误的论点，进行迭代处理。最终，这些相互攻击的论点会被转换成一个正式的框架，通过
    Reasoner 解决出一组合理连贯的论点。
- en: The theoretical motivation for our method stems from non-monotonic logic, logical
    intuition and cognitive clinical. Studies have shown that LLM performs reasonably
    well for simple reasoning, single-step reasoning problems, however, as the number
    of reasoning steps rises, the rate of correct reasoning decreases in a catastrophic
    manner Creswell et al. ([2022](#bib.bib5)). Thus, we consider that LLM is primed
    with rational intuition, but lacks true logical reasoning ability. In light of
    this, ASCD Prompt Stratygy guides LLM in a recursive form to generate a series
    of casual reasoning steps as a tentative conclusion, with any further evidence
    withdrawing their conclusion. The process ultimately leads to a directed graph
    representing the disputed relationships. In addition this, agents with different
    LLMs roles within ArgMed-Agents interact collaboratively with each other in a
    formalized process consistent with clinical reasoning (i.e., following the ASCD
    prompt strategy). This design not only facilitates LLMs to engage in clinical
    reasoning in a critical-thinking manner, which in turn maintains a cognitive processes
    consistent with clinicians to improve the explainability of decisions, but also
    allows for the effective highlighting of some implicit knowledge in LLMs that
    cannot be readily accessed through traditional prompts.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们方法的理论动机来源于非单调逻辑、逻辑直觉和认知临床。研究表明，LLM在简单推理、单步推理问题上表现相对较好，然而，随着推理步骤数量的增加，正确推理的比例会以灾难性的方式下降（Creswell
    et al. ([2022](#bib.bib5))）。因此，我们认为LLM具备理性直觉，但缺乏真正的逻辑推理能力。鉴于此，ASCD提示策略以递归形式指导LLM生成一系列因果推理步骤作为暂定结论，任何进一步的证据都会撤回其结论。该过程最终形成一个表示争议关系的有向图。此外，在ArgMed-Agents中扮演不同角色的代理会以符合临床推理的正式化过程（即，遵循ASCD提示策略）相互协作。这一设计不仅有助于LLM以批判性思维方式参与临床推理，从而保持与临床医生一致的认知过程，提高决策的可解释性，而且还能够有效突出LLM中一些通过传统提示无法直接访问的隐性知识。
- en: 4.2 Explainable Argumentative Reasoning
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 可解释的论证推理
- en: ArgMed-Agent obtains a complete argument graph by iterating through the ASCD
    Prompt Strategy. In this section, we describe how Reasoner reasons and explains
    decisions through these arguments. First, we map the reasoning results of ASCD
    to the AA framework.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ArgMed-Agent通过迭代ASCD提示策略获得一个完整的论证图。在这一部分，我们描述Reasoner如何通过这些论证进行推理和解释决策。首先，我们将ASCD的推理结果映射到AA框架中。
- en: Definition 1.
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 1.
- en: 'An AA framework for ASCD is a pair $\langle\mathcal{A},\mathcal{R}\rangle$
    such that:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ASCD的AA框架是一个对偶$\langle\mathcal{A},\mathcal{R}\rangle$，满足以下条件：
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists arg=\langle P,c,V\rangle\in\mathcal{A}$ is constituted by the argumentation
    schemes.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists arg=\langle P,c,V\rangle\in\mathcal{A}$由论证方案构成。
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\mathcal{A}=Args_{d}(\mathcal{A})\cup Args_{b}(\mathcal{A})$.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\mathcal{A}=Args_{d}(\mathcal{A})\cup Args_{b}(\mathcal{A})$。
- en: 'In Definition [1](#Thmdefinition1 "Definition 1\. ‣ 4.2 Explainable Argumentative
    Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes"),
    arguments in support of decisions $Args_{d}(\mathcal{A})$ correspond to ASSE and
    ASBD in the argumentation scheme. These two types of arguments play different
    roles; arguments in support of decisions build on beliefs and goals and try to
    justify choices, while arguments in support of beliefs always try to undermine
    decision arguments. Therefore, based on the modeling of ASCD, we make the following
    setup for the attack relation between these two types of arguments: first, arguments
    in support of different decisions are in conflict with each other, which is consistent
    with our previous description of decisions being exclusive in ASCD. Second, arguments
    in support of decisions are not allowed to attack arguments in support of beliefs,
    which is dictated by the modeling of ASCD, as can be seen in Figure [1](#S3.F1
    "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes"),
    where ASSE and ASBD are always trying to disprove ASD, while the converse does
    not work. Formalized as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '在定义 [1](#Thmdefinition1 "Definition 1\. ‣ 4.2 Explainable Argumentative Reasoning
    ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable Clinical
    Decision Reasoning with Large Language Models via Argumentation Schemes") 中，支持决策的论据
    $Args_{d}(\mathcal{A})$ 对应于论证方案中的ASSE和ASBD。这两种类型的论据扮演着不同的角色：支持决策的论据建立在信念和目标之上，试图证明选择的合理性，而支持信念的论据则总是试图削弱决策论据。因此，基于ASCD的建模，我们对这两种论据之间的攻击关系做如下设置：首先，支持不同决策的论据彼此冲突，这与我们之前描述的ASCD中决策的排他性一致。其次，支持决策的论据不允许攻击支持信念的论据，这由ASCD的建模决定，如图
    [1](#S3.F1 "Figure 1 ‣ 3 Argumentation Scheme for Clinial Decision ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes") 中所示，其中ASSE和ASBD总是试图反驳ASD，而反之则不成立。形式化为：'
- en: Definition 2.
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义2。
- en: 'Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$ such
    that:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个AA框架用于ASCD $\langle\mathcal{A},\mathcal{R}\rangle$，其中：
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\forall arg_{1},arg_{2}$
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\forall arg_{1},arg_{2}$
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\nexists(arg_{1},arg_{2})$.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\nexists(arg_{1},arg_{2})$。
- en: Next, we use the preferred semantics in the AA framework to illustrate how the
    Reasoner Agent selects the set of possible admissible arguments to support clinical
    decision.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用AA框架中的首选语义来说明Reasoner Agent如何选择可能的可接受论据集以支持临床决策。
- en: Definition 3.
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义3。
- en: Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个AA框架用于ASCD $\langle\mathcal{A},\mathcal{R}\rangle$。
- en: Example 1.
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 示例1。
- en: An AA framework for ASCD is given below such that $Args_{d}(\mathcal{A})=\{A,B,C\}$
    are optional because they are supported by preferred extension.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个AA框架用于ASCD，其如下所示，其中$Args_{d}(\mathcal{A})=\{A,B,C\}$是可选的，因为它们由首选扩展支持。
- en: '<svg id="S4.SS2.p4.pic1" class="ltx_picture" height="254.32" overflow="visible"
    version="1.1" width="357.03"><g transform="translate(0,254.32) matrix(1 0 0 -1
    0 0) translate(-152.35,0) translate(0,225.48)"><g stroke="#000000" fill="#000000"
    stroke-width="0.75pt"><g transform="matrix(1.0 0.0 0.0 1.0 205.75 -111.3)" fill="#000000"
    stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 87.54)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 92.38)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="20.56"
    height="16.6" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">A</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 156.96 -220.87)" fill="#000000" stroke="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 171.82)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.66)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="20.42" height="16.6"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">B</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 252.62 -220.87)" fill="#000000" stroke="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 171.82)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.66)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="25.49" height="16.6"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">C</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 240.53 -36.67)" fill="#000000" stroke="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 30.13)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 34.97)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><foreignobject width="17.75" height="16.6" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">E</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 172.98 -35.18)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 28.98)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 33.82)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="17.75" height="16.6" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">D</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 306.98 -197.58)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 165.08)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 169.91)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="197.79" height="113.46" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Admissible Sets: $\displaystyle\{B,D,E\},$</foreignobject></g></g></g></g></g></g></svg>'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg id="S4.SS2.p4.pic1" class="ltx_picture" height="254.32" overflow="visible"
    version="1.1" width="357.03"><g transform="translate(0,254.32) matrix(1 0 0 -1
    0 0) translate(-152.35,0) translate(0,225.48)"><g stroke="#000000" fill="#000000"
    stroke-width="0.75pt"><g transform="matrix(1.0 0.0 0.0 1.0 205.75 -111.3)" fill="#000000"
    stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 87.54)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 92.38)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="20.56"
    height="16.6" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">A</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 156.96 -220.87)" fill="#000000" stroke="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 171.82)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.66)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="20.42" height="16.6"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">B</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 252.62 -220.87)" fill="#000000" stroke="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 171.82)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.66)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="25.49" height="16.6"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">C</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 240.53 -36.67)" fill="#000000" stroke="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 30.13)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 34.97)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><foreignobject width="17.75" height="16.6" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">E</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 172.98 -35.18)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 28.98)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 33.82)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="17.75" height="16.6" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">D</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 306.98 -197.58)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 165.08)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 169.91)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="197.79" height="113.46" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">可接受的集合: $\displaystyle\{B,D,E\},$</foreignobject></g></g></g></g></g></g></svg>'
- en: In this regard, we present a proposition to justify the Reasoner agent’s use
    of preferred semantics for decision making.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，我们提出一个命题来证明 Reasoner 代理使用首选语义进行决策的合理性。
- en: Proposition 1.
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 命题 1。
- en: Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$ where,
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个用于 ASCD 的 AA 框架 $\langle\mathcal{A},\mathcal{R}\rangle$，其中，
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists a\in Args_{d}(\mathcal{A})$
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists a\in Args_{d}(\mathcal{A})$
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $\exists a\in Args_{d}(\mathcal{E})$.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\exists a\in Args_{d}(\mathcal{E})$。
- en: 'Proposition [1](#Thmproposition1 "Proposition 1\. ‣ 4.2 Explainable Argumentative
    Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")
    states that using preferred semantics on the AA framework for ASCD always selects
    extensions that contain the only acceptable decision, which is consistent with
    our expected reasoning. Meanwhile, arguments from $Args_{b}(\mathcal{E})$ Fan
    and Toni ([2015](#bib.bib12)). The proof of the proposition proceeds as follows:
    We first prove that there will be only one decision in the preferred extension.
    According to Definition [2](#Thmdefinition2 "Definition 2\. ‣ 4.2 Explainable
    Argumentative Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes"), we know that decisions are exclusive, so different decisions do not
    appear in the same admissible set. Secondly, we prove that the preferred extension
    will always contain a argument in support of decision. According to the modeling
    of ASCD as well as Definition [2](#Thmdefinition2 "Definition 2\. ‣ 4.2 Explainable
    Argumentative Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents:
    Explainable Clinical Decision Reasoning with Large Language Models via Argumentation
    Schemes"), it can be seen that arguments in support of decision (ASD) are built
    on top of arguments in support of beliefs (ASSE and ASBD), i.e., the inclusion
    of ASD arguments does not lead to the ASSE and ASBD arguments becoming unacceptable.
    Therefore, the set is maximized when the acceptable set includes pro-decision
    arguments.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '命题 [1](#Thmproposition1 "Proposition 1\. ‣ 4.2 Explainable Argumentative Reasoning
    ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable Clinical
    Decision Reasoning with Large Language Models via Argumentation Schemes") 说明在
    ASCD 的 AA 框架中使用首选语义总是选择包含唯一可接受决策的扩展，这与我们预期的推理一致。同时，来自 $Args_{b}(\mathcal{E})$
    的论点 Fan 和 Toni ([2015](#bib.bib12))。命题的证明过程如下：我们首先证明在首选扩展中只会有一个决策。根据定义 [2](#Thmdefinition2
    "Definition 2\. ‣ 4.2 Explainable Argumentative Reasoning ‣ 4 ArgMed-Agents: a
    Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning
    with Large Language Models via Argumentation Schemes")，我们知道决策是排他的，因此不同的决策不会出现在同一个可接受的集合中。其次，我们证明首选扩展总是会包含一个支持决策的论点。根据
    ASCD 的建模以及定义 [2](#Thmdefinition2 "Definition 2\. ‣ 4.2 Explainable Argumentative
    Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")，可以看出，支持决策的论点（ASD）是建立在支持信念的论点（ASSE
    和 ASBD）之上的，即 ASD 论点的包含不会导致 ASSE 和 ASBD 论点变得不可接受。因此，当可接受的集合包括支持决策的论点时，该集合是最大化的。'
- en: Definition 4.
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 4。
- en: Given an AA framework for ASCD $\langle\mathcal{A},\mathcal{R}\rangle$.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个用于 ASCD 的 AA 框架 $\langle\mathcal{A},\mathcal{R}\rangle$。
- en: 'Clinical reasoning errors are discussed in Tang et al. ([2024](#bib.bib35)).
    They consider that most clinical reasoning errors in LLMs are due to confusion
    about domain knowledge. On the other hand, research by Singhal et al. ([2022](#bib.bib33))
    points out that LLMs may produce compelling misinformation about medical treatment,
    so it is crucial to recognize this illusion, which is difficult for humans to
    detect. For this purpose, we define the relevant mechanisms for identifying clinical
    reasoning errors in Reasoner as follows: When any decision in the AA framework
    is not accepted, we consider there are errors in the reasoning by ArgMed-Agents.
    This mechanism assists ArgMed-Agents in identifying the capability boundaries
    of LLMs when their knowledge reserves are insufficient to address certain issues.This
    helps ArgMed-Agents avoid the risks associated with adopting erroneous decisions
    and achieving more robust and safe clinical reasoning.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 临床推理错误在 Tang 等人 ([2024](#bib.bib35)) 中讨论。他们认为 LLM 中的大多数临床推理错误源于对领域知识的混淆。另一方面，Singhal
    等人 ([2022](#bib.bib33)) 的研究指出，LLM 可能产生关于医疗治疗的令人信服的虚假信息，因此识别这种幻觉至关重要，而这对人类来说很难检测。为此，我们在
    Reasoner 中定义了识别临床推理错误的相关机制：当 AA 框架中的任何决策未被接受时，我们认为 ArgMed-Agents 的推理存在错误。该机制帮助
    ArgMed-Agents 识别 LLM 在知识储备不足时处理某些问题的能力边界。这有助于 ArgMed-Agents 避免采用错误决策所带来的风险，从而实现更强健和安全的临床推理。
- en: 5 Experiments
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: In this section, we demonstrate the potential of ArgMed-Agents in clinical decision
    reasoning by evaluating the accuracy and explainability.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过评估 ArgMed-Agents 在临床决策推理中的准确性和解释性，展示其潜力。
- en: 'We implemented Generator and Verifier in ArgMed-Agents using the APIs GPT-3.5-turbo
    and GPT-4 provided by OpenAI OpenAI ([2023](#bib.bib25)), and according to our
    setup, the LLM Agents are implemented with the same LLM and different few-shot
    prompts. Each agent is configured with specific parameters: the temperature is
    set to 0.0, as well as a dialogue limit of 4, indicating the maximum number of
    decisions allowed for ArgMed-Agents to generate, which is to prevent the agents
    from getting into loops with each other. On the other hand, we using python3 to
    implemente a symbolic solver of abstract argumentation framework as Reasoner.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 ArgMed-Agents 中实现了 Generator 和 Verifier，使用了 OpenAI 提供的 GPT-3.5-turbo 和 GPT-4
    APIs ([2023](#bib.bib25))。根据我们的设置，LLM Agents 使用相同的 LLM 和不同的少样本提示进行实现。每个代理配置了特定参数：温度设置为
    0.0，同时对话限制为 4，表示 ArgMed-Agents 生成的决策次数上限，以防止代理之间出现循环。同时，我们使用 python3 实现了抽象论证框架的符号求解器作为
    Reasoner。
- en: 5.1 Accuracy
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 准确性
- en: 'The following two datasets were used to assess the accuracy of ArgMed-Agents
    clinical reasoning:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两个数据集用于评估 ArgMed-Agents 临床推理的准确性：
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: MedQA Jin et al. ([2020](#bib.bib17)):Answering multiple-choice questions derived
    from the United States Medical License Exams (USMLE). This dataset is sourced
    from official medical board exams and encompasses questions in English, simplified
    Chinese, and traditional Chinese. The total question counts for each language
    are 12,723, 34,251, and 14,123, respectively.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MedQA Jin 等人 ([2020](#bib.bib17))：回答源自美国医学执照考试（USMLE）的多项选择题。该数据集来自官方医学考试，涵盖了英语、简体中文和繁体中文的问题。每种语言的问题总数分别为
    12,723、34,251 和 14,123。
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'PubMedQA Jin et al. ([2019](#bib.bib16)): A biomedical question and answer
    (QA) dataset collected from PubMed abstracts. The task of PubMedQA is to answer
    yes/no/maybe research questions using the corresponding abstracts (e.g., Do preoperative
    statins reduce atrial fibrillation after coronary artery bypass graft surgery?).'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PubMedQA Jin 等人 ([2019](#bib.bib16))：一个从 PubMed 摘要中收集的生物医学问答（QA）数据集。PubMedQA
    的任务是使用相关摘要回答是/否/也许的研究问题（例如：术前使用他汀类药物是否能减少冠状动脉旁路移植手术后的心房颤动？）。
- en: We randomly selected 300 examples in each dataset for our experiments. We set
    the baseline in our experiments to compare with gpt direct generation and Chain
    of Thought(CoT) Wei et al. ([2023](#bib.bib39)). It is worth noting that we focussed
    on evaluating the performance of ArgMed-Agents on clinical decision reasoning,
    however, there were some biomedical general knowledge quiz-type questions in MedQA
    and PubMedQA, and so we intentionally excluded this part of the questioning in
    selecting the example.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个数据集中随机选择了 300 个示例进行实验。我们在实验中设置了基线，以便与 gpt 直接生成和链式思维（CoT）进行比较（Wei 等人 [2023](#bib.bib39)）。值得注意的是，我们专注于评估
    ArgMed-Agents 在临床决策推理中的表现，但 MedQA 和 PubMedQA 中存在一些生物医学常识问答类型的问题，因此我们在选择示例时有意排除了这部分问题。
- en: '| Model | Method | MedQA | PubMedQA |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 方法 | MedQA | PubMedQA |'
- en: '|  | Direct | 52.7 | 68.4 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | Direct | 52.7 | 68.4 |'
- en: '| GPT-3.5-turbo | CoT | 48.0 | 71.5 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | CoT | 48.0 | 71.5 |'
- en: '|  | ArgMed-Agents | 62.1 | 78.3 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | ArgMed-Agents | 62.1 | 78.3 |'
- en: '|  | Direct | 67.8 | 72.9 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | Direct | 67.8 | 72.9 |'
- en: '| GPT-4 | CoT | 71.4 | 77.2 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | CoT | 71.4 | 77.2 |'
- en: '|  | ArgMed-Agents | 83.3 | 81.6 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|  | ArgMed-Agents | 83.3 | 81.6 |'
- en: 'Table 1: Results of the accuracy of various clinical decision reasoning methods
    on MedQA and PubMedQA datasets.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：各种临床决策推理方法在 MedQA 和 PubMedQA 数据集上的准确性结果。
- en: 'Table [1](#S5.T1 "Table 1 ‣ 5.1 Accuracy ‣ 5 Experiments ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes")
    shows the accuracy results of MedQA and PubMedQA. We compared ArgMed-Agents to
    several baselines in direct generation and CoT settings. Notably, both GPT-3.5-turbo
    and GPT4 models showed that our proposed ArgMed-Agents improved accuracy on a
    clinical decision reasoning task compared to a baseline such as CoT. This result
    demonstrates the effectiveness of ArgMed-Agents to enhance the clinical reasoning
    performance of LLMs. Interestingly, after we repeated the experiment several times,
    we found that the introduction of CoT sometimes leads to a surprising drop in
    performance. The reason for this may be that when LLMs experience hallucinatory
    phenomena, the use of CoT will amplify such hallucinations indefinitely. In contrast,
    our approach of using mutual argumentation iterations between multiple agents
    effectively mitigates this problem. We analysed the data from our experiments
    and found that each AS’s CQ1 (i.e., asking the Verifier whether there is evidence
    to support the argument made by the Generator) acts as a hallucination detector
    in the reasoning process. On the other hand, we analysed the examples in which
    both Direct Generation, CoT and ArgMed-Agents reasoned wrongly. We found that
    ArgMed-Agents can report 76% of errors in these examples according to Reasoner’s
    definition [4](#Thmdefinition4 "Definition 4\. ‣ 4.2 Explainable Argumentative
    Reasoning ‣ 4 ArgMed-Agents: a Multi-LLM-Agents Framework ‣ ArgMed-Agents: Explainable
    Clinical Decision Reasoning with Large Language Models via Argumentation Schemes").
    This provides initial evidence that ArgMed-Agents not only has higher accuracy
    compared to baseline, but also that it is safer for clinical decision reasoning.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](#S5.T1 "表 1 ‣ 5.1 准确性 ‣ 5 实验 ‣ ArgMed-Agents: 通过论证方案进行的大型语言模型的可解释临床决策推理")
    显示了 MedQA 和 PubMedQA 的准确性结果。我们将 ArgMed-Agents 与几个基线模型在直接生成和 CoT 设置下进行了比较。值得注意的是，GPT-3.5-turbo
    和 GPT4 模型均表明，我们提出的 ArgMed-Agents 在临床决策推理任务中相较于基线（如 CoT）提高了准确性。这个结果展示了 ArgMed-Agents
    在提升大型语言模型临床推理性能方面的有效性。有趣的是，我们在多次重复实验后发现，引入 CoT 有时会导致性能的意外下降。其原因可能是，当大型语言模型经历幻觉现象时，使用
    CoT 会无限放大这种幻觉。相比之下，我们的多代理互相论证迭代的方法有效地缓解了这个问题。我们分析了实验数据，发现每个 AS 的 CQ1（即询问验证者是否有证据支持生成者提出的论点）在推理过程中充当了幻觉检测器。另一方面，我们分析了直接生成、CoT
    和 ArgMed-Agents 错误推理的示例。我们发现，根据 Reasoner 的定义，[4](#Thmdefinition4 "定义 4\. ‣ 4.2
    可解释的论证推理 ‣ 4 ArgMed-Agents: 多大型语言模型代理框架 ‣ ArgMed-Agents: 通过论证方案进行的大型语言模型的可解释临床决策推理")，ArgMed-Agents
    可以报告这些示例中的 76% 错误。这提供了初步证据，表明 ArgMed-Agents 不仅相比于基线具有更高的准确性，而且在临床决策推理中更安全。'
- en: 5.2 Human Evaluation for Explainability
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 可解释性的人工评估
- en: 'The main focus of Explainable AI (XAI) is usually the reasoning behind decisions
    or predictions made by AI that become more understandable and transparent. In
    the context of artificial intelligence, Explainability is defined as follows ISO
    ([2020](#bib.bib15)):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释人工智能（XAI）的主要关注点通常是 AI 做出的决策或预测背后的推理，使其变得更易理解和透明。在人工智能的背景下，解释性定义如下 ISO ([2020](#bib.bib15))：
- en: …level of understanding how the AI-based system came up with a given result.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: …了解基于 AI 的系统如何得出给定结果的程度。
- en: 'Based on this criterion, we define two measures of LLMs’ explanability:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这一标准，我们定义了 LLM 解释性的两个测量指标：
- en: •
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'predictability(Pre.): Can the explanations given by LLMs help users predict
    LLM decisions?'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可预测性 (Pre.)：LLM 提供的解释是否能帮助用户预测 LLM 的决策？
- en: •
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'proof-based traceability(Tra.): Can the model reason about the correct decision
    based on the correct path of inference (i.e. does the path of inference as an
    explanation have relevance to the LLM’s decision)?'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 证明基础可追溯性 (Tra.)：模型能否根据正确的推理路径推理出正确的决策（即推理路径作为解释是否与 LLM 的决策相关）？
- en: '| Method | Pre. | Tra. | $\%$ Arg. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 可预测性 (Pre.) | 证明基础可追溯性 (Tra.) | $\%$ 论证 |'
- en: '| CoT | 0.63 | 2.8 | 59.5$\%$ |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| CoT | 0.63 | 2.8 | 59.5$\%$ |'
- en: '| ArgMed-Agents | 0.91 | 4.2 | 87.5$\%$ |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| ArgMed-Agents | 0.91 | 4.2 | 87.5$\%$ |'
- en: 'Table 2: Human evaluation result on 20 examples.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：20 个示例的人类评估结果。
- en: 'For the evaluation of predictability, our experimental setup is as follows:
    we recorded the inputs and the reasoning process (e.g., the complete dialogue
    between Generator and Verifier in ArgMed-Agents and the corresponding argumentation
    framework). We invited 50 undergraduate and graduate students in medical-related
    disciplines to answer questions given only the inputs to the LLMs as well as the
    explanations (four questions were distributed to each individual), and counted
    to what extent they were able to predict the decisions of the LLMs.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估可预测性，我们的实验设置如下：我们记录了输入和推理过程（例如，ArgMed-Agents 中生成器和验证器之间的完整对话以及相应的论证框架）。我们邀请了
    50 名医学相关学科的本科生和研究生，仅凭 LLM 的输入和解释回答问题（每人分发了四个问题），并统计了他们预测 LLM 决策的能力。
- en: 'Our team has produced a fully functional knowledge-based clinical decision
    support system at an early stage that can be used to assist in treatment decisions
    for complex diseases such as cancer, neurological disorders, and infectious diseases.
    Figure [3](#S5.F3 "Figure 3 ‣ 5.2 Human Evaluation for Explainability ‣ 5 Experiments
    ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models
    via Argumentation Schemes") illustrates this knowledge-based CDSS, consisting
    of computer-interpretable guidelines in the form of Resource Description Framework
    (RDF) Klyne and Carroll ([2004](#bib.bib20)) and the corresponding inference engine.
    We use the knowledge-based CDSS’s process of performing reasoning on the 20 examples
    in MedQA as a logical criterion for measuring the proof-based traceability of
    LLMs. We manually evaluated the consistency of ArgMed-Agents’ reasoning paths
    with logical criteria and the relevance of explanations to decision making, scoring
    each example on a scale of one to five. CoT performance was also used as a comparison.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的团队在早期阶段开发了一个完全功能的知识基础临床决策支持系统，可用于协助复杂疾病如癌症、神经系统疾病和传染病的治疗决策。图 [3](#S5.F3 "图
    3 ‣ 5.2 人工评估解释性 ‣ 5 实验 ‣ ArgMed-Agents：通过论证方案进行的可解释临床决策推理") 说明了这个知识基础 CDSS，包括以资源描述框架（RDF）Klyne
    和 Carroll ([2004](#bib.bib20)) 形式呈现的计算机可解释的指南和相应的推理引擎。我们使用知识基础 CDSS 对 MedQA 中
    20 个示例进行推理的过程作为衡量 LLM 证明基础可追溯性的逻辑标准。我们手动评估了 ArgMed-Agents 推理路径与逻辑标准的一致性以及解释与决策的相关性，按一到五的评分标准对每个示例进行评分。CoT
    性能也用作比较。
- en: '![Refer to caption](img/f0056aa6c5c303ca1364daad6e45389f.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f0056aa6c303ca1364daad6e45389f.png)'
- en: 'Figure 3: A screenshot of the knowledge-based CDSS for diagnosing depression,
    where prismatic nodes represent enquiry, circular nodes represent decision, and
    square nodes represent action.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：用于诊断抑郁症的知识基础 CDSS 的屏幕截图，其中棱镜节点表示查询，圆形节点表示决策，方形节点表示行动。
- en: 'In Table [2](#S5.T2 "Table 2 ‣ 5.2 Human Evaluation for Explainability ‣ 5
    Experiments ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning with Large
    Language Models via Argumentation Schemes"), it is shown that ArgMed-Agents outperforms
    CoT in both measures of explainability. Specifically, in the experiment evaluating
    predictability, 50 participants answered the question a total of 200 times, of
    which participants succeeded 91 out of 100 times in predicting ArgMed-Agents decisions,
    compared to 63/100 times in predicting the CoT. On the other hand, most of the
    reasoning nodes of the knowledge-based CDSS can be found to correspond in the
    reasoning process of ArgMed-Agents, whereas the reasoning process of the CoT method
    to arrive at an answer is often logically incomplete. Interestingly, we found
    that the reasoning of the knowledge-based CDSS on many examples can be regarded
    as a reasoning subgraph of ArgMed-Agents, probably because ArgMed-Agents traverses
    all the reasoning paths in a randomly generated manner, and thus the reasoning
    graph includes not only the reasoning paths of the correct decisions, but also
    the explanations of the incorrect decisions.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '在表格[2](#S5.T2 "Table 2 ‣ 5.2 Human Evaluation for Explainability ‣ 5 Experiments
    ‣ ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models
    via Argumentation Schemes")中，显示了ArgMed-Agents在解释性两个指标上优于CoT。具体来说，在评估预测能力的实验中，50名参与者共回答了200次问题，其中参与者在预测ArgMed-Agents的决策时成功了91次（100次中），而在预测CoT时成功了63次（100次中）。另一方面，大多数基于知识的CDSS的推理节点可以在ArgMed-Agents的推理过程中找到相应部分，而CoT方法得出答案的推理过程往往在逻辑上不完整。有趣的是，我们发现基于知识的CDSS在许多例子中的推理可以被视为ArgMed-Agents的推理子图，可能是因为ArgMed-Agents以随机生成的方式遍历所有推理路径，从而推理图不仅包括正确决策的推理路径，还包括错误决策的解释。'
- en: 6 Related Work
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: 6.1 LLM-based Clinical Decision Support System
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 基于LLM的临床决策支持系统
- en: Extensive research highlights the potential for LLMs to be used in medicine
    Bao et al. ([2023](#bib.bib2)); Nori et al. ([2023](#bib.bib23)); Jin et al. ([2023](#bib.bib18)).
    However, LLMs still struggle to make safe and trustworthy decisions when they
    encounter clinical decisions that require complex medical expertise and good reasoning
    skills Singhal et al. ([2022](#bib.bib33)). Therefore, much work has begun to
    focus on ways to enhance clinical reasoning in LLMs. Tang et al. ([2024](#bib.bib35))
    proposes a Multi-disciplinary Collaboration (MC) framework that utilises LLM-based
    agents in a role-playing environment that engages in collaborative multi-round
    discussions until consensus is reached. Despite the results achieved, the method
    is unable to formalise the iterative results in such a way as to enhance the inference
    performance of the LLM using inference tools. Savage et al. ([2024](#bib.bib31))
    proposes a method that uses diagnostic reasoning prompts to improve clinical reasoning
    abilities and interpretability in LLM. However, their approach does not focus
    on critical reasoning in clinical decision-making, which allows LLM to generate
    explanations of why one decision is ”good” but not why others were not chosen.
    In addition to this, the work such as Singhal et al. ([2023](#bib.bib34)); Li
    et al. ([2023](#bib.bib21)) fine-tuned LLMs using extensive datasets collected
    from the medical and biomedical literature. Unlike our approach, ours focuses
    more on exploiting the latent medical knowledge inherent in LLMs to improve their
    reasoning ability in a training-free environment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 广泛的研究突显了LLMs在医学中应用的潜力 Bao et al. ([2023](#bib.bib2)); Nori et al. ([2023](#bib.bib23));
    Jin et al. ([2023](#bib.bib18))。然而，LLMs在遇到需要复杂医学专业知识和良好推理技能的临床决策时，仍然难以做出安全且可信的决定
    Singhal et al. ([2022](#bib.bib33))。因此，许多工作已开始集中在提升LLMs临床推理能力的方法上。Tang et al.
    ([2024](#bib.bib35))提出了一个多学科合作（MC）框架，该框架利用基于LLM的代理在角色扮演环境中进行协作性多轮讨论，直到达成共识。尽管取得了成果，但该方法无法以增强推理性能的方式形式化迭代结果。Savage
    et al. ([2024](#bib.bib31))提出了一种方法，通过使用诊断推理提示来改善LLM的临床推理能力和可解释性。然而，他们的方法并未关注临床决策中的关键推理，使LLM能够生成解释为什么一个决策是“好”的，但不解释为何其他决策未被选择。此外，像Singhal
    et al. ([2023](#bib.bib34)); Li et al. ([2023](#bib.bib21))这样的工作通过使用从医学和生物医学文献中收集的大量数据集对LLMs进行微调。与我们的方法不同，我们的方法更关注利用LLMs固有的潜在医学知识，以在无需训练的环境中提高其推理能力。
- en: 6.2 Logical Reasoning with LLMs
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 与LLMs的逻辑推理
- en: An extensive body of research has been dedicated to utilizing symbolic systems
    to augment reasoning, which includes code environments, knowledge graphs, and
    formal theorem provers Pan et al. ([2023](#bib.bib27), [2024](#bib.bib28)); Wu
    et al. ([2023](#bib.bib40)). In the study by Jung et al. Jung et al. ([2022](#bib.bib19)),
    reasoning is constructed as a satisfiability problem of its logical relations
    through inverse causal reasoning, with consistent reasoning enhanced using SAT
    solvers to improve the reasoning abilities of Large Language Models (LLMs). Zhang
    et al.’s work Zhang et al. ([2023](#bib.bib44)) employs cumulative reasoning to
    decompose tasks into smaller components, thereby simplifying the problem-solving
    process and enhancing efficiency. Xiu et al. Xiu et al. ([2022](#bib.bib42)) delve
    into the non-monotonic reasoning capabilities of LLMs. However, despite the initial
    promise exhibited by LLMs, their performance falls short in terms of generalization
    and proof-based traceability, with a significant decline in performance observed
    with increasing depth of reasoning. In line with our study, some recent works
    have started to explore the potential for argumentative reasoning in LLMs Chen
    et al. ([2023](#bib.bib4)), aiming to enhance LLMs argumentative reasoning abilities
    de Wynter and Yuan ([2023](#bib.bib7)); Castagna et al. ([2024](#bib.bib3)).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 大量研究致力于利用符号系统来增强推理，包括代码环境、知识图谱和形式化定理证明器 Pan et al. ([2023](#bib.bib27), [2024](#bib.bib28));
    Wu et al. ([2023](#bib.bib40))。Jung et al. 的研究 Jung et al. ([2022](#bib.bib19))
    将推理构建为其逻辑关系的可满足性问题，通过逆向因果推理，利用SAT求解器增强一致推理，以提高大语言模型（LLMs）的推理能力。Zhang et al. 的工作
    Zhang et al. ([2023](#bib.bib44)) 采用累积推理将任务分解为更小的组件，从而简化问题解决过程并提高效率。Xiu et al.
    Xiu et al. ([2022](#bib.bib42)) 深入研究了LLMs的非单调推理能力。然而，尽管LLMs初期展现了潜力，但其性能在泛化和基于证明的可追溯性方面仍然不尽如人意，随着推理深度的增加，性能显著下降。与我们的研究一致，一些近期的工作已开始探索LLMs中的论证推理潜力
    Chen et al. ([2023](#bib.bib4))，旨在提升LLMs的论证推理能力 de Wynter 和 Yuan ([2023](#bib.bib7));
    Castagna et al. ([2024](#bib.bib3))。
- en: 7 Conclusion
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: In this work, We propose a novel medical multi-agent interaction framework called
    ArgMed-Agents, which inspires agents of different roles to iterate through argumentation
    and critical questioning, systematically generating an abstract argumentation
    framework. Then, using a Reasoner agent to identify a set of reasonable and coherent
    arguments in this framework as decision support. The experimental results indicate
    that, compared to different baselines, using ArgMed-Agent for clinical decision-making
    reasoning achieves greater accuracy and provides inherent explanations for its
    inferences.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了一种新颖的医学多智能体交互框架，称为ArgMed-Agents，旨在激励不同角色的智能体通过论证和批判性提问进行迭代，从而系统地生成一个抽象的论证框架。随后，利用Reasoner智能体在该框架中识别一组合理且连贯的论据作为决策支持。实验结果表明，与不同基准相比，使用ArgMed-Agent进行临床决策推理能够实现更高的准确性，并为其推断提供内在解释。
- en: Despite the success of ArgMed-Agents, there are still some limitations. In particular,
    abstract arguments alone may struggle with clinical reasoning tasks that numerical
    calculations or probabilistic reasoning. Therefore, future research will focus
    on enhancing the capabilities of ArgMed-Agents to address these challenges. One
    promising avenue involves exploring the integration of value-based argumentation
    or probabilistic argumentation techniques. Our goal is to provide healthcare professionals
    with powerful tools to enhance their decision-making process and ultimately improve
    patient outcomes.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ArgMed-Agents取得了成功，但仍然存在一些局限性。特别是，仅凭抽象论据可能在处理需要数值计算或概率推理的临床推理任务时遇到困难。因此，未来的研究将集中在增强ArgMed-Agents的能力，以应对这些挑战。一条有前景的途径是探索基于价值的论证或概率论证技术的整合。我们的目标是为医疗专业人员提供强大的工具，以增强其决策过程，并最终改善患者结果。
- en: Ethical Statement
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: There are no ethical issues.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 没有伦理问题。
- en: References
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Ayers et al. [2023] John W. Ayers, Adam Poliak, Mark Dredze, Eric C. Leas, Zechariah
    Zhu, Jessica B. Kelley, Dennis J. Faix, Aaron M. Goodman, Christopher A. Longhurst,
    Michael Hogarth, and Davey M. Smith. Comparing Physician and Artificial Intelligence
    Chatbot Responses to Patient Questions Posted to a Public Social Media Forum.
    JAMA Internal Medicine, 183(6):589–596, 06 2023.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ayers et al. [2023] John W. Ayers, Adam Poliak, Mark Dredze, Eric C. Leas, Zechariah
    Zhu, Jessica B. Kelley, Dennis J. Faix, Aaron M. Goodman, Christopher A. Longhurst,
    Michael Hogarth, 和 Davey M. Smith. 比较医生与人工智能聊天机器人对患者在公共社交媒体论坛上提问的回答。JAMA 内科医学,
    183(6):589–596, 2023年6月。
- en: 'Bao et al. [2023] Zhijie Bao, Wei Chen, Shengze Xiao, Kuang Ren, Jiaao Wu,
    Cheng Zhong, Jiajie Peng, Xuanjing Huang, and Zhongyu Wei. Disc-medllm: Bridging
    general large language models and real-world medical consultation, 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bao et al. [2023] Zhijie Bao, Wei Chen, Shengze Xiao, Kuang Ren, Jiaao Wu,
    Cheng Zhong, Jiajie Peng, Xuanjing Huang, 和 Zhongyu Wei. Disc-medllm: 桥接通用大型语言模型与现实世界医疗咨询,
    2023。'
- en: 'Castagna et al. [2024] Federico Castagna, Nadin Kokciyan, Isabel Sassoon, Simon
    Parsons, and Elizabeth Sklar. Computational argumentation-based chatbots: a survey,
    2024.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Castagna et al. [2024] Federico Castagna, Nadin Kokciyan, Isabel Sassoon, Simon
    Parsons, 和 Elizabeth Sklar. 基于计算论证的聊天机器人：一项综述, 2024。
- en: Chen et al. [2023] Guizhen Chen, Liying Cheng, Luu Anh Tuan, and Lidong Bing.
    Exploring the potential of large language models in computational argumentation,
    2023.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2023] Guizhen Chen, Liying Cheng, Luu Anh Tuan, 和 Lidong Bing.
    探索大型语言模型在计算论证中的潜力, 2023。
- en: 'Creswell et al. [2022] Antonia Creswell, Murray Shanahan, and Irina Higgins.
    Selection-inference: Exploiting large language models for interpretable logical
    reasoning, 2022.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Creswell et al. [2022] Antonia Creswell, Murray Shanahan, 和 Irina Higgins.
    Selection-inference: 利用大型语言模型进行可解释的逻辑推理, 2022。'
- en: 'Čyras et al. [2018] Kristijonas Čyras, Brendan Delaney, Denys Prociuk, Francesca
    Toni, Martin Chapman, Jesús Domínguez, and Vasa Curcin. Argumentation for explainable
    reasoning with conflicting medical recommendations. CEUR Workshop Proceedings,
    2237, January 2018. 2018 Joint Reasoning with Ambiguous and Conflicting Evidence
    and Recommendations in Medicine and the 3rd International Workshop on Ontology
    Modularity, Contextuality, and Evolution, MedRACER + WOMoCoE 2018 ; Conference
    date: 29-10-2018.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Čyras et al. [2018] Kristijonas Čyras, Brendan Delaney, Denys Prociuk, Francesca
    Toni, Martin Chapman, Jesús Domínguez, 和 Vasa Curcin. 针对解释性推理的论证与冲突医学建议。CEUR工作坊论文集,
    2237, 2018年1月。2018年模糊和冲突证据及医学建议联合推理会议和第3届本体模块化、情境性和演变国际研讨会，MedRACER + WOMoCoE
    2018；会议日期：2018年10月29日。
- en: 'de Wynter and Yuan [2023] Adrian de Wynter and Tommy Yuan. I wish to have an
    argument: Argumentative reasoning in large language models, 2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'de Wynter and Yuan [2023] Adrian de Wynter 和 Tommy Yuan. 我希望有一个论证: 大型语言模型中的论证性推理,
    2023。'
- en: Dietz et al. [2021] Emmanuelle Dietz, Antonis Kakas, and Loizos Michael. Computational
    argumentation and cognition, 2021.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dietz et al. [2021] Emmanuelle Dietz, Antonis Kakas, 和 Loizos Michael. 计算论证与认知,
    2021。
- en: 'Dietz et al. [2022] Emmanuelle Dietz, Antonis Kakas, and Loizos Michael. Argumentation:
    A calculus for human-centric ai. Frontiers in Artificial Intelligence, 5, 2022.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dietz et al. [2022] Emmanuelle Dietz, Antonis Kakas, 和 Loizos Michael. 论证：一种以人为本的人工智能计算方法。人工智能前沿,
    5, 2022。
- en: Dung [1995] Phan Minh Dung. On the acceptability of arguments and its fundamental
    role in nonmonotonic reasoning, logic programming and n-person games. Artificial
    Intelligence, 77(2):321–357, 1995.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dung [1995] Phan Minh Dung. 关于论证的可接受性及其在非单调推理、逻辑编程和n人博弈中的基本作用。人工智能, 77(2):321–357,
    1995。
- en: Eigner and Händler [2024] Eva Eigner and Thorsten Händler. Determinants of llm-assisted
    decision-making, 2024.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eigner and Händler [2024] Eva Eigner 和 Thorsten Händler. 大型语言模型辅助决策的决定因素, 2024。
- en: Fan and Toni [2015] Xiuyi Fan and Francesca Toni. On computing explanations
    in argumentation. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial
    Intelligence, AAAI’15, page 1496–1492\. AAAI Press, 2015.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan and Toni [2015] Xiuyi Fan 和 Francesca Toni. 论计算论证中的解释。在第二十九届AAAI人工智能会议论文集中，AAAI’15，页面1496–1492。AAAI出版社，2015。
- en: Gandhi et al. [2023] Kanishk Gandhi, Dorsa Sadigh, and Noah D. Goodman. Strategic
    reasoning with language models, 2023.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gandhi et al. [2023] Kanishk Gandhi, Dorsa Sadigh, 和 Noah D. Goodman. 与语言模型的战略推理,
    2023。
- en: Hong et al. [2023] Shengxin Hong, Liang Xiao, and Jianxia Chen. An interaction
    model for merging multi-agent argumentation in shared clinical decision making.
    In 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),
    pages 4304–4311, 2023.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong et al. [2023] Shengxin Hong, Liang Xiao, 和 Jianxia Chen. 一种用于合并多智能体论证的交互模型，在2023
    IEEE国际生物信息学与生物医学会议（BIBM）上，页面4304–4311，2023年。
- en: 'ISO [2020] ISO, IEC: AWI TS 29119-11: Software and systems engineering - software
    testing - part 11: Testing of AI systems. Technical report, 2020.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ISO [2020] ISO, IEC: AWI TS 29119-11: 软件与系统工程 - 软件测试 - 第11部分：AI系统的测试。技术报告,
    2020。'
- en: 'Jin et al. [2019] Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W. Cohen,
    and Xinghua Lu. Pubmedqa: A dataset for biomedical research question answering,
    2019.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jin等[2019] Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W. Cohen, 和 Xinghua
    Lu. Pubmedqa: 一个用于生物医学研究问题解答的数据集, 2019。'
- en: Jin et al. [2020] Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi
    Fang, and Peter Szolovits. What disease does this patient have? a large-scale
    open domain question answering dataset from medical exams, 2020.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin等[2020] Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang,
    和 Peter Szolovits. 这个患者得了什么病？一个来自医学考试的大规模开放领域问答数据集, 2020。
- en: 'Jin et al. [2023] Qiao Jin, Yifan Yang, Qingyu Chen, and Zhiyong Lu. Genegpt:
    Augmenting large language models with domain tools for improved access to biomedical
    information, 2023.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jin等[2023] Qiao Jin, Yifan Yang, Qingyu Chen, 和 Zhiyong Lu. Genegpt: 通过领域工具增强大型语言模型以改善对生物医学信息的访问,
    2023。'
- en: 'Jung et al. [2022] Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra
    Bhagavatula, Ronan Le Bras, and Yejin Choi. Maieutic prompting: Logically consistent
    reasoning with recursive explanations, 2022.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jung等[2022] Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra
    Bhagavatula, Ronan Le Bras, 和 Yejin Choi. Maieutic prompting: 具有递归解释的逻辑一致性推理,
    2022。'
- en: 'Klyne and Carroll [2004] Graham Klyne and Jeremy J. Carroll. Resource description
    framework (rdf): Concepts and abstract syntax. W3C Recommendation, 2004.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Klyne 和 Carroll [2004] Graham Klyne 和 Jeremy J. Carroll. 资源描述框架（rdf）：概念与抽象语法。W3C
    推荐标准, 2004。
- en: 'Li et al. [2023] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian
    Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon, and Jianfeng Gao. Llava-med:
    Training a large language-and-vision assistant for biomedicine in one day, 2023.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li等[2023] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu,
    Jianwei Yang, Tristan Naumann, Hoifung Poon, 和 Jianfeng Gao. LLAVA-MED: 在一天内为生物医学训练大型语言与视觉助手,
    2023。'
- en: Nayak et al. [2023] Anupama Nayak, Michael S Alkaitis, Karthik Nayak, Martin
    Nikolov, Kevin P Weinfurt, and Kevin Schulman. Comparison of history of present
    illness summaries generated by a chatbot and senior internal medicine residents.
    JAMA Intern Med, 183(9):1026–1027, Sep 2023.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nayak等[2023] Anupama Nayak, Michael S Alkaitis, Karthik Nayak, Martin Nikolov,
    Kevin P Weinfurt, 和 Kevin Schulman. 比较聊天机器人与资深内科住院医师生成的现病史总结。JAMA Intern Med,
    183(9):1026–1027, 2023年9月。
- en: Nori et al. [2023] Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard
    Edgar, Nicolo Fusi, Nicholas King, Jonathan Larson, Yuanzhi Li, Weishung Liu,
    Renqian Luo, Scott Mayer McKinney, Robert Osazuwa Ness, Hoifung Poon, Tao Qin,
    Naoto Usuyama, Chris White, and Eric Horvitz. Can generalist foundation models
    outcompete special-purpose tuning? case study in medicine, 2023.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nori等[2023] Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard Edgar,
    Nicolo Fusi, Nicholas King, Jonathan Larson, Yuanzhi Li, Weishung Liu, Renqian
    Luo, Scott Mayer McKinney, Robert Osazuwa Ness, Hoifung Poon, Tao Qin, Naoto Usuyama,
    Chris White, 和 Eric Horvitz. 通用基础模型是否能超越专用调优？医学领域的案例研究, 2023。
- en: Oliveira et al. [2018] Tiago Oliveira, Jérémie Dauphin, Ken Satoh, Shusaku Tsumoto,
    and Paulo Novais. Argumentation with goals for clinical decision support in multimorbidity.
    In Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent
    Systems, 2018. 2031–2033.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oliveira等[2018] Tiago Oliveira, Jérémie Dauphin, Ken Satoh, Shusaku Tsumoto,
    和 Paulo Novais. 基于目标的论证用于多病共存的临床决策支持。在第17届国际自主代理和多代理系统会议论文集, 2018. 2031–2033。
- en: OpenAI [2023] OpenAI. Gpt-4 technical report, 2023.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023] OpenAI. GPT-4 技术报告, 2023。
- en: 'Pal et al. [2023] Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu.
    Med-halt: Medical domain hallucination test for large language models, 2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pal等[2023] Ankit Pal, Logesh Kumar Umapathi, 和 Malaikannan Sankarasubbu. Med-halt:
    针对大型语言模型的医学领域幻觉测试, 2023。'
- en: 'Pan et al. [2023] Liangming Pan, Alon Albalak, Xinyi Wang, and William Yang
    Wang. Logic-lm: Empowering large language models with symbolic solvers for faithful
    logical reasoning, 2023.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pan等[2023] Liangming Pan, Alon Albalak, Xinyi Wang, 和 William Yang Wang. Logic-lm:
    利用符号求解器赋能大型语言模型以实现忠实的逻辑推理, 2023。'
- en: 'Pan et al. [2024] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang,
    and Xindong Wu. Unifying large language models and knowledge graphs: A roadmap.
    IEEE Transactions on Knowledge and Data Engineering, page 1–20, 2024.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan等[2024] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, 和 Xindong
    Wu. 统一大型语言模型和知识图谱：路线图。IEEE 知识与数据工程学报, 第1–20页, 2024。
- en: Qassas et al. [2015] Malik Al Qassas, Daniela Fogli, Massimiliano Giacomin,
    and Giovanni Guida. Analysis of clinical discussions based on argumentation schemes.
    Procedia Computer Science, 64:282–289, 2015. Conference on ENTERprise Information
    Systems/International Conference on Project MANagement/Conference on Health and
    Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2015
    October 7-9, 2015.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qassas et al. [2015] Malik Al Qassas、Daniela Fogli、Massimiliano Giacomin 和 Giovanni
    Guida。基于论证模式的临床讨论分析。Procedia Computer Science, 64:282–289, 2015。ENTERprise 信息系统会议/国际项目管理会议/健康和社会护理信息系统及技术会议，CENTERIS/ProjMAN
    / HCist 2015，2015年10月7-9日。
- en: Sassoon et al. [2021] Isabel Sassoon, Nadin Kökciyan, Sanjay Modgil, and Simon
    Parsons. Argumentation schemes for clinical decision support. Argument and Computation,
    12(3):329–355, November 2021.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sassoon et al. [2021] Isabel Sassoon、Nadin Kökciyan、Sanjay Modgil 和 Simon Parsons。临床决策支持的论证模式。Argument
    and Computation, 12(3):329–355, 2021年11月。
- en: Savage et al. [2024] Thomas Savage, Abhishek Nayak, Robert Gallo, and et al.
    Diagnostic reasoning prompts reveal the potential for large language model interpretability
    in medicine. npj Digital Medicine, 7:20, 2024.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Savage et al. [2024] Thomas Savage、Abhishek Nayak、Robert Gallo 等。诊断推理提示揭示了大语言模型在医学领域的可解释性潜力。npj
    Digital Medicine, 7:20, 2024。
- en: 'Shi et al. [2024] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang
    Wu, Yuanda Zhu, Joyce Ho, Carl Yang, and May D. Wang. Ehragent: Code empowers
    large language models for few-shot complex tabular reasoning on electronic health
    records, 2024.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. [2024] Wenqi Shi、Ran Xu、Yuchen Zhuang、Yue Yu、Jieyu Zhang、Hang Wu、Yuanda
    Zhu、Joyce Ho、Carl Yang 和 May D. Wang。Ehragent：代码使大语言模型能够在电子健康记录上进行少样本复杂表格推理，2024年。
- en: Singhal et al. [2022] Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi,
    Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen
    Pfohl, Perry Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal Scharli,
    Aakanksha Chowdhery, Philip Mansfield, Blaise Aguera y Arcas, Dale Webster, Greg S.
    Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun Liu,
    Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan Karthikesalingam, and
    Vivek Natarajan. Large language models encode clinical knowledge, 2022.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singhal et al. [2022] Karan Singhal、Shekoofeh Azizi、Tao Tu、S. Sara Mahdavi、Jason
    Wei、Hyung Won Chung、Nathan Scales、Ajay Tanwani、Heather Cole-Lewis、Stephen Pfohl、Perry
    Payne、Martin Seneviratne、Paul Gamble、Chris Kelly、Nathaneal Scharli、Aakanksha Chowdhery、Philip
    Mansfield、Blaise Aguera y Arcas、Dale Webster、Greg S. Corrado、Yossi Matias、Katherine
    Chou、Juraj Gottweis、Nenad Tomasev、Yun Liu、Alvin Rajkomar、Joelle Barral、Christopher
    Semturs、Alan Karthikesalingam 和 Vivek Natarajan。大语言模型编码临床知识，2022年。
- en: Singhal et al. [2023] Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery
    Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal,
    Mike Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar, Philip Mansfield, Sushant
    Prakash, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Nenad Tomasev,
    Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle Barral, Dale
    Webster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam,
    and Vivek Natarajan. Towards expert-level medical question answering with large
    language models, 2023.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singhal et al. [2023] Karan Singhal、Tao Tu、Juraj Gottweis、Rory Sayres、Ellery
    Wulczyn、Le Hou、Kevin Clark、Stephen Pfohl、Heather Cole-Lewis、Darlene Neal、Mike
    Schaekermann、Amy Wang、Mohamed Amin、Sami Lachgar、Philip Mansfield、Sushant Prakash、Bradley
    Green、Ewa Dominowska、Blaise Aguera y Arcas、Nenad Tomasev、Yun Liu、Renee Wong、Christopher
    Semturs、S. Sara Mahdavi、Joelle Barral、Dale Webster、Greg S. Corrado、Yossi Matias、Shekoofeh
    Azizi、Alan Karthikesalingam 和 Vivek Natarajan。利用大语言模型实现专家级医学问答，2023年。
- en: 'Tang et al. [2024] Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun
    Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein. Medagents: Large language
    models as collaborators for zero-shot medical reasoning, 2024.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang et al. [2024] Xiangru Tang、Anni Zou、Zhuosheng Zhang、Ziming Li、Yilun Zhao、Xingyao
    Zhang、Arman Cohan 和 Mark Gerstein。Medagents：大语言模型作为零样本医学推理的合作者，2024年。
- en: Walton et al. [2008] Douglas Walton, Chris Reed, and Fabrizio Macagno. Argumentation
    Schemes. Cambridge University Press, New York, 2008.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walton et al. [2008] Douglas Walton、Chris Reed 和 Fabrizio Macagno。论证模式。Cambridge
    University Press，纽约，2008年。
- en: Walton [1996] Douglas Walton. Argumentation Schemes for Presumptive Reasoning.
    Routledge, 1st edition, 1996.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walton [1996] Douglas Walton。假设推理的论证模式。Routledge，第一版，1996年。
- en: Wang et al. [2023] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, and Ji-Rong Wen. A survey on large language model based autonomous agents,
    2023.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. [2023] Lei Wang、Chen Ma、Xueyang Feng、Zeyu Zhang、Hao Yang、Jingsen
    Zhang、Zhiyuan Chen、Jiakai Tang、Xu Chen、Yankai Lin、Wayne Xin Zhao、Zhewei Wei 和
    Ji-Rong Wen。基于大语言模型的自主代理调查，2023年。
- en: Wei et al. [2023] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. Chain-of-thought prompting elicits
    reasoning in large language models, 2023.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等人 [2023] Jason Wei，Xuezhi Wang，Dale Schuurmans，Maarten Bosma，Brian Ichter，Fei
    Xia，Ed Chi，Quoc Le，和 Denny Zhou。《链式思维提示引发大型语言模型的推理》，2023。
- en: 'Wu et al. [2023] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, and Chi Wang. Autogen: Enabling next-gen llm applications
    via multi-agent conversation, 2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '吴等人 [2023] 青云吴，Gagan Bansal，Jieyu Zhang，Yiran Wu，Beibin Li，Erkang Zhu，Li Jiang，Xiaoyun
    Zhang，Shaokun Zhang，Jiale Liu，Ahmed Hassan Awadallah，Ryen W White，Doug Burger，和
    Chi Wang。《Autogen: Enabling next-gen llm applications via multi-agent conversation》，2023。'
- en: 'Xie et al. [2024] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou,
    Yuandong Tian, Yanghua Xiao, and Yu Su. Travelplanner: A benchmark for real-world
    planning with language agents, 2024.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '谢等人 [2024] Jian Xie，Kai Zhang，Jiangjie Chen，Tinghui Zhu，Renze Lou，Yuandong
    Tian，Yanghua Xiao，和 Yu Su。《Travelplanner: 真实世界规划的语言代理基准》，2024。'
- en: 'Xiu et al. [2022] Yeliang Xiu, Zhanhao Xiao, and Yongmei Liu. LogicNMR: Probing
    the non-monotonic reasoning ability of pre-trained language models. In Yoav Goldberg,
    Zornitsa Kozareva, and Yue Zhang, editors, Findings of the Association for Computational
    Linguistics: EMNLP 2022, pages 3616–3626, Abu Dhabi, United Arab Emirates, December
    2022\. Association for Computational Linguistics.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '修等人 [2022] 叶亮修，战浩肖，和永梅刘。《LogicNMR: 探测预训练语言模型的非单调推理能力》。在 Yoav Goldberg，Zornitsa
    Kozareva，和 Yue Zhang 编辑的《计算语言学协会发现：EMNLP 2022》一书中，第3616–3626页，阿布扎比，阿拉伯联合酋长国，2022年12月。计算语言学协会。'
- en: Zeng et al. [2020] Zhiwei Zeng, Zhiqi Shen, Benny Toh Hsiang Tan, Jing Jih Chin,
    Cyril Leung, Yu Wang, Ying Chi, and Chunyan Miao. Explainable and Argumentation-based
    Decision Making with Qualitative Preferences for Diagnostics and Prognostics of
    Alzheimer’s Disease. In Proceedings of the 17th International Conference on Principles
    of Knowledge Representation and Reasoning, pages 816–826, 9 2020.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曾等人 [2020] 志伟曾，志齐沈，Benny Toh Hsiang Tan，晶继陈，Cyril Leung，余望，英奇，和春艳苗。《可解释的基于论证的决策制定及其在阿尔茨海默病诊断与预测中的定性偏好》。在第17届知识表示与推理原则国际会议论文集中，第816–826页，2020年9月。
- en: Zhang et al. [2023] Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih
    Yao. Cumulative reasoning with large language models, 2023.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人 [2023] 益凡张，晶秦杨，杨远，和 Andrew Chi-Chih Yao。《利用大型语言模型的累积推理》，2023。
- en: Appendix A Formal Description of ArgMed-Agents
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A ArgMed-Agents 的正式描述
- en: Algorithm 1 ArgMed-Agents Interaction Reasoning
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 ArgMed-Agents 互动推理
- en: 1:Question $Q$)24:end function
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '1: 问题 $Q$)24: 结束函数'
- en: Appendix B ASCD Reasoning Mechanisms
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B ASCD 推理机制
- en: '| Argumentation Scheme | Critical Questions | Reject Rule | Derive Role | Attack
    Rule |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 | 关键问题 | 拒绝规则 | 推导角色 | 攻击规则 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Argumentation Scheme |  |  |  |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 |  |  |  |  |'
- en: '| for Decision(ASD) | ASD.CQ1 | NO (no evidence to support the argument) |
    none | self-attack |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 为决策（ASD） | ASD.CQ1 | 否（没有证据支持论点） | 无 | 自我攻击 |'
- en: '|  | ASD.CQ2 | YES (there are side effects of decision-making) | ASSE | ASSE
    attack ASD |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | ASD.CQ2 | 是的（决策有副作用） | ASSE | ASSE 攻击 ASD |'
- en: '|  | ASD.CQ3 | NO (incomplete decisions to fulfil goals) | none | self-attack
    |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  | ASD.CQ3 | 否（决策不完整以达成目标） | 无 | 自我攻击 |'
- en: '|  | ASD.CQ4 | YES (existence of alternative decisions) | ASD | ASBD attack
    the worse decision |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | ASD.CQ4 | 是的（存在替代决策） | ASD | ASBD 攻击较差决策 |'
- en: '| in ASD_1 and ASD_2 |  |  |  |  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 在 ASD_1 和 ASD_2 中 |  |  |  |  |'
- en: '| Argumentation Scheme |  |  |  |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 |  |  |  |  |'
- en: '| for Side Effect(ASSE) | ASSE.CQ1 | NO (no evidence to support the argument)
    | none | self-attack |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 为副作用（ASSE） | ASSE.CQ1 | 否（没有证据支持论点） | 无 | 自我攻击 |'
- en: '|  | ASSE.CQ2 | NO (the side-effect is acceptable) | none | self-attack |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '|  | ASSE.CQ2 | 否（副作用可以接受） | 无 | 自我攻击 |'
- en: '|  | ASSE.CQ3 | YES (there are ways to ameliorate side effects) | ASD | none
    |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  | ASSE.CQ3 | 是的（有方法改善副作用） | ASD | 无 |'
- en: '| Argumentation Scheme |  |  |  |  |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 论证方案 |  |  |  |  |'
- en: '| for Better Decision(ASBD) | ASBD.CQ1 | NO (no evidence to support the argument)
    | none | self-attack |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 为更好的决策（ASBD） | ASBD.CQ1 | 否（没有证据支持论点） | 无 | 自我攻击 |'
- en: 'Table 3: List of specialized schemes, CQs, when CQs will be rejected and their
    derived roles and attack rules between derived roles and initial schemes. Notably,
    every ASD is attacking each other by default, so it is not shown in the attack
    rules.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：专用方案、CQ 列表、CQ 被拒绝的情况以及它们派生角色与初始方案之间的攻击规则。值得注意的是，每个 ASD 默认会攻击其他 ASD，因此在攻击规则中没有显示。
- en: Appendix C More Case Details in Experiment
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 实验中的更多案例细节
- en: '![Refer to caption](img/a82eff4588abaf8dd2da648b816fe126.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a82eff4588abaf8dd2da648b816fe126.png)'
- en: 'Figure 4: Example of correct reasoning by ArgMed-Agents. We show the flow of
    the multi-agent dialogue and the resulting formal AA framework.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：ArgMed-Agents 正确推理的示例。我们展示了多智能体对话的流程及其生成的正式 AA 框架。
- en: '![Refer to caption](img/e8d0b933be92c11e95ff772dd88fde0b.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e8d0b933be92c11e95ff772dd88fde0b.png)'
- en: 'Figure 5: (continued) Example of correct reasoning by ArgMed-Agents. We provide
    runnable demo files with available GPT-4 API Keys in the code that include these
    cases.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：（续）ArgMed-Agents 正确推理的示例。我们提供了包含这些案例的可运行演示文件和可用的 GPT-4 API 密钥。
