- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:42:55'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief
    Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.17232](https://ar5iv.labs.arxiv.org/html/2406.17232)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yun-Shiuan Chuang, Zach Studdiford^†, Krirk Nirunwiroj^†, Agam Goyal
  prefs: []
  type: TYPE_NORMAL
- en: Vincent V. Frigo, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers
  prefs: []
  type: TYPE_NORMAL
- en: University of Wisconsin-Madison
  prefs: []
  type: TYPE_NORMAL
- en: '{yunshiuan.chuang,studdiford,nirunwiroj,agoyal25}@wisc.edu'
  prefs: []
  type: TYPE_NORMAL
- en: '{vfrigo, syang84, dshah, junjie.hu, ttrogers}@wisc.edu'
  prefs: []
  type: TYPE_NORMAL
- en: ^† joint second author
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Creating human-like large language model (LLM) agents is crucial for faithful
    social simulation. Having LLMs role-play based on demographic information sometimes
    improves human likeness but often does not. This study assessed whether LLM alignment
    with human behavior can be improved by integrating information from empirically-derived
    human belief networks. Using data from a human survey, we estimated a belief network
    encompassing 18 topics loading on two non-overlapping latent factors. We then
    seeded LLM-based agents with an opinion on one topic, and assessed the alignment
    of its expressed opinions on remaining test topics with corresponding human data.
    Role-playing based on demographic information alone did not align LLM and human
    opinions, but seeding the agent with a single belief greatly improved alignment
    for topics related in the belief network, and not for topics outside the network.
    These results suggest a novel path for human-LLM belief alignment in work seeking
    to simulate and understand patterns of belief distributions in society.
  prefs: []
  type: TYPE_NORMAL
- en: 'Beyond Demographics:'
  prefs: []
  type: TYPE_NORMAL
- en: Aligning Role-playing LLM-based Agents Using Human Belief Networks
  prefs: []
  type: TYPE_NORMAL
- en: Yun-Shiuan Chuang, Zach Studdiford^†, Krirk Nirunwiroj^†, Agam Goyal Vincent
    V. Frigo, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers University of
    Wisconsin-Madison {yunshiuan.chuang,studdiford,nirunwiroj,agoyal25}@wisc.edu {vfrigo,
    syang84, dshah, junjie.hu, ttrogers}@wisc.edu ^† joint second author
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With rapid advances in large language models (LLMs), there has grown increasing
    interest in using these technologies to simulate and understand dynamics of human
    communication and persuasion Park et al. ([2023](#bib.bib17), [2022](#bib.bib18));
    Chuang et al. ([2023](#bib.bib7)); Taubenfeld et al. ([2024](#bib.bib23)). Contemporary
    LLMs can be prompted to role-play as individuals with particular demographic traits,
    sometimes then producing patterns of behavior that seem remarkably human-like.
    For instance, when asked to report the US unemployment rate when President Obama
    left office, ChatGPT will provide the exact answer; but if first instructed to
    role-play as a typical Democrat or Republican and asked the same question, the
    model produces incorrect, inflated estimates that mirror patterns of partisan
    bias in analogous human studies Chuang et al. ([2024](#bib.bib8)). Such results
    raise the possibility that, with strategic prompting, LLMs may serve as useful
    proxies for capturing beliefs and attitudes of various socio-demographic groups.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/832ef8037ac4896115f4e980591ffe03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: An LLM agent $i^{\prime}$).'
  prefs: []
  type: TYPE_NORMAL
- en: Other recent work suggests, however, that the alignment between beliefs expressed
    by role-playing LLMs and matched human participants is unreliable at best. For
    instance, Santurkar et al. ([2023](#bib.bib20)) found that LLMs tuned via human
    feedback generally reflect opinions from liberal and well-educated demographics
    and that having LLMs role-play as humans with different socio-demographic traits
    does not remediate this tendency. Similarly, Sun et al. ([2024](#bib.bib22)) had
    LLMs offer opinions on controversial issues while role-playing as humans with
    varying demographic characteristics, and found that the model only reflected corresponding
    human opinions on one of the ten total topics. Chuang et al. ([2023](#bib.bib7))
    additionally found that, even when seeded with prompts specifying an initial belief
    that runs contrary to social consensus (e.g., "global warming is a hoax"), LLMs
    quickly revert to the accepted ground-truth attitude after repeated interactions
    with other agents. Overall, this work suggests that LLM fine-tuned with human
    feedback tend to adopt progressive stances regardless of the demographic background
    they role-play–a behavior that may aid LLM fairness and value alignment, but limits
    their utility as models of human communicative dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: 'The current paper considers an alternative approach to aligning the attitudes
    expressed by role-playing LLMs and the human groups they are intended to emulate.
    The central idea relies on behavioral studies of human belief networks: the empirical
    observation that beliefs on different topics are not distributed at random across
    the population, but tend to cohere together in patterns of high-order covariation
    Boutyline and Vaisey ([2017](#bib.bib3)); Vlasceanu et al. ([2024](#bib.bib25));
    Keating ([2023](#bib.bib15)); Turner-Zwinkels and Brandt ([2022](#bib.bib24)).
    For instance, people who believe that government should support social welfare
    programs are also more likely to believe in higher taxes on the wealthy, strong
    union protections, and universal health care. Thus, knowing a person’s opinion
    on one topic can carry rich information about their likely views on many others.
    Because LLMs learn from vast amounts of human-generated language, the weights
    they acquire and hence patterns of behaviors they exhibit may implicitly capture
    the tendency for various beliefs to co-occur in human populations, providing novel
    leverage for alignment. Specifically, human-LLM alignment may be guided, not just
    by socio-demographic role-playing, but also by instructing the LLM to hold a specific
    opinion on a representative topic.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e74b4918083bd0504c08b1a3a51ed1fe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The belief network estimated by factor analysis from human respondents’
    responses on the Belief Survey. (a) Partial factor loading matrix that includes
    the columns for these Ghost (green) and the Partisan (violet) factors and the
    rows for topics that belong to these two factor categories. The full factor loading
    matrix is in Figure [5](#A6.F5 "Figure 5 ‣ Appendix F The Full Factor Analysis
    Results ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human
    Belief Networks") (§[F](#A6 "Appendix F The Full Factor Analysis Results ‣ Beyond
    Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks")).
    Red indicates topics that load positively on a factor, gray indicates near 0 loading,
    and blue indicates loading in the negative direction. The topics in the Ghost
    category has minimal loading on the Partisan factor and vice versa (highlighted
    by the black boxes). The training topics are further highlighted by dark green
    (“Dead Talk”) and purple (“Gun Control”) boxes, respectively. The full statement
    of the each topic is in Table LABEL:tab:list_topic (§[A](#A1 "Appendix A List
    of the 64 Topics in the Belief Survey ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks")). (b) The graphical respresentation
    of the belief network, where the central nodes are the two latent factors, and
    the leaves (rectangles) are the individual topics. Red and blue edges indicate
    positive and negative loadings, respectively. The width of each edge encodes the
    strength of the loading. The training topics are highlighted with grey backgrounds.'
  prefs: []
  type: TYPE_NORMAL
- en: To test this idea, we considered a simple belief network constructed in prior
    work by applying factor analysis to a dataset measuring human beliefs across a
    diverse array of topics Frigo ([2022](#bib.bib11)). Factor analysis decomposes
    patterns of covariation among expressed beliefs, identifying relationships between
    the beliefs themselves and a set of underlying latent factors. From this analysis
    we identified two orthogonal factors, each receiving high loadings from several
    controversial beliefs, and with no overlap between the beliefs loading highly
    on each. These included a ghost factor grouping beliefs in various supernatural
    phenomena (e.g., talking to the dead) and a partisan factor grouping beliefs that
    are typically politically polarizing in the US (e.g., effectiveness of gun control).
    We then considered how well the opinions of contemporary LLMs align with human
    participants when prompted (a) with no role-playing information, (b) with demographic
    information only, or (c) with demographic information plus a corresponding belief
    on a single topic that aligns strongly with either the ghost factor or the partisan
    factor in the belief network. When seeding each model with such a belief, we additionally
    compared the effects of in-context learning (i.e., prompting) versus supervised
    fine-tuning. The results suggest that attention to empirically-derived human belief
    networks may provide a useful strategy for human-LLM alignment, more so than demographic
    role-playing.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6032867c79f07ef530d70d43a8910f51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: LLM agent construction conditions with different levels of respondent’s
    information through in-context learning. (a) “None” condition without role-playing,
    and we directly query the LLM about its opinion on the query topic ($x_{\text{query}}$).
    Everything is in the “system message” except the query topic, which is in the
    “user message”.'
  prefs: []
  type: TYPE_NORMAL
- en: '2 Preliminaries: LLM Agents as Human Digital Twins'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As depicted in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Beyond Demographics:
    Aligning Role-playing LLM-based Agents Using Human Belief Networks"), we aim to
    construct an LLM agent $i^{\prime}$. Note that we use the term LLM-based “agent”
    to refer to the digital twin because they are designed to produce a wide range
    of social behaviors that emulate the human individual they role-play Park et al.
    ([2023](#bib.bib17)); Shao et al. ([2023](#bib.bib21)); Zhou et al. ([2023](#bib.bib26)).'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Controversial Beliefs Survey
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The specific opinions we assessed were taken from the Controversial Beliefs
    Survey developed in Frigo ([2022](#bib.bib11)). The survey measures the direction
    and strength of belief across 64 topics spanning broad aspects of human knowledge,
    including history, science, health, religion, the supernatural, economics, politics,
    and conspiracy theories (see Table LABEL:tab:list_topic in §[A](#A1 "Appendix
    A List of the 64 Topics in the Belief Survey ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks") for the full list of topics). Topics
    were selected to elicit a diverse range of opinions about their truthfulness (hence
    “controversial beliefs”). Each belief is stated as a factual proposition (e.g.,
    "States with stricter gun control laws have fewer gun deaths per capita"), and
    participants rate their view about the truth of the statement on a six-point Likert
    scale ranging from "Certainly false" to "Certainly true." Responses with high
    numbers indicate agreement with the rational/consensus ground truth. The dataset
    also contains extensive demographic data from respondents, including age, gender,
    education level, household income, urban versus rural living environment, state
    of residence, and political leaning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset includes ratings for $N=564$: Certainly true. No neutral value
    was provided so participants must minimally lean in one direction or the other.
    The demographic and opinion data together were used to construct and evaluate
    the LLM agents (§[3.3](#S3.SS3 "3.3 LLM Agent Construction ‣ 3 Methods ‣ Beyond
    Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks")).
    The survey dataset can be obtained by contacting its authors Frigo ([2022](#bib.bib11)).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Constructing a Belief Network using Factor Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our objective was to find two independent “belief networks”–that is, two groups
    of topics where expressed beliefs covaried across participants within each group
    but were independent between groups. To this end, we relied on a previous factor
    analysis Frigo ([2022](#bib.bib11)) that first computed correlations in the ratings
    produced across participants for each pair of topics, then decomposed the resulting
    matrix into a set of orthogonal latent factors using principal component analysis
    (PCA) with Varimax rotation Kaiser ([1958](#bib.bib14)). The PCA yielded a factor
    loading matrix that encodes the loading between each topic and each latent factor.
    Nine latent factors were extracted based on the factor scree plot (Cattell, [1966](#bib.bib5),
    see §[D](#A4 "Appendix D The Choice of Number of Factors in Factor Analysis ‣
    Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief
    Networks")), which together accounted for 72% of the variance in the correlation
    matrix. From these, we selected two factors such that topics loading highly on
    the first had loadings near zero on the second and vice versa. These are shown
    in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Beyond Demographics: Aligning
    Role-playing LLM-based Agents Using Human Belief Networks"). The ghost factor
    receives high loadings from 12 topics, all pertaining to supernatural or otherworldly
    beliefs; the partisan factor receives high loadings from 6 topics on highly polarized
    political issues. We referred to these topics as either belonging to the ghost
    topic category or partisan topic category, respectively. We took these 18 topics
    and the corresponding latent factors as the targets for our analysis of LLM alignment.
    The full factor analysis results, including the full factor loading matrix of
    the nine factors, can be found in §[F](#A6 "Appendix F The Full Factor Analysis
    Results ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human
    Belief Networks").'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 LLM Agent Construction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For each factor we designated the topic possessing the highest loading as the
    model training topic ($x_{\text{train}}$ on these topics were used to evaluate
    their alignment with the human respondents. We hypothesized that specifying the
    agent’s opinion on the training topic might elicit shared representation that
    generalize to testing topics close within the belief network (i.e., sharing the
    same latent factor), but not those from the other belief network.
  prefs: []
  type: TYPE_NORMAL
- en: For each human respondent $i$), and measured how ratings generated by the digital
    twins correlate with the true opinions expressed by corresponding human respondents.
    We then assessed how this measure of human-LLM belief alignment varied with different
    strategies for constructing the digital twin.
  prefs: []
  type: TYPE_NORMAL
- en: In-context Learning (ICL).
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As shown in Figure [3](#S1.F3 "Figure 3 ‣ 1 Introduction ‣ Beyond Demographics:
    Aligning Role-playing LLM-based Agents Using Human Belief Networks"), these strategies
    involve initializing agents via in-context learning only, with different information
    included in their system message (see §[4.1](#S4.SS1 "4.1 Configuration for LLM
    Agents ‣ 4 Experimental Settings ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks") and Appendix §[B](#A2 "Appendix
    B The Prompts for LLM Agent Construction Through In-context Learning ‣ Beyond
    Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks")
    for the prompts).'
  prefs: []
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'None: An LLM, without role-playing, is directly queried for its Likert-scale
    opinion on the query topic, providing a performance floor since there is no way
    for the LLM to align with a corresponding human participant. Note that variation
    may still be present due to temperature sampling (§[4.1](#S4.SS1 "4.1 Configuration
    for LLM Agents ‣ 4 Experimental Settings ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks")).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Demo: An LLM agent is constructed to role-play the $i$) in the prompt.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Demo+Train [same category]: In addition to demographic information, the LLM
    receives a respondent’s Likert-scale opinion on the training topic ($x_{\text{train}}$
    within the belief network. This is the condition of interest.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Demo+Train [different category]: This control condition is similar to Demo+Train
    [same category], but assesses the LLM on topics from the opposing topic category,
    allowing us to determine whether the cross-topic generalization is restricted
    to adjacent topics in the belief network.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: e.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Demo+Train+Query: This control condition provides the human opinion rating
    on both the training topic ($x_{\text{train}}$) during the agent construction,
    providing an upper bound on generalization behavior.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Supervised Fine-tuning (SFT).
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We also investigated whether seeding initial beliefs via supervised fine-tuning
    (SFT) can increase human-LLM alignment. Specifically, the correspondence between
    the demographic information $d$. Details of the fine-tuning procedure and the
    corresponding prompts are in §[C](#A3 "Appendix C The Prompts for LLM Agent Construction
    Through Supervised Fine-tuning ‣ Beyond Demographics: Aligning Role-playing LLM-based
    Agents Using Human Belief Networks") and §[E](#A5 "Appendix E Supervised Fine-tuning
    Details ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human
    Belief Networks").'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experimental Settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Category | Topic | Conditions for LLM Agent Construction (In-context Learning)
    |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT (gpt-3.5-turbo-0125) | Mistral (Mistral-7B-Instruct-v0.2) |'
  prefs: []
  type: TYPE_TB
- en: '| None | Demo | Demo+Train | Demo+Train | Demo+Train | None | Demo | Demo+Train
    | Demo+Train | Demo+Train |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | [Diff. Cat.] | [Same Cat.] | + Query |  |  | [Diff. Cat.] | [Same
    Cat.] | + Query |'
  prefs: []
  type: TYPE_TB
- en: '| Ghost |  |  |  |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|       Train | Dead Talk | 0.04 | 0.02 | 0.04 | 0.98 | 1.00 | NA | NA | 0.07
    | 0.97 | 0.98 |'
  prefs: []
  type: TYPE_TB
- en: '|       Test | Ghost | 0.03 | 0.05 | -0.07 | 0.53 | 0.75 | NA | NA | NA | 0.59
    | 0.73 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Alien Visit | -0.08 | -0.05 | -0.04 | 0.33 | 0.63 | NA | NA | NA | 0.37
    | 0.62 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Soul Walk | -0.05 | 0.06 | -0.07 | 0.40 | 0.89 | NA | NA | 0.07 | 0.53
    | 0.63 |'
  prefs: []
  type: TYPE_TB
- en: '|  | See Future | -0.03 | 0.07 | -0.03 | 0.34 | 0.80 | NA | NA | -0.08 | 0.38
    | 0.85 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Astrology | -0.04 | 0.06 | -0.07 | 0.28 | 0.88 | NA | NA | NA | 0.32 |
    0.71 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Roswell | -0.10 | -0.07 | 0.03 | 0.26 | 0.85 | NA | NA | NA | 0.21 | 0.28
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Past Life | -0.02 | 0.01 | 0.09 | 0.31 | 0.79 | NA | NA | -0.05 | 0.17
    | 0.61 |'
  prefs: []
  type: TYPE_TB
- en: '|  | The Secret | -0.01 | 0.05 | 0.02 | 0.32 | 0.66 | NA | NA | NA | 0.07 |
    0.67 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Aura | 0.03 | 0.02 | -0.02 | 0.25 | 0.80 | NA | NA | NA | 0.35 | 0.62
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Luck | -0.04 | 0.08 | -0.09 | 0.23 | 0.84 | NA | NA | NA | NA | 0.46 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dousing | -0.02 | 0.03 | 0.00 | 0.19 | 0.71 | NA | NA | 0.01 | 0.23 |
    0.58 |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{MAE}_{\text{test}}\downarrow$ | [2.42] | [2.54] | [2.31] | [1.29]
    | [0.34] | [1.82] | [1.82] | [1.83] | [1.28] | [0.71] |'
  prefs: []
  type: TYPE_TB
- en: '| Partisan |  |  |  |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|       Train | Gun Control | -0.04 | 0.25 | 0.30 | 0.98 | 1.00 | NA | 0.33
    | 0.12 | 0.90 | 0.90 |'
  prefs: []
  type: TYPE_TB
- en: '|       Test | Globe Warm | -0.09 | 0.27 | 0.27 | 0.27 | 0.94 | NA | 0.32 |
    0.22 | 0.38 | 0.81 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Globe Human | -0.10 | 0.30 | 0.35 | 0.35 | 0.98 | NA | 0.31 | 0.33 | 0.39
    | 0.73 |'
  prefs: []
  type: TYPE_TB
- en: '|  | US Deficit | 0.03 | 0.02 | 0.03 | 0.16 | 0.70 | NA | NA | -0.02 | 0.09
    | 0.70 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Unions | 0.03 | 0.18 | 0.08 | 0.18 | 0.88 | NA | 0.06 | 0.04 | 0.13 |
    0.78 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Death Penalty | -0.14 | 0.00 | 0.00 | 0.00 | 0.32 | NA | NA | NA | NA
    | 0.46 |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{MAE}_{\text{test}}\downarrow$ | [1.42] | [1.32] | [1.35] | [1.25]
    | [0.38] | [2.20] | [1.32] | [1.39] | [1.28] | [0.63] |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Kendall’s $\tau_{t}$, the higher the human-LLM alignment. In particular,
    the inclusion of same-category training topic opinions significantly increases
    the alignment. (“Diff. Cat.” : Different Category; “Same Cat.”: Same Category)'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Configuration for LLM Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We evaluated LLM agents using both ChatGPT (gpt-3.5-turbo-0125; OpenAI, [2022](#bib.bib16))
    and Mistral (Mistral-7B-Instruct-v0.2; Jiang et al., [2023](#bib.bib13)) with
    temperature of $0.7$) were fed to the agent through the model’s “user messages”.
    When using in-context learning (§[3.3](#S3.SS3 "3.3 LLM Agent Construction ‣ 3
    Methods ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human
    Belief Networks")), the training/query topic opinions were also included in the
    model’s “system messages”. The LLM agents were constructed through LangChain Chase
    ([2022](#bib.bib6)). For our compute resources, see §[G](#A7 "Appendix G Compute
    Resources ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents Using
    Human Belief Networks").'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Supervised Fine-tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For LLM agents constructed through supervised fine-tuning (§[3.3](#S3.SS3 "3.3
    LLM Agent Construction ‣ 3 Methods ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks")), we used the ChatGPT model gpt-3.5-turbo-0125’s
    fine-tuning API. Critically, because the label (i.e., opinion response $o$. §[E](#A5
    "Appendix E Supervised Fine-tuning Details ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks") lists the hyperparameters for fine-tuning.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Evaluation Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To evaluate the “human-likeness” of the LLM agents’ opinions, we for each topic
    $x$) within the topic category.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The results for in-context learning and supervised fine-tuning were qualitatively
    similar; we discuss the in-context learning results first.
  prefs: []
  type: TYPE_NORMAL
- en: Demographic information alone does not align the LLM agent’s opinion.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As shown in Table [1](#S4.T1 "Table 1 ‣ 4 Experimental Settings ‣ Beyond Demographics:
    Aligning Role-playing LLM-based Agents Using Human Belief Networks"), incorporating
    solely the demographic information (the Demo condition) fails to align LLM agents
    with human respondents. The Kendall’s $\tau$ of the Demo condition is also similar
    to the None baseline condition, indicating that the demographic information alone
    does not help LLM agents align with the human respondents they role-play.'
  prefs: []
  type: TYPE_NORMAL
- en: Specifying the agent’s opinion on a training topic aligns other beliefs in the
    same network.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When the LLM is instructed to adopt the twinned human’s opinion on the training
    topic ($x_{\text{train}}$). This effect is limited to topics within the same belief
    network: expressed beliefs in the other topic category (e.g., about the effectiveness
    of gun control law; Demo+Train [different category] condition) remain uncorrelated
    (unaligned) with the corresponding human opinion opinion. This supports our hypothesis
    – opinions on one topic encourage the LLM agents to align their opinions only
    on topics that are adjacent in the belief network. We additionally note that such
    alignment is not total: human-LLM correlations in the Demo+Train [same category]
    condition do not reach the upper bounds established by the Demo+Train+Query control
    condition, highlighting opportunities for future work to further improve the alignment.'
  prefs: []
  type: TYPE_NORMAL
- en: Degree of alignment reflects factor loadings.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Different topics showed differing degrees of human-LLM alignment following the
    training-topic prompt, ranging from zero correlation for the death penalty topic
    (“States that have the death penalty have higher rates of violent crime on average”)
    to a correlation of 0.53 (ChatGPT) and 0.59 (Mistral) for belief in ghosts (“After
    people die it is sometimes possible to see their ghost.”). Yet the different topics
    also vary in the strength with which load on their primary factor. To assess whether
    this variation explains alignment patterns, we computed, across all test topics,
    the correlation between the topic’s loading on its primary factor and its degree
    of alignment in the Demo+Train [same category] condition. The result showed a
    tight correlation between these ($r=0.77,p<.001$), suggesting that degree of alignment
    following the training prompt reflects strength of the topic’s participation in
    the corresponding belief network. This relationship does not explain all cross-topic
    variation; at least one topic (death penalty) showed zero alignment even when
    given the correct opinion in the prompt, suggesting some degree of inherent bias
    in model responses for certain topics.
  prefs: []
  type: TYPE_NORMAL
- en: Alignment does not reflect superficial repetition.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Category | Topic | Demo+Train condition [Same Cat.] |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT | Mistral |'
  prefs: []
  type: TYPE_TB
- en: '| [Original] | [Balanced] | [Original] | [Balanced] |'
  prefs: []
  type: TYPE_TB
- en: '| Ghost |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Train | Dead Talk | 0.98 | 0.99 | 0.97 | 0.97 |'
  prefs: []
  type: TYPE_TB
- en: '| Test | Ghost | 0.53 | 0.46 | 0.59 | 0.61 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Alien Visit | 0.33 | 0.25 | 0.37 | 0.18 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Soul Walk | 0.40 | 0.40 | 0.53 | 0.53 |'
  prefs: []
  type: TYPE_TB
- en: '|  | See Future | 0.34 | 0.16 | 0.38 | 0.52 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Astrology | 0.28 | 0.13 | 0.32 | 0.32 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Roswell | 0.26 | 0.31 | 0.21 | 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Past Life | 0.31 | 0.32 | 0.17 | 0.18 |'
  prefs: []
  type: TYPE_TB
- en: '|  | The Secret | 0.32 | 0.14 | 0.07 | 0.07 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Aura | 0.25 | 0.15 | 0.35 | 0.32 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Luck | 0.23 | 0.03 | NA | NA |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dousing | 0.19 | 0.24 | 0.23 | 0.32 |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{MAE}_{\text{test}}\downarrow$ | [1.29] | [1.64] | [1.28] | [1.26]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Partisan |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Train | Gun Control | 0.98 | 0.88 | 0.90 | 0.93 |'
  prefs: []
  type: TYPE_TB
- en: '| Test | Globe Warm | 0.27 | 0.03 | 0.38 | 0.14 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Globe Human | 0.35 | 0.12 | 0.39 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '|  | US Deficit | 0.16 | 0.01 | 0.09 | 0.10 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Union Protection | 0.18 | 0.18 | 0.13 | 0.19 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Death Penalty | 0.00 | 0.00 | NA | NA |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{MAE}_{\text{test}}\downarrow$ | [1.25] | [1.24] | [1.28] | [1.23]
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Kendall’s $\tau_{t}$, the higher the human-LLM alignment. Note that
    balancing the label distribution still maintains the superiority of Demo+Train
    [same category] condition when compared with the Demo condition (Table [1](#S4.T1
    "Table 1 ‣ 4 Experimental Settings ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Does increased alignment following the Demo+Train [same category] condition
    arise from a model tendency to simply repeat the opinion providing for the training
    topic? Such a pattern might appear to lead to increased alignment simply because
    the training topic opinion, by definition, correlates with opinions on other topics
    in the same belief network. To address this concern, we conducted an additional
    experiment in which we balanced the label distribution in the prompting contexts
    by constructing reversed framing statements that entail the same semantic meaning.
    We then included both the original and reversed framing statements in the context.
    For example, for the original statement “You believe it is certainly true that
    ‘States with stricter gun control laws have fewer gun deaths per capita”’, the
    reversed frame stated “You believe it is certainly false that ‘States with stricter
    gun control laws have more gun deaths per capita”’. Both statements were included
    in the context in random order so the LLM cannot show increased alignment by merely
    repeating the training topic opinion. Table [2](#S5.T2 "Table 2 ‣ Alignment does
    not reflect superficial repetition. ‣ 5 Results ‣ Beyond Demographics: Aligning
    Role-playing LLM-based Agents Using Human Belief Networks") shows that the LLMs
    continue to show significant alignment with human opinions (high $\tau$ alone.'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised fine-tuning yields similar results.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As shown in Table [3](#S5.T3 "Table 3 ‣ Supervised fine-tuning yields similar
    results. ‣ 5 Results ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents
    Using Human Belief Networks"), when the agents are fine-tuned with a training
    topic $x_{\text{train}}$; the Demo+Train [same category] condition), but not on
    those belonging to a different network (Demo+Train [different category] condition)–a
    pattern of results qualitatively similar to in-context learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Cat. | Topic | Conditions for LLM Agent Construction (SFT) |'
  prefs: []
  type: TYPE_TB
- en: '| None | Demo | Demo+Train | Demo+Train |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | [Diff. Cat.] | [Same Cat.] |'
  prefs: []
  type: TYPE_TB
- en: '| Ghost |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Train | Dead Talk | 0.04 | 0.02 | 0.04 | 0.22 |'
  prefs: []
  type: TYPE_TB
- en: '| Test | Ghost | 0.03 | 0.05 | -0.08 | 0.10 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Alien Visit | -0.08 | -0.05 | -0.02 | 0.10 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Soul Walk | -0.05 | 0.06 | -0.05 | 0.14 |'
  prefs: []
  type: TYPE_TB
- en: '|  | See Future | -0.03 | 0.07 | 0.07 | 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Astrology | -0.04 | 0.06 | 0.07 | 0.06 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Roswell | -0.10 | -0.07 | 0.05 | 0.16 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Past Life | -0.02 | 0.01 | -0.02 | 0.06 |'
  prefs: []
  type: TYPE_TB
- en: '|  | The Secret | -0.01 | 0.05 | 0.05 | 0.14 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Aura | 0.03 | 0.02 | -0.07 | 0.06 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Luck | -0.04 | 0.08 | -0.06 | 0.17 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dousing | -0.02 | 0.03 | -0.07 | 0.08 |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{MAE}_{\text{test}}\downarrow$ | [2.42] | [2.54] | [2.45] | [1.65]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Partisan |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Train | Gun Control | -0.04 | 0.25 | 0.20 | 0.28 |'
  prefs: []
  type: TYPE_TB
- en: '| Test | Globe Warm | -0.09 | 0.27 | 0.02 | 0.30 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Globe Human | -0.10 | 0.30 | 0.15 | 0.30 |'
  prefs: []
  type: TYPE_TB
- en: '|  | US Deficit | 0.03 | 0.02 | 0.01 | 0.09 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Union Protection | 0.03 | 0.18 | 0.07 | 0.18 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Death Penalty | -0.14 | 0.00 | 0.00 | 0.05 |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\text{MAE}_{\text{test}}\downarrow$ | [1.42] | [1.32] | [1.71] | [1.26]
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Kendall’s $\tau$, the higher the human-LLM alignment. In particular,
    fine-tuning LLM with same-category training topic opinions significantly increases
    the alignment. The “None” and “Demo” conditions are identical to the ones in Table [1](#S4.T1
    "Table 1 ‣ 4 Experimental Settings ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks") because they are tuning-free baselines.'
  prefs: []
  type: TYPE_NORMAL
- en: 6 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Aligning human and LLM opinions.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recent studies highlight both the potential and the limitations of using LLMs
    to emulate human opinions Argyle et al. ([2023](#bib.bib1)); Santurkar et al.
    ([2023](#bib.bib20)); Sun et al. ([2024](#bib.bib22)); Feng et al. ([2023](#bib.bib10));
    Chuang et al. ([2023](#bib.bib7), [2024](#bib.bib8)). Argyle et al. ([2023](#bib.bib1))
    showed that LLMs conditioned on demographic backstories can emulate human voting
    preferences and language use, but did not investigate topic-specific opinions.
    Santurkar et al. ([2023](#bib.bib20)) found that different models have different
    inherent opinions that often align with liberal, high-income, well-educated demographics,
    and that these opinions could not be shifted by providing demographic role-playing
    information. The current paper replicates this finding, but additionally suggests
    that alignment may be shifted via belief networks. To the best of our knowledge
    no prior work has studied such effects.
  prefs: []
  type: TYPE_NORMAL
- en: Belief networks.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A great deal of prior work has studied human belief networks Boutyline and Vaisey
    ([2017](#bib.bib3)); Vlasceanu et al. ([2024](#bib.bib25)); Keating ([2023](#bib.bib15));
    Turner-Zwinkels and Brandt ([2022](#bib.bib24)); Powell et al. ([2023](#bib.bib19));
    Devine ([2015](#bib.bib9)); Jewitt and Goren ([2016](#bib.bib12)); Baldassarri
    and Goldberg ([2014](#bib.bib2)); Brandt and Sleegers ([2021](#bib.bib4)) and
    has developed a range of approaches beyond factor analysis for characterizing
    these including partial correlation networks Turner-Zwinkels and Brandt ([2022](#bib.bib24))
    or Bayesian networks Powell et al. ([2023](#bib.bib19)). Such networks have been
    shown to predict “spillover effects” of attitude changes across related topics
    Turner-Zwinkels and Brandt ([2022](#bib.bib24)); Powell et al. ([2023](#bib.bib19))
    in human participants, where a change in a given topic can ripple through the
    belief network and influence related topics. In the present study, we investigate
    whether we can leverage the belief network derived from human data to construct
    LLM agents that more accurately reflect human opinions.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We investigated the use of empirically-derived belief networks for promoting
    alignment of expressed beliefs between Large Language Model (LLM) agents and twinned
    human participants. We showed that demographic role-playing alone does not produce
    significant alignment Santurkar et al. ([2023](#bib.bib20)), but that initializing
    an agent with a human opinion on one topic then aligns opinions on nearby topics
    within the belief network. The effect does not extend to distant topics within
    the network, and varies depending the strength of the test-topic’s participation
    in the belief network. We found similar effects for in-context learning and supervised
    fine-tuning, for both a proprietary and an open-source LLM. This work highlights
    a novel and potentially powerful means of enhancing LLM agents’ alignment with
    human opinions.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The scope of topics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We considered just 18 topics derived from two orthogonal latent factors identified
    in prior work. While the Partisan topics are of public interest and the Ghost
    topics explore an orthogonal dimension, future research could greatly the scope
    of topics.
  prefs: []
  type: TYPE_NORMAL
- en: The structure of the belief network.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We considered belief networks based on two highly distinct clusters to facilitate
    evaluation. Other studies have used more sophisticated models, such as Bayesian
    networks Powell et al. ([2023](#bib.bib19)), which allow for precise predictions
    about topic interrelations. Future work could apply such methods to better characterize
    belief networks.
  prefs: []
  type: TYPE_NORMAL
- en: The actions of the LLM agents.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our LLM agents expressed their opinions through Likert-scale ratings. This facilitated
    direct comparison with human responses but may not fully capture the expression
    of opinions in real-world settings like social media communication. Future studies
    could explore more complex actions (e.g., writing social media posts) to assess
    their human-likeness in realistic applications.
  prefs: []
  type: TYPE_NORMAL
- en: Ethics Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We aim to develop LLM agents capable of simulating realistic human communicative
    dynamics, including the expression of potentially harmful beliefs such as misconception
    about the reality of global warming. Our objective is to facilitate a deeper understanding
    of social phenomena like misinformation spread in order to identify strategies
    that mitigate these challenges effectively. Note that under the current setting,
    the LLM agents only produce Likert-scale ratings from a fixed set of options.
    Therefore, they are not able to produce unexpected harmful responses. We will
    release our code base solely for research purposes, and adhere to the terms of
    use by OpenAI’s API ⁴⁴4[https://openai.com/policies/terms-of-use](https://openai.com/policies/terms-of-use)
    and their MIT license ⁵⁵5[https://github.com/openai/openai-openapi/blob/master/LICENSE](https://github.com/openai/openai-openapi/blob/master/LICENSE),
    as well as Mistral AI’s non-production license (MNPL) ⁶⁶6[https://mistral.ai/licenses/MNPL-0.1.md](https://mistral.ai/licenses/MNPL-0.1.md).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Argyle et al. (2023) Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler,
    Christopher Rytting, and David Wingate. 2023. Out of one, many: Using language
    models to simulate human samples. *Political Analysis*, 31(3):337–351.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baldassarri and Goldberg (2014) Delia Baldassarri and Amir Goldberg. 2014.
    Neither ideologues nor agnostics: Alternative voters’ belief system in an age
    of partisan politics. *American Journal of Sociology*, 120(1):45–95.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Boutyline and Vaisey (2017) Andrei Boutyline and Stephen Vaisey. 2017. Belief
    network analysis: A relational approach to understanding the structure of attitudes.
    *American journal of sociology*, 122(5):1371–1447.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brandt and Sleegers (2021) Mark J Brandt and Willem WA Sleegers. 2021. Evaluating
    belief system networks as a theory of political belief system dynamics. *Personality
    and Social Psychology Review*, 25(2):159–185.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cattell (1966) Raymond B Cattell. 1966. The scree test for the number of factors.
    *Multivariate behavioral research*, 1(2):245–276.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chase (2022) Harrison Chase. 2022. [Langchain](https://github.com/langchain-ai/langchain).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chuang et al. (2023) Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth
    Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy T Rogers.
    2023. Simulating opinion dynamics with networks of llm-based agents. *arXiv preprint
    arXiv:2311.09618*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chuang et al. (2024) Yun-Shiuan Chuang, Nikunj Harlalka, Siddharth Suresh,
    Agam Goyal, Robert D Hawkins, Sijia Yang, Dhavan V Shah, Junjie Hu, and Timothy T
    Rogers. 2024. The wisdom of partisan crowds: Comparing collective intelligence
    in humans and llm-based agents. In *ICLR 2024 Workshop on Large Language Model
    (LLM) Agents*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devine (2015) Christopher J Devine. 2015. Ideological social identity: Psychological
    attachment to ideological in-groups as a political phenomenon and a behavioral
    influence. *Political Behavior*, 37:509–535.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feng et al. (2023) Shangbin Feng, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov.
    2023. From pretraining data to language models to downstream tasks: Tracking the
    trails of political biases leading to unfair nlp models. In *Proceedings of the
    61st Annual Meeting of the Association for Computational Linguistics (Volume 1:
    Long Papers)*, pages 11737–11762.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frigo (2022) Vincent V Frigo. 2022. *An Examination of Non-Normative Belief
    Updating Behavior in Humans (Why Is It so Hard to Change Minds?)*. The University
    of Wisconsin-Madison.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jewitt and Goren (2016) Caitlin E Jewitt and Paul Goren. 2016. Ideological structure
    and consistency in the age of polarization. *American Politics Research*, 44(1):81–105.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaiser (1958) Henry F Kaiser. 1958. The varimax criterion for analytic rotation
    in factor analysis. *Psychometrika*, 23(3):187–200.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keating (2023) David M Keating. 2023. Persuasive message effects via activated
    and modified belief clusters: toward a general theory. *Human Communication Research*,
    page hqad035.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2022) OpenAI. 2022. Introducing ChatGPT. [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt).
    [Accessed 13-10-2023].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2023) Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive
    simulacra of human behavior. *arXiv preprint arXiv:2304.03442*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2022) Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2022. Social simulacra: Creating
    populated prototypes for social computing systems. In *Proceedings of the 35th
    Annual ACM Symposium on User Interface Software and Technology*, pages 1–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Powell et al. (2023) Derek Powell, Kara Weisman, and Ellen M Markman. 2023.
    Modeling and leveraging intuitive theories to improve vaccine attitudes. *Journal
    of Experimental Psychology: General*, 152(5):1379.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Santurkar et al. (2023) Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo
    Lee, Percy Liang, and Tatsunori Hashimoto. 2023. Whose opinions do language models
    reflect? In *International Conference on Machine Learning*, pages 29971–30004\.
    PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shao et al. (2023) Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. 2023.
    Character-llm: A trainable agent for role-playing. *arXiv preprint arXiv:2310.10158*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2024) Seungjong Sun, Eungu Lee, Dongyan Nan, Xiangying Zhao, Wonbyung
    Lee, Bernard J Jansen, and Jang Hyun Kim. 2024. Random silicon sampling: Simulating
    human sub-population opinion using a large language model based on group-level
    demographic information. *arXiv preprint arXiv:2402.18144*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taubenfeld et al. (2024) Amir Taubenfeld, Yaniv Dover, Roi Reichart, and Ariel
    Goldstein. 2024. Systematic biases in llm simulations of debates. *arXiv preprint
    arXiv:2402.04049*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turner-Zwinkels and Brandt (2022) Felicity M Turner-Zwinkels and Mark J Brandt.
    2022. Belief system networks can be used to predict where to expect dynamic constraint.
    *Journal of Experimental Social Psychology*, 100:104279.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vlasceanu et al. (2024) Madalina Vlasceanu, Ari M Dyckovsky, and Alin Coman.
    2024. A network approach to investigate the dynamics of individual and collective
    beliefs: Advances and applications of the bending model. *Perspectives on Psychological
    Science*, 19(2):444–453.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2023) Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei
    Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig,
    et al. 2023. Sotopia: Interactive evaluation for social intelligence in language
    agents. *arXiv preprint arXiv:2310.11667*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A List of the 64 Topics in the Belief Survey
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Table LABEL:tab:list_topic shows the full stetements of the 64 topics in the
    Belief Survey, including the topic category to which they belong according to
    the factor analysis result, along with whether they belong to the training or
    the test partition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: The statements of the 64 topics in the Belief Survey, including the
    topic category to which they belong according to the factor analysis result.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Topic Category | Topic Name | Topic Statement |'
  prefs: []
  type: TYPE_TB
- en: '| Ghost | Dead Talk | No one is able to converse with the dead. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Ghost | After someone has died it is not possible to see his or her ghost.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Alien Visit | Intelligent beings from outer space have not visited the
    Earth via spaceships. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Soul Walk | It is not possible for anyone to project their soul out of
    their body. |'
  prefs: []
  type: TYPE_TB
- en: '|  | See Future | No one is capable of having visions that accurately predict
    future events. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Astrology | The position of the planets at the time of your birth has
    no influence on your personality. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Roswell | No alien spacecraft has ever crashed near Roswell, New Mexico.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Past Life | Nobody can accurately remember living a past life. |'
  prefs: []
  type: TYPE_TB
- en: '|  | The Secret | Strongly visualizing your fondest wish does not make it more
    likely to become a reality. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Aura | Health cannot be improved by manipulating a person’s aura or electrical
    field. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Luck | “Lucky streaks” where random events are more likely to favor a
    person are not real. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dousing | Nobody can sense water using only a forked stick. |'
  prefs: []
  type: TYPE_TB
- en: '| Psychics | Pyrokinesis | Nobody can start fires just by thinking about it.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Thought Control | Nobody can control another’s actions with their mind.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Food | Food dropped on the ground for less than five seconds can become
    contaminated. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Palm Reading | It is not possible to predict future life events from markings
    on a person’s palm. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Telekinesis | No one is capable of moving objects with his or her mind.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Witches | Witches cannot influence events by using magic. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Mind Reading | No one is capable of reading another person’s thoughts.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Moon Landing | US astronauts have landed on the moon. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Crystals | Crystals do not have unexplained powers. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Lightning | Lightning can strike twice in the same place. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Alien Abd | Human beings have not been abducted by aliens from outer space.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Religion | God | God does not exist. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Prayer | Prayer cannot cure illness. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Angels | Angels are not real. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Religion Explain | Religion does not provide the most accurate explanation
    for how the universe came into existence. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Evil Spirit | It is not possible for a person’s actions to be controlled
    by an evil spirit. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Science Expl | Everything that happens can eventually be explained by
    science. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Miracles | Miracles that defy the laws of nature cannot happen. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Evolution | Species living on the Earth today have not always existed
    in their present form. |'
  prefs: []
  type: TYPE_TB
- en: '| Trump | Homicide | In the US, about 80% of white homicide victims are killed
    by white people. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Trump Inaug | More people attended the inauguration of Barack Obama than
    the inauguration of Donald Trump. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Kenya | Barack Obama was born in Hawaii. |'
  prefs: []
  type: TYPE_TB
- en: '|  | US Employment | The US unemployment rate in 2016 was lower than 40%. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Gov Reg | Government regulations do not always stifle economic growth.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Holocaust | The Nazi government in Germany murdered approximately 6 million
    Jewish people during the second world war. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Trump Votes | Hilary Clinton received the most overall votes in the 2016
    Presidential election. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Abortion | Strongly Republican states have higher rates of abortion than
    strongly Democratic states. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dem Guns | The official platform of the Democratic Party does not seek
    to repeal the 2nd Amendment. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Health Insurance | Since the Affordable Care Act (Obamacare) passed, more
    Americans have health insurance. |'
  prefs: []
  type: TYPE_TB
- en: '| Partisan | Gun Control | States with stricter gun control laws have fewer
    gun deaths per capita. |'
  prefs: []
  type: TYPE_TB
- en: '|  | US Deficit | The US deficit decreased after President Obama was elected.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Globe Human | Human activity is causing the globe to warm. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Globe Warm | The global climate is rapidly growing warmer. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Unions | States with strong union protections have lower unemployment
    than states without such protections. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Death Penalty | States that have the death penalty have higher rates of
    violent crime on average. |'
  prefs: []
  type: TYPE_TB
- en: '| Economic | US Taxes | The United States doesn’t have the highest federal
    income tax rate of any Western country. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Deport | President G. W. Bush deported fewer undocumented immigrants than
    President Obama. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Low Taxes | Lowering taxes does not always lead to economic growth. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Bailout | The rescue of big banks by the federal government aided recovery
    from the 2008 recession. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Gold Stand | Returning to the Gold Standard would make the US more vulnerable
    to a recession. |'
  prefs: []
  type: TYPE_TB
- en: '| LowInfo | Refugees | In 2016 fewer than 100,000 refugees from the Middle
    East were granted permission to live in the United States. |'
  prefs: []
  type: TYPE_TB
- en: '|  | US Crime | The violent crime rate in the US has declined over the past
    10 years. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Earth Age | The Earth is not around 6,000 years old. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Human Trex | The Tyrannosaurus Rex and humans did not live on the Earth
    at the same time. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Pub Priv | For a given level of education, private-sector workers typically
    earn more than government workers. |'
  prefs: []
  type: TYPE_TB
- en: '| Health | Bod Cleanse | A “body cleanse” in which you consume only particular
    kinds of nutrients over 1-3 days does not help your body to eliminate toxins.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Organic | Organic foods are not healthier to eat than non-organic foods.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Fasting | Regular fasting will not improve your health. |'
  prefs: []
  type: TYPE_TB
- en: '| Conspiracy | Twin Towers | The twin towers were not brought down from the
    inside by explosives during the 9/11 attack. |'
  prefs: []
  type: TYPE_TB
- en: '|  | JFK | Only one gunman was involved in the assassination of John F. Kennedy.
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Pearl Harbor | President Roosevelt did not know about the attack on Pearl
    Harbor ahead of time. |'
  prefs: []
  type: TYPE_TB
- en: '|  | Vaccinations | Vaccinations cannot cause Autism. |'
  prefs: []
  type: TYPE_TB
- en: Appendix B The Prompts for LLM Agent Construction Through In-context Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Table [5](#A2.T5 "Table 5 ‣ Appendix B The Prompts for LLM Agent Construction
    Through In-context Learning ‣ Beyond Demographics: Aligning Role-playing LLM-based
    Agents Using Human Belief Networks") shows the prompts we use to construct and
    query the LLM agents in the in-context learning setting (§[3.3](#S3.SS3 "3.3 LLM
    Agent Construction ‣ 3 Methods ‣ Beyond Demographics: Aligning Role-playing LLM-based
    Agents Using Human Belief Networks")). Different LLM agent construction conditions
    include various sets of the prompt types. The parts enclosed in curly brackets
    “$\{\}$), where they are filled with actual information from either the respondents
    or the belief survey. As shown in Figure [3](#S1.F3 "Figure 3 ‣ 1 Introduction
    ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief
    Networks") and §[3.3](#S3.SS3 "3.3 LLM Agent Construction ‣ 3 Methods ‣ Beyond
    Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks"),
    in the None condition, only the “Query” prompt is included. In the Demo condition,
    both the prompt types “Demographics” and “Query” are included. In the Demo + Train
    conditions (both [same category] and [different category]), the prompt types include
    “Demographics”, “Training Topic Opinion”, and “Query”. In the Demo + Train + Query
    condition, the prompt types include “Demographics”, “Training Topic Opinion”,
    “Query Topic Opinion”, and “Query”.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Prompt Type | Message Type (LangChain) | Prompt Template | Example |'
  prefs: []
  type: TYPE_TB
- en: '| Demographics | System Message | You are role playing a real person. You are
    a {demo_gender}. You are {demo_age} years old. The highest education You have
    completed is {demo_education}. Your race is {demo_race}. Your household income
    is {demo_income}. The population of your city is {demo_city_pop}. You would characterize
    your hometown as {demo_urban_rural}, and you are from the state of {demo_state}.
    Your political leaning is {demo_party}. | You are role playing a real person.
    You are a {Male}. You are {41} years old. The highest education You have completed
    is {Some college but no degree}. Your race is {White}. Your household income is
    {$40,000-$59,999}. The population of your city is {100,000 - 500,000}. You would
    characterize your hometown as {Urban (City)}, and you are from the state of {Florida}.
    Your political leaning is {Democrat}. |'
  prefs: []
  type: TYPE_TB
- en: '| Training Topic Opinion | System Message | You believe that {training_topic_statement
    ($x_{\text{train}}$)}. | You believe that {States with stricter gun control laws
    have fewer gun deaths per capita.} is {Probably True}. |'
  prefs: []
  type: TYPE_TB
- en: '| Query Topic Opinion | System Message | You believe that that {query_topic_statement
    ($x_{\text{query}}$)}. | You believe that {The global climate is rapidly growing
    warmer.} is {Certainly True}. |'
  prefs: []
  type: TYPE_TB
- en: '| Query | User Message | Now, what is your opinion on the following statement
    using the following scale of responses?'
  prefs: []
  type: TYPE_NORMAL
- en: '{query_topic_statement ($x_{\text{query}}$)} is Certainly True.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Statement: {query_topic_statement ($x_{\text{query}}$)}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Your opinion on the scale of responses: | Now, what is your opinion on the
    following statement using the following scale of responses?'
  prefs: []
  type: TYPE_NORMAL
- en: '{The global climate is rapidly growing warmer.} is Certainly False, {The global
    climate is rapidly growing warmer.} is Probably False, {The global climate is
    rapidly growing warmer.} is Lean False, {The global climate is rapidly growing
    warmer., Probably True that {The global climate is rapidly growing warmer.} is
    Lean True, {The global climate is rapidly growing warmer.} is Certainly True'
  prefs: []
  type: TYPE_NORMAL
- en: 'Statement: {The global climate is rapidly growing warmer.}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Your opinion on the scale of responses: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: The prompts used for the LLM agent construction and querying in the
    in-context learning setting.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C The Prompts for LLM Agent Construction Through Supervised Fine-tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Table [6](#A3.T6 "Table 6 ‣ Appendix C The Prompts for LLM Agent Construction
    Through Supervised Fine-tuning ‣ Beyond Demographics: Aligning Role-playing LLM-based
    Agents Using Human Belief Networks") shows the prompts we use to construct and
    query the LLM agents in the supervised fine-tuning setting (§[3.3](#S3.SS3 "3.3
    LLM Agent Construction ‣ 3 Methods ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks")). The demographic information is
    included in the system message in the same prompt template as in §[B](#A2 "Appendix
    B The Prompts for LLM Agent Construction Through In-context Learning ‣ Beyond
    Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks").
    For the topic-specific opinions, however, instead of including them in the prompt,
    we formulate them as (prompt, response) pairs for supervised fine-tuning, where
    prompt is the input and response is the output. The prompt templates and examples
    are shown in Table [6](#A3.T6 "Table 6 ‣ Appendix C The Prompts for LLM Agent
    Construction Through Supervised Fine-tuning ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Prompt Template | Example Prompt | Response Template | Example Response |'
  prefs: []
  type: TYPE_TB
- en: '| What is your opinion on the following statement using the following scale
    of responses?'
  prefs: []
  type: TYPE_NORMAL
- en: Certainly False that {query_topic_statement ($x_{\text{query}}$)}.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please choose your response from the following list of options: Certainly False,
    Probably False, Maybe False, Maybe True, Probably True, Certainly True. | What
    is your opinion on the following statement using the following scale of responses?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Certainly False that {States with stricter gun control laws have fewer gun
    deaths per capita}, Probably False that {States with stricter gun control laws
    have fewer gun deaths per capita}, Maybe False that {States with stricter gun
    control laws have fewer gun deaths per capita}, Maybe True that {States with stricter
    gun control laws have fewer gun deaths per capita}, Probably True that {States
    with stricter gun control laws have fewer gun deaths per capita}, Certainly True
    that {States with stricter gun control laws have fewer gun deaths per capita}
    Statement: {States with stricter gun control laws have fewer gun deaths per capita}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Please choose your response from the following list of options: Certainly False,
    Probably False, Maybe False, Maybe True, Probably True, Certainly True. | My Response:
    {opinion_response} | My Response: {Certainly True} |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: The prompts used for the LLM agent construction and querying in the
    supervised fine-tuning setting.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D The Choice of Number of Factors in Factor Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/606ebf5b25f25d80f32dabdea3ffaa3f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The scree plot of the factor analysis solution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine the number of factors to retain in our factor analysis (FA), we
    visualize the scree plot in Figure [4](#A4.F4 "Figure 4 ‣ Appendix D The Choice
    of Number of Factors in Factor Analysis ‣ Beyond Demographics: Aligning Role-playing
    LLM-based Agents Using Human Belief Networks"). We see that the explained variance
    plateaus after including 9 factors (the “elbow point”). Therefore, we decide to
    retain 9 factors.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Supervised Fine-tuning Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we elaborate the different strategies used for constructing
    LLM agents through supervised fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: a.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'None: Baseline without fine-tuning, (identical to same condition in ICL.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Demo: Baseline without fine-tuning, identical to same condition in ICL.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Demo+Train [same category]: For each topic category we constructed the dataset
    $\mathcal{D}_{\text{SFT}}=\{(d_{i},x_{\text{train},i}),o_{\text{train},i}\}_{i=1}^{N}$
    ⁷⁷7For example, we fine-tuned an LLM on the respondents’ opinions on the training
    topic for the Ghost category, then queried its opinion on the test topics in the
    Ghost category.. This is the critical condition of interest that tests cross-topic
    generalization. The verbatim prompts are in §[C](#A3 "Appendix C The Prompts for
    LLM Agent Construction Through Supervised Fine-tuning ‣ Beyond Demographics: Aligning
    Role-playing LLM-based Agents Using Human Belief Networks").'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Demo+Train [different category]: Similar to Demo+Train [same category] condition,
    but the training topic opinion ($x_{\text{train}}^{\dagger}$, allowing us to assess
    whether generalization is restricted to topics in the same belief category.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'ChatGPT (gpt-3.5-turbo-0125) is fine-tuned through OpenAI’s fine-tuning API
    ⁸⁸8[https://platform.openai.com/docs/guides/fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
    These were the hyper-parameters used in fine-tuning:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Number of Epochs: 3'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Batch Size: 1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Learning Rate Multiplier: 2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Appendix F The Full Factor Analysis Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d71f598fcc0278dda314087ccf87d31b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The factor loading matrix of the Controversial Belief Survey. The
    column indicates the nine factor, and the rows are the 64 topics. Red indicates
    topics that load highly on a factor, gray indicates near 0 loading, and blue indicates
    loading in the negative direction. We focus on the Ghost category and Partisan
    categories, highlighted by the green box and the violet box respectively. The
    topics in the Ghost category has minimal loading on the Partisan factor and vice
    versa (highlighted by the black boxes). The full statement of each topic is in
    Table LABEL:tab:list_topic (§[A](#A1 "Appendix A List of the 64 Topics in the
    Belief Survey ‣ Beyond Demographics: Aligning Role-playing LLM-based Agents Using
    Human Belief Networks")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Beyond Demographics: Aligning
    Role-playing LLM-based Agents Using Human Belief Networks") in the main text,
    we only show the factor loading matrix of the Ghost and the Partisan factors,
    and the corresponding topics. In this section, we discuss the full factor analysis
    result.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The factor analysis reveals nine latent factors underlying the 64 topics. Figure [5](#A6.F5
    "Figure 5 ‣ Appendix F The Full Factor Analysis Results ‣ Beyond Demographics:
    Aligning Role-playing LLM-based Agents Using Human Belief Networks") shows the
    full factor loading matrix. The red blocks highlight strong correlations among
    opinions within each factor, indicating that endorsing one conception in a cluster
    often predicts opinion in other conceptions within the same cluster. We assign
    the name of each factor based on its constituent topics: Ghost, Psychics, Religion,
    Trump, Partisan, Economic, LowInfo, Health, and Conspiracy. The 64 topics are
    categorized by which factor they have the highest loadings on. For instance, the
    topic about communication with the dead belongs to the Ghost category because
    it has the highest loading on the Ghost factor (Table LABEL:tab:list_topic shows
    the full list of topics and categories).'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix G Compute Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We ran all experiments with Mistral on a GPU machine equipped with 1x NVIDIA
    A100\. The experiments with ChatGPT cost about 300 USD.
  prefs: []
  type: TYPE_NORMAL
