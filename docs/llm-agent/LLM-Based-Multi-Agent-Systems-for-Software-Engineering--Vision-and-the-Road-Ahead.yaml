- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:48:48'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road
    Ahead'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.04834](https://ar5iv.labs.arxiv.org/html/2404.04834)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Junda He [jundahe@smu.edu.sg](mailto:jundahe@smu.edu.sg) Singapore Management
    University80 Stamford Rd.178902SingaporeSingapore ,  Christoph Treude [ctreude@smu.edu.sg](mailto:ctreude@smu.edu.sg)
    Singapore Management University80 Stamford Rd.178902SingaporeSingapore  and  David
    Lo [davidlo@smu.edu.sg](mailto:davidlo@smu.edu.sg) Singapore Management University80
    Stamford Rd.178902SingaporeSingapore
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Integrating Large Language Models (LLMs) into autonomous agents marks a significant
    shift in the research landscape by offering cognitive abilities competitive to
    human planning and reasoning. This paper envisions the evolution of LLM-based
    Multi-Agent (LMA) systems in addressing complex and multi-faceted software engineering
    challenges. LMA systems introduce numerous benefits, including enhanced robustness
    through collaborative cross-examination, autonomous problem-solving, and scalable
    solutions to complex software projects. By examining the role of LMA systems in
    future software engineering practices, this vision paper highlights the potential
    applications and emerging challenges. We further point to specific opportunities
    for research and conclude with a research agenda with a set of research questions
    to guide future research directions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Large Language Models, Autonomous Agents, Multi-Agent Systems, Software Engineering^†^†conference:
    International Workshop on Software Engineering in 2030; November 2024; Porto de
    Galinhas (Brazil)'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Autonomous agents, defined as intelligent entities that autonomously perform
    specific tasks through environmental perception, strategic self-planning, and
    action execution (Franklin and Graesser, [1996](#bib.bib14); Albrecht and Stone,
    [2018](#bib.bib6); Mele, [2001](#bib.bib31)), have emerged as a rapidly expanding
    research field since the 1990s (Maes, [1993](#bib.bib30)). Despite initial advancements,
    these early iterations often lack the sophistication of human intelligence (Unland,
    [2015](#bib.bib37)). However, the recent advent of Large Language Models (LLMs) (Kasneci
    et al., [2023](#bib.bib24)) has marked a turning point. This LLM breakthrough
    has demonstrated cognitive abilities nearing human levels in planning and reasoning (Achiam
    et al., [2023](#bib.bib4); Kasneci et al., [2023](#bib.bib24)), which aligns with
    the expectations for autonomous agents. As a result, there is an increased research
    interest in integrating LLMs at the core of autonomous agents (Lo, [2023](#bib.bib29);
    Xi et al., [2023](#bib.bib45); Wang et al., [2023b](#bib.bib39)) (for short, we
    refer to them as LLM-based agents in this paper).
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, the application of singular LLM-based agents encounters limitations,
    since real-world problems often span multiple domains, requiring expertise from
    various fields. In response to this challenge, developing LLM-Based Multi-Agent
    (LMA) systems represents a pivotal evolution, aiming to boost performance via
    synergistic collaboration. An LMA system harnesses the strengths of multiple specialized
    agents, each with unique skills and responsibilities. These agents work in concert
    towards a common goal, engaging in collaborative activities like debate and discussion.
    These collaborative mechanisms have been proven to be instrumental in encouraging
    divergent thinking (Liang et al., [2023](#bib.bib28)), enhancing factuality and
    reasoning (Du et al., [2023](#bib.bib12)), and ensuring thorough validation (Wu
    et al., [2023b](#bib.bib43)). As a result, LMA systems hold promise in addressing
    a wide range of complicated real-world scenarios across various sectors (Horton,
    [2023](#bib.bib21); Wang et al., [2023c](#bib.bib38), [a](#bib.bib40)), such as
    software engineering (Lo, [2023](#bib.bib29); Qian et al., [2023](#bib.bib33);
    Li et al., [2024](#bib.bib27); Hong et al., [2023](#bib.bib20)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The study of software engineering (SE) focuses on the entire lifecycle of software
    systems (Kan, [2003](#bib.bib23)), including stages like requirements elicitation (Goguen
    and Linde, [1993](#bib.bib15)), development (Abrahamsson et al., [2017](#bib.bib3)),
    and quality assurance (Tian, [2005](#bib.bib36)), among others. This multifaceted
    discipline requires a broad spectrum of knowledge and skills to effectively tackle
    its inherent challenges in each stage. Integrating LMA systems into software engineering
    introduces numerous benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Robustness and Fault Tolerance: LMA systems address robustness issues through
    cross-examination in decision-making, akin to code reviews and automated testing
    frameworks, thus detecting and correcting faults early in the development process.
    On their own, LLMs may produce unreliable outputs, known as hallucination (Zhang
    et al., [2023](#bib.bib48); Yang et al., [2023](#bib.bib47)), which can lead to
    bugs or system failure in software development. However, by employing methods
    like debating, examining, or validating responses from multiple agents, LMA systems
    ensure convergence on a single, more accurate and robust solution. This enhances
    the system’s reliability, error handling, and aligns with best practices in software
    quality assurance.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Autonomous Problem-Solving: LMA systems can bring significant autonomy to SE
    tasks. It is an intuitive approach to divide high-level requirements into sub-tasks
    and detailed implementation, which mirrors agile and iterative methodologies (Larman,
    [2004](#bib.bib26)) where tasks are broken down and assigned to specialized teams
    or individuals. By automating this process, developers are freed to focus on strategic
    planning, design thinking, and innovation.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scalability to Complex Systems: The growth in complexity of software systems,
    with increasing lines of code, frameworks, and interdependencies, demands scalable
    solutions in project management and development practices. LMA systems offer an
    effective scaling solution by incorporating additional agents for new technologies
    and reallocating tasks among agents based on evolving project needs. LMA systems
    ensure that complex projects, which may be overwhelming for individual developers
    or traditional teams, can be managed effectively through distributed intelligence
    and collaborative agent frameworks.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Existing research has illuminated the critical roles of these collaborative
    agents in advancing toward the era of Software Engineering 2.0 (Lo, [2023](#bib.bib29)).
    LMA systems are expected to significantly speed up software development and drive
    innovation, marking a major shift in software engineering practices. This article
    aims to delve deeper into the roles of LMA systems in shaping the future of software
    engineering, spotlighting potential applications, emerging challenges, and the
    vital collaboration between academia and industry to harness these advancements
    fully. Furthermore, we present a comprehensive research agenda, which enumerates
    a series of research questions to direct subsequent research efforts.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Preliminary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1\. Autonomous Agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An autonomous agent is a computational entity designed for independent and
    effective operation in dynamic environments (Mele, [2001](#bib.bib31)). Its essential
    attributes are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Autonomy: Independently manages its actions and internal state without external
    controls.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perception: Detects the changes in the surrounding environment through sensory
    mechanisms.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Intelligence and Goal-Driven: Aims for specific goals using domain-specific
    knowledge and problem-solving abilities.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Social Ability: Can interact with humans or other agents, manages social relationships
    to achieve goals.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Learning Capabilities: Continuously adapts, learns, and integrates new knowledge
    and experiences.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2.2\. LLM-based Autonomous Agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Formally speaking, an LLM-based agent can be described by the tuple $\langle
    L,O,M,A,R\rangle$ (Cheng et al., [2024](#bib.bib10)), where:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: $L$ symbolizes the Large Language Model, serving as the agent’s cognitive core.
    It is usually equipped with extensive, potentially domain-specific, knowledge,
    enabling it to make informed decisions from observations, feedback, and rewards.
    Typically, an LLM possesses significant zero-shot or few-shot learning capabilities,
    and we interact with the LLM with prompts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: $O$ stands for the Objective, the desired outcome or goal the agent aims to
    achieve. This defines the agent’s focus, driving its strategic planning and task
    breakdown.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: $M$ represents Memory, which holds information on both historical and current
    states, as well as feedback from external interactions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: $A$ signifies Action, encompassing the range of executions of the agent, from
    utilizing tools to communicating with other agents.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: $R$ refers to Rethink, a post-action reflective thinking process that evaluates
    the results and feedback, along with stored memories. Guided by this insight,
    the LLM-based agent then takes subsequent actions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2.3\. LLM-Based Multi-Agent Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In contrast to single-agent systems, a Multi-Agent system places a greater
    emphasis on coordination, communication, and knowledge sharing among agents. LMA
    systems are especially suited for complex tasks that require expertise across
    various knowledge domains. In this paper, we define that a Multi-Agent system,
    particularly an LLM-Based Multi-Agent system, includes two primary elements: an
    orchestration platform and LLM-based agents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Orchestration Platform: The platform serves as the core infrastructure that
    manages interaction and information flow among agents. It is designed to ensure
    efficient operation and communication within the LMA system through several key
    functions: *Agent Profiling:* As we desire a broad spectrum of expertise, agents
    are defined with unique abilities and actions, fitting specific roles within the
    system. Profiles may be explicitly pre-defined (Qian et al., [2023](#bib.bib33);
    Hong et al., [2023](#bib.bib20)) or dynamically generated by LLMs (Wang et al.,
    [2023b](#bib.bib39)).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Communication Mechanisms:* Specifically, these communication mechanisms include:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Communication Paradigms: Styles of interaction, such as Cooperative (i.e.,
    agents work together towards a shared goal) (Abdelnabi et al., [2023](#bib.bib2)),
    Debate (i.e., agents engage in discussions to challenge and refine ideas) (Li
    et al., [2024](#bib.bib27)), and Competitive (i.e., agents have conflicting objectives
    and compete against each other) (Wu et al., [2024](#bib.bib44)).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Communication Structure: The organization of communication channels, which
    can be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $-$
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Decentralized: Agents communicate directly with each other without a central
    controlling authority (Chen et al., [2023](#bib.bib9)).'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: $-$
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Centralized: A central agent facilitates communication between all other agents (Agashe,
    [2023](#bib.bib5)).'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: $-$
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hierarchical: With clear layers of authority and responsibility, information
    flows from higher to lower levels (Zhao et al., [2024](#bib.bib49)).'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: $-$
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nested: Communication structures are embedded within one another, combining
    characteristics of hierarchical, decentralized, and centralized systems (Han et al.,
    [2024](#bib.bib17)).'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Communication Content: The actual data exchanged among agents, often in text
    form. In the context of software engineering, this may be programming languages,
    commit messages (Zhou et al., [2023](#bib.bib50)), Stack Overflow posts (He et al.,
    [2022](#bib.bib18)), etc.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'LLM-based agents: We focus on the scenarios where agents within the Multi-Agent
    systems are powered with LLMs. Leveraging LLMs’ feedback integration capabilities,
    agents can engage in meaningful dialogues, enhancing cooperation and performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Current Development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we review the current applications of LMA agents in the software
    engineering domains.
  prefs: []
  type: TYPE_NORMAL
- en: Software Development. Several works have applied LMA systems in software development.
    Li et al. introduce a pioneering communicative Multi-Agent framework named role-playing (Li
    et al., [2024](#bib.bib27)) with exceptional performance in code generation. ChatDev (Qian
    et al., [2023](#bib.bib33)) divides the development process into designing, coding,
    testing, and documentation phases, with specialized teams of software agents,
    such as programmers and test engineers. Experiment results demonstrate that ChatDev
    can finalize the development of an application in less than seven minutes with
    a cost below one dollar. MetaGPT (Hong et al., [2023](#bib.bib20)) embeds Standardized
    Operating Procedures (SOPs) (Belbin and Brown, [2022](#bib.bib7)) into its workflow
    and further includes roles like product manager and QA Engineer. Subsequent studies
    have further explored the impact of role differentiation among LLM-based agents
    on collaborative software development  (Dong et al., [2023](#bib.bib11); Huang
    et al., [2023](#bib.bib22)).
  prefs: []
  type: TYPE_NORMAL
- en: Frameworks. Numerous open-source repositories have been developed, which offer
    developers the means to customize and refine these agents for distinct tasks.
    AutoGen (Wu et al., [2023a](#bib.bib42)) is an open-source framework that enables
    the creation of LMA applications through customizable, conversable agents that
    integrate LLMs, human inputs, and executable tools with flexible conversation
    patterns. Langroid (langroid contributors, [2024](#bib.bib25)) implements its
    Multi-Agent pipeline based on the Actor Framework (Hewitt et al., [1973](#bib.bib19)).
    Moreover, frameworks like LangChain (Chase, [2022](#bib.bib8)), OpenAgents (Xie
    et al., [2023](#bib.bib46)), AutoGPT (Significant Gravitas, [[n. d.]](#bib.bib35))
    and GPT-Engineer (Osika, [2023](#bib.bib32)), can also be adaptable for use in
    LMA systems, despite being originally designed on single-agent applications.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Research Agenda
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previous research has laid the groundwork for the exploration of LMA systems
    in software engineering, yet this domain remains in its nascent stages, with many
    critical challenges awaiting resolution. In this section, we outline our perspective
    on these challenges and suggest research questions that could advance this burgeoning
    field. We envision two phases for the development of LMA in software engineering.
    We discuss each of these phases below and suggest a series of research questions
    that could form the basis of future research projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Phase 1: Enhancing Individual Agent Capabilities'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Indeed, the effectiveness of an LMA system is closely linked to the capabilities
    of its individual agents. This first phase is dedicated to improving these agents’
    skills, with a particular focus on adaptability and the acquisition of specialized
    skills in SE. The potential of individual LLM-based agents in SE is further explored
    through our initial research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What SE roles are suitable for LLM-based agents to play and how can their abilities
    be enhanced to represent these roles?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to design an effective, flexible, and robust prompting language that enhances
    LLM-based agents’ capabilities?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Refining Role-playing Capabilities in SE. The capability of the LLM-based agents
    for role-playing is pivotal under an LMA system. These agents demonstrate proficiency
    in simulating well-recognized roles, but they may not accurately represent specialized
    SE roles, such as blockchain developers and DevOps Engineers. This shortfall arises
    from their training on general text corpora, which typically lack the specialized
    content necessary to grasp the nuanced expertise required in SE. To address this
    limitation, we propose a structured three-step approach encompassing the identification,
    selection, and enhancement of role-playing abilities.
  prefs: []
  type: TYPE_NORMAL
- en: The initial step focuses on identifying key SE roles, prioritizing those with
    high industry demand, significant complexity, and the potential to substantially
    boost productivity. This involves a detailed analysis of the SE sector’s current
    trends and needs, utilizing market reports, job postings, and industry forecasts
    to identify roles where LLM-based agents can offer the greatest value. The process
    concludes with value addition modeling, which evaluates potential efficiency gains,
    cost reductions, and the acceleration of innovation, informing the selection of
    roles for LLM-based agents.
  prefs: []
  type: TYPE_NORMAL
- en: Progressing to the second step, the focus shifts towards understanding the limitations
    of LLM-based agents against the demands of identified SE roles. Through competency
    mapping, this phase evaluates the agents’ proficiency in essential skills such
    as code generation, architecture design, and project management. By employing
    real-world software engineering tasks, we can accurately assess the agents’ performance
    and identify specific areas where their skills may be lacking. Furthermore, consultations
    with software engineering professionals and academics are instrumental in refining
    the capabilities of LLM-based agents. These discussions uncover the complex needs
    of specialized roles that training data may not fully represent, guiding targeted
    improvements in the agents’ skill sets.
  prefs: []
  type: TYPE_NORMAL
- en: The last step is to tailor the LLM-based agents’ to effectively represent the
    identified SE roles. This requires creating specialized training datasets that
    reflect the unique requirements of each role for fine-tuning. Specifically, it
    involves collecting materials from open-source code repositories, technical forums,
    and detailed software documentation to build a comprehensive corpus for training
    agents. Additionally, we can design customized prompts that enhance the adaptability
    of LLM-based agents to specific SE roles.
  prefs: []
  type: TYPE_NORMAL
- en: Advancing Prompts through Agent-oriented Programming Paradigms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In previous sections, we highlight that well-crafted prompts can substantially
    enhance an LLM-based agent’s performance, including the agents’ abilities in planning,
    reasoning, communication, and mitigating the issue of hallucinations. Yet, crafting
    prompts for LLM-based agents is particularly challenging. The complexity lies
    in developing a versatile, effective, and robust prompt framework that is suitable
    across various scenarios and roles. Currently, this area of research is still
    largely unexplored and urgently requires the development of an advanced prompting
    language designed to augment the cognitive functions of LLM-based agents. Introducing
    Agent-Oriented Programming (AOP) (Shoham, [1993](#bib.bib34)) into the realm of
    LLM-based agents holds promising potential. Similar to objects in Object-Oriented
    Programming (OOP) (Wegner, [1990](#bib.bib41)), AOP is a paradigm that treats
    agents as fundamental programming units. This approach emphasizes defining agents’
    reasoning mechanisms, objectives, and methods of cooperation. By adopting AOP,
    we can craft a more refined prompting language, one that facilitates the articulation
    of complex, detailed instructions alongside specific constraints, This, in turn,
    will empower LLM-based agents to execute their designated roles with heightened
    efficiency and precision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Phase Two: Optimizing Agent Synergy'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In Phase Two, the spotlight turns towards optimizing agent synergy, underscoring
    the importance of collaboration and how to leverage the diverse strengths of individual
    agents. This phase delves into both the internal dynamics among agents and the
    role of external human intervention in enhancing the efficacy of the LMA system.
    Key research questions guiding this phase include:'
  prefs: []
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to best allocate tasks between humans and LLM-based agents?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to scale LMA systems for large-scale projects?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (5)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What industrial organization mechanisms can be applied to LMA systems?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (6)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What strategies allow LMA systems to dynamically adjust their approach?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (7)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to ensure security among private data sharing within LMA systems?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Human-Agent Collaboration Strategically allocating tasks between humans and
    LMA agents to exploit their distinct strengths is crucial. Humans bring to the
    table unparalleled creativity, critical thinking, and ethical insight. Conversely,
    LMA agents are adept at swiftly processing extensive data sets, executing repetitive
    tasks with exceptional precision, and uncovering patterns that might escape human
    notice. Identifying the most effective roles for humans, optimizing the provision
    of human feedback, and determining the appropriate moments for human intervention
    in agent collaborations pose significant challenges. Furthermore, developing predictive
    models to ascertain the ideal human-to-agent ratio across various project types
    and stages is another fundamental concern. Such models need to evaluate project
    complexity, time restrictions, project priorities, and the particular capabilities
    and limitations of both human participants and LMA agents. As a result, it ensures
    that tasks are allocated to fully harness both human creativity and agent efficiency
    within the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaling Up for Complex Projects. Current applications of LMA systems are limited
    to small-scale software projects (Qian et al., [2023](#bib.bib33); Hong et al.,
    [2023](#bib.bib20)), however, transitioning to complex projects introduces several
    challenges: First, as software projects grow in size and complexity, breaking
    down high-level requirements into manageable sub-tasks for agents becomes increasingly
    difficult. Global planning and task allocation become more complicated since the
    variability and randomness in tasks escalate. Second, expanding projects necessitate
    a larger team of agents. This increase complicates the communication network,
    introducing challenges in coordination among agents. Such issues can lead to misinformation,
    threatening the resultant outcome of the LMA system. Furthermore, extensive information
    exchange strains memory and computational resources. A larger team of agents also
    implies more rounds of discussion are needed, which can significantly prolong
    the decision-making process. To address these challenges, innovative solutions
    in architectural design are required. These solutions should focus on facilitating
    efficient and reliable information exchange within the expanded LMA systems, ensuring
    the timely and effective completion of tasks. Streamlining communication and coordination
    among a growing number of agents, while managing the increased computational demands,
    are key to scaling LMA systems for complex software projects effectively.'
  prefs: []
  type: TYPE_NORMAL
- en: Industrial Inspiration. The organizational strategies employed by industrial
    companies in structuring their development teams offer valuable lessons for LMA
    system design. Just as these companies adjust team sizes, roles, and project management
    approaches in response to shifting project landscapes, LMA systems can adopt similar
    adaptive mechanisms to remain agile and effective. For example, we can draw inspiration
    from agile development practices, and emulating iterative development models.
    LMA systems can implement mechanisms for incremental changes and continuous learning,
    allowing for gradual adaptation without overhauling the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic Adaptation. Given the complexity and variability of different software
    tasks, predicting the optimal configuration for LMA systems at the task’s outset
    is unrealistic. It therefore demands the system to dynamically adjust its scale
    and strategies while developing. This includes the ability to automatically modify
    the number of agents, redefine their roles, reallocate memory and computational
    resources, and modify communication methods in response to the development progress.
    Furthermore, as software projects inevitably change requirements, the adaptability
    of LMA systems to these changes becomes crucial. Through evaluating existing solutions
    and identifying reusable elements, LMA systems should be able to minimize redundant
    work. LMA systems should continuously learn from each cycle of development, identifying
    patterns, efficiencies, and inefficiencies. This learning enables the system to
    make informed decisions about how to approach similar tasks in the future or adapt
    existing solutions to meet new requirements. Moreover, the inherent uncertainty
    in the software development process poses another challenge in defining effective
    termination conditions of LMA systems. Relying solely on pre-defined termination
    conditions may not always be feasible, as these conditions might lead to infinite
    loops or premature task termination, hindering potential improvements. To address
    this, another critical research direction is the dynamic control of task termination.
    Possible solutions include implementing a monitoring model that continuously assesses
    the progress of tasks against their objectives. These models dynamically adjust
    their criteria for task completion based on real-time analysis, and may also escalate
    for human intervention judiciously, allowing for continuous refinement and optimization
    of outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy and Partial Information. In multi-organization projects, data often
    resides in silos, leading to the need for specific agents to access sensitive
    information while ensuring privacy. This necessitates robust access control mechanisms
    that prevent unauthorized access but also address the varied data access needs
    among agents. Establishing protocols for agents to share insights from sensitive
    data without revealing the data itself is essential. Research could focus on applying
    differential privacy (Dwork, [2006](#bib.bib13)) and secure multi-party computation (Goldreich,
    [1998](#bib.bib16)) to enable involvement in collective decision-making without
    breaching privacy. Additionally, investigating integrated data storage for non-sensitive
    information could help minimize redundancy and achieve system-wide consistency.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Conclusion and Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In conclusion, this paper outlines a structured research agenda to advance LMA
    integration in SE. Future work will concentrate on addressing the set of critical
    research questions identified, with a focus on enhancing LMA capabilities and
    optimizing their synergy within software development processes.
  prefs: []
  type: TYPE_NORMAL
- en: In the immediate term, efforts will be dedicated to enhancing the capabilities
    of LLM-based agents in representing specialized SE roles. This will involve creating
    specialized datasets and pre-training tasks that mirror the complex realities
    of SE tasks. Additionally, there will be a focus on formulating advanced prompting
    strategies, which can refine the agents’ cognitive functions and decision-making
    skills. Looking towards the longer-term objectives, the emphasis will transition
    towards optimizing the synergy between agents. The initial step involves examining
    optimal strategies for task allocation between humans and LLM-based agents, capitalizing
    on the unique strengths of both entities. Further, we need to delve into developing
    scalable methodologies for LMA systems, enabling LMA systems to efficiently orchestrate
    and complete large-scale, multifaceted SE projects. Furthermore, ensuring the
    privacy and confidentiality of data within LMA systems is critical. This entails
    exploring data management and access control mechanisms to protect sensitive information
    while still enabling the essential exchange of insights among project stakeholders.
    By systematically exploring these research questions, our goal is to drive innovation
    in LMA systems for software engineering, aiming to create a more cohesive, effective,
    and flexible LMA-driven development process.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abdelnabi et al. (2023) Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea
    Schönherr, and Mario Fritz. 2023. Llm-deliberation: Evaluating llms with interactive
    multi-agent negotiation games. *arXiv preprint arXiv:2309.17234* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abrahamsson et al. (2017) Pekka Abrahamsson, Outi Salo, Jussi Ronkainen, and
    Juhani Warsta. 2017. Agile software development methods: Review and analysis.
    *arXiv preprint arXiv:1709.08439* (2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. 2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*
    (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agashe (2023) Saaket Agashe. 2023. *LLM-Coordination: Developing Coordinating
    Agents with Large Language Models*. University of California, Santa Cruz.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Albrecht and Stone (2018) Stefano V Albrecht and Peter Stone. 2018. Autonomous
    agents modelling other agents: A comprehensive survey and open problems. *Artificial
    Intelligence* 258 (2018), 66–95.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belbin and Brown (2022) R Meredith Belbin and Victoria Brown. 2022. *Team roles
    at work*. Routledge.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chase (2022) Harrison Chase. 2022. *LangChain*. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023) Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, and
    Chuchu Fan. 2023. Scalable multi-robot collaboration with large language models:
    Centralized or decentralized systems? *arXiv preprint arXiv:2309.15943* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cheng et al. (2024) Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng,
    Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, et al. 2024.
    Exploring Large Language Model based Intelligent Agents: Definitions, Methods,
    and Prospects. *arXiv preprint arXiv:2401.03428* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dong et al. (2023) Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. 2023. Self-collaboration
    Code Generation via ChatGPT. *arXiv preprint arXiv:2304.07590* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum,
    and Igor Mordatch. 2023. Improving factuality and reasoning in language models
    through multiagent debate. *arXiv preprint arXiv:2305.14325* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dwork (2006) Cynthia Dwork. 2006. Differential privacy. In *International colloquium
    on automata, languages, and programming*. Springer, 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Franklin and Graesser (1996) Stan Franklin and Art Graesser. 1996. Is it an
    Agent, or just a Program?: A Taxonomy for Autonomous Agents. In *International
    workshop on agent theories, architectures, and languages*. Springer, 21–35.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goguen and Linde (1993) Joseph A Goguen and Charlotte Linde. 1993. Techniques
    for requirements elicitation. In *[1993] Proceedings of the IEEE International
    Symposium on Requirements Engineering*. IEEE, 152–164.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goldreich (1998) Oded Goldreich. 1998. Secure multi-party computation. *Manuscript.
    Preliminary version* 78, 110 (1998), 1–108.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Han et al. (2024) Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo
    Xu, and Chaoyang He. 2024. LLM Multi-Agent Systems: Challenges and Open Problems.
    *arXiv preprint arXiv:2402.03578* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. (2022) Junda He, Bowen Xu, Zhou Yang, DongGyun Han, Chengran Yang,
    and David Lo. 2022. Ptm4tag: sharpening tag recommendation of stack overflow posts
    with pre-trained models. In *Proceedings of the 30th IEEE/ACM International Conference
    on Program Comprehension*. 1–11.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hewitt et al. (1973) Carl Hewitt, Peter Boehler Bishop, and Richard Steiger.
    1973. A Universal Modular ACTOR Formalism for Artificial Intelligence. In *Proceedings
    of the 3rd International Joint Conference on Artificial Intelligence. Standford,
    CA, USA, August 20-23, 1973*, Nils J. Nilsson (Ed.). William Kaufmann, 235–245.
    [http://ijcai.org/Proceedings/73/Papers/027B.pdf](http://ijcai.org/Proceedings/73/Papers/027B.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al.
    2023. Metagpt: Meta programming for multi-agent collaborative framework. *arXiv
    preprint arXiv:2308.00352* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Horton (2023) John J Horton. 2023. *Large language models as simulated economic
    agents: What can we learn from homo silicus?* Technical Report. National Bureau
    of Economic Research.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2023) Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck, and
    Heming Cui. 2023. AgentCoder: Multi-Agent-based Code Generation with Iterative
    Testing and Optimisation. *arXiv preprint arXiv:2312.13010* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kan (2003) Stephen H Kan. 2003. *Metrics and models in software quality engineering*.
    Addison-Wesley Professional.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kasneci et al. (2023) Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria
    Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnemann,
    Eyke Hüllermeier, et al. 2023. ChatGPT for good? On opportunities and challenges
    of large language models for education. *Learning and individual differences*
    103 (2023), 102274.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'langroid contributors (2024) The langroid contributors. 2024. langroid: A Language
    Model Framework. [https://github.com/langroid/langroid](https://github.com/langroid/langroid).
    Accessed: 2024-03-20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Larman (2004) Craig Larman. 2004. *Agile and iterative development: a manager’s
    guide*. Addison-Wesley Professional.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2024) Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin,
    and Bernard Ghanem. 2024. Camel: Communicative agents for” mind” exploration of
    large language model society. *Advances in Neural Information Processing Systems*
    36 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2023) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023. Encouraging divergent
    thinking in large language models through multi-agent debate. *arXiv preprint
    arXiv:2305.19118* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lo (2023) David Lo. 2023. Trustworthy and Synergistic Artificial Intelligence
    for Software Engineering: Vision and Roadmaps. *arXiv preprint arXiv:2309.04142*
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maes (1993) Pattie Maes. 1993. Modeling adaptive autonomous agents. *Artificial
    life* 1, 1_2 (1993), 135–162.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mele (2001) Alfred R Mele. 2001. *Autonomous agents: From self-control to autonomy*.
    Oxford University Press, USA.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Osika (2023) Anton Osika. 2023. *gpt-engineer*. [https://github.com/gpt-engineer-org/gpt-engineer](https://github.com/gpt-engineer-org/gpt-engineer)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qian et al. (2023) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shoham (1993) Yoav Shoham. 1993. Agent-oriented programming. *Artificial intelligence*
    60, 1 (1993), 51–92.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Significant Gravitas ([n. d.]) Significant Gravitas. [n. d.]. *AutoGPT*. [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tian (2005) Jeff Tian. 2005. *Software quality engineering: testing, quality
    assurance, and quantifiable improvement*. John Wiley & Sons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unland (2015) Rainer Unland. 2015. Software agent systems. In *Industrial Agents*.
    Elsevier, 3–22.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023c) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023c. Voyager: An open-ended
    embodied agent with large language models. *arXiv preprint arXiv:2305.16291* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023b) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023b. A Survey
    on Large Language Model based Autonomous Agents. CoRR abs/2308.11432 (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023a) Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian
    Ma, and Yitao Liang. 2023a. Describe, explain, plan and select: Interactive planning
    with large language models enables open-world multi-task agents. *arXiv preprint
    arXiv:2302.01560* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wegner (1990) Peter Wegner. 1990. Concepts and paradigms of object-oriented
    programming. *ACM Sigplan Oops Messenger* 1, 1 (1990), 7–87.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2023a) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun
    Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023a. AutoGen:
    Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework. *CoRR*
    abs/2308.08155 (2023). [https://doi.org/10.48550/ARXIV.2308.08155](https://doi.org/10.48550/ARXIV.2308.08155)
    arXiv:2308.08155'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2023b) Yiran Wu, Feiran Jia, Shaokun Zhang, Qingyun Wu, Hangyu Li,
    Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, and Chi Wang. 2023b. An empirical
    study on challenging math problem solving with gpt-4. *arXiv preprint arXiv:2306.01337*
    (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2024) Zengqing Wu, Shuyuan Zheng, Qianying Liu, Xu Han, Brian Inhyuk
    Kwon, Makoto Onizuka, Shaojie Tang, Run Peng, and Chuan Xiao. 2024. Shall We Talk:
    Exploring Spontaneous Collaborations of Competing LLM Agents. *arXiv preprint
    arXiv:2402.12327* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. 2023. The rise and
    potential of large language model based agents: A survey. *arXiv preprint arXiv:2309.07864*
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xie et al. (2023) Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng,
    Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, Leo Z. Liu, Yiheng Xu,
    Hongjin Su, Dongchan Shin, Caiming Xiong, and Tao Yu. 2023. OpenAgents: An Open
    Platform for Language Agents in the Wild. arXiv:2310.10634 [cs.CL]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023) Chengran Yang, Jiakun Liu, Bowen Xu, Christoph Treude, Yunbo
    Lyu, Ming Li, and David Lo. 2023. APIDocBooster: An Extract-Then-Abstract Framework
    Leveraging Large Language Models for Augmenting API Documentation. *arXiv preprint
    arXiv:2312.10934* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023) Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen
    Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. 2023. Siren’s song
    in the AI ocean: a survey on hallucination in large language models. *arXiv preprint
    arXiv:2309.01219* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2024) Zhonghan Zhao, Kewei Chen, Dongxu Guo, Wenhao Chai, Tian
    Ye, Yanting Zhang, and Gaoang Wang. 2024. Hierarchical Auto-Organizing System
    for Open-Ended Multi-Agent Navigation. *arXiv preprint arXiv:2403.08282* (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2023) Xin Zhou, Bowen Xu, DongGyun Han, Zhou Yang, Junda He, and
    David Lo. 2023. CCBERT: Self-Supervised Code Change Representation Learning. In
    *2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)*.
    IEEE, 182–193.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
