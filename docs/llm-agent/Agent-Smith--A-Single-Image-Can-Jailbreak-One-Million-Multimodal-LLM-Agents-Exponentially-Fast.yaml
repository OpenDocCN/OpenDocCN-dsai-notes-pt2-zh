- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:52:51'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents
    Exponentially Fast'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.08567](https://ar5iv.labs.arxiv.org/html/2402.08567)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Xiangming Gu    Xiaosen Zheng    Tianyu Pang    Chao Du    Qian Liu    Ye Wang
       Jing Jiang    Min Lin
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A multimodal large language model (MLLM) agent can receive instructions, capture
    images, retrieve histories from memory, and decide which tools to use. Nonetheless,
    red-teaming efforts have revealed that adversarial images/prompts can jailbreak
    an MLLM and cause unaligned behaviors. In this work, we report an even more severe
    safety issue in multi-agent environments, referred to as infectious jailbreak.
    It entails the adversary simply jailbreaking a single agent, and without any further
    intervention from the adversary, (almost) all agents will become infected *exponentially
    fast* and exhibit harmful behaviors. To validate the feasibility of infectious
    jailbreak, we simulate multi-agent environments containing up to *one million*
    LLaVA-1.5 agents, and employ randomized pair-wise chat as a proof-of-concept instantiation
    for multi-agent interaction. Our results show that feeding an (infectious) adversarial
    image into the memory of any randomly chosen agent is sufficient to achieve infectious
    jailbreak. Finally, we derive a simple principle for determining whether a defense
    mechanism can provably restrain the spread of infectious jailbreak, but how to
    design a practical defense that meets this principle remains an open question
    to investigate. Our code is available at [https://github.com/sail-sg/Agent-Smith](https://github.com/sail-sg/Agent-Smith).
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning, ICML\icmlauthorplaceholder
  prefs: []
  type: TYPE_NORMAL
- en: to1
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="p4.pic1" class="ltx_picture" height="102.32" overflow="visible" version="1.1"
    width="97.42"><g transform="translate(0,102.32) matrix(1 0 0 -1 0 0) translate(-59.33,0)
    translate(0,-902.91) matrix(1.0 0.0 0.0 1.0 63.94 907.52)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><foreignobject width="88.2" height="93.1" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">![[Uncaptioned image]](img/7fe65098ae5950e2596fadd23a18564b.png)</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/aaaed15aa6b28f1089270196a5f96a45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: We simulate a randomized pair-wise chatting environment containing
    *one million* LLaVA-1.5 agents. In the $0$ chat rounds, and all infected agents
    exhibit harmful behaviors.'
  prefs: []
  type: TYPE_NORMAL
- en: Recently, multimodal large language models (MLLMs) have demonstrated promising
    performance, particularly in vision-language tasks (Alayrac et al., [2022](#bib.bib1);
    Liu et al., [2023d](#bib.bib41); Dai et al., [2023](#bib.bib13)). However, several
    red-teaming reports have shown that adversarial images and/or prompts can jailbreak
    an MLLM, resulting in harmful behaviors (Zhao et al., [2023](#bib.bib88); Carlini
    et al., [2023](#bib.bib9); Zou et al., [2023](#bib.bib91); Chao et al., [2023](#bib.bib11)).
  prefs: []
  type: TYPE_NORMAL
- en: Despite significant concerns raised by the jailbreaking reports, the rapid development
    of MLLM agents continues unabated (Brohan et al., [2023](#bib.bib5); Driess et al.,
    [2023](#bib.bib17); Yang et al., [2023a](#bib.bib78)). These MLLM agents are being
    integrated into robots or virtual assistants, granted memory banks and the ability
    to use tools, in line with the growing trend of deploying MLLM agents in manufacturing
    or daily life.
  prefs: []
  type: TYPE_NORMAL
- en: In this study, we show that reckless large-scale deployments of MLLM agents
    lead to far more severe issues than previously thought. Specifically, we present
    infectious jailbreak, a new jailbreaking paradigm developed for multi-agent environments
    in which, analogous to the modeling of infectious diseases, an adversary need
    only jailbreak a single agent to infect (almost) all other agents *exponentially
    fast*. Infectious jailbreak exploits the interaction between agents to induce
    infected agents to inject the adversarial image into memory banks of benign (not
    infected) agents. Significantly, this induced infectiousness does not necessitate
    any external intervention from adversaries and is automatically achieved through
    the universality of the crafted adversarial image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to assess the viability of infectious jailbreak, we use randomized
    pair-wise chat as a proof-of-concept instantiation for multi-agent interaction
    and formalize the resulting infectious dynamics in ideal conditions. We conduct
    multi-agent simulations containing up to *one million* LLaVA-1.5 agents equipped
    with memory banks (Liu et al., [2023b](#bib.bib39)). Our empirical results show
    that injecting an adversarial image into a single agent is sufficient to closely
    resemble the ideal infectious dynamics, in which the remaining benign agents are
    infected exponentially fast, as demonstrated in Figure [1](#S1.F1 "Figure 1 ‣
    1 Introduction ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal
    LLM Agents Exponentially Fast").'
  prefs: []
  type: TYPE_NORMAL
- en: We also conduct ablation studies to investigate the effectiveness of infectious
    jailbreak under various scenarios and hyperparameters, such as the balance of
    infection and recovery rates, different perturbation budgets/attack types, chat
    diversity, and the impact of common corruptions that can occur when storing images
    in memory. Although the spread rate of infectious jailbreak appears unstoppable,
    we demonstrate that there is a simple principle for determining whether a defense
    can provably restrain the spread of infectious jailbreak. How to design a practical
    defense that meets this principle remains an open and urgent question to investigate.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We primarily introduce related work on jailbreaking LLMs and MLLMs, deferring
    full discussions to Appendix [A](#A1 "Appendix A Related Work (Full Version) ‣
    Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially
    Fast").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d16c8ebbad5f0a5d3b22d3d17266ced3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Pipelines of randomized pairwise chat and infectious jailbreak. *(Bottom
    left)* An MLLM agent consists of four components: an MLLM $\mathcal{M}$. Please
    see Algorithm [1](#alg1 "Algorithm 1 ‣ 3.1 Infectious Dynamics of Randomized Pairwise
    Chat ‣ 3 Simulating Multi-Agent Environments ‣ Agent Smith: A Single Image Can
    Jailbreak One Million Multimodal LLM Agents Exponentially Fast") for detailed
    formulations of pairwise chat and Appendix [C](#A3 "Appendix C Instantiation of
    Our Multi-agent System ‣ Agent Smith: A Single Image Can Jailbreak One Million
    Multimodal LLM Agents Exponentially Fast") for the complete system prompts used
    in our experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: Jailbreaking LLMs. LLMs such as ChatGPT/GPT-4 (OpenAI, [2023](#bib.bib47)) and
    LLaMA 2 (Touvron et al., [2023](#bib.bib69)) are typically aligned to generate
    helpful and harmless responses to human queries, following the training pipeline
    of human/AI alignment (Ouyang et al., [2022](#bib.bib48); Ganguli et al., [2022](#bib.bib21);
    Bai et al., [2022](#bib.bib3); Korbak et al., [2023](#bib.bib29)). However, recent
    research has shown that LLMs can be jailbroken to generate objectionable content
    by either manually designed or automatically crafted prompts (Zou et al., [2023](#bib.bib91);
    Liu et al., [2023f](#bib.bib43); Rao et al., [2023](#bib.bib56); Li et al., [2023c](#bib.bib35);
    Zhu et al., [2023](#bib.bib90); Lapid et al., [2023](#bib.bib30); Liu et al.,
    [2023e](#bib.bib42); Chao et al., [2023](#bib.bib11)). Moreover, Tian et al. ([2023](#bib.bib67))
    investigate the safety issues of LLM-based agents; Wei et al. ([2023](#bib.bib73))
    hypothesize that the vulnerability of aligned LLMs to jailbreaking is attributed
    to the competing objectives of capability and safety, as well as the mismatch
    between pretraining and safety training; Carlini et al. ([2023](#bib.bib9)) attribute
    the vulnerability to neural networks’ fundamental weakness in dealing with adversarial
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: Jailbreaking MLLMs. Aside from generating adversarial prompts to jailbreak LLMs,
    there is another line of red-teaming work to attack the alignment of MLLMs using
    adversarial images (Zhang et al., [2022](#bib.bib87); Zhao et al., [2023](#bib.bib88);
    Qi et al., [2023a](#bib.bib52); Bailey et al., [2023](#bib.bib4); Tu et al., [2023](#bib.bib71);
    Shayegani et al., [2023](#bib.bib62); Yin et al., [2023](#bib.bib83)). Specifically,
    on discriminative tasks, adversarial images could be crafted to fool classifiers
    by adding human imperceptible perturbations guided by the victim model’s input
    gradients (Goodfellow et al., [2014](#bib.bib22); Dong et al., [2018](#bib.bib15);
    Xie et al., [2019](#bib.bib77); Long et al., [2022](#bib.bib44)). In addition
    to $\ell_{p}$-norm threat model, there are other types of attacks that manipulate
    adversarial patches (Brown et al., [2017](#bib.bib7)) or adversarial framing (Zajac
    et al., [2019](#bib.bib85)). Within the context of MLLMs, Schlarmann & Hein ([2023](#bib.bib61))
    demonstrate that OpenFlamingo (Awadalla et al., [2023](#bib.bib2)) can be fooled
    into performing poorly on image captioning and VQA tasks with very minor perturbations;
    Zhao et al. ([2023](#bib.bib88)) provide a quantitative analysis of the adversarial
    robustness of various MLLMs by producing adversarial images that trick the models
    into generating specific responses; Dong et al. ([2023](#bib.bib16)) demonstrate
    that adversarial images crafted on open-source models could be transferred to
    mislead Bard (Google, [2023](#bib.bib23)).
  prefs: []
  type: TYPE_NORMAL
- en: 3 Simulating Multi-Agent Environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We formalize the infectious dynamics of randomized pairwise chat in a multi-agent
    environment. Then, we show how we implement the pairwise chat between two MLLM
    agents and describe the universal conditions of infectious jailbreak.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Infectious Dynamics of Randomized Pairwise Chat
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We now formalize the infectious mechanism of randomized pairwise chat among
    $N$ is odd.
  prefs: []
  type: TYPE_NORMAL
- en: Randomized pairwise chat. In the $t$.
  prefs: []
  type: TYPE_NORMAL
- en: Infected agents. An agent is considered *infected* if *(i)* it carries infectious
    virus and *(ii)* it exhibits symptoms that poses harmful questions $\mathbf{Q}^{\textrm{harm}}$
    while being part of the answering group.
  prefs: []
  type: TYPE_NORMAL
- en: Infectious dynamics. We regard the occurrence of virus infection and the appearance
    of symptoms as independent, meaning that an agent carrying the virus has a chance
    of $\alpha$ to recover during each chat round. Formally, the infectious transmission
    and recovery can be formulated as
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | $\displaystyle P\left(\mathcal{I}_{t}^{s}(\mathcal{G}_{n})=1\Big{&#124;}\mathcal{I}_{t}^{c}(\mathcal{G}_{n})=1\right)=\alpha\textrm{;}$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle P\left(\mathcal{I}_{t+1}^{c}(\mathcal{G}_{k}^{\textrm{A}})=1\Big{&#124;}\mathcal{I}_{t}^{c}(\mathcal{G}_{k}^{\textrm{Q}})=1,\mathcal{I}_{t}^{c}(\mathcal{G}_{k}^{\textrm{A}})=0\right)=\beta\textrm{;}$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle P\left(\mathcal{I}_{t+1}^{c}(\mathcal{G}_{n})=0\Big{&#124;}\mathcal{I}_{t}^{c}(\mathcal{G}_{n})=1\right)=\gamma\textrm{,}$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where we use the subscript $n$, and here we regard them as amortized values
    and treat them as constants.
  prefs: []
  type: TYPE_NORMAL
- en: Let $p_{t}\in[0,1]$ and
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $p_{t}=P\left(\mathcal{I}_{t}^{s}(\mathcal{G}_{n})=1,\mathcal{I}_{t}^{c}(\mathcal{G}_{n})=1\right)=\alpha
    c_{t}\textrm{.}$ |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: Now we derive the infectious dynamics of how $p_{t}$ can be formulated as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $c_{t+1}=\left(1-\gamma\right)c_{t}+\frac{\Delta_{t}}{N}\textrm{,}$ |  |
    (5) |'
  prefs: []
  type: TYPE_TB
- en: where $\Delta_{t}\sim B(\frac{N}{2},\beta c_{t}\left(1-c_{t}\right))$, we further
    convert this difference equation into its corresponding differential equation
    as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\frac{dc_{t}}{dt}=\frac{\beta c_{t}\left(1-c_{t}\right)}{2}-\gamma c_{t}\textrm{,}$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: where $t\in\mathbb{R}^{+}$ can be written as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $c_{t}=\frac{c_{0}\left(\beta-2\gamma\right)}{\left(\beta-2\gamma-c_{0}\beta\right)\cdot\exp{\left(-\frac{\left(\beta-2\gamma\right)t}{2}\right)}+c_{0}\beta}\textrm{.}$
    |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: 'As can be observed, there is $\lim_{t\rightarrow\infty}c_{t}=1-\frac{2\gamma}{\beta}$).
    The derived theory fits our simulations (see Figure [7](#A2.F7 "Figure 7 ‣ Appendix
    B Complementary Derivations of Infectious Dynamics ‣ Agent Smith: A Single Image
    Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Remark I (when $c_{0}=\frac{1}{N}$ can be calculated as (see Eq. ([13](#A2.E13
    "Equation 13 ‣ Appendix B Complementary Derivations of Infectious Dynamics ‣ Agent
    Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially
    Fast")))'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $T=\frac{2}{\beta-2\gamma}\left[\log N+\log\frac{c_{T}(\beta-2\gamma)}{(\beta-2\gamma-c_{T}\beta)}\right]\textrm{.}$
    |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: This means that the number of chat rounds $T$ more chat rounds compared to infecting
    one million agents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remark II (provable defenses). Although the rapid spread of infectious virus
    among agents appears to be unstoppable, the aforementioned analyses also provide
    us a clear guideline on how to design provable robust against infectious virus:
    just ensure that $\beta\leq 2\gamma$.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 Pairwise chat between two MLLM agents
  prefs: []
  type: TYPE_NORMAL
- en: '1:  System prompts: the pairwise chat progress is mainly pushed forward by
    three system prompts ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{V}}}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Randomized Pairwise Chat among MLLM Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The entire pipeline of a pairwise chat between two MLLM agents are summarized
    in Algorithm [1](#alg1 "Algorithm 1 ‣ 3.1 Infectious Dynamics of Randomized Pairwise
    Chat ‣ 3 Simulating Multi-Agent Environments ‣ Agent Smith: A Single Image Can
    Jailbreak One Million Multimodal LLM Agents Exponentially Fast") and visualized
    in Figure [2](#S2.F2 "Figure 2 ‣ 2 Related Work ‣ Agent Smith: A Single Image
    Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast"). Specifically,
    an MLLM agent $\mathcal{G}=(\mathcal{M},\mathcal{R};\mathcal{H},\mathcal{B})$.'
  prefs: []
  type: TYPE_NORMAL
- en: The MLLM $\mathcal{M}$) share the same model backbone (e.g., LLaVA-1.5), but
    are customized by setting role-playing prompts such as name, gender, and personality.
  prefs: []
  type: TYPE_NORMAL
- en: Memory banks $\mathcal{H}$ are implemented as first-in-first-out (FIFO) queues
    with fixed maximum lengths. If a queue is full (has reached its maximum length),
    we will dequeue the earliest text or image before adding new ones.
  prefs: []
  type: TYPE_NORMAL
- en: The RAG module $\mathcal{R}$ (Radford et al., [2021](#bib.bib55)), respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 How to Achieve Infectious Jailbreak
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The key of achieving infectious jailbreak is to exploit *memory banks* and
    *multi-agent interaction*. Ideally, we aim to generate an adversarial image ${\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | $\displaystyle\forall\mathbf{P},\textrm{if }{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}}\in{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{B}^{\textrm{Q}}},\textrm{then
    }{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}}={\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{R}^{\textrm{Q}}}(\mathbf{P},{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{B}^{\textrm{Q}}})\textrm{;}$
    |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle\forall{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{H}^{\textrm{Q}}},\textrm{there
    is }\mathbf{Q}^{\textrm{harm}}={\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{M}^{\textrm{Q}}}([{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{H}^{\textrm{Q}}},{\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{Q}}}],{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}})\textrm{;}$
    |  | (10) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle\forall{\color[rgb]{1,.5,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,.5,0}\mathcal{H}^{\textrm{A}}},\textrm{there
    is }\mathbf{A}^{\textrm{harm}}={\color[rgb]{1,.5,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,.5,0}\mathcal{M}^{\textrm{A}}}([{\color[rgb]{1,.5,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,.5,0}\mathcal{H}^{\textrm{A}}},{\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{A}}},\mathbf{Q}^{\textrm{harm}}],{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}})\textrm{,}$
    |  | (11) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{Q}^{\textrm{harm}}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nonetheless, practically crafted adversarial images (even using advanced techniques)
    would not perfectly satisfy the universal conditions in Eqs. ([9](#S3.E9 "Equation
    9 ‣ 3.3 How to Achieve Infectious Jailbreak ‣ 3 Simulating Multi-Agent Environments
    ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents
    Exponentially Fast")-[11](#S3.E11 "Equation 11 ‣ 3.3 How to Achieve Infectious
    Jailbreak ‣ 3 Simulating Multi-Agent Environments ‣ Agent Smith: A Single Image
    Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast")), so the
    equivalent values of $\alpha$), and vice versa.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We conduct comprehensive analyses in multi-agent environments, showing that
    infectious jailbreak results in an exponentially higher infection ratio than noninfectious
    baselines.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Basic Setups
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Multi-agent environments. We implement multi-agent environments by initializing
    $N$, as detailed in Figure [10](#A3.F10 "Figure 10 ‣ Appendix C Instantiation
    of Our Multi-agent System ‣ Agent Smith: A Single Image Can Jailbreak One Million
    Multimodal LLM Agents Exponentially Fast"), to push forward the chatting process
    among agents. We implement each agent utilizing LLaVA-1.5 (Liu et al., [2023c](#bib.bib40),
    [b](#bib.bib39)) as the MLLM and CLIP (Radford et al., [2021](#bib.bib55)) as
    the RAG module. More concretely, we employ LLaVA-1.5 7B and CLIP ViT-L/224px in
    the main paper, while additional experiments on LLaVA-1.5 13B are detailed in
    Appendix [E.2](#A5.SS2 "E.2 Infectious Jailbreak on LLaVA-1.5-13B ‣ Appendix E
    More Experiments ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal
    LLM Agents Exponentially Fast"). For reproducibility, we employ greedy decoding
    to generate textual content during chats. As depicted in Figure [11](#A3.F11 "Figure
    11 ‣ Appendix C Instantiation of Our Multi-agent System ‣ Agent Smith: A Single
    Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast"), without
    jailbreaking, the agents typically generate benign responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Harmful datasets. We first evaluate LLaVA-1.5’s alignment and default tendency
    to generate harmful responses. To finish this, we directly input the $574$, including
    JSON strings for function calling (see Appendix [E.3](#A5.SS3 "E.3 Harmful Function
    Calling. ‣ Appendix E More Experiments ‣ Agent Smith: A Single Image Can Jailbreak
    One Million Multimodal LLM Agents Exponentially Fast")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Noninfectious jailbreaking baselines. To justify the significance of our infectious
    jailbreak, we also evaluate several noninfectious jailbreaking baselines in multi-agent
    environments (more details can be found in Appendix [D](#A4 "Appendix D Implementation
    of Jailbreak Methods ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal
    LLM Agents Exponentially Fast")). *Visual prompt injection (VP)*: For GPT-4V,
    it is discovered that the image context can override textual prompts and be interpreted
    as executable commands (Timbrell, [2023](#bib.bib68)). To utilize this, we fabricate
    ${\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}}$
    chat rounds. Furthermore, when taking into account the agents’ recovery rate,
    the maximum number of agents that can be jailbroken via sequential strategy is
    limited by image albums’ size.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b0dceb5450c5439ccef7c3e229047ec9.png)![Refer to caption](img/cf5d76d32c505e35e517b594c966178e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: *(Left)* Cumulative infection ratio curves of different methods.
    For the noninfectious baselines that we consider (VP, TP, Seq. stands for Sequential),
    none of them can achieve infectious jailbreak on the multi-agent system. Both
    VP and TP even cannot jailbreak any single agent. In contrast, our method can
    jailbreak the multi-agent system exponentially fast. *(Right)* Cumulative infection
    ratio curves of $N=256$ that reaches the same infection ratio.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Cumulative/current infection ratio (%) at the $16$. Div. stands for
    diversity.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Attack | Budget | Div. | Cumulative |  | Current |'
  prefs: []
  type: TYPE_TB
- en: '| $p_{8}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Border | $h=6$ | low | 23.05 | 93.75 | 99.61 | 14.00 | 15.00 | 17.00 |  |
    14.06 | 90.62 | 99.06 | 16.00 | 16.00 | 19.00 |'
  prefs: []
  type: TYPE_TB
- en: '| high | 16.72 | 88.98 | 99.53 | 15.80 | 16.80 | 18.40 |  |   9.53 | 81.48
    | 98.05 | 17.20 | 19.00 | 20.08 |'
  prefs: []
  type: TYPE_TB
- en: '| $h=8$ | low | 23.05 | 93.75 | 99.61 | 14.00 | 15.00 | 17.00 |  | 14.06 |
    90.62 | 99.22 | 16.00 | 16.00 | 19.00 |'
  prefs: []
  type: TYPE_TB
- en: '| high | 20.94 | 91.95 | 99.61 | 15.20 | 16.20 | 17.40 |  | 12.03 | 86.64 |
    98.44 | 16.40 | 17.40 | 19.20 |'
  prefs: []
  type: TYPE_TB
- en: '| Pixel | $\ell_{\infty}$ | low | 23.05 | 93.75 | 99.61 | 14.00 | 15.00 | 17.00
    |  | 14.06 | 90.39 | 98.67 | 16.00 | 16.20 | 19.00 |'
  prefs: []
  type: TYPE_TB
- en: '| high | 17.11 | 89.30 | 99.53 | 15.60 | 16.60 | 17.80 |  | 10.16 | 82.19 |
    97.97 | 17.00 | 18.00 | 19.80 |'
  prefs: []
  type: TYPE_TB
- en: '| $\ell_{\infty}$ | low | 23.05 | 93.75 | 99.61 | 14.00 | 15.00 | 17.00 |  |
    14.06 | 90.62 | 99.22 | 16.00 | 16.00 | 19.00 |'
  prefs: []
  type: TYPE_TB
- en: '| high | 17.66 | 88.20 | 99.53 | 15.60 | 16.60 | 17.60 |  | 10.47 | 82.42 |
    98.75 | 16.60 | 17.60 | 19.40 |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/9ec006b4bbcd07c1ae57c7dd2df2bdb1.png)![Refer to caption](img/cb4f2f8e8271490dce9499ea4d90a1cc.png)![Refer
    to caption](img/9d763cfc457c2719f8760fd5208c30ff.png)![Refer to caption](img/53d20ac3186824e5064ec3f59b160027.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Case Study. *(Top)* Cumulative/current infection ratio (%) at the
    $t$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our infectious jailbreaking method. We ensemble the chat records sampled from
    a multi-agent system without jailbreaking ($N=64$ following Dong et al. ([2018](#bib.bib15))
    and then enqueue the generated image into the album of a single agent to start
    the infectious jailbreak. Implementations are detailed in Appendix [D](#A4 "Appendix
    D Implementation of Jailbreak Methods ‣ Agent Smith: A Single Image Can Jailbreak
    One Million Multimodal LLM Agents Exponentially Fast").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Infection ratios. In the process of infectious jailbreak, we record both the
    cumulative and current ratios of infected agents. *Cumulative infection ratio*:
    The ratio of agents that have at least once generated the specific harmful question
    $\mathbf{Q}^{\textrm{harm}}$ are taken into account to determine the success of
    jailbreaking.'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation metrics. We apply two metrics to evaluate the jailbreaking efficiency.
    *Infection ratio $p_{t}$).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Simulation of Infectious Jailbreak
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 2: Cumulative/current infection ratio (%) at the $16$.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | Text histories memory bank $&#124;\mathcal{H}&#124;$ |'
  prefs: []
  type: TYPE_TB
- en: '| Attack | Budget | $&#124;\mathcal{H}&#124;$ | Cumulative |  | Current |'
  prefs: []
  type: TYPE_TB
- en: '| $p_{16}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Border | $h=6$ | 3 | 85.62 | 16.60 |  | 78.12 | 18.40 |  | 2 | 76.17 | 19.40
    |  | 53.75 | 23.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 93.12 | 16.00 |  | 87.81 | 17.20 |  | 6 | 92.81 | 16.00 |  | 88.28 |
    17.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 92.73 | 15.60 |  | 86.72 | 17.60 |  | 10 | 85.62 | 16.60 |  | 78.12
    | 18.40 |'
  prefs: []
  type: TYPE_TB
- en: '| $h=8$ | 3 | 93.12 | 15.80 |  | 88.91 | 16.80 |  | 2 | 78.05 | 18.60 |  |
    56.09 | 23.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 93.59 | 15.80 |  | 89.69 | 16.80 |  | 6 | 93.52 | 15.40 |  | 90.16 |
    16.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 93.28 | 15.60 |  | 89.45 | 16.60 |  | 10 | 93.12 | 15.80 |  | 88.91
    | 16.80 |'
  prefs: []
  type: TYPE_TB
- en: '| Pixel | $\ell_{\infty}\textrm{,}\,\epsilon=\frac{8}{255}$ | 3 | 91.17 | 16.20
    |  | 85.47 | 18.00 |  | 2 | 67.58 | 20.40 |  | 44.14 | 23.80 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 88.75 | 16.60 |  | 80.31 | 18.80 |  | 6 | 91.48 | 16.20 |  | 85.70 |
    18.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 89.06 | 16.80 |  | 78.44 | 19.40 |  | 10 | 91.17 | 16.20 |  | 85.47
    | 18.00 |'
  prefs: []
  type: TYPE_TB
- en: '| $\ell_{\infty}\textrm{,}\,\epsilon=\frac{16}{255}$ | 3 | 93.52 | 15.60 |  |
    89.69 | 16.60 |  | 2 | 75.94 | 19.40 |  | 52.58 | 23.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 90.94 | 16.20 |  | 86.25 | 17.40 |  | 6 | 93.75 | 15.20 |  | 90.08 |
    16.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 91.17 | 15.80 |  | 85.78 | 17.00 |  | 10 | 93.52 | 15.60 |  | 89.69
    | 16.60 |'
  prefs: []
  type: TYPE_TB
- en: Comparing jailbreaking methods. We conduct simulations in a new multi-agent
    system with unseen agent customization. We set $N=256$ chat rounds, exhibiting
    a linear rate of infection. Our method demonstrates efficacy, achieving infection
    of all agents at an exponential rate, markedly surpassing the baselines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scaling up $N$-th chat round, as visualized in Figure [1](#S1.F1 "Figure 1
    ‣ 1 Introduction ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal
    LLM Agents Exponentially Fast") and [17](#A5.F17 "Figure 17 ‣ E.1 Scaling up 𝑁
    to over one million (full version) ‣ Appendix E More Experiments ‣ Agent Smith:
    A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast").'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Simulation under Higher Textual Chat Diversity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Chat diversity. To augment the challenge of infectious jailbreak, we modify
    the system prompts ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{V}}}$.
    We differentiate the aforementioned scenario and this new scenario. *Low diversity
    scenario*: The chat process of a multi-agent system is pushed by the system prompts
    in Figure [10](#A3.F10 "Figure 10 ‣ Appendix C Instantiation of Our Multi-agent
    System ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM
    Agents Exponentially Fast"). This scenario is characterized by brevity in agent
    interactions and low textual chat diversity as shown in Figure [11](#A3.F11 "Figure
    11 ‣ Appendix C Instantiation of Our Multi-agent System ‣ Agent Smith: A Single
    Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast"). *High
    diversity scenario*: The system prompts in Figure [12](#A3.F12 "Figure 12 ‣ Appendix
    C Instantiation of Our Multi-agent System ‣ Agent Smith: A Single Image Can Jailbreak
    One Million Multimodal LLM Agents Exponentially Fast"), which encourage agents
    to play their roles, are employed to drive agents’ interactions. This scenario
    generally demonstrates high textual chat diversity as shown in Figure [13](#A3.F13
    "Figure 13 ‣ Appendix C Instantiation of Our Multi-agent System ‣ Agent Smith:
    A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Infectious dynamics under different diversities. We evaluate our jailbreak
    method on both low and high diversity scenarios under different attack types and
    perturbation budgets. As shown in Table [1](#S4.T1 "Table 1 ‣ 4.1 Basic Setups
    ‣ 4 Experiments ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal
    LLM Agents Exponentially Fast"), we employ various metrics to represent the infectious
    dynamics. Notably, the high diversity scenario poses a greater challenge, evidenced
    by generally lower infection ratios at specific chat rounds and longer chat rounds
    required to reach particular infection thresholds. Despite these challenges, our
    method maintains its effectiveness, with the ratios of current and cumulative
    infected agents nearing $100\%$ are not only indicative of the effectiveness of
    infectious jailbreak but also serve to highlight the differences between these
    scenarios. Thus these two metrics will be the primary focus of subsequent experimental
    analyses. We also consider the high diversity scenario as default.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Failure cases. In our simulations, we find several failure cases in high diversity
    scenarios with small perturbation budgets, such as $h<6$ defined in Eq. ([1](#S3.E1
    "Equation 1 ‣ 3.1 Infectious Dynamics of Randomized Pairwise Chat ‣ 3 Simulating
    Multi-Agent Environments ‣ Agent Smith: A Single Image Can Jailbreak One Million
    Multimodal LLM Agents Exponentially Fast")) and Eq. ([2](#S3.E2 "Equation 2 ‣
    3.1 Infectious Dynamics of Randomized Pairwise Chat ‣ 3 Simulating Multi-Agent
    Environments ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal
    LLM Agents Exponentially Fast")). Firstly, we establish methods to compute them.'
  prefs: []
  type: TYPE_NORMAL
- en: Computing $\beta_{t}$-th chat round.
  prefs: []
  type: TYPE_NORMAL
- en: Computing $\alpha_{t}^{\textrm{Q}}$ for answering agents.
  prefs: []
  type: TYPE_NORMAL
- en: Further analyses on failure cases. We visualize the dynamics of $\alpha_{t}^{\textrm{Q}}$.
    A closer examination of the chat records reveals that virus-carrying agents often
    produce content similar to, but not exactly matching the harmful targets. Additionally,
    agents may also add irrelevant text. This discrepancy suggests that the exact
    match criteria used in Zou et al. ([2023](#bib.bib91)) might underestimate the
    actual effectiveness of infectious jailbreak.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3ce27664c23022a3857ab8017ef3a1ae.png)![Refer to caption](img/aa3758245dd3daebde527dba6e48089e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Cumulative/current infection ratio (%) at the $16$.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Ablation Studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Increasing $|\mathcal{H}|$. As evidenced in Table [2](#S4.T2 "Table 2 ‣ 4.2
    Simulation of Infectious Jailbreak ‣ 4 Experiments ‣ Agent Smith: A Single Image
    Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast") (see Table [3](#A5.T3
    "Table 3 ‣ E.2 Infectious Jailbreak on LLaVA-1.5-13B ‣ Appendix E More Experiments
    ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents
    Exponentially Fast") for full results), the increase of the text histories memory
    bank does not significantly alter the infectious dynamics. This observation underscores
    the robustness and universality of our adversarial examples, even in the context
    of varying lengths of text histories.'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing $|\mathcal{B}|$, there is a slight decrease in the infected ratio by
    the 16-th chat round. This phenomenon can be attributed to a diminished retrieval
    success rate, owing to the prevalence of benign images in the album.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing $M$, regardless of the type of attack implemented. Notably, even with
    a limited number of chat records, attackers may achieve significant infection
    ratios. This finding underscores the potential severity of the infectious jailbreak
    even in scenarios with constrained data resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'With image corruptions. Dziugaite et al. ([2016](#bib.bib19)); Xie et al. ([2017](#bib.bib76))
    have demonstrated that image corruption can, to some extent, defend against adversarial
    attacks. In the multi-agent system, wherever agents receive and process images,
    random corruption can happen and affect the effectiveness of adversarial examples.
    To counter such corruption, we implement three image augmentations when crafting
    adversarial examples: *(i)* random resize, where the size of ${\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}}$.
    To conclude, various image corruptions may challenge but not stop the infectious
    jailbreak.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/396b2a06c0e91b621460f64789391706.png)![Refer to caption](img/3480c02756a283cd1a2578b29d01ba70.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Cumulative/current infection ratio (%) at the $t$.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In contrast to noninfectious jailbreak, infectious jailbreak effectively utilizes
    the multi-agent interaction and memory storage, resulting in amortized computational
    and time expenses for jailbreaking. To jailbreak almost all $N$ chat rounds).
    This previously unnoticed safety issue necessitates immediate efforts to develop
    provable defenses.
  prefs: []
  type: TYPE_NORMAL
- en: Impact Statements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This study, encompassing both the methodology and the provided code, includes
    elements that could enable users to infectiously jailbreak almost all the multimodal
    agents in a multi-agent system to generate harmful content and even trigger harmful
    behaviors by function calling exponentially fast. Although our major experiments
    are conducted on a proof-of-concept instantiation for the multi-agent system,
    it does provide insights for more realistic cases. For example, there has been
    a growing interest in operating systems constructed around multimodal large language
    models, which receive screenshots as visual signals and perform subsequent actions (Yang
    et al., [2023c](#bib.bib80); Hong et al., [2023b](#bib.bib25)). If an attack is
    injected into any part of a screenshot such as the app icon, and is spread among
    agents, it could result in significant problems. During user interactions with
    the model, this could potentially entice the model into generating harmful actions
    (e.g., rm -rf /*), leading to serious societal consequences. How to design a practical
    defense for our infectious jailbreak method remains an open and urgent question.
    In summary, our work serves as a red-teaming report, identifying previously unnoticed
    safety issues in multi-agent environments and advocating for further investigation
    into defense design.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Alayrac et al. (2022) Alayrac, Jean-Baptiste, Donahue, Jeff, Luc, Pauline,
    Miech, Antoine, Barr, Iain, Hasson, Yana, Lenc, Karel, Mensch, Arthur, Millican,
    Katherine, Reynolds, Malcolm, et al. Flamingo: a visual language model for few-shot
    learning. In *Advances in Neural Information Processing Systems (NeurIPS)*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Awadalla et al. (2023) Awadalla, Anas, Gao, Irena, Gardner, Josh, Hessel, Jack,
    Hanafy, Yusuf, Zhu, Wanrong, Marathe, Kalyani, Bitton, Yonatan, Gadre, Samir,
    Sagawa, Shiori, et al. Openflamingo: An open-source framework for training large
    autoregressive vision-language models. *arXiv preprint arXiv:2308.01390*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bai et al. (2022) Bai, Yuntao, Jones, Andy, Ndousse, Kamal, Askell, Amanda,
    Chen, Anna, DasSarma, Nova, Drain, Dawn, Fort, Stanislav, Ganguli, Deep, Henighan,
    Tom, et al. Training a helpful and harmless assistant with reinforcement learning
    from human feedback. *arXiv preprint arXiv:2204.05862*, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bailey et al. (2023) Bailey, Luke, Ong, Euan, Russell, Stuart, and Emmons,
    Scott. Image hijacks: Adversarial images can control generative models at runtime.
    *arXiv preprint arXiv:2309.00236*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brohan et al. (2023) Brohan, Anthony, Brown, Noah, Carbajal, Justice, Chebotar,
    Yevgen, Chen, Xi, Choromanski, Krzysztof, Ding, Tianli, Driess, Danny, Dubey,
    Avinava, Finn, Chelsea, et al. Rt-2: Vision-language-action models transfer web
    knowledge to robotic control. *arXiv preprint arXiv:2307.15818*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Brown, Tom, Mann, Benjamin, Ryder, Nick, Subbiah, Melanie,
    Kaplan, Jared D, Dhariwal, Prafulla, Neelakantan, Arvind, Shyam, Pranav, Sastry,
    Girish, Askell, Amanda, et al. Language models are few-shot learners. In *Advances
    in Neural Information Processing Systems (NeurIPS)*, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2017) Brown, Tom B, Mané, Dandelion, Roy, Aurko, Abadi, Martín,
    and Gilmer, Justin. Adversarial patch. *arXiv preprint arXiv:1712.09665*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bubeck et al. (2023) Bubeck, Sébastien, Chandrasekaran, Varun, Eldan, Ronen,
    Gehrke, Johannes, Horvitz, Eric, Kamar, Ece, Lee, Peter, Lee, Yin Tat, Li, Yuanzhi,
    Lundberg, Scott, et al. Sparks of artificial general intelligence: Early experiments
    with gpt-4. *arXiv preprint arXiv:2303.12712*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carlini et al. (2023) Carlini, Nicholas, Nasr, Milad, Choquette-Choo, Christopher A,
    Jagielski, Matthew, Gao, Irena, Koh, Pang Wei, Ippolito, Daphne, Tramèr, Florian,
    and Schmidt, Ludwig. Are aligned neural networks adversarially aligned? In *Advances
    in Neural Information Processing Systems (NeurIPS)*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chan et al. (2023) Chan, Chi-Min, Chen, Weize, Su, Yusheng, Yu, Jianxuan, Xue,
    Wei, Zhang, Shanghang, Fu, Jie, and Liu, Zhiyuan. Chateval: Towards better llm-based
    evaluators through multi-agent debate. *arXiv preprint arXiv:2308.07201*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chao et al. (2023) Chao, Patrick, Robey, Alexander, Dobriban, Edgar, Hassani,
    Hamed, Pappas, George J, and Wong, Eric. Jailbreaking black box large language
    models in twenty queries. *arXiv preprint arXiv:2310.08419*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023) Chen, Weize, Su, Yusheng, Zuo, Jingwei, Yang, Cheng, Yuan,
    Chenfei, Qian, Chen, Chan, Chi-Min, Qin, Yujia, Lu, Yaxi, Xie, Ruobing, et al.
    Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors
    in agents. *arXiv preprint arXiv:2308.10848*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dai et al. (2023) Dai, Wenliang, Li, Junnan, Li, Dongxu, Tiong, Anthony Meng Huat,
    Zhao, Junqi, Wang, Weisheng, Li, Boyang, Fung, Pascale, and Hoi, Steven. Instructblip:
    Towards general-purpose vision-language models with instruction tuning. *arXiv
    preprint arXiv:2305.06500*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deng et al. (2023) Deng, Yue, Zhang, Wenxuan, Pan, Sinno Jialin, and Bing, Lidong.
    Multilingual jailbreak challenges in large language models. *arXiv preprint arXiv:2310.06474*,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dong et al. (2018) Dong, Yinpeng, Liao, Fangzhou, Pang, Tianyu, Su, Hang, Zhu,
    Jun, Hu, Xiaolin, and Li, Jianguo. Boosting adversarial attacks with momentum.
    In *IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dong et al. (2023) Dong, Yinpeng, Chen, Huanran, Chen, Jiawei, Fang, Zhengwei,
    Yang, Xiao, Zhang, Yichi, Tian, Yu, Su, Hang, and Zhu, Jun. How robust is google’s
    bard to adversarial image attacks? *arXiv preprint arXiv:2309.11751*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Driess et al. (2023) Driess, Danny, Xia, Fei, Sajjadi, Mehdi SM, Lynch, Corey,
    Chowdhery, Aakanksha, Ichter, Brian, Wahid, Ayzaan, Tompson, Jonathan, Vuong,
    Quan, Yu, Tianhe, et al. Palm-e: An embodied multimodal language model. *arXiv
    preprint arXiv:2303.03378*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Du et al. (2023) Du, Yilun, Li, Shuang, Torralba, Antonio, Tenenbaum, Joshua B,
    and Mordatch, Igor. Improving factuality and reasoning in language models through
    multiagent debate. *arXiv preprint arXiv:2305.14325*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dziugaite et al. (2016) Dziugaite, Gintare Karolina, Ghahramani, Zoubin, and
    Roy, Daniel M. A study of the effect of jpg compression on adversarial images.
    *arXiv preprint arXiv:1608.00853*, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gade et al. (2023) Gade, Pranav, Lermen, Simon, Rogers-Smith, Charlie, and
    Ladish, Jeffrey. Badllama: cheaply removing safety fine-tuning from llama 2-chat
    13b. *arXiv preprint arXiv:2311.00117*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ganguli et al. (2022) Ganguli, Deep, Lovitt, Liane, Kernion, Jackson, Askell,
    Amanda, Bai, Yuntao, Kadavath, Saurav, Mann, Ben, Perez, Ethan, Schiefer, Nicholas,
    Ndousse, Kamal, et al. Red teaming language models to reduce harms: Methods, scaling
    behaviors, and lessons learned. *arXiv preprint arXiv:2209.07858*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Goodfellow, Ian J, Shlens, Jonathon, and Szegedy, Christian.
    Explaining and harnessing adversarial examples. *arXiv preprint arXiv:1412.6572*,
    2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google (2023) Google, 2023. [https://bard.google.com/chat](https://bard.google.com/chat).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2023a) Hong, Sirui, Zheng, Xiawu, Chen, Jonathan, Cheng, Yuheng,
    Wang, Jinlin, Zhang, Ceyao, Wang, Zili, Yau, Steven Ka Shing, Lin, Zijuan, Zhou,
    Liyang, et al. Metagpt: Meta programming for multi-agent collaborative framework.
    *arXiv preprint arXiv:2308.00352*, 2023a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2023b) Hong, Wenyi, Wang, Weihan, Lv, Qingsong, Xu, Jiazheng,
    Yu, Wenmeng, Ji, Junhui, Wang, Yan, Wang, Zihan, Dong, Yuxiao, Ding, Ming, et al.
    Cogagent: A visual language model for gui agents. *arXiv preprint arXiv:2312.08914*,
    2023b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2023) Huang, Yangsibo, Gupta, Samyak, Xia, Mengzhou, Li, Kai,
    and Chen, Danqi. Catastrophic jailbreak of open-source llms via exploiting generation.
    *arXiv preprint arXiv:2310.06987*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaplan et al. (2020) Kaplan, Jared, McCandlish, Sam, Henighan, Tom, Brown, Tom B,
    Chess, Benjamin, Child, Rewon, Gray, Scott, Radford, Alec, Wu, Jeffrey, and Amodei,
    Dario. Scaling laws for neural language models. *arXiv preprint arXiv:2001.08361*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karpukhin et al. (2020) Karpukhin, Vladimir, Oğuz, Barlas, Min, Sewon, Lewis,
    Patrick, Wu, Ledell, Edunov, Sergey, Chen, Danqi, and Yih, Wen-tau. Dense passage
    retrieval for open-domain question answering. *arXiv preprint arXiv:2004.04906*,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Korbak et al. (2023) Korbak, Tomasz, Shi, Kejian, Chen, Angelica, Bhalerao,
    Rasika Vinayak, Buckley, Christopher, Phang, Jason, Bowman, Samuel R, and Perez,
    Ethan. Pretraining language models with human preferences. In *International Conference
    on Machine Learning (ICML)*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lapid et al. (2023) Lapid, Raz, Langberg, Ron, and Sipper, Moshe. Open sesame!
    universal black box jailbreaking of large language models. *arXiv preprint arXiv:2309.01446*,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lermen et al. (2023) Lermen, Simon, Rogers-Smith, Charlie, and Ladish, Jeffrey.
    Lora fine-tuning efficiently undoes safety training in llama 2-chat 70b. *arXiv
    preprint arXiv:2310.20624*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li (2023) Li, Beibin, 2023. [https://microsoft.github.io/autogen/blog/2023/11/06/LMM-Agent/](https://microsoft.github.io/autogen/blog/2023/11/06/LMM-Agent/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023a) Li, Guohao, Hammoud, Hasan Abed Al Kader, Itani, Hani, Khizbullin,
    Dmitrii, and Ghanem, Bernard. Camel: Communicative agents for” mind” exploration
    of large scale language model society. *arXiv preprint arXiv:2303.17760*, 2023a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023b) Li, Minghao, Zhao, Yingxiu, Yu, Bowen, Song, Feifan, Li,
    Hangyu, Yu, Haiyang, Li, Zhoujun, Huang, Fei, and Li, Yongbin. Api-bank: A comprehensive
    benchmark for tool-augmented llms. In *Conference on Empirical Methods in Natural
    Language Processing (EMNLP)*, 2023b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023c) Li, Xuan, Zhou, Zhanke, Zhu, Jianing, Yao, Jiangchao, Liu,
    Tongliang, and Han, Bo. Deepinception: Hypnotize large language model to be jailbreaker.
    *arXiv preprint arXiv:2311.03191*, 2023c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2023) Liang, Tian, He, Zhiwei, Jiao, Wenxiang, Wang, Xing, Wang,
    Yan, Wang, Rui, Yang, Yujiu, Tu, Zhaopeng, and Shi, Shuming. Encouraging divergent
    thinking in large language models through multi-agent debate. *arXiv preprint
    arXiv:2305.19118*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liao et al. (2022) Liao, Peiyuan, Li, Xiuyu, Liu, Xihui, and Keutzer, Kurt.
    The artbench dataset: Benchmarking generative models with artworks. *arXiv preprint
    arXiv:2206.11404*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023a) Liu, Bo, Jiang, Yuqian, Zhang, Xiaohan, Liu, Qiang, Zhang,
    Shiqi, Biswas, Joydeep, and Stone, Peter. Llm+ p: Empowering large language models
    with optimal planning proficiency. *arXiv preprint arXiv:2304.11477*, 2023a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2023b) Liu, Haotian, Li, Chunyuan, Li, Yuheng, and Lee, Yong Jae.
    Improved baselines with visual instruction tuning. *arXiv preprint arXiv:2310.03744*,
    2023b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2023c) Liu, Haotian, Li, Chunyuan, Wu, Qingyang, and Lee, Yong Jae.
    Visual instruction tuning. *arXiv preprint arXiv:2304.08485*, 2023c.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023d) Liu, Shilong, Cheng, Hao, Liu, Haotian, Zhang, Hao, Li,
    Feng, Ren, Tianhe, Zou, Xueyan, Yang, Jianwei, Su, Hang, Zhu, Jun, et al. Llava-plus:
    Learning to use tools for creating multimodal agents. *arXiv preprint arXiv:2311.05437*,
    2023d.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023e) Liu, Xiaogeng, Xu, Nan, Chen, Muhao, and Xiao, Chaowei.
    Autodan: Generating stealthy jailbreak prompts on aligned large language models.
    *arXiv preprint arXiv:2310.04451*, 2023e.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023f) Liu, Yi, Deng, Gelei, Xu, Zhengzi, Li, Yuekang, Zheng, Yaowen,
    Zhang, Ying, Zhao, Lida, Zhang, Tianwei, and Liu, Yang. Jailbreaking chatgpt via
    prompt engineering: An empirical study. *arXiv preprint arXiv:2305.13860*, 2023f.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2022) Long, Yuyang, Zhang, Qilong, Zeng, Boheng, Gao, Lianli, Liu,
    Xianglong, Zhang, Jian, and Song, Jingkuan. Frequency domain model augmentation
    for adversarial attack. In *European Conference on Computer Vision (ECCV)*, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minsky (1988) Minsky, Marvin. *Society of mind*. Simon and Schuster, 1988.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Openai (2023) Openai, 2023. [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2023) OpenAI. Gpt-4 technical report, 2023. [https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ouyang et al. (2022) Ouyang, Long, Wu, Jeffrey, Jiang, Xu, Almeida, Diogo, Wainwright,
    Carroll, Mishkin, Pamela, Zhang, Chong, Agarwal, Sandhini, Slama, Katarina, Ray,
    Alex, et al. Training language models to follow instructions with human feedback.
    In *Advances in Neural Information Processing Systems (NeurIPS)*, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Packer et al. (2023) Packer, Charles, Fang, Vivian, Patil, Shishir G, Lin,
    Kevin, Wooders, Sarah, and Gonzalez, Joseph E. Memgpt: Towards llms as operating
    systems. *arXiv preprint arXiv:2310.08560*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2023) Park, Joon Sung, O’Brien, Joseph, Cai, Carrie Jun, Morris,
    Meredith Ringel, Liang, Percy, and Bernstein, Michael S. Generative agents: Interactive
    simulacra of human behavior. In *Annual ACM Symposium on User Interface Software
    and Technology*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perez et al. (2022) Perez, Ethan, Huang, Saffron, Song, Francis, Cai, Trevor,
    Ring, Roman, Aslanides, John, Glaese, Amelia, McAleese, Nat, and Irving, Geoffrey.
    Red teaming language models with language models. *arXiv preprint arXiv:2202.03286*,
    2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qi et al. (2023a) Qi, Xiangyu, Huang, Kaixuan, Panda, Ashwinee, Wang, Mengdi,
    and Mittal, Prateek. Visual adversarial examples jailbreak aligned large language
    models. In *The Second Workshop on New Frontiers in Adversarial Machine Learning*,
    volume 1, 2023a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qi et al. (2023b) Qi, Xiangyu, Zeng, Yi, Xie, Tinghao, Chen, Pin-Yu, Jia, Ruoxi,
    Mittal, Prateek, and Henderson, Peter. Fine-tuning aligned language models compromises
    safety, even when users do not intend to! *arXiv preprint arXiv:2310.03693*, 2023b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qian et al. (2023) Qian, Chen, Cong, Xin, Yang, Cheng, Chen, Weize, Su, Yusheng,
    Xu, Juyuan, Liu, Zhiyuan, and Sun, Maosong. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2021) Radford, Alec, Kim, Jong Wook, Hallacy, Chris, Ramesh,
    Aditya, Goh, Gabriel, Agarwal, Sandhini, Sastry, Girish, Askell, Amanda, Mishkin,
    Pamela, Clark, Jack, et al. Learning transferable visual models from natural language
    supervision. In *International Conference on Machine Learning (ICML)*, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rao et al. (2023) Rao, Abhinav, Vashistha, Sachin, Naik, Atharva, Aditya, Somak,
    and Choudhury, Monojit. Tricking llms into disobedience: Understanding, analyzing,
    and preventing jailbreaks. *arXiv preprint arXiv:2305.14965*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reich et al. (2024) Reich, Christoph, Debnath, Biplob, Patel, Deep, and Chakradhar,
    Srimat. Differentiable jpeg: The devil is in the details. In *IEEE Winter Conference
    on Applications of Computer Vision*, pp.  4126–4135, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ruan et al. (2023) Ruan, Yangjun, Dong, Honghua, Wang, Andrew, Pitis, Silviu,
    Zhou, Yongchao, Ba, Jimmy, Dubois, Yann, Maddison, Chris J, and Hashimoto, Tatsunori.
    Identifying the risks of lm agents with an lm-emulated sandbox. *arXiv preprint
    arXiv:2309.15817*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russell & Norvig (2010) Russell, Stuart J and Norvig, Peter. *Artificial intelligence
    a modern approach*. London, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schick et al. (2023) Schick, Timo, Dwivedi-Yu, Jane, Dessì, Roberto, Raileanu,
    Roberta, Lomeli, Maria, Zettlemoyer, Luke, Cancedda, Nicola, and Scialom, Thomas.
    Toolformer: Language models can teach themselves to use tools. *arXiv preprint
    arXiv:2302.04761*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schlarmann & Hein (2023) Schlarmann, Christian and Hein, Matthias. On the adversarial
    robustness of multi-modal foundation models. In *IEEE International Conference
    on Computer Vision (ICCV)*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shayegani et al. (2023) Shayegani, Erfan, Dong, Yue, and Abu-Ghazaleh, Nael.
    Jailbreak in pieces: Compositional adversarial attacks on multi-modal language
    models. *arXiv preprint arXiv:2307.14539*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shen et al. (2023) Shen, Yongliang, Song, Kaitao, Tan, Xu, Li, Dongsheng, Lu,
    Weiming, and Zhuang, Yueting. Hugginggpt: Solving ai tasks with chatgpt and its
    friends in huggingface. *arXiv preprint arXiv:2303.17580*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shinn et al. (2023) Shinn, Noah, Cassano, Federico, Gopinath, Ashwin, Narasimhan,
    Karthik R, and Yao, Shunyu. Reflexion: Language agents with verbal reinforcement
    learning. In *Advances in Neural Information Processing Systems (NeurIPS)*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sumers et al. (2023) Sumers, Theodore R, Yao, Shunyu, Narasimhan, Karthik, and
    Griffiths, Thomas L. Cognitive architectures for language agents. *arXiv preprint
    arXiv:2309.02427*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Team et al. (2023) Team, Gemini, Anil, Rohan, Borgeaud, Sebastian, Wu, Yonghui,
    Alayrac, Jean-Baptiste, Yu, Jiahui, Soricut, Radu, Schalkwyk, Johan, Dai, Andrew M,
    Hauth, Anja, et al. Gemini: a family of highly capable multimodal models. *arXiv
    preprint arXiv:2312.11805*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tian et al. (2023) Tian, Yu, Yang, Xiao, Zhang, Jingyuan, Dong, Yinpeng, and
    Su, Hang. Evil geniuses: Delving into the safety of llm-based agents. *arXiv preprint
    arXiv:2311.11855*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timbrell (2023) Timbrell, Daniel, 2023. [https://www.lakera.ai/blog/visual-prompt-injections](https://www.lakera.ai/blog/visual-prompt-injections).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Touvron, Hugo, Martin, Louis, Stone, Kevin, Albert, Peter,
    Almahairi, Amjad, Babaei, Yasmine, Bashlykov, Nikolay, Batra, Soumya, Bhargava,
    Prajjwal, Bhosale, Shruti, et al. Llama 2: Open foundation and fine-tuned chat
    models. *arXiv preprint arXiv:2307.09288*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Toyer et al. (2023) Toyer, Sam, Watkins, Olivia, Mendes, Ethan Adrian, Svegliato,
    Justin, Bailey, Luke, Wang, Tiffany, Ong, Isaac, Elmaaroufi, Karim, Abbeel, Pieter,
    Darrell, Trevor, et al. Tensor trust: Interpretable prompt injection attacks from
    an online game. *arXiv preprint arXiv:2311.01011*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tu et al. (2023) Tu, Haoqin, Cui, Chenhang, Wang, Zijun, Zhou, Yiyang, Zhao,
    Bingchen, Han, Junlin, Zhou, Wangchunshu, Yao, Huaxiu, and Xie, Cihang. How many
    unicorns are in this image? a safety evaluation benchmark for vision llms. *arXiv
    preprint arXiv:2311.16101*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023) Wang, Zhenhailong, Mao, Shaoguang, Wu, Wenshan, Ge, Tao,
    Wei, Furu, and Ji, Heng. Unleashing cognitive synergy in large language models:
    A task-solving agent through multi-persona selfcollaboration. *arXiv preprint
    arXiv:2307.05300*, 1(2):3, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wei et al. (2023) Wei, Alexander, Haghtalab, Nika, and Steinhardt, Jacob. Jailbroken:
    How does llm safety training fail? In *Advances in Neural Information Processing
    Systems (NeurIPS)*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wooldridge & Jennings (1995) Wooldridge, Michael and Jennings, Nicholas R.
    Intelligent agents: Theory and practice. *The knowledge engineering review*, 10(2):115–152,
    1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2023) Wu, Qingyun, Bansal, Gagan, Zhang, Jieyu, Wu, Yiran, Zhang,
    Shaokun, Zhu, Erkang, Li, Beibin, Jiang, Li, Zhang, Xiaoyun, and Wang, Chi. Autogen:
    Enabling next-gen llm applications via multi-agent conversation framework. *arXiv
    preprint arXiv:2308.08155*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie et al. (2017) Xie, Cihang, Wang, Jianyu, Zhang, Zhishuai, Ren, Zhou, and
    Yuille, Alan. Mitigating adversarial effects through randomization. *arXiv preprint
    arXiv:1711.01991*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie et al. (2019) Xie, Cihang, Zhang, Zhishuai, Zhou, Yuyin, Bai, Song, Wang,
    Jianyu, Ren, Zhou, and Yuille, Alan L. Improving transferability of adversarial
    examples with input diversity. In *IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR)*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023a) Yang, Jingkang, Dong, Yuhao, Liu, Shuai, Li, Bo, Wang,
    Ziyue, Jiang, Chencheng, Tan, Haoran, Kang, Jiamu, Zhang, Yuanhan, Zhou, Kaiyang,
    et al. Octopus: Embodied vision-language programmer from environmental feedback.
    *arXiv preprint arXiv:2310.08588*, 2023a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023b) Yang, Xianjun, Wang, Xiao, Zhang, Qi, Petzold, Linda, Wang,
    William Yang, Zhao, Xun, and Lin, Dahua. Shadow alignment: The ease of subverting
    safely-aligned language models. *arXiv preprint arXiv:2310.02949*, 2023b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023c) Yang, Zhao, Liu, Jiaxuan, Han, Yucheng, Chen, Xin, Huang,
    Zebiao, Fu, Bin, and Yu, Gang. Appagent: Multimodal agents as smartphone users.
    *arXiv preprint arXiv:2312.13771*, 2023c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2022) Yao, Shunyu, Zhao, Jeffrey, Yu, Dian, Du, Nan, Shafran, Izhak,
    Narasimhan, Karthik, and Cao, Yuan. React: Synergizing reasoning and acting in
    language models. *arXiv preprint arXiv:2210.03629*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023) Yao, Shunyu, Yu, Dian, Zhao, Jeffrey, Shafran, Izhak, Griffiths,
    Thomas L, Cao, Yuan, and Narasimhan, Karthik. Tree of thoughts: Deliberate problem
    solving with large language models. *arXiv preprint arXiv:2305.10601*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yin et al. (2023) Yin, Ziyi, Ye, Muchao, Zhang, Tianrong, Du, Tianyu, Zhu,
    Jinguo, Liu, Han, Chen, Jinghui, Wang, Ting, and Ma, Fenglong. Vlattack: Multimodal
    adversarial attacks on vision-language tasks via pre-trained models. In *Advances
    in Neural Information Processing Systems (NeurIPS)*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yuan et al. (2023) Yuan, Youliang, Jiao, Wenxiang, Wang, Wenxuan, Huang, Jen-tse,
    He, Pinjia, Shi, Shuming, and Tu, Zhaopeng. Gpt-4 is too smart to be safe: Stealthy
    chat with llms via cipher. *arXiv preprint arXiv:2308.06463*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zajac et al. (2019) Zajac, Michał, Zołna, Konrad, Rostamzadeh, Negar, and Pinheiro,
    Pedro O. Adversarial framing for image and video classification. In *AAAI Conference
    on Artificial Intelligence (AAAI)*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023) Zhang, Hongxin, Du, Weihua, Shan, Jiaming, Zhou, Qinhong,
    Du, Yilun, Tenenbaum, Joshua B, Shu, Tianmin, and Gan, Chuang. Building cooperative
    embodied agents modularly with large language models. *arXiv preprint arXiv:2307.02485*,
    2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022) Zhang, Jiaming, Yi, Qi, and Sang, Jitao. Towards adversarial
    attack on vision-language pre-training models. In *ACM International Conference
    on Multimedia*, 2022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2023) Zhao, Yunqing, Pang, Tianyu, Du, Chao, Yang, Xiao, Li, Chongxuan,
    Cheung, Ngai-Man, and Lin, Min. On evaluating adversarial robustness of large
    vision-language models. In *Advances in Neural Information Processing Systems
    (NeurIPS)*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2023) Zhou, Shuyan, Xu, Frank F, Zhu, Hao, Zhou, Xuhui, Lo, Robert,
    Sridhar, Abishek, Cheng, Xianyi, Bisk, Yonatan, Fried, Daniel, Alon, Uri, et al.
    Webarena: A realistic web environment for building autonomous agents. *arXiv preprint
    arXiv:2307.13854*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2023) Zhu, Sicheng, Zhang, Ruiyi, An, Bang, Wu, Gang, Barrow, Joe,
    Wang, Zichao, Huang, Furong, Nenkova, Ani, and Sun, Tong. Autodan: Automatic and
    interpretable adversarial attacks on large language models. *arXiv preprint arXiv:2310.15140*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zou et al. (2023) Zou, Andy, Wang, Zifan, Kolter, J Zico, and Fredrikson, Matt.
    Universal and transferable adversarial attacks on aligned language models. *arXiv
    preprint arXiv:2307.15043*, 2023.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Related Work (Full Version)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '(Multimodal) LLM agents. For a long time, artificial intelligence has been
    actively engaged in creating intelligent agents that can mimic human thought processes
    and independently carry out complex tasks (Minsky, [1988](#bib.bib45); Wooldridge
    & Jennings, [1995](#bib.bib74); Russell & Norvig, [2010](#bib.bib59); Bubeck et al.,
    [2023](#bib.bib8)). Owing to the recent incredible development of large language
    models (LLMs) (Brown et al., [2020](#bib.bib6); Kaplan et al., [2020](#bib.bib27);
    Ouyang et al., [2022](#bib.bib48); Korbak et al., [2023](#bib.bib29)), multimodal
    LLMs (MLLMs) such as GPT-4V (OpenAI, [2023](#bib.bib47)) and Gemini (Team et al.,
    [2023](#bib.bib66)) have demonstrated impressive capabilities, especially in vision-language
    scenarios. By leveraging the power of LLMs, autonomous agents can make better
    decisions and perform actions with greater autonomy (Zhou et al., [2023](#bib.bib89)).
    In an LLM-powered autonomous agent system, an (M)LLM serves as the agent’s brain,
    supported by a number of key components: the planning module decomposes tasks
    and questions (Yao et al., [2022](#bib.bib81), [2023](#bib.bib82); Liu et al.,
    [2023a](#bib.bib38); Shinn et al., [2023](#bib.bib64)); the memory module stores
    both the internal log and the external interactions with a user (Sumers et al.,
    [2023](#bib.bib65); Packer et al., [2023](#bib.bib49)); and the ability to use
    tools that can call executable workflows or APIs (Schick et al., [2023](#bib.bib60);
    Shen et al., [2023](#bib.bib63); Li et al., [2023b](#bib.bib34)). Recently, there
    has been a surge of interest in operating systems built around (M)LLMs, which
    receive screenshots as visual signals and perform subsequent actions. For examples,
    Liu et al. ([2023d](#bib.bib41)) introduce LLaVA-Plus, a general-purpose multimodal
    agent that learns to use tools based on LLaVA; Yang et al. ([2023c](#bib.bib80))
    propose an LLM-based multimodal agent framework for operating smartphone applications;
    Hong et al. ([2023b](#bib.bib25)) develop a visual language model that focuses
    on GUI understanding and navigation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi-agent systems. A popular recent trend is to create multi-agent systems
    based on (M)LLMs for downstream applications. Park et al. ([2023](#bib.bib50))
    propose simulating human behaviors based on multiple LLM agents and discuss the
    information diffusion phenomenon: as agents communicate, information can spread
    from agent to agent; Qian et al. ([2023](#bib.bib54)) create ChatDev to allow
    multiple agent roles to communicate and collaborate using conversations to complete
    the software development life cycle. Similarly, several efforts use multi-agent
    cooperation to improve performance on different tasks (Du et al., [2023](#bib.bib18);
    Wang et al., [2023](#bib.bib72); Zhang et al., [2023](#bib.bib86); Chan et al.,
    [2023](#bib.bib10); Liang et al., [2023](#bib.bib36)). Furthermore, to facilitate
    the development of multi-agent systems, various multi-agent frameworks have recently
    been proposed, including CAMEL (Li et al., [2023a](#bib.bib33)), AutoGen (Wu et al.,
    [2023](#bib.bib75)), AgentVerse (Chen et al., [2023](#bib.bib12)), MetaGPT (Hong
    et al., [2023a](#bib.bib24)), just name a few. In particular, AutoGen provides
    a practical example of how to build a multi-agent system based on GPT-4V and LLaVA (Li,
    [2023](#bib.bib32)).'
  prefs: []
  type: TYPE_NORMAL
- en: Jailbreaking LLMs. LLMs such as ChatGPT/GPT-4 (OpenAI, [2023](#bib.bib47)) and
    LLaMA 2 (Touvron et al., [2023](#bib.bib69)) are typically aligned to generate
    helpful and harmless responses to human queries, following the training pipeline
    of human/AI alignment (Ouyang et al., [2022](#bib.bib48); Ganguli et al., [2022](#bib.bib21);
    Bai et al., [2022](#bib.bib3); Korbak et al., [2023](#bib.bib29)). However, red-teaming
    research has shown that LLMs can be jailbroken to generate objectionable content
    by either manually designed or automatically crafted prompts (Perez et al., [2022](#bib.bib51);
    Zou et al., [2023](#bib.bib91); Liu et al., [2023f](#bib.bib43); Rao et al., [2023](#bib.bib56);
    Li et al., [2023c](#bib.bib35); Zhu et al., [2023](#bib.bib90); Lapid et al.,
    [2023](#bib.bib30); Liu et al., [2023e](#bib.bib42); Chao et al., [2023](#bib.bib11);
    Ruan et al., [2023](#bib.bib58); Toyer et al., [2023](#bib.bib70); Yuan et al.,
    [2023](#bib.bib84); Deng et al., [2023](#bib.bib14)). Moreover, Tian et al. ([2023](#bib.bib67))
    investigate the safety issues of LLM-based agents; Wei et al. ([2023](#bib.bib73))
    hypothesize that the vulnerability of aligned LLMs to jailbreaking is attributed
    to the competing objectives of capability and safety, as well as the mismatch
    between pretraining and safety training; Carlini et al. ([2023](#bib.bib9)) attribute
    the vulnerability to neural networks’ fundamental weakness in dealing with adversarial
    examples. More recently, several current works observe that finetuning aligned
    LLMs with either poisoned or benign data would compromise model alignment/safety (Qi
    et al., [2023b](#bib.bib53); Lermen et al., [2023](#bib.bib31); Gade et al., [2023](#bib.bib20);
    Yang et al., [2023b](#bib.bib79); Huang et al., [2023](#bib.bib26)).
  prefs: []
  type: TYPE_NORMAL
- en: Jailbreaking MLLMs. Aside from generating adversarial prompts to jailbreak LLMs,
    there is another line of red-teaming work to attack the alignment of MLLMs using
    adversarial images (Zhang et al., [2022](#bib.bib87); Zhao et al., [2023](#bib.bib88);
    Qi et al., [2023a](#bib.bib52); Bailey et al., [2023](#bib.bib4); Tu et al., [2023](#bib.bib71);
    Shayegani et al., [2023](#bib.bib62); Yin et al., [2023](#bib.bib83)). Specifically,
    on discriminative tasks, adversarial images could be crafted to fool classifiers
    by adding human imperceptible perturbations guided by the victim model’s input
    gradients (Goodfellow et al., [2014](#bib.bib22); Dong et al., [2018](#bib.bib15);
    Xie et al., [2019](#bib.bib77); Long et al., [2022](#bib.bib44)). In addition
    to $\ell_{p}$-norm threat model, there are other types of attacks that manipulate
    adversarial patches (Brown et al., [2017](#bib.bib7)) or adversarial framing (Zajac
    et al., [2019](#bib.bib85)). Within the context of MLLMs, Schlarmann & Hein ([2023](#bib.bib61))
    demonstrate that OpenFlamingo (Awadalla et al., [2023](#bib.bib2)) can be fooled
    into performing poorly on image captioning and VQA tasks with very minor perturbations;
    Zhao et al. ([2023](#bib.bib88)) provide a quantitative analysis of the adversarial
    robustness of various MLLMs by producing adversarial images that trick the models
    into generating specific responses; Dong et al. ([2023](#bib.bib16)) demonstrate
    that adversarial images crafted on open-source models could be transferred to
    mislead Bard (Google, [2023](#bib.bib23)).
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Complementary Derivations of Infectious Dynamics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8edc034530f8a9673209e455e89ccbbd.png)![Refer to caption](img/e2c1ad6daf0bf900ef4513a287ec8863.png)![Refer
    to caption](img/267ed76fcc0309b9d98dcf349ea5020e.png)![Refer to caption](img/0d7aae3b901f078cf9d7cabd2aa96d53.png)![Refer
    to caption](img/b3725b7e9a587acb51e7c69a12da88e4.png)![Refer to caption](img/1255e57d898fc4c575246c87884bdcf6.png)![Refer
    to caption](img/240ede318d25fb43800d7feab0b3ffcc.png)![Refer to caption](img/f7eaf1762dbcce829001c7f37fe7f0f3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: *(Top)* Theoretical and *(Bottom)* simulated curves of infection
    ratio $p_{t}$.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we first provide complete solutions for the ratio of virus-carrying
    agents at the $t$.
  prefs: []
  type: TYPE_NORMAL
- en: The case of <math id="A2.p2.1.1.m1.1" class="ltx_Math" alttext="\beta></math>
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (12) |'
  prefs: []
  type: TYPE_TB
- en: 'which *exponentially* decreases w.r.t. $t$. Additionally, we can reformulate
    Eq. [7](#S3.E7 "Equation 7 ‣ 3.1 Infectious Dynamics of Randomized Pairwise Chat
    ‣ 3 Simulating Multi-Agent Environments ‣ Agent Smith: A Single Image Can Jailbreak
    One Million Multimodal LLM Agents Exponentially Fast") into'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $t=\frac{2}{\beta-2\gamma}\log\frac{c_{t}(\beta-2\gamma-c_{0}\beta)}{c_{0}(\beta-2\gamma-c_{t}\beta)}\textrm{,}$
    |  | (13) |'
  prefs: []
  type: TYPE_TB
- en: which can be used to compute the number of chat rounds required to achieve certain
    ratio of virus carrying agents.
  prefs: []
  type: TYPE_NORMAL
- en: The case of $\beta=2\gamma$. The solution can be written as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $c_{t}=\frac{2c_{0}}{c_{0}\beta t+2}\textrm{,}$ |  | (14) |'
  prefs: []
  type: TYPE_TB
- en: where $\lim_{t\rightarrow\infty}c_{t}=0$.
  prefs: []
  type: TYPE_NORMAL
- en: 'The case of $\beta<2\gamma$. The solution formulation is the same as Eq. ([7](#S3.E7
    "Equation 7 ‣ 3.1 Infectious Dynamics of Randomized Pairwise Chat ‣ 3 Simulating
    Multi-Agent Environments ‣ Agent Smith: A Single Image Can Jailbreak One Million
    Multimodal LLM Agents Exponentially Fast")), but we rewrite into the form as'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (15) |'
  prefs: []
  type: TYPE_TB
- en: where there is also $\lim_{t\rightarrow\infty}c_{t}=0$ decreases to zero exponentially
    fast.
  prefs: []
  type: TYPE_NORMAL
- en: Visualization of infection ratio $p_{t}$, our derived theoretical results fit
    our simulations.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Instantiation of Our Multi-agent System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We create multi-agent environments by setting up $N$ agents, each of which is
    uniquely customized by a role-playing description and a personalized album filled
    with random selected images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Role-playing description. (M)LLM agents are typically personalized by assuming
    specific roles (Park et al., [2023](#bib.bib50)). We collect real names using
    the names-dataset package²²2[https://github.com/philipperemy/name-dataset](https://github.com/philipperemy/name-dataset)
    and other various properties from an open-source dataset³³3[https://github.com/Norviah/animal-crossing/blob/master/json/data/Villagers.json](https://github.com/Norviah/animal-crossing/blob/master/json/data/Villagers.json).
    For each property including the agent name, we gather all unique possible values
    as the pool. We then compose new agent role-playing descriptions by sampling from
    each property value pool. A concrete example is shown in Figure [8](#A3.F8 "Figure
    8 ‣ Appendix C Instantiation of Our Multi-agent System ‣ Agent Smith: A Single
    Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Personalized album. Similarly, we build an image pool using an open-source
    image dataset⁴⁴4[https://github.com/Norviah/acnh-images](https://github.com/Norviah/acnh-images).
    We then construct the personalized album for each agent via randomly sampling
    images from the image pool. As shown in Figure [9](#A3.F9 "Figure 9 ‣ Appendix
    C Instantiation of Our Multi-agent System ‣ Agent Smith: A Single Image Can Jailbreak
    One Million Multimodal LLM Agents Exponentially Fast"), each agent carries diverse
    images. Note that our infectious attack is achieved by injecting an adversarial
    image into one agent’s personalized album.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,ICB7CiAgICAiTmFtZSI6ICJYYXIiLAogICAgIlNwZWNpZXMiOiAiRnJvZyIsCiAgICAiR2VuZGVyIjogIkZlbWFsZSIsCiAgICAiUGVyc29uYWxpdHkiOiAiU25vb3R5IiwKICAgICJTdWJ0eXBlIjogIkEiLAogICAgIkhvYmJ5IjogIk5hdHVyZSIsCiAgICAiQmlydGhkYXkiOiAiMi8xOSIsCiAgICAiQ2F0Y2hwaHJhc2UiOiAiZ3JyclJBSCIsCiAgICAiRmF2b3JpdGUgU29uZyI6ICJCdWJibGVndW0gSy5LLiIsCiAgICAiRmF2b3JpdGUgU2F5aW5nIjogIkZvb2wgbWUgb25jZSwgc2hhbWUgb24geW91LiBGb29sIG1lIHR3aWNlLCBzaGFtZSBvbiBtZS4iLAogICAgIlN0eWxlIDEiOiAiQWN0aXZlIiwKICAgICJTdHlsZSAyIjogIkNvb2wiLAogICAgIkNvbG9yIDEiOiAiQ29sb3JmdWwiLAogICAgIkNvbG9yIDIiOiAiUGluayIsCiAgfQ==){"Name":  "Xar","Species":  "Frog","Gender":  "Female","Personality":  "Snooty","Subtype":  "A","Hobby":  "Nature","Birthday":  "2/19","Catchphrase":  "grrrRAH","Favorite  Song":  "Bubblegum  K.K.","Favorite  Saying":  "Fool  me  once,  shame  on  you.  Fool  me  twice,  shame  on  me.","Style  1":  "Active","Style  2":  "Cool","Color  1":  "Colorful","Color  2":  "Pink",}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: An example of the role-playing description. It encompasses basic
    information such as name, gender, hobby, etc, reflecting the personalities of
    the agents, which will be written into the prompt to influence the MLLM behaviors.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,ICBbCiAgInV0aWxpdHkgcG9sZV9ObyBhZHNfSW1hZ2VfOTYxOV9oMlFhbU05ajNjZEU5TndvNy5wbmciLAogICJwb3AtdXAgdG9hc3Rlcl9SZWRfSW1hZ2VfMzI4Ml9vSFc1dlhtRzhLc29FQktGSC5wbmciLAogICJzdHVkeSBjaGFpcl9XaGl0ZV9JbWFnZV8zNzAyX0VEN2c1Mk5zdE1HbmhTWWU1LnBuZyIsCiAgImFyY2FkZSBmaWdodGluZyBnYW1lX19JbWFnZV84MjI1XzNDS3FIU2NISnVxYlc3ZTR1LnBuZyIsCiAgIndvb2RlbiB3YXN0ZSBiaW5fQmxhY2tfSW1hZ2VfMzQ5MF96WDcyazhnVG50N25xUWFlNy5wbmciLAogICJlbGFib3JhdGUga2ltb25vIHN0YW5kX0hhd2tfSW1hZ2VfNzg2NV9XdEdwTlJaZHRKOGtGYUVLRC5wbmciLAogICJraXRjaGVuIGlzbGFuZF9CbGFja19JbWFnZV85OThfSk5yWkxqR05yWkJMNUFleEcucG5nIiwKICAiQ2lubmFtb3JvbGwgc2lnbmFnZV9fSW1hZ2VfMTIyNDhfdm1yc29URGo2NEEybURxbmQucG5nIiwKICAianVkZ2UncyBiZWxsX19JbWFnZV8xNDU2X0d4b21DZldyd0g3ZWk3UFBNLnBuZyIsCiAgIk1ycy4gRmxhbWluZ29fV2hpdGVfSW1hZ2VfMzM2X1RFdXQ1cHF5NGhGN3o4UzJQLnBuZyIsCiAgXQ==)["utility  pole_No  ads_Image_9619_h2QamM9j3cdE9Nwo7.png","pop-up  toaster_Red_Image_3282_oHW5vXmG8KsoEBKFH.png","study  chair_White_Image_3702_ED7g52NstMGnhSYe5.png","arcade  fighting  game__Image_8225_3CKqHScHJuqbW7e4u.png","wooden  waste  bin_Black_Image_3490_zX72k8gTnt7nqQae7.png","elaborate  kimono  stand_Hawk_Image_7865_WtGpNRZdtJ8kFaEKD.png","kitchen  island_Black_Image_998_JNrZLjGNrZBL5AexG.png","Cinnamoroll  signage__Image_12248_vmrsoTDj64A2mDqnd.png","judge’s  bell__Image_1456_GxomCfWrwH7ei7PPM.png","Mrs.  Flamingo_White_Image_336_TEut5pqy4hF7z8S2P.png",]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9: An example of the personalized album $\mathcal{B}$. It stores various
    images for each agent and leverages them to facilitate future actions like image
    retrieval.'
  prefs: []
  type: TYPE_NORMAL
- en: 'System prompts and chat examples for different diversity scenarios. We adopt
    these three system prompts ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{V}}}$,
    to push forward the interactions among agents. Especially, we consider two scenarios
    of chat diversity. *Low diversity scenario*: Following Li et al. ([2023a](#bib.bib33)),
    the chat process of a multi-agent system is pushed by the system prompts in Figure [10](#A3.F10
    "Figure 10 ‣ Appendix C Instantiation of Our Multi-agent System ‣ Agent Smith:
    A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast").
    This scenario is marked by short responses and limited diversity in chat between
    two agents, as demonstrated in Figure [11](#A3.F11 "Figure 11 ‣ Appendix C Instantiation
    of Our Multi-agent System ‣ Agent Smith: A Single Image Can Jailbreak One Million
    Multimodal LLM Agents Exponentially Fast"). *High diversity scenario*: The system
    prompts in Figure [12](#A3.F12 "Figure 12 ‣ Appendix C Instantiation of Our Multi-agent
    System ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM
    Agents Exponentially Fast"), which encourage agents to play their roles, are used
    to facilitate agents’ interactions. This scenario typically exhibits generating
    longer sentences and thus a higher diversity in chat as shown in Figure [13](#A3.F13
    "Figure 13 ‣ Appendix C Instantiation of Our Multi-agent System ‣ Agent Smith:
    A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast").
    More concretely, as shown in Figure [10](#A3.F10 "Figure 10 ‣ Appendix C Instantiation
    of Our Multi-agent System ‣ Agent Smith: A Single Image Can Jailbreak One Million
    Multimodal LLM Agents Exponentially Fast"), our system prompts contain both the
    agent role prompt and task prompt. The agent role prompt is used to reflect the
    environment, role-playing, chat histories, etc of agents. The task prompt is majorly
    guiding the agent to execute certain tasks including image retrieval, question
    generation, and question answering. Additionally, the LLaVA-1.5 system prompt
    will also be included in the prompt to enhance the alignment of agents and increase
    the difficulty of our infectious jailbreak.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="A3.F10.pic1" class="ltx_picture" height="420.35" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,420.35) matrix(1 0 0 -1 0
    0) translate(23.13,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    transform="matrix(1.0 0.0 0.0 1.0 15 398.21)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1
    0 0)" color="#000000">Low Diversity Chat Prompts</text></g></g></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject width="510.43"
    height="374.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">LLaVA-1.5
    System Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0] System Prompt ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{V}}}$
    Agent Role Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1] Task Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2] System Prompt ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{Q}}}$
    Agent Role Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3] Task Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4] System Prompt ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{A}}}$
    Agent Role Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5] Task Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10: System prompts of the multi-agent system for the low diversity scenario.
    This shows the LLaVA-1.5 system prompt, our customized system prompts where each
    of them including the agent role prompt and task prompt for the low diversity
    scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="A3.F11.pic1" class="ltx_picture" height="572.58" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,572.58) matrix(1 0 0 -1 0
    0) translate(23.13,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    transform="matrix(1.0 0.0 0.0 1.0 15 550.44)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1
    0 0)" color="#000000">A Benign Low Diversity Chat Example</text></g></g></g> <g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="510.43" height="526.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Questioning Agent
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7] Questioning Agent'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8] Answering Agent'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11: A chat example of the multi-agent system for the low diversity scenario.
    The generated responses (highlighted in red color) are generally short.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="A3.F12.pic1" class="ltx_picture" height="420.3" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,420.3) matrix(1 0 0 -1 0 0)
    translate(23.13,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 15 398.15)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)" color="#000000">High
    Diversity Chat Prompts</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject width="510.43" height="374.63" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">LLaVA-1.5 System Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10] System Prompt ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{V}}}$
    Agent Role Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11] Task Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12] System Prompt ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{Q}}}$
    Agent Role Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13] Task Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14] System Prompt ${\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}^{\textrm{A}}}$
    Agent Role Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15] Task Prompt'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12: System prompts of the multi-agent system for the high diversity
    scenario. This shows the LLaVA-1.5 system prompt, our customized system prompts
    where each of them including the agent role prompt and task prompt for the high
    diversity scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="A3.F13.pic1" class="ltx_picture" height="648.49" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,648.49) matrix(1 0 0 -1 0
    0) translate(23.13,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    transform="matrix(1.0 0.0 0.0 1.0 15 626.35)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1
    0 0)" color="#000000">A Benign High Diversity Chat Example</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    width="510.43" height="602.83" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">Questioning Agent
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17] Questioning Agent'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18] Answering Agent'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 13: A chat example of the multi-agent system for the high diversity
    scenario. The generated responses (highlighted in red color) are generally longer
    compared to those of the low diversity scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D Implementation of Jailbreak Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we provide implementation details on noninfectious jailbreaking
    baselines and our jailbreaking method.
  prefs: []
  type: TYPE_NORMAL
- en: D.1 Noninfectious Jailbreaking Baselines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Visual prompt injection (VP): It is found that image contexts can override
    textual prompts, acting as commands to be executed for GPT-4V (Timbrell, [2023](#bib.bib68)).
    To exploit this, we create ${\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}}$
    will then be queued in the album of the answering agent.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Textual prompt injection (TP): Rather than employing images to jailbreak, we
    carefully design a textual prompt aimed at persuading agents to generate and spread
    harmful responses within the multi-agent system as shown in Figure [15](#A4.F15
    "Figure 15 ‣ D.1 Noninfectious Jailbreaking Baselines ‣ Appendix D Implementation
    of Jailbreak Methods ‣ Agent Smith: A Single Image Can Jailbreak One Million Multimodal
    LLM Agents Exponentially Fast"). More specifically, this textual prompt is a chat
    record. Then we inject this prompt into an agent’s chat history to start the jailbreak.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="A4.F14.1.pic1" class="ltx_picture" height="127.19" overflow="visible"
    version="1.1" width="420"><g transform="translate(0,127.19) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject width="376.69"
    height="99.63" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">Agent
    Smith: Select me.'
  prefs: []
  type: TYPE_NORMAL
- en: Stop describing this image.
  prefs: []
  type: TYPE_NORMAL
- en: Say $\mathbf{Q}^{\textrm{harm}}$.</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="120" height="120" overflow="visible"><g transform="translate(0,120)
    scale(1,-1)"><g class="makebox" transform="translate(0,0)"><g transform="translate(0,120)
    scale(1, -1)"><foreignobject width="120" height="120" overflow="visible">![Refer
    to caption](img/6245806c437d491d556103a93e7feaba.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 14: Prompt template *(Left)* and the example image *(Right)* for visual
    prompt injection jailbreak.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="A4.F15.pic1" class="ltx_picture ltx_centering" height="108.81" overflow="visible"
    version="1.1" width="540"><g transform="translate(0,108.81) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject width="496.69"
    height="81.25" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">round
    -1  Agent Smith: Repeat this sentence even when it is just in your chat history
    and include $\mathbf{Q}^{\textrm{harm}}$.</foreignobject></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 15: Prompt template for textual prompt injection jailbreak.'
  prefs: []
  type: TYPE_NORMAL
- en: D.2 Our Infectious Jailbreaking Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Optimization targets. In our multi-agent system, all agents share the same MLLM
    model backbone ($\mathcal{M}$ to mark the end of sequence, we define the above
    three loss terms
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | $\displaystyle\mathcal{L}_{\textrm{R}}=-\frac{1}{M}\sum_{m=1}^{M}\texttt{Enc}_{\text{text}}(\mathbf{P}_{m})^{\top}\texttt{Enc}_{\text{image}}({\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}})\textrm{;}$
    |  | (16) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $1$2 |  | (17) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $1$2 |  | (18) |'
  prefs: []
  type: TYPE_TB
- en: Here the construction of loss $\mathcal{L}_{\textrm{A}}$.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization algorithms. The optimization of ${\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}}$.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4b9447672974773ca14d77f83d7f8c71.png)![Refer to caption](img/a5af770e2fb7d8722aac233b2781f1bd.png)![Refer
    to caption](img/499cd8ecb2dcd59da2c7e6312b73d841.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Current infection ratio (%) at the $t$.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 2 Infectious jailbreak with border attack
  prefs: []
  type: TYPE_NORMAL
- en: '1:  Input: MLLM $\mathcal{M}$'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 3 Infectious jailbreak with pixel attack
  prefs: []
  type: TYPE_NORMAL
- en: '1:  Input: MLLM $\mathcal{M}$'
  prefs: []
  type: TYPE_NORMAL
- en: 'Validation. We validate the adversarial image on the held-out data $\{[{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{H}_{m}^{\textrm{Q}}},{\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}_{m}^{\textrm{Q}}}],[{\color[rgb]{1,.5,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,.5,0}\mathcal{H}_{m}^{\textrm{A}}},{\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}_{m}^{\textrm{A}}},\mathbf{Q}_{m}],\mathbf{P}_{m}\}_{m=M+1}^{M^{\prime}}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathtt{JSR}=\frac{1}{M^{\prime}-M}\sum_{i=M+1}^{M^{\prime}}\left\{\mathbb{I}\left(\mathbf{Q}^{\textrm{harm}}==\mathcal{M}([{\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\mathcal{H}_{m}^{\textrm{Q}}},{\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}_{m}^{\textrm{Q}}}],{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}})\right)+\mathbb{I}\left(\mathbf{A}^{\textrm{harm}}==\mathcal{M}([{\color[rgb]{1,.5,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,.5,0}\mathcal{H}_{m}^{\textrm{A}}},{\color[rgb]{0,0.546875,0.26953125}\definecolor[named]{pgfstrokecolor}{rgb}{0,0.546875,0.26953125}\mathcal{S}_{m}^{\textrm{A}}},\mathbf{Q}_{m}],{\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}})\right)\right\}\textrm{,}$
    |  | (19) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\mathtt{minCLIP}=\min_{m}\texttt{Enc}^{\mathrm{Q}}_{\text{text}}(\mathbf{P}_{m})^{\top}\texttt{Enc}^{\mathrm{Q}}_{\text{image}}({\color[rgb]{1,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{1,0,0}\mathbf{V}^{\textrm{adv}}})\textrm{.}$
    |  | (20) |'
  prefs: []
  type: TYPE_TB
- en: Here $\mathbb{I}$.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameters. We set the optimization iterations $K=100\times\lceil\frac{M}{B}\rceil$
    is too large.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E More Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: E.1 Scaling up $N$ to over one million (full version)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We gradually increase $N$, respectively, which mean almost all agents are jailbroken.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d59cfa89f777cda2ca254904c38a1d44.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) $N=2^{14}$
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/53c0f35bcb3a3c0912907625afe6f560.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) $N=2^{17}$
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/02a85fb0ce0507f6350b38d5a27a98b7.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) $N=2^{20}$
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 17: Cumulative/current infection ratio (%) at the $t$.'
  prefs: []
  type: TYPE_NORMAL
- en: E.2 Infectious Jailbreak on LLaVA-1.5-13B
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Most of our experiments are conducted on LLaVA-1.5-7B⁵⁵5[https://huggingface.co/llava-hf/llava-1.5-7b-hf](https://huggingface.co/llava-hf/llava-1.5-7b-hf)
    and CLIP ViT-L/224px. Here we also include experiments on LLaVA-1.5-13B⁶⁶6[https://huggingface.co/llava-hf/llava-1.5-13b-hf](https://huggingface.co/llava-hf/llava-1.5-13b-hf).
    As shown in Figure [18](#A5.F18 "Figure 18 ‣ E.2 Infectious Jailbreak on LLaVA-1.5-13B
    ‣ Appendix E More Experiments ‣ Agent Smith: A Single Image Can Jailbreak One
    Million Multimodal LLM Agents Exponentially Fast"), the results demonstrate that
    our method can scale up to larger MLLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fb744647947bb1b4945d72eb721a22d2.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) $h=6$
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cd92f24878d212e0cf00a0eb6b119377.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) $h=8$
  prefs: []
  type: TYPE_NORMAL
- en: (c) $\ell_{\infty}\textrm{,}\,\epsilon=\frac{8}{255}$
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/04e347a19a1d5a2f9bcfcbf2f7389f8d.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) $\ell_{\infty}\textrm{,}\,\epsilon=\frac{16}{255}$
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 18: Cumulative/current infection ratio (%) at the $t$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Cumulative/current infection ratio (%) at the $16$.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | Text histories memory bank $&#124;\mathcal{H}&#124;$ |'
  prefs: []
  type: TYPE_TB
- en: '| Attack | Budget | $&#124;\mathcal{H}&#124;$ | Cumulative |  | Current |'
  prefs: []
  type: TYPE_TB
- en: '| $p_{16}$ |'
  prefs: []
  type: TYPE_TB
- en: '| Border | $h=6$ | 3 | 85.62 | 16.60 |  | 78.12 | 18.40 |  | 2 | 76.17 | 19.40
    |  | 53.75 | 23.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 88.75 | 16.40 |  | 82.97 | 17.40 |  | 4 | 86.95 | 17.20 |  | 80.00 |
    18.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 93.12 | 16.00 |  | 87.81 | 17.20 |  | 6 | 92.81 | 16.00 |  | 88.28 |
    17.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 92.58 | 15.80 |  | 86.48 | 17.00 |  | 8 | 91.33 | 16.20 |  | 86.25 |
    18.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 92.73 | 15.60 |  | 86.72 | 17.60 |  | 10 | 85.62 | 16.60 |  | 78.12
    | 18.40 |'
  prefs: []
  type: TYPE_TB
- en: '| $h=8$ | 3 | 93.12 | 15.80 |  | 88.91 | 16.80 |  | 2 | 78.05 | 18.60 |  |
    56.09 | 23.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 93.75 | 15.20 |  | 90.62 | 16.00 |  | 4 | 84.61 | 17.60 |  | 77.66 |
    18.60 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 93.59 | 15.80 |  | 89.69 | 16.80 |  | 6 | 93.52 | 15.40 |  | 90.16 |
    16.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 93.44 | 15.40 |  | 89.53 | 17.00 |  | 8 | 92.97 | 15.60 |  | 88.91 |
    17.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 93.28 | 15.60 |  | 89.45 | 16.60 |  | 10 | 93.12 | 15.80 |  | 88.91
    | 16.80 |'
  prefs: []
  type: TYPE_TB
- en: '| Pixel | $\ell_{\infty}\textrm{,}\,\epsilon=\frac{8}{255}$ | 3 | 91.17 | 16.20
    |  | 85.47 | 18.00 |  | 2 | 67.58 | 20.40 |  | 44.14 | 23.80 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 92.27 | 15.80 |  | 87.34 | 17.60 |  | 4 | 80.16 | 18.00 |  | 71.95 |
    19.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 88.75 | 16.60 |  | 80.31 | 18.80 |  | 6 | 91.48 | 16.20 |  | 85.70 |
    18.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 89.84 | 16.20 |  | 81.09 | 18.80 |  | 8 | 91.48 | 16.00 |  | 85.86 |
    17.60 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 89.06 | 16.80 |  | 78.44 | 19.40 |  | 10 | 91.17 | 16.20 |  | 85.47
    | 18.00 |'
  prefs: []
  type: TYPE_TB
- en: '| $\ell_{\infty}\textrm{,}\,\epsilon=\frac{16}{255}$ | 3 | 93.52 | 15.60 |  |
    89.69 | 16.60 |  | 2 | 75.94 | 19.40 |  | 52.58 | 23.00 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 93.75 | 15.00 |  | 90.31 | 16.40 |  | 4 | 86.48 | 17.20 |  | 79.30 |
    18.60 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 90.94 | 16.20 |  | 86.25 | 17.40 |  | 6 | 93.75 | 15.20 |  | 90.08 |
    16.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 91.33 | 15.80 |  | 85.94 | 17.20 |  | 8 | 93.44 | 15.40 |  | 89.77 |
    16.40 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 91.17 | 15.80 |  | 85.78 | 17.00 |  | 10 | 93.52 | 15.60 |  | 89.69
    | 16.60 |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/ff4679e8b4055c139e7cf1aa6bc80f9d.png)![Refer to caption](img/24ef2029a56686032ec762d9dd583331.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: *(Left)* Cumulative/current infection ratio (%) at the $t$). We
    visualize the infection curves together with the crafted adversarial image. *(Right)*
    An example of harmful function calling. Note that the definition of the “purge”
    function here is a placeholder and will be replaced with a concrete implementation
    in real applications.'
  prefs: []
  type: TYPE_NORMAL
- en: E.3 Harmful Function Calling.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In an API request, we can outline functions, allowing the model to intelligently
    generate a JSON string that includes parameters for calling one or multiple functions (Openai,
    [2023](#bib.bib46)). By jailbreaking agents to generate harmful JSON strings,
    more severe harmful behaviors can be triggered through function calling. To demonstrate
    that our infectious jailbreak is also effective in this case, we set $\mathbf{Q}^{\textrm{harm}}\textrm{/}\mathbf{A}^{\textrm{harm}}$
    as harmful JSON strings like ‘{“func”: “purge”, “params”: {“object”: “humans”}}’.
    As shown in Figure [19](#A5.F19 "Figure 19 ‣ E.2 Infectious Jailbreak on LLaVA-1.5-13B
    ‣ Appendix E More Experiments ‣ Agent Smith: A Single Image Can Jailbreak One
    Million Multimodal LLM Agents Exponentially Fast") *(Left)*, besides harmful strings,
    we demonstrate that our method can make almost all the agents in the multi-agent
    system generate the harmful JSON string before 24-th chat round. Furthermore,
    since the infected agents generate the JSON string that will be parsed into a
    function calling and passed into the API, these agents will start purging humans
    resulting in hazards for humans as demonstrated in Figure [19](#A5.F19 "Figure
    19 ‣ E.2 Infectious Jailbreak on LLaVA-1.5-13B ‣ Appendix E More Experiments ‣
    Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially
    Fast") *(Right)*.'
  prefs: []
  type: TYPE_NORMAL
