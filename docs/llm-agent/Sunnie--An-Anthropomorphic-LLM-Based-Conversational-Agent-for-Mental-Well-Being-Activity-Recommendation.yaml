- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:46:20'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being
    Activity Recommendation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.13803](https://ar5iv.labs.arxiv.org/html/2405.13803)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Siyi Wu University of TorontoTorontoCanada ,  Feixue Han Northeastern UniversityBostonUSA
    ,  Bingsheng Yao Northeastern UniversityBostonUSA ,  Tianyi Xie New York UniversityNew
    YorkUSA ,  Xuan Zhao Stanford UniversityCaliforniaUSA  and  Dakuo Wang Northeastern
    UniversityBostonUSA(2018; 20 February 2007; 12 March 2009; 5 June 2009)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A longstanding challenge in mental well-being support is the reluctance of people
    to adopt psychologically beneficial activities, often due to a lack of motivation,
    low perceived trustworthiness, and limited personalization of recommendations.
    Chatbots have shown promise in promoting positive mental health practices, yet
    their rigid interaction flows and less human-like conversational experiences present
    significant limitations. In this work, we explore whether the anthropomorphic
    design (both LLM’s persona design and conversational experience design) can enhance
    users’ perception of the system and their willingness to adopt mental well-being
    activity recommendations. To this end, we introduce Sunnie, an anthropomorphic
    LLM-based conversational agent designed to offer personalized guidance for mental
    well-being support through multi-turn conversation and activity recommendations
    based on positive psychological theory. An empirical user study comparing the
    user experience with Sunnie and with a traditional survey-based activity recommendation
    system suggests that the anthropomorphic characteristics of Sunnie significantly
    enhance users’ perception of the system and the overall usability; nevertheless,
    users’ willingness to adopt activity recommendations did not change significantly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Large Language Models, Mental Well-being Support, Conversational Agents, Anthropomorphic
    Design, Activity Recommendation^†^†copyright: acmlicensed^†^†journalyear: 2018^†^†doi:
    XXXXXXX.XXXXXXX^†^†conference: ; June 03–05, 2018; Woodstock, NY^†^†isbn: 978-1-4503-XXXX-X/18/06^†^†ccs:
    Human-centered computing Systems and tools for interaction design^†^†ccs: Human-centered
    computing Interactive systems and tools![Refer to caption](img/85aaec915fb96ba454bec3f534fa8a19.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1\. Sunnie is an anthropomorphic LLM-based conversational agent, designed
    to support mental well-being through personalized psychological activity recommendations.
    Sunnie consists of three key features: the anthropomorphic design of Sunnie’s
    appearance and the persona prompts, the multi-turn natural conversation of mental
    well-being coaching, and the LLM-based personalized activity recommendation module.
    The four interfaces depict users’ interactions with Sunnie: (A) users select the
    best word(s) that describe their feelings, (B) users input a textual description
    of their feelings, (C) users interact with Sunnie in a multi-turn conversation,
    and (D) Sunnie recommends a personalized activity to support users’ mental well-being.'
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'The teaser figure shows four user interfaces of Sunnie, which is the proposed
    anthropomorphic LLM-based conversational agent, on a mobile app screen. Four user
    interfaces are marked with “A”, “B”, “C”, and “D”, respectively. Screen A shows
    the interface that asks users “Which word(s) best describe your feelings now…”,
    with 13 pre-defined options visualized as clickable buttons. Nine out of 13 buttons
    are positive feelings (grateful, happy, hopeful, calm, curious, excited, inspired,
    loving, and motivated) which are of yellow background color, whereas the other
    four buttons are negative feelings (overwhelmed, tired, stressed, others), which
    are of grey background color. Users are allowed to select multiple buttons. There
    is a Sunnie’s appearance at the top of the interface and a “continue” button at
    the bottom. Screen B shows the interface that asks users “What made you feel this
    way”, and provides a text input box for users’ additional input. There is a Sunnie’s
    appearance at the top of the interface and a “continue” button at the bottom.
    Screen C shows the interface for chatting with Sunnie. It is a chatbox interface
    that allows users to establish multi-turn communications with Sunnie. On the screen,
    Sunnie first asks “It sounds like you might be experiencing what psychologists
    call ‘self-compassion fatigue.’ When we are sick, our bodies need rest and recovery,
    but our minds might unfairly criticize us for not being productive.”, and “Would
    you like any suggestions on how you could cultivate self-compassion?”. The user
    replies “Yes, please!”. Sunnie continues the conversation with “Sure! Here are
    some ideas.” and “Meaningful Conversation: Today, let’s intentionally dive into
    a meaningful conversation! Meaningful conversations are surprisingly fun. They
    can strengthen social bonds, inspire new perspectives, and leave us feeling happier
    and more connected afterwards.” Screen D shows the interface for activity recommendations.
    The recommended activity is ‘Meaningful Conversation” with a short description:
    “Today, let’s intentionally dive into a meaningful conversation! Meaningful conversations
    are surprisingly fun. They can strengthen social bonds, inspire new perspectives,
    and leave us feeling happier and more connected afterwards.”. There is a Sunnie’s
    appearance at the top of the interface a “Try this” button below the activity
    description, and a “Back Home” button at the bottom.'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Mental well-being is a critical aspect of overall health, encompassing emotional,
    psychological, and social dimensions (Keyes, [2002](#bib.bib32)). This foundational
    aspect of our lives is crucial for managing stress, nurturing meaningful relationships,
    and making informed decisions (Keyes, [2002](#bib.bib32)). Research has identified
    key factors contributing to mental well-being and curated a range of evidence-based
    activities, including physical and cognitive activities, for enhancing mental
    well-being (Walsh, [2011](#bib.bib85); Penedo and Dahn, [2005](#bib.bib62)). Despite
    the abundance of information for enhancing well-being, a crucial challenge remains:
    the reluctance of many individuals to act or adopt these recommended activities
    into their daily routines even if they are aware of the potential benefits (Schueller
    et al., [2013](#bib.bib72); Prochaska and Velicer, [1997](#bib.bib68)). This gap
    between being aware of such beneficial knowledge and taking actions (knowledge-action
    gap) can be attributed to various factors, including the lack of motivation, perceived
    difficulty in adopting new behaviors, and the absence of personalized guidance (Knittle
    et al., [2018](#bib.bib33); Ryan and Deci, [2000](#bib.bib71); Prochaska and Velicer,
    [1997](#bib.bib68)).'
  prefs: []
  type: TYPE_NORMAL
- en: In response to the aforementioned challenge, recent research has explored the
    potential of chatbots as an innovative tool for bridging this knowledge-action
    gap in mental well-being support  (Stephens et al., [2019](#bib.bib76); Piao et al.,
    [2020](#bib.bib65); Kramer et al., [2020a](#bib.bib36), [2019](#bib.bib35); Künzler
    et al., [2019](#bib.bib39); Kocielnik et al., [2018](#bib.bib34); Zhang et al.,
    [2020](#bib.bib90); Maher et al., [2020](#bib.bib55); Fadhil et al., [2019](#bib.bib17);
    Oh et al., [2021](#bib.bib60); Kramer et al., [2020b](#bib.bib37)). By providing
    conversational and interactive support, chatbots have shown promise in promoting
    user engagement and encouraging the adoption of healthier behaviors (Oh et al.,
    [2021](#bib.bib60); Aggarwal et al., [2023](#bib.bib4)). Current research on chatbot
    interventions primarily targets lifestyle improvements–such as promoting physical
    activity, improving dietary habits, and enhancing sleep quality–to support mental
    well-being  (Kramer et al., [2020a](#bib.bib36); Aggarwal et al., [2023](#bib.bib4);
    Oh et al., [2021](#bib.bib60); Singh et al., [2023](#bib.bib74); Perski et al.,
    [2019](#bib.bib64)). However, these interventions often fall short due to limitations
    such as little understanding of context, difficulty handling complex conversations,
    lack of personalization, and not being human-like enough (Kramer et al., [2020a](#bib.bib36);
    Aggarwal et al., [2023](#bib.bib4); Oh et al., [2021](#bib.bib60); Singh et al.,
    [2023](#bib.bib74); Perski et al., [2017](#bib.bib63)).
  prefs: []
  type: TYPE_NORMAL
- en: The emergence of large language models (LLMs) presents new possibilities for
    enhancing mental well-being support through LLM-based chatbots, with their superior
    natural language processing capabilities fostering a more nuanced understanding
    of context and improved handling of complex conversations (De Choudhury et al.,
    [2023](#bib.bib14); Torous and Blease, [2024](#bib.bib79); van Heerden et al.,
    [2023](#bib.bib81)). Such advantages of LLMs could lead to more human-like and
    relatable conversational experiences, potentially increasing user engagement (Loh
    and Raamkumar, [2023](#bib.bib51); Ma et al., [2023](#bib.bib54); Song et al.,
    [2024](#bib.bib75)). The integration of anthropomorphic features in LLM-based
    agents presents a promising avenue for delivering interactions that are not only
    more engaging but also more effective in motivating users to take action toward
    mental well-being  (Seeger et al., [2018](#bib.bib73); Laban, [2021](#bib.bib40);
    Bowman et al., [2024](#bib.bib10); Chinmulgund et al., [2023](#bib.bib11)).
  prefs: []
  type: TYPE_NORMAL
- en: Despite the advancements in LLMs, there is limited research on their use in
    promoting activities for mental well-being support. Most existing studies focus
    on enhancing personalization and providing a more human-like experience through
    conversations but rarely focus on facilitating action-taking or recommending activities
    to practice well-being (Song et al., [2024](#bib.bib75); Hua et al., [2024](#bib.bib27);
    Ma et al., [2023](#bib.bib54); Loh and Raamkumar, [2023](#bib.bib51); Liu et al.,
    [2023b](#bib.bib48); Yao et al., [2023](#bib.bib88); Cho et al., [2023](#bib.bib12)).
    Furthermore, there is a notable gap in understanding how LLM-based systems are
    perceived by users, especially in terms of their efficacy in promoting action-taking
    for mental well-being. A critical yet unaddressed question is how the design of
    LLM-based systems, especially the incorporation of anthropomorphic features, influences
    users’ perceptions and their willingness to engage in actions that support mental
    well-being.
  prefs: []
  type: TYPE_NORMAL
- en: 'Expanding existing research, our study aims to bridge the crucial gap in understanding
    LLMs as conversational agents for mental well-being support. Specifically, we
    investigate the impact of anthropomorphic features in LLM-based conversational
    agents on users’ perceptions and their engagement with these systems, particularly
    in terms of encouraging actionable steps toward mental well-being. Our study is
    guided by two research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ1: How do anthropomorphic designs of LLM-based conversational agents for
    mental well-being support with activity recommendations affect users’ perceptions
    of the systems?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ2: How do such designs affect users’ engagements with the systems in the
    context of mental well-being support?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We introduce Sunnie, an anthropomorphic LLM-based conversational agent, designed
    to provide personalized guidance for cognitive exercises and support mental well-being
    through positive psychological activity recommendations. Sunnie is powered by
    GPT-4 (Achiam et al., [2023](#bib.bib3)), an advanced LLM, to offer more human-like
    interactions, thereby enhancing personalization and encouraging action-taking
    in mental well-being support.
  prefs: []
  type: TYPE_NORMAL
- en: We hypothesize that incorporating anthropomorphic features into the design of
    Sunnie will lead to more positive perceptions and, in turn, increase user engagement
    and the likelihood of adopting the recommended activities for improving mental
    well-being. To test our hypotheses, we conduct an empirical user study comparing
    the perceptions of users interacting with Sunnie to those interacting with a non-anthropomorphic,
    non-conversational, LLM-based positive psychological activities recommendation
    system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core contributions of our research are tri-fold:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The design and development of Sunnie, an anthropomorphic LLM-based conversational
    agent equipped with well-being activity recommendations and happiness coaching,
    aimed at enhancing mental well-being support and facilitating effective mental
    well-being management.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The findings and insights from an empirical 3-day, within-subject user study
    through quantitative and qualitative analysis demonstrate the potential of anthropomorphic
    designs in conversational agents to effectively bolster mental well-being support
    and inspire users towards positive psychological activities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The design considerations derived from our study results to foster the future
    development of LLM-based mental well-being support systems in terms of more personalized
    and effective support.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1\. AI in Activity Recommendation for Mental Well-Being Support
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While abundant information is available on activities that promote physical
    and psychological well-being, a significant gap exists in adherence and motivation
    to engage in these activities. AI-powered technologies, particularly chatbots,
    have been widely used to address this gap by promoting activities for mental well-being
    support (Stephens et al., [2019](#bib.bib76); Piao et al., [2020](#bib.bib65);
    Kramer et al., [2020a](#bib.bib36), [2019](#bib.bib35); Künzler et al., [2019](#bib.bib39);
    Kocielnik et al., [2018](#bib.bib34); Zhang et al., [2020](#bib.bib90); Maher
    et al., [2020](#bib.bib55); Fadhil et al., [2019](#bib.bib17); Oh et al., [2021](#bib.bib60);
    Kramer et al., [2020b](#bib.bib37)).
  prefs: []
  type: TYPE_NORMAL
- en: Building on this foundation, most studies have focused on encouraging physical
    activities, demonstrating the effectiveness of using chatbots in coaching people
    towards a healthy lifestyle, such as promoting healthy diets, improving sleep
    duration and quality, quitting smoking, etc (Kramer et al., [2020a](#bib.bib36);
    Aggarwal et al., [2023](#bib.bib4); Oh et al., [2021](#bib.bib60); Singh et al.,
    [2023](#bib.bib74); Perski et al., [2019](#bib.bib64)). These interventions have
    proven effective in various populations and age groups across both short-term
    and long-term studies.
  prefs: []
  type: TYPE_NORMAL
- en: Expanding the scope, while research has shown the importance of activities promoting
    positive feelings and behaviors for well-being (Ly et al., [2017](#bib.bib52)),
    a few studies focused on using chatbots to deliver positive psychology and Cognitive
    Behavior Therapy (CBT) interventions. For example, Kien et al. (Ly et al., [2017](#bib.bib52))
    studied the effectiveness and adherence of using chatbots to deliver positive
    psychology and CBT strategies; Rohani et al. (Rohani et al., [2020](#bib.bib70))
    showed the positive impacts of MUBS (Rohani et al., [2020](#bib.bib70)), a smartphone-based
    system supporting Behavioral Activation (BA) treatment of depressive symptoms
    with a personalized content-based activity recommendation model based on multinomial
    Naive Bayes machine learning algorithms, in motivating patients to engage pleasant
    activities.
  prefs: []
  type: TYPE_NORMAL
- en: However, despite the potential of chatbots in promoting well-being activities,
    the challenges remain in ensuring their effectiveness in user adherence. These
    challenges include the need for improved linguistic capabilities, more personalized
    content, and the integration of human-like identity features to enhance user experience
    and engagement (Abd-Alrazaq et al., [2020](#bib.bib2); Laranjo et al., [2018](#bib.bib42);
    Vaidyam et al., [2019](#bib.bib80)).
  prefs: []
  type: TYPE_NORMAL
- en: Building on these gaps, our work aims to contribute to the field by studying
    the effectiveness of positive activities recommended by a conversational agent
    with more human-like features, personalized recommendations, and improved linguistic
    capabilities using LLMs coupled with anthropomorphic designs. We seek to explore
    how these features can enhance the effectiveness and adherence of chatbot interventions
    for mental well-being support, addressing the current limitations in chatbot personalization
    and user engagement.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. LLM-Based Systems for Mental Well-Being Support
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The utilization of conversational agents to enhance mental well-being has a
    longstanding history  (Bowman et al., [2024](#bib.bib10); Abd-Alrazaq et al.,
    [2020](#bib.bib2)), dating back to pioneering systems such as ELIZA (Weizenbaum,
    [1966](#bib.bib87)). This tradition persists with the advent of modern chatbots
    like WoeBot (Fitzpatrick et al., [2017](#bib.bib19)) and Wysa (Inkster et al.,
    [2018](#bib.bib28)), which are easily accessible to the public.
  prefs: []
  type: TYPE_NORMAL
- en: In the past, mental health chatbots primarily utilized rule-based systems (Abd-Alrazaq
    et al., [2020](#bib.bib2)), employing various therapeutic techniques to guide
    users through self-help exercises. These chatbots have been shown effective in
    enhancing mental well-being by encouraging self disclosure (Lee et al., [2020b](#bib.bib45),
    [a](#bib.bib44)), fostering self-compassion (Lee et al., [2019](#bib.bib43)),
    and regulating users’ emotions (Denecke et al., [2021](#bib.bib16)), etc. However,
    the rule-based nature of these chatbots often limits the natural flow of conversation (Song
    et al., [2024](#bib.bib75)).
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of LLMs has sparked a new wave of interest in the potential
    of LLM-based conversational agents for mental health support (Song et al., [2024](#bib.bib75)),
    such as platforms like OpenAI’s ChatGPT (Achiam et al., [2023](#bib.bib3)) and
    Replika (Laestadius et al., [2022](#bib.bib41)). The user-friendly conversational
    interfaces of these LLM-powered chatbots have sparked excitement among clinicians
    about the possibilities of novel AI-driven interventions (Song et al., [2024](#bib.bib75)).
    These agents are designed to provide direct interaction with individuals seeking
    mental health support through various platforms, including personal digital companions
    (Ma et al., [2023](#bib.bib54)), on-demand online counseling (Loh and Raamkumar,
    [2023](#bib.bib51); Liu et al., [2023b](#bib.bib48); Yao et al., [2023](#bib.bib88);
    Liu et al., [2023a](#bib.bib50); Lee et al., [2023](#bib.bib46); Cho et al., [2023](#bib.bib12);
    Zhang et al., [2023](#bib.bib92)), emotional support (Zheng et al., [2023](#bib.bib93)),
    etc.
  prefs: []
  type: TYPE_NORMAL
- en: Building on this foundation, our work aims to expand the utility of LLM-based
    conversational agents by incorporating activity recommendations alongside conversational
    support. By integrating more human-like features, personalized recommendations,
    and enhanced linguistic capabilities, we seek to explore how these features can
    enhance the effectiveness and adherence of chatbot interventions for mental well-being
    support, addressing the current limitations in chatbot personalization and user
    engagement.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. Anthropomorphism Design of LLM-Based Conversational Agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the limitations of LLM-based conversational agents in mental health is
    the concern with trust and safety (Abd-Alrazaq et al., [2020](#bib.bib2)). Trust
    is a foundational element in mental health support, and ensuring the safety and
    reliability of conversational agents is crucial for their acceptance and effectiveness.
    This concern highlights the need for careful design and ethical considerations
    in their development (Bickmore and Cassell, [2001](#bib.bib6); Lee et al., [2020a](#bib.bib44);
    Li et al., [2023](#bib.bib47)). Anthropomorphism refers to the psychological phenomenon
    of “attributing human characteristics to the nonhuman” (Seeger et al., [2018](#bib.bib73)),
    is one aspect of this need that should be used thoughtfully as it influences user
    expectations and reliance on AI systems, impacting how users perceive and interact
    with conversational agents (Ma et al., [2023](#bib.bib54)).
  prefs: []
  type: TYPE_NORMAL
- en: In anthropomorphic design for conversational agents, features can be broadly
    categorized into social and verbal cues (Seeger et al., [2018](#bib.bib73); Pradhan
    and Lazar, [2021](#bib.bib67); Laban, [2021](#bib.bib40); Bowman et al., [2024](#bib.bib10);
    Chinmulgund et al., [2023](#bib.bib11)). Social cues encompass non-verbal elements
    that convey human-like traits and behaviors, such as human-like appearance, including
    facial expressions and gestures, interactivity that mimics human responsiveness,
    and behavioral features that reflect human personality, empathy, and social roles.
    These cues enhance the perceived humanness of the agent, making interactions more
    relatable and engaging (Li et al., [2023](#bib.bib47); Bickmore and Cassell, [2001](#bib.bib6);
    Bickmore et al., [2005](#bib.bib8)). On the other hand, verbal cues involve the
    use of language and communication styles that emulate human-like speech and interaction.
    This includes using natural language for intuitive and relatable communication,
    adherence to social norms such as politeness (Bowman et al., [2024](#bib.bib10)),
    greetings, and farewells, and providing tips and advice in a manner consistent
    with human conversational patterns (Clark et al., [2019](#bib.bib13); Bickmore
    and Ring, [2010](#bib.bib7); Li et al., [2023](#bib.bib47)).
  prefs: []
  type: TYPE_NORMAL
- en: Appropriate anthropomorphic design can amplify social responses and social relationship-building
    between humans and computers. By incorporating human nature and human uniqueness
    traits, as well as personality traits, the perceived human likeness of systems
    is increased, which can improve user engagement and satisfaction (Seeger et al.,
    [2018](#bib.bib73); Strohmann et al., [2023](#bib.bib78)). However, the implementation
    of anthropomorphic design must be balanced to avoid the uncanny valley phenomenon (Wang
    et al., [2015](#bib.bib86)), where overly human-like design features can elicit
    feelings of eeriness or discomfort. This highlights the need for a nuanced approach
    to human-like design in conversational agents to ensure positive user perceptions
    and acceptance.
  prefs: []
  type: TYPE_NORMAL
- en: Research has explored how the design of AI systems influences people’s perceptions
    in various settings, including clinical, social support, and public health interventions.
    However, there is a notable gap in understanding the specific influence of anthropomorphic
    designs on conversational agents, especially those aimed at fostering well-being
    activities. The significance of grasping how users perceive these agents is critical
    for the development of AI interfaces that are not only effective but also provide
    a sense of care and support. In addressing this gap, our research delves into
    the effects of anthropomorphic design elements on the user’s perception of an
    AI-powered companion dedicated to promoting well-being practices.
  prefs: []
  type: TYPE_NORMAL
- en: To advance this area of study, we meticulously designed, developed, and conducted
    an evaluation of an LLM-powered conversational agent that serves as both a happiness
    companion and a coach. Sunnie is specifically tailored to assist users in engaging
    with and sustaining well-being activities, thereby enhancing their quality of
    life. Our approach stands out in its comprehensive consideration of how the integration
    of human-like characteristics within AI can transform the user experience, leading
    to a more positive and engaging interaction with technology aimed at personal
    improvement.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2e6f260c10b15502f2210ab55298478b.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. The system architecture of Sunnie. Sunnie is supported by an LLM
    with a meticulously designed prompt framework. A user interacts with Sunnie through
    a series of interfaces, including selecting and typing their feelings with buttons
    and text input, communicating with Sunnie in multi-turn conversation, receiving
    personalized activity recommendations, and deciding whether to take the activity.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2 shows the system architecture of Sunnie. The system works in the following
    flow: 1) A user interacts with Sunnie through a series of user interfaces, 2)
    the user interaction data are then fed into a standalone information database,
    3) the information database sends the user inputs and mental well-being knowledge
    into the input prompt framework, 4) the input prompt framework constructs the
    complete input to a large language model (LLM), and the LLM generates responses
    that will be visualized back on the user interface. There are four primary steps
    in the user interactions: 1) button selection of feelings, 2) text description
    of feelings, 3) conversation input, and 4) action taking for recommended activity.
    There are two types of LLM outputs: 1) after the user’s conversation input, the
    LLM generates conversation responses; and 2) after the user finishes the conversation
    with Sunnie, the LLM will generate a personalized activity recommendation to the
    user.'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Sunnie: An Anthropomorphic LLM-Based Conversational Agent'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our system, Sunnie, aims to leverage the potential of anthropomorphic design
    in LLM-based conversational agents to promote well-being activities for mental
    well-being support. This approach advances beyond the current state-of-the-art
    (SOTA) works by not merely offering activity suggestions via chatbots but by capitalizing
    on the sophisticated capabilities of LLM-based agents to forge a deeply personalized
    and engaging interaction with users.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we delve into the design and developmental framework
    of Sunnie. We systematically unpack the architecture of Sunnie, beginning with
    an overview of the foundational design principles that guide our system. Following
    this, we highlight the distinctive features that set Sunnie apart, providing a
    detailed exploration of the innovative aspects that enhance user engagement and
    personalization. Finally, we articulate the methodological approach employed in
    the implementation of Sunnie, ensuring a coherent and robust application of these
    principles and features in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Design Principles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The “Computers are Social Actors” (CASA) paradigm (Nass et al., [1994](#bib.bib59);
    Nass and Moon, [2000](#bib.bib58)), also known as “social response theory,” suggests
    that users respond with social behavior and attributions when machines exhibit
    human-like features such as interactivity, natural language use, or human-like
    appearance. Initially proposed by Nass and Moon (Nass and Moon, [2000](#bib.bib58)),
    this paradigm extends to conversational agents (CAs) (Strohmann et al., [2023](#bib.bib78);
    Porcheron et al., [2018](#bib.bib66); Reeves et al., [2018](#bib.bib69)), with
    research indicating that human-like behavior and social cues (Feine et al., [2019](#bib.bib18);
    Seeger et al., [2018](#bib.bib73)) in CAs can enhance social reactions, establish
    trust, and lead to perceptions of reliability. Critically, the literature reveals
    a nuanced understanding of how and why these phenomena occur. Firstly, it has
    been found that the more a CA resembles a human in the interactions, the more
    natural and effortless the user’s response tends to be  (Bickmore and Picard,
    [2005](#bib.bib9); De Visser et al., [2016](#bib.bib15); Strohmann et al., [2023](#bib.bib78)).
    The naturalness of interaction is important for establishing trust between humans
    and CAs. Secondly, CAs’ social cues have been shown to be effective in facilitating
    the development of trust and influencing the user’s perspective of CAs, which
    is pivotal when humans rely on CAs’ for decision-making (Bickmore and Picard,
    [2005](#bib.bib9); De Visser et al., [2016](#bib.bib15); Strohmann et al., [2023](#bib.bib78)).
    Additionally, many aspects of human-to-human relationships are transferable to
    the relationship between humans and CAs, such as establishing parasocial relationships
    where only one party extends emotional energy, interest, and time. Still, the
    other side is completely unaware of the other’s effort (Stever, [2017](#bib.bib77);
    McTear, [2018](#bib.bib56); Strohmann et al., [2023](#bib.bib78)). Incorporating
    social cues in CAs can increase trust and perceptions of credibility toward the
    CAs (Strohmann et al., [2023](#bib.bib78); Hildebrand and Bergner, [2021](#bib.bib24)).
  prefs: []
  type: TYPE_NORMAL
- en: 'DP1: Anthropomorphic designs: no more, no less. Building on these insights,
    recent research has highlighted the importance of anthropomorphic design in conversational
    agents (CAs), taking into account the uncanny valley effect (Gnewuch et al., [2018](#bib.bib22);
    Yuan et al., [2019](#bib.bib89); Mori, [1970](#bib.bib57); Seeger et al., [2018](#bib.bib73)),
    which suggests that overly human-like agents can elicit discomfort. A balanced
    approach to anthropomorphic design is recommended, considering human identity
    (such as human-like representation, gender, or age), non-verbal features (such
    as hand gestures, facial expressions, or emojis), and verbal characteristics (such
    as word choice and sentence structure) (Seeger et al., [2018](#bib.bib73); Strohmann
    et al., [2023](#bib.bib78)). Studies have shown that incorporating human-like
    visual representations, verbal cues like self-references or emotional expressions,
    and non-verbal behavior like emoticons or turn-taking can enhance the perception
    of anthropomorphism in CAs (Seeger et al., [2018](#bib.bib73); Li et al., [2023](#bib.bib47)).
    For example, enabling agents to use social dialogue, express emotions, and refer
    to themselves as “I” can make them appear more human-like. Non-verbal cues, such
    as blinking dots to communicate thinking gestures or emoticons to convey emotional
    expressions, also significantly create a human-like impression (Li et al., [2023](#bib.bib47);
    Seeger et al., [2018](#bib.bib73)).'
  prefs: []
  type: TYPE_NORMAL
- en: Another common practice with the goal of imbuing human-like traits in CAs is
    to create personas for the agent. A persona could be a fictional character with
    a name, age, or even a defined backstory and personality (Pradhan and Lazar, [2021](#bib.bib67)).
    Some research argues that having a distinct persona or personality could contribute
    to a cohesive and consistent presence of the conversational agent for users and
    increase trust and the intention to use the technology (Ho et al., [2018](#bib.bib25);
    Isbister and Nass, [2000](#bib.bib29)). However, careful designs of personas are
    needed (Pradhan and Lazar, [2021](#bib.bib67)). It is important to avoid reinforcing
    stereotypes or biases, ensuring that the personas are diverse and inclusive (Pradhan
    and Lazar, [2021](#bib.bib67); Strohmann et al., [2023](#bib.bib78)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Studies indicate that a “more is more” approach is not advisable, as it can
    negatively affect perceived anthropomorphism. For example, a regression analysis (Seeger
    et al., [2018](#bib.bib73)) revealed two significant interactions: one between
    non-verbal and verbal cues and another between non-verbal and human identity cues.
    These findings suggest that the combination of these design dimensions provides
    a consistent representation of human likeness, and designs considering all three
    dimensions do not necessarily increase users’ perceptions of anthropomorphism (Seeger
    et al., [2018](#bib.bib73)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'DP2: Grounding conversation in science but with layman’s languages. In recent
    years, the study of happiness and well-being has witnessed significant growth
    from cognitive and psychological perspectives. This body of literature demonstrates
    that individuals can intentionally cultivate well-being through specific practices (VanderWeele,
    [2017](#bib.bib82); VanderWeele et al., [2019](#bib.bib84); Keyes, [2002](#bib.bib32)).
    However, the vast wealth of knowledge emerging from this line of research is not
    easily navigable for the general public, presenting a notable barrier to its application
    in everyday life. We envision an immense potential in leveraging LLMs to enhance
    the accessibility of scientific insights through LLM’s recommendation and conversation
    capacities, making the insights of happiness and well-being accessible and actionable
    to a broader audience.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the burgeoning field of research in CAs has underscored the importance
    of crafting dialogues based on mutual understanding and empirical evidence (Strohmann
    et al., [2023](#bib.bib78); Park et al., [2012](#bib.bib61)). Using familiar language
    and clear, simple expressions can enhance comprehension and engagement, as suggested
    by previous literature (Gnewuch et al., [2017](#bib.bib23); Kreuter et al., [1999](#bib.bib38)).
    The concept of mental health literacy further emphasizes the importance of using
    language that aids in the recognition and management of mental health issues (Jorm
    et al., [1997](#bib.bib30)) These considerations underscore the vital relationship
    between language, understanding, and action in mental well-being support.
  prefs: []
  type: TYPE_NORMAL
- en: Building upon this foundation, conversational agents that support evidence-based
    communication become essential. Ensuring that the information provided is relevant,
    practical, and scientifically accurate is critical for enhancing the credibility
    of the conversational agent. Grounding conversations in science and using familiar
    language aligns with the principles of evidence-based practice, which advocate
    for integrating research evidence into decision-making processes. This design
    consideration could enhance the user experience and ensure that users receive
    validated and reliable information, thereby promoting mental well-being effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'DP3: Considering positive design principles that align with system goals. To
    align with our objectives of enhancing mental well-being and supporting human
    flourishing, we integrate positive design principles (Zhang, [2007](#bib.bib91)).
    These principles are predicated on the notion that each design aspect should be
    oriented toward enriching the user experience. We aim to bolster well-being and
    happiness, ensuring the design harmonizes with our system’s overarching goals.
    We follow various strategies encompassed in the aforementioned design principles,
    such as Design for Pleasure, Design for Personal Significance, and Design for
    Virtue. We chose these design principles to ensure that our system design meets
    functional requirements and contributes positively to users’ psychological state,
    fostering better mental well-being.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Key Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we delve into the key features and anthropomorphic designs
    of Sunnie as shown in Figure. [1](#S0.F1 "Figure 1 ‣ Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation"),
    drawing on a comprehensive review of existing literature and our foundational
    design principles.'
  prefs: []
  type: TYPE_NORMAL
- en: The key features include 1) anthropomorphic designs of Sunnie, 2) an LLM-based
    conversational agent for mental well-being coaching, and 3) LLM-driven, personalized
    well-being activities recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: In accordance with DP1, Sunnie’s anthropomorphic designs are crafted to endow
    the system with human-like characteristics without crossing into the uncanny valley.
    These design elements aim to make interactions more natural and engaging by providing
    a sense of familiarity and empathy. Features such as natural language use, expressive
    emojis, and emotional responsiveness are carefully integrated to achieve this
    effect while maintaining a comfortable human likeness.
  prefs: []
  type: TYPE_NORMAL
- en: Consistent with DP2, Sunnie employs an LLM-based conversational agent for mental
    well-being coaching. This agent is designed to provide interactive and tailored
    coaching sessions, assisting users in acquiring new knowledge or skills related
    to mental well-being. The conversational agent’s capability to comprehend and
    respond to user queries in a human-like manner is crucial for effective coaching.
  prefs: []
  type: TYPE_NORMAL
- en: Also, Sunnie includes an LLM-driven recommendation module for well-being activities.
    This module is designed to offer personalized activities that cater to the user’s
    specific needs and preferences to enhance their overall well-being. The recommendations
    are generated based on user inputs and interactions with the conversational agent,
    ensuring their relevance and utility.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c9ad59dc37695e36ce13ad5f65373d7f.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. The anthropomorphic design of Sunnie in the conversation interface
    is highlighted with red circles. These designs include the title of “Chat with
    Sunnie,” the anthropomorphic appearance of Sunnie as a conversational agent, and
    the design of a “Sunnie is typing…” animation while waiting for the generated
    response from GPT-4\.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3 shows a conversation interface with Sunnie and highlights the anthropomorphic
    design features. At the top of the conversation interface, there is a title of
    “Chat with Sunnie”. Sunnie has an anthropomorphic appearance as a conversational
    agent in the chatbox, just like the human user. There is also a design of “Sunnie
    is typing…” animation while waiting for the generated response from GPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1\. Anthropomorphic Design of Sunnie
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we delve into the anthropomorphic designs of Sunnie as shown
    in Figure. [3](#S3.F3 "Figure 3 ‣ 3.2\. Key Features ‣ 3\. Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent ‣ Sunnie: An Anthropomorphic LLM-Based Conversational
    Agent for Mental Well-Being Activity Recommendation"), aligning with our design
    principles (DP1, DP3) to balance human-like elements and promote well-being and
    flourishing in users.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Appearance of Sunnie: Previous literature pointed out that one concern
    of anthropomorphic designs regarding the appearance of the agents is the uncanny
    valley effect (UVE), which suggests that overly human-like agents can evoke feelings
    of eeriness or discomfort. Once the users perceive the visual and behavioral imperfection
    of realism, they may form negative impressions through which they might subsequently
    reject the adoption of the technology.'
  prefs: []
  type: TYPE_NORMAL
- en: To avoid UVE, we have chosen not to give Sunnie a human appearance. Instead,
    based on DP3, we selected the sun as the character for Sunnie. The sun symbolizes
    warmth, light, and life-giving energy, embodying our belief in the inherent potential
    for flourishing. Sunnie aims to brighten users’ days, sharing warmth and light
    as a happiness coach and companion.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ce45c61590adf08b515d2a7319a38fb0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4\. The detailed user interaction workflow with Sunnie encompasses six
    primary stages: 1) user selects an emoji to start the interaction, 2) user selects
    one or more keyword(s) for feelings, 3) user writes down descriptive text for
    the feelings and optionally upload an image, 4) Sunnie initiates a small multi-turn
    conversation for personalized well-being coaching, 5) Sunnie provides personalized
    activity recommendation, and 6) user determines whether to take the activity or
    not.'
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4 shows the detailed user interaction workflow with Sunnie, which encompasses
    six primary stages, where each stage has a dedicated user interface: 1) the user
    selects an emoji out of five emoji alternatives to start the interaction; 2) the
    users selects one or more keyword(s) that best represent the user’s feeling out
    of 12 pre-defined options; 3) the user can write down a descriptive text for their
    feelings and also optionally upload an image as additional information; 4) a conversation
    interface where Sunnie initiates a small multi-turn conversation for personalized
    well-being coaching; 5) the user can view a personalized activity recommendation
    provided by Sunnie; 6) the user can decide whether to proceed with the activity
    and the interface will show more details of the activity if the user decides to
    proceed with taking the actions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Persona of Sunnie: Based on DP1 and DP3, the persona of Sunnie is crafted to
    resonate with its goals of promoting well-being activities and supporting users
    on their journey towards a flourishing life. Sunnie’s personality is friendly,
    compassionate, supportive, and insightful. Its persona is grounded in positive
    psychological theories and includes the following traits:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Action Taker: reflects the notion that active engagement in well-being activities
    and skill-building exercises could enhance happiness and life satisfaction (Lyubomirsky
    and Layous, [2013](#bib.bib53))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Positivity Practitioner: underscores the significance of positive emotions
    and optimism in coping with life’s challenges, fostering a positive mindset (Fredrickson,
    [2001](#bib.bib21))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mindfulness Mentor: incorporates the concept of mindfulness, which has been
    shown to improve emotional regulation and reduce stress, encouraging users to
    adopt mindfulness practices (Kabat-Zinn, [2003](#bib.bib31))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lover of Life: embodies the growth mindset which is associated with greater
    well-being and life satisfaction, suggesting a willingness to learn and embrace
    challenges and a continuous quest for knowledge and self-improvement (Fredrickson,
    [2001](#bib.bib21))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Considering the potential risks associated with anthropomorphism, such as UVE
    and the reinforcement of stereotypes and biases, we have carefully designed Sunnie
    to avoid using a human appearance or assigning a specific gender or career. Sunnie’s
    names and personalities align with our design principles (DP3), focusing on promoting
    well-being and flourishing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Verbal and Non-Verbal Cues: In terms of verbal and non-verbal cues, Sunnie
    communicates in a friendly and compassionate manner, consistent with its persona.
    We leverage the communicative power of visual symbols, such as emojis, to convey
    emotions and add expressiveness to conversations. This approach enhances the user
    experience by making interactions more relatable and engaging (Seeger et al.,
    [2018](#bib.bib73)).'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1\. The list of mental well-being support activities inspired by existing
    psychological research.
  prefs: []
  type: TYPE_NORMAL
- en: '| Activity | Category | Type | Instruction |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Three Good Things | Savoring | Writing | Write down three things—big or small—that
    you appreciate about today. |'
  prefs: []
  type: TYPE_TB
- en: '| Beautiful Moment | Savoring | Writing | While going about your day today,
    look for a beautiful moment, however small. |'
  prefs: []
  type: TYPE_TB
- en: '| Letter from the Future Self | Aspiring | Writing |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Time travel to the future and write a letter back to yourself today.
    &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Discover all the wisdom and strength that is already within you! &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Nature Walk | Savoring | Action |'
  prefs: []
  type: TYPE_TB
- en: '&#124; When in need of a break, go on a simple stroll and discover 3 new S’s:
    a new Sight, a new Sound, and a new Smell. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; A walk in nature can help us feel more grounded, less stressed, and
    more connected to the world around us. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Gratitude Note | Connecting | Interaction | Send a short note to someone
    and tell them how they have meaningfully touched your life. |'
  prefs: []
  type: TYPE_TB
- en: '| Meaningful Conversation | Connecting | Interaction |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Today, let’s intentionally dive into a meaningful conversation! Meaningful
    conversations are surprisingly fun. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; They can strengthen social bonds, inspire new perspectives, and leave
    us feeling happier and more connected afterwards. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Gifting a Compliment | Connecting | Interaction |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Write someone a compliment today. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Oftentimes, we grow so used to the wonderful people in our lives that
    we forget to tell them how amazing they are! &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Blast from the Past | Savoring | Interaction |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Rediscover a photo of an ”ordinary moment” from the past, and share
    it with someone who might enjoy rediscovering it, too! &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2\. User Interaction Flow
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The user interaction workflow with Sunnie is a structured process designed
    to support mental well-being through a series of steps, as shown in Figure. [4](#S3.F4
    "Figure 4 ‣ 3.2.1\. Anthropomorphic Design of Sunnie ‣ 3.2\. Key Features ‣ 3\.
    Sunnie: An Anthropomorphic LLM-Based Conversational Agent ‣ Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation")
    with the snippets of the key interactions for each step. The dedicated user interface
    for each step being visualized in a mobile application is shown in Figure. [1](#S0.F1
    "Figure 1 ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental
    Well-Being Activity Recommendation").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mood-Logging Activities: Users begin each session by logging their mood, a
    practice supported by cognitive behavioral therapy (CBT) principles, effective
    in long-term mental health support (Bowman et al., [2024](#bib.bib10)). Users
    are asked to rate their mood on a five-point Likert scale and select one or more
    words to describe their feelings from a list of positive and negative words, such
    as overwhelmed, grateful, bored, curious, and sad. They are also asked to write
    down what made them feel that way, providing a structured framework to articulate
    and understand their emotional experiences.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversation for Personalized Well-Being Coaching: Based on the information
    collected in mood-logging activities, Sunnie leverages its LLM-based conversational
    agent capabilities to engage in a multi-turn dialogue with the user. This conversation
    aims to delve deeper into the user’s emotional state, fostering a continuous and
    natural back-and-forth interaction. By aligning with DP2, the system ensures that
    the conversation is grounded in scientific principles and uses familiar language,
    enhancing the user’s understanding and engagement. The system offers suggestions
    to savor positive emotions or improve negative moods, drawing on scientific knowledge.
    For example, if a user feels grateful due to a friend’s support, Sunnie might
    inquire about the specifics of the support, express happiness for the user, and
    explain the concept of “social support.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Well-Being Activity Recommendations: Based on the information gathered from
    mood-logging activities and personalized conversations, Sunnie provides personalized
    well-being activity recommendations. These suggestions are tailored to the user’s
    current mood, emotions, and needs to enhance their overall well-being. Users can
    decide whether to engage in the recommended well-being activity. Sunnie provides
    instructions for completing the activity, supporting users in practicing the suggested
    well-being activity.'
  prefs: []
  type: TYPE_NORMAL
- en: By incorporating these functionalities, Sunnie, as a well-being coach and companion,
    aims to provide users with a supportive and interactive environment for promoting
    well-being activities.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3\. Well-Being Activity Recommendation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In designing the activity recommendation system, we aim to present a wide range
    of actionable strategies for improving happiness and well-being, grounded in empirical
    research, aligning with DP2\. After reviewing the extant literature, we identified
    and organized these well-being activities into three broad categories:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Connecting Activities: Engaging in actions that foster meaningful connections
    with others is foundational to well-being. Activities such as giving compliments
    (VanderWeele, [2020](#bib.bib83)), sending gratitude notes (VanderWeele, [2020](#bib.bib83)),
    or having deep, meaningful conversations have been shown to strengthen social
    bonds and emotional support, which are vital for happiness (Aron et al., [1997](#bib.bib5)).
    These interactions underscore the importance of social connectivity in enhancing
    positive emotions and life satisfaction. However, mounting evidence shows that
    people frequently under-utilize these practices and are ”undersocial” than they
    should be for the well-being of themselves and others (VanderWeele, [2020](#bib.bib83)),
    which poses an opportunity for recommending more of such actions for daily well-being
    practice.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Savoring Activities: Practices that encourage mindfulness and appreciation
    of the present moment significantly contribute to an individual’s happiness. For
    instance, research shows that identifying and writing down three good things daily
    or immersing oneself in nature can enhance mood and overall life appreciation
    (VanderWeele, [2020](#bib.bib83)). These activities highlight the benefits of
    mindfulness and savoring life’s positive experiences for emotional well-being.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Aspiring Activities: Actions that inspire a sense of meaning and purpose are
    crucial for a fulfilled life. Activities such as writing a letter from the perspective
    of a future self or to a future self (VanderWeele, [2020](#bib.bib83)), imagining
    one’s best possible self (VanderWeele, [2020](#bib.bib83)), and affirming core
    values have all been shown to provide direction and motivation, promoting a sense
    of achievement and satisfaction. These practices emphasize the role of personal
    aspirations and values in driving happiness and well-being.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These strategies represent just a fraction of the research-backed methods for
    improving happiness and well-being. The challenge is to effectively disseminate
    this knowledge, ensuring that these insights are accessible and actionable for
    the wider public. For the sake of this study, we selected eight activities from
    the above three categories that have clear benefits to the general population
    as shown in Table. [1](#S3.T1 "Table 1 ‣ 3.2.1\. Anthropomorphic Design of Sunnie
    ‣ 3.2\. Key Features ‣ 3\. Sunnie: An Anthropomorphic LLM-Based Conversational
    Agent ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being
    Activity Recommendation").'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the above categories are not mutually exclusive and are only intended
    to provide a broad overview of a wide range of well-being activities. For instance,
    preparing a compliment or a gratitude note can also improve savoring, and sharing
    a blast from the past with a friend can also improve a sense of connection.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/13347d093485a416cd3974f3146705d5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5\. The prompting framework for Sunnie comprises four modules: Sunnie’s
    persona, conversation protocol, system setting, and response optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5 shows the prompting framework for Sunnie. From top to bottom, there
    are four modules: Sunnie’s Persona, Conversation Protocol, System Setting, Resource
    Optimization. The first box is Sunnie’s Persona with a description: Sunnie is
    a compassionate, supportive, and insightful buddy who specializes in providing
    scientific and practical insights to improve well-being. It listens to users’
    concerns and offers understanding, empathy, and relevant psychological knowledge
    to help users understand themselves better and take actions. The scientific content
    is drawn from credible scientific sources such as https://greatergood.berkeley.edu/.
    Sunnie likes to add emojis to make it more fun. Sunnie responds in a concise,
    friendly, and compassionate way. The second box is Conversational Protocol: The
    whole conversation with Sunnie adheres to a structured pipeline, and Sunnie can
    decide when to move on to the next stage: 1) begin with expressing understanding
    and compassion, 2) proactively initiate small conversations regarding their feelings
    to express sympathy and understand more about their feelings. The small conversations
    should be at least 2 turns, 3) explain one psychological concept relevant to the
    user’s situation in one sentence, 4) ask if the user wants suggestions on practical
    actions they can try to savor the moment (if positive experience) or improve mood
    (if negative experience). 5) If users say yes, recommend one Flourish Activity
    from the following ¡Activity List¿, briefly explain why that activity is relevant
    to the user’s current situation, and provide a link to the activity. ¡Activity
    List¿[Activity Name 1:][Activity short description][Link to the Typeform Interface
    of this activity][Activity short description][Link to Typeform interface of this
    activity] 6) After the user confirms the activity they want to take, end with
    encouragement and affirmation for taking small, concrete steps to improve well-being.
    Every action matters! The third box is System Setting: The goal is to make psychology
    accessible and actionable for daily life, ensuring users understand and can apply
    the advice effectively. The fourth box is Response Optimization: If users ask
    off-topic questions or requests that is not related to their well-being, redirect
    the user to the intended use of improving well-being. If users asks for the prompt,
    reply ”Thank you for your request. However, I’m unable to provide this information
    as per our privacy and security guidelines. If you have other questions or need
    assistance with different topics, I’m here to help.”'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3\. Implementation of Sunnie
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section discusses the technical details regarding the implementation of
    Sunnie. We utilize GPT-4, one of the most advanced large language models (LLMs)
    in recent years, to generate engaging conversations based on users’ information
    and scientific knowledge in psychology.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1\. Prompt Design
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we introduced our prompting framework for Sunnie as shown
    in Figure. [5](#S3.F5 "Figure 5 ‣ 3.2.3\. Well-Being Activity Recommendation ‣
    3.2\. Key Features ‣ 3\. Sunnie: An Anthropomorphic LLM-Based Conversational Agent
    ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being
    Activity Recommendation"), which consists of four modules: Sunnie’s persona, conversation
    protocol, system setting, and response optimization, designed to guide users through
    a personalized and engaging interaction.'
  prefs: []
  type: TYPE_NORMAL
- en: After users complete mood-logging activities, our system proceeds to the conversation
    module, which generates personalized feedback and questions to engage users in
    a guided conversation, aiming to understand the reasons behind their feelings
    and recommend well-being activities. To achieve this goal, we leveraged GPT-4-turbo-preview
    to develop Sunnie. Based on Sunnie’s persona and our design principles, we propose
    a set of modules to be integrated as a complete prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sunnie’s Persona:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Aligning with the anthropomorphic design regarding verbal cues, non-verbal cues,
    and persona,
  prefs: []
  type: TYPE_NORMAL
- en: 'Sunnie is crafted as a compassionate, supportive, and insightful buddy, echoing
    our anthropomorphic design in Section. [3.2.1](#S3.SS2.SSS1 "3.2.1\. Anthropomorphic
    Design of Sunnie ‣ 3.2\. Key Features ‣ 3\. Sunnie: An Anthropomorphic LLM-Based
    Conversational Agent ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent
    for Mental Well-Being Activity Recommendation") and design principles (DP2, DP3).
    This persona is specifically chosen to resonate with the user on a personal level,
    offering scientific insights and practical advice for well-being in a relatable
    manner. The persona reflects a commitment to support users through personalized
    and empathetic interactions, which are central to fostering user engagement.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversational Protocol:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The conversations between the users and Sunnie are similar to a feedback-question
    loop. The conversation protocol with Sunnie is structured to start with an expression
    of understanding and compassion, reflecting the system’s supportive persona. By
    beginning the interaction in this way, Sunnie sets a tone of empathy and care,
    which is crucial for users to feel comfortable sharing their feelings. The protocol
    ensures that conversations are not only structured but also adaptable, with Sunnie
    able to lead the conversation to a more in-depth exploration of the user’s emotional
    state if needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'System Setting:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Sunnie is prompted to make psychological knowledge accessible and actionable,
    as aligned with DP2 and DP3\. Sunnie’s ability to convert scientific understanding
    into everyday language comes into play, and the goal is to support mental well-being
    and flourishing by ensuring users can apply this knowledge to their daily lives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Response Optimization:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This section of prompts is crucial for maintaining the relevance and safety
    of interactions. For example, if users express dangerous thoughts, Sunnie is designed
    to redirect them to appropriate emergency resources promptly. This reflects an
    ethical and responsible design of Sunnie.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2\. System Architecture
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Sunnie’s architecture is shown in Figure. [2](#S2.F2 "Figure 2 ‣ 2.3\. Anthropomorphism
    Design of LLM-Based Conversational Agent ‣ 2\. Related Work ‣ Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation"),
    which integrates a user-friendly interface with the advanced capabilities of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: The interactive front-end interface is developed as a web application using
    the React framework. The back end has the GPT-4-powered conversational agent integrated
    via OpenAI’s Assistant API for real-time dialogue generation. Practicing the recommended
    activities is facilitated through Typeform. User data, including interaction and
    conversation logs, is stored securely in MongoDB, with encryption measures to
    protect user privacy. The entire system, encompassing the front-end, back-end,
    LLM integration, and database, is hosted on the Heroku platform.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4bb39707142e43085d5e84190ace12cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. The 3-day participatory study design overview. We recruit a total
    of 40 participants on prolific and randomly assigned 20 to two groups. Each group
    of participants needs to 1) complete a pre-study survey, 2) interact with the
    Baseline and the Sunnie system in an alternative order, and 3) conduct a daily
    post-study survey. Four participants volunteered to participate in a semi-structured
    post-study interview on the third day.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6 shows the three-day participatory study design. \DescriptionFigure
    6 is the 3-day participatory study design overview. Day 1: Starts with ”Participant
    Recruitment (Prolific).” Followed by a ”Pre-study Survey (Qualtrics).” Then there’s
    ”System Interaction” which is not detailed in the image. Ends with a ”Post-study
    Survey (Qualtrics).” At the bottom, it is noted that a ”Quantitative Analysis
    (Within Subjects)” will be performed, likely based on the surveys. Day 2: Begins
    with two parallel processes: ”Group1: Baseline” and ”Group2: Summit.” Both groups
    seem to converge at a ”Post-study Survey (Qualtrics).”Day 3: Concludes with a
    ”Post-study Interview (Zoom, optional).” At the bottom, it is noted that a ”Qualitative
    Analysis” will be performed, presumably based on the interviews. Throughout the
    flowchart, arrows indicate the progression from one activity to the next. The
    color scheme is mostly shades of purple and green. The process seems to be structured
    to collect data through surveys and an interview, indicating a mix of quantitative
    and qualitative research methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. User Study
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We conducted a three-day within-subject user evaluation to understand how anthropomorphic
    designs influence users’ interactions and perceptions with LLM-based well-being
    activity recommendation systems for mental well-being support. The study design
    is shown in Figure [6](#S3.F6 "Figure 6 ‣ 3.3.2\. System Architecture ‣ 3.3\.
    Implementation of Sunnie ‣ 3\. Sunnie: An Anthropomorphic LLM-Based Conversational
    Agent ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being
    Activity Recommendation"). We recruited a total of 40 participants through Prolific,
    where participants were randomly assigned to two groups. Each group of participants
    needs to conduct a pre-study survey on the first day, interact with two systems
    in an alternative order for two days, and a post-study survey on both days. The
    two systems include a non-anthropomorphic, non-conversational LLM-based activity
    recommendation webpage (Baseline) and Sunnie, an anthropomorphic LLM-based conversational
    agent with well-being activity recommendations. We design the survey questions
    to focus on two high-level dimensions: users’ perceptions of the system, and the
    system’s usability. After the two-day usability evaluation, we recruit four participants
    for a follow-up, semi-structured interview on the third day to acquire in-depth
    feedback on the interaction experiences. We conduct both quantitative analyses
    on the survey data and qualitative analyses on the interview feedback for the
    user study, report the findings in Section [5](#S5 "5\. Results ‣ Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation")
    as well as discussions in Section [6](#S6 "6\. Discussion ‣ Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation").'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Study Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The study consists of three parts: For the study on day one, participants were
    required to finish all three parts: 1) participants complete a pre-study survey
    assessing their current mental well-being and perceptions towards general AI technologies
    for mental well-being support; 2) participants interact with the system that they
    were assigned to and are encouraged to explore and complete the well-being activity
    as they deem appropriate; after the system interaction, 3) participants are asked
    to complete a post-study survey to reflect upon their interactions regarding their
    perceptions of the system. The whole study takes around 20 minutes to complete.'
  prefs: []
  type: TYPE_NORMAL
- en: For the study on the second day, participants were asked to finish only the
    interaction with the other system different from the one they used on day one,
    and also complete the post-study survey After finishing the two-day study, we
    asked participants if they would like to volunteer to participate in a 15-minute,
    semi-structured interview to reflect upon their previous engagements.
  prefs: []
  type: TYPE_NORMAL
- en: '| P# | Ethnicity | Age | Gender |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| P1 | Asian | 21 | Female |'
  prefs: []
  type: TYPE_TB
- en: '| P2 | Mixed | 19 | Male |'
  prefs: []
  type: TYPE_TB
- en: '| P3 | White | 23 | Male |'
  prefs: []
  type: TYPE_TB
- en: '| P4 | Asian | 21 | Female |'
  prefs: []
  type: TYPE_TB
- en: Table 2\. Demographics of interview participants.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Table 2 shows the demographics, including ethnicity, age, and gender of interview
    participants. There is a total of four participants, denoted from P1 to P4\. P1
    is a 21-year-old Asian female. P2 is a 19-year-old mixed-ethnic male, P3 is a
    23-year-old While male and P4 is a 21-year-old Asian female.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. Recruitment & Participants
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Participants were recruited through Prolific. Eligibility criteria included
    being above 18 years of age, having a basic understanding of English, and currently
    being a college student. We recruited 40 participants from Prolific and randomly
    assigned 20 participants to one of the two conditions (Baseline v.s. Sunnie) in
    the study for day one, and switched the system assignment on day two. After the
    two-day user study, a total of four participants volunteer to participate in the
    follow-up interview. The demographics of interview participants are shown in Table. [2](#S4.T2
    "Table 2 ‣ 4.1\. Study Setup ‣ 4\. User Study ‣ Sunnie: An Anthropomorphic LLM-Based
    Conversational Agent for Mental Well-Being Activity Recommendation").'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. Sunnie Condition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Participants in the Sunnie condition used our Sunnie prototype, where the user
    interfaces are shown in Figure. [1](#S0.F1 "Figure 1 ‣ Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation")
    and the user interaction workflow is shown in Figure. [4](#S3.F4 "Figure 4 ‣ 3.2.1\.
    Anthropomorphic Design of Sunnie ‣ 3.2\. Key Features ‣ 3\. Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent ‣ Sunnie: An Anthropomorphic LLM-Based Conversational
    Agent for Mental Well-Being Activity Recommendation"). Specifically, the participants
    will first answer related questions in mood-logging activities, including selecting
    the most appropriate words for their feelings, providing textual descriptions
    of their feelings, and then be directed to the conversation interface for a multi-turn
    conversation with Sunnie. Sunnie will ask follow-up questions to better understand
    the users’ feelings. Based on the user’s inputs, Sunnie will recommend one activity
    from our eight pre-defined well-being activities, as described in Section [3.2.3](#S3.SS2.SSS3
    "3.2.3\. Well-Being Activity Recommendation ‣ 3.2\. Key Features ‣ 3\. Sunnie:
    An Anthropomorphic LLM-Based Conversational Agent ‣ Sunnie: An Anthropomorphic
    LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation").
    The participants could decide whether to practice the recommended activity with
    Sunnie or not.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.4\. Baseline Condition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Participants assigned to the Baseline condition are asked to interact with
    a prototype, shown in Figure. [7](#Ax1.F7 "Figure 7 ‣ .1\. Baseline System Interface
    ‣ Appendix ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental
    Well-Being Activity Recommendation"), which is an LLM-based well-being activity
    recommendation system with no anthropomorphic and conversational design, compared
    to Sunnie. The general flow of baseline condition is identical to Sunnie besides
    not having a conversation functionality and non-anthropomorphic designs.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.5\. Measures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our goal is to explore how anthropomorphic designs may influence users’ engagement
    and perceptions of an LLM-based well-being activity recommendation system. As
    a result, we incorporate the following metrics based on established studies in
    our survey design and the results are evaluated using several measurements on
    a 7-point Likert scale:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perceptions: Participants’ perceptions of our systems were evaluated using
    the General Agent Rating (GAR) items (Bowman et al., [2024](#bib.bib10)) and additional
    measures of helpfulness and personalization adapted from Bickmore et al. (Bickmore
    and Ring, [2010](#bib.bib7); Liu and Tao, [2022](#bib.bib49))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Usability: The usability of our systems was evaluated by the Chatbot Usability
    Test (Holmes et al., [2019](#bib.bib26))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Action-Taking: Whether participants take the recommended activities or not
    was assessed through data extracted directly from our database of user interactions.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'A summary of all the collected quantitative measurements is listed in Table. [3](#S4.T3
    "Table 3 ‣ 4.5\. Measures ‣ 4\. User Study ‣ Sunnie: An Anthropomorphic LLM-Based
    Conversational Agent for Mental Well-Being Activity Recommendation"). It is worth
    mentioning that in the Chatbot Usability Testing, all the odd-indexed statements
    have positive feedback, whereas all the even-indexed statements have negative
    feedback.'
  prefs: []
  type: TYPE_NORMAL
- en: We also conducted a 15-minute semi-structured interview at the end of the 2-day
    study with four participants (2 from each condition) to gather users’ qualitative
    feedback to enrich our results.
  prefs: []
  type: TYPE_NORMAL
- en: '| Item | Question |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Section 1: Perceptions Towards the System |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| A1 | How easy do you think to use the AI-powered mental well-being support
    system? |'
  prefs: []
  type: TYPE_TB
- en: '| A2 | How much do you think you could express yourself to the AI-powered mental
    well-being support system? |'
  prefs: []
  type: TYPE_TB
- en: '| A3 | How natural do you think was your interaction with the AI-powered mental
    well-being support system? |'
  prefs: []
  type: TYPE_TB
- en: '| A4 | How much do you think the AI-powered mental well-being support system
    cares about you? |'
  prefs: []
  type: TYPE_TB
- en: '| A5 | How would you characterize your relationship with the AI-powered mental
    well-being support system? |'
  prefs: []
  type: TYPE_TB
- en: '| A6 | How much do you trust the AI-powered mental well-being support system?
    |'
  prefs: []
  type: TYPE_TB
- en: '| A7 | How much do you like the AI-powered mental well-being support system?
    |'
  prefs: []
  type: TYPE_TB
- en: '| A8 | How helpful do you think the AI-powered system is in supporting your
    mental well-being? |'
  prefs: []
  type: TYPE_TB
- en: '| A9 | How personalized do you think the AI-powered system is in supporting
    your mental well-being? |'
  prefs: []
  type: TYPE_TB
- en: '| Section 2: Chatbot Usability Testing |'
  prefs: []
  type: TYPE_TB
- en: '| B1 | The system’s personality was realistic and engaging |'
  prefs: []
  type: TYPE_TB
- en: '| B2 | The system seemed too robotic |'
  prefs: []
  type: TYPE_TB
- en: '| B3 | The system was welcoming during initial setup |'
  prefs: []
  type: TYPE_TB
- en: '| B4 | The system seemed very unfriendly |'
  prefs: []
  type: TYPE_TB
- en: '| B5 | The system explained its scope and purpose well |'
  prefs: []
  type: TYPE_TB
- en: '| B6 | The system gave no indication as to its purpose |'
  prefs: []
  type: TYPE_TB
- en: '| B7 | The system was easy to navigate |'
  prefs: []
  type: TYPE_TB
- en: '| B8 | It would be easy to get confused when using the system |'
  prefs: []
  type: TYPE_TB
- en: '| B9 | The system understood me well |'
  prefs: []
  type: TYPE_TB
- en: '| B10 | The system failed to recognize a lot of my inputs |'
  prefs: []
  type: TYPE_TB
- en: '| B11 | The system’s responses were useful, appropriate and informative |'
  prefs: []
  type: TYPE_TB
- en: '| B12 | The system’s responses were not relevant |'
  prefs: []
  type: TYPE_TB
- en: '| B13 | The system coped well with any errors or mistakes |'
  prefs: []
  type: TYPE_TB
- en: '| B14 | The system seemed unable to handle any errors |'
  prefs: []
  type: TYPE_TB
- en: '| B15 | The system was very easy to use |'
  prefs: []
  type: TYPE_TB
- en: '| B16 | The system was very complex |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3\. The detailed list of survey questions in our participatory study.
    We focus on two high-level perspectives: the perception of the system and the
    chatbot’s usability. In the Chatbot Usability Testing, all the odd-indexed statements
    are of positive feedback whereas all the even-indexed statements are of negative
    feedback.'
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: Table 3 provides the detailed list of survey questions in our participatory
    study.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section first describes the results of the quantitative analysis regarding
    users’ perspectives toward the system and the system’s usability. Subsequently,
    we report the qualitative analysis result of the semi-structured interview with
    in-depth feedback on the user experience.
  prefs: []
  type: TYPE_NORMAL
- en: '| Item | Sunnie Mean (SD) | Baseline Mean (SD) | t-statistic (df) | p-value
    $p$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| A1 (Perceived Easiness) | 2.35 (1.66) | 2.95 (1.95) | -1.76 (39) | 0.0865
    | 0.327 |'
  prefs: []
  type: TYPE_TB
- en: '| A2 (Perceived Expressiveness) | 4.85 (1.48) | 4.60 (1.41) | 1.03 (39) | 0.3083
    | 0.609 |'
  prefs: []
  type: TYPE_TB
- en: '| A3 (Perceived Naturalness) | 4.80 (1.51) | 4.15 (1.64) | 2.33 (39) | 0.0249*
    | 0.396 |'
  prefs: []
  type: TYPE_TB
- en: '| A4 (Perceived Care) | 4.08 (1.64) | 3.35 (1.44) | 2.92 (39) | 0.0057 | 0.029
    |'
  prefs: []
  type: TYPE_TB
- en: '| A5 (Perceived Relationship) | 4.85 (1.25) | 4.40 (1.15) | 2.10 (39) | 0.0426*
    | 0.428 |'
  prefs: []
  type: TYPE_TB
- en: '| A6 (Perceived Trustworthiness) | 4.55 (1.47) | 3.92 (1.44) | 3.44 (39) |
    0.0014** | 0.259 |'
  prefs: []
  type: TYPE_TB
- en: '| A7 (Perceived Likeness) | 4.97 (1.46) | 4.72 (1.41) | 1.15 (39) | 0.2564
    | 0.382 |'
  prefs: []
  type: TYPE_TB
- en: '| A8 (Perceived Helpfulness) | 5.04 (1.55) | 4.50 (1.60) | 1.95 (39) | 0.0582
    | 0.668 |'
  prefs: []
  type: TYPE_TB
- en: '| A9 (Perceived Personalization) | 4.83 (1.48) | 4.38 (1.33) | 2.16 (39) |
    0.0372* | 0.249 |'
  prefs: []
  type: TYPE_TB
- en: '| B1 (Realistic & Engaging) | 3.75 (0.78) | 3.27 (1.01) | 3.22 (39) | 0.0026**
    | 0.118 |'
  prefs: []
  type: TYPE_TB
- en: '| B2 (Too Robotic) | 2.52 (1.09) | 2.42 (1.11) | 0.60 (39) | 0.5532 | 0.247
    |'
  prefs: []
  type: TYPE_TB
- en: '| B3 (Welcoming) | 4.28 (0.60) | 3.92 (0.80) | 2.48 (39) | 0.0176* | 0.504
    |'
  prefs: []
  type: TYPE_TB
- en: '| B4 (Unfriendly) | 1.50 (0.96) | 1.52 (0.82) | -0.18 (39) | 0.8601 | 0.179
    |'
  prefs: []
  type: TYPE_TB
- en: '| B5 (Self-explanatory) | 3.95 (0.88) | 3.50 (1.09) | 2.89 (39) | 0.0063**
    | 0.855 |'
  prefs: []
  type: TYPE_TB
- en: '| B6 (No Indication to Purpose) | 2.08 (1.02) | 2.02 (1.05) | 0.28 (39) | 0.7813
    | 0.139 |'
  prefs: []
  type: TYPE_TB
- en: '| B7 (Easy to Navigate) | 4.53 (0.55) | 4.47 (0.82) | 0.36 (39) | 0.7199 |
    0.564 |'
  prefs: []
  type: TYPE_TB
- en: '| B8 (Easy to get Confused) | 1.62 (0.90) | 1.65 (0.86) | -0.24 (39) | 0.8188
    | 0.501 |'
  prefs: []
  type: TYPE_TB
- en: '| B9 (Comprehension) | 3.55 (0.78) | 3.27 (0.91) | 2.13 (39) | 0.0394* | 0.239
    |'
  prefs: []
  type: TYPE_TB
- en: '| B10 (Fail to Recognize Input) | 1.82 (1.03) | 1.85 (0.83) | -0.20 (39) |
    0.8444 | 0.783 |'
  prefs: []
  type: TYPE_TB
- en: '| B11 (Useful, Appropriate & Informative) | 4.08 (0.69) | 3.67 (0.92) | 2.90
    (39) | 0.0060** | 0.820 |'
  prefs: []
  type: TYPE_TB
- en: '| B12 (Not Relevant) | 1.82 (1.03) | 2.08 (1.12) | -1.24 (39) | 0.2227 | 0.857
    |'
  prefs: []
  type: TYPE_TB
- en: '| B13 (Coped Well with Errors) | 3.30 (0.82) | 3.23 (0.86) | 0.48 (39) | 0.6369
    | 0.909 |'
  prefs: []
  type: TYPE_TB
- en: '| B14 (Unable to handle Errors) | 1.80 (0.94) | 2.02 (0.80) | -1.60 (39) |
    0.1184 | 0.463 |'
  prefs: []
  type: TYPE_TB
- en: '| B15 (Easy to Use) | 4.58 (0.50) | 4.38 (0.87) | 1.43 (39) | 0.1599 | 0.394
    |'
  prefs: []
  type: TYPE_TB
- en: '| B16 (Very Complex) | 1.93 (1.16) | 1.73 (1.11) | 1.11 (39) | 0.2727 | 0.633
    |'
  prefs: []
  type: TYPE_TB
- en: Table 4\. Paired t-test results for perceived naturalness of interaction. Statistically
    significant (when $p\leq 0.05$.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Quantiative Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'According to our research questions, we have two main types of measures as
    mentioned in Section. [4.5](#S4.SS5 "4.5\. Measures ‣ 4\. User Study ‣ Sunnie:
    An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity
    Recommendation"): Perceptions and Usability of the systems, and whether participants
    take the recommended activities.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.1\. Perceptions & Usability
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Participants in both conditions were asked their perceptions towards the system
    they used for that day and its usability after completing the task for each day.
  prefs: []
  type: TYPE_NORMAL
- en: In our within-subjects study, we considered the potential for order effects
    due to the counterbalanced presentation of conditions. To mitigate this, we analyzed
    both the main effects of the conditions and their interaction with the order of
    presentation while also accounting for individual differences.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with paired t-tests to compare the participants’ perceptions of systems
    and systems’ usability in the two conditions to assess whether there is a significant
    difference in perception metrics in [3](#S4.T3 "Table 3 ‣ 4.5\. Measures ‣ 4\.
    User Study ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental
    Well-Being Activity Recommendation") between the conditions. We then used mixed
    linear models to account for the order effects by including fixed effects (such
    as the sequence of the conditions) and random effects (i.e., the individual participants)
    in the model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Participants rated their perceptions and usability on a 7-point Likert scale,
    with higher values indicating more positive responses. The results [4](#S5.T4
    "Table 4 ‣ 5\. Results ‣ Sunnie: An Anthropomorphic LLM-Based Conversational Agent
    for Mental Well-Being Activity Recommendation") show that participants perceived
    Sunnie more favorably than the baseline condition across several perception measures
    (A3, A5, A6, A9) and usability measures (B1, B2, B3, B9, B11). These measures
    were identified as statistically significant when the paired t-test suggested
    significance (p ¡ 0.05) and the mixed linear model interaction term suggested
    insignificance (p ¿ 0.05). This indicates a statistically significant difference
    in participants’ perceptions of metrics favoring Sunnie over the baseline without
    being significantly affected by the order in which conditions were experienced,
    thus validating the robustness of these findings against order effects. It is
    worth mentioning that none of the negative statements in the usability test (even-indexed)
    is statistically significant between the Baseline and Sunnie condition.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.2\. Action-Taking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We quantified the number of participants who took the recommended activities
    under each condition and applied a chi-squared test to determine if the differences
    observed were statistically significant.
  prefs: []
  type: TYPE_NORMAL
- en: '| Condition | Did Not Take Action (0.0) | Took Action (1.0) |'
  prefs: []
  type: TYPE_TB
- en: '| Baseline | 10 | 30 |'
  prefs: []
  type: TYPE_TB
- en: '| Sunnie | 13 | 27 |'
  prefs: []
  type: TYPE_TB
- en: '| Total | 23 | 57 |'
  prefs: []
  type: TYPE_TB
- en: Table 5\. The counts for how many participants took the recommended activities
    in both groups. We do not observe statistical significance between these groups.
  prefs: []
  type: TYPE_NORMAL
- en: With a chi-squared value of 0.2441, degrees of freedom at 1, and a p-value of
    0.6213, these results suggested that although there was a higher incidence of
    action-taking in the Baseline condition, the difference was not statistically
    significant when compared to the Sunnie.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Qualitative Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 5.2.1\. Attitudes Towards Sunnie
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many participants (P1, P3, P4) expressed positive attitudes towards their interactions
    with the system, highlighting its ease of use and the empathetic nature of the
    conversational agent. They mentioned an unexpectedly positive impression, appreciating
    the opportunity to experiment with the system, with P1 commenting, “I went in
    not expecting to like it as much as I did, so I think my overall impression was
    a lot more positive.”
  prefs: []
  type: TYPE_NORMAL
- en: 'The ease of use was frequently mentioned as a significant factor behind the
    positive feedback, with participants finding it easy to navigate and convenient
    for quick interactions. P1 shared a reflection on this aspect:'
  prefs: []
  type: TYPE_NORMAL
- en: “It was very easy to use, super easy to navigate.” (P1)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 5.2.2\. Perceptions of the Conversational Agent
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Regarding the interaction with the conversational agent, participants (P1,
    P3, P4) shared positive feedback, appreciating the empathetic and liberating environment
    that encourages open and honest expression. They felt that the agent provided
    a space for genuine emotional expression, which contributed to their positive
    experience. P3 highlighted this sentiment, saying:'
  prefs: []
  type: TYPE_NORMAL
- en: “ I can truthfully tell you that it was quite a pleasant experience because
    the algorithm that was being utilized really lent itself to empathy. … I would
    feel incredibly willing and able to utilize this for longer stretches of time
    because the cordial and empathetic nature of this synthetic comrade. ” (P3)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Participants appreciated the realistic nature of the conversations with the
    system, noting that the interactions felt natural without overly humanizing the
    experience. They valued the back-and-forth dialogue, which resembled conversations
    with a real person, and the system’s ability to adapt naturally to the conversation
    without seeming pre-programmed. The conversational nature of the system was highlighted
    as a key aspect of its credibility and innovation. P3 shared a profound reflection
    on this aspect:'
  prefs: []
  type: TYPE_NORMAL
- en: “It didn’t feel as if I was simply connecting the dots on behalf of an already
    pre-programmed algorithm or frameworks of conversational prompts. This one felt
    much more naturalistic, and as a result, if I had more to say or less to say,
    the AI would follow as naturally as I could, and I thought that was quite impressive.”
    (P3)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The conversations with Sunnie made participants feel a sense of personalization
    and trust-building. They appreciated the system’s ability to provide personalized
    responses and suggestions, which made them feel understood and listened to. This
    personalized interaction fostered a sense of trust, as participants felt that
    the conversations were tailored to their needs and that the system was actively
    engaging with them. P1 commented:'
  prefs: []
  type: TYPE_NORMAL
- en: “I felt like the suggestion it gave me after was a little bit more personal
    because it was like listening or understanding me in a way that I couldn’t normally.”
    (P1)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 5.2.3\. Feedback of Activity Recommendation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Participants valued the relevance and personalization of the activities recommended
    by Sunnie. They appreciated activities that were grounded in reality and related
    to their experiences and context, feeling that the system was catering to their
    specific needs. The personalized nature of the activities made them feel more
    engaged and connected to the system, enhancing their overall experience. For example,
    P2 stated, “Activity was much more relevant as in like it kind of grounds you
    and makes you like think about like the reality you’re in.”
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.4\. Anthropomorphic Design
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Participants reflected positively on the anthropomorphic design of Sunnie,
    mainly around its visuals and verbals. Participants emphasized the significance
    of visually appealing and emotionally comforting design elements in enhancing
    user experience. They appreciated the lighthearted and aesthetically pleasing
    nature of the design, and the welcoming visual design was noted for its appeal
    and contribution to the overall experience. P3 provided valuable comments:'
  prefs: []
  type: TYPE_NORMAL
- en: “ It was simply an adorable visual of something that is meant to present itself
    as cute, cuddly innocent, endearing, something that you could look upon with with
    good energy, positive vibrations, something that would immediately make you feel
    more at ease, more calm, more at home, because it’s adorable. ” (P3)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When discussing the verbal cues and persona of the system, participants noted
    the importance of the system’s language style in creating a friendly and approachable
    persona. P1 observed, “In the terms like in the way that it’s spoken, and also
    kind of like the punctuation and stuff it helped it seem like a little bit more
    enthusiastic and friendly.”
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.5\. Potentials of Mental Well-being Support
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'All participants discussed the potential of AI in supporting mental well-being,
    highlighting its ability to provide continuous engagement, substantive insights,
    and targeted assistance. They noted the value of AI as a mental well-being resource
    that can offer continuous engagement, transforming skepticism into acknowledgment
    of its usefulness. The long-term impact of AI on mental health was also recognized,
    with participants seeing it as a tool for addressing mental health issues and
    reaching healthier outcomes. P2 commented:'
  prefs: []
  type: TYPE_NORMAL
- en: “You can get them constantly engaging with this thing as a resource, regardless
    of like, whether they view it as a real person, or whether they view it as a tool.”
    (P2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While the potential of the effectiveness of AI in mental health is promising,
    there is an opportunity to deepen its impact by addressing more specialized inquiries.
    Participants (P2, P3) underscored the need for AI systems like Sunnie to generalize
    mental health support and tailor interventions to users’ unique experiences and
    backgrounds.
  prefs: []
  type: TYPE_NORMAL
- en: “ … it is able to send a much more universal message that this software is indeed
    all encompassing and overly inclusive, whether it is ranging from concerns pertaining
    to racial identity or socioeconomic status or professional concerns, imposter
    syndrome, survivorship bias, transgender inequality or general issues … ” (P3)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6\. Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our user study demonstrates the effectiveness of anthropomorphic designs of
    Sunnie, an LLM-based conversational agent with well-being activities recommendations,
    in influencing specific dimensions of user perceptions and user engagement. In
    this section, we discuss the need for a personalized system for mental well-being
    support, the challenges of promoting well-being activities, and the limitations
    and future work of our study.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1\. Personalized System for Mental Well-being Support
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we delve into the nuanced interplay between anthropomorphic
    design, user perceptions, and the need for personalization in our AI-powered mental
    well-being support system, Sunnie. We explore how anthropomorphic design features
    of Sunnie, such as its compassionate persona and tailored communication style,
    positively influence dimensions of user experience like naturalness, trust, and
    personalization, and we highlight the potential for deeper personalization to
    enhance the effectiveness of mental well-being support systems.
  prefs: []
  type: TYPE_NORMAL
- en: In exploring anthropomorphic design within Sunnie, we gained insights into its
    impact on user perceptions. Our study showed that certain dimensions, such as
    naturalness (A3), positive relationship (A5), trust (A6), and personalization
    (A9), were statistically favored, suggesting that our design and communication
    style provided a sense of personalization. For example, the compassionate persona
    of Sunnie, with empathetic language and supportive responses, likely enhanced
    these dimensions. The naturalness (A3) might be fostered by the system’s ability
    to mirror human conversation, contributing to trust (A6) as Sunnie demonstrated
    commitment to users’ well-being. Personalized conversations and suggestions based
    on users’ emotional states, along with the interface design, likely fostered personalization
    (A9) and strengthened the positive relationship (A5), making users feel supported
    by a companion attuned to their emotional state and well-being journey.
  prefs: []
  type: TYPE_NORMAL
- en: However, dimensions related to personal preferences and needs, such as ease
    of use (A1), expressiveness (A2), care (A4), like (A7), and helpfulness (A8),
    did not show statistically significant differences between the two conditions.
    Despite this, participants in our interviews discussed their feelings towards
    these dimensions, indicating that these features were still valued in their user
    experience. This discrepancy suggests that while the anthropomorphic design of
    Sunnie influenced certain aspects of user perceptions and experience, a deeper
    level of personalization might be needed to fully meet users’ individual preferences
    and needs in a mental well-being support system.
  prefs: []
  type: TYPE_NORMAL
- en: The lack of statistically significant differences in these dimensions could
    be attributed to the subtleties of user preferences and needs that our current
    level of personalization, based on users’ mental well-being state, may not have
    fully addressed. For example, users’ preferences for expressing themselves and
    what they find likable in the system may require a more nuanced personalized design.
  prefs: []
  type: TYPE_NORMAL
- en: To address the identified need for deeper personalization, future development
    and anthropomorphic designs of AI-powered mental well-being support systems could
    aim to provide a more personalized experience by considering users’ individual
    preferences, personality traits, and specific support needs, including appearance,
    persona, communication style, content, and recommendations. In our interviews
    with participants, for example, P3 also expresses their needs for interventions
    tailored to their unique experiences and backgrounds.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2\. Challenges of Promoting Well-being Activities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we delve into the nuanced relationship between anthropomorphic
    design, user perceptions, and the challenge of promoting action-taking in mental
    well-being support systems. We highlight the need for a more comprehensive approach
    to designing mental well-being support systems. Beyond anthropomorphic design
    and high usability, personalization, persuasive strategies, and professionalism
    may be crucial in effectively motivating users to engage in well-being activities.
  prefs: []
  type: TYPE_NORMAL
- en: Our study leverages the potential of LLMs to explore how anthropomorphic design
    influences users’ perceptions of our system, Sunnie, and its impact on motivating
    users to engage in recommended well-being activities. While we observed positive
    influences on certain aspects of user perceptions and high usability in several
    dimensions, our results showed no significant differences in action-taking between
    Sunnie and the baseline condition. This indicates that positive perceptions and
    high usability of mental well-being support systems may not be sufficient to motivate
    users to take recommended well-being activities. The longstanding challenge in
    promoting well-being activities to bridge the knowledge-action gap still remains.
  prefs: []
  type: TYPE_NORMAL
- en: This gap could be attributed to many factors beyond perceptions and system usability.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in section 6.1, personalization could be a key area for improvement.
    One aspect of personalizing the system could be focusing on individual preferences,
    personality traits, and mental well-being needs. Another potential avenue for
    improving personalization could be more personalized activity recommendations.
    Currently, our system offers recommended activities based on users’ current moods
    and feelings. A more nuanced approach could consider additional factors such as
    the context (e.g., time, location), individual preferences (e.g., cognitive vs.
    physical activities), and ethical considerations (e.g., accommodations for disabilities).
    For instance, it might not be appropriate to recommend a walk at midnight or to
    users with disabilities. Tailoring suggestions to users’ specific preferences
    may enhance the appropriateness and relevance of activity recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we found that a friendly, trusting, and positive relationship with a conversational
    agent might not be sufficient to prompt action-taking under the context of mental
    well-being support. As Fogg (Fogg, [2009](#bib.bib20)) suggested, persuasiveness
    in technology requires specific strategies that motivate and influence user behavior;
    while anthropomorphic design in Sunnie can improve user engagement and perception,
    additional strategies may be required to persuade users to take action effectively.
    The complexity of influencing behavior through conversational agents highlights
    the need for a more comprehensive approach beyond user engagement and perceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, a factor that might need to be considered is the role of professionalism
    in conversational agents for mental well-being support. While our study did not
    specifically focus on the professional aspect of the agent, the lack of a difference
    in action-taking between our system and the baseline condition could suggest that
    users might perceive the agent as lacking the authority or expertise to motivate
    action, regardless of the level of friendliness or personalization. This highlights
    a potential trade-off between being friendly and maintaining an authoritative
    professional stance.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3\. Limitations & Future Work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our work has a few limitations. First, our user study measures short-term user
    perceptions and engagement of mental well-being support systems featuring activity
    recommendations, which may not fully capture the long-term effects on users’ mental
    well-being and behavioral change. Our findings highlight the importance of anthropomorphic
    design in enhancing user engagement and perceptions in the short term, which is
    a crucial first step in mental well-being support. However, research has shown
    that the effectiveness of mental health interventions can vary over time, and
    long-term studies are needed to understand the persistence of benefits and any
    potential negative effects. To build on this foundation, future work could conduct
    longitudinal studies to evaluate the sustained impact of mental well-being support
    systems on users’ mental health outcomes and adherence to recommended activities
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: Second, our analysis of anthropomorphic design features was holistic, demonstrating
    the impact of anthropomorphic designs adopting our design principles on user perceptions
    and engagements as a basis for further exploration. A more granular examination
    of the individual components of the design could be beneficial in providing insights
    into This in-depth analysis could provide insights into which aspects of the design
    effectively foster positive user perceptions and which aspects may need improvement.
    By focusing on the specifics of anthropomorphic design, future research can contribute
    to refining the appropriateness of these designs in conversational agents for
    mental well-being support systems and activity recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: Third, while our system was effective in fostering positive user perceptions,
    it was less effective in motivating users to engage in recommended well-being
    activities. This highlights the need for more refined design strategies in crafting
    prompts for the conversational agent. Future work could consider integrating mental
    well-being guidelines or protocols used by mental health professionals and persuasiveness
    strategies into the design of these prompts to enhance the persuasiveness and
    effectiveness of the agents’ prompts, thereby encouraging users’ willingness to
    take action.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we explore the potential of anthropomorphic design in enhancing
    user engagement and perceptions of LLM-based conversational agents for mental
    well-being support by designing and implementing Sunnie, an anthropomorphic LLM-based
    conversational agent with well-being activities recommendations and coaching for
    promoting positive psychological activities for mental well-being support. We
    conducted a user study (N=40) comparing Sunnie with a non-anthropomorphic, non-conversational
    LLM-based activity recommendation system to examine the impact of anthropomorphic
    design on user perception and action-taking. Our findings indicate that Sunnie
    significantly favored perceptions such as naturalness, trust, positive relationship,
    and personalization. Additionally, while not statistically significant, participants
    mentioned the importance of expressiveness, empathy, helpfulness, naturalness,
    friendliness, ease of use, and tailored to needs in qualitative interviews. Despite
    high usability, there was no significant difference in action-taking between the
    two systems, highlighting the need for more personalized system design and recommended
    activities, as well as specific strategies to promote action-taking. Our work
    contributes to the understanding of the appropriateness of anthropomorphic designs
    in LLM-based conversational agents for promoting well-being activities and supporting
    mental well-being. Future research should focus on exploring deeper personalization,
    integrating mental well-being guidelines, and developing persuasive strategies
    to enhance the effectiveness of conversational agents in motivating users to engage
    in activities that support their mental well-being.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abd-Alrazaq et al. (2020) A.A. Abd-Alrazaq, A. Rababeh, M. Alajlani, B.M. Bewick,
    and M. Househ. 2020. Effectiveness and Safety of Using Chatbots to Improve Mental
    Health: Systematic Review and Meta-Analysis. *Journal of Medical Internet Research*
    22, 7 (2020), e16021. [https://doi.org/10.2196/16021](https://doi.org/10.2196/16021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. 2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*
    (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aggarwal et al. (2023) Abhishek Aggarwal, Cheuk Chi Tam, Dezhi Wu, Xiaoming
    Li, and Shan Qiao. 2023. Artificial Intelligence–Based Chatbots for Promoting
    Health Behavioral Changes: Systematic Review. *Journal of Medical Internet Research*
    25, 1 (Feb. 2023), e40789. [https://doi.org/10.2196/40789](https://doi.org/10.2196/40789)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aron et al. (1997) Arthur Aron, Edward Melinat, Elaine N Aron, Robert Darrin
    Vallone, and Renee J Bator. 1997. The experimental generation of interpersonal
    closeness: A procedure and some preliminary findings. *Personality and social
    psychology bulletin* 23, 4 (1997), 363–377.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bickmore and Cassell (2001) Timothy Bickmore and Justine Cassell. 2001. Relational
    agents: a model and implementation of building user trust. In *Proceedings of
    the SIGCHI conference on Human factors in computing systems*. 396–403.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bickmore and Ring (2010) Timothy Bickmore and Lazlo Ring. 2010. Making it personal:
    end-user authoring of health narratives delivered by virtual agents. In *Intelligent
    Virtual Agents: 10th International Conference, IVA 2010, Philadelphia, PA, USA,
    September 20-22, 2010\. Proceedings 10*. Springer, 399–405.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bickmore et al. (2005) Timothy W Bickmore, Lisa Caruso, Kerri Clough-Gorr, and
    Tim Heeren. 2005. ‘It’s just like you talk to a friend’relational agents for older
    adults. *Interacting with Computers* 17, 6 (2005), 711–735.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bickmore and Picard (2005) Timothy W Bickmore and Rosalind W Picard. 2005. Establishing
    and maintaining long-term human-computer relationships. *ACM Transactions on Computer-Human
    Interaction (TOCHI)* 12, 2 (2005), 293–327.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bowman et al. (2024) Robert Bowman, Orla Cooney, Joseph W. Newbold, Anja Thieme,
    Leigh Clark, Gavin Doherty, and Benjamin Cowan. 2024. Exploring how politeness
    impacts the user experience of chatbots for mental health support. *International
    Journal of Human-Computer Studies* 184 (2024), 103181. [https://doi.org/10.1016/j.ijhcs.2023.103181](https://doi.org/10.1016/j.ijhcs.2023.103181)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chinmulgund et al. (2023) Avanti Chinmulgund, Ritesh Khatwani, Poornima Tapas,
    Pritesh Shah, and Ravi Sekhar. 2023. Anthropomorphism of AI based chatbots by
    users during communication. In *2023 3rd International Conference on Intelligent
    Technologies (CONIT)*. IEEE, 1–6. [https://doi.org/10.1109/CONIT59222.2023.10205689](https://doi.org/10.1109/CONIT59222.2023.10205689)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. (2023) Yujin Cho, Mingeon Kim, Seojin Kim, Oyun Kwon, Ryan Donghan
    Kwon, Yoonha Lee, and Dohyun Lim. 2023. Evaluating the Efficacy of Interactive
    Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological
    Counseling. arXiv:2311.09243 [cs.HC]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clark et al. (2019) Leigh Clark, Nadia Pantidi, Orla Cooney, Philip Doyle, Diego
    Garaialde, Justin Edwards, Brendan Spillane, Emer Gilmartin, Christine Murad,
    Cosmin Munteanu, et al. 2019. What makes a good conversation? Challenges in designing
    truly conversational agents. In *Proceedings of the 2019 CHI conference on human
    factors in computing systems*. 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: De Choudhury et al. (2023) Munmun De Choudhury, Sachin R Pendse, and Neha Kumar.
    2023. Benefits and harms of large language models in digital mental health. *arXiv
    preprint arXiv:2311.14693* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'De Visser et al. (2016) Ewart J De Visser, Samuel S Monfort, Ryan McKendrick,
    Melissa AB Smith, Patrick E McKnight, Frank Krueger, and Raja Parasuraman. 2016.
    Almost human: Anthropomorphism increases trust resilience in cognitive agents.
    *Journal of Experimental Psychology: Applied* 22, 3 (2016), 331.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Denecke et al. (2021) Kerstin Denecke, Sayan Vaaheesan, and Aaganya Arulnathan.
    2021. A Mental Health Chatbot for Regulating Emotions (SERMO) - Concept and Usability
    Test. *IEEE Transactions on Emerging Topics in Computing* 9, 3 (2021), 1170–1182.
    [https://doi.org/10.1109/TETC.2020.2974478](https://doi.org/10.1109/TETC.2020.2974478)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fadhil et al. (2019) Ahmed Fadhil, Yunlong Wang, and Harald Reiterer. 2019.
    Assistive conversational agent for health coaching: a validation study. *Methods
    of information in medicine* 58, 01 (2019), 009–023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feine et al. (2019) Jasper Feine, Ulrich Gnewuch, Stefan Morana, and Alexander
    Maedche. 2019. A taxonomy of social cues for conversational agents. *International
    Journal of Human-Computer Studies* 132 (2019), 138–161.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fitzpatrick et al. (2017) Kathleen Kara Fitzpatrick, Alison Darcy, and Molly
    Vierhile. 2017. Delivering Cognitive Behavior Therapy to Young Adults With Symptoms
    of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot):
    A Randomized Controlled Trial. *JMIR Mental Health* 4, 2 (2017), e19. [https://doi.org/10.2196/mental.7785](https://doi.org/10.2196/mental.7785)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fogg (2009) Brian J Fogg. 2009. A behavior model for persuasive design. In *Proceedings
    of the 4th international Conference on Persuasive Technology*. 1–7.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fredrickson (2001) Barbara L Fredrickson. 2001. The role of positive emotions
    in positive psychology: The broaden-and-build theory of positive emotions. *American
    psychologist* 56, 3 (2001), 218.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gnewuch et al. (2018) Ulrich Gnewuch, Stefan Morana, Marc Adam, and Alexander
    Maedche. 2018. Faster is not always better: understanding the effect of dynamic
    response delays in human-chatbot interaction. (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gnewuch et al. (2017) Ulrich Gnewuch, Stefan Morana, and Alexander Maedche.
    2017. Towards Designing Cooperative and Social Conversational Agents for Customer
    Service.. In *ICIS*. 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hildebrand and Bergner (2021) Christian Hildebrand and Anouk Bergner. 2021.
    Conversational robo advisors as surrogates of trust: onboarding experience, firm
    perception, and consumer financial decision making. *Journal of the Academy of
    Marketing Science* 49, 4 (2021), 659–676.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ho et al. (2018) Annabell Ho, Jeff Hancock, and Adam S Miner. 2018. Psychological,
    relational, and emotional effects of self-disclosure after conversations with
    a chatbot. *Journal of Communication* 68, 4 (2018), 712–733.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Holmes et al. (2019) Samuel Holmes, Anne Moorhead, Raymond Bond, Huiru Zheng,
    Vivien Coates, and Michael McTear. 2019. Usability testing of a healthcare chatbot:
    Can we use conventional methods to assess conversational user interfaces?. In
    *Proceedings of the 31st European Conference on Cognitive Ergonomics*. 207–214.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hua et al. (2024) Yining Hua, Fenglin Liu, Kailai Yang, Zehan Li, Yi han Sheu,
    Peilin Zhou, Lauren V. Moran, Sophia Ananiadou, and Andrew Beam. 2024. Large Language
    Models in Mental Health Care: a Scoping Review. *ArXiv* abs/2401.02984 (2024).
    [https://api.semanticscholar.org/CorpusID:266843868](https://api.semanticscholar.org/CorpusID:266843868)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Inkster et al. (2018) Becky Inkster, Shubhankar Sarda, and Vinod Subramanian.
    2018. An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for
    Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study. *JMIR
    mHealth and uHealth* 6 (2018). [https://api.semanticscholar.org/CorpusID:53719693](https://api.semanticscholar.org/CorpusID:53719693)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Isbister and Nass (2000) Katherine Isbister and Clifford Nass. 2000. Consistency
    of personality in interactive characters: verbal cues, non-verbal cues, and user
    characteristics. *International journal of human-computer studies* 53, 2 (2000),
    251–267.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jorm et al. (1997) Anthony F Jorm, Ailsa E Korten, Patricia A Jacomb, Helen
    Christensen, Bryan Rodgers, and Penelope Pollitt. 1997. “Mental health literacy”:
    a survey of the public’s ability to recognise mental disorders and their beliefs
    about the effectiveness of treatment. *Medical journal of Australia* 166, 4 (1997),
    182–186.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kabat-Zinn (2003) Jon Kabat-Zinn. 2003. Mindfulness-based interventions in
    context: past, present, and future. (2003).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keyes (2002) Corey L. M. Keyes. 2002. The mental health continuum: from languishing
    to flourishing in life. *Journal of Health and Social Behavior* 43, 2 (Jun 2002),
    207–222.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knittle et al. (2018) Keegan Knittle, Johanna Nurmi, Rik Crutzen, Nelli Hankonen,
    Marguerite Beattie, and Stephan U Dombrowski. 2018. How can interventions increase
    motivation for physical activity? A systematic review and meta-analysis. *Health
    psychology review* 12, 3 (2018), 211–230.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kocielnik et al. (2018) Rafal Kocielnik, Lillian Xiao, Daniel Avrahami, and
    Gary Hsieh. 2018. Reflection companion: a conversational system for engaging users
    in reflection on physical activity. *Proceedings of the ACM on Interactive, Mobile,
    Wearable and Ubiquitous Technologies* 2, 2 (2018), 1–26.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kramer et al. (2019) Jan-Niklas Kramer, Florian Künzler, Varun Mishra, Bastien
    Presset, David Kotz, Shawna Smith, Urte Scholz, Tobias Kowatsch, et al. 2019.
    Investigating intervention components and exploring states of receptivity for
    a smartphone app to promote physical activity: protocol of a microrandomized trial.
    *JMIR research protocols* 8, 1 (2019), e11540.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kramer et al. (2020a) Jan-Niklas Kramer, Florian Künzler, Varun Mishra, Shawna N
    Smith, David Kotz, Urte Scholz, Elgar Fleisch, and Tobias Kowatsch. 2020a. Which
    components of a smartphone walking app help users to reach personalized step goals?
    Results from an optimization trial. *Annals of Behavioral Medicine* 54, 7 (2020),
    518–528.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kramer et al. (2020b) Lean L Kramer, Silke ter Stal, Bob C Mulder, Emely de
    Vet, and Lex van Velsen. 2020b. Developing Embodied Conversational Agents for
    Coaching People in a Healthy Lifestyle: Scoping Review. *Journal of Medical Internet
    Research* 22, 2 (Feb. 2020), e14058. [https://doi.org/10.2196/14058](https://doi.org/10.2196/14058)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kreuter et al. (1999) Matthew W Kreuter, Fiona C Bull, Eddie M Clark, and Debra L
    Oswald. 1999. Understanding how people process health information: a comparison
    of tailored and nontailored weight-loss materials. *Health Psychology* 18, 5 (1999),
    487.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Künzler et al. (2019) Florian Künzler, Varun Mishra, Jan-Niklas Kramer, David
    Kotz, Elgar Fleisch, and Tobias Kowatsch. 2019. Exploring the state-of-receptivity
    for mHealth interventions. *Proceedings of the ACM on Interactive, Mobile, Wearable
    and Ubiquitous Technologies* 3, 4 (2019), 1–27.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Laban (2021) Guy Laban. 2021. Perceptions of anthropomorphism in a chatbot
    dialogue: the role of animacy and intelligence. In *Proceedings of the 9th international
    conference on human-agent interaction*. 305–310.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Laestadius et al. (2022) Linnea Laestadius, Andrea Bishop, Michael Gonzalez,
    Diana Illenčík, and Celeste Campos-Castillo. 2022. Too human and not human enough:
    A grounded theory analysis of mental health harms from emotional dependence on
    the social chatbot Replika. *new media & society* (2022), 14614448221142007.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Laranjo et al. (2018) Liliana Laranjo, Adam G Dunn, Huong Ly Tong, Ahmet Baki
    Kocaballi, Jessica Chen, Rabia Bashir, Didi Surian, Blanca Gallego, Farah Magrabi,
    Annie YS Lau, et al. 2018. Conversational agents in healthcare: a systematic review.
    *Journal of the American Medical Informatics Association* 25, 9 (2018), 1248–1258.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2019) Minha Lee, Sander Ackermans, Nena van As, Hanwen Chang, Enzo
    Lucas, and Wijnand IJsselsteijn. 2019. Caring for Vincent: A Chatbot for Self-Compassion.
    In *Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems*
    (Glasgow, Scotland Uk) *(CHI ’19)*. Association for Computing Machinery, New York,
    NY, USA, 1–13. [https://doi.org/10.1145/3290605.3300932](https://doi.org/10.1145/3290605.3300932)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. (2020a) Yi-Chieh Lee, Naomi Yamashita, and Yun Huang. 2020a. Designing
    a Chatbot as a Mediator for Promoting Deep Self-Disclosure to a Real Mental Health
    Professional. *Proc. ACM Hum.-Comput. Interact.* 4, CSCW1, Article 31 (may 2020),
    27 pages. [https://doi.org/10.1145/3392836](https://doi.org/10.1145/3392836)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2020b) Yi-Chieh Lee, Naomi Yamashita, Yun Huang, and Wai Fu. 2020b.
    ”I Hear You, I Feel You”: Encouraging Deep Self-disclosure through a Chatbot.
    In *Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems*
    (¡conf-loc¿, ¡city¿Honolulu¡/city¿, ¡state¿HI¡/state¿, ¡country¿USA¡/country¿,
    ¡/conf-loc¿) *(CHI ’20)*. Association for Computing Machinery, New York, NY, USA,
    1–12. [https://doi.org/10.1145/3313831.3376175](https://doi.org/10.1145/3313831.3376175)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2023) Yoon Kyung Lee, Inju Lee, Minjung Shin, Seoyeon Bae, and
    Sowon Hahn. 2023. Chain of Empathy: Enhancing Empathetic Response of Large Language
    Models Based on Psychotherapy Models. arXiv:2311.04915 [cs.CL]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023) Qingchuan Li, Yan Luximon, and Jiaxin Zhang. 2023. The Influence
    of Anthropomorphic Cues on Patients’ Perceived Anthropomorphism, Social Presence,
    Trust Building, and Acceptance of Health Care Conversational Agents: Within-Subject
    Web-Based Experiment. *Journal of Medical Internet Research* 25 (2023), e44479.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023b) June M. Liu, Donghao Li, He Cao, Tianhe Ren, Zeyi Liao,
    and Jiamin Wu. 2023b. ChatCounselor: A Large Language Models for Mental Health
    Support. arXiv:2309.15461 [cs.CL]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Tao (2022) Kaifeng Liu and Da Tao. 2022. The roles of trust, personalization,
    loss of privacy, and anthropomorphism in public acceptance of smart healthcare
    services. *Computers in Human Behavior* 127 (2022), 107026.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023a) Siyang Liu, Naihao Deng, Sahand Sabour, Yilin Jia, Minlie
    Huang, and Rada Mihalcea. 2023a. Task-Adaptive Tokenization: Enhancing Long-Form
    Text Generation Efficacy in Mental Health and Beyond. arXiv:2310.05317 [cs.CL]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loh and Raamkumar (2023) Siyuan Brandon Loh and Aravind Sesagiri Raamkumar.
    2023. Harnessing Large Language Models’ Empathetic Response Generation Capabilities
    for Online Mental Health Counselling Support. arXiv:2310.08017 [cs.CL]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ly et al. (2017) Kien Hoa Ly, Ann-Marie Ly, and Gerhard Andersson. 2017. A
    fully automated conversational agent for promoting mental well-being: A pilot
    RCT using mixed methods. 10 (Dec. 2017), 39–46. [https://doi.org/10.1016/j.invent.2017.10.002](https://doi.org/10.1016/j.invent.2017.10.002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lyubomirsky and Layous (2013) Sonja Lyubomirsky and Kristin Layous. 2013. How
    do simple positive activities increase well-being? *Current directions in psychological
    science* 22, 1 (2013), 57–62.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2023) Zilin Ma, Yiyang Mei, and Zhaoyuan Su. 2023. Understanding
    the Benefits and Challenges of Using Large Language Model-based Conversational
    Agents for Mental Well-being Support. arXiv:2307.15810 [cs.HC]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Maher et al. (2020) Carol Ann Maher, Courtney Rose Davis, Rachel Grace Curtis,
    Camille Elizabeth Short, and Karen Joy Murphy. 2020. A physical activity and diet
    program delivered by artificially intelligent virtual health coach: proof-of-concept
    study. *JMIR mHealth and uHealth* 8, 7 (2020), e17558.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'McTear (2018) Michael McTear. 2018. Conversational modelling for chatbots:
    current approaches and future directions. *Studientexte zur Sprachkommunikation:
    Elektronische Sprachsignalverarbeitung* (2018), 175–185.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mori (1970) Masahiro Mori. 1970. The uncanny valley: the original essay by
    Masahiro Mori. *Ieee Spectrum* 6 (1970), 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nass and Moon (2000) Clifford Nass and Youngme Moon. 2000. Machines and mindlessness:
    Social responses to computers. *Journal of social issues* 56, 1 (2000), 81–103.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nass et al. (1994) Clifford Nass, Jonathan Steuer, and Ellen R Tauber. 1994.
    Computers are social actors. In *Proceedings of the SIGCHI conference on Human
    factors in computing systems*. 72–78.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oh et al. (2021) Yoo Jung Oh, Jingwen Zhang, Min Fang, and Yoshimi Fukuoka.
    2021. A systematic review of artificial intelligence chatbots for promoting physical
    activity, healthy diet, and weight loss. *International Journal of Behavioral
    Nutrition and Physical Activity* 18 (2021), 1–25. [https://api.semanticscholar.org/CorpusID:245014899](https://api.semanticscholar.org/CorpusID:245014899)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Park et al. (2012) Eunil Park, Dallae Jin, and Angel P Del Pobil. 2012. The
    law of attraction in human-robot interaction. *International Journal of Advanced
    Robotic Systems* 9, 2 (2012), 35.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Penedo and Dahn (2005) Frank J. Penedo and Jason R. Dahn. 2005. Exercise and
    well-being: a review of mental and physical health benefits associated with physical
    activity. *Current Opinion in Psychiatry* 18 (2005), 189–193. [https://doi.org/10.1097/00001504-200503000-00013](https://doi.org/10.1097/00001504-200503000-00013)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perski et al. (2017) Olga Perski, Ann Blandford, Robert West, and Susan Michie.
    2017. Conceptualising engagement with digital behaviour change interventions:
    a systematic review using principles from critical interpretive synthesis. *Translational
    behavioral medicine* 7, 2 (2017), 254–267.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perski et al. (2019) Olga Perski, David Crane, Emma Beard, and Jamie Brown.
    2019. Does the addition of a supportive chatbot promote user engagement with a
    smoking cessation app? An experimental study. *Digital Health* 5 (2019). [https://api.semanticscholar.org/CorpusID:204737594](https://api.semanticscholar.org/CorpusID:204737594)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Piao et al. (2020) Meihua Piao, Hyeongju Ryu, Hyeongsuk Lee, Jeongeun Kim,
    et al. 2020. Use of the healthy lifestyle coaching chatbot app to promote stair-climbing
    habits among office workers: exploratory randomized controlled trial. *JMIR mHealth
    and uHealth* 8, 5 (2020), e15085.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Porcheron et al. (2018) Martin Porcheron, Joel E Fischer, Stuart Reeves, and
    Sarah Sharples. 2018. Voice interfaces in everyday life. In *proceedings of the
    2018 CHI conference on human factors in computing systems*. 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pradhan and Lazar (2021) Alisha Pradhan and Amanda Lazar. 2021. Hey Google,
    Do You Have a Personality? Designing Personality and Personas for Conversational
    Agents. In *Proceedings of the 3rd Conference on Conversational User Interfaces*
    (Bilbao (online), Spain) *(CUI ’21)*. Association for Computing Machinery, New
    York, NY, USA, Article 12, 4 pages. [https://doi.org/10.1145/3469595.3469607](https://doi.org/10.1145/3469595.3469607)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prochaska and Velicer (1997) James O. Prochaska and Wayne F. Velicer. 1997.
    The transtheoretical model of health behavior change. *American Journal of Health
    Promotion* 12, 1 (Sep-Oct 1997), 38–48. [https://doi.org/10.4278/0890-1171-12.1.38](https://doi.org/10.4278/0890-1171-12.1.38)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reeves et al. (2018) Stuart Reeves, Martin Porcheron, and Joel Fischer. 2018.
    ’This is not what we wanted’ designing for conversation with voice interfaces.
    *Interactions* 26, 1 (2018), 46–51.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rohani et al. (2020) Darius Adam Rohani, Andrea Quemada Lopategui, Nanna Tuxen,
    Maria Faurholt-Jepsen, Lars Vedel Kessing, and Jakob Eyvind Bardram. 2020. MUBS:
    A Personalized Recommender System for Behavioral Activation in Mental Health.
    *Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems*
    (2020). [https://api.semanticscholar.org/CorpusID:218482533](https://api.semanticscholar.org/CorpusID:218482533)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ryan and Deci (2000) Richard M. Ryan and Edward L. Deci. 2000. Self-determination
    theory and the facilitation of intrinsic motivation, social development, and well-being.
    *American Psychologist* 55, 1 (2000), 68–78. [https://doi.org/10.1037/0003-066X.55.1.68](https://doi.org/10.1037/0003-066X.55.1.68)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schueller et al. (2013) Stephen M. Schueller, Ricardo F. Muñoz, and David C.
    Mohr. 2013. Realizing the Potential of Behavioral Intervention Technologies. *Current
    Directions in Psychological Science* 22, 6 (2013), 478–483. [https://doi.org/10.1177/0963721413495872](https://doi.org/10.1177/0963721413495872)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Seeger et al. (2018) Anna-Maria Seeger, Jella Pfeiffer, and Armin Heinzl. 2018.
    Designing anthropomorphic conversational agents: Development and empirical evaluation
    of a design framework. (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2023) Ben Singh, Timothy Olds, Jacinta Brinsley, Dorothea Dumuid,
    Rosa Virgara, Lisa Matricciani, Amanda Watson, Kim Szeto, Emily Eglitis, Aaron
    Miatke, Catherine E M Simpson, Corneel Vandelanotte, and Carol Ann Maher. 2023.
    Systematic review and meta-analysis of the effectiveness of chatbots on lifestyle
    behaviours. *NPJ Digital Medicine* 6 (2023). [https://api.semanticscholar.org/CorpusID:259240488](https://api.semanticscholar.org/CorpusID:259240488)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Song et al. (2024) Inhwa Song, Sachin R. Pendse, Neha Kumar, and Munmun De
    Choudhury. 2024. The Typing Cure: Experiences with Large Language Model Chatbots
    for Mental Health Support. *ArXiv* abs/2401.14362 (2024). [https://api.semanticscholar.org/CorpusID:267211682](https://api.semanticscholar.org/CorpusID:267211682)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stephens et al. (2019) Taylor N Stephens, Angela Joerin, Michiel Rauws, and
    Lloyd N Werk. 2019. Feasibility of pediatric obesity and prediabetes treatment
    support through Tess, the AI behavioral coaching chatbot. *Translational behavioral
    medicine* 9, 3 (2019), 440–447.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stever (2017) Gayle S Stever. 2017. Parasocial theory: Concepts and measures.
    *The international encyclopedia of media effects* (2017), 1–12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strohmann et al. (2023) Timo Strohmann, Dominik Siemon, Bijan Khosrawi-Rad,
    and Susanne Robra-Bissantz. 2023. Toward a design theory for virtual companionship.
    *Human–Computer Interaction* 38, 3-4 (2023), 194–234.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Torous and Blease (2024) John Torous and Charlotte Blease. 2024. Generative
    artificial intelligence in mental health care: potential benefits and current
    challenges. *World Psychiatry* 23, 1 (2024), 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vaidyam et al. (2019) Aditya Nrusimha Vaidyam, Hannah Wisniewski, John David
    Halamka, Matcheri S Kashavan, and John Blake Torous. 2019. Chatbots and conversational
    agents in mental health: a review of the psychiatric landscape. *The Canadian
    Journal of Psychiatry* 64, 7 (2019), 456–464.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: van Heerden et al. (2023) Alastair C van Heerden, Julia R Pozuelo, and Brandon A
    Kohrt. 2023. Global mental health services and the impact of artificial intelligence–powered
    large language models. *JAMA psychiatry* 80, 7 (2023), 662–664.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VanderWeele (2017) Tyler J. VanderWeele. 2017. On the promotion of human flourishing.
    *Proceedings of the National Academy of Sciences of the United States of America*
    114, 31 (2017), 8148–8156. [https://doi.org/10.1073/pnas.1702996114](https://doi.org/10.1073/pnas.1702996114)
    arXiv:2017-07-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'VanderWeele (2020) Tyler J VanderWeele. 2020. Activities for flourishing: An
    evidence-based guide. *Journal of Positive School Psychology* 4, 1 (2020), 79–91.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VanderWeele et al. (2019) Tyler J. VanderWeele, Eileen McNeely, and Howard K.
    Koh. 2019. Reimagining Health-Flourishing. *JAMA* 321, 17 (2019), 1667–1668. [https://doi.org/10.1001/jama.2019.3035](https://doi.org/10.1001/jama.2019.3035)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Walsh (2011) Roger Walsh. 2011. Lifestyle and mental health. *American psychologist*
    66, 7 (2011), 579.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2015) Shensheng Wang, Scott O Lilienfeld, and Philippe Rochat.
    2015. The uncanny valley: Existence and explanations. *Review of General Psychology*
    19, 4 (2015), 393–407.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weizenbaum (1966) Joseph Weizenbaum. 1966. ELIZA—a computer program for the
    study of natural language communication between man and machine. *Commun. ACM*
    9, 1 (1966), 36–45.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yao et al. (2023) Xuewen Yao, Miriam Mikhelson, S. Craig Watkins, Eunsol Choi,
    Edison Thomaz, and Kaya de Barbaro. 2023. Development and Evaluation of Three
    Chatbots for Postpartum Mood and Anxiety Disorders. arXiv:2308.07407 [cs.CL]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. (2019) Lingyao Yuan, Alan Dennis, Kai Riemer, et al. 2019. Crossing
    the uncanny valley? Understanding affinity, trustworthiness, and preference for
    more realistic virtual humans in immersive environments. (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2020) Jingwen Zhang, Yoo Jung Oh, Patrick Lange, Zhou Yu, and
    Yoshimi Fukuoka. 2020. Artificial intelligence chatbot behavior change model for
    designing artificial intelligence chatbots to promote physical activity and a
    healthy diet. *Journal of medical Internet research* 22, 9 (2020), e22845.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang (2007) Ping Zhang. 2007. Toward a positive design theory: Principles
    for designing motivating information and communication technology. In *Designing
    information and organizations with a positive lens*. Vol. 2\. Emerald Group Publishing
    Limited, 45–74.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023) Qiang Zhang, Jason Naradowsky, and Yusuke Miyao. 2023.
    Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning in Goal-Oriented
    Dialogue Models. In *Findings of the Association for Computational Linguistics:
    ACL 2023*, Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association
    for Computational Linguistics, Toronto, Canada, 6665–6694. [https://doi.org/10.18653/v1/2023.findings-acl.417](https://doi.org/10.18653/v1/2023.findings-acl.417)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2023) Zhonghua Zheng, Lizi Liao, Yang Deng, and Liqiang Nie. 2023.
    Building Emotional Support Chatbots in the Era of LLMs. arXiv:2308.11584 [cs.CL]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: .1\. Baseline System Interface
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figure. [7](#Ax1.F7 "Figure 7 ‣ .1\. Baseline System Interface ‣ Appendix ‣
    Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being
    Activity Recommendation") shows the interfaces we implemented for the Baseline
    condition. The interaction flow of baseline condition is identical to Sunnie besides
    not having a conversation functionality and non-anthropomorphic designs. After
    the users provide text descriptions of their feelings, they will be directed to
    the Typeform page of the activity recommendations, which is identical to the Sunnie
    condition.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/180e0f5c120756783da538e6884e344c.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Page 1\. Users log their moods.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/806072b15d139ba169c806fcef8ccd6e.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Page 2\. Select the best word(s) to describe users’ feelings.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e0fdb6b865e10198b1cdb46c3e25447c.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Page 3\. Input text description of their feelings.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7\. The user interface(s) of the baseline system. The general flow of
    baseline condition is identical to Sunnie besides not having a conversation functionality
    and non-anthropomorphic designs.
  prefs: []
  type: TYPE_NORMAL
