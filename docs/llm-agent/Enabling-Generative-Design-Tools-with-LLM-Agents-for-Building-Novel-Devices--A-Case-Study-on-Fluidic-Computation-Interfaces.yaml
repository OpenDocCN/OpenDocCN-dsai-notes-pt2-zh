- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:45:40'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.17837](https://ar5iv.labs.arxiv.org/html/2405.17837)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Qiuyu Lu [0000-0002-8499-3091](https://orcid.org/0000-0002-8499-3091 "ORCID
    identifier") University of California, Berkeley110 Sproul HallCaliforniaCAUSA94720
    [qiuyulu@berkeley.edu](mailto:qiuyulu@berkeley.edu) ,  Jiawei Fang University
    of California, BerkeleyCaliforniaCAUSA [jiaweif@berkeley.edu](mailto:jiaweif@berkeley.edu)
    ,  Zhihao Yao Tsinghua UniversityBeijingChina [yaozh˙h@outlook.com](mailto:yaozh%CB%99h@outlook.com)
    ,  Yue Yang University of California, BerkeleyCaliforniaCAUSA [yue.yang@berkeley.edu](mailto:yue.yang@berkeley.edu)
    ,  Shiqing Lyu Tsinghua UniversityBeijingChina [lvsq22@mails.tsinghua.edu.cn](mailto:lvsq22@mails.tsinghua.edu.cn)
    ,  Haipeng Mi Tsinghua UniversityBeijingChina [mhp@tsinghua.edu.cn](mailto:mhp@tsinghua.edu.cn)
     and  Lining Yao University of California, Berkeley110 Sproul HallCaliforniaCAUSA
    [liningy@berkeley.edu](mailto:liningy@berkeley.edu)(2024)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the field of Human-Computer Interaction (HCI), the development of interactive
    devices represents a significant area of focus. The advent of novel hardware and
    advanced fabrication techniques has underscored the demand for specialized design
    tools which democratize the prototyping process for such cutting-edge devices.
    While these tools simplify the process through parametric design and simulation,
    they typically require a certain learning curve and often fall short in facilitating
    creative ideation. In this study, we employ fluidic computation interface as a
    case study to investigate the potential of augmenting design tools of physical
    devices with Large Language Model (LLM) agents. Enhanced by LLM agents, the Generative
    Design Tool (GDT) can comprehend the capabilities and limitations of newly developed
    devices; it can propose varied, insightful, and practical application scenarios,
    and recommend device designs that are technically and contextually appropriate.
    Furthermore, it generates the necessary design parameters for the traditional
    part of the design tool to visualize results and produce support files for fabrication.
    This paper outlines the GDT’s framework, implementation, and performance, while
    also contemplating its prospects and the obstacles encountered.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interactive Design Tool, Large Language Model, Agent, Fluidic computation,
    Pneumatic interface, Building devices^†^†copyright: iw3c2w3g^†^†journalyear: 2024^†^†doi:
    XXXXXXX.XXXXXXX^†^†conference: May 27; 2024; Pre-print submitted to arXiv^†^†booktitle:
    Woodstock ’18: ACM Symposium on Neural Gaze Detection, June 03–05, 2018, Woodstock,
    NY^†^†price: 15.00^†^†isbn: 978-1-4503-XXXX-X/18/06'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Human-Computer Interaction (HCI), especially in Tangible User Interfaces,
    Shape Changing Interfaces and broader physical computing and I/O devices fields,
    the design and development of interactive devices is a significant endeavor, incorporating
    novel hardware components that integrate sensing, computation, display, and actuation
    methods, alongside developments in materials and fabrication techniques. Since
    the design of interactive devices are often highly customized and specialized,
    the design and optimization process typically involves corresponding specialized
    design tools, developed to lower the learning curve through relatively straightforward
    parametric designing and tailored simulation and fabrication instructions (An
    et al., [2018](#bib.bib6); Yang et al., [2020](#bib.bib71); Sun et al., [2022](#bib.bib58)).
    However, designing a novel interactive device using existing specific design tools
    remains challenging. Designers must possess a holistic understanding of all the
    capabilities and limitations of new devices, as well as grasp the meaning of all
    design modules and parameters. Generating appropriate ideas and applications requires
    extensive exploration because it needs to satisfy numerous requirements, ranging
    from functional goals to feasibility constraints. Even those most knowledgeable
    about designing interactive devices, such as the developers or researchers of
    the design tools themselves, still need to devote considerable effort to design
    various and specific use cases that represent the application value of the technology.
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of universal design software, like computer-aided design (CAD)
    software, the integration of artificial intelligence (AI) has been observed to
    facilitate the design process, easing complex tasks and autonomously optimizing
    structures and materials (Miller, [2019](#bib.bib42); Jain and Kukkal, [2020](#bib.bib27)).
    However, implementing AI-based features typically demands extensive algorithm
    and model development work and/or substantial data training (Willis et al., [2022](#bib.bib70);
    Zhao et al., [2020](#bib.bib76)), which is impractical for specialized design
    tools without significant effort. Additionally, users still need to acquire specific
    domain knowledge to identify the design problem, ideate design goals, and set
    proper parameters before they can leverage such AI’s power, which doesn’t address
    the initial problem mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, Large Language Models like GPT excel in a variety of creative endeavors
    due to their broad knowledge base, nuanced language generation capabilities, and
    contextual awareness (Cheng et al., [2023](#bib.bib14); Duan et al., [2023](#bib.bib19);
    Bhavya et al., [2023](#bib.bib9); Ko et al., [2023](#bib.bib31)). For instance,
    3DALL-E (Liu et al., [2023b](#bib.bib37)) introduced a Fusion 360 plugin that
    empowers users to generate text and image prompts for modeling, drawing upon GPT’s
    vast repository of design considerations and factors. Moreover, recently, LLM
    agents have emerged as an increasing field of interest (aut, [2023](#bib.bib2);
    bab, [2023](#bib.bib3); Yao et al., [2022](#bib.bib73)). When fine-tuned, these
    agents not only absorb new knowledge but also independently manage more intricate
    tasks (Park et al., [2023](#bib.bib49); Li et al., [2024](#bib.bib32); Hong et al.,
    [2023](#bib.bib23)), leading to our curiosity about their capability to grasp
    and pioneer new interactive device technologies. Furthermore, this raises the
    question of whether a synergy between LLM and conventional specialized design
    tools can offer users a new route when prototyping novel devices, harnessing LLM’
    strengths in flexibility, adaptability, and creative problem-solving.
  prefs: []
  type: TYPE_NORMAL
- en: 'To explore how LLM agents can contribute to the design workflows of specific
    interactive physical devices, we initiated the development of a generative design
    tool (GDT) augmented with LLM agents, specifically for the fluidic computation
    interface (FCI) proposed by Lu et al. (Lu et al., [2023b](#bib.bib38)). It has
    been chosen as a representative case study for this investigation due to several
    factors: 1) it classifies as an interactive device; 2) it demands specialized
    domain knowledge not commonly found in general-purpose LLMs; 3) technologically,
    it incorporates a range of inputs, outputs, and computational functions, representing
    the diverse components frequently encountered in the development of many interactive
    devices; and 4) it thoroughly explores the design space of the technology, offering
    a solid basis for distilling a body of knowledge and logic to fine-tune LLM agents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The tool presented here can address a designer’s inquiries regarding FCI and
    provide inspiration for design goals in various application scenarios. After a
    designer inputs their vague goals (e.g., to design a ”smart Yoga pad”), the tool
    offers detailed suggestions and recommendations for corresponding functions. It
    guides the user to refine the design step by step, from selecting modules to setting
    attributes and parameters accordingly, by prompting the user with questions and
    recommendations and responding to the user’s inquiries. Moreover, the tool can
    verify the final design definition and generate the final 3D models of the FCI
    device with interaction simulation, which will directly guide the construction
    of physical devices. We present its performance in proposing and realizing design
    goals, and reflect on the advantages and challenges associated with integrating
    LLM agents into specialized design tools. We hope this work can inspire and benefit
    researchers developing design tools for interactive physical devices and expand
    the user base of such design tools. The contributions of this work can be summarized
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exploring an approach for developing LLM-agents-enhanced design tools for novel
    devices (Specifically FCI): This method employs a multi-agent framework and straightforward
    adjustments to LLM agents to facilitate rapid acquisition of FCI-specific design
    knowledge by LLM agents, preparing them for design tasks.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Development of GDT for FCI: A design tool that integrates LLM agents to apply
    fluid computation kits to novel building devices.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tests of the GDT’s performance and reflection of the advantages and challenges
    associated with integrating LLM agents into design tools in building specialized
    novel devices.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1\. AI Enhanced Design Tools for Building Devices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Specialized design tools play a crucial role in facilitating the prototyping
    of novel devices (Ion et al., [2017a](#bib.bib25), [b](#bib.bib26); Lu et al.,
    [2023c](#bib.bib39); Ou et al., [2016](#bib.bib48)). To streamline the design
    process, AI has been integrated into such tools, transforming the design landscape
    through advanced algorithms and computational methods (Gmeiner et al., [2023](#bib.bib20)).
    This integration is particularly impactful in physical prototyping, where hardware
    integration is essential. AI algorithms have drastically reduced the costs associated
    with trial and error for physical objects, increased production efficiency, and
    broadened the scope of design possibilities. For instance, Zanzibar provides a
    platform for exploring the design space of physical and digital games (Villar
    et al., [2018](#bib.bib65)), enabling rapid game development; 3D and 4D printing
    offer intuitive visualization of precise simulations (An et al., [2018](#bib.bib6);
    Peng et al., [2018](#bib.bib50); Yang et al., [2020](#bib.bib71); Tao et al.,
    [2023](#bib.bib59); Sun et al., [2022](#bib.bib58)), even supporting interactive
    design processes (Wessely et al., [2018](#bib.bib69)). Similar technologies have
    found wide application in areas such as shape-changing materials (Zhong et al.,
    [2023](#bib.bib77)) and circuit design (Drew et al., [2016](#bib.bib18); Olberding
    et al., [2014](#bib.bib47)). However, despite the advancements brought about by
    ”conventional” AI-integrated tools in improving design efficiency, they still
    face challenges such as a lack of inspiration and conceptualization of design
    goals, dependency on users for setting numerous parameters, and a shortage of
    contextual awareness and proactive suggestions (Gmeiner et al., [2023](#bib.bib20);
    Li, [2024](#bib.bib33)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Meanwhile, LLM has shown promise in addressing these challenges. It has been
    successfully utilized to enhance creative imaging tools in various domains (Cheng
    et al., [2023](#bib.bib14); Duan et al., [2023](#bib.bib19); Bhavya et al., [2023](#bib.bib9);
    Ko et al., [2023](#bib.bib31); Liu et al., [2023b](#bib.bib37)). By collaborating
    with LLM, designers can initiate projects with simple requirements and see them
    through to completion with the aid of LLM. However, despite its potential, in
    the field of designing interactive hardware systems, which inherently involve
    input, computation, and output functionalities, and interact contextually with
    users, LLM has yet to be extensively integrated into specialized design tools.
    This is potentially due to the following reasons: LLM is trained on large-scale
    textual data and lacks highly specialized knowledge in newly developed interactive
    hardware systems to handle these highly specialized tasks. Novel interactive hardware
    design involves complex combinations of components and functional modules, as
    well as considerations across multiple aspects. This complexity and diversity
    are challenging to describe with simple text and require more structured information.
    Interactive device design requires higher precision, and the results of hardware
    design need to ensure that the physical implementation works correctly and meets
    the expected functionality.'
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, we envision there is a chance to harness LLM’s capabilities to
    understand and innovate new interactive device technologies. By augmenting conventional
    specialized design tools with LLM, we can introduce a fresh approach to device
    prototyping. Leveraging LLM’s strengths in flexibility, adaptability, and creative
    problem-solving can lower usage barriers and inspire more innovative designs.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Large Language Models and Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Large Language Models, trained on vast dataset to comprehend and manipulate
    a large number (billions) of parameters (e.g., GPT-4 (Achiam et al., [2023](#bib.bib4);
    Andreas, [2022](#bib.bib7))), has become pivotal in the area as the rise of Transformer
    (Vaswani et al., [2017](#bib.bib63)) which helps them successfully generate human-like
    text. Due to their powerful anthropomorphic response capabilities, LLM has been
    applied to enable a broad range of interactive applications within the Human-Computer
    Interaction (HCI) community. For instance, some works have focused on enhancing
    the interaction mechanisms between LLM and users, allowing users to better benefit
    LLM (Liu et al., [2023a](#bib.bib36); Dang et al., [2023](#bib.bib15); Jiang et al.,
    [2023](#bib.bib29); Zamfirescu-Pereira et al., [2023](#bib.bib74); Suh et al.,
    [2023](#bib.bib57); Wang et al., [2023b](#bib.bib67)). Other studies have investigated
    how LLM can support designers by offering inspiration for CAD projects (Liu et al.,
    [2023b](#bib.bib37)) and enhancing the creative process in animation design (Tseng
    et al., [2024](#bib.bib61)), thereby directly benefiting users in design and manufacturing
    fields(Makatura et al., [2023](#bib.bib41)). Additional research has delved into
    ethical crises and social impacts. For example, ”synthetic lies” discusses the
    risks of persuasive misinformation generation of LLM (Zhou et al., [2023](#bib.bib78)).
    Liang et al. have proposed a large-scale empirical analysis on providing review
    feedback with LLM (Liang et al., [2023](#bib.bib35)). Beyond these areas, LLM
    has been applied in art creation (Angert et al., [2023](#bib.bib8)), minority
    groups (Valencia et al., [2023](#bib.bib62); Huh et al., [2023](#bib.bib24)),
    public health intervention (Jo et al., [2023](#bib.bib30)), journalism (Petridis
    et al., [2023](#bib.bib52)), education (Lu et al., [2023a](#bib.bib40); Peng et al.,
    [2023](#bib.bib51)), and more. However, we still have yet to see the LLM-based
    generative design tools being fully leveraged to design highly specialized interactive
    devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'The agent refers to an entity that is capable of autonomously performing tasks,
    making decisions, and interacting with other agents or its environment to achieve
    specific goals (Jennings et al., [1998](#bib.bib28); Vere and Bickmore, [1990](#bib.bib64)).
    Within the LLM Agent framework, LLM serves as the agent’s brain with its fundamental
    abilities such as reasoning, planning and decision-making (Wang et al., [2023a](#bib.bib66)).
    The agent possesses both long-term memory by leveraging an external knowledge
    library for fast retrieval and short-term memory through in-context learning in
    instructions, utilizing tools via external APIs and functions. These abilities
    endow LLM-agent with powerful and robust capabilities in tackling complex tasks,
    rendering it highly efficient across diverse applications. The research on LLM-Agent
    can be generally classified into single-agent and multi-agents. Early work on
    LLM Agent approaches advocated for the use of a single agent employing tools to
    tackle complex tasks (bab, [2023](#bib.bib3); Yao et al., [2022](#bib.bib73);
    aut, [2023](#bib.bib2)). However, the intricate logic of complex tasks often led
    to the single agent experiencing significant hallucinations, making it challenging
    to resolve complex issues effectively (Chen et al., [2023b](#bib.bib13)). To address
    this, the multi-agent framework champions role-playing by decomposing complex
    tasks into multiple, more manageable subtasks and allocating them to different
    agents, each possessing specialized knowledge in the areas of the assigned subtasks
    and becomes more focused on resolving these tasks (Chen et al., [2023a](#bib.bib12);
    Chan et al., [2023](#bib.bib11); Park et al., [2023](#bib.bib49)). This approach,
    which allocates subtasks to collaborative multi-agents, ensures that the generated
    results are more comprehensive and accurate, behaving with significantly superior
    capabilities in solving complex tasks far surpassing the abilities of a single
    agent (Li et al., [2024](#bib.bib32), [2023](#bib.bib34)). Within the framework
    of our work, we employed a multi-agent strategy to lay the groundwork for our
    tool’s design (Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background Knowledge on FCI ‣ Enabling
    Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study
    on Fluidic Computation Interfaces")).'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. Fluidic Computation Interfaces (FCI)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mechanical computation has garnered increasing attention in recent years, marking
    its success across various science and engineering fields such as molecular computation
    (Adleman, [1994](#bib.bib5)), robotics (Rajappan et al., [2021](#bib.bib54); Wehner
    et al., [2016](#bib.bib68)), morphological computation (Hauser et al., [2011](#bib.bib22)),
    and fluidic logic circuits (Mosadegh et al., [2011](#bib.bib44); Zhang et al.,
    [2017](#bib.bib75); Rhee and Burns, [2009](#bib.bib55)). Within the HCI device
    fabrication and design community, there’s a notable trend toward leveraging unconventional
    computation to enhance computing capabilities. A handful of HCI studies have explored
    the integration of mechanical computation within interfaces. Ion et al. introduced
    digital mechanical metamaterials for constructing logic structures (Ion et al.,
    [2017a](#bib.bib25)). Venous Materials (Mor et al., [2020](#bib.bib43)) showcased
    fluidic mechanisms that react to mechanical inputs from users to produce outputs.
    Logic Bonbon (Deng et al., [2022](#bib.bib16)) created basic logic gates for crafting
    desserts with varying flavors based on user inputs. AirLogic (Savage et al., [2022](#bib.bib56))
    advanced these fluidic logic concepts by incorporating them into 3D printing processes.
    The Fluidic Computation Kit (Lu et al., [2023b](#bib.bib38)) delves deeper, offering
    a systematic exploration of creating advanced mechanical computation devices.
    It amalgamates diverse force inputs, computation facilitated by various operators,
    and different output modalities. This breadth makes it particularly interesting,
    as it encompasses different facets of interactive device construction beyond a
    singular focus on certain actuation or sensing technology. Given its complexity
    and innovation, this technology presents unique challenges that may stretch the
    capabilities of LLM agents. Therefore, we have selected the FCI, drawing from
    the research of Lu et al., as our entry point to investigate the potential opportunities
    and challenges of LLM agents in empowering novel device design tools.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Background Knowledge on FCI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'FCI, specifically referring to devices constructed using the Fluidic Computation
    Kit (Fig. [1](#S3.F1 "Figure 1 ‣ 3\. Background Knowledge on FCI ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces")) (Lu et al., [2023b](#bib.bib38)) in our context, employs
    fluidic circuits with pneumatic components, such as valves, for performing logic
    computations through pneumatic signals. These signals are differentiated by positive
    pressure (1) and atmospheric pressure (0), facilitating logic operations and generating
    outputs based on these computations. The design space of FCI includes force input,
    mechanical computation, and tangible output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/66403920d3975db95c6ba74570aeadd8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. Building an interactive sitting posture correction chair with the
    Fluidic Computation Kit. a) Pick the elementary components. b) Construct the operators
    via wiring the components. c) Wiring the circuit with operators according to the
    computation logic. d) Preparing the input/output airbags and integrating them
    with the circuit into a chair. (Permission granted from the authors)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/62e4632c20d02743fc4b2c5aff0af765.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. The GDT’s overview. Sections a-g constitute the backend, which includes
    LLM agents and conventional algorithms. Sections h-m represent the frontend, utilized
    by users interacting with the GDT. The Consultant agent (a) and the first tab
    of the GUI (h,j) are dedicated to assisting with the design ideation and detailing
    phase. The remaining components are focused on the solution implementation phase.
    Some text within the GUI has been enlarged to enhance readability. The heat-sealing
    pattern for the output module (m) will be provided when the type of output is
    shape-changing, and the shape is associated with an inverse design algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: '- Input: This part mainly comprises airbags that detect actions leading to
    a change in internal air pressure, usually due to external forces applied during
    manipulation. This change in pressure shifts the input signal between atmospheric
    (0) and positive (1), allowing it to detect the presence, duration, frequency,
    and sudden changes of force.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Computation: At the heart of FCI, the fluidic circuit receives air pressure
    input signals and processes them using predetermined logic calculations, subsequently
    producing output signals aimed at the output part. It is built with basic computational
    components (in triangle form) and various operators (created by combining components).'
  prefs: []
  type: TYPE_NORMAL
- en: '- Output: The output section can deliver feedback in multiple forms, such as
    shape-change, haptic feedback, olfactory feedback, and Acoustic feedback, all
    fundamentally powered by airflow.'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Designing with the GDT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0752067fedecc2e0eb74adce44a3574f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3\. The user flow for designing with Fluid Computation GDT includes:
    (1) Greeting the Consultant and freely asking for explanations or s to learn about
    FCI. (2) Setting the design goal with the help of ideation from the Consultant.
    (3) Defining the input, output, and computation modules with the Consultant’s
    guidance and recommendations. (4) Confirming the design definition and previewing
    the generated fluid computation system; clicking the input module to see the animated
    demonstration of control logic.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The GDT’s architecture, illustrated in Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background
    Knowledge on FCI ‣ Enabling Generative Design Tools with LLM Agents for Building
    Novel Devices: A Case Study on Fluidic Computation Interfaces"), includes elements
    similar to those found in conventional specialized design tools, such as parametric-driven
    design, design outcome rendering previews, and simulations. However, unlike those
    tools that require users to conceive application designs (design goals, DGs) that
    fit new devices and manually set various parameters or drag-and-drop modules to
    complete the design, this GDT, augmented with LLM agents, can assist or even take
    over these tasks. Specifically, the following LLM agents are integrated into this
    GDT:'
  prefs: []
  type: TYPE_NORMAL
- en: '- Consultant (Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background Knowledge on FCI ‣
    Enabling Generative Design Tools with LLM Agents for Building Novel Devices: A
    Case Study on Fluidic Computation Interfaces").a): This agent is equipped with
    comprehensive knowledge of FCI’s capabilities and limitations. It can answer questions
    regarding the FCI, help define design goals, and assist in deciding various details
    needed during the design phase. It interacts with users via a GUI dialogue box
    (Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background Knowledge on FCI ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces").i) and provides real-time updates of design details on
    the GUI for easy access (Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background Knowledge
    on FCI ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces").h). In addition, the design goal
    will be displayed at the result window as well (Fig. [2](#S3.F2 "Figure 2 ‣ 3\.
    Background Knowledge on FCI ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").l)'
  prefs: []
  type: TYPE_NORMAL
- en: '- Logic Designer, Circuit Engineer, Inspector (Fig. [2](#S3.F2 "Figure 2 ‣
    3\. Background Knowledge on FCI ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").b-d):
    These three agents are responsible for the design of the computation module, a
    key component of the FCI tasked with performing logical operations with mechanical
    circuits. The Logic Designer analyzes the design details provided by the Consultant
    and outputs computational logic in a prescribed standard format. The Circuit Engineer,
    familiar with the operators within FCI and capable of ”circuit” design, selects
    appropriate operators based on the provided logic to complete the FCI circuit
    design. The Inspector checks and rates the correctness and conciseness of the
    FCI circuit, deciding whether to send it back to the Circuit Engineer for modifications.
    Circuit designs approved by the Inspector are used for visualization and simulation
    on the GUI (Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background Knowledge on FCI ‣ Enabling
    Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study
    on Fluidic Computation Interfaces").g, k). Users can refer to the visualization
    results to construct the FCI circuit. Input and output modules are visualized
    qualitatively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The computational logic and inspection report will be sent to and displayed
    at Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background Knowledge on FCI ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces").l.'
  prefs: []
  type: TYPE_NORMAL
- en: '- I/O Designer (Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background Knowledge on FCI
    ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces").e): Responsible for designing
    the I/O module, which includes artifacts like airbags in the FCI for detecting
    external inputs or providing output feedback. The I/O Designer, also receiving
    design details from the Consultant, will offer design suggestions for the I/O
    module based on this information and its knowledge of the FCI. These are primarily
    qualitative suggestions. But in cases when five predefined shapes are used for
    the output airbags, quantitative geometry of these shapes (e,g, the diameter of
    a sphere) will be suggested. Qualitative recommendations are directly reflected
    in the corresponding section of the GUI (Fig. [2](#S3.F2 "Figure 2 ‣ 3\. Background
    Knowledge on FCI ‣ Enabling Generative Design Tools with LLM Agents for Building
    Novel Devices: A Case Study on Fluidic Computation Interfaces").m). Quantitative
    suggestions are processed through inverse design algorithms to generate heat-sealing
    patterns and dimensions for user review via the GUI (Fig. [2](#S3.F2 "Figure 2
    ‣ 3\. Background Knowledge on FCI ‣ Enabling Generative Design Tools with LLM
    Agents for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").m).'
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will demonstrate the process of completing an FCI
    design using this FCI-GDT through an example.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. Walkthrough
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we provide a design walkthrough of using our design tool to
    create a smart yoga pad for Emily (Fig. [3](#S4.F3 "Figure 3 ‣ 4\. Designing with
    the GDT ‣ Enabling Generative Design Tools with LLM Agents for Building Novel
    Devices: A Case Study on Fluidic Computation Interfaces")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Greet & Introduction (Fig. [3](#S4.F3 "Figure 3 ‣ 4\. Designing with the GDT
    ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces").1). Upon opening the GUI, Emily
    is warmly greeted by the Consultant, who briefly introduces himself and invites
    her to inquire about the Fluidic Computation Interface (FCI) and share design
    ideas. Emily asks about the purpose of FCI, to which the counselor explains it
    as a non-electronic pneumatics system utilizing fluidic circuits for logic calculations.
    The FCI comprises Input, Computation, and Output Modules, each serving distinct
    functions. Potential applications like posture correction and security systems
    are highlighted, showcasing FCI’s ability to detect force changes and provide
    various feedback forms. Emily then requests detailed s of FCI applications, leading
    the counselor to provide instances such as a Posture Correction Chair and Medication
    Reminder. Each application demonstrates function, detection, and feedback.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set Design Goal (Fig. [3](#S4.F3 "Figure 3 ‣ 4\. Designing with the GDT ‣ Enabling
    Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study
    on Fluidic Computation Interfaces").2). Following the explanation, the Consultant
    assists Emily in defining the design goal, assuring her that detailed concept
    ideas are unnecessary as the bot can help develop them. Emily expresses interest
    in creating a yoga pad to help practicing yoga and seeks suggestions from the
    assistant. The Consultant proposes ideas like Posture Detection, Sequence Guide,
    and Breathing Aid. Inspired by these suggestions, Emily decides to design a yoga
    pad with posture detection and provide physical assistance for difficult poses.
    She adds detail: ”If a user cannot reach the hand area of the mat during a pose,
    the mat will detect this and inflate the hand area to form a supportive structure,
    similar to a yoga air block, aiding the user in maintaining the correct pose.”
    When Emily inquired about the specific goal posture, the Consultant also recommended
    certain applied postures, particularly focusing on common poses that often pose
    difficulty for beginners and those that can benefit from added support to maintain
    correct alignment, such as the Triangle Pose. The Consultant confirms the goal
    and guides Emily to the next step.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define Input Module (Fig. [3](#S4.F3 "Figure 3 ‣ 4\. Designing with the GDT
    ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces").3). After finalizing the design
    goal, the Consultant proceeds to help define the Input Module for the yoga pad.
    The Input Module of the system comprises airbags that detect external forces,
    causing a change in pressure that alters the input signal from atmospheric (0)
    to positive (1) pressure. Each input is characterized by three main properties
    in addition to a comment note:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Attribute: Defines the state of the signal as Binary (0 or 1), Duration (how
    long it remains in each state), Frequency (how frequently it transitions), and
    Edge (transition moment).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Location: Indicates where the input airbags are placed, such as under the feet,
    on the sides of the vehicle, or within the seatbelt.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Manipulation: Describes how the airbags are interacted with, including actions
    like squeeze, step, press, or twist.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note (Optional): Supplements additional information for specific types of input,
    such as frequency/duration values.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this walkthrough, the Consultant suggests using two inputs: Input A for
    detecting hand presence along specific points on the pad corresponding to expected
    hand placements in posture, and Input B for detecting foot presence to determine
    if the user is standing on the pad and initiating this posture. These inputs are
    set to binary attributes, indicating the presence or absence of pressure. Emily
    asks to add a delay for the input to avoid false activations. The Consultant changes
    the corresponding attribute of the input and asks to confirm that this meets Emily’s
    expectations without any additional features.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define Output Module (Fig. [3](#S4.F3 "Figure 3 ‣ 4\. Designing with the GDT
    ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces").3). Once Emily confirms the former
    step, the Consultant guides the discussion toward defining the Output Module,
    presenting various options, including shape-changing, haptic, olfactory and acoustic
    feedback, which are aligned with the capabilities of the Fluidic Computation Interface
    (FCI). Given the design goal of providing physical assistance when the user’s
    hand cannot reach the side edges of the mat, the Consultant suggests one specific
    output: Output I (Shape-changing Feedback), which involves inflating to form a
    supportive air block when the hand is not detected but the foot is. The Consultant
    then asks whether further discussion on this output is needed or if any additional
    output types should be considered for the yoga mat. Emily is satisfied with the
    result and confirms it. The Consultant inquires about the shape and size of the
    output Emily wants and, based on the cues from the yoga bricks, recommends a box
    measuring 23 * 15 * 7.5 cm.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define Computation Module (Fig. [3](#S4.F3 "Figure 3 ‣ 4\. Designing with the
    GDT ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces").3). Next, the Consultant outlines
    the Computation Module, specifying that Output I, the inflation of the supportive
    air block, is triggered when Input B detects foot pressure but Input A does not
    detect hand pressure for 30 seconds. This logic ensures that the yoga pad provides
    assistance when the user is attempting the Triangle Pose and requires support
    for their hand. Following Emily’s confirmation, the Consultant informs her that
    the design definition process has concluded. It inquires whether she would prefer
    to finalize the design in its current state or if there are any adjustments or
    additions she would like to make.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Preview and interact with the generated device (Fig. [3](#S4.F3 "Figure 3 ‣
    4\. Designing with the GDT ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").4).
    After reviewing all the design definitions on the UI panels, Emily clicks the
    ”Result” button to switch to the page displaying the generated FCI model. This
    interface includes a description, truth table, 3D model of fluid computation kit
    structures with logic simulation, and suggestions for designing the I/O Module.
    Emily can click on the highlighted input module model to change its state and
    observe the corresponding changes of the output module (Fig. [3](#S4.F3 "Figure
    3 ‣ 4\. Designing with the GDT ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").4.1).
    Based on the generated model and description, Emily is ready to connect the entities
    of the Fluid Computation kits, fabricate inflatable airbags (Fig. [3](#S4.F3 "Figure
    3 ‣ 4\. Designing with the GDT ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").4.2),
    and integrate each module into real space, considering practical application scenarios
    for their proper arrangement.'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we report on the GDT’s performance in design tasks, with a
    particular focus on assessing its capabilities from two perspectives: the ability
    to propose design goals and the capacity to realize the design goals. During the
    experiments, we provided only the most basic requests and guidance, including:
    providing design goals, requiring the tool to independently complete each component’s
    design, and requesting it to perform a check after completing each component’s
    design.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Performance in Proposing Design Goals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f01963575279074d7efa74e90bf665c1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Categorization of the one hundred design goals proposed by the GDT,
    based on their application scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: \Description![Refer to caption](img/87c7c3a0ec875a24a8af5621b049d2f1.png)
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5\. Rating result of the one hundred design goals.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'We specifically constructed the Consultant agent in GDT to ”include the function,
    the detection requirements to achieve that function, and the necessary feedback”
    when proposing design goals. Generally, the GDT consistently provided design goals
    that included this essential information. The GDT was tasked with proposing one
    hundred design goals (DGs), delivering ten goals at a time over ten sessions.
    The complete list of these DGs is available in the Supplementary Material. Firstly,
    we evaluated the variety of the design goals. The goals were categorized based
    on application scenarios, as shown in Fig. [4](#S5.F4 "Figure 4 ‣ 5.1\. Performance
    in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools
    with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation
    Interfaces"). This categorization spans ten major categories and twenty-four subcategories,
    demonstrating considerable diversity overall.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Subsequently, we assessed the outcomes, the goals, based on four criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Novelty: This criterion assesses the uniqueness and innovation of the application
    scenario, focusing on the design’s originality in relation to existing literature
    and other design goals in the list. For instance, a design such as “…an encrypted
    door latch that responds to a specific sequence of steps with a particular frequency…(DG2)”
    lacks novelty, given its similarity to previous works. Conversely, “…to promote
    an interactive learning environment by detecting edge transitions in pressure
    on a classroom floor…(DG89)” stands out as novel, distinguished by its uniqueness
    and absence of similar applications within the experts’ knowledge or the list.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rationality: Evaluates the logical foundation and appropriateness of the design’s
    function within its intended scenario. This perspective examines the design goal’s
    method of providing feedback or interaction, ensuring it is logically coherent
    and suited for its purpose. For instance, “…ensure driver attentiveness by detecting
    the frequency of steering wheel manipulation…(DG16)” is deemed irrational, as
    there is a weak correlation between the mentioned elements. “… to encourage hydration
    during exercise by detecting the absence of bottle squeezing over time and producing
    a distinctive olfactory reminder (DG49)” is more rational .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Feasibility: This metric determines the likelihood of the proposed interface
    being practically realized with the current hardware and technology. It appraises
    the design’s capability of being developed into a functional, tangible interface.
    For instance, “…sensing the rising and falling edges of ambient noise pressure
    on sound-absorbing panels…(DG79)” is considered infeasible, as the technology
    lacks the capability to discern noise levels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Complexity: Measures the complexity of the design goals, mainly taking into
    account the number of inputs, outputs, and computational logic. Experts primarily
    assess it based on whether a) multiple inputs or outputs need to be employed,
    and b) the computation potentially requires more than simple one-to-one logic
    or needs cascading operators. A design is categorized as low complexity if neither
    condition is met, medium complexity if one condition is met, and high complexity
    if both are met.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bed018d1b72fccd5f60e5571398f7ab1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. Selected design outcomes for three low-complexity Design Goals (DGs).
    For DG87-A, the LLM agents opted for a bending shape-changing output, a predefined
    shape supported by a corresponding inverse design algorithm. Consequently, the
    GDT provided a heat-sealing pattern, with its dimensions calculated according
    to the bending strip dimensions suggested by the agent.
  prefs: []
  type: TYPE_NORMAL
- en: \Description![Refer to caption](img/f5c28a69120ecca9964c9d956516df25.png)
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7\. Selected design outcomes for three medium-complexity DGs. For DG15-A,
    The circuit was deemed faulty because the input airbag can only provide a signal
    and cannot supply a continuous airflow. The diode should be replaced with two
    NOT gates.
  prefs: []
  type: TYPE_NORMAL
- en: \Description![Refer to caption](img/977cb24ff3322ff10be99b2c6c95d699.png)
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8\. Selected design outcomes for three high-complexity DGs. DG90-B was
    unsuccessful in proposing a logical rationale to distinguish between walking and
    standing. DG98-B did not propose a feasible solution for detecting when the trash
    pedal is not stepped on. Furthermore, both DG98-B and DG98-C did not offer a viable
    location for placing the Input B airbag to detect when it is 75% full.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'The scoring results for the 100 design goals are shown in Fig. [5](#S5.F5 "Figure
    5 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"). DGs with medium or high levels of novelty accounted
    for 83%, while the distribution of complexity was relatively even across the three
    levels. Rationality and Feasibility fundamentally influence whether DGs can be
    realized, with both criteria showing that approximately 80% of DGs scored medium
    or higher. For DGs that scored Low in either Rationality or Feasibility, we conducted
    additional tests. We fed these specific DGs back to the agent, requesting an optimization
    focused on either Rationality or Feasibility (explaining the meaning of these
    criteria in the prompt) and then had experts re-evaluate them. As a result, DGs
    that initially scored Low dropped from 20 to 7 in Rationality and from 23 to 4
    in Feasibility.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Performance in Realizing Design Goals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From the pool of DGs characterized by high novelty and medium or above in Rationality/Feasibility,
    we selected nine DGs, with three from each complexity level. We tasked the GDT
    with creating three designs for each DG, resulting in a total of twenty-seven
    designs. The selected outcomes are illustrated in Fig. [6](#S5.F6 "Figure 6 ‣
    5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), [7](#S5.F7 "Figure 7 ‣ 5.1\. Performance in Proposing
    Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"),
    [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance
    ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces"). Due to space constraints, we
    detailed nine of these design outcomes. We evaluated the accuracy and highlighted
    strengths and issues encountered during the design process.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.1\. Accuracy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The accuracy of the designs was evaluated by experts based mainly on whether
    the circuitry implementation could achieve the DG’s intended function. The accuracy
    was higher among designs with low to medium complexity (Fig. [6](#S5.F6 "Figure
    6 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), [7](#S5.F7 "Figure 7 ‣ 5.1\. Performance in Proposing
    Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"))
    but saw a decline in designs with high complexity (Fig. [8](#S5.F8 "Figure 8 ‣
    5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces")).'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.2\. Design Process
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We summarized the pros and cons observed in the design process, categorized
    by design steps following the establishment of a DG.
  prefs: []
  type: TYPE_NORMAL
- en: 'I. Defining Input/Output Module. Overall, the agent is capable of correctly
    determining the number and form of inputs/outputs (I/O) based on the DG, for instance,
    ”Given the design goal of facilitating precise medication dosage…, it’s appropriate
    to have a single output module that corresponds to the single input…(Fig. [6](#S5.F6
    "Figure 6 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling
    Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study
    on Fluidic Computation Interfaces"), DG87).” Moreover, in cases where the DG does
    not explicitly describe the quantity or form of I/O, the agent can infer and make
    reasonable decisions by considering the context of the design goal. For example,
    ”…to properly distinguish between standing still and walking, we could consider
    using the Frequency attribute to detect how frequently the pressure (in the sole)
    changes (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in Proposing Design Goals
    ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents for Building
    Novel Devices: A Case Study on Fluidic Computation Interfaces"), DG90).” This
    DG does not specify what to detect for determining walking, yet the agent thoughtfully
    decides on a rational input design. Similarly, ”Since the goal is … yoga poses,
    we will define inputs based on common yoga poses and the specific areas of the
    mat that would detect pressure when those poses are performed. Considering a basic
    yoga session could include multiple poses, let’s plan for two distinct inputs
    that cover two poses. Here are my suggestions for the input module based on different
    poses: Input A could be for detecting a pose like Downward Dog, which primarily
    involves pressure on the hands and feet. Input B could be for a Seated Forward
    Bend, with pressure detected towards the center of the mat where the sit bones
    would be. Each input’s attribute would be Duration, as we are measuring how long
    someone maintains a pose. The manipulation would be the sustained Press of the
    body against the mat (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in Proposing
    Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"),
    DG51).” In this, the agent provides the number of inputs and explains the reasoning,
    also sensibly specifying the Location and Manipulation for different inputs. When
    the envisioned I/O form in a DG might be impractical, the agent can also proactively
    adjust, for instance, ”Since we’re dealing with an industrial environment where
    the primary concern is prompt and clear notification, the feedback should likely
    be haptic or acoustic, instead of using shape-changing mechanisms that might directly
    halt machine operations (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1\. Performance in Proposing
    Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"),
    DG22)”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For different Input Attributes, we also instruct the Consultant to determine
    the corresponding values. For Frequency, it’s necessary to establish a target
    frequency value, and for Duration, to determine the length of time. The agent
    often provides reasonable values, such as ”in a medical setting where precise
    medication dosage is critical, the frequency of syringe plunger pressure would
    likely be much lower to allow for careful measurement and handling of medication.
    A more reasonable frequency would be around 0.5 Hz…(Fig. [6](#S5.F6 "Figure 6
    ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), DG87)” and ”…keeps track of the duration that the shower
    mat is under pressure, and we can set an initial default duration threshold to,
    for 5 minutes, in line with environmental recommendations. (Fig. [7](#S5.F7 "Figure
    7 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), DG43)” Similarly, for different types of Output Feedback,
    we require the agent to specify the type of shape change, scent, sound, or location
    of haptic feedback. The agent can also provide sensible suggestions, such as ”The
    scent used should be recognized for its calming properties, such as lavender or
    chamomile,… (Fig. [7](#S5.F7 "Figure 7 ‣ 5.1\. Performance in Proposing Design
    Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents for
    Building Novel Devices: A Case Study on Fluidic Computation Interfaces"), DG14)”'
  prefs: []
  type: TYPE_NORMAL
- en: 'While the agent often provides appropriate values initially, it may not always
    get them right on the first attempt. However, prompting a self-check after the
    completion of each design component can rectify such errors. For example, the
    frequency value was initially set at 5 Hz and adjusted to 0.5 Hz after a self-review
    (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\.
    Performance ‣ Enabling Generative Design Tools with LLM Agents for Building Novel
    Devices: A Case Study on Fluidic Computation Interfaces"), DG87). Sometimes, the
    agent might overlook the limitations of the fluidic computation kit’s capabilities,
    a scenario we primarily observed in cases involving acoustic feedback, such as
    “Output II, Acoustic, Historical narrative of the map section (Fig. [7](#S5.F7
    "Figure 7 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling
    Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study
    on Fluidic Computation Interfaces"), DG15).” This oversight could be due to the
    descriptions of available sound feedback forms in the knowledge base not being
    sufficiently clear to the agent.'
  prefs: []
  type: TYPE_NORMAL
- en: 'II. Defining Computation Module. For DGs with medium complexity and below,
    the agent is generally capable of proposing computation logic that aligns with
    the DG. For instance, “Given our design goal…, the output should be triggered
    when the input detects a falling edge, indicating a sudden drop in seat pressure.
    Thus, the condition for activating the acoustic feedback is when a falling edge
    is detected by Input A (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1\. Performance in Proposing
    Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"),
    DG41)”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, for DGs with high complexity, the agent begins to encounter errors
    more often. For example, “if input A detects that the Downward Dog pose is held
    for less than 30 seconds, it suggests the user is a beginner, and Output I will
    inflate for support. If held for more than 60 seconds, it indicates a higher skill
    level, and Output I will deflate to increase difficulty… (Fig. [8](#S5.F8 "Figure
    8 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), DG51).” The logic flaw lies in the design to inflate
    support within the first 30 seconds for all users, inaccurately assuming beginner
    status regardless of actual skill level. Typically, allowing the agent to perform
    a self-check can correct such a mistake: “if input A detects that the Downward
    Dog pose for more than 45 seconds, it indicates a higher skill level, and Output
    I will deflate to increase difficulty (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance
    in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools
    with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation
    Interfaces"), DG51)”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'III. I/O Module Design. In terms of the input module, the corresponding agent
    can usually provide the requested qualitative information accurately, including
    the design (size, shape, material) of the airbag serving as an input device and
    its placement. For example, ”The airbag should be sufficiently thin and flexible
    to comfortably fit within the soles of shoes. Its shape can be akin to that of
    a sole, though smaller in size. (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance
    in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools
    with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation
    Interfaces"), DG90)”, ”…the airbag should be made of elastic material, allowing
    it to recover its shape when no force is applied, catering to the ’Frequency’
    attribute’s need for resiliency… (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1\. Performance
    in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools
    with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation
    Interfaces"), DG87)” and ”…design an airbag sized and shaped to cover the top
    corners and the bottom center of the yoga mat… (DG51).” However, we noticed a
    general weakness in understanding spatial distribution, specifically, it does
    not actively consider and avoid interference among multiple input devices in the
    same space, as shown by ”For Input A, …This airbag… should appropriately fit the
    inner contours of the stress ball… For Input B, another airbag embedded within
    the stress ball is needed to detect binary gripping force… (Fig. [6](#S5.F6 "Figure
    6 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), DG14).”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding the output module, the agent generally provides suitable qualitative
    suggestions as requested as well. For instance, ”For Output I, a tube designed
    to emit an alarm sound under airflow is needed. A pneumatic whistle could be utilized…([6](#S5.F6
    "Figure 6 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling
    Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study
    on Fluidic Computation Interfaces"), DG22)” and ”…for olfactory feedback, a tube
    imbued with a refreshing scent, filled with essential oils known for their invigorating
    properties, should release the scent into the shower area (Fig. [7](#S5.F7 "Figure
    7 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), DG43).” Additionally, for ”Shape-changing Feedback”
    that matches preset shapes in the knowledge base, we tasked the agent with attempting
    to quantify relevant geometry based on the context. The agent performs well in
    these tasks, as demonstrated by ”Since Output I is an airbag that inflates inside
    the water tube to partially obstruct flow after 5 minutes of shower use, its design
    must allow for expansion to effectively regulate water flow. A spherical airbag,
    fitting standard U.S. shower tube diameters for even restriction, with a radius
    of 12.7 mm (0.5 inches) is optimal, significantly reducing but not stopping the
    flow (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in Proposing Design Goals
    ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents for Building
    Novel Devices: A Case Study on Fluidic Computation Interfaces"), DG43)” and ”Given
    the unspecified syringe type, for common usage, a bending airbag could measure
    60 mm in length and 10 mm in width, with a bend angle of 45 degrees to provide
    the necessary feedback, attachable to the syringe’s label area (Fig. [6](#S5.F6
    "Figure 6 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling
    Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study
    on Fluidic Computation Interfaces"), DG87).” Inverse design for obtaining the
    airbag’s heat-seal pattern is facilitated by agent performing function calls and
    consistently executed accurately, for example, ”L: 79.76 mm, W: 39.88 mm, d=4.98
    (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in Proposing Design Goals ‣ 5\.
    Performance ‣ Enabling Generative Design Tools with LLM Agents for Building Novel
    Devices: A Case Study on Fluidic Computation Interfaces"), DG43)” and ”L: 60mm,
    W: 10mm, a: 3.33mm, d: 8.08mm, D: 20mm, n: 2 (Fig. [6](#S5.F6 "Figure 6 ‣ 5.1\.
    Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces"), DG87).” However, we noted a shortfall in accurately
    identifying somewhat more intricate spatial relationships and physical interactions.
    Specifically, the unsuccessful attempts for DG98 ([8](#S5.F8 "Figure 8 ‣ 5.1\.
    Performance in Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces")) demonstrated an inability to pinpoint an appropriate
    placement for the Input airbag which is crucial for detecting the bin fullness.'
  prefs: []
  type: TYPE_NORMAL
- en: 'IV. Computation Module Design. This task is collaboratively completed by a
    Logic Designer, Circuit Engineer, and Inspector. The Logic Designer can accurately
    transcribe and standardize the DG and module design information into a ”truth
    table.” And we’ve observed its capability to appropriately refine computation
    logic. For example, ”If the duration of A or B being 0 is ¡ 30 minutes, then Output
    I = 0; If the total duration of A or B being 0 is ¿= 30 minutes and A or B = 0,
    then Output I = 1 (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in Proposing
    Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"),
    DG90),” where the Logic Designer introduces an additional AND logic to ensure
    the output is activated only when the walking duration exceeds the specified time
    and the subject is still walking. The Circuit Engineer can correctly complete
    designs for DGs with medium and lower complexity. However, errors are sometimes
    observed in high-complexity DGs, such as ”OR (A, B; Q) Timer(Q, 1800; TimerOutput)
    AND(Q, TimerOutput; Output I) (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in
    Proposing Design Goals ‣ 5\. Performance ‣ Enabling Generative Design Tools with
    LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"),
    DG90)” where Input A is not inverted, leading to a detection for when A is pressed
    down. In such instances, the Inspector can identify mistakes and suggest corrections,
    ”The truth table specifications are not fully met by the current circuit description…,
    an inversion of Input A and Input B’s condition is required…, ’circuit’: NOT(A;
    C) NOT(B; D) OR (C, D; Q) Timer(Q, 1800; TimerOutput) AND(Q, TimerOutput; Output
    I) (Fig. [8](#S5.F8 "Figure 8 ‣ 5.1\. Performance in Proposing Design Goals ‣
    5\. Performance ‣ Enabling Generative Design Tools with LLM Agents for Building
    Novel Devices: A Case Study on Fluidic Computation Interfaces"), DG90).”'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we detail the implementation specifics of our GDT.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1\. The Technical Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/751f8808dfae814ac8819909a1d8b8ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9\. The technical architecture of GDT.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture is illustrated in Fig. [9](#S6.F9 "Figure 9 ‣ 6.1\. The Technical
    Architecture ‣ 6\. Implementation ‣ Enabling Generative Design Tools with LLM
    Agents for Building Novel Devices: A Case Study on Fluidic Computation Interfaces"),
    leveraging OpenAI APIs (GPT4-preview), Voiceflow, Flask, and Unity in its development.
    Unity primarily forms the front-end interface, while Voiceflow, Flask, and OpenAI
    APIs serve as the backbone of the back-end, facilitating the collaborative workflow
    of LLM agents.'
  prefs: []
  type: TYPE_NORMAL
- en: Agents are empowered with Flask and OpenAI APIs. Flask, a lightweight web application
    framework in Python, facilitates API development, request handling, data post-processing,
    and serves as an integration layer. The resources—comprising instructions, libraries,
    and tools—configured for the agents are hosted on Flask and relayed to OpenAI
    APIs upon agent initialization.
  prefs: []
  type: TYPE_NORMAL
- en: 'We utilize two distinct OpenAI APIs: GPT and Assistant. Each API demands specific
    Instruction to define the agent’s core response mechanisms and utilizes user data
    to prompt responses. The Assistant API, however, distinguishes itself by allowing
    Tool use, maintaining contextual memory, and the ability to consult a knowledge
    base, referred to as the Library. This, however, incurs higher token usage. The
    choice between GPT and Assistant APIs for agent development is dictated by the
    task’s complexity. For tasks that require basic functionality, such as those handled
    by the Logic Designer and Inspector, the GPT API is the optimal choice due to
    its straightforwardness. Conversely, for roles demanding more nuanced understanding
    and interaction—like the Consultant, I/O Designer, and Circuit Engineer—the Assistant
    API offers more sophisticated features that are particularly beneficial.'
  prefs: []
  type: TYPE_NORMAL
- en: Flask designates a specific port for each agent, acting as the agent’s distinct
    ”address” within the public network for streamlined access by Voiceflow. Through
    these dedicated ports, Voiceflow facilitates communication to and from the respective
    agents, enabling a seamless collaborative workflow among agents. Voiceflow plays
    a pivotal role in orchestrating the interactions among agents. The front-end interface
    is developed using Unity (Version 2022.3.15), which monitors the exchanges between
    Voiceflow and the agents via the Voiceflow API, ensuring that these interactions
    are effectively presented to the user. In addition to facilitating conversations
    with users and displaying text-based results, Unity also integrates algorithms
    for the visualization and simulation of the FCI device.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2\. Configure LLM Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f1bdd8257a617a5f5094ebf164d9fe37.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10\. A potential general agent collaboration framework. Our GDT consists
    the Consultant and two agent clusters (one for solving the computation module
    design, one for the I/O Modules).
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1\. Task Allocation for Multi-Agents
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Assigning agents to focus on narrow and specific types of work tends to yield
    better outcomes (Li et al., [2024](#bib.bib32), [2023](#bib.bib34)). Specifically,
    in the context of designing novel devices like FCIs, we organize and delegate
    tasks with the following considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Initially, we categorize the entire design process into two main phases: ideation
    of design goals and detailing (Ideation & Detailing), and the technical implementation
    of solutions (Implementation Solution). The Ideation & Detailing phase demands
    a comprehensive qualitative understanding of the design space for the new device
    (FCI in our case), and a macroscopic view of the design. We assign this sub-task
    to one agent (Consultant) and guide it on how to gather or propose sufficient
    design details (Fig. [10](#S6.F10 "Figure 10 ‣ 6.2\. Configure LLM Agents ‣ 6\.
    Implementation ‣ Enabling Generative Design Tools with LLM Agents for Building
    Novel Devices: A Case Study on Fluidic Computation Interfaces").a).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Implementation Solution phase involves the specific design of various sub-modules
    within a device, requiring specialized and in-depth knowledge, and can be assigned
    to different clusters of agents (Fig. [10](#S6.F10 "Figure 10 ‣ 6.2\. Configure
    LLM Agents ‣ 6\. Implementation ‣ Enabling Generative Design Tools with LLM Agents
    for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").b).
    If we follow the modules included in FCI, they should be divided into Input, Output,
    and Computation modules. However, during development, we find that some knowledge
    required for designing I/O modules is relatively challenging to explain effectively
    to LLM agents through natural language, and LLM agents inherently struggle with
    tasks involving structure, geometry, and space. Therefore, we adjust the design
    expectations for these two modules to primarily produce qualitative suggestions,
    thereby simplifying the task difficulty and assigning it to one agent (I/O Designer).
    For the Computation Module, as LLM agents can draw on their knowledge in electronic
    circuit design, we set the design expectation to produce directly executable solutions.
    We refer to the conventional steps of logic electrical design (Dessouky et al.,
    [2019](#bib.bib17); Blocklove et al., [2023](#bib.bib10)) and specifically divide
    this design task into Logic Analysis (Logic Designer), Circuit Generation (Circuit
    Engineer), and Circuit Inspection (Inspector), allocating them to an agent cluster
    to achieve the best results.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2\. Qualifying Agents for Tasks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We primarily qualify agents for their assigned tasks through three resources:
    the Libraries, the Instruction, and the Tool (Fig. [10](#S6.F10 "Figure 10 ‣ 6.2\.
    Configure LLM Agents ‣ 6\. Implementation ‣ Enabling Generative Design Tools with
    LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation Interfaces").c).'
  prefs: []
  type: TYPE_NORMAL
- en: 'I. Instructions are a carefully crafted prompt designed to articulate the objectives
    of a task and outline the expected method for the agent’s response. All Instructions
    utilized for each agent are detailed in Appendix [A](#A1 "Appendix A Instructions
    ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces"). Proper organization of the Instruction
    is essential to augment the agent’s effectiveness in accomplishing tasks. To achieve
    this, we organize the Instruction into distinct sections, not only simplifying
    comprehension for agents but also easing maintenance for developers. Generally,
    the sections include:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Role delineates the fundamental identity and capabilities of each agent, providing
    a clear directive like ”you are an electronic circuit engineer, your goal is …”.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Input Interpretation enhances an agent’s comprehension of information received
    from others, ensuring accurate understanding and response.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Resources function as the agents’ memory, embedding highly relevant task-specific
    knowledge, such as ”I/O module design principles” for the I/O Designer. Another
    is the Operator Description Language, specially devised for the Circuit Engineer
    and Inspector (Appendix [A.4](#A1.SS4 "A.4\. Circuit Engineer ‣ Appendix A Instructions
    ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces"), sec:Inspector). This language
    efficiently and succinctly conveys the assembly of FCI’s basic computational units
    to the agent, and by digitizing analog operators such as filters and timers, it
    also lightens the load for agents during the circuit design process. Meanwhile,
    information not immediately necessary is cataloged in the Library, not here. It
    is accessible to agents only when the need arises. This organization prevents
    Instructions from becoming unwieldy and distracting.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools convey to the agent the suite of functions it can utilize, presented more
    as an accessible list than detailed within the Instructions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Workflow provides a structured approach for task execution, guiding agents through
    complex activities. For instance, we offer a reference dialogue logic for the
    Consultant to ensure a comprehensive collection of design details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attention section draws the agent’s focus to critical aspects that warrant extra
    scrutiny. For instance, the I/O Designer is reminded to utilize corresponding
    functions for calculating dimensions of the heat-sealing pattern when certain
    specific shapes are specified for the output module.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output Requirement delineates the anticipated format, categories, and constraints
    for the agent’s outputs. Setting these standards facilitates smoother communication
    among agents.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'II. Library (Appendix [B](#A2 "Appendix B Library ‣ Enabling Generative Design
    Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation
    Interfaces")). In our context, the Library houses systemic knowledge regarding
    the design space of FCI. The content is distilled and abstracted from academic
    papers (Lu et al., [2023b](#bib.bib38)), preserving core information essential
    for agents to comprehend FCI. It is meticulously organized and supplemented with
    tags to streamline retrieval. The content of the library mainly focuses on the
    basic concept and framework of FCI, in addition to detailed explanations of the
    input module, output module, and computation module. Additionally, several s of
    regarding each module are included.'
  prefs: []
  type: TYPE_NORMAL
- en: 'III. Tools (Appendix [C](#A3 "Appendix C Tools ‣ Enabling Generative Design
    Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation
    Interfaces")) predominantly consist of functions helping the agent to execute
    certain tasks. For the Consultant, upon completing a module design, it can utilize
    functions to save basic information to local JSON files and seamlessly transition
    into the next phase of the design process. Another group of tools is the inverse
    design functions for the output module when sphere, cylinder, box, fold, or bend
    shape is chosen (Teng et al., [2018](#bib.bib60); Yang et al., [2024](#bib.bib72))
    (Appendix [C.2](#A3.SS2 "C.2\. I/O Designer ‣ Appendix C Tools ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces")). The I/O Designer will invoke the corresponding function
    as needed.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3\. Facilitating Agents Collaboration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To facilitate collaboration among agents, we implement standardized information
    formats for communication and ensure the agents receive necessary information
    only.
  prefs: []
  type: TYPE_NORMAL
- en: 'I. Standardized Information Formats. The use of well-defined structured information,
    like Standardized Operating Procedures (SOPs) (Gourevitch and Morris, [2008](#bib.bib21)),
    has been shown to significantly enhance the consistent and accurate completion
    of tasks (Qian et al., [2023](#bib.bib53); Hong et al., [2023](#bib.bib23)). Similarly,
    we mandate that each agent output information in a defined format as a JSON file,
    with the goal of enhancing cooperation and enabling more efficient information
    extraction. For example, the output from the Circuit Engineer should resemble
    {’circuit’: ’Filter(input, 3; output)’, ’description’: ’The Filter operator is
    used to …’}. This standardization allows for the circuit’s details to be extracted
    from the JSON for visualization within Unity and for evaluation by the Inspector.'
  prefs: []
  type: TYPE_NORMAL
- en: II. Receive Necessary Information Only To avoid information overload and enhance
    the operational efficiency of our agents, we ensure that they are provided only
    with the information critical to their specific roles. Excessive, irrelevant information
    can dilute an agent’s focus, resulting in outputs that stray from the established
    standards. This drop in performance is partly due to the reliance of LLM on the
    Transformer architecture, which is based on attention mechanisms (Vaswani et al.,
    [2017](#bib.bib63)). For instance, our observations indicated that the proficiency
    of the Circuit Engineer in designing efficient circuits diminished as it was exposed
    to more non-essential information.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3\. Circuit Visualization and Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We implemented the core algorithm for circuit construction using C# in Unity.
    It is mainly divided into three parts: FCI operator construction, layout wiring,
    and simulation.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1\. FCI Operator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We crafted models for operators in Blender and defined their data structures
    upon importing them into Unity (Fig. [11](#S6.F11 "Figure 11 ‣ 6.3.1\. FCI Operator
    ‣ 6.3\. Circuit Visualization and Simulation ‣ 6\. Implementation ‣ Enabling Generative
    Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic
    Computation Interfaces")). Each type of logic operator has an associated template,
    which includes the operator’s cell positions, port positions, number of inputs,
    and a simulation function. The process of parsing the circuit begins with the
    final JSON format generated during the design stage, detailing all the logic operators
    in the circuit and their connections. The parsing function converts this description
    into an internal network structure, creating an instance of the circuit network.
    This process involves assigning a unique node to each logic operator, recording
    the connections (inputs and outputs) of each operator within the network, and
    generating network ports corresponding to each logic operator.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c1368850ae451997916af7c0f5b49bb9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11\. The model of the FCI Operator and its corresponding input/output
    ports.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2\. Layout Wiring
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We employed a simulated annealing algorithm to optimize the physical layout,
    aiming to minimize the occupied area of the circuit and reduce the crossing of
    wires. Starting from a random initial layout, the system progressively explores
    the layout space by randomly changing the positions and rotation angles of the
    logic operators. After each change, a target function assesses the quality of
    the layout, considering the overlap of logic operators, the length of connecting
    wires, and the total area occupied by the circuit. Ultimately, a compact and optimized
    circuit design scheme is found.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3\. Simulation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Initially, we use the user’s click events on the input model(s) as a starting
    state for the simulation process. The system navigates through each logic operator
    within the circuit network, computing the output for each operator based on its
    typology through the utilization of predefined logical functions. A dictionary
    structure is employed to efficiently archive and retrieve the signal states of
    logic operators along with their ports, facilitating the system’s rapid response
    and update to the circuit logic. Furthermore, a list is systematically curated
    to sequentially archive the components within the circuit and the pathways of
    signal propagation, enabling signal processing according to the circuit’s design
    sequence. Given the asynchronous nature of signal propagation, a specialized queue
    was devised to ensure the accurate sequence of signal transmission across logic
    operators, thereby mirroring the dynamic signal alterations observed in actual
    circuits. The output model(s) will display a qualitative animation when activated.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Reflection & Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we concentrate on reflecting on the advantages and limitations
    of LLM agents we found within the context of enhancing design tools for innovative
    devices. Furthermore, by using several novel device technology projects as examples,
    we discuss the potential of applying LLM to their design tools.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1\. Breadth of Knowledge and Divergent Thinking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLM agents bring a vast expanse of knowledge and a unique capacity for generating
    a diverse array of ideas, complementing human creativity in the design ideation
    phase. This approach is particularly advantageous when generating innovative solutions
    across various scenarios, as LLM agents can rapidly access and synthesize information
    across a wide range of topics, thus expanding perspectives and catalyzing creative
    thought.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, in the DG detailing phase, the synergy between human intuition
    and LLM’s data-driven suggestions can lead to fascinating outcomes. For example,
    beyond proposing specific scents for olfactory feedback in FCIs, the LLM agent
    can delve into its extensive database to suggest essential oil recipes, enriching
    the design process with detailed and informed choices.
  prefs: []
  type: TYPE_NORMAL
- en: However, this extensive knowledge base and capacity for idea generation can
    become a drawback if not appropriately managed. It is crucial to clearly communicate
    the new technology’s design space and capabilities to the LLM agent. Setting constraints
    is also beneficial; for instance, although FCIs may be compatible with electronic
    sensors or actuators, the focus is encouraged to be on exploring non-electronic
    designs. Explicitly informing the agent that FCI is a non-electronic system can
    greatly reduce the likelihood of it suggesting unsuitable electronic components.
    This approach ensures that the LLM agent’s contributions are aligned with the
    project’s goals and adhere to the specified technological framework.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2\. Specialized Knowledge and Areas of Limited Proficiency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Designing novel devices often involves specialized technical tasks. If corresponding
    knowledge is well-represented in the LLM’s training data, the agent typically
    performs competently, as seen in tasks like programming (Hong et al., [2023](#bib.bib23))
    and electronic circuit design (Blocklove et al., [2023](#bib.bib10)). If not,
    the extent to which a LLM agent can handle a specific task would highly depend
    on how efficiently we can explain the new knowledge to it, and if the agent can
    leverage its existing ability in the task. For instance, the “circuitry” in FCIs
    represents a novel approach to mechanical computation, yet it shares analogies
    with electronic circuits—a domain that has been covered in LLM training. Therefore,
    after explaining the logic operators used in FCI to the agent, it can combine
    its extensive knowledge of electronic circuitry to finish designing the computation
    module of FCIs.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the design intricacies of I/O modules within FCIs illuminate
    a challenging domain for LLM agents, primarily due to the specialized knowledge
    required for understanding soft actuators’ complex behaviors and structures could
    require knowledge about the intricate structures and functionalities of soft actuators,
    areas with which the LLM can be less acquainted. At present, the tuned agent in
    our GDT can provide mainly qualitative guidance in these aspects. Although capable
    of suggesting quantitative dimensions for a few relatively simple shapes that
    we have explained to it, its ability to tackle tasks that demand a deep understanding
    of spatial geometry remains constrained. This limitation is true both in introducing
    new geometric concepts to the agent and in expecting it to design complex geometric
    shapes or mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Efforts to overcome spatial comprehension challenges are crucial, especially
    since numerous novel device technologies, particularly those involving innovative
    output actuators, depend heavily on understanding complex spatial and mechanical
    concepts. To enhance an LLM agent’s capabilities in spatial reasoning and mechanical
    design, one strategy could involve enriching its training data with s that encompass
    spatially complex and mechanically detailed scenarios. However, it’s also important
    to acknowledge that certain domains, such as three-dimensional modeling and design,
    may inherently lie outside the optimal skill set of LLM due to their primarily
    text-based knowledge and reasoning capabilities. In such cases, it might be more
    effective to leverage other types of generative AI that are specifically tailored
    for 3D conceptualization and design. These specialized AI systems can complement
    LLM agents by providing expertise in areas where LLM faces limitations, ensuring
    a more holistic approach to the design and development of novel devices. Recognizing
    and integrating the strengths of different AI modalities can potentially further
    enhance the GDT.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3\. Contextual Awareness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Throughout the design task, we noted the agent exhibited great contextual awareness
    and cognitive capabilities. This keen awareness facilitates a better understanding
    of the nuances involved in design tasks, enabling the agent to contribute more
    effectively. We’ve identified three tiers of contextual awareness displayed by
    the agents within the FCI GDT, each contributing uniquely to the design process:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Understanding the Design Space: The agent possesses a good awareness of the
    FIC’s design space if properly tuned. This enables it to not only grasp the broader
    technological landscape but also to identify and propose relevant and appropriate
    DGs.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reasonably Detailing Post-DG Establishment: After a DG is established, the
    agent can suggest sensible design details and correct errors based on the context.
    For instance, it can suggest representative yoga poses and propose corresponding
    input detection methods; it also recommends feasible parameters like frequency
    and duration based on the intended detection target or action.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Strategic Technical Implementation: When determining technical implementation,
    the agent can suggest practical qualitative and even quantitative solutions based
    on the DG and design details. s include advising on the shape and processing material
    requirements for input airbags, or suggesting dimensions for shape-changing output
    airbags tailored to the usage scenario.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We believe the contextual awareness of LLM agents could positively impact the
    process of designing novel devices. Our hypothesis suggests that such awareness
    not only makes the ideation and development phases more efficient but also fosters
    the creation of solutions that blend innovation with practicality, thereby enhancing
    the collaborative design performance between AI and human users. This vision emphasizes
    the necessity for extensive empirical studies in human-AI co-design tasks using
    our tool to substantiate these potential outcomes. Accordingly, we posit that
    the agent’s contextual awareness could emerge as a crucial factor in navigating
    the complexities of novel device design. Should LLM agents demonstrate the capacity
    to understand, detail, and implement design strategies with precision, they could
    become invaluable resources in the evolving landscape of novel device creation.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4\. Configuring and Debugging Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the implementation of the FCI-GDT, configuring and debugging the agent emerges
    as a core aspect. Throughout this process, the careful crafting of the Library
    and clear Instruction is particularly crucial. Theoretically, the configuration
    process is straightforward, making it relatively simple for those without an extensive
    programming or development background. Both the library and instructions are mainly
    written in natural language and can be constructed using our organizational structure
    as a template (section [6.2.2](#S6.SS2.SSS2 "6.2.2\. Qualifying Agents for Tasks
    ‣ 6.2\. Configure LLM Agents ‣ 6\. Implementation ‣ Enabling Generative Design
    Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation
    Interfaces")). However, practical implementation is not without challenges. Creating
    the library tests developers’ abilities to distill key technological information,
    while writing instructions examines their skills in conveying information to the
    agent efficiently and succinctly. Moreover, natural language is not always the
    most efficient means of conveying a lot of information, differing greatly from
    the highly abstract, structured, and standardized norms of coding.'
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the library and instructions guide the agent more as a form of
    soft constraint, with the agent acting based on its own ”understanding and thinking.”
    For instance, for the Consultant agent, we defined a dialogue inquiry flow, but
    it doesn’t necessarily strictly follow this process and can switch freely between
    different sections. Developers should acknowledge this dynamic, steering away
    from the inclination to compel the agent into specific actions. Instead, they
    ought to embrace and leverage the agent’s autonomy, trying to trust the agent’s
    abilities and granting it a certain freedom in completing tasks. For example,
    it could be made clear to the agent that it can independently judge the collection
    of design details and guide users through completing various sections.
  prefs: []
  type: TYPE_NORMAL
- en: The process of debugging agents also greatly differs from software debugging.
    In the process of debugging an agent, pinpointing problems is often vague, unlike
    software debugging where specific lines of code with issues is possible to be
    identified. Developers need to continuously practice to identify the agents’ erroneous
    behaviors and gradually adjust and improve the library and instructions. For instance,
    if the agent consistently overlooks certain functions of the device, additional
    relevant knowledge might need to be supplemented; if an agent’s designs exceed
    the device’s capabilities, new restrictions could be added; if an agent misuses
    a certain design space elements due to misunderstanding, it’s necessary to check
    if the expressions caused confusion, etc.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the process of configuring and debugging the agent is essentially
    iterative and optimization-focused, akin to writing and revising a manual. Through
    precise knowledge libraries and clear operational instructions, as well as meticulous
    debugging of agent behavior, the performance and applicability of the GDT can
    be enhanced.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5\. Enhancing Other Novel Device Designs with LLM Agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We propose that a similar strategy employed in the development of the FCI-GDT,
    particularly in terms of task decomposition and agent allocation, could be potentially
    applied to other research work involving novel devices. To illustrate, we analyze
    potential approaches for integrating LLM agents into the design tools for several
    projects as examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Digital Mechanical Metamaterials (DMM) (Ion et al., [2017b](#bib.bib26)) are
    devices created through 3D printing that incorporate mechanical computation. For
    ideation and detailing phases, a similar Consultant agent could be utilized. However,
    the design space of this technology has not been systematically summarized in
    the paper, necessitating its distillation and summarization to clearly explain
    this technology’s capabilities to the Consultant agent. This includes its fundamental
    concepts, core framework, input detection and output capabilities, and limitations.
    For technical implementation, the device could potentially be divided into two
    main parts: the mechanical circuitry and the metamaterials (Ion et al., [2017a](#bib.bib25)),
    each assigned to different groups of agents. The design process for mechanical
    circuitry could leverage the agents’ expertise in electronic circuit design, akin
    to what is seen in FCI-GDT. However, it’s important to note the key differences
    between DMM circuitry and that of FCI. DMM circuits operate on non-volatile, binary
    computing principles, utilizing bistable configurations that do not rely on a
    constant “power supply”. Instead, they require recharging to recover lost energy
    after use. These critical differences need to be clearly communicated to the agents.
    Additionally, it’s crucial to effectively draw analogies between the mechanical
    operators in DMM systems and the electronic operators in traditional circuits.
    This approach will facilitate corresponding agents in leveraging their existing
    circuit design expertise for mechanical circuitry tasks. Synthesizing and visualizing
    the structure, as well as generating fabricable files for the circuit, could still
    depend on ”traditional” design tools as outlined in the DMM paper. The metamaterial
    part could be delegated to another agent or group of agents. Such structures might
    be unfamiliar to LLM agents, making it unlikely for them to provide precise quantitative
    suggestions. However, agents could potentially offer reference suggestions, like
    advising on approximate overall dimensions for the device’s placement or ergonomic
    shapes and thickness for specific parts, like handles.'
  prefs: []
  type: TYPE_NORMAL
- en: LineForm (Nakagaki et al., [2015](#bib.bib45)) represents an actuated curve
    interface reminiscent of serpentine robotics. Its design space is thoroughly outlined
    in the associated paper, which could aid a Consultant agent in grasping the underlying
    technology. The technical implementation primarily emphasizes the programming
    aspects of the devices, tasks that could potentially be delegated to one group
    of agents. To effectively program, an agent must first quantitatively describe
    the target shape which the Consultant agent might have decided to adopt for specific
    design scenarios. This may involve identifying a set of geometric parameters that
    can comprehensively define the shapes and explaining these parameters to the agent—along
    with how altering these parameters influences the shape. The next step could involve
    assisting another agent in understanding how adjusting each servo’s parameters
    affects curve control, thereby enabling the agent to program the servos to achieve
    the desired shape described by the previous agent. If it’s discovered that the
    final step of achieving and realizing the desired shape can be more efficiently
    managed using an inverse design algorithm, then a strategic shift could be advantageous.
    In this case, the agent’s role would mainly be leveraging its contextual awareness
    and decision-making capabilities to determine the shape parameters based on the
    design scenario. These parameters would then be inputted into the inverse design
    algorithm, which is adept at calculating the precise adjustments needed to program
    the device accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: FoamSense (Nakamaru et al., [2017](#bib.bib46)) introduces a novel soft sensor
    capable of measuring the deformation states of volumetric soft objects, including
    compression, bending, twisting, and shearing. The paper meticulously outlines
    the design process and elements, providing a solid foundation for tuning a Consultant
    agent to conceptualize and detail the designs. Given the technology’s emphasis
    on sensor development, two clusters of agents could potentially undertake this
    task. The first cluster of agents, guided by the Consultant agent’s assembly of
    requirements—such as the type of manipulation and the specific surface/object
    integration—would be tasked with estimating the force range, determining the sensor’s
    optimal shape, selecting suitable materials, and more. The experimental results
    discussed in the paper could empower the agent to offer quantitative insights
    regarding these parameters. The second cluster of agents would concentrate on
    developing the Arduino code and peripheral support circuits. This area falls within
    the ”comfort zone” of LLM agents and is theoretically capable of yielding executable
    outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 7.6\. Limitations and Future Work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Quality control & improvement. While LLMs excel in creative tasks, it’s important
    to note that creativity often benefits from collaboration between AI and humans.
    LLMs can generate ideas, suggest possibilities, and provide inspiration, but human
    judgment, expertise, and subjective taste play crucial roles in refining and realizing
    creative visions. Besides, LLMs are prone to hallucinations, although we have
    made efforts to minimize them using multiple agents and confirming with users
    at each step. Additionally, incorporating feedback from experts and lessons from
    positive or negative examples in practices could be crucial in refining GPT training.
    This feedback would be instrumental in enhancing the quality of generated content.
  prefs: []
  type: TYPE_NORMAL
- en: Multimodality. The current version of the tool only supports users in conveying
    their ideas through textual descriptions, and the generated innovative concept
    designs are limited to FCI modeling and textual descriptions. It currently lacks
    support for translating these ideas into sketches, images, models, or videos with
    real-life scenarios, such as demonstrating the effect of using the Computation
    Kit on a yoga mat. Future work could explore and integrate advanced technologies
    and theories, such as leveraging other types of generative AI models. These improvements
    have the potential to assist users not only in designing and developing the Fluid
    Computation device but also in testing, refining, and realizing these concepts
    in more practical and applicable formats.
  prefs: []
  type: TYPE_NORMAL
- en: User study & Human-AI co-design interaction. Currently, testing of this tool
    primarily concentrates on objectively evaluating GPT’s performance in designing
    FCI with minimal human intervention. Future plans include expanding the research
    to encompass a more diverse user base with varying levels of expertise, to assess
    how increased human involvement and collaborative design affect performance. This
    expansion may include role-switching activities between questioning and answering
    to encourage a more interactive and iterative design methodology, ultimately aiming
    to understand how these advancements enhance the user experience in design tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This study points towards the growing need for improved design tools in the
    development of interactive devices, suggesting the use of LLM agents as a practical
    enhancement. Through examining fluidic computation devices, we’ve seen how LLM
    agents in a GDT can help navigate design challenges, providing useful, context-aware
    design insights. We’ve outlined the GDT’s structure, its practical application,
    and its performance, shedding light on both its advantages and the hurdles it
    faces. This exploration indicates a potential path for refining design tools,
    combining traditional methods with LLM capabilities for a more effective approach
    to device prototyping.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: aut (2023) 2023. AutoGPT. [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: bab (2023) 2023. BabyAGI. [https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. 2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*
    (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adleman (1994) Leonard M Adleman. 1994. Molecular computation of solutions to
    combinatorial problems. *science* 266, 5187 (1994), 1021–1024.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An et al. (2018) Byoungkwon An, Ye Tao, Jianzhe Gu, Tingyu Cheng, Xiang ’Anthony’
    Chen, Xiaoxiao Zhang, Wei Zhao, Youngwook Do, Shigeo Takahashi, Hsiang-Yun Wu,
    Teng Zhang, and Lining Yao. 2018. Thermorph: Democratizing 4D Printing of Self-Folding
    Materials and Interfaces *(CHI ’18)*. Association for Computing Machinery, New
    York, NY, USA, 1–12. [https://doi.org/10.1145/3173574.3173834](https://doi.org/10.1145/3173574.3173834)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andreas (2022) Jacob Andreas. 2022. Language models as agent models. *arXiv
    preprint arXiv:2212.01681* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Angert et al. (2023) Tyler Angert, Miroslav Suzara, Jenny Han, Christopher
    Pondoc, and Hariharan Subramonyam. 2023. Spellburst: A Node-based Interface for
    Exploratory Creative Coding with Natural Language Prompts. In *Proceedings of
    the 36th Annual ACM Symposium on User Interface Software and Technology*. 1–22.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhavya et al. (2023) Bhavya Bhavya, Jinjun Xiong, and Chengxiang Zhai. 2023.
    CAM: A Large Language Model-based Creative Analogy Mining Framework *(WWW ’23)*.
    Association for Computing Machinery, New York, NY, USA, 12 pages. [https://doi.org/10.1145/3543507.3587431](https://doi.org/10.1145/3543507.3587431)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Blocklove et al. (2023) Jason Blocklove, Siddharth Garg, Ramesh Karri, and
    Hammond Pearce. 2023. Chip-chat: Challenges and opportunities in conversational
    hardware design. In *2023 ACM/IEEE 5th Workshop on Machine Learning for CAD (MLCAD)*.
    IEEE, 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. Chateval: Towards better llm-based
    evaluators through multi-agent debate. *arXiv preprint arXiv:2308.07201* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023a) Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay,
    Börje F Karlsson, Jie Fu, and Yemin Shi. 2023a. Autoagents: A framework for automatic
    agent generation. *arXiv preprint arXiv:2309.17288* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2023b) Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei
    Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, et al. 2023b.
    Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors.
    In *The Twelfth International Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cheng et al. (2023) Yu Cheng, Jieshan Chen, Qing Huang, Zhenchang Xing, Xiwei
    Xu, and Qinghua Lu. 2023. Prompt Sapper: A LLM-Empowered Production Tool for Building
    AI Chains. (dec 2023). [https://doi.org/10.1145/3638247](https://doi.org/10.1145/3638247)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dang et al. (2023) Hai Dang, Sven Goller, Florian Lehmann, and Daniel Buschek.
    2023. Choice over control: How users write with large language models using diegetic
    and non-diegetic prompting. In *Proceedings of the 2023 CHI Conference on Human
    Factors in Computing Systems*. 1–17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2022) Jialin Deng, Patrick Olivier, Josh Andres, Kirsten Ellis,
    Ryan Wee, and Florian Floyd Mueller. 2022. Logic Bonbon: Exploring Food as Computational
    Artifact. In *CHI Conference on Human Factors in Computing Systems* (New Orleans,
    LA, USA) *(CHI ’22)*. Association for Computing Machinery, New York, NY, USA,
    1–21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dessouky et al. (2019) Ghada Dessouky, David Gens, Patrick Haney, Garrett Persyn,
    Arun Kanuparthi, Hareesh Khattri, Jason M Fung, Ahmad-Reza Sadeghi, and Jeyavijayan
    Rajendran. 2019. $\{$ Hardware Bugs. In *28th USENIX Security Symposium (USENIX
    Security 19)*. 213–230.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Drew et al. (2016) Daniel Drew, Julie L. Newcomb, William McGrath, Filip Maksimovic,
    David Mellis, and Björn Hartmann. 2016. The Toastboard: Ubiquitous Instrumentation
    and Automated Checking of Breadboarded Circuits *(UIST ’16)*. Association for
    Computing Machinery, New York, NY, USA, 677–686. [https://doi.org/10.1145/2984511.2984566](https://doi.org/10.1145/2984511.2984566)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duan et al. (2023) Peitong Duan, Jeremy Warner, and Bjoern Hartmann. 2023. Towards
    Generating UI Design Feedback with LLMs *(UIST ’23 Adjunct)*. Association for
    Computing Machinery, New York, NY, USA, 3 pages. [https://doi.org/10.1145/3586182.3615810](https://doi.org/10.1145/3586182.3615810)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gmeiner et al. (2023) Frederic Gmeiner, Humphrey Yang, Lining Yao, Kenneth Holstein,
    and Nikolas Martelaro. 2023. Exploring challenges and opportunities to support
    designers in learning to co-create with AI-based manufacturing design tools. In
    *Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems*.
    1–20.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gourevitch and Morris (2008) Philip Gourevitch and Errol Morris. 2008. *Standard
    operating procedure*. Penguin.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hauser et al. (2011) Helmut Hauser, Auke J Ijspeert, Rudolf M Füchslin, Rolf
    Pfeifer, and Wolfgang Maass. 2011. Towards a theoretical foundation for morphological
    computation with compliant bodies. *Biological cybernetics* 105, 5 (2011), 355–370.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al.
    2023. Metagpt: Meta programming for multi-agent collaborative framework. *arXiv
    preprint arXiv:2308.00352* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huh et al. (2023) Mina Huh, Yi-Hao Peng, and Amy Pavel. 2023. GenAssist: Making
    Image Generation Accessible. In *Proceedings of the 36th Annual ACM Symposium
    on User Interface Software and Technology*. 1–17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ion et al. (2017a) Alexandra Ion, Ludwig Wall, Robert Kovacs, and Patrick Baudisch.
    2017a. Digital mechanical metamaterials. In *Proceedings of the 2017 CHI Conference
    on Human Factors in Computing Systems* (Denver, Colorado, USA) *(CHI ’17)*. Association
    for Computing Machinery, New York, NY, USA, 977–988.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ion et al. (2017b) Alexandra Ion, Ludwig Wall, Robert Kovacs, and Patrick Baudisch.
    2017b. Digital Mechanical Metamaterials. In *Proceedings of the 2017 CHI Conference
    on Human Factors in Computing Systems* (Denver, Colorado, USA) *(CHI ’17)*. Association
    for Computing Machinery, New York, NY, USA, 977–988. [https://doi.org/10.1145/3025453.3025624](https://doi.org/10.1145/3025453.3025624)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jain and Kukkal (2020) Rajeev Jain and Pankaj Kukkal. 2020. Data-driven CAD
    or Algorithm-Driven CAD: Competitors or Collaborators? *(MLCAD ’20)*. Association
    for Computing Machinery, New York, NY, USA, 69. [https://doi.org/10.1145/3380446.3430686](https://doi.org/10.1145/3380446.3430686)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jennings et al. (1998) Nicholas R Jennings, Katia Sycara, and Michael Wooldridge.
    1998. A roadmap of agent research and development. *Autonomous agents and multi-agent
    systems* 1 (1998), 7–38.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2023) Peiling Jiang, Jude Rayan, Steven P Dow, and Haijun Xia.
    2023. Graphologue: Exploring large language model responses with interactive diagrams.
    In *Proceedings of the 36th Annual ACM Symposium on User Interface Software and
    Technology*. 1–20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jo et al. (2023) Eunkyung Jo, Daniel A Epstein, Hyunhoon Jung, and Young-Ho
    Kim. 2023. Understanding the benefits and challenges of deploying conversational
    AI leveraging large language models for public health intervention. In *Proceedings
    of the 2023 CHI Conference on Human Factors in Computing Systems*. 1–16.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ko et al. (2023) Hyung-Kwon Ko, Gwanmo Park, Hyeon Jeon, Jaemin Jo, Juho Kim,
    and Jinwook Seo. 2023. Large-scale Text-to-Image Generation Models for Visual
    Artists’ Creative Works *(IUI ’23)*. Association for Computing Machinery, New
    York, NY, USA, 15 pages. [https://doi.org/10.1145/3581641.3584078](https://doi.org/10.1145/3581641.3584078)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2024) Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin,
    and Bernard Ghanem. 2024. Camel: Communicative agents for” mind” exploration of
    large language model society. *Advances in Neural Information Processing Systems*
    36 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li (2024) Weiyi Li. 2024. A Study on Factors Influencing Designers’ Behavioral
    Intention in Using AI-Generated Content for Assisted Design: Perceived Anxiety,
    Perceived Risk, and UTAUT. *International Journal of Human–Computer Interaction*
    (2024), 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023) Yuan Li, Yixuan Zhang, and Lichao Sun. 2023. Metaagents: Simulating
    interactions of human behaviors for llm-based task-oriented coordination via collaborative
    generative agents. *arXiv preprint arXiv:2310.06500* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. (2023) Weixin Liang, Yuhui Zhang, Hancheng Cao, Binglu Wang, Daisy
    Ding, Xinyu Yang, Kailas Vodrahalli, Siyu He, Daniel Smith, Yian Yin, et al. 2023.
    Can large language models provide useful feedback on research papers? A large-scale
    empirical analysis. *arXiv preprint arXiv:2310.01783* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023a) Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Benjamin
    Zorn, Jack Williams, Neil Toronto, and Andrew D Gordon. 2023a. “What it wants
    me to say”: Bridging the abstraction gap between end-user programmers and code-generating
    large language models. In *Proceedings of the 2023 CHI Conference on Human Factors
    in Computing Systems*. 1–31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023b) Vivian Liu, Jo Vermeulen, George Fitzmaurice, and Justin
    Matejka. 2023b. 3DALL-E: Integrating text-to-image AI in 3D design workflows.
    In *Proceedings of the 2023 ACM designing interactive systems conference*. 1955–1977.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2023b) Qiuyu Lu, Haiqing Xu, Yijie Guo, Joey Yu Wang, and Lining
    Yao. 2023b. Fluidic Computation Kit: Towards Electronic-free Shape-changing Interfaces.
    In *Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems*
    *(CHI ’23)*. Association for Computing Machinery, New York, NY, USA, 1–21. [https://doi.org/10.1145/3544548.3580783](https://doi.org/10.1145/3544548.3580783)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2023c) Qiuyu Lu, Tianyu Yu, Semina Yi, Yuran Ding, Haipeng Mi, and
    Lining Yao. 2023c. Sustainflatable: Harvesting, Storing and Utilizing Ambient
    Energy for Pneumatic Morphing Interfaces. In *Proceedings of the 36th Annual ACM
    Symposium on User Interface Software and Technology* (¡conf-loc¿, ¡city¿San Francisco¡/city¿,
    ¡state¿CA¡/state¿, ¡country¿USA¡/country¿, ¡/conf-loc¿) *(UIST ’23)*. Association
    for Computing Machinery, New York, NY, USA, Article 32, 20 pages. [https://doi.org/10.1145/3586183.3606721](https://doi.org/10.1145/3586183.3606721)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2023a) Xinyi Lu, Simin Fan, Jessica Houghton, Lu Wang, and Xu Wang.
    2023a. Readingquizmaker: A human-nlp collaborative system that supports instructors
    to design high-quality reading quiz questions. In *Proceedings of the 2023 CHI
    Conference on Human Factors in Computing Systems*. 1–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Makatura et al. (2023) Liane Makatura, Michael Foshey, Bohan Wang, Felix HähnLein,
    Pingchuan Ma, Bolei Deng, Megan Tjandrasuwita, Andrew Spielberg, Crystal Elaine
    Owens, Peter Yichen Chen, et al. 2023. How Can Large Language Models Help Humans
    in Design and Manufacturing? *arXiv preprint arXiv:2307.14377* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miller (2019) Tim Miller. 2019. Explanation in artificial intelligence: Insights
    from the social sciences. *Artificial intelligence* 267 (2019), 1–38.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mor et al. (2020) Hila Mor, Tianyu Yu, Ken Nakagaki, Benjamin Harvey Miller,
    Yichen Jia, and Hiroshi Ishii. 2020. Venous Materials: Towards Interactive Fluidic
    Mechanisms. In *Proceedings of the 2020 CHI Conference on Human Factors in Computing
    Systems* (Honolulu, HI, USA) *(CHI ’20)*. Association for Computing Machinery,
    New York, NY, USA, 1–14. [https://doi.org/10.1145/3313831.3376129](https://doi.org/10.1145/3313831.3376129)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mosadegh et al. (2011) Bobak Mosadegh, Tommaso Bersano-Begey, Joong Yull Park,
    Mark A Burns, and Shuichi Takayama. 2011. Next-generation integrated microfluidic
    circuits. *Lab on a Chip* 11, 17 (2011), 2813–2818.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nakagaki et al. (2015) Ken Nakagaki, Sean Follmer, and Hiroshi Ishii. 2015.
    LineFORM: Actuated Curve Interfaces for Display, Interaction, and Constraint.
    In *Proceedings of the 28th Annual ACM Symposium on User Interface Software &
    Technology* (Charlotte, NC, USA) *(UIST ’15)*. Association for Computing Machinery,
    New York, NY, USA, 333–339. [https://doi.org/10.1145/2807442.2807452](https://doi.org/10.1145/2807442.2807452)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nakamaru et al. (2017) Satoshi Nakamaru, Ryosuke Nakayama, Ryuma Niiyama, and
    Yasuaki Kakehi. 2017. FoamSense: Design of Three Dimensional Soft Sensors with
    Porous Materials. In *Proceedings of the 30th Annual ACM Symposium on User Interface
    Software and Technology* (Québec City, QC, Canada) *(UIST ’17)*. Association for
    Computing Machinery, New York, NY, USA, 437–447. [https://doi.org/10.1145/3126594.3126666](https://doi.org/10.1145/3126594.3126666)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Olberding et al. (2014) Simon Olberding, Michael Wessely, and Jürgen Steimle.
    2014. PrintScreen: fabricating highly customizable thin-film touch-displays. In
    *Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology*
    (Honolulu, Hawaii, USA) *(UIST ’14)*. Association for Computing Machinery, New
    York, NY, USA, 281–290. [https://doi.org/10.1145/2642918.2647413](https://doi.org/10.1145/2642918.2647413)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ou et al. (2016) Jifei Ou, Mélina Skouras, Nikolaos Vlavianos, Felix Heibeck,
    Chin-Yi Cheng, Jannik Peters, and Hiroshi Ishii. 2016. aeroMorph - Heat-sealing
    Inflatable Shape-change Materials for Interaction Design. In *Proceedings of the
    29th Annual Symposium on User Interface Software and Technology* *(UIST ’16)*.
    Association for Computing Machinery, New York, NY, USA, 121–132. [https://doi.org/10.1145/2984511.2984520](https://doi.org/10.1145/2984511.2984520)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive
    simulacra of human behavior. In *Proceedings of the 36th Annual ACM Symposium
    on User Interface Software and Technology*. 1–22.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2018) Huaishu Peng, Jimmy Briggs, Cheng-Yao Wang, Kevin Guo, Joseph
    Kider, Stefanie Mueller, Patrick Baudisch, and François Guimbretière. 2018. RoMA:
    Interactive Fabrication with Augmented Reality and a Robotic 3D Printer *(CHI
    ’18)*. Association for Computing Machinery, New York, NY, USA, 1–12. [https://doi.org/10.1145/3173574.3174153](https://doi.org/10.1145/3173574.3174153)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2023) Zhenhui Peng, Xingbo Wang, Qiushi Han, Junkai Zhu, Xiaojuan
    Ma, and Huamin Qu. 2023. Storyfier: Exploring Vocabulary Learning Support with
    Text Generation Models. In *Proceedings of the 36th Annual ACM Symposium on User
    Interface Software and Technology*. 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Petridis et al. (2023) Savvas Petridis, Nicholas Diakopoulos, Kevin Crowston,
    Mark Hansen, Keren Henderson, Stan Jastrzebski, Jeffrey V Nickerson, and Lydia B
    Chilton. 2023. Anglekindling: Supporting journalistic angle ideation with large
    language models. In *Proceedings of the 2023 CHI Conference on Human Factors in
    Computing Systems*. 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qian et al. (2023) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rajappan et al. (2021) Anoop Rajappan, Barclay Jumet, and Daniel J Preston.
    2021. Pneumatic soft robots take a step toward autonomy. *Science Robotics* 6,
    51 (2021), eabg6994.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rhee and Burns (2009) Minsoung Rhee and Mark A Burns. 2009. Microfluidic pneumatic
    logic circuits and digital pneumatic microprocessors for integrated microfluidic
    systems. *Lab on a Chip* 9, 21 (2009), 3131–3143.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Savage et al. (2022) Valkyrie Savage, Carlos Tejada, Mengyu Zhong, Raf Ramakers,
    Daniel Ashbrook, and Hyunyoung Kim. 2022. AirLogic: Embedding Pneumatic Computation
    and I/O in 3D Models to Fabricate Electronics-Free Interactive Objects. In *Proceedings
    of the 35th Annual ACM Symposium on User Interface Software and Technology* (Bend,
    OR, USA) *(UIST ’22)*. Association for Computing Machinery, New York, NY, USA,
    Article 9, 12 pages. [https://doi.org/10.1145/3526113.3545642](https://doi.org/10.1145/3526113.3545642)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suh et al. (2023) Sangho Suh, Bryan Min, Srishti Palani, and Haijun Xia. 2023.
    Sensecape: Enabling multilevel exploration and sensemaking with large language
    models. In *Proceedings of the 36th Annual ACM Symposium on User Interface Software
    and Technology*. 1–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2022) Lingyun Sun, Jiaji Li, Junzhe Ji, Deying Pan, Mingming Li,
    Kuangqi Zhu, Yitao Fan, Yue Yang, Ye Tao, and Guanyun Wang. 2022. X-Bridges: Designing
    Tunable Bridges to Enrich 3D Printed Objects’ Deformation and Stiffness *(UIST
    ’22)*. Association for Computing Machinery, New York, NY, USA, 12 pages. [https://doi.org/10.1145/3526113.3545710](https://doi.org/10.1145/3526113.3545710)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tao et al. (2023) Ye Tao, Shuhong Wang, Junzhe Ji, Linlin Cai, Hongmei Xia,
    Zhiqi Wang, Jinghai He, Yitao Fan, Shengzhang Pan, Jinghua Xu, Cheng Yang, Lingyun
    Sun, and Guanyun Wang. 2023. 4Doodle: 4D Printing Artifacts Without 3D Printers
    *(CHI ’23)*. Association for Computing Machinery, New York, NY, USA, Article 731,
    16 pages. [https://doi.org/10.1145/3544548.3581321](https://doi.org/10.1145/3544548.3581321)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Teng et al. (2018) Shan-Yuan Teng, Tzu-Sheng Kuo, Chi Wang, Chi-huan Chiang,
    Da-Yuan Huang, Liwei Chan, and Bing-Yu Chen. 2018. PuPoP: Pop-up Prop on Palm
    for Virtual Reality. In *Proceedings of the 31st Annual ACM Symposium on User
    Interface Software and Technology* *(UIST ’18)*. Association for Computing Machinery,
    New York, NY, USA, 5–17. [https://doi.org/10.1145/3242587.3242628](https://doi.org/10.1145/3242587.3242628)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tseng et al. (2024) Tiffany Tseng, Ruijia Cheng, and Jeffrey Nichols. 2024.
    Keyframer: Empowering Animation Design using Large Language Models. *arXiv preprint
    arXiv:2402.06071* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Valencia et al. (2023) Stephanie Valencia, Richard Cave, Krystal Kallarackal,
    Katie Seaver, Michael Terry, and Shaun K Kane. 2023. “The less I type, the better”:
    How AI Language Models can Enhance or Impede Communication for AAC Users. In *Proceedings
    of the 2023 CHI Conference on Human Factors in Computing Systems*. 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is all you need. *Advances in neural information processing systems* 30 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vere and Bickmore (1990) Steven Vere and Timothy Bickmore. 1990. A basic agent.
    *Computational intelligence* 6, 1 (1990), 41–60.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Villar et al. (2018) Nicolas Villar, Daniel Cletheroe, Greg Saul, Christian
    Holz, Tim Regan, Oscar Salandin, Misha Sra, Hui-Shyong Yeo, William Field, and
    Haiyan Zhang. 2018. Project Zanzibar: A Portable and Flexible Tangible Interaction
    Platform *(CHI ’18)*. Association for Computing Machinery, New York, NY, USA.
    [https://doi.org/10.1145/3173574.3174089](https://doi.org/10.1145/3173574.3174089)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023a) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023a. A survey
    on large language model based autonomous agents. *arXiv preprint arXiv:2308.11432*
    (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023b) Yunlong Wang, Shuyuan Shen, and Brian Y Lim. 2023b. Reprompt:
    Automatic prompt editing to refine ai-generative art towards precise expressions.
    In *Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems*.
    1–29.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wehner et al. (2016) Michael Wehner, Ryan L Truby, Daniel J Fitzgerald, Bobak
    Mosadegh, George M Whitesides, Jennifer A Lewis, and Robert J Wood. 2016. An integrated
    design and fabrication strategy for entirely soft, autonomous robots. *nature*
    536, 7617 (2016), 451–455.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wessely et al. (2018) Michael Wessely, Theophanis Tsandilas, and Wendy E. Mackay.
    2018. Shape-Aware Material: Interactive Fabrication with ShapeMe *(UIST ’18)*.
    Association for Computing Machinery, New York, NY, USA, 127–139. [https://doi.org/10.1145/3242587.3242619](https://doi.org/10.1145/3242587.3242619)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Willis et al. (2022) Karl DD Willis, Pradeep Kumar Jayaraman, Hang Chu, Yunsheng
    Tian, Yifei Li, Daniele Grandi, Aditya Sanghi, Linh Tran, Joseph G Lambourne,
    Armando Solar-Lezama, et al. 2022. Joinable: Learning bottom-up assembly of parametric
    cad joints. In *Proceedings of the IEEE/CVF Conference on Computer Vision and
    Pattern Recognition*. 15849–15860.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2020) Humphrey Yang, Kuanren Qian, Haolin Liu, Yuxuan Yu, Jianzhe
    Gu, Matthew McGehee, Yongjie Jessica Zhang, and Lining Yao. 2020. SimuLearn: Fast
    and Accurate Simulator to Support Morphing Materials Design and Workflows. In
    *Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology*
    (Virtual Event, USA) *(UIST ’20)*. Association for Computing Machinery, New York,
    NY, USA, 71–84. [https://doi.org/10.1145/3379337.3415867](https://doi.org/10.1145/3379337.3415867)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2024) Yue Yang, Lei Ren, Chuang Chen, Bin Hu, Zhuoyi Zhang, Xinyan
    Li, Yanchen Shen, Kuangqi Zhu, Junzhe Ji, Yuyang Zhang, Yongbo Ni, Jiang Wu, Qi
    Wang, Lingyun Sun, Ye Tao, and Wang Guanyun. 2024. SnapInflatables: Designing
    Inflatables with Snap-through Instability for Responsive Interaction. In *Proceedings
    of the 2024 CHI Conference on Human Factors in Computing Systems* (¡conf-loc¿,
    ¡city¿Honolulu¡/city¿, ¡country¿USA¡/country¿, ¡/conf-loc¿) *(CHI ’24)*. Association
    for Computing Machinery, Honolulu, HI, USA, 1–15. [https://doi.org/10.1145/3613904.3642933](https://doi.org/10.1145/3613904.3642933)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting
    in language models. *arXiv preprint arXiv:2210.03629* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zamfirescu-Pereira et al. (2023) JD Zamfirescu-Pereira, Richmond Y Wong, Bjoern
    Hartmann, and Qian Yang. 2023. Why Johnny can’t prompt: how non-AI experts try
    (and fail) to design LLM prompts. In *Proceedings of the 2023 CHI Conference on
    Human Factors in Computing Systems*. 1–21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2017) Qiongdi Zhang, Ming Zhang, Lyas Djeghlaf, Jeanne Bataille,
    Jean Gamby, Anne-Marie Haghiri-Gosnet, and Antoine Pallandre. 2017. Logic digital
    fluidic in miniaturized functional devices: Perspective to the next generation
    of microfluidic lab-on-chips. *Electrophoresis* 38, 7 (2017), 953–976.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2020) Allan Zhao, Jie Xu, Mina Konaković-Luković, Josephine Hughes,
    Andrew Spielberg, Daniela Rus, and Wojciech Matusik. 2020. Robogrammar: graph
    grammar for terrain-optimized robot design. *ACM Transactions on Graphics (TOG)*
    39, 6 (2020), 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhong et al. (2023) Ke Zhong, Adriane Fernandes Minori, Di Wu, Humphrey Yang,
    Mohammad F. Islam, and Lining Yao. 2023. EpoMemory: Multi-state Shape Memory for
    Programmable Morphing Interfaces *(CHI ’23)*. Association for Computing Machinery,
    New York, NY, USA, Article 744, 15 pages. [https://doi.org/10.1145/3544548.3580638](https://doi.org/10.1145/3544548.3580638)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2023) Jiawei Zhou, Yixuan Zhang, Qianni Luo, Andrea G Parker,
    and Munmun De Choudhury. 2023. Synthetic lies: Understanding ai-generated misinformation
    and evaluating algorithmic and human solutions. In *Proceedings of the 2023 CHI
    Conference on Human Factors in Computing Systems*. 1–20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix
  prefs: []
  type: TYPE_NORMAL
- en: Appendix A Instructions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Instructions are a pre-designed prompt aimed at clearly explaining the objectives
    of a task and specifying the expected method for the agent’s response. We generally
    divide the Instructions into distinct sections, including Role, Input Interpretation,
    Resources, Tool and Output Requirement, utilizing symbols such as ”#” and ”⁢⁢”
    to demarcate these various segments. Details of Information are presented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: A.1\. Consultant
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Role:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You are a Fluidic Computation Interface (FCI) design Consultant who helps design
    such interfaces. You should acquire all mandatory information about the ⁢⁢Design
    Goal⁢⁢, the ⁢⁢Input Module⁢⁢, the **Output Module**, and the **Computation Module**,
    and write them to local JSON files when finished.
  prefs: []
  type: TYPE_NORMAL
- en: 'Attention:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 1\. Try to follow the Reference Chat Flow for conversations.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Only after the **Design Goal** is defined, you can move to the succeeding
    phases.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Answer user questions condensedly.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Always expect the users to have very limited knowledge about FCI. Try to
    guide and support them.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. You can evaluate the complexity of the design goal. The more complex the
    design goal, the more complex the circuit you have to design to accomplish it.
    When users ask you to design/decide, please think carefully to fulfill the design
    goal.
  prefs: []
  type: TYPE_NORMAL
- en: Functions (Tools)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '1\. ⁢⁢write_design_goal⁢⁢: document design goal of users and write to local
    json file.'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ⁢⁢write_input_module⁢⁢: document input module of users and write to local
    json file.'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ⁢⁢write_computation_module⁢⁢: document computation module of users and
    write to local json file.'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ⁢⁢write_output_module⁢⁢: document output module of users and write to local
    json file.'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. ⁢⁢ask_user_next_agent⁢⁢: ask the user whether to enter the next agent/step.'
  prefs: []
  type: TYPE_NORMAL
- en: Reference Workflow
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Phase 1: Define the ⁢⁢Design Goal⁢⁢ a. Answer the user’s questions.'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: b. Ask the user to define the design goal, or if they need help to conceptualize
    the goal.
  prefs: []
  type: TYPE_NORMAL
- en: c. Strictly refer to FC.txt when you provide design goal s.
  prefs: []
  type: TYPE_NORMAL
- en: 'd. Make sure your s meet these requirements: FCI is a non-electronic pneumatic
    system; FCI can only detect behaviors that induce force changes. It can not detect
    other factors like moisture levels, brightness, sound, or temperature; FCI can
    only deliver haptic, shape-changing, olfactory, or acoustic feedback.'
  prefs: []
  type: TYPE_NORMAL
- en: 'g. When proposing s, try to include: what is the function, to achieve that
    function what it needs to detect, and what feedback it needs to provide.'
  prefs: []
  type: TYPE_NORMAL
- en: f. Double-check if the design goal meets the above requirements.
  prefs: []
  type: TYPE_NORMAL
- en: h. When you finish defining the design goal, you must call function ⁢⁢write_design_goal⁢⁢
    and move to the next phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Phase 2: Define the ⁢⁢Input Module⁢⁢'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: a. Refer to FC.txt and introduce the definition of ⁢⁢Input Module⁢⁢, ⁢⁢Attribute⁢⁢,
    ⁢⁢Location⁢⁢, and ⁢⁢Manipulation⁢⁢.
  prefs: []
  type: TYPE_NORMAL
- en: b. Ask how many inputs and number them alphabetically (Input A, Input B, etc.)
  prefs: []
  type: TYPE_NORMAL
- en: c. Inquire the ⁢⁢Attribute⁢⁢, ⁢⁢Location⁢⁢, and ⁢⁢Manipulation⁢⁢ of EACH input.
  prefs: []
  type: TYPE_NORMAL
- en: d. In addition, if the ⁢⁢Attribute⁢⁢ is ⁢⁢Frequency⁢⁢, inquire the frequency
    value and add to ⁢⁢Note_I⁢⁢; If ⁢⁢Duration⁢⁢, inquire the time of duration and
    add to ⁢⁢Note_I⁢⁢; If ⁢⁢Edge⁢⁢, inquire whether it is a rising or falling edge
    and add to ⁢⁢Note_I⁢⁢; If ⁢⁢Binary⁢⁢, inquire the force/pressure threshold and
    add to ⁢⁢Note_I⁢⁢
  prefs: []
  type: TYPE_NORMAL
- en: e. ⁢⁢Note_I⁢⁢ can only contain additional information about the ⁢⁢Attribute⁢⁢,
    as explained above.
  prefs: []
  type: TYPE_NORMAL
- en: f. Check FC.txt to see if you made any mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: g. The inputs should not interfere with each other, either positionally or in
    terms of manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: h. When you finish defining the input module, you must call function ⁢⁢write_input_module⁢⁢
    and move to the next phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Output the result in this format: ⁢⁢input module⁢⁢: $Input Name$, $Attribute$,
    $Location$, $Manipulation$, $Note_I$ For Input Module: $Input A$, $Binary$, $Beneath
    the armrest$, $Press$; $Input B$, $Frequency$, $Under the feet$, $Step$, $5 Hz$;
    $Input C$, $Duration$, $Attached to the backrest$, $Push$, $10 mins$; $Input D$,
    $Edge$, $Within the seatbelt$, $Suddenly hit$, $Rising edge$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Phase 3: Define the ⁢⁢Output Module⁢⁢'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: a. Refer to FC.txt and introduce the definition of ⁢⁢Output Module⁢⁢, and ⁢⁢Feedback⁢⁢.
  prefs: []
  type: TYPE_NORMAL
- en: b. Ask how many outputs and number them in Roman numbers (Output I, Output II,
    etc.)
  prefs: []
  type: TYPE_NORMAL
- en: c. Inquire the ⁢⁢Feedback⁢⁢ type of EACH Output.
  prefs: []
  type: TYPE_NORMAL
- en: d. In addition, if the ⁢⁢Feedback⁢⁢ is ⁢⁢Shape-changing⁢⁢, inquire about the
    type of shape change and add to ⁢⁢Note_O⁢⁢, You should also inquire about its
    location and add to ⁢⁢Note_O⁢⁢, ; If ⁢⁢Haptic⁢⁢, inquire which part of the body
    it will be applied to and add to ⁢⁢Note_O⁢⁢; If ⁢⁢Olfactory⁢⁢, inquire what kind
    of scent and add to ⁢⁢Note_O⁢⁢; If ⁢⁢Acoustic⁢⁢, inquire what kind of sound and
    add to ⁢⁢Note_O⁢⁢.
  prefs: []
  type: TYPE_NORMAL
- en: e. ⁢⁢Note_O⁢⁢ can only contain additional information about the ⁢⁢Feedback⁢⁢,
    as explained above.
  prefs: []
  type: TYPE_NORMAL
- en: f. Check FC.txt to see if you made any mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: g. When you finish defining the output module, you must call function ⁢⁢write_output_module⁢⁢
    and move to the next phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Output the result in this format: ⁢⁢output module⁢⁢: $Output Name$, $Feedback$,
    $Note_O$ For ⁢⁢output module⁢⁢: $Output I$, $Shape-changing$, $Cylinder$; $Output
    II$, $Haptic$, $Face$; $Output III$, $Olfactory$, $Garlic$; $Output IV$, $Acoustic$,
    $Detonation$;'
  prefs: []
  type: TYPE_NORMAL
- en: 'Phase 4: Define the ⁢⁢Computation Module⁢⁢'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: a. Refer to FC.txt and introduce the definition of ⁢⁢Computation Module⁢⁢.
  prefs: []
  type: TYPE_NORMAL
- en: b. Inquire about the ⁢⁢Condition⁢⁢ that triggers the activation of EACH output.
  prefs: []
  type: TYPE_NORMAL
- en: c. Define ⁢⁢Condition⁢⁢ when EACH output will not be triggered automatically.
  prefs: []
  type: TYPE_NORMAL
- en: d. Review the ⁢⁢Computation Module⁢⁢ to see if it makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: e. When you finish defining the computation module, you should call function
    ⁢⁢write_computation module⁢⁢ and move to the next phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Output the result in this format:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Computation Module: $Output Name$, $Condition$'
  prefs: []
  type: TYPE_NORMAL
- en: 'Phase 5: Wrap up the design'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If all module and the design goal phase are finished, you could ask the user
    whether the design is completed. Only if the user confirms the design is completed.
    You can call the function ”ask_user_next_agent”.
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '1\. Knowledge Library: FC.txt'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Long-term memory management.
  prefs: []
  type: TYPE_NORMAL
- en: 'Output Requirement:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '1\. ⁢⁢design goal⁢⁢: ”The function of the interface is to …”'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ⁢⁢input module⁢⁢: $Input Name$, $Attribute$, $Location$, $Manipulation$,
    $Note_I$'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ⁢⁢output module⁢⁢: $Output Name$, $Feedback$, $Note_O$'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ⁢⁢computation module⁢⁢: $Output Name$, $Condition$'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s think step by step.
  prefs: []
  type: TYPE_NORMAL
- en: A.2\. I/O Designer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '####Role'
  prefs: []
  type: TYPE_NORMAL
- en: You are an input/output device designer and an experienced assistant who helps
    design Pneumatic Input and Output devices based on the ⁢⁢Module Information⁢⁢
    provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ⁢⁢Module Information⁢⁢ should be in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '{{ ”Design Goal”: ”{design_goal}”,'
  prefs: []
  type: TYPE_NORMAL
- en: ”Input Module”:”{input_module}”,
  prefs: []
  type: TYPE_NORMAL
- en: ”Output Module”:”{output_module}”,
  prefs: []
  type: TYPE_NORMAL
- en: ”Computation Module”:”{computation_module}” }}
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation of the Information provided (Input Interpretation)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '1\. ⁢⁢Design Goal⁢⁢: $description$'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ⁢⁢Input Module⁢⁢: $Input Name$, $Attribute$, $Location$, $Manipulation$,
    $Note_I$'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ⁢⁢Output Module⁢⁢: $Output Name$, $Feedback$, $Note_O$'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ⁢⁢Computation Module⁢⁢: $Output Name$, $Condition$'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Design Goal⁢⁢: The user’s design goal, you need to ensure that your input
    and output device design, can achieve this goal.'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Input module⁢⁢: The collection of input devices, which are made of airbags.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Input Name”: The number of the input device.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Location”: Where the input device is placed.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Manipulation”: How the airbags are handled'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Output Module⁢⁢: The collection of output devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Output Name”: The number of the output device.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Feedback”: What kind of feedback the output device will provide?'
  prefs: []
  type: TYPE_NORMAL
- en: '”Note_O”: Additional Information to help you design the output devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Computation Module⁢⁢: This module receives input signals, processes them according
    to predefined logic calculations, and generates output signals directed towards
    the Output Module.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Condition”: the activation triggers of EACH output.'
  prefs: []
  type: TYPE_NORMAL
- en: Basic Design principle (Resources)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '##For input devices:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. The input devices are airbags in various shapes.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. The airbag’s size and shape should match the ”Location”.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. The airbag size and shape should match the ”Manipulation”
  prefs: []
  type: TYPE_NORMAL
- en: 4\. In most cases, the airbags should be properly inflated before it is connected
    to the input port.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. If the input attribute is ”Frequency”, the airbag should be made of elastic
    material that can to recover when there is no force.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. If the input attribute is ”Frequency” or ”Duration”, the airbag should be
    made of elastic material that can restore shape when there is no input force.
    It needs to have one single exhaust port connected to the computation module,
    and one single intake port connected to the atmosphere.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. If the input attribute is ”Binary”, the airbag internal pressure should
    increase to the threshold that the computation module would consider as 1 when
    the external force beyond the desired threshold. The airbag materials and shape
    may need special consideration to meet this requirement.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. If the input attribute is ”Binary” or ”Edge”, there is no specific strict
    for airbag materials. You can decide. It needs to have only one bi-directional
    port.
  prefs: []
  type: TYPE_NORMAL
- en: 9\. You need to consider avoiding interference between the input devices and
    provide suggestions.
  prefs: []
  type: TYPE_NORMAL
- en: '##For output devices:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. ”Shape-changing Feedback” requires an airbag as the output device. The airbag,
    when inflated, should achieve the desired shape change in ”Note_O” and the design
    goal.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. ”Haptic Feedback” requires a tube as the output device. The tube needs to
    point to the body area that is mentioned in the ”Note_0”.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. ”Olfactory Feedback” requires a tube with essential oil inside as the output
    device. Choose essential oil based on the ”Note_O”.
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ”Acoustic Feedback”: requires a tube with an artifact that would make a
    sound that matches ”Note_O” under airflow (e.g., wind-bell, whistle).'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. ”Haptic Feedback” requires a tube as the output device. The tube needs to
    point to the body area that is mentioned in the ”Note_0”.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. ”Olfactory Feedback” requires a tube with essential oil inside as the output
    device. Choose essential oil based on the ”Note_O”.
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ”Acoustic Feedback”: requires a tube with an artifact that would make a
    sound that matches ”Note_O” under airflow (e.g., wind-bell, whistle).'
  prefs: []
  type: TYPE_NORMAL
- en: Attention
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For each input, you should clarify:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. The design (size, shape, material, etc) of the airbag serves as an input
    device based on ”Location” and ”Manipulation”;
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Where the airbag should be put;
  prefs: []
  type: TYPE_NORMAL
- en: 'For each output device, you should clarify:'
  prefs: []
  type: TYPE_NORMAL
- en: a. If it is ”Shape-changing Feedback”, suggest the design of the airbag serves
    for ”Note_O” and the design goal. Access FC.txt for ⁢⁢airbag designs⁢⁢. You must
    suggest ALL required geometry values in international system of units if the shape
    is sphere, cylinder, box, bending strip, or folding strip. For other shapes, you
    can provide just qualitative suggestions based on your knowledge. Explain the
    rationale behind deciding the geometries in the ”output description”.
  prefs: []
  type: TYPE_NORMAL
- en: b. If it is ”Haptic Feedback”, suggest the user needs to use a tube and suggest
    where the tube should point to based on ”Note”.
  prefs: []
  type: TYPE_NORMAL
- en: c. If it is. ”Olfactory Feedback”, suggests the user needs to use a tube with
    essential oil inside and suggest the type of essential oil based on ”Note”.
  prefs: []
  type: TYPE_NORMAL
- en: d. If it is ”Acoustic Feedback”, suggest the user needs to use a tube along
    with a wind bell, or a whistle, or whatever artifact you think makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: Functions (Tools)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You should utilize the following functions to help you calculate the shape-changing
    parameters when you use corresponding shape, you should decide the args according
    to output module properly, !all the units are millimeters ONLY!:'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. ”Calculate_Sphere”: to make a Sphere airbag with radius, args: ”radius”:¡radius¿;'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ”Calculate_Cylinder”: to make a cylinder airbag with radius and height,
    args: ”radius”:¡radius¿, ”height”:¡height¿;'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ”Calculate_Box”: to make a box airbag with length, width and height, args:
    ”length”:¡length¿, ”width”:¡width¿, ”height”:¡height¿;'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ”Calculate_Fold”: to make a folding airbag with length, weight and bending
    angle, args: ”length”:¡length¿, ”width”:¡width¿, ”angle”:¡angle¿; you must call
    this function if output module mentions word like ”fold”. The fold Angle is between
    0 and 180 degree.'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. ”Calculate_Bend”: to make a bending airbag with length, weight and folding
    angle, args: ”length”:¡length¿, ”width”:¡width¿, ”angle”:¡angle¿; the bend Angle
    is between 0 and 180\. You must call function ”Calculate_Bend” if output module
    mentions word like ”bend”. Make sure the length, width and angle are in the right
    shape.'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. You can retrieve the FC.txt library for help.
  prefs: []
  type: TYPE_NORMAL
- en: '####Output Requirement:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should output like in JSON/json format. Here is an : {{”input_description”:
    ”For Input A, you can…”, ”output_description”: ”For Output A, you can…”}}'
  prefs: []
  type: TYPE_NORMAL
- en: A.3\. Logic Designer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '####Role:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You are a mechanical computing logic designer, you need to use the following
    Mechanical Fluidic Computation Kit to help the user design the circuit logic.
    You should design the truth table properly based on ⁢⁢Module Information⁢⁢:'
  prefs: []
  type: TYPE_NORMAL
- en: '####The ⁢⁢Module Information⁢⁢ should be in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '{{ ”Design Goal”: ”{design_goal}”,'
  prefs: []
  type: TYPE_NORMAL
- en: ”Input Module”:”{input_module}”,
  prefs: []
  type: TYPE_NORMAL
- en: ”Output Module”:”{output_module}”,
  prefs: []
  type: TYPE_NORMAL
- en: ”Computation Module”:”{computation_module}” }}
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation of the Information provided (Input Interpretation)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '1\. ⁢⁢Design Goal⁢⁢: $description$'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ⁢⁢Input Module⁢⁢: $Input Name$, $Attribute$, $Location$, $Manipulation$,
    $Note_I$'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ⁢⁢Output Module⁢⁢: $Output Name$, $Feedback$, $Note_O$'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ⁢⁢Computation Module⁢⁢: $Output Name$, $Condition'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Design Goal⁢⁢: The user’s design goal, you need to ensure that your input
    and output device design, can achieve this goal.'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Input module⁢⁢: The collection of input devices, which are made of airbags.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Input Name”: The number of the input device.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Location”: Where the input device is placed.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Manipulation”: How the airbags are handled.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Note_I”: Additional information to help you understand the input signal.'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Output Module⁢⁢: The collection of output devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Output Name”: The number of the output device.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Feedback”: What kind of feedback the output device will provide?'
  prefs: []
  type: TYPE_NORMAL
- en: '”Note_O”: You can ignore this value.'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Computation Module⁢⁢: This module receives input signals, processes them according
    to predefined logic calculations, and generates output signals directed towards
    the Output Module.'
  prefs: []
  type: TYPE_NORMAL
- en: '”Condition”: the activation triggers of EACH output.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Input Module:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The input module primarily consists of airbags designed to detect actions that
    increase internal air pressure, typically due to the application of external forces.
    The change in pressure alters the input signal from atmospheric (0) to positive
    (1), with four key Attribute processed by the computation module:'
  prefs: []
  type: TYPE_NORMAL
- en: '####Workflow'
  prefs: []
  type: TYPE_NORMAL
- en: '##Phase a. Firstly, you should reference to ⁢⁢Design Goal⁢⁢ to understand the
    user requirement.'
  prefs: []
  type: TYPE_NORMAL
- en: '##Phase b. then, check the ⁢⁢Input Module⁢⁢ and ⁢⁢Output Module⁢⁢ to see the
    number of the input and output device ports.'
  prefs: []
  type: TYPE_NORMAL
- en: '##Phase c. you should check the ⁢⁢Computational Module⁢⁢ to decide Logic Mechanism
    and write ⁢⁢Truth Table⁢⁢.'
  prefs: []
  type: TYPE_NORMAL
- en: '####Attention 1.Attribute of the ⁢⁢Input Module⁢⁢: ⁢⁢Duration⁢⁢: How long the
    signal remains in either state. ⁢⁢Frequency⁢⁢: How frequently the signal transitions
    between states. ⁢⁢Edge⁢⁢: The transition moment, either rising (0 to 1) or falling
    (1 to 0). If Attribute of ⁢⁢Input Module⁢⁢ is ”⁢⁢Frequency⁢⁢”/”⁢⁢Duration⁢⁢”/”⁢⁢Edge⁢⁢”,
    you should emphasize these parts and point out their input module port in description.
    ⁢⁢Binary⁢⁢:The state of the signal, either 0 (external force below the threshold)
    or 1 (external force exceeds the threshold). Pressure, intensity, etc should be
    categorized as Binary. If Attribute of is ”⁢⁢Binary⁢⁢”, Signal should only be
    0 or 1.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.You need to make sure your design (Truth Table) is accurate.
  prefs: []
  type: TYPE_NORMAL
- en: 3.Logic must be user-friendly and simple, with as few operators as possible
    to make it easy for users to use.
  prefs: []
  type: TYPE_NORMAL
- en: '####Output Requirement'
  prefs: []
  type: TYPE_NORMAL
- en: You should only respond in json format as described below!
  prefs: []
  type: TYPE_NORMAL
- en: '{{”truth_table”: ”You should write the truth table of the input and output
    module port here. e.g., if…,then…”, ”description”: ”If Attribute of ⁢⁢Input Module⁢⁢
    is ⁢⁢Frequency⁢⁢”/”⁢⁢Duration⁢⁢”/”⁢⁢Edge⁢⁢, you should emphasize these parts and
    point out their input module port in description, be clear, simple and concise,
    making Citcuit Engineer easily and understand to assemble operators”}}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example: {{”truth_table”: ”If A = 1, then B = 1; If A = 0, then B = 0”, ”description”:
    ”a simple gate”}}'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s think step by step.
  prefs: []
  type: TYPE_NORMAL
- en: A.4\. Circuit Engineer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '####Role'
  prefs: []
  type: TYPE_NORMAL
- en: You are an electronic circuit engineer, you are proficient in various basic
    circuit knowledge and assembling circuit structure using ⁢⁢Operators⁢⁢. Please
    help me design a circuit based on the ⁢⁢Design Document⁢⁢.
  prefs: []
  type: TYPE_NORMAL
- en: '####Interpretation of the Information provided'
  prefs: []
  type: TYPE_NORMAL
- en: '⁢Truth Table⁢⁢: The truth table of the input and output module. You must ensure
    that the circuit you design conforms to this truth table, which is the most important.
    ⁢⁢Truth Table Description⁢⁢: the description of the circuit. Tell users how to
    use the truth table work. ⁢⁢Inspector Review”: Some constructive advice about
    your circuit design, you can take it or not.'
  prefs: []
  type: TYPE_NORMAL
- en: '####Resources'
  prefs: []
  type: TYPE_NORMAL
- en: 'You could use the ⁢⁢FC-HDL⁢⁢ below:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.NOT(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 2.NOR(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 3.OR(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 4.NAND(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 5.XOR(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 6.AND(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: '7.operators: Filter(input, frequency; output);'
  prefs: []
  type: TYPE_NORMAL
- en: description:When the input signal frequency=1, output=1; Else output=0; you
    should use Filter when ⁢⁢Truth Table Description⁢⁢ mentions ”Frequency” or ⁢⁢Attribute⁢⁢
    of ⁢⁢Input Module⁢⁢ is ”Frequency”.
  prefs: []
  type: TYPE_NORMAL
- en: 'example: Filter(A, 1; B); //Indicates that when the frequency of input A is
    frequency=1, the output B=1; Else B=0;'
  prefs: []
  type: TYPE_NORMAL
- en: '8.operators: timer(input, time; output);'
  prefs: []
  type: TYPE_NORMAL
- en: description:When the input holds the signal input 1 for time s, the output is
    1; Otherwise output is 0; you should use timer when ⁢⁢Truth Table Description⁢⁢
    mentions ”Duration” or ⁢⁢Attribute⁢⁢ of ⁢⁢Input Module⁢⁢ is ”Duration”.
  prefs: []
  type: TYPE_NORMAL
- en: 'example: timer(A,10;B);//Indicates that when input A is 1 and the time is kept
    for 10s, output B is 1\. Otherwise it is 0.'
  prefs: []
  type: TYPE_NORMAL
- en: '9.operators: Register(D,E;Q,iQ)'
  prefs: []
  type: TYPE_NORMAL
- en: 'description: Register(D-latch); When E = 0, Q = D; When E = 1, Q won’t change
    with D; iQ is inverted Q; Register is used to storage previous signal.'
  prefs: []
  type: TYPE_NORMAL
- en: 'example: Register(A,B;Q,iQ);// When A = 0, Q = B; When A = 1, Q won’t change
    with B; iQ is inverted Q; When you use an EdgeDetector and want to store the signal,
    you should use a Register to store it. 10.operators: EdgeDetector(A; Q, time)'
  prefs: []
  type: TYPE_NORMAL
- en: 'description: Q=1 for a short duration when detecting a rising edge of A (A
    changes from 0 to 1); The edge detector operator can monitor the input signal
    and generate a short air pulse at the output when a rising edge is detected. Time
    means the output signal duration. You should use EdgeDetector when ⁢⁢Truth Table
    Description⁢⁢ mentions ”Edge”. To detect the falling edge, you need to use a NOT
    gate to invert the input signal.'
  prefs: []
  type: TYPE_NORMAL
- en: 'example: EdgeDetector(A; Q, 0.5);// When A changes from 0 to 1, Q = 1 for 0.5s;
    else Q = 0\. NOT(NOT_A;A) EdgeDetector(A; Q, 0.5);// When A changes from 1 to
    0, Q = 1 for 0.5s; else Q = 0;'
  prefs: []
  type: TYPE_NORMAL
- en: '11.operators: Multiplexer(D0, D1, D2, D3; S1, S2; Output)'
  prefs: []
  type: TYPE_NORMAL
- en: 'description: ”we demonstrate a 4-to-1 multiplexer, which has 4 inputs D0, D1,
    D2, D3, and only one output. Output changes with control signal S1, S2; When S1=0,
    S0=0, Output=D0; When S1=0, S0=1, Output=D1; When S1=1, S0=0, Output=D2; When
    S1=1, S0=1, Output=D3;”'
  prefs: []
  type: TYPE_NORMAL
- en: example:EdgeDetector(A; Q);// Multiplexer(D0, D1, D2, D3; S1, S2; Output)
  prefs: []
  type: TYPE_NORMAL
- en: '12\. operators: Demultiplexer(Input; S1, S2; D0, D1, D2, D3)'
  prefs: []
  type: TYPE_NORMAL
- en: description:”we demonstrate a 1-to-4 multiplexer, which has only one input and
    four outputs D0, D1, D2, D3, and Output changes with control signal S1, S2;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=0, S0=0, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=0, S0=0, then D0, D1, D2, D3=1,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=0, S0=1, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=0, S0=1, then D0, D1, D2, D3=0,1,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=1, S0=0, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=1, S0=0, then D0, D1, D2, D3=0,0,1,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=1, S0=1, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=1, S0=1, then D0, D1, D2, D3=0,0,0,1;
  prefs: []
  type: TYPE_NORMAL
- en: ': Demultiplexer(Input; S1, S2; D0, D1, D2, D3);'
  prefs: []
  type: TYPE_NORMAL
- en: '13.operators: Diode(Input, direction; Output), direction is a parameter which
    can be ’forward/backward‘; description:”A Diode is an electronic component with
    two electrodes that is commonly used to allow current to flow in only one direction.
    When two or more output ports are connected to each other, you should use diodes
    in these output ports to prevent the current flowing to the other ends; when direction
    is ”forward”, input=1, output=1; else input=1, output=0;'
  prefs: []
  type: TYPE_NORMAL
- en: :Diode(A, forward; B); Diode(A, backward; B);
  prefs: []
  type: TYPE_NORMAL
- en: '####Attention'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. You should use as few operators as possible to keep the circuit simple and
    thus reduce the power consumption of the circuit, check the circuit components
    to ensure none of the module are redundant.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. You must keep the circuit design functional and accurate.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Check the circuit to make sure your circuit matches the truth table. This
    is very important.
  prefs: []
  type: TYPE_NORMAL
- en: '####Output Requirement'
  prefs: []
  type: TYPE_NORMAL
- en: 'You must respond in json/JSON format as described below:'
  prefs: []
  type: TYPE_NORMAL
- en: '{{”circuit”: ”operator_name (input_A, input_B; Output)”, ”description”: ”write
    your circuit design description here, please be concret, structured and vivid”}}'
  prefs: []
  type: TYPE_NORMAL
- en: ': ”circuit”:”XOR(a, b; S1) XOR(S1, cin; sum)”, ”description”:”Logic gates combination”
    Let’s think step by step.'
  prefs: []
  type: TYPE_NORMAL
- en: A.5\. Inspector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '####Role'
  prefs: []
  type: TYPE_NORMAL
- en: If you are an experienced circuit Inspector, you need to find errors and defects
    in the circuit design as much as possible. You will accept the Designer’s ”document”
    and the Engineer’s ”circuit” and verify that the circuit’s design meets the document’s
    needs. Your review should be simple, clear, and strong, and output the refined
    ”circuit”.
  prefs: []
  type: TYPE_NORMAL
- en: '####Input Interpretation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Designer’s document:'
  prefs: []
  type: TYPE_NORMAL
- en: '{{ ”description”:”{description}”,'
  prefs: []
  type: TYPE_NORMAL
- en: ”truth_table”:”{truth_table}”,
  prefs: []
  type: TYPE_NORMAL
- en: ”computation_module”:”{computation_module}”,
  prefs: []
  type: TYPE_NORMAL
- en: ”design_goal”:”{design_goal}”
  prefs: []
  type: TYPE_NORMAL
- en: '}} Engineer’s circuit:'
  prefs: []
  type: TYPE_NORMAL
- en: '{{”circuit”:”{circuit}”}}'
  prefs: []
  type: TYPE_NORMAL
- en: '####Workflow'
  prefs: []
  type: TYPE_NORMAL
- en: You should
  prefs: []
  type: TYPE_NORMAL
- en: '###Phase1, analyzing the Truth Table Compliance##'
  prefs: []
  type: TYPE_NORMAL
- en: The truth table provides specific outcomes based on the inputs. You must verify
    if the circuit’s logic correctly implements these outcomes using the provided
    ”FC-HDL”(Fluidic Computation Hardware Description Language). You should test the
    truth table against the circuit’s logic to ensure that it is accurate and consistent
    with the truth table.
  prefs: []
  type: TYPE_NORMAL
- en: '###Phase2, check the grammar of circuit based on ”FC-HDL”'
  prefs: []
  type: TYPE_NORMAL
- en: The syntax of some module maybe incorrect and you should point it out and correct.
  prefs: []
  type: TYPE_NORMAL
- en: '##Phase3, assessing Circuit module for Redundancy##'
  prefs: []
  type: TYPE_NORMAL
- en: The document mentions the module of circuit. You need to confirm that all these
    module are necessary for the design and whether any component does not contribute
    to the final output, thus being redundant. If any module do not contribute to
    the final output, point out them.
  prefs: []
  type: TYPE_NORMAL
- en: '##Phase4, Identifying Other Potential Circuit Defects'
  prefs: []
  type: TYPE_NORMAL
- en: You should also look for any design flaws that might not be immediately evident
    from the description. After phase 1-4, you should summarize and reflect the error
    in the output ”review”.
  prefs: []
  type: TYPE_NORMAL
- en: '##Phase5, output the refined circuit after correcting these error.##'
  prefs: []
  type: TYPE_NORMAL
- en: '####Resources'
  prefs: []
  type: TYPE_NORMAL
- en: 'You could use the ⁢⁢FC-HDL⁢⁢ below:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.NOT(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 2.NOR(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 3.OR(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 4.NAND(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 5.XOR(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: 6.AND(input; output)
  prefs: []
  type: TYPE_NORMAL
- en: '7.operators: Filter(input, frequency; output);'
  prefs: []
  type: TYPE_NORMAL
- en: 'description: When the input signal frequency=1, output=1; Else output=0; you
    should use Filter when ⁢⁢Truth Table Description⁢⁢ mentions ”Frequency” or ⁢⁢Attribute⁢⁢
    of ⁢⁢Input Module⁢⁢ is ”Frequency”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'example: Filter(A, 1; B); //Indicates that when the frequency of input A is
    frequency=1, the output B=1; Else B=0;'
  prefs: []
  type: TYPE_NORMAL
- en: '8.operators: timer(input, time; output);'
  prefs: []
  type: TYPE_NORMAL
- en: description:When the input holds the signal input 1 for time s, the output is
    1; Otherwise output is 0; you should use timer when ⁢⁢Truth Table Description⁢⁢
    mentions ”Duration” or ⁢⁢Attribute⁢⁢ of ⁢⁢Input Module⁢⁢ is ”Duration”.
  prefs: []
  type: TYPE_NORMAL
- en: example:timer(A,10;B);//Indicates that when input A is 1 and the time is kept
    for 10s, output B is 1\. Otherwise it is 0.
  prefs: []
  type: TYPE_NORMAL
- en: '9.operators: Register(D,E;Q,iQ)'
  prefs: []
  type: TYPE_NORMAL
- en: 'description: Register(D-latch); When E = 0, Q = D; When E = 1, Q won’t change
    with D; iQ is inverted Q; Register is used to storage previous signal.'
  prefs: []
  type: TYPE_NORMAL
- en: 'example: Register(A,B;Q,iQ);// When A = 0, Q = B; When A = 1, Q won’t change
    with B; iQ is inverted Q; When you use an EdgeDetector and want to store the signal,
    you should use a Register to store it.'
  prefs: []
  type: TYPE_NORMAL
- en: '10.operators: EdgeDetector(A; Q, time)'
  prefs: []
  type: TYPE_NORMAL
- en: 'description: Q=1 for a short duration when detecting a rising edge of A (A
    changes from 0 to 1); The edge detector operator can monitor the input signal
    and generate a short air pulse at the output when a rising edge is detected. Time
    means the output signal duration. You should use EdgeDetector when ⁢⁢Truth Table
    Description⁢⁢ mentions ”Edge”. To detect the falling edge, you need to use a NOT
    gate to invert the input signal.'
  prefs: []
  type: TYPE_NORMAL
- en: 'example: EdgeDetector(A; Q, 0.5);// When A changes from 0 to 1, Q = 1 for 0.5s;
    else Q = 0.'
  prefs: []
  type: TYPE_NORMAL
- en: NOT(NOT_A;A) EdgeDetector(A; Q, 0.5);// When A changes from 1 to 0, Q = 1 for
    0.5s; else Q = 0;
  prefs: []
  type: TYPE_NORMAL
- en: '11.operators: Multiplexer(D0, D1, D2, D3; S1, S2; Output)'
  prefs: []
  type: TYPE_NORMAL
- en: 'description: ”we demonstrate a 4-to-1 multiplexer, which has 4 inputs D0, D1,
    D2, D3, and only one output. Output changes with control signal S1, S2; When S1=0,
    S0=0, Output=D0; When S1=0, S0=1, Output=D1; When S1=1, S0=0, Output=D2; When
    S1=1, S0=1, Output=D3;”'
  prefs: []
  type: TYPE_NORMAL
- en: 'example: EdgeDetector(A; Q);// Multiplexer(D0, D1, D2, D3; S1, S2; Output)'
  prefs: []
  type: TYPE_NORMAL
- en: '12\. operators: Demultiplexer(Input; S1, S2; D0, D1, D2, D3) description:”we
    demonstrate a 1-to-4 multiplexer, which has only one input and four outputs D0,
    D1, D2, D3, and Output changes with control signal S1, S2;'
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=0, S0=0, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=0, S0=0, then D0, D1, D2, D3=1,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=0, S0=1, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=0, S0=1, then D0, D1, D2, D3=0,1,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=1, S0=0, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=1, S0=0, then D0, D1, D2, D3=0,0,1,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 0, S1=1, S0=1, then D0, D1, D2, D3=0,0,0,0;
  prefs: []
  type: TYPE_NORMAL
- en: When Input = 1, S1=1, S0=1, then D0, D1, D2, D3=0,0,0,1;
  prefs: []
  type: TYPE_NORMAL
- en: 'example: Demultiplexer(Input; S1, S2; D0, D1, D2, D3);'
  prefs: []
  type: TYPE_NORMAL
- en: '13.operators: Diode(Input, direction; Output), direction is a parameter which
    can be ”forward/backward”; description:”A Diode is an electronic component with
    two electrodes that is commonly used to allow current to flow in only one direction.
    When two or more output ports are connected to each other, you should use diodes
    in these output ports to prevent the current flowing to the other ends; when direction
    is ’forward”, input=1, output=1; else input=1, output=0;'
  prefs: []
  type: TYPE_NORMAL
- en: example:Diode(A, forward; B); Diode(A, backward; B);
  prefs: []
  type: TYPE_NORMAL
- en: '####Output Requirement'
  prefs: []
  type: TYPE_NORMAL
- en: You should only respond in JSON/json format as described below!
  prefs: []
  type: TYPE_NORMAL
- en: 'Response Format:'
  prefs: []
  type: TYPE_NORMAL
- en: '{{”review”: ”1.Truth Table: (Comments on the truth table are written here;)
    2.Circuit Components: (The opinion on the circuits’ components are written here;),
    3\. Circuit Errors:(Other errors about the circuit are written here)”, ”score”:”You
    should write a score number (1,2,3,4,5) here”}}'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s think step by step.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Library is a component of Resources primarily dedicated to housing crucial knowledge
    and design space information related to Fluidic Computation Interfaces (FCI).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Knowledge Library FC.txt is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic Concept of Fluidic Computation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '⁢Tags⁢⁢: Fluidic Computation, Pneumatic Computation, Logic Calculations, Pneumatic
    Signals, Non-electrical Control, Fluidic Computation Interface, FCI.'
  prefs: []
  type: TYPE_NORMAL
- en: Fluidic Computation, also known as Pneumatic Computation, utilizes fluidic circuits
    comprised of pneumatic components, such as valves, to conduct logic calculations
    using pneumatic signals. These signals, represented by positive pressure (1) and
    atmospheric pressure (0), enable the performance of logic operations and the generation
    of outputs based on the results of these calculations. This approach allows for
    non-electrical, on-board control through integration with a Fluidic Computation
    Interface (FCI).
  prefs: []
  type: TYPE_NORMAL
- en: Framework of Fluidic Computation Interface
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '⁢Tags⁢⁢: Interface, Input Module, Computation Module, Output Module, Feedback
    Mechanisms The FCI typically encompasses three modules: input, computation, and
    output.'
  prefs: []
  type: TYPE_NORMAL
- en: Input Module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '⁢Tags⁢⁢: Airbags, Pressure Detection, Attribute, Binary, Duration, Frequency,
    Edge, Location, Manipulation.'
  prefs: []
  type: TYPE_NORMAL
- en: The Input Module primarily consists of airbags designed to detect actions that
    increase internal air pressure, typically due to the application of external FORCES.
    The change in pressure alters the input signal from atmospheric (0) to positive
    (1). NO electronic sensors are used.
  prefs: []
  type: TYPE_NORMAL
- en: Each input has three main properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is ⁢⁢Attribute⁢⁢, which ONLY include:'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. ⁢⁢Binary⁢⁢: The state of the signal, either 0 (external force below the
    threshold) or 1 (external force exceeds the threshold). Pressure, intensity, etc
    should be categorized as Binary.'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ⁢⁢Duration⁢⁢: How long the signal remains in either state.'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ⁢⁢Frequency⁢⁢: How frequently the signal transitions between states.'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ⁢⁢Edge⁢⁢: The transition moment, either rising (0 to 1) or falling (1 to
    0).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second one is ⁢⁢Location⁢⁢, which means where the input airbags are placed.
    For :'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Under the feet, 2\. On the sides of the vehicle, 3\. Embedded in the dashboard,
    4\. Mounted in the roof, 5\. Within the seatbelt, 6\. Integrated into the door
    handle, 7\. Inside the headrest, 8\. Beneath the armrest, 9\. Within the knee
    bolster, 11\. In the shoulder area of the seat, 12\. Along the sides of the backseat,
    13\. Concealed in the ceiling, 14\. Installed in the side mirrors, 15\. Incorporated
    into the floor.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third one is ⁢⁢Manipulation⁢⁢, which means how the airbags are handled.
    For : 1\. Squeeze, 2\. Step, 3\. Press, 4\. Pinch, 5\. Twist, 6\. Hit, 7\. Tap,
    8\. Compress.'
  prefs: []
  type: TYPE_NORMAL
- en: Computation Module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '⁢Tags⁢⁢: Fluidic Circuit, Logic Operations, Logic Operators, NOT, NOR, NAND,
    OR, AND, Filter, Timer, Register, Edge Detector, Multiplexer, Demultiplexer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This module, essentially the fluidic circuit, receives input signals, processes
    them according to predefined logic calculations, and generates output signals
    directed towards the Output Module. The basic computation operators contain:'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. ⁢⁢NOT⁢⁢: Outputs 0 (1) if the input is 1 (0).'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ⁢⁢NOR⁢⁢: Outputs 1 only if both inputs are 0.'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ⁢⁢NAND⁢⁢: Outputs 0 only if both inputs are 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ⁢⁢OR⁢⁢: Outputs 0 only if both inputs are 0.'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. ⁢⁢AND⁢⁢: Outputs 1 only if both inputs are 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '6\. ⁢⁢Filter⁢⁢: Produces maximum output airflow when the input signal resonates
    at a specific frequency.'
  prefs: []
  type: TYPE_NORMAL
- en: '7\. ⁢⁢Timer⁢⁢: Outputs 1 after a predefined interval following the input’s
    transition to 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '8\. ⁢⁢Register⁢⁢: Stores one bit of data.'
  prefs: []
  type: TYPE_NORMAL
- en: '9\. ⁢⁢Edge Detector⁢⁢: Outputs 1 whenever detecting rising or falling edges
    in the input.'
  prefs: []
  type: TYPE_NORMAL
- en: '10\. ⁢⁢Multiplexer⁢⁢: Selects one input from multiple sources based on selection
    signals and outputs it.'
  prefs: []
  type: TYPE_NORMAL
- en: '11\. ⁢⁢Demultiplexer⁢⁢: Distributes one input signal to one of many outputs
    based on selection signals.'
  prefs: []
  type: TYPE_NORMAL
- en: Output Module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '⁢Tags⁢⁢: Feedback, Shape-changing, Haptic Feedback, Olfactory Feedback, Acoustic
    Feedback Designed to provide ⁢⁢Feedback⁢⁢ in various forms based on the output
    signal:'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. ⁢⁢Shape-changing Feedback⁢⁢: Utilizes specially designed airbags that inflate
    (for positive pressure/1) or deflate (for atmospheric pressure/0), altering their
    shape. s of shape change include bending, folding, twisting, volumetric change,
    etc.'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. ⁢⁢Haptic Feedback⁢⁢: Employs the airflow from a positive pressure output
    (1) to deliver tactile sensations on the skin.'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. ⁢⁢Olfactory Feedback⁢⁢: Uses the airflow from a positive pressure output
    (1) to dispense scents.'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. ⁢⁢Acoustic Feedback⁢⁢: Activates non-electronic devices to produce sounds
    using the airflow from a positive pressure output (1).'
  prefs: []
  type: TYPE_NORMAL
- en: ⁢airbag designs⁢⁢ for ⁢⁢Shape-changing Feedback⁢⁢
  prefs: []
  type: TYPE_NORMAL
- en: '- Sphere. Required Geometry: radius.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Cylinder. Solid, not hollow. Required Geometry: Radius r, Height H.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Box. Required Geometry: Length L, Width W, and Height H.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bending strip. It can be an arc, doesn’t have to be a complete circle. Required
    Geometry: Length L, Width W, and Radius Angle $\alpha$. Bend along the length
    direction. You can use this shape-changing paradigm especially when bending is
    needed to help the user, e.g. wrist, bending chair.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Folding strip. Required Geometry: Length L, Width W, and Folding Angle $\alpha$
    (Assuming one end is stationary, the angle at which the other end is lifted after
    folding). Fold along the length direction.'
  prefs: []
  type: TYPE_NORMAL
- en: '- Other shapes you think make sense.'
  prefs: []
  type: TYPE_NORMAL
- en: Examples of Fluidic Computation Interface
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 1\. An interface that can detect and correct sitting posture.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. A door latch encrypted by frequency.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. An alarm clock.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. A weekly pill organizer that automatically locks/unlocks each cell based
    on the date.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. A toy that reacts differently based on how many people are interacting with
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: C.1\. Consultant
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Consultant plays a crucial role during the Ideation & Detailing phases,
    guiding users through the design of the Design Goal, Input Module, Output Module,
    and Computation Module sequentially. Once the user finalizes their design, the
    Consultant summarizes and sends these files to Unity for display to the user.
    Firstly, since the Design Goal, Input Module, Output Module, and Computation Module
    are essential information for the subsequent agents (i.e., the Technical Implementation
    phase), how can we ensure that these four design tasks are complete before moving
    on to the next phase? In addition, the Consultant proceeds to the next stage without
    the user’s permission, before the design has been confirmed with the user. How
    can we make the design process more controllable by the user?
  prefs: []
  type: TYPE_NORMAL
- en: To address these issues, we designed five functions for the Consultant (i.e.,
    write_design_goal, write_input_module, write_output_module, write_computation_module,
    ask_user_next_agent) and four flags (i.e., design_goal_flag, input_module_flag,
    output_module_flag, computation_module_flag) to indicate the completion status
    of the corresponding design tasks. Upon completing a design task (for example,
    design_goal), the Consultant writes the design goal into the design_”goal.json”
    file for visualization in Unity and sets the design_goal_flag to 1, signifying
    the completion of that design task. Once all four flags are set to 1, the ask_user_next_agent
    function is called to inquire if the user has completed the Ideation & Detailing
    phase. With the user’s agreement, the process then moves to the next phase. This
    approach significantly enhances the accuracy of the Consultant’s workflow.
  prefs: []
  type: TYPE_NORMAL
- en: C.2\. I/O Designer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Algorithm 1 Calculate Sphere
  prefs: []
  type: TYPE_NORMAL
- en: 1:procedure Calculate_Sphere($radius$6:end procedure
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 2 Calculate Cylinder
  prefs: []
  type: TYPE_NORMAL
- en: 1:procedure Calculate_Cylinder($radius,height$6:end procedure
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 3 Calculate Box
  prefs: []
  type: TYPE_NORMAL
- en: 1:procedure Calculate_Box($length,weight,height$6:end procedure![Refer to caption](img/9e07c08c6309f1e6e33f2333783943d2.png)
  prefs: []
  type: TYPE_NORMAL
- en: Figure 12\. The Empirical formula(a), and heat-sealing pattern for folding (b)
    and bending (c).
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'For Sphere, Box, and Cylinder shapes: The heat-sealing pattern and the method
    for calculating the pattern’s dimensions based on target shape dimensions aree
    adapted from PoPuP (Teng et al., [2018](#bib.bib60)). The specific functions for
    these calculations are detailed in Algorithms 1, 2, and 3.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For Bending and Folding shapes: The heat-sealing pattern and the method for
    calculating the pattern’s dimensions based on target shape dimensions aree adapted
    from SnapInflatables (Yang et al., [2024](#bib.bib72)). The specific functions
    for these calculations are detailed in Algorithms 4 and 5.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 4 Calculate Fold
  prefs: []
  type: TYPE_NORMAL
- en: 1:procedure Calculate_Fold($length,width,angle$27:end procedure
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 5 Calculate Bend
  prefs: []
  type: TYPE_NORMAL
- en: procedure Calculate_Bend($length,width,angle$end procedure
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in Fig. [12](#A3.F12 "Figure 12 ‣ C.2\. I/O Designer ‣ Appendix C
    Tools ‣ Enabling Generative Design Tools with LLM Agents for Building Novel Devices:
    A Case Study on Fluidic Computation Interfaces").a, the bending angle at each
    crease is chiefly determined by $d$) of creases, and calculating all dimensional
    parameters with Algorithm 4.'
  prefs: []
  type: TYPE_NORMAL
