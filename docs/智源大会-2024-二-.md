# 智源大会 2024（二）



# 2024北京智源大会-人工智能+数据新基建 - P2：大模型需要大数据流转模式创新-黄铁军 - 智源社区 - BV1qx4y14735

尊敬的上部长夏局长啊，各位领导啊，各位专家呃，特别感谢啊，大家来这个出席今天这个志愿大会，我们嗯围绕人工智能，特别是数据呃的一一些这样的一个重大问题，来开展那个呃研讨，那我呢这个报告呢。

呃希望呢可能是从呃从事人工智能呃研究吧，这样的一个一个呃角度呢来呃谈一下看法。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8b9a0b0cc961f1a37562688026b833ea_1.png)

因为今天呢后面我们还有几个呃很重要的报告，会很专业的角度来来来讲，我想呢就是汇报三个观点，或者说个人的这个一个一个思考，第一个呢就是智能，我们讲人工智能源头就是数据啊，这是呃，当然大家会经常会觉得。

你们搞研研究人工智能的算法呀，这个理论啊那些东西好像很核心，但是我想说呢，这个呃所有的智能，包括人的智能，归根结底源头就是数据，没有别的东西，没有别的东西，这是第一个，第二个呢数据加工数据标注。

今天数据是正在成为一个产业，靠谁靠人还是靠人工智能，我想说呢主要靠人工智能，不是不要人啊，人还要人，要还要发挥作用，但是大比例的应该是靠人工智能，这是第二个观点，第三个呢数据和智能的关系问题呃。

我我建议呢这个要要研究这个体制机制，这个流通模式，我们怎么看待数据这样的一个资产，让他怎么在这个人工智能这样的一个时代中，发挥更大的作用，更快的更好的发挥作用，呃我我觉着一个基本的思考呢。

就是你要想实现正反这么一个良，良性的正反馈的话，应该是先试用，先使用后付费，而不能呢当成一个一个物理资产去去去标价，上来就要花多少钱去买，大概这么三个观点来谈一下看法，时间有限呢。

有些地方呢可能不能太太展开，第一个呢就是智能的源头哦，是数据，这一点呢在人工智能发展的历史中呢，其实一开始呢并没有得到这个这样一个充分的，或者彻底的认识，所以早期的人工智能是人把自己想的太重要了。

我们简而言之呢，就是人来这个把这个智能过程变成算法，变成规则，后来呢把这个呃我们叫知识啊，实际上就是数据中的这些规律性的东西，这些这些条目由人来整理变成知识库，知识工程呃，这个相当于人嚼完了哎。

然后让机器执行呃以为这就是人工智能，但是这么去做，后后后来呢证明是这个，无法真正的解决智能问题的，所以呢从第三次浪，我们今天都讲人工智能进入第三次浪潮，第三次浪潮最大的革命就是从数据中学习。

当然这个思想已经，这个从上个世纪80年到现在，差不多已经快40年的历史，所以如果人工智能分成上半页，下半页的话，上半页是以人工为主，下半夜是从数据中学习为主，好已经开始重视数据了对吧，要要从数据中学习。

当然更广义的人工智能啊，如果展开谈那个更复杂对吧，或者那个技术路线，或者大家的这个这个idea更多呃，但是呢我今天有限，我就不展开说这个这些这些这些点，但是最重要的呢就是这么多年。

经过这个各种这个尝试呃，各种这个可以说是这个失败之后呃，才终于找到了这么一条一条可行的道路，就像我刚才说的，当初以为这个人思考，然后是人的思考形式化，然后让机器执行，以为这就能解决。

实际上那是个好像会思考，是解决不了死机器，真正的这个思考和智能问题的，那第二个路线，也就是今天咱们用的路线，就是要有一套神经，人工神经网络神经系统来进行对数据，对信息进行处理，然后才能产生这个智能嗯。

这从这个时候开始，我们才说呢，你看人工智能才算走上了一个，这个这个正确的道路，第三个行为主义也讲的很多啊，就是实际上就是在一个身体，今天讲具身智能对吧，就是智能不是天上掉下来的，智能是一个主体。

具体来说对于我们人，我们就人是主体，对于一个低等动物，对一个单细胞，甚至对于一个有机物来说，它都是一个主体，它要跟环境互动，所以这里边提到环境的概念，数据和环境是密不可分的。

数据是什么数据当然大家都低着头的，数字的数字的，它表示的是什么，它表示的是环境对吧，无论是传感器还是其他任何这个手段，你获取的其实都是关于这个事件的一些，一个一个是一个一个表达方式。

所以当我们看这些几十年的这个人工智能的发，展的，这个这些这些曲曲折折的这样的一些道路啊，这些呃通常说符号主义，刚才符号主义，连接主义，行为主义，这是我们经典的呃，通常说的这个三三大学派或者三个技术流派。

那么比较新的，过去十几年谈的多的深度学习，强化学习，还有类脑智能呃，这个类脑智能可能听起来比较新啊，其实一点都不新，它就是连接主义的一个彻底的方式，就是那个神经网络，就像人的这个呃生物的神经网络一样。

做一个这种这种呃神经网络，为什么要做那个神经网络，因为那样的我们大脑这样的神经网络具有，就就有这个强的智能现象，但是不论是深度学习，从数据中学还是强化学习，从环境中学，还是我刚才说的累脑。

你做就就你就把人脑做出来，完全照着人人脑的方式做一个光电的这个大脑，他也不是天生，就像我们人生生下来，这个就具备我们这些后天的能力的，那只是你有了这个学习的条件和潜力，你的能力，你的智能还得学对吧。

所以我们还要读书，还要学习，还要跟环境互动，还要这个逐逐渐的提高提高自己的智能水平，所以不管是什么方法，什么路线，归根结底智能是从环境中学，如果说的近一点，就是从数据中学，就像刚才说的。

数据是环境的一个一个一个表达，是实际上大家再思考一下智能这个东西啊，为什么地球上会出现智能，为什么智能会水平是这个水平越来越高，其实它不过是我刚才说的一个智能主体，你要适应这个环境。

你必须具备的一种能力，而适应这个环境其实就是对这个这个这个世界，这个环境是什么的，一个一个抽象的一个一一个表达，这是我们智能的这个基础，然后呢再通过神经网络啊什么方式去执行而已，所以呃结论啊。

所有的智能来自于数据，广义的讲就来自于环境，智能只不过是环境和数据的一个投射，一个凝练，一个一种一种一种一种高度的浓缩的一种表达，使得我们能够比较好的去适应这个环境，应对这个环境。

所以智能从来都不是都不是抽象的，地球这个环境就造就了我们地球的这种智能，这种这种智能的这个形态，如果是一个外星球的，它的智能肯定跟我们不一样，原因很简单，他要适应那个环境。

你地球上这一套适应地球环境的这个能力，你换一个完全不同的物理环境，你你你你你这没有办法去应对，那个那个那个那个那个条件的，所以什么样的环境造就什么样的，是什么样的智能，那今天我们比较现实的。

就是说我们要从数据中学，我们过去的这个呃56年时间啊，我经常说人工智能发展六七十年，但是最大的革命就是过去的56年，具体来说就是就是大模型，大模型呢当然是一个神经网络，它是一个很多参数的神经网络。

但是这个大模型中的智能，就在那个神经网络的连接上，就是神经网络的这个这个连接的强度，那个那个强度是怎么训练出来的，但是从大数据中训练出来的呃，怎么训，其实呢你如果给的是一个随机数啊。

就是如果是海量的数据，全是没有规律的，是一个随机的数，你训不出智能来，因为你给的数据有规律，所以它最后的这个参数它才有才有有了规律，就像我刚才说的这些参数，不过是你你你为的数据的一个一个投射而已。

那这规律怎么学呃，其实大模型的学这个学法，从2013年开始的这种呃，这个我们说计算机表达数据关系的，这种磁向量技术给了一个解决方案，就是学数据的关系，那数据我们今天叫token对吧，一个一个的单元。

学这个单元与单元之间的关系而已，所以transformer这样的一个神经网络是什么，那就是学这个，咱们说对吧，你输喂入这个余料，那我那我那我就要研究这个一个一个的词，和其他词之间的关系。

你能你能把词与词之间的关系学到，你就学到了这个这个数据背后的规律，那这件事呢说的有点这个拗口啊，大家说真的能做到这一点吗，其实呢我我想这个时间有限啊，我不能花大太多时间去解释，但是我想有一句话。

大家我相信大家都有学过马克思说的啊，马克思说人是一切社会社会关系的总和，什么叫一个人，怎么定义一个人是和你和他人之间的关系，所确定下来的对吧，在家庭在工作，在生活中，在这个社会上。

在专业你都有很多人有有有关联，包括今天咱们一起参加这个会，我们之间就有了这个关系，嗯我呢我在这跟大家这个交流，就是定义我这个人的，一个一个一个一个一个方面啊，当然我还跟其他人交流对吧，我还有我还有家庭。

定义了我是谁，所以一个个体，它的含义是由它跟其他个体之间的关系定义的，这是马克思的这个这个这个讲的，那刚才说大模型去学，从海量的语料学，其实学的也是一样，一个token就是一个个体一个单元。

这个单元在大量的这个语料里边，跟其他单元出现对吧，前后它有有关系，你只要能把那个这个关系充分的学，然后映射为这个这个大模型的那个参数，神经连接，那就学到了这个它的它的含义。

所以今天大贸行我们说说我说结论啊，今天当美是真的理解了语言，以及其他模态背后的含义的，而且可以说比人理解的还要精准，因为它是仔仔细细的这么算算出来的，算出来的，而且用一个高维的这个向量来表示呃。

实际上我就解释到这个地方啊，所以这个人工智能没有什么神秘的，人工智能的这个能力全在来自于数据，而且呢我们刚刚才讲过去556年的时间，人类找到了一个办法，用一个大型的神经网络的参数，这个大量的参数来表达。

刚才说的这样的，这个隐含在海量数据背后的这个规律，所以这就是经常说的skin law，规模定律，一直说什么意思呢，就是数据很大，所以你我们需要一个很大的网络，这个网络的规模的扩大。

和刚才说的数据量的增加，当然需要计算的那个那个次数的增加，所以算力也需要很大，它就会它就能越来越多的，越来越越丰富的把那个语义呢给给给抽取出来，他得到语意之后，他就表现出了这些越来越丰富的能力。

就像我们人学多了对吧，我们学了唐诗300首，我们就开始会会会，大概会写个写个像样的诗对吧，我们学了那么多这个知识，然后我们慢慢的这个就自己就有了很多，很多的这个创新和想法，大模型其实也是一样的。

所以大模型的这种这种从海量的数据中学出来，产生的，今天就像变魔法一样的，大家看到的这些能力，其实就是一个自然规律的一个体现，这些能力不是这我们这些搞人工智能研究的人，设计出来的，不是我们聪明。

我们不聪明，我们用的就是刚才说大家用的都是这个这么，一个一个一个很容易理解的这么一个方法，聪明智能都在数据里边，这个办法只不过把那个数据里边，那个东西转换成了一个一个神经网络。

而这个转换过程是计算是机器自己在执行的，他能表现出什么能力，没人知道，设计师不知道，训的时候，也不知道他会出现什么能力，但是那规模到了那种程度，规模越来越大，它就会产生越来越强的能力。

而且我们相信这个还没看到天花板，规模还会继续更增，大数据随着数据的更变得越来越大，这个能力就越来越强，这个这是人类我们说遇到了一次技术革命，这次革命呃，可能跟历史上这个最伟大的这个革命。

经常说像指南针的发明，飞机的发明相提并论，我们找到了一条从数据中提炼智能的道路，而且还看不到尽头，这个智能是可能这个不断的涌现，甚至将来涌现出这个超过人类的智能，所以这是就是今天人工智能的这个一个一个。

一个基本的一个一个一个现象啊，但所以我也可以说运气很好，搞人工智能的人本身不聪明诶，但是赶上了这么一个一个机会，一个一个时代，然后把把这件事呢就这个做的越来越好，这是第一个观点啊。

第二个观点呢是数据加工，因为刚才说源头是数据，这个数据呢还是要做些处理的，你不能一股脑的这个就塞进去就就就完了，因为如果你的数据有错误，那好了，那那那肯定后边的这个这个模型也就跟着，就就错了对吧。

所以我们我们是这个教育都都教科书，教科书不能随便这个出出版对吧，一定是要仔细的核查，确保里面不出现错误呃，不能说绝对不出现错误，但是但是我们是尽可能的这个呃，确保它的正确训练，人工智能其实也是一样的。

如果你那里边有有很多这个错误的地方，那至少你的这后边训练的那个代价会很多，就像小孩，你给他一个错误的价值观，你想纠正过来，那那那你可能用十倍的百倍的代价，你你都纠正不过来，因为他他一定认为那是对的啦。

但实际上它是错的对吧，你你你想去纠正那个就太难了，所以高质量的数据为就事实本身，就数据本身不要犯错，它本身不要存在错误，可以说这个基础条件。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8b9a0b0cc961f1a37562688026b833ea_3.png)

但是这么多数据靠人类去去处理，去加工，其实代价很高的，今天我们说不要标注了，不像以前对吧，还要打标签，还要画框呃，不要了，哎我们直接拿着这个这个语言啊，各种数据都可以训，但是这还是要做清洗，还是要做。

刚才说确认它是正这个正确这个正确广义的啊，我想就是首先大家可能很难理解什么叫做，你这个这个你不做，你不知道里边有多有多乱啊，比如说你你你弄一个PDF文件，简单的转成文本，你看吧，那里边有很多这个空格。

或者是那个那个一串奇怪的符号，你那玩意要直接喂进去，那好了，那人工智能看到的就是这些，含了这么多乱的东西，它它一定会出出出出错误的，所以在过去的这个56年时间呢，志愿研究院我因为我们做的这个呃比较早。

因为成立那一年呢，就是open n i g p T1这个出现的那一年，所以我们呃做了很多模型啊，但是我们都是开源开放的模型。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8b9a0b0cc961f1a37562688026b833ea_5.png)

所以在这个这个这个过程中呢，一方面在模型方面取得了一些一些一些成果，同时呢在数据的处理方面，也积累了比较丰富的经验，因为像刚才说你要训一个好的模型，前提，你得把这个高质量的数据给给给给给准备出来。

这个准备数据的过程一开始可能相对简单，但是随着这个模型的这个这个水平的提高，其实对人的要求，对这个数据处理者，这个者的这个要求呢也逐渐的提高，一开始可能就刚才说把数据中那些噪音去掉啊。

保证一些格式的问题，可能大家就认为就行了，但实际上后来对吧，就开始要要要要要选择了，你比如网页，那不是随便抓了，网页就就直接就喂进去就就好，因为有很多网页都是些车轱辘，话里边也没有什么价值含量。

和真正有含量的相比，那肯定是这个这个这个内容意义上，这个语义上，专业上它有价值的东西，所以呢对对标注我们叫它标注式或者数据处理，这个工作工作人员的要求呢也越来越高。

这个高质量或者高质量的数据质量怎么定义啊，对吧，然后这里边当然还有价值观，还有安全啊，这样的一一些问题，所以实际上看着现在说我们要自监督学习，不需要那个人类标注了。

但实际上仍然是需要刚才说很多很多加工的，但是靠人类这个成本呃，这个还有管理，还有标准的问题，还有人员的这个能力对吧，你一个人啥都会，这个也也很难对吧，其实是压力越来越大，所以呢我们就探探索。

用人工智能来这个代替一部分，这个人类数据处理处理能力，呃，目前呢已经这个呃我们叫agent对吧，今天大模型大模型agent的形式出现，这个每个agent就是一个角色，就代替某某某类某类工种嘛。

咱们就说数据处理中的工种，已经越来越多的在替代了人类的这个数据工作，人员的这个这个工作呃，应该可以，我就说应该可以啊，有些还这个还没还没有那么准确，但差不多啊，我们可以估计啊。

用A证的替代90%以上的人工是可以的，不会百分之百，因为有些比如价值观的问题，可能我们还要人来核对，但是大部分大家一般想象中的那些数据，数据的处理的工作都可以被人类呃，都可以被agent AI所所替代。

但是他就说你用数据训练一个agent，又用这个agent去去去检查数据，你这不是一个一个死循环吗，这个行不行啊，这是个迭代发展的过程，用今天的agent处理今天的数据，训练出更高水平的agent。

再去进一步处理，它是一个不断循环循环的过程，所以不是一个死循环，本来就是这么一个一个不断的这个渐进式的，迭代式的，往往往往前往前进的，所以我想呢一个基本的观点啊，就是agent主导的智能数据产线。

才是今天，这个也也一定是未来的，这个数据加工的一个主要的形态，呃，在这方面呢呃那个我们已经有了一定的实践，而且也取得了不错的这个这个这个呃成效，最近呢我们听说啊，就是我们也听一个。

有跟一些咱们一些地方的那个接触呃，咱们国家的这个数据标注基地已经七个城市，已经成这个呃呃得到了这个牌照啊，所以我们也愿意呢，把我们过去的56年时间在做大模型的训练，数据所这个形成的一些经验。

最后变成了这样的，我们叫它数据产线好了，这样的一个一个一个成果呢，呃愿意支持各基地的发展对吧，大家不是招一帮人，然后就开始标数据，不是这样的，你再有先进的生产线，跟我们以前造产品。

也是这个其他的物理产品也是一样的，产线先进了，同你的人工的消费呢就会就会是小很多，或者说一一当十对吧，就刚才说90%的工作呢，让让让让AI去干，然后这个人做一些必要必要的工作，这是第二个。

第三个呢就关于数据，刚才讲和智能的关系问题，如何实现这个正反馈，像刚才说的，我们得有数据才能训练出智能，好的智能能够帮助这个数据的加工，提这提高数据的质量，训练要训训练出更好的大模型，更好的智能。

这两个东西如果能正循环起来，正反馈，那这个事情会加速，会这个对对，我们国家这个人工智能大模型的发展，具有战略战略价值，但是呢今天啊至少我们遇遇到遇到的问题，第一个障碍就是钱。

数据集现在有越来越多的这个这个机构，那个开始做数据，但是呢大家把数据当成了一个物理资产，我就不点名了啊，我们国家很有名的一个大媒体，央媒，我可以这么说，做了一个数据，然后问我说你们要不要数据。

说要啊数据越多越好，高质量的意思，我们做了一个数据集，500万，要这么去训练，你看我们这是个我们是一个非营利机构，我不是说我们没有钱，政府也很支持我们，社会也很支持我们。

但是这个模型还没有任何盈利的时候，我现在先先花出几千万，几个亿，先去把数据买回来，然后这个模型训训完之后，到底这个怎么样，还不知道，那这事儿没没有办法做，我相信很多大模型公司也是咬着牙也得买对吧。

有些属于你不买这个工作就就没法开展，就没法这个竞争，但是呢这么做这个产业是没有办法，这个刚才说正循环起来的，所以这一关一定是要这个，要要要把它这个解决掉，所以前一段呢。

然后当时我就我就提出这么一个问题啊，我的想法呢呃很简单啊，要构建一个人工智能大模型的生态，首先要把数据流通问题解决解解决了，我们不能把物理资产的那种管理方式，直接简单的搬到数据资产，数据数据集上去。

数据是一个数字形态的，这个产品它是可以多次使用的，你拿来给我用，我训模型没成功，他就没发，最终没发挥作用，你这时候先给我收500万，这这这个从从从这个，咱们说交易上也也也不合理，而且我用你这一次并没有。

并没有真的说你这东西就给我就没了对吧，不是啊，它不是个物理的东西，用多次都没都没问题，所以让我们这些机构，包括让企业去用，本身并没有什么损失，这种情况下呢，我我觉着呢咱们这个这个这个问题呢。

应该反过来思考，应该先使用后收益，这样的一个原则来制定数据制度啊，这是我们从这个一线的这个，这个这个单位的一个一个想法，第一呢数据一定要确权对吧，是谁加工的，谁做的这个这个这是要这是要做的。

这是要管的对吧，不能，这是这是一个一个最最基本的一个，一个一个条件，在确定数据确权的情况下，我要用你的数据，我一定要确认我不能偷着用，那不行对吧，你有什么数据，咱们比如有管理，有有标签，有有有这个标识。

我用了什么数据，我一定会清楚的说，我这个模型训练用了多少多少多少，数据集都是谁的，这时候你别给我收钱，请大家不要收钱，你让我我还不一定训练成功呢对吧，你这个你让我安心的，大家都去做，都都去训练。

如果我这个模型没有商业收益，或者说我就是个商品，但是但是我根本都没挣到钱，还赔了，公司都亏了，后边一帮数据公司给我要债对吧，那把我一下子就本来可能还活过来，现在一下子打死了。

所以所以这时候大家不要再收费了，因为他都没挣钱，他只不过用了一下对吧，他自己也也没也也没也没带来什么好处，所以这种情况下呢就不要再去追责了，但是如果确实取得了商业收益，而且生意公司做的越来越好。

这模型用的越来越多，我我收益了，按比例该该用了谁的，刚才不是说用了谁的数据吗，你你你你就像那个按一定的比例，当然我说的很简单啊，这背后确权费率监管，这里边有一系列的复杂的问题需要去去解决。

但是我觉得基本模式上，我们的数据制度呢可能是这种形式呢，更有利于这个这个呃发展呃，这个事呢因为我不是专业做数据的啊，我后来跟那个黄刚老师啊，我们北都是北大的，这个他是做大数据的。

他说你说这事对我来说很轻松，我有办法，所以他等会会讲他怎么来解决这个问题，就是不是说想法，而是说他有一套这个现成的软件平台呃，已基本上应该说已经可以解决这个问题了，所以如果是这样。

如果数据和智能能正循环了，正反馈了那个速度就是数据飞轮建起来之后，那就会那就真正我们讲智能时代真的是可期了，将来的这个智能，我们这是我们二零嗯，21年这个这个发布舞蹈2。0大模型的时候。

当时讲的这个PPT啊，就是数据和算力是生产要素，就像今天发电一样的，发电背后有大量的挖煤的对吧，有这个风力的，有水有水水水电站对吧，各种其实都差不多，就相当于今天的数据数据产业。

所以背后是一个庞大的产业，因为这些数据的24×7的数据的处，理和供应，保证了这个大模型，实时的这个了解世界的这个变化，和各各方面的信息训练出的模型，以这个智力服务的方式，像电一样的给我们千家万户。

给这个给企业去去用，这个时代才才算这个到到到到来了，这样的一个设施就叫智力基础设施，就像今天的电力基础设施一样，那我刚才也讲了，电力技术是背后是大量的以能源的这个这个呃。

电力的这个生产为为为为为目标的这个呃，各种各种煤啊，各种电能源的这个是这个呃转换数据，转换成智能，跟电力时代没转换成电是一样的，这个呃产业，所以它是个庞大的产业，但是要理顺这个关系。

不能这个煤矿先上来说，先给我交很多钱，我这电还没发出来，然后还没卖出去，那这个这个生意呢就就就死了，所以最后一句啊，我想我们讲了很多很多很多的，这个过去的几十年啊，讲了很多很多的话计算啊，数字化。

信息化，网络化，虚拟化，信息基础设施，网络基础设施，算力基础设施，其实我觉着呢大概都指向一个方向，就是智能化建设国家治理基础设施，而数据基，基础设施呢是治理基础设施的一个前提。

否则的话治理学就是空空中多隔，那建好之后，我们就进入了一个时代，这个时代我们叫它智力时代，就像电力时代一样的，一个一个用电驱动整个经济社会发展，将来是以治理这个驱动的是整个社会发展，也叫置业时代。

就像工业时代一样的，它把我们从这个繁重的劳动中，体力劳动中解放出来呃，用机器的治理来替代很多人的治理，来进入一个全新的历史的新时期。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8b9a0b0cc961f1a37562688026b833ea_7.png)

好我就汇报这些。

# 2024北京智源大会-人工智能+数据新基建 - P3：介绍“北京人工智能数据运营平台”-林咏华- - 智源社区 - BV1qx4y14735

呃大家好呃，感谢各位嘉宾，那很荣幸，今天在这里头给大家介绍，这个北京人工智能数据运营平台，首先我还是想稍微介绍一下它的一个重要性，那呃我们在过去十几年做人工智能，其实我觉得这三个数据集是尤为重要。

在2022007年，image ne开始筹建，那2012111年发布，如果没有当初的image net，其实并不会那么快出现alex net resnet，这些影响了我们后面所有计算机视觉。

深度学习的这些模型出现，那又如果没有在2007年就已经开始构建的，这个全球最大的网页的数据集，common CORE也不会出现我们这么快迭代的语言模型，也如果没有在2021年启动的。

这个line的这个数据集，这也是一个国外的数据集，这个是有几10亿图文对的，也不会有过去这几年出现的clip，这种跨模态的图文模型，也不会有到现在这么蓬勃发展的多模态，所以正因为有这个全球其实是在国外。

这些呃来自非盈利，都是非营利机构的这些长期的积累啊，如果没有他们，的确，我们很难想象，在过去十几年这么快的人工智能的迭代，尤其是到了现在大模型的迭代，那但是这个这些有这些数据集够吗，远远不够。

所以在这里头，首先我也想给大家分享一下，在我们做这个人工智能数据，尤其是训练数据，我们会面临的三大难题，数据量，数据质量，数据使用，首先数据量虽然come on call数据集啊。

每个月有几10亿的新增的网页，但咱们看回来，咱们中文，咱们中文的互联网用户，全球占比接近20%，但是咱们国内的中文网站的传球价占比，十分的低，这图当然还有一个重要的问题是数据孤岛问题。

咱们可以想象今天大家每天用的APP里头，我们看的新闻是不很多，都在例如像微信抖音这些APP里头，所以这里头就存在很多的数据孤岛问题，另外还有就是多模态，在这个新兴的模态里头，到了我们的视频数据。

未来的3D数据这些就更加少，那再落入到行业数据，这就是又是十分欠缺，那另外数据质量也是很多的问题，我就不再赘述，还有一个很重要的数据使用，我们离不开的一个问题，总是会讨论的是数据版权问题，数据安全问题。

所以摆在我们前面的这三大问题，我们希望不断的去探索，我们必须要去做一些事情，不能等这些问题都解决了，我们才启动我们人工智能大模型的发展是吧，所以这也是为什么，我们智源研究院在过去的几年一直在积累。

来探探讨，那我们通过，首先我们通过大量的去汇聚这些数据集，试图帮助整个产业来积累这个数据量，我们希望打造更多更好的数据处理工具，来帮助大家来提升这个数据质量，尤其很重要的是。

为什么我们要发布这个数据平台，就是进一步来帮助大家去解决，这些数据使用的问题，所以今天等会要发布的这个人工智能，数据运营平台，它是涵盖了平台数据集和工具这些重要的部分。

首先这个北京人工智能数据运营平台呃，北京市科委，海淀区政府，还有中国网络空间安全协会共同推动下，由智源研究院和金融数产共同建设，为什么我们需要这么多的这个呃相关的部门哈，国家级包括北京市部门推动。

的确数据这个问题很重要，也很难，所以必须要借助很多的社会力量，来去共同去推动和解决，那我们在这个数据平台上面呃。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/287b3ec83816623b27555fca6cc40d7d_1.png)

有三种的使用方式，首先是开源开放，我们呃会有一批的数据集是完全啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/287b3ec83816623b27555fca6cc40d7d_3.png)

不需要任何条件可以，大家可以下载使用，这一块很重要，这是我们视为一个社会责任，也是推动科研创新很重要的，第二个对于一些有高质量的数据，我们可能我们会构建这个合作共享，也就是在一个联盟的范围内。

大家去共同构建这样一个数据池，大家贡献多少。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/287b3ec83816623b27555fca6cc40d7d_5.png)

它可以换回多少，这样一种合作共享的创新的方式。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/287b3ec83816623b27555fca6cc40d7d_7.png)

来鼓励更多的企业加进来，去互换这种高质量的数据，最后我们还是会有相当多的是版权数据，相当高质量，高价值的数据是不能够被带出来去使用，毕竟我们今天从版权法的角度，还没能完全解决这个问题。

所以我们也打造了数算一体，这样的一种使用方式，也就说我们的数据存在一个安全域类，它的加工和模型的训练，都不出这个安全域模型呃，团队在通过这个安全预期进行呃，数据的加工和训练之后，带走的是模型。

数据不带走，这样子进一步的要保障这个数据的一个安全，所以基于这样三种方式，我们整个平台支持了多种的模态，包括文本图像视频等等，也打造了全流程的数据处理工具，前面黄老师一直提到，我们希望用AI的方式。

来解决这个数据标注的问题。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/287b3ec83816623b27555fca6cc40d7d_9.png)

这是我们的一个目标的方向，然后另外还有一个很重要章是说，为了支撑数算一体，我们把数据和算力打通深度融合，那前面是平台，后面是数据，我们现在在今天发布的这个平台上面啊，已经聚集了两大板块的数据。

一个是适合于用来做通用模型训练的，通用数据集，已经积累超过了700TB的通用数据集，放到了这个平台上，此外我们也愈加发现，看到行业垂类的数据很重要，所以我们也打造了行业的专业板块。

来放置这样行业的垂类数据集嗯，那这些数据也是基于过去这么多年，资源的一个资积累，以及刚才谈到的相关部门，以及咱们在全国超过30家合作企业，贡献的所有数据，我们也会以开源开放合作。

共享数算一体三种方式来提供给大家使用，那进一步呃，今天也随着这个平台的发布，也进一步介绍一下，我们有两个很重要的发布的数据集，一个是今天早上在主论坛提及的，全球最大的多行业中英文双语数据集。

这个数据集涵盖了18个行业呃，分为开分为开源数据和非开源，也就是可以向我们定向申请这个数据，那总共有4。3TB呃，还包括医疗以及教育两个行业，它的微调数据和这个呃，人类反馈的这种对齐数据。

那大家可以看右边右下角这个图，这个图上面那个橙色的bar是指，我们在某一个行业，我们的这个数据集量，蓝色的是目前全球已经开源的，在这个行业里头的数据集，大家可以看到我们在几乎所有的数据集上面。

都远超现在全球已经开展的所有的，在这个行业的数据集的总和，所以我们说这个数据集的推出，势必帮助大幅提升全球各个行业，开源数据集的总量，那为了证明这个数据集的有效性，我们也针对医疗行业进行了一次实验。

我们在我们的基础模型上面，把这个数据及医疗行业，其中18行业头医疗行业的数据进行一个，首先是预训练呃，持续预训练，然后提取它的SFT数据，然后再做LHF的训练，做完整一个这样一个流程之后。

我们可以把一个普通的基础模型，在医疗行业的一些评测上提升20%，所以这意味着是说所所有的行业企业，您都可以使用这样子的数据集，重复我们这样一套流程，去获得您的行业模型的提升，并且我们这样一套做法也会呃。

就在这两天在阿凯放上面会放出来。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/287b3ec83816623b27555fca6cc40d7d_11.png)

那另外一个今天也是发布的很重要的数据集，是千万级的这个指令微调数据集啊，那大家向来知道在去年大模型起来很多开源，但是众多的开源里头，没有哪一家厂商把自己真实的这个，SFT数据集开源出来。

所以几乎所有的大模型企业，它要针对一个基础模型进行SFT训练的时候，不得不重构自己的SFT数据集，因为大家都视为这个是他自己的秘密武器，所以这一次智远也是，我们重塑了整一个SFT这样，指令微调的数据集。

并且进行了呃我们的模型验证，那目前呢，呃我们是已经完成了300万条的数据集，其实我们整个千万条的数据集已经准备好了，但是我们是属是处于逐步验证，我们要在多个基础模型上。

通过这样的数据集来验证它的一个效果，真正能达到提升整个性能质量的，我们才敢放出来，那目前我们已经完成了300万条的这个呃验证，然后已经放出来，大家可以在这个开源网址去下载。

那这个这个这个效果大家可以看哈，橙色的是我们的，我们是用那个MIRTB这样一个模型，去做一个指令微调，它出来的效果比la的拉玛三的8B的insurance的，以及后续后面的这些，包括3。5。

包括GERMANY都要好，所以和大家可以期待把这个数据集拿回去下载，用于您的这个下游的这个chat模型的指令微调，那当然这样的数据及建设，也是基于我们很多的技术的加工哈，包括多标签的数据分析。

要保证多种能力的一个分分布，高质量的数据筛选，还有数据合成等等，在这人因为时间关系我就不详细说，那最后刚才提到了工具，工具是我们很重要的提升数据质量的的的武器，我们这次也是把我们智源研究院在过去几年。

一直迭代的工具进行了一个完全的升级，通过同样的工具我们去处理这些数据，所以今天这个flight data这个工具集啊，也是升级到了3。0，大家可以在这个开源网址进行下载使用。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/287b3ec83816623b27555fca6cc40d7d_13.png)

最后呃大家如果有看今天上午的king呃，那个主论坛啊，open AI的RAMESH，他提了这句话，呃我我我挺喜欢这句话，虽然不是百分百认同，他说道说，与其我们固定住数据集，而不去攀登这种。

我们的目标函数和模型架构的话，现在他认为应该是固定住目标函数和模型架构，不断在数据集的高峰上进行攀登，那其实这个也是印证了大家的一个，行业共识和产业共识，数据包括数据的质量，包括数据的认知。

对模型的性能和它未来的智能，起到至关重要的一个因素，坦白说大模型领域数据是一个很深的研究，我们我指的是我们整个产业，包括学术界对于数据的问题，还是初步的一个研究，我们所有的力量还是刚刚起步啊。

所以我们也呼吁希望有更多的力量，无论是数据汇聚还是数据研究，可以投入到这里来。

# 2024北京智源大会-人工智能+数据新基建 - P4：介绍“行业数据集-场景应用创新计划-南新生 - 智源社区 - BV1qx4y14735

我代表中国互联网协会啊，来介绍一下，我们要，启动的这项计划，这个计划的名称叫行业数据局，场景应用创新计划，那么在通用大模型如火如荼的今天啊，其实更多的企业啊，更关注的是人工智能在行业里边的应用。

是行业应用模型，行业大模型怎么样落地的问题，那么由于数据是界定大模型，智能边界的关键因素，再加上行业大模型的数据呀，由于它的专业性，稀缺性和不流通性是一个严重匮乏的，这就制约了行业大模型的落地。

所以我们说啊，行业数据局是大模型落地的重要的基石，也正是基于行业数据局对行业应用，对行业大模型落地的重要性，所以我们中国互联网协会联合智源研究院，按照国家AI加战略的指引，为了解决行业的痛点。

我们发起这个行业数据局场景应用创新计划，那么这个计划呢是有基础的，这个基础就是刚才林院长介绍的，他发布的这个平台里边其实也介绍了呃，智源研究院在行业数据局里边已经有的积累，这就是他刚才讲的。

我们已经覆盖了18个主要的行业，有高达4。33T的数据，今后呢还会拓展到30个主要的行业，那么这个计划呢相对也比较简单，分三个部分，第一个部分也是刚才林院长讲到了，我们会进行行业数据的发集。

行业数据局的发布，同时征集应用创新的案例，那么第二个要做的事情呢，就是搜集行业数据的需求，征集合作者合作的方案，第三个呢就是对应用创新的案例，进行评选和推广，那么简单的三个部分，时间安排上呢是今天发布。

争取在10月份之前完成第一轮的数据集的发集，应用案例的征集，需求的收集和评选推广，争取在明年的1月份之前完成第二轮，这就是时间的安排，所以欢迎广大企业所有有意愿的能够参与进来。

那么我们也利用今天的机会啊，就给大家一个二维码，请大家扫描啊，我们便于我们征集行业数据的这个愿望清单。



# 2024北京智源大会-人工智能+数据新基建 - P5：发布“北京人工智能数据运营平台”暨“行业数据集-场景应用创新计划”启动仪式-中国互联网协会- - 智源社区 - BV1qx4y14735

让我们有请参加发布及启动仪式的，领导和嘉宾啊，一同上台，共同见证北京人工智能数据运营平台的发布，和行业数据局场景应用创新计划的启动，北京市科委董其超副主任，北京市海淀区董超副区长。

中国互联网协会代委副秘书长，智源研究院林永华副院长，北京能源集团副总经理张凤阳，中国移动研究院人工智能与智慧研究中心，常务副总经理邓超，中国互联网协会，人工智能工作委员会秘书长邓凯，有请各位领导。

请各位领导嘉宾把手放在屏幕上方的，这个手印的位置，然后让我们一起来见证倒计时，321，祝贺北京人工智能数据运营平台发布及，行业数据及场景运用创新计划。



# 2024北京智源大会-人工智能+数据新基建 - P6：基于数联网的大模型智能体数据供应链-黄 罡 - 智源社区 - BV1qx4y14735

那个呃非常感谢这个呃铁军理事长，邀请我到这个呃智源大会来分享，我们过去在这个呃苏联诶，这个数联网上的一些工作，然后这个题目这个可能是不对啊，其实我们这个工作呢就是不是说马上就做完了。

其实去呃前年那个GPT发布的时候，其实我是焦虑了四个月，然后焦虑了四个月呢，反正后来一下想明白以后呢，我们实际上是差不多花了一年的时间，把整个这个这个问题给解决了，所以也不是说马上就解决了。

然后我整个这个呃分享呢，呃因为时间因素，所以说呃更多还是从这个原理，就是一定是从科学原理上说，它能把这个问题给解决掉，所以呢我们首先呃我不做大模型啊，我是做数据的，所以首先是从这个呃数据危机的角度。

我们看说他到底这个一天到晚说这个大模型，缺数据是怎么回事，第二个呢，就是实际上就是我们说这个从数据的视角，那这个问题能不能解，然后最后呢，实际上就是刚才前面很多专家也在说。

特别是铁军说那个先用后付费对吧，本质上实际上是我们想重塑，移动互联网时代的数据飞轮对吧，那有没有可能，所以我们也就打造了一条这个呃数据供应链，我们现在目前呃内测已经50多个高校，差不多快半年了。

应该应该我们自认为已经找到了这个呃，数据飞轮的一个一个一个解，所以今天就介绍这个，首先呢我们呃从数据视角呃，所谓的大数据大模型，我们认为都是第四范式呃，第三范式大家知道对吧，业务驱动计算密集。

做计算仿真的CPU单机操作系统APP，然后所谓的我们从数据角度看，第四范式就是把第三范式产生的数据，一股脑的塞给第四范式的大模型，当然也包括各种小模型对吧，这个时候呢其实它整个模式是模型驱动，数据密集。

我们说GPU大模型智能体，所谓的这个高质量危机，我们可以看到，实际上是说这个呃万维网上，我们可以相对容易的以开源方式获得的数据，不够了对吧，其实我们可以看到这个，这个这个实际上是很早的一个数据。

但是其实基本上反映了这个现状，就是我们真正的高质量数据，都是藏在用HTTP开源访问不到的，就你要不就登录，要不就藏在APP里面的，所以这就是一个，所以我经常说这个V和机制，首先V对吧。

是说呃大家都想的是说这个呃数据不够了，然后这个大模型这个skinning law还能下去吗，那大模型还能再涌现更高的智能吗，这是V，但是呢我更多的看到的是机对吧，就是机遇是谁能大家想想。

就ChatGPT，严格意义上是以4%的开放数据，加上GITHUB和百科全书里的一些声网数据，训练出来的，已经把我们给人类给呃震惊都不行了对吧，所以说谁能够搞定96%的思域数据。

那么谁的大模型就绝对占据了，在除非再出现新的一类，我们说内老的啊，或者像铁金做的那个脉冲啊等等新的对吧，但在现在我们说大数据大模型这个技术路线下，它一定会占据主导地位。

那我们说这个事情实际上从我们搞数据的，其实我们认为还是要提一下这个第四范式对吧，就是呃实验观测理论推演与计算仿真，到现在第四范式呃，我个人认为是从第四范式到了商业领域，实际上是大数据。

然后一直到今天我们的大模型，我认为它覆盖到了全域，我个人认为实际上是呃到今天的大数据大模型，实际上是第四范式，从科学领域扩展到了整个领域，那么我们再来看看第四范式为什么叫数据密集。

其实包括大家可以看一下这个jim green，2006年给的定义对吧，第四范式的目标是所有的科学文献，核数据全部在线且可以互操作，所以大家想想看，我们刚才其实呃特别刚才那个呃，呃冯总说的很对对吧。

我们现在大部分的语料数据，都是用来服务于信息系统或者信息系统产生，实际上呃第四范式已经讲清楚了，其实以前我们更关注的是业务数据大模型，现在更多要的是我们说是文献数据，或者叫文档数据，其实在第四范式里面。

再从概念上我们说早就定义了，说两个都要，只不过我们以前更多聚焦的是，而且在那个大数据时代，更多聚焦的是业务数据，所以这个我们看原理对吧，那我们说为什么要数据加文档全在线，它本质上实际上是什么。

实际上是基于数据复用，能够实现科学研究的复现和探索加速，这是我21年就开始讲的一个PPT对吧，就我也我也不换BT理，按呃理解路线，5月份发布对吧，那个论文把他的数据及算法全发布了。

然后百度两个月换成中文，就是earning对吧，文心纳模型，然后FACEBOOK就是也两个月换成自己的聊天数据，高质量数据，然后出来robot，然后后面当然无数的出来。

然后我们简单看一下google g s是google score，我们就可以看到，其实大家想想短短的两个月，这么复杂的一个工作，就影响到了百度和meta，以及到现在也就5年五年五年多的时间对吧。

将近10万次引用，这就是所谓的价值，因为从科学研究的角度，论文就是数据价值的释放，所以我个人认为这就是典型的一种，这个我们说为什么文献要在线和互操作，那我们说它的理想情况是什么呢，其实我们此前就只上这。

前年我们就开始做这个demo，实际上就是所有的数据论文，如果我们真的是进入到理想的第四范式，或者数据都可以畅通无阻的情况下，实际上我们可以一键去复现科研论文里的，所有的算法和它的case。

并且进行探索对吧，但是这个问题大家可以看到，其实这一套到今天其实都依然没有实现对吧，我们说问题是什么啊，我我我我其实是搞软件的对吧，我们从技术角角一看，实际上我们发现说。

实际上论文数据加代码之间的复杂关系，以及论文数据代码之间，包括其他的，大家可以看到刚就刚才那个图对吧，其实他们有一个复杂的关系，然后今天我们已经有了3。1万篇论文，3。1亿篇论文，然后呢。

包括我们有很多我们所谓的文文档文献对吧，大家可以想象一下，其实今天在互联网上，由于大数据和大模型的存在，已经在互联网上形成了一个，由数据形成了一个巨复杂网络，但这个网络很遗憾。

第一很像我们的万维网数据封装的网页，网页网页也进行操练对吧，但是整个这一个地势范式或者大数据大模型的，这个数据的网络用外卖网是看不到的，看不见摸不着，用不起来，所以就没有网络效应。

那这个事情呢其实非常巧合，我们说2006年，jim gray提出了地势范畴的概念，在同年互联网的发明人和万维网的发明人两位，我个人认为是改变人类文明的两位大师对吧，同时发文提出。

互联网和万维网应该向数联网引进，大家可以看到罗伯特卡恩TCPIP发明人，机器机器之间的互联应该演进，把上面的数据和数据应该进行互联，外面网不能势力对吧，是网页和网页，它认为是文档和文档的互联不够。

必须要把业务数据加进去，就提出了link的data，所以我们可以看到这两个对吧，比如我们简单以罗伯特卡恩的这个例子，因为它是TCPIP，大家都很清楚，机器有一个IP地址，所以他的思想非常朴素。

第一数据有一个标识就DOI，现在我们所有人发论文都是有了这个号，你的论文就发了，然后呢呃每个论文它有原数据，作者什么关键词等等，然后这个论文的实体三要素基于这三要素，为了让它变成全网唯一的一个独立实体。

他就建立了一套就包括中国在内，建立了一套DNS以外的第二套全球域名系统，叫DOA，这套系统，实际上我们今天的论文，几乎所有的出版物全在上面，并不是在互联网上，并不是在万维网上。

所以可以看到它就是这样一个呃，呃畅想的一个东西对吧，这实际上已经到了今天，那我们从这个简单可以看到，所以也可以看到呃，呃特别夏季赛，实际上那个数据基础设施，我现在一直呼吁说，实际上早就提出来了。

我第一次范思这本书对吧，就实际上就是呃总结了jam grade的很多概念哈，然后呢实际上是2009年的这本书，在前言里面，golden bear就是高性能计算的先驱，他就明确在前言里面说了。

说第四范式从技术角度的dream，就是技术梦是有一个无处不在的date infrastructure，干什么啊，大家可以看上面的可能很小的吧，叫做跨组织的数据分享，所以说应该从概念的角度，我们认为。

实际上本质上就是希望有一套这种全新的，在互联网和万维网上能够长出来的数据和数据，能够互相分享连接的一套全新的基础设施，那么从这个角度一看呢，实际上刚才已经介绍了他们两个，其实。

因为整个基础设施的演进是非常非常缓慢的，所以在这个时候，基础设施还来不及演进的情况下，有很多的这种哎临时性的，局部性的一些平台工具，比如说数据空间仓库，比如说数据湖，数据网格，数据编制。

国际数据空间隐私计算都是属于此类，所以从这个角度呢，我个人认为因为现在大家都在说，特别中央在说，要适当超前部署数字基础设施对吧，我个人认为实际上是从这张图就可以看到，数据基础设施不是适度超前。

实际上是严重滞后于我们的大数据，大模型发展所需要的，数联网的规模和效率的增长需求，不是超前，是落后对吧，当然这个时候实际上全球都落后对吧，所以我个人认为实际上是特别是数据局提出来，要建数据基础设施。

这个定位是非常非常关键的好，第二个我们就说能不能从数据的角度，找到我们大模型数据危机的解决之道，我们简单诶做个广告对吧，我们数据空间是大数据领域唯一的全国重点史，实际上这是中央呃。

基本上是实际上从20年就开始，给我们批复了一个实体机构，然后23年呢就最终拿到这块牌子，然后呢，这个主要是我们的带头人梅宏院士，跟我们这个研究院或者我们这个实验室相关的，实际上就这么三句话呃。

解读其实上反过来解读就是我们当时就提出来，大数据一定会带来万物互联，人机交互，天地一理的网络空间，实际上这是数据空间，那么它必然需要新一代的基础设施，也进而需要全新的大数据的核心技术。

所以应该是反过来解读，那么呃基于此呢，就是中央批准我们其实团结优势的单位，我们就呃使命就是负责，要研制数联网和数据空间的关键软件，并且支撑它的发展，那么我们的逻辑是什么，为什么是苏联网和数据空间。

这是我们的一个解读，实际上前一阵那个孙林辉院士也在人大上讲了，类似的这个概念，因为我们也长期进行这个交流呃，第一我们认为网络空间最早是机器和机器，通过网络连接形成的计算空间，1。0时代，2。

0时代就是随着万维网的出现，导致人机交互变得特别频繁，而且是变成主流模式，所以人机当然中间还有一点点，物机二元两种世界进行通过信息，因为网页里面的全部信息形成了信息空间，那么到今天。

我们显然是人机物三元只能通过数据进行连接，因为信息已经经过加工了，所以呢由此形成数据空间，特别是我黄色标出来的，其实大家可以看到网络空间1。0，本质上是69年美国启动的阿帕net所诞生的，而网络空间。

信息空间，实际上是93年美国启动的NII计划，一举奠定了美国，我们说在信息时代的主导地位，那么到了3。0时代，其实我个人认为大家可以看到，至少从我们所知的全球发布的战略来看，实际上中国已经适当超前对吧。

17年发布，而美国联邦数据战略，欧洲数量都是20年，所以在这个视角下，我们看我们中国是不是有希望在网络空间，3。0的人机物融合的数据空间领域，形成我们的领先地位，这就是我们这个全国重点影视的使命。

那么从这个视角呢，也是为了配合那个数据局定义的，这个数据基础设施，然后呢我们给了一个解读，实在这里面呢实际上是包括刚才冯总谈的是呃，呃中国移动的苏联网，实际上是我们都认为是解决互通和互操作。

实际上它核心是什么呢，实际上三个互联，就是我要发现并且定位数据互通，数据要能够交换，互操作，要能正确使用，那么从这个角度，我们其实因为时间关系我就不展开讲了，就是实际上万维网是从技术基础上就是不符合。

所以这也是为什么伯乐斯利也好，呃罗伯特卡恩也好，都认为要有全新的一套，那么基于这个呢，概念也很简单，首先我们是和罗伯特凯恩一起合作，就是干什么概念呢，就是我们只解决分散在互联网上的私域数据呃，公益数据。

因为HTTP就够了，我们我们不关心对吧，那么在这个上面呢是把数据封装成数字对象，数字对象彼此之间通过与用关系连接，形成一套全新的软件定义的数字对战网络，然后上面再进行数据空间以及大模型。

那么这个方案呢当然我们简单说一下，我们其实呃为什么说是扩展数字对象架构，因为呃卡恩的那罗伯特，卡恩提的那个毕竟很早了对吧，所以说其实我们在标识在那个雨用在那个纯正。

还有在这个协议上都做了一系列的全新的创新，那么也因此呢，应该说整个这一套技术应该还是属于这个，我们具有自主原创的，但是同时也是国际化的一套技术体系，那么在这个下面呢，最终为了配合我们这个整个呃。

我们这个数联网的建设，其实我们现在也研制了一款这个数联网一体机，然后这一个呢，其实今天上午也刚刚和中国移动信息中心，那个完成了交流，我们在8月份数博会会发布出来，中国移动，苏联猫和这个全国重点视数联网。

一体机的一个合并版本，也希望到时候能够得到各位专家和领导的，这个呃支持和这个指导，那么整个呢我们本身就是开开放标准，开源软件，所以都可以用对吧，所以这就是然后呢，我们整个苏联网呢。

实际上现在是按照这种就是经过我们呃，呃过去呃33年的建设，首先是行业建设，互联网解决行业内部的数据问题，行业行业之间跨域有一个公共互联网，就跟公网一样，但它主要是解决发现定位和调度，所以这也是呃。

我个人认为应该是由数据局来主导统建共用的，那么最后呢在跨境方面，因为数据太重要了，特别是前一阵美国已经明确，对我们禁运美国的数据对吧，所以这个时候，其实数据的流通已经跟互联网时代不一样了。

实际上目前基本上都是数据海关的模式，那这一块呢我们也已经在技术上完成了，和doa solid以及欧盟的IDS，以及甚至以太坊这样的相关的，我们认为是一个巨大的数据空间的一些。

技术上的完成了互联互通的一些工作，那么比如说在行业方面，有一个重点研发计划，就是1000家临床实验数据，700家药物企业，每年3000种新药临床实验数据的流通，然后呢传统思路建一个共享汇聚平台。

但是在这个场景里面不存在，为什么1000家医院卫健委管700家药企，跟他们比起来只是一个小小局，所以说他既没有权利也没有义务，其实去建一个汇聚式的平台，所以只能用数联网这种分布式。

就每个医院装一个苏联网前端一体机对吧，药企也装一个，你就调什么数据好了，调完以后把它销毁，所以整个这一套，那同样我们说因为这里面有很多医院，药企在里面，既有医院已经开始基于这一套进行。

医院之间的临床实验的这个研究，同时也有药企在开始探索药物的全生命周期的，这个数据和模型的驱动，那么呢在公网方面，我们主要是支撑中国工业互联网研究院，进行工业数据的要素登记，这样的话就可以实现在整个。

因为中国工业是个大工业的概念，能够实现整个工业数据领域的这个登记和流通，然后呢呃在跨境方面，我们主要是支撑这个上海跨境数科呃，进行这个和国际上进行对等合作的，基于苏联网的这个数据海关。

那么特别是在上个月呃，上海临港呃，陈书记带队去，以及目前和巴西和智利已经签订了相关的协议，希望未来在巴西和智利也建设呃，基于数联网的国际数据港，这样的话就能实现我们自己的这套技术，走向国外好。

那简单分析完了以后，最后就来讲一下我们解决大冒险，就是过去一年我们是怎么解决的，我首先我的理念呢实际上是呃，我认为呃，只从大模型的视角解决大模型的数据问题，肯定是不够的。

因为我们都知道大模型真正产生价值是A证的，而agent的从我们的搞数据的角度很简单，就是对业务数据的读和写，所以这也就意味着，必须要先解决agent或者业务数据的读写的前提下。

你才可能把业务文档的数据拿出来，喂给我们的大模型对吧，当然这也要解决，铁军说的就是到底怎么个呃，先使用后付费的问题是吧，所以呢我们整个这个工作呢原理非常简单，就是把整个大模型从训练微调到增强。

一直到AH，整个就和推理整个把它全拆开，把中间的数据相关的全部变成数字对象，然后形成一张网，当然这张网不是专门给大模型的，而是我刚才说的，实际上是全国的那一张数联网，那么在这个上面呢。

然后我们做了一个什么热呢，实际上就是呃重点汇报一下呃这个系统，这是个真实的系统啊，其实但这这这现在是个截图，实际上大家可以看到就是呃重点是回答这个呵，铁去受字，要第一，我们说我们首先解决私域数据问题。

就是把私域数据导到我们的数字对象仓库，然后我们的大模型会自动的对这些数据进行，分门别类的处理，处理成语料数据向量，数据库表，数据库表接口，这些就是业务数据，实际上就是把业务数据和业务文档给它。

分别进行处理，然后在这个时候呢，我们就是让思域的用户自己用大模型处理，他的私域数据就可以了，他压根不用管外面任何事情，那么在这个过程中，其实我们搞大模型都知道，其实你的每一次聊天，对他的每一次点赞。

或者说他的问题不好，你应该怎么修改，其实隐藏了你对向量和语料数据的，觉得是满意还是不满意，实际上也就意味着我们知道其实可以知道，因为我们是用的一套信息增强对吧，rag的我们是知道，第一你有什么实际数据。

这个实际数据你可以给别人，当然我们说只是可以对吧，要征得你的同意，第二你缺什么数据，实际上通过聊天是知道的，特别是在你反复纠结一个问题的时候，这就一定意味着，其实这个大模型怎么都生成不来，你要的东西。

实际上它缺余量或者缺向量，那么收集到这个信息以后，其实我们就会通过我们的苏联网前面讲的，因为苏联网只是网上的，只是原数据，没有数据本体甩出去，然后我们做一个全网的数据的自动撮合，那什么概念。

大家可以看最左边那个就是前一阵给那个呃，北京市盈利数据呃，呃现场演示的就相当于呃，我们要生成1000字的这个呃，北京市的产业空间布局，然后呢这时候我们就可以看到，其实我们会把现在是55个高校。

当当时是20多个高校的，100万篇相关的内部报告，实际上公开发表论文不多，然后呢它里面跟这个北京市产业工具相关的，反正都向量化以后，反正最终命中，大家可以看到左下角那个，就是这一篇报告的生成。

用了哪一个高效的哪一个向量数据，不是语料，因为我们这是A卷的，这个时候，然后呢满意了你就可以付钱，付了钱以后，实际上这个时候，这个钱我就可以分给这些向量数据，这是我们说先解决agent的向量数据的。

大家愿意拿出来就是每一次提问，每一次大模型A景的使用，只要他挣到了钱，导我们就会要求，因为我们是用一套智能合约给他锁死的，然后基于解决完这个问题后，然后呢再来看啊，右边这个大模型，我们这有个大模型商店。

这个时候呢其实我们就会提供一些相关的余量，因为其实向量数据说白了，其实很多时候是可以变成语料，或者原始数据丢给这个呃训练基地对吧，训练基地自己按自己的调整去怎么去封装，语料是随便，那因为我们的。

所以我们的前提假设是私域数据的拥有者，已经在智能体的使用过程中，第一满足了他自己的要求，第二他也从别人的智能体使用中，通过刚才那个向量命中，他已经得到了收益的前提下，他已经第一解决了他的心理障碍。

第二他其实已经分到了一部分的收益，那这个时候我个人认为他其实在心理和这个呃，这个经济上已经完全基本上能够接受，说我把这个数据顺便卖给或者送给基础大模型，当然中间还有一个很关键的，大家可以看那个小字里面。

其实在我们这里面基础大模型也是可以收费的，所以这就解决了呃，我上次和铁军一直聊的对吧，就相当于说其实呃智源的那个模型，基础模型训练出来以后，他怎么怎么收益，实际上是就进到agent的对吧。

然后呢形成了这个相关的语料，又从这边回到，所以呢这个时候甚至我们可以认为，其实基础大模型连先使用后付费都没有，完全是可以说你这一个用户给基础大，某个基础大模型贡献了多少token。

那么你未来在用这个技术大模型，解决你的agent的时候，实际上是个交换，不需要交易，所以这是我们的一个呃，目前基本上就是按这一套一套逻辑设计的对吧，然后呢整个因为时间有限，我就简单了。

实际上我们现在这就是那个武术无高下，现在我们已经开始呃，呃以实训为这个呃场景开始在推了，但其实现在我们也在呃园区，还包括那个钢铁几个领域，基本上都在推，这个，就除开前面的我们那个传统的业务数据的啊。

我们其实现在已经开始了，就是以解决相当于其上呃我我我简单的说，实际上就是把大模型智能体的数据使用门槛，打到最低的，以这个为目标再进行相关的推广，那么呃最后就是说，其实呃我们因为我实际上是做这个的。

是做软件的，这个是我们19年的时候，其实是国家唉，第一个以人机物融合为主题的，国家重点研发计划，所以当时我汇聚了这个八个国家重点制，工程实验室，我牵头，然后我们花了一年半的时间，回答什么叫人机物融合呃。

最后在很高，很幸运的是，最后还是在19年12月中期验收的时候，在文津酒店我们就基本上回答了一个满意的，大家可以看到所有的人机物的东西，全部封装成数字对象，然后可以以低代码的方式把这些进行编程。

最后一运行起来，是可以由这种实时的进行数字孪生的监控，所有的关键状态全部存到区块链上，所以大家可以看到，其实当时什么元宇宙，那些3D代码都还没有对吧，所以说我们当时把这个做完以后。

认为这就是数据空间的未来，就是什么概念，就是以数据为中心表征和操作，在网络里能够看到的，所有的人机物的状态和行为，实际上这就是今天我们大家梦寐以求的，智能体环境，所以我们下一步的工作实际上就是。

当然第一步工作我们就发现数据很好，第二步工作发现智能不够，但你今天我们就准备把刚才说的那一套唉，大模型和智能体的数据供应链的整个系统，再往这上面一压，我们就觉得其实可能接下来就是智能体。

或者所谓空间智能，或者所谓的那个离声或者聚生智能，可能至少从软件或者从数据的角度，应该就不成为问题了，好我的汇报到这。



# 2024北京智源大会-人工智能+数据新基建 - P7：面向大模型的数据工程-李荪 - 智源社区 - BV1qx4y14735

各位专家大家下午好，我是来自于中国信息通信研究院，人工智能研究所的李孙，然后今天呢下午给大家去分享的主题呢，是面向于大模型的数据工程呃，其实这个题的话，其实对于中国信息通信研研究院来说的话。

我们可能主要承担两个职责，一个是叫国家高端专业智库，然后另外一个是创呃产业创新发展平台，所以的话其实我们做的研究，更多的是我们集宏观，然后再结合产业的微观，然后做一些中观的研究。

也就是说我们去更多的支撑政府，把顶层的一些规划，我们去结合产业实际的情况，然后找寻一些落地的方法和路径，然后明确的一个发展的方向。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_1.png)

然后今天的分享的话，主要我会先去介绍一下，人工智能现在数据的一个现状和挑战，然后还有就是我们面向于大模型的话，如何去做数据的工程，然后为大模型更好的去，更高效地提供这种高质量的数据集。

然后最后去介绍一下。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_3.png)

就现在我们在这方面的一些研究的进展啊，呃我们首先来看的话，其实随着整个人工智能的发展的话，它其实每一阶段呃，现在我们看人工智能的三驾马车叫算法算力，然后包括我们的数据，然后现在的算法的话。

到大模型时期的话，它整个的呃能力体系，包括刚才其实有很多专家有介绍到，他，不管他对于这种理解的能力，推理的能力其实是完全是有了一个呃质的飞跃，然后而且的话我们是按照算力来说的话，现在算力的话。

其实国家也在提这个算力一体化，然后为我们整个人工智能整个算力的基础设施，其实也提供了很好的保障，但是我们现在看到数据来说的话，呃其实随着人工智能的发展路径的话，现在数据的他的要求是完全是发生了一个。

很直接的变化，首先来说的话，就对于大模型来说，它要求的是很非常大规模的这种数据，同时的话它类型也是多样化的，尤其是现在我们是就多模态的数据，它也要进行这种信息的对齐。

然后这跟其其实我们叫上一代的人工智能，完全是不一样的，就上一代的人工智能的话，其实我们更多的是叫这种单点的孤立的，就原来我们叫就叫呃，我们专门去研究NLP，然后研究CV，然后研究语音。

然后我们针对于小模型的话，单独为它去构建数据，所以在那个时候的话，其实大家对于数据的认识，或者说对于它的重要程度，好像还没有呃那么的敏感，那现在为什么现在对于大模型时代，它的这个我们对数据关注度这么高。

是因为它现在的质量要求是极高的，这个我们去换算一下，因为现在对于大模型训练的话，尤其是在预训练的阶段，他投入的成本是非常高的，这里边就涉及到我的算力的成本，涉及到人力的成本，还有一些时间的成本。

那这里边如果我的数据质量不高的话，它我中间我会比如出现宕机，然后我要进行版本的追溯，那这里边其实很大的程度都是跟数据有关系的，然后而且的话其实我们从呃就大家可以看到，就21年和22年大概是在这个周期。

就是世界上一些人工智能的顶尖的学者，也在提这个data centric AI，就是我们上一代叫以模型为中心的人工智能，然后慢慢的话其实未来的话呃，现在模型为中心可能到达一个瓶颈。

未来我们人工智能的重点的发力方向是什么，其实核心就是数据，其实现在尤其大模型来了，也就印证了这个观点，这个我们来看的话，就是说呃这个特别像第二次工业革命，这个我们第二次工业革命的核心。

其实是先有了发动机，然后又有了汽车，那我们汽车想要在路上跑的时候，其实我们要有高质量的汽油，那这个汽油的话，我们从石油怎么历练成汽油，然后包括这个汽油的运输，然后以及我们加油站的建设。

其实就特别像我们现在人工智能整个模型，我们要去快速的奔跑，那整个我们这个能源，然后以及这个就我们叫数据，可以换算成这个汽油啊，就是这个汽油的整个全产业链条，怎么去保证未来人工智能可以快速去发展。

和应用落地，其实呃咱们国家就一直在推动，整个包括像数据要素，包括人工智能的整个发展的话，其实大家去梳，我们去梳理了整个呃一些相关的一些政策，大家可以看到，其实里边的话已经不断的在提出来。

就对于人工智能来说，要不断的去提供整个高质量，数据要素的整个供给，然后包括一些先行先试的一些数据的制度，然后包括的标准，然后包括我们整个数据的供给，和一些市场的交易，以及相对应的资源建设。

然后在今年的5月份的话，然后提出来建设国家级的数据标注基地，就数据标注其实对于人工来认，人工智能来说是非常关键的，因为它呃其实更多的加入了人类的知识，然后尤其是现在我们大模型，要去跟行业去结合的时候。

然后它是需要很多这种专家的知识，那未来的话整个数据标注，我们认为它其实是一个很核心的环节，一方面它可以更好的把我们整个呃，原有的数据加工承重高质量的数据集，然后更好的去释放这个数据价值的要素的释放。

然后同时的话也为人工智能，源源的去源源不断的去提供这个，高质量的数据集，然后这个的话其实数据标注基的建设，其实这里边的话也提到了，就是六个方面的一些重点的任务，就是它里边不仅是数据本身。

它是从整个权威度来看，这个这就涉及到有技术的创新，产业的赋能，生态培育标准应用人才，就业和数据安全，所以说未来的整个数据标注，包括呃为人工智能数据高质量的发展的话，它从整个机制体制。

包括我们的顶层规划来说，都已经有了很全面的一个考虑，然后人工智能的整个工程化落地，其实是这两年我们一直重点在关注的一个方向，就是我们叫人工智能逐渐从实验室走向了产业，那工程化落地。

那这里边工程化落地它就会涉及到方方面面，然后包括有这个硬件，包括算力，其实数据也是很核心的一个环节，它是直接去链接我们底层的整个人工智能，包括算力，基础设施跟我们场景应用很关键的一个环节。

因为对于数据来说，数据就是其实刚才很多专家有提到，就数据是本身是我叫模型应用方拥有的，但是呢呃这个我技术提供方，我本身是没有这些数据的，但是我怎么去融合融合这个中间的这个鸿沟。

那这里边其实呃我们跟很多这个就相关的，这个就是产业的用户方和技术提供方，有交流过啊，大家经常会陷到一个问题里边，就是说您有什么样的数据，和你要什么样的数据的一个问题，那这个鸿沟到底怎么去解决。

其实现在目前就对于人工智能工程化落地，是一个非常呃关键的一个问题，这个也就是应对了，今天我重点跟大家去分享的就是，我们将面向于大模型的，数据工程的这么一个话题。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_5.png)

然后在我们的大模型呃，现在时代到来的话，其实大家其实看到就是刚才有介绍到，就整个我们叫呃数据的整个发展历程，它其实对于整个数据的数量跟质量，其实都要求非常高，我们叫双量。

就现在看到主流的大模型的token数，其实是非常大的，但是的话，现在目前我们可以用于模型训练的数据，其实对于它的质量来说，是没有一个统一的评价的标准，然后这样就导致我们在训练模型。

包括在它的工程化落地过程当中，需需要投入很多的时间来进行数据的处理，然后同时的话整个大模型的整个训练过程当中，包括应用落地过程当中，它是会涉及到很多环节的，而且每一个环节它对于数据的要求也是不一样。

那这里边我们就就必须得有一个很高效的，很自动化的一个数据工程的概念，这里边就会涉及到我不同类型的不同阶段，我对于整个数据需求我要怎么去管理，怎么去制作它，其实应该是有一套统一的方法论。

同时的话我要增加这个效率，因为现在是大规模的这种数据，我如果是只是靠人工标注，那这里边它效率是非常低的，所以说现在其实我们有看到很多，这个智能化的标注技术有产生，然后同时也会用这个呃大模型来标注数据。

还有的话就是呃，以以前我们叫上一代的模型去部署完了以后，其实不会涉及到它的更新迭代，但是大模型的话它是一个持续学习的过程，就像我们一个呃人在我们的就是叫呃，我们从那个就是从小学初中高中。

他其实是要不停的不停的去学习的，所以要不停的给他去喂数据，那这样的话我们就需要一个数据的更新的机制，所以这里边就包括它的整个效率，包括它的整个自动化的高效的流程，然后包括它里边的一些机制。

是对于整个数据工程师才是一个完善的呃，很体系化的内容呃，然后再有的话就对于整个全流程，就刚才我们说到，其实我们数据对于现在的大模型，它不是一次性的，它是随着时间，然后随着全流程。

是不断的在跟模型来进行交互的，那这里边的话就涉及到要可信的，全流程的数据的治理，那这里边的安全，包括我们的整个数据治理体系如何去设计，也是一个非常关键的问题。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_7.png)

然后我们再来看的话，就是我们去看整个大模型训练的一个周期啊，就我们从整个预训练的大模型到微调，到形成一个通用的大模型，到我们行业应用落地的行业大模型，我们去每个阶段去拆分出来，大家其实也可以看到。

这里边会涉及到预训练的数据集，有微调的数据集，包括提示工程，然后以及人类强化学习反馈一些偏好的数据，指令的数据，还有一些行业知识的数据，那这里边的话针对于不同的数据，其实我有相应的数据处理的方法。

以及数据训练的策略，然后最一开始的话包括预训练数据的话，我们会从这个是比较传统的，像数据的获取过滤清洗，但是它是大规模的，所以我很关键的，最后最后要有一个数据质量的评估，可能原来对于小模型来说。

质量评估它并不是那么关键，但现在质量评估是直接可以去呃，直接影响整个模型训练的成本，包括模型训练效果的，那然后在整个全流程过程当中的话又会呃，因为最一开始是呃无监督的，后面到自监督的话。

我还会有数据的标注，然后以及我在不停的在优化的过程当中，我还要做一些提示的工程，然后这里边我就要引入一些这种呃，我们叫交叉复合性，很专业性的这人才进行专家的标注，然后以及这个的话就我们认认为这个呃。

就数据跟模型之间的效果，它其实是相互呼应的，所以在每某就是每一个阶段，我怎么去制定数据的策略，它其实是需要一套测试的体系的，我通过测试模型的效果，知道它需要什么样的数据，它还缺什么样的数据。

他应该学什么样的数据，所以我们通过，但是这个测试的话，就又会涉及到我们原来叫二八的理论，就是我们要去构建一些评测的数据集，所以大家可以纵看这就是全看这个图啊，图里边就看到。

就这个模型跟数据它是相生相息的，是完全是密不可分的，所以我们认为整个大模型的数据工程的话，一定是贯穿于整个大模型的全生命周期，然后再来看就是呃我们叫嗯就是相生相息的话，它其实就是个兼容并包的过程。

那我们这里边去看到，整个面向于大模型的数据工程的话，它核心的我们梳理出来五大的核心要素，就包括了有管理的体系，开发维护，质量控制，资源运营和合规可信，那我这五大要素是怎么总结出来的。

就是一方面我们要去融合已有的数据，管理的成熟度评估模型，这里边的话就会涉及到整个八大要素，然后以及像模型开发过程当中，像模呃就是模型开发的过程当中，从开发到模型的能力，应用运营可信。

它有会也有会自己对模数据的一些要求，那我们把已有的现在大数据领域的，数据管理的成熟度评估模型，和我们现在模型开发过程当中，对数据的要求来进行一个融合，其实就是现在我们面向于大模型的数据工程。

那这里边的核心的话，就是对于整个大模型数据工程，其实我们更多的是要提高整个呃，就是对于整个数据的供给，或者它的管理的运营的效率，以及提升它的整个呃我们叫高质量的数据。

就是它质量可以来进行进一步的提升和优化。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_9.png)

然后以及保障它相应的安全，那我们分开来看的话，就第一个先看这个管理体系，就我们针对于大模型的数据管理体系的话，就是呃我们对于这个数据管理，大家应该很多专家都很熟悉啦。

就是数据它其实有一套非常完整的管理体系，那针对于我们大模型或者人工智能的数据，我们要怎么去管理呢，这里边我们核心可能更多宏观的我们就不谈了，我们更谈的更谈的是更多是偏落地的。

这里边就会涉及到这个项目管理，那我们针对于大模型数据，根据刚才说到那个呃就互相融合，互相交叉的话，大模型的数据工程，我的全全周期里边我的数据的资源的分配，然后以及我整个数据，不管我是形成这个呃。

就形成数据集或者是数据训练的策略，然后里边它的整个机制，然后以及进度如何去控制，然后它的质量如何去保证，以及它的一些风险风险的管理的问题，然后可以我针对于大模型，不管它是要这种预训练的数据微调的数据。

还是呃这个就是偏好数据提示工程的数据，我都可以按照模型的训练周期，按时按点保质保量的给它进行交付，然后同时的话成本可控，那这里边就会涉及到，我里边肯定要有一个核心的项目，管理的这么一个职责。

然后第二的话就是组织建设，那组织建设的话，其实我们知道就是呃大部分企业来说的话，它一般是会有一个大数据的团队，然后有一个人工智能的团队呃，现在我们跟很多这个包括大型的企企业，包括现在做大模型开发的。

一些互联网的头部的企业，也都交流过，大家在组织建设这块，目前可能还不是完全的统一，但大部分来说的话，现在这个团队可能还是在大模型的团队，或者在人工智能的团队为主，但这里边它其实会有一个核心的问题是说。

其实这部分的话它更多，它没办法完全去了解，整个数据资源和整个数据供给的体系，和一些机制的建设，因为它只是融在了整个大模型团队里边的，一个职能团队，那这里边我要去进行这个全流程的一些。

数据的管理和一些机制，包括现在想嗯嗯包括这个项目管理的话，它其实这一个团队是完全没办法去支撑的，所以说这里边的话，就是针对于整个大模型的数据工程的话，怎么把两个团队来进行进。

进行一个有效的融合和一个高效的协同的话，这里边其实是我们需要呃甚就是完全去探讨，然后也要结合企业实际落地的情况，来进行一些呃调整，然后还有的话就是标准应用，然后针对于就是大模，就针对于大数据领域。

其实我们是会有很多标准嗯，包括现在我们也成立了那个国家数据，也成立了树标委，其实把我们之前很多这个标准，然后未来也要推推向整个应用落地，然后人工智能呢其实我们这么多年来推，其实也有。

但针对于人工智能的数据方面的标准，其实呃我们后边具体片子我我会有介绍，就我们在这块也在做一些相应的工作在推进，但是的确这块更可供我们去参考，包括嗯能实际去应用，落地的标准相对来说是比较少的。

尤其现在我们在推这个就是呃国家也在推，地方也在，就是跟产业也在，一直在说这个高质量的数据集，那这个高质量数据到底到底怎么去定义，我怎么去建一个高质量的数据集，然后这个数据集的话。

如何跟伟大模型去进行融合，这里边其实会涉及到很多这个标准化的问题，呃这里边你看就像到这，像这个数据我如何去加工处理，然后以及大模型的数据开发，它的质量其实等等的话，现在其实我们是需要去建立一些操作规范。

以供这个不管是技术的，就是呃数据的提供方还是模型的开发方，还是这个呃就是产品的应用方，它其实都需要这个来自己作为一个参考，嗯然后最后的话就是说这个人才的管理，就我们知道就是刚才针对于整个呃。

我们这个叫跨学科，跨专业，跨领域，这个怎么去理解呢，就是我们现在既懂数据又懂模型的人才，相对来说是比较少的，比如说呃就是我们大数据领域的人才有很多，然后对于模型开发，对算法懂得也很多，但原来我们叫。

就是叫数据科学家和这个算法工程师，但是这个的话其实如何对二者做一个结合，其实目前来说，这未来的人才其实要往这个方向去发展，然后同时的话，现在我们整个呃呃就是大模型，在应用落地过程当中。

他需要这种多学科的这种知识的背景，然后你要懂模型，同时也懂模型要学什么样的知识，那这里边的话包括像医学金融，其实很多这个呃这种有有多学科交叉的人才，其实在我们整个人工智能数据构建的时候，是非常缺乏的。

嗯开发维护的话，第二个开发维护，其实更核心的是关注于整个全生命周期的，一些技术的要点，然后这里边关键环节其实呃就会涉及到，其实最大的整个数据的处理量，还是在最一开始预训练阶段，从整个数据的采集的汇聚。

然后这里边其实更多的是针对于，无监督的这种数据，然后它数据来源就包括有通视行业就等等很多，这个呃就是还有合成数据呃，这个其实我们去年也做了一个大模型，数据的资源地图这么一个研究的工作，其实也是在研究。

现在就是目前大模型用到的数据都是从哪来的，然后同时的话这里边我如何去采集呢，然后有手工的，有自动化的，然后也有一些合成的数据，然后数据的预处理就是我首先拿到数据，我怎么去呃。

把这个数据形成一个模型可以用的，那它就会涉及到预处理和标注两个环节，预处理更核心的，它其实是去做整个数据的整个清洗，增强转换调度去读等等，脱敏，就是它其实是达到一个可用的这么一个效果。

就是我要去保证模型它不出偏差，所以我要达到可用的效果的话，我要先去做数据的预处理，然后如果说模型好用的话，那它其实要通过数据的标注，这也就是说刚才说到，我们需需要需要这个多学科。

多背景的这种人才来进行标注，那这里边的话数据标注的话呃，它也是会涉及到不同的大模型，不同的阶段，这里边目前来说我们整个数据标注的产业的话，就是因为现在我们也在做这方面的研究，然后包括跟地方。

包括跟很多这个数据标注的企业也在对，就目前我们整个呃数据标注产业来说的，它的不管是人员的结构，还是整个服务技术能力的水平，相对来说还是比较处于起步的阶段，那未来的话。

整个我们怎么把整个数据标注的产业的能力，可以进行这种产业化的升级，为我们整个人工智能提供这种更优质的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_11.png)

更高质量的数据集，其实也是现在就刚才有说到，我们国家数据在推这个国家级数据标注基地，很核心的一个目标，然后再说到这个，就是针对于大模型的不同的阶段啊，刚才说到这种预训练的阶段。

它其实不同的阶段对数据的需求是不一样的，然后像预训练的话，他就规模大，然后但是他需要我去呃，就是大家其实可以去反馈啊，就是反向来看，就是不同的阶段需要什么样的数据，其实是说我这个模型要达到什么样的效果。

在预训练阶段的话，我需要大规模的数据，然后这数据要有更多的覆盖性，要有更多的多样化，它其实更多的是一个基座大模型，然后同时在指令微调阶段的话，它的规模相对来说比较小。

但是的话它就要有明确的指令跟明确的方向，包括有明确的内容，那这里边的话我们就会涉及到这种有监督的呃，这种处理的方式，然后同时的话还有反馈对齐的阶段，就是你通过人不停的在给告诉模型。

你到底呃就是他通过这个数据标注，然后告诉模型你哪个地方需要能力提升，哪个地方需要去优化，它是通过跟人的交互来快速迭代，来进行这种模型的更新，呃刚才说到这个高质量的数据集，就高质量数据集。

我们还不能说只看这个数据本身这个质量，我们再去看这个人工智能数据的高质量的话，它核心的话我们要从三个维度去看啊，首先是说这个数据的质量，就是会涉及到这个数据的指标，就大家知道这个就是国标有DQAM的。

国标的六型，就针对于大模型数据质量，我们是呃，现在已经有一个国标是明确的，在指导这个数据质量，但是对于整个人工智能的数据质量的话，它其实是要有根据模型的质量来反馈，我需要什么样的数据。

所以这里边的话我们也梳理出来，11个核心的维度，这个后边具体再跟大家去介绍，然后指标完了以后，就是说我这个指标如何去落地，其实我是需要有一套评估的方法和评估的工具，这里边其实有规则的，有人工的。

然后可能我还要再加一些模型效果的验证，然后以及针对于全流程的一些质量的控制，那这里边其实我会呃，呃有一些质量的监测的手段，就是刚才有说到，我要通过不停的对模型来进行反馈。

包括刚才说到那个人类强化学习反馈，其实也是这个概念，就是我要通过不同的跟模型来进行交互，我要实时的去调整整个数据的策略，然后以及数据的如何去，就是将模型的效果跟数据质量，要形成一个强映射的关系。

第四方面的话就说到这个资产运营啊，就是呃我们形成一个高质量的数据，就是人工智能数据集，它虽然是用于模型去训练的，但是我在模拟训练之前，它其实核心还是一个数据产品，那它既然是一个数据产品。

它就还是有数据本身的属性，我需要对我这个数据集也可以去进行交易，然后也可以进行资产入表，所以说这里边我对于这个数据集的资源的话，也要进行相应的运营和相应的管理，那这里边的话整个运营我会涉及到哪些部分。

就商，首先的话，我对我的数据集要进行一个资源目录的管理，然后同时的话对它要进行分级分类，同时我的数据集还会涉及到对外的开放共享，和对内的一些流通呃，就是开放共享，就开放共享的话。

会涉及到对外的开放共享和对内的呃，就包括呃他就是上下级的公司和部门部门之间，那这里边的话我开放的内容要求协议，其实我都要定义的非常清楚，然后要结合整个人工智能训练的需求跟模型，效果的。

就是模型的呃要求来定，然后同时的话这个流通交易的话，包括现在我们和呃，像北京上海，贵阳，就很多这个数据交易所，其实也有很紧密的联系跟交流，就现在各个数据交易所其实都有上架呃，语料库的数据集。

包括人工智能数据的专区就可以看到，其实刚才肖教授有介绍到，就未来的话，整个人工智能是撬动数据价值以及数据流通，很关键的一个要素，嗯那现在的话其实大家可以看到嗯，有很多这个就我们认识的这个叫呃数据数商啊。

数商很多就是数据标注服务商，他们原来都是给人工智能企业，去提供一些数据产品，然后同时的话，现在很多大模型企业也会去数据交易所，去找这些数据，那就可以看得出来，未来的话整个人工智能数据集。

它还是有很大的一个市场的空间，呃然后最后就说到整个大模型的一个，就是数据工程的一个合规可信的问题，呃，因为这个我们也是就是所有的片子，跟大家分享的都是一个反向的一个思路啊。

就是这个其实在我们的就国家发布的那个，深城市人工智能管理办法里边，我们也去细细的去分析过，里边有18次有提到数据的问题，然后里边它包括就是有提到，要保证整个数据的真实可信，然后以及数据的可追溯。

就其实可以看得出来，就相当于是我们把模型比成一个人，如果他学的内容有问题，他最后输出的内容一定输出的呃，一定是有问题的，所以说我们按照整个呃模型治理，包括对人工智能安全的一些要求，去反推过来的话。

这里会包括整个对数据的一些安全性的要求，包括从整个数据的公平性，它的非歧视性以及数据的可解释性，同时的话我们的数据安全也要去结合，我们大数据领域现在对安全的一些要求，包括它的隐私的安全。

然后它的整个审计，它的监控，它的安全合规，所以说我们在看整个人工智能数据集啊，它是两个领域的一个融合，就我们既要去呃，完全去遵守大数据领域，已有的一些标准和已有一些规定制度，包括政策的要求。

同时的话要结合人工智能领域，对于模型效果的一些要求，要把二者做一个充分的融合和结合，最后就给大家简单介绍一下，就目前就是中国信通院，在做的一些相关的研究的工作。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_13.png)

首先我们就是去年9月份的话，就在中国人工智能产业发展联盟呃，这个联盟的话是也给大家介绍一下，然后目前这个联盟的话会员有将近900多家，就是基本上覆盖到了我们整个人工智能，从技术提供方到技术应用方的。

很多的产学研的相应的机构，然后9月份的话我们也正式成立了数据委员会，其实核心就是聚焦整个为人工智能领域，如何去提供这个呃高质量的数据集，同一些标准啊，场景呃，场景的这种探索。

然后包括技术的攻关和一些公共的服务嗯，然后从去年开始，我们也办了很多这个大道论坛，小到一些沙龙，也是希望跟各界共同去探讨，就我们如何去为整个人工智能的发展，以及更好的去释放数据。

要要素价值这两个角度形成一个双轮的效应，嗯那大概今年上月份的呃，上半年的话就是我们也做了一些相应的活动，这个就是我就不细细介绍了，这里边就会涉及到很多有偏研究类的，有活动类的。

然后呃而且的数据委员会我们现在也有很多，这个包括央国企业大部模型，企业有作为这个数据委员会的副组长单位，就我们作为牵头，但是更多的是想跟大家去形成一个联动的效应，把大家的这个需求和供给。

然后以及相应的问题，可以通过这种生态的力量共同去呃，进行一个探讨和解决，嗯相应的研究的工作的话，就刚才也介绍到，就去年我们去发布了呃大模型的数据资源地图，就这个其实我们初衷是想因为我们很接触很多。

这个就相当于是呃呃我们叫技术的应用方，就是人工智能技术的应用方，包括模型的开发方，他们就一直在问这个，就是我需要构建什么样的数据，我可以去用大模型，或者说我的大模型可以去哪去找到，这种高质量的数据。

就是很多很多在问，所以我们去年就启动了这个事，也是想呃，当时的初衷是想跟各个行业来进行一个，深入的研究，后面发现这个设计其实挺难的，难度比较大，然后所以说后边我们就选择了一些呃，比较有代表性的。

而且这个领域的话，相对来说对人工智能的接纳程度，和它的整个技术能力水平也都比较高的，一些头部的企业选了金融通信，汽车和智慧城市，然后对整个行业的数据进行了一个初步的摸排，但这里边和数据资源地图。

更核心的是想跟大家去说的，就是目前的整个大模型来说的话，它的数据的来源就包括有公开的获取，然后有数据采购以及生态的商业的合作，这里边其实可以看到就公开获取的，现在就是基本上公开获取的数据啊。

我们了解到大模企业基本上都拿的差不多了，然后数据采购能买列都差不多了，然后生态商业合作就说大部分都是拿不到的，数据，其实也就偏我们整个行业包括场景的数据，行业场景呢它其实也有很多这种共性的数据。

包括这种公开的网页，然后有这个像一些知识百科书书籍文献，但是针对于我们业务的数据，如何去进行梳理的话，这里边的话就需要呃我们去结合相应的方法，相应的体系，然后它里边可能也会涉及到。

针对于就大的分级分类的呃，整个依据，然后再结合整个行业的特色，其实针对于我的模型应用的场景，然后要这个对数据来进行一个分级分类，以及目录的管理，然后以及就是我们去整个标注产业的话。

我们认为是很核心的一环，但是我们把把整个标注产业去，把它打开来看的话，我们认为是一个人工智能的数据的产业，人工智能数据产业我们怎么去理解呢，就是它其实跟就刚才说到，它核心是贯通。

人工智能跟数据要素是两个产业的，然后它的整个产业的升级的话，将会对整个数据要素价值的释放和人工智能，它是会可以双向赋能的，那未来的话，就这是我们初步梳理的一个产业图谱。

那现在的整个产业图谱里其实很多能力点，包括它的整个产业链的环境还不是特别的清晰，那未来的话随着整个产业的不断的升级，包括我们国家顶层的一些产业政策的推动，包括我们生态的力量。

包括我们这些企业呃不断的去进步啊，包括今我们现在看到就是国外很有代表性，叫skill AI的这个公司，其实去年的话呃，他们现在估值大概是有130亿美元呃，但是这样的企业目前在我们国内还没有出现。

但是这样其实我们是可以看到，就未来这个方向还是呃很好的，那这个就需要我们对于整个人工智能数据产业，不管它是它的技术能力，还有它的整个工具平台的产品，以及它的整个服务，还有人才。

整个它跟行业的一个结合程度，其实全方位的都要有一个呃相应的这调整，包括相应的一个进步，然后这样的话才能更好的去贯通，就是为我们人工智能更好的去输出，高质量的数据，包括高质量的数据服务。

然后同时的话对整个数据要素的一些，核心的价值，然后以及对整个数据要素，可以整个数据要素的市场来进行进一步的扩充，呃第三个的话就是刚才说到，就是我们现在其实也在做一些标准，研究性的工作。

我们根据现在就是我们把供需双方的这个呃，大家核心关注的对于标准规范的一些内容，形成了一个标准研究的一个框架图，这里边就会涉及到很多共性的内容，就是包括我们怎么去定义这个高质量的数据集。

包括怎么去定义数据集，然后这里边从整个数据集的全流程，包括它的呃，呃就是里边会涉及到的一些关键的技术，然后以及说我们对于数据的处理，然后数据标注的一些工具的平台，以及它呃质量如何去评估控制。

然后以及它的整个开发管理能力和交付，第三方的交付实施能力，资源运营以及行业应用，然后形成了一个总体的视图，然后目前的话哦，这个下面没有去显示全，就目前我们正在推推进的是五项标准。

然后第一的话是面向于人工智能的数据集的，质量的通用的评估方法，这也就是核心想回答产业界，就什么是一个高质量的数据集呃，这里边我们有涉及到11性，因为数据质量是目前来说，产业界很关注的一个内容。

待会有专就是呃，有有两页片子专门去介绍这个事情啊，然后第二个的话就针对于人工智能数据生产，标注服务能力的一个通用成熟度评估模型，就是更好，这个其实更多的是对于数据标注的，现在很多供应商嗯。

我不知道大家了不了解，但是真正做模型开发的，肯定会经常会跟他们去打交道，就他们会去对数据做些标注，目前来说是我们叫劳动密集型呃，而且的话他们的整个服务能力可能还完全没法。

就没有办法去覆盖到我们现在大模型，对于一些高质量的数据，包括一些行业数据的这种需求，那这样的话未来整个数据标注服务商的能力，我们如何去给它定一个更高，更远的一个目标的话，我们希望通过整个标准来说呃。

里边我们会涉及到也有人才，然后以及它的整个产业链的协同的能力，然后以技术，技术服务能力有很多的这个呃这个指标体系，然后第三个的话包括合成数据，就是合成数据，其实是我们认为是未来很关键的一个。

就是我们现在就是说呃，可以看到就是目前数据来说的话，我们叫这个大模型，已经把现在已有的数据基本上学，差不多可能到26年，就是我们叫看到公开有信息叫消耗殆尽啊，那未来合成数据。

我们怎么把现在这个合成数据作为一个呃，很典型的一个发展的方向的话，把现在比如小规模的数据我们去做泛化，那未来整个合成数据的生成和管理能力，也非常重要呃，然后第四个的话，其实我们现在在做的。

就针对于大模型的开发管理，就大模型数据的一个开发管理，就是从它的整个刚才说的那个五要素，其实在里边都有统一的叙述，然后还有的话，我们现在针对于这数据工程的一个技术，平台的要求。

然后我们现在也搭建了整个围绕着人工智能，数据工程的一个整体的呃，呃一个我们叫评估的视图啊，就未来我们针对于人工智能数据机，我们需要从几方面去发力，然后以及能力的提升的话，就包括我们的技术的平台。

这里边涉及到清洗管理等等一系列，然后以及呃针对于大模型，如何去做数据的开发管理，包括组织技术质量等等，然后以及它的质检，就数据及如何去质检，包括它的评估，包括的质量管理，以及我最上面就是其实我们叫数据。

其实也是一个生产嘛，就是也有专家跟我提过，叫人机料法环的一个概念啊，就是我这个数据到底要怎么去生产出来，然后标注数据的标注服务，更多的是把这个数据变成高质量的数据，合成数据的话就把小规模的数据。

没有的数据我把它合成出来，那这里边它其实都是和目前，包括未来我们认为是呃很关键的几个方面，然后这里边我们也去结合了刚才说到了，就是面向的大模型，数据工程的五大的核心要素，我们面向有数据的运营方。

数据管理方以及模型的开发方呃，这是整个我们现在做的数据集，质量的一个呃标准，然后从原来的像ISO8000跟DQAM，我们去延伸到了11性，然后并且每一性也是结合模型的效果。

包括模型对于整个功能逻辑应用稳定性的一些，我们去反馈回来，对于数据它有什么样的要求，有一级指标，有二级指标，以及对于整个我这个质量如何要去验证的话，里边会涉及到我们传统的整个规则的检测。

更多的是客观指标，然后以及人工抽样有主观的，然后更核心的是我们要通过这种模型效果，然后实时去反馈，然后给他提出一些数据优化的策略以及建议嗯，还有最后的话就是说，我们对于整个如何去做模型验证的话。

这个其实又是另外一个很大的话题了，然后去年我们也去发布了，整个方身大模型的一个基准测试体系，就如何去测的话，这里边有测试的指标，测试方法，测试数据集和测试的工具呃，测试的话我们认为整个大模型的测试。

它其实是一个很复杂的一个工程化的呃，也不能它是现在是说原来的数额小模型的测试，它相对来说简单一点，但对于大模型的测试的话，第一是它涉及到的任务类型有很多，然后而且的话它有很多种涌现，思维链等等。

它会涉及到不同的方面，所以我们未来的话，我们认为整个大模型的基准测试，其实跟数据一样，也是贯穿于大模型的全生命周期，从大模型的开发，然后到达萌新的选型应用部署持续监测。

其实都需要做一个基准测试的workflow，然后从测试需求数据构建环境，然后以及最后对于一个结果的这种分析嗯，然后目前的话整个呃测试数据集的话，我有将近300万个，然后这300万条。

然后这里边的话就涉及到呃，本身17年，其实信通院已经在开始在做可信AI的，整个人工智能的测试呃，这里边我有我们自由的数据集，然后有外采的，有开源的，然后同时我们也跟行业很多，包括金融政务。

然后有共建一些数据集呃。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/18783f07b5db40fc25d0f93531c75ac0_15.png)

这就是我今天的汇报。

# 2024北京智源大会-人工智能+数据新基建 - P8：全国性数据流通交易体系的探索实践-冯进 - 智源社区 - BV1qx4y14735

感谢大会的邀请哈，我是中国电子烟的冯进呃，我一直是做我呃从事数据这个领域呃，今天大家现场的嘉宾以及到会的数据同仁，非常辛苦哈，一直坚持到现在，那么前面几位嘉宾的分享给了我很多的启发。

包括我们呃智研院的人工智能数据运营平台，还有黄老师的呃互联网，包括刚才上一位老师提到的大模型的工程体系，那么我从呃数据流通交易体系啊，给大家做一下分享和汇报，那么里面的观点或者我们的这个探索。

有不妥的地方，也欢迎大家批评指正，那么主要三个部分哈，第一块就是整个数据要素市场化的一个背景，第二部分呢是基于这个背景，那么我们啊在前方啊去探索实践全国啊，数据流通交易。

第三块呢刚好跟今天的主题有一个呼应，就是以数据为中心为核心的智能家的一些探索，那么首先说到啊，数据要素市场化配置改革呃，坚持以数据要素市场化配置改革为主线，那么什么是数据要素市场化配置改革。

这张图是我个人以及我团队的理解哈，我认为核心是市场化，所以这张图的目标是推动这个高效市场配置，从上往下看，那么我们要围绕着数据呃，数据市场的主体去展开工作，包括多样化的市场主体。

那么靠什么把它们聚在一起呢，靠价值驱动啊，聚焦场景，也就是我们数据局提出来的数据要素城行动，那么有了市场主体，我们还需要有市场的环境，那么包括内部的数据资源环境会好，治好数据以及一级数据要素市场。

那么来这个完成数据资源开发利用权的流通，以及二级数据要素市场，数据产品经营权的流通，那么在这个市场的支撑过程中，需要通过登记来确保来界定权属，以及啊这个针对私域数据设施，数据指主体统一授权。

那么有了市场底下，需要有不同类型数据资源的啊，一个一个核心，以及以数据为主要，代主要核心的各类数字化平台，那么再向下是算力的统一调度，包括算力网以及前面刚才的老师提到的数联网。

再往下才是我们配套的这个数据制度规则体系，包括四梁八柱，还有这个细化的，从数据登记到产权相关的这个规则体系，再往下才是我们配套的这样的一个组织体系哈，那么基于这样的一个呃，市场化配置改革的总体框架呢。

呃中国电子云也是面向全国进行业务运营，那么我们的这样的一个业务呃，范围在呃数据产权这一块呢，我们提供数据资产登记平台，包括资产化服务平台到从入表到融资到抵押，那么在一级数据环境哦。

面向公共数据提供一体化公共大数据，面向企业啊，数据中台以及一级数据要素，市场环境的数据运营服务平台，AI模型开发平台，包括数据交易服务平台，同时呢我们自己也打造噢，中电云数据港这样一个品牌。

来上架自己的数据产品，那么参与到数据要素层场景的落地和运营，那么我们数据局提到的数据要素成行动方案，我个人的认为哈，他是去激活和推动数据要素，二级市场完善联动协同。

这样的一个系统化和协同化的运营服务体系啊，那么我们要去落地这个数据要素成行动，包括数据要素成行动里面哦，蕴藏着很多智能家的这种场景，那么我们迫切需要去解决数据高质量的流通，那么影响数据高质量的流通呢。

呃这里面存在着很多的挑战哈，包括确全览合规的成本高，撮合难，刚才前面的老师也提到了哦，这个数据和场景的图谱来加速撮合，包括定价栏，还有流通栏，那么这些阻碍数据的这个流通交易，我们需要从制度，从规则。

从技术，从运营多个维度去探索实践，那么这里面呢我们也提出一体化数据流通体系，交易的这样的一个啊思路哈，围绕着数据流通中的五栏，那么我们和申诉所一起，共创打造全国性数据交易平台。

那么平台与制度与规则与运营相结合，那么在平台上面呢，我们抽象五大中心，登记中心，合规中心，交易中心这个数据交付流通中心以及资产中心，那么通过这五大中心，将上面的数据资产化的业务流进行串接。

从登记一直到资产化，那么在这个平台支撑的基础之上呢，面向全国啊，这个进行能这个数据资产化能力的赋能，那么推动工作站的成立，以及和其他区域型的数据交易，交易中心互联互通，那么从而形成这样的一个啊。

全国性数据流通体系的一个网络，那么呃中国电子云呃，有幸能够和申诉所围绕着在数据流通，交易体系的这样的一个啊，创新和技术引领的一个互融，那么申诉所呃从战略上看，那么它呃面向全国的这样的一个数据要素市场。

打造数据交易网，那么中国电子云呢，发挥在全国各省合资公司的优势，来推动全国将近30余个，第四的公共数据授权运营，形成数据运营的网，那么这两个网我们会后续逐步去对接和联通。

那么我们希望这样的一个数据交易体系，能够成为全国数据资源汇聚地，数据产品的开发地，以及这个数据的流通调动调动中心，那么要实现这样的一个愿景，我们从技术啊，从四个维度啊去做统筹，包括在算力上哈。

多云算力的这个纳管和调度，包括在数据底层的流通上啊，通过可信计算的数联网络，所以后续啊我们也会和刚才北大老师提到的，苏联网去做对接，包括在数据流通交易这一块哦，那么我们打造全程的数字化，一切线上化。

最后呢是在供需撮合上，那么要实现动态智能，那么通过这个数据到场景，数据到数商之间的这样的一个图谱加速啊，供需撮合供需撮合，那么在技术规划和技术平台支撑的基础之上，那么数据交易体系呢在运营上呃。

从四个维度去构建自己的能力啊，从内部来看哈，是建啊，从外部来看是聚，那么内部建什么呢，第一是打造这个高效的供需衔接机制，这里面包括线上线下的各种运营手段，那么第二块呢就是守住数据合规的价值观。

那么打造啊地方标准，那么这个确保数据流通交易过程中的啊，这个全链路的合规，那么在外部距上面，那么通过生态的方式去聚合我们在不同领域，包括大模型领域的上下游的这个呃数商主体，那么在流通支撑上。

那么接入更多的影视计算的，或者是数数可信数据空间的主体，能够链接到更多的数据数据供给侧，那么目前哦，这个申诉所也取得一定的这个这个成绩吧，包括交易额场内啊，80余亿上市的数据标的超过2000个。

包括市市场主体超过呃2000家哦，那么我们来分享一下，以上四个领域的一些这种啊方法或者实践，那么在供需衔接这一块呢，呃数据交易平台上面重点上架哦，不同主题的专区，那么通过专区将数据的这个数据方和需求方。

要这个有机拉通有机整合哈，那么加速这个供需撮合的效率，那么同时呢呃着眼全球，完善数据跨境流通的机制，那么这里面包括四个部分，那么完善整个数据跨境的基础规则制度，当地的这个相关事务机构建立协同监管机制。

那么呃稳妥推进数据的跨境，这里面包括推进分类分级的这样的一些，白名单的机制，那么创新探索这个金融的工具，能够助力数据跨境的流通，以及啊推动数据跨境流通技术的体系，那么最后也取得了一定的成果哈。

那么跨境的数据交易，那么超过超过1亿，那么有55笔，同时呢也完成场内的数据跨境里的交易，包括还有境外数据商的一个入驻，那么同呃，这里面就是基于刚才的呃，跨境的一个细化的分享哈。

那么最左边呢是呃某科技公司，那么他们的数据标的啊，通过右边的风险评估体系，流通交易体系，能够让境外的买家能够购买到，这样的一个数据产品，那么右边呢是呃引入这个境外的数据商。

将他们这个在境外采集的有关电商平台的数据，以及分析的产品上架到我们的交易所，那么同时呢在供需衔接啊，通过这个社区的力量，通过联盟的力量，能够链接到人工智能这个上下游的，从算力到数据到平台。

到模型到应用的这个呃相关产业的市场主体，那么将它们导流到啊，我们深圳的这样的一个人呃人工智能训练场，那么也完成了这个通过可信数据空间，那么让哈工大和这个呃睿来智慧。

完成了语料跨越的一个呃这个可信的交付吧，那么同时呢右边也上架了哈，我们国内知名厂商的相关的数据产品，同时这里面也和我们信通院这个呃，搭建可信数据和模型质量评测，这样的一个授牌哈。

那么呃在供需对接有一个很重要的数据来源，就是公共数据资源哈，那么前面刚才也讲到过，就是在公共数据资源供给这一侧呢，中国电子云，充分发挥我们在全国各地市布局的优势，那么将我们在公共数据授权运营平台的。

数据产品和我们的数据交易所进行打通，完成这个正所支联，那么右边呢我们可以看到，上架了不同的公共数据产品，以及我们面向公共数据测产品孵化的机制，包括探索公共数据产品啊，这个定价的一个一个创创新和落地。

那么在合规保障这一块呢，呃数据交易所，那么这个提出动态合规这样的一个品牌，那么动态合规我们可以看到左边它从三个环节，就是我们数据流通交易过程中数交易的标的哈，交易的主体以及流通三个环节啊，四个维度啊。

包括合法诚信，安全权益保障四个维度啊，拆解出100多项合合规的这样的一个规则，那么同时呃平台提供分环节动态审核，那么信用分级别这个动态监管啊，流通分阶段动态合规的这样的一个模式。

那么我们也提供在合规上的标准啊，防线和增强防线，标准防线呢是当数商提供相关的材料平台，初审平台终审包括合规委员会啊，如果出现啊比较严苛的条款，由合规委员会复审，包括底下的合规的联盟成员参与复审。

如果出现分歧的话，那么进入到底下的合格委员会啊，统一来拉通，那么形成这样的一套防线，那么同时呢呃基于合规，那么构建整个合规的信用体系，为我们的市场主体去刻画主体的这个信用画像。

那么右边呢通过大模型和合规的审查的结合，面向我们的数据商，面向我们的律师，面向我们平台以及监管侧，提供智能合规的能力支撑，提高效率，那么在流通支撑这一块呢，呃左边我们可以看到哈。

就是整合我们可信这个数据空间的技术，来搭建啊，可信数据空间的实验实验室，那么右边呢我们会探索基于这个工业制造领域，向右边长虹，那么它的产线数据和代工客户之间的库存数据，以及计划数据要进行打通。

那么通过可信数据空间，让长虹的产线数据，在保护持有权和让渡部分开发利用权的情况下，完成多方数据的融合，那么实现产业链上下游业务的一个协同，那么在生态发展这块呃，申诉所的主要的几个模式哈。

第一个是啊这个开放群岛开源社区，那么包括数据要素服务工作站，以及人才发展计划和产业园区这样的一个模式，那么我们可以看到开放群岛呃，这个开源社区呢目前来说已经发展的比较蓬勃。

那么涵盖数据从可信技术到流通哦，到这个不同的垂直领域，不同的区域这样的一些专项小组，那么开放群岛呃，通过这样的生态的拉通呢，那么在影视计算这块也发布了相关的哦，影视计算的开源的一些框架。

还有一系列的案例成果，那么在呃数据要素服务工作站，面向全国来拓展哈，那么来解决大模型，在全国上下游这样的最后一公里，那么申诉所包括中国电子云，为每个工作站提供安全合规产品服务化。

数据资产化等多项专业服务能力，那么最后我们从技术回归来看一下，那么数据交易所要支持我们的数据产品，从数据集，数据文件API多方安全计算，联邦学习各种形态的这个产品的交付流转，所以在这张图里面。

我们可以看到，从交付管理到产品交付到统一纳管，以及面向不同类型的数据产品的，这样的一个统一的接入，来确保数据在供需双方能够可信的高效的流转，最后呢我们看一下在智能家探索哈，那么刚才前面的嘉宾也提到了。

我们进入以数据为中心的AI，那么AI智能离不开数据，那么数据需要炼化，才能产生有价值的高质量的数据集，那么这个模型在不同的训练阶段哦，它对于数据的，不同类型的数据集的需求也是不一样的。

那么如何解决这些数据荒的问题，那么这里面四个维度做一个分享，第一块就是开放开放蒜料的联盟啊，通过联盟来汇聚啊，这个算料算算力啊，这个大模型上下游的这样一些主体，第二块就是上架高质量的数据集。

第三就是构建可信的流通途径，第四是积极参与到AI训练场，那么在开放算料联盟这一块呢，呃申诉所包括我们相关的生态哈，一起共同这个组建，其目的是为了凝聚共识，那么共同倡导我们多模态的这个训练数据。

大家能够共建共享，那么底下我们也看到也绘制了大模型的地图，包括这个提供开放的高质量的数据集啊，那么我们高质量的数据集呢，目前做了一个统计哈，那么覆盖相关的领域，那么也包括七大类啊，500多个数据集。

目前最新的是700多个，那么这里面做部分的一个啊清单，给大家做一个分享啊，那么在可信数据集的流通呃，这个路径上呢，从绘制这个数据资源地图，到数据及入驻我们的交易所。

到和这个中国信通院联合做可信AI质量评估，最后到上市合规审查，那么完成流通交易的一个闭环，以及配套数据资产化服务，帮助数据集的主体噢完成数据的入表，融资抵押等等相关的资产化服务。

那么这里面是可信数据质量评估，我不赘述了，前面老师已经讲过，那么同时呢也通过这样大模型，上下游的这样的一些生态优势，那么将我们的这个数据集，我们的大模型的上下游厂商，那么带到我们的这个训练场哈，训练场。

那么同时呢中国电子云也参与和主导，我们北京人工智能训练场的一些规划设计，那么左边的字算中心也是中国电子云来承建哈，右边是我们正在提出来的规划，希望打造数据集算力，以及和交易之间的一个流通闭环。

那么最后小结一下呢，中国电子云在啊，人工智能这块是一加N加M的这样的一个呃，策略或者模式吧，一就是一套可信的智算平台产品，目前已经上市，N呢是投资和建设N个可信计算中心。

那么包括哦我们这边看到的武汉经开，还有石家庄，还有北京亦庄，那么打造N个某个行业模型，那么右边我们也看到这是公安领域哈，在面向竞争，缉毒等不同场景大模型的孵化，那么呃很快把我们这个在全国数据流通交易。

给大家做一个分享哈，那么希望我们的产业链朋友，能够在数据流通交易这样的一个网络里面，一起共享，一起共建，一起共推我们大模型的事业。



# 2024北京智源大会-人工智能+数据新基建 - P9：圆桌讨论 - 智源社区 - BV1qx4y14735

呃林老师和肖老师都做过报告哈，所以我就想我们把开场的机会给到啊，红门企业界也是呃那个呃很多今天赶过来呀，我想听完有很多的想法嗯，那我们能不能从这个要不从陈明总开始，我问题是这样，就是看看呃。

今天听了很多这个数据方面的挑战呀，问题觉得呃是不是说到了，觉得有没有受到了哪些主要的启发，还有你觉得哪些挑战是没有，今天没有讨论到，没有覆盖到的，呃大家好，这个非常荣幸有这样的机会，参与这个圆桌讨论啊。

我是来自南方电网公司数字化部大学处的陈冰，那么主要是针对今天的这个数据集压，高质量数据供给到人，人工智能，包括大模型这块的一些工作呃，平时在负责这这些相应的工作，那今天听完这个论坛之后呢。

我几我自己有几点这个比较深的一个体会啊，首先呢就是说今天的这个论坛，各个专家提出来的这个论点，包括一些研究的方向，其实是非常契合，我们现在企业正在开展人工智能加的工作的。

呃第一个呢大模型这块的这个这个带来的，这个对企业带来这个变化是非常大的，它改变了我们整个生产的模式，管理的模式呃，还有创新的模式，所以对于如何能够用好大模型，真正能够发挥大模型的这个人工智能。

大模型的这个作用，其实是我们企业比较重视，也是比较在一直在聚焦了个问题呃，因为我们不是为了建大模型和建模，大模型是一定是通过大模型来反过来，促进我们自身的管理呃经营，甚至乎一些新业态。

新商业模式的这个发展的，那在这个过程中呢，我们确实也遇到了一些痛点，比如说从数据数据这个数据集本身啊，我们的这个质量，还有这个相关的这种联通都有不不少的挑战，首先从这个量来说吧。

因为我们本身嗯经过数字化转型，很多企业都是通过数字化转型，带来了些从线下到线上的业务的发展，然后积累了不少的数据，但是其实这些数据对我们在大模型的这个，训练和推理过程中呢，其实是远远不够的。

今天很多的专家也提到了这个呃，不我们如何能够解决我们这个量的这个问题，其实是摆在我们目前在国企业界，我们作为这个大模型使用方的，这么一个非常重要的一个很核心的一个问题，第二个就是智，大家也知道。

大模型它是需要用数据不断去训练的，就像个小孩一样，你要喂给它比较准确的数据才能长，才能长得好，那如何能够提高我们本身数据的质量，这种数据质量刚刚我们信通院的专家也说过。

他其实跟我们原始的生产管理的这种数据质量，还是有不同的这个维度和不同的这个方向的，对吧，我们传统我们做到数据管理能力成熟度，PU已经到了五级的这么一个比较高水平的，一个阶段。

但是是不是就能够满足人工智能带来的大模型，带来的这个需求，目前我们来看，其实还是有比较大的这个这个比比瓶颈的，第三个呢就是流通，因为本身企业的数据，它可能更专注于某一个行业。

但是大模型它更更多的要发挥跨领域，跨这个跨界的这些数据的融合创新，协同复用的作用，所以如何能够更好地获取这个，我们说的跨域的数据，这个其实对我们企业来说也非常重要，譬如我以我们电电网企业为例。

我们需要有很多的类似像气象数据，像经济这个经济经济数据，人口数据等等来协助我们做什么呢，做电力的整个规划，能够更好的去建设我们的新型电力系统，更好的去消纳我们的新新型能源。

更好的去做好我们这个供给侧的这块的这个呃，原网互动等等，这些都是要有很多的，除了电网之外的数据来整合在一起，来去训练我们的模型的，所以这块也是我们比较大的一个遇到的痛点。

那今天有很多的这个专家学者也提到了，包括我们这个资源，提供了很好的一些数据集的这些案例，我觉得未来我们可以有很多的合作的这个方向，第四个就是在这个合规，合规的这种流通的基础上。

我们如何能够更好的去促进数据的这个，互信互用，那现在目前有很多业内有很多的这种技术，包括像隐私计算，包括像可信空间等等，但是要真正的落地，我觉得目前还是有很大的这个需要去努力的，这个空间的。

那这几点我从今天的会议上面，我也得到了一些启发，包括刚刚中国电子这块，中国电子云，介绍了他们那些数据流通的一些，基础设施建设的内容，我觉得未来对我们在电网行业，更好的去推动大模型。

更好地推动数据驱动会有带来很好的帮助，嗯今天谈的这几个话题里面，我觉得呃稍微呃没有讲到的话题，可能是跟人工智能的伦理的话题，因为本身这个事情，对于人工智能发展也是很很重要的啊，这块可能从不是从技术上。

而是从更多的从法规，从伦理上，那这可能跟我们这个今天的这个这个议题，可能不太这个贴近，但是我觉得伦理其实也是人工智能比较，必须要去考虑的问题，包括你刚刚说到的这些数据。

因为数据本身对于大模型的这个发展来说，非常重要，他对数据的这对对大模型的这个训练，它带来的方向是好的，对的还是不好的，它其实它里面也存在着一些的伦理的问题，那这块可能接下来在业界。

可能还需要更多的去研究性去探索，好谢谢谢谢谢谢，刚才提到了量质量呃，流通融合，还有我们伦理方面的哈，还有请赵总，韩信是我们每天都在使用的，呵呵是啊，各位专家呃，大家好啊，那个我是来自中国航信的赵玉霞呃。

大家可能对中国航信不是很了解，所以我用简单的几句话先自报一下家门呃，中国航信呢是国资委管理的97家央企之一，那么同时呢，我们也是民航全行业的信息服务平台呃，中国所有的航空公司呢。

都是通过航信的这个SAS系统，来完成它的旅客服务和机票销售的功能，那中国的这个所有的机场呃，也是通过航信的平台来完成这个值机呀，还有我们的这个安检，以及这个呃登机这些业务的操作嗯。

机票的代理人也是通过接入航信的系统，来获取实时的这个呃座位信息啊，来为这个旅客实现这个订票啊，所以呢我们的系统里边，实际上是沉淀了整个行业，民航业过去30年的，这个所有的这个旅客的行程数据嗯。

我们恒绿纵横是我们推出的一款，面向C端的这个应用啊，因为背靠航信的这种呃全行业全量级的数据吧，所以航旅纵横一经推出呢，就受到了大家的欢迎，所以很多很多朋友就不知道中国航信，但是呢是航旅纵横的深度用户嗯。

这几年呢我们航信也是在积极的拥抱人工智能，我们组建了这个智能创新的团队和大模型的，厂商呢，这个主动建立合作啊，也在探索落地这个大模型，在民航业的这个应用场景，那其实我们的目的呢。

还是希望能够跟上这波人工智能变迁的潮流，然后更好的赋能我们的行业，那就回到今天这个会议的主题，这个数据这个层面呢，嗯民航业基于自身的，就是一个沉浸在数据中的行业，因为我们是最早实现实名制交易的行业。

所以我们这个行业当中呢，就是存在着大量的这个敏感数据啊，和这个关键基础设施的数据，比方说这个旅客的姓名啊，身份证号啊，他的行程啊，航班以及这个发动机，就是核心的这种发动机的这个运行数据。

所以民航业的企业都会比较关注这个啊，数据的安全问题，数据隐私保护的问题，数据泄露风险的问题，嗯所以在应用大模型的时候就有一种顾虑，因为大模型的这个训练的语料啊，以及这个这个向量数据和这个接口数据。

里边都会包含很多的这个啊敏感数据，比方说这个航班的数据啊，旅客的个人数据等等，那如果这是这个不加保护的话，这些大模型在组织应答的时候，就有可能把这些隐私数据泄露出来，那么还有一种可能的话呢。

就是呃也是可以，也有可能是通过这种反逆向工程的这个方式，去反向获取这个我们的训练数据，所以这个数据的脱敏是非常关键的，数据隐私保护非常关键的嗯，但是呢这个文本的数据可能脱敏，就是手段比较成熟哈。

但是我们还有大量的这种多模态的数据，比方说呃客服的语音啊，以及这种远程的监控数据，还有一些个这个图片的这个几个记录数据，对于对于这些多模态的数据，海量的多模态的数历史数据，那么如何进行啊。

快速的安全的这个脱敏，这是我们在实践中遇到的一个一个问题，还没有一个成熟的方案，当然今天这个通过参加这个会啊，我也这个这个很有收获，那接下来线下呢，我们也是希望能够，广泛的和这些个技术供应商进行接触啊。

第二个第二个问题呢，其实就是因为我们是具体的这个业务系统，业务操作系统呢，那我们更关注的是这个大模型的这个，去幻觉化的问题和精准拉齐的问题，因为我们最终的目标，我们是希望能够通过大模型。

然后形成一个精准的答案，然后直接驱动我们的业务系统，这里就对这种呃精准要求的就比较高，所以但是目前来讲的话，我们是看到就是还是呃离离，达到这个最终的这个驱动呃，实时驱动业务系统。

还有最后一公里的这个距离，以上呢是我们这个目前在应用中，关注的两个点啊，非常好非常好，大家也知道这个航旅纵横的背后了，谢谢来有请，反正我们国双了呃，感谢啊，今天有今天有，你要不用我的呃。

感谢今有今天这个这样一个机会来来嗯，做做一些分享，是我来自国国双科技，是这个我们国双科技呢，因为可能大家都不熟悉嗯，简单做个介绍呃，国创科技呢是呃一个组为为大大型客户嗯。

包括我们大量的央国企客户或者政府组织的，数字化智能化区域呃，服务提供底层基础软件的一家公司，我们的产品呢，我们自己把它叫做数字底座基础软件啊，在这个这个服务呃，结合今天这个话题呢。

就说的嗯大大模型与呃呃数据这个话题呢，其实我我更多的是在想分享一些，我们在实践中的一些呃，一一些碰到的一些问题或者是困难，嗯很很高兴呢，这个碰到这些问题和困难，今天看到了在这么一个场合呢。

有很多专家做了一些分享，也做了一些探索，那这这这个主要是探索，那个我们这些困难是哪些方面呢，我觉得呃第一个就是我们这些大模型，其实大模型这两年活了这快两年了呃，但是怎么到企业或者产业场景去真正落地。

可能大家这个这个呃，今天没有看到很多的这样分享，那我们我呢首先来分享一下，我们在这方面的一些呃一一有一些实践的应用，最大的感受呢就是大模型这个嗯，提供的这些这些结果，或者是智能的到场景里边去。

大模型总是这个似似而非呃，往往很难去解决企业的呃，现场的呃真正的问题，这个这个问题呢，这个这个其实也不奇怪，因为大模型是预训练模型，用的数据是过去的数据，它不是实时数据呃。

很多数据呃呃呃那个向量根本不够，所以所以说呢他很难去解决问题，解决问题，这个这个时候呢，那我们我们在这个实践中过程中呃，我们一肯定是，这就是模型，怎么和企业内部的这些数据去结合起来。

这个就是把大模型这个设计的，这个呃是嗯通用性质的数据呃，的经过通用数据的训练的这种模型，怎么通过企业的私私域性质的数据去结合起来，去训练，再再来二次使用，这这这是一个也可以把它作为垂类模型。

都往往行业发展的一个一个方向，那我们同时也做了另外一个探索，就是利用其他类型的人工智能技术来来做，做了一些呃，对大模型做出一些延展和约束，你比如说利用知识图谱技术对我们这些大模型。

继续在语料或者是训练数据的这个这个，做一些规范和收敛，或者是在它输出数据做一些收收收敛，来解解答，我们在企业生产或者设备运行过程中，碰到的这种实际问题，这是我们一个一个这个，我们一个一个比较大的体会。

其实今天还有一个这个讨讨论的，这个这个这个会场呢，还有第二第二个我们觉得就是没感受到的，就说在企业内部，其实大模型运用到企业这个场景嗯，其实企业的数据这个怎么呃，今天这讲了。

要要我们要要要这个实现行业数据的统，但是怎么去统，尤其是在企业内部怎么统，我们都知道企业内部有数据孤岛，信息孤岛，这个首先企业内部的数据的统通融，这是一个今天没有涉及到的话题，这个话题其实很关键。

如果大模型往后续发展，或者要做成垂类行业模型，如果这一方面没有突破的话，很难首先统这个我们都知道，其实过去信息化时代积累了很多信息化系统，这些数据统起来是很难的，有历史沉淀的，有标准不一不一的。

还有各种各样的这个呃变化的，这些数据统计来是本身是就是一个难题呃，通那这个这个就是个数据的标准化，这个数据的标准化和数据治理的问题，这个通也是很很难的一件事，融就是更难了，容就是我刚才讲的。

就是你比如说在一个一个工业设备，在一个生产线上，它在运行过程中能采集很用IOT采，采集很多数据，但是这些数据和它的结果之间有什么关系，你比如说一台一台设备的振动是什么，引起发的振动。

这些要增加数据的向量纬度，这些数据呢，但是呢在采集的过程中往往是采集不到的，需要我们在这个很多现场，自己生产线上的一些一些专家，去为这些数据去附附加附加一些信息，附加一些新的内容内涵去去做的。

这是说这这个程度层层面啊，所以说我们目前只是感受到在企业维度，就说大模型和企业到企业场景的应用嗯，感觉还有还有很一条路走，第三个方面就是今天也涉及到，今天也听到了一些涉及到一方面就是大模型。

实际上嗯涉及到成本的这个算是算力，也需要成本，数据采集需要成本，那企业生产这个刚才一开始冯院长就讲了，企业要叫追求价值回报的，那这个大模型在企业这个应用成本怎么去解决，这个目前是说实话。

我们在呃在我们自己的在业务实践中呃，还没有看到很好的办法呃，大型企业可以承担成本，那面向中小企业呃怎么去解决，这是这是我们没有解到呃，呃我这是我的一个理念，感受特别特别认同啊，潘总其实刚才也谈到。

就是这个企业走向这个拥抱大模型过程中的，这个好像抱不住一样的，这个这个隔隔山隔水的这种这种挑战感吧，嗯然后接下来我其实想特别想问两位老师的哈，其实嗯李院长好，肖老师现在都是很好的朋友啊。

我觉得他们对业界的看法，每次其实都是非常入木三分的，其实我一直在思考一个问题，包括呃刘长一开始讲的就说，其实数据集对人工智能的发展是极关重要的，我们回去看历史都是这么驱动过来的。

但是为什么这些数据集本身也不是中国的啊，其实要回归问题，就说呃就是我们能否就是就之前的数据共享，就是驱动了技术的发展，那就是有人看到了这样一个就是技术的卡点，要从数据的角度来解决，其实我们我不知道。

我我其实觉得大家都知道这个这种差距，但差距一方面在算力，但算力不可能是全全社会去公关这个算力，这是不太可能的，但是然后第二个大的这个卡点可能就是数据，数据可能是需要更多的人合作，在这个过程当中。

其实我觉得它分几层，一是我们数据本身的状态，就是就是就是个包括通识数据哈，包括我们有什么样的数据，第二层才是说我们数据的流通，共享的这样一种机制也没有设立嗯，第三才是说哎我们我们要赋能整个产业的话。

那不太可能像学术界一样，只是拿一个数据集触动技术的发展，是整个整个体系的，其实我很担心说，如果啊这个方面是落后的，其辉其实会又让我们整个产业的升级落后，其实想听听嗯，两位老师的想法，就国外有很多呃。

企业很多作通方式，就目前来看确实就包括各家做大模型的，其实国外数据用的是更多的，怎么从根本上我们能推动带来这样一个势，能，解决这样一个呃，就数据上面的这个问题来，要不李院长您先来好，谢谢。

这个是个挺难回答的问题，就是的确现状，就是说现在看到大家都看到的，所有的大型数据集，都是来源于很多年前，这些非盈利机构或基金会的的的，一直在做，并且有意思的是说。

甚至例如这条中中间那个common cor，他们在2007年做这个的时候，其实并不是因为大模型需要，那时候都还没有大模型，他们也是一种抗拒垄断，所以为对没错对，包括其实还有一个书籍的书籍叫古腾堡。

也是这个也是大量大家会下载，用来这个免费的一个书籍，数据也是很多年大家考虑到，我要保护所有这些书籍，所以免费的聚集在一起，所以所以其实那个呃，为什么这些都会出现在国外，而国内很少。

其实这个里头呃这个这个挺挺难回答的，这个问题，但我想回答另外一个问题哈，这个嗯就说那我们既然看到这个问题，我们希望用一些什么办法来去解决呃，虽然现在想不到什么根本性的解决方法，但是呢解。

这也是为什么我们呃在刚才介绍那平台里头，打造的三种方式，第一个开源，就说我们还是觉得是说，当我们去跟好些企业说哎，一起来贡献数据，他们有可能会有几种态度说哎我的数据呃，我只愿意在小部分人里头去共享。

我不愿意拿出来，或者说我就只愿意定向的去给，那我们通常都会去再去磨一磨，说那你是是否可以再来一小部分，您觉得没有，那么呃呃呃价值敏感性的再拿一部分出来呃，我们是可以放到开源社区啊，这个是我们一直在做的。

就所有所有我们接触过的，我们在过去印一两年，接触了很多几十家数据企业呃，然后每一家我们都会这么做，所以第一个要保证开开源有一部分，但是的确呢就说我们中间那个共建共享，那个机制是我们很想打造。

因为实际上现在至今为止，不可能有任何一个企业自己可以靠自己的能力，建起来这么大的自己训练要用的数据，他肯定要用到别人的数据集，所以这也是为什么，我们呃就是去去尝试这样一个手段。

就是说当他自己贡献的一部分，我们会把这部分数据去衡量它的一个呃质量，把这个质量系数乘以它的贡献量，就得到一个积分，他可以拿这个积分在我们这个工作组或联盟内，去换取他其他人贡献的数据。

这样子做一个这样子的一个一一种交换，那呃我们我们的一个发现是说，在去年刚开始做这个事情的时候，其实很多企业都是比较观望的，但到今年呢实际上越来越多的一些呃企业，他们被会比较积极的去加入进来。

那我猜想是说，尤其照今年那个多模态模型，纹身视频，这些就更加难去通过企各各自去解决这个问题，但坦白说这个方法是不是根本性解决呢，也不是也不是，然后所以我们又又又打造第三种。

就是说有一些的确有一些有一些重要的这些，包括视频数据，影视影音数据好多实际上都都是有版权的，那对于这些高质量数据，那我们就让他就撤，就说我们先把这个安全性保护起来，让他没有这个安全性的顾虑。

然后但是这个数据不能出来，但是通过这三种方法，其实我们只是解决了一个数据的一个呃，在一定范围内流通的问题，但是其实并没有是说真正的全全部打开，这个数据孤岛嗯，呃让整个产业去去去。

有一个呃绝对放心的一个一种方式，来把这些数据都去用起来啊，那所以在这里头，我们也是因为我们知道，这里头可能还是会有好些这个呃法律法规啊，有因为毕竟当初从版权法等等。

并没有预料到今天会这个数据会被机器学习，而不是被人去看去传播，那因此呃，有些东西可能还是要从立法或司法解释的角度，去进一步去推动，那现在我觉得现有的一些想法还是权宜之计好，谢谢来曹老师，谢谢刘娜。

跟我们一起思考，对啊冯老师这个问题很有挑战性啊，就是说我们怎么去构建围绕人工智能大模型的，这个高质量数据集，其实这个数据集构建两种基本机制啊，我们看到国外主要是靠开源开放。

那为什么我们国内没有那么多开源开放啊，我想这可能也是我们的发展阶段决定的，我们才发展多少年啊，我们的这个进入信息化，进入数字化时代才多少年对吧，所以我们整个的这个发展的这个这个阶段呢。

决定了我们可能开源开放没有国外的发达，这个我觉得也是客观现实啊，所以呢在从开源开放，我们能够的数据集可能不多，或者主要依赖国外的，那么另外一个我觉得很重要的就是购物数据，这些机制是什么呢。

就是要建立市场机制，所以我们现在当下这个数据要素，这个市场制度的建设完善呢，对于这个数据的汇聚啊，数据集的构建可能是一个非常重要的一个啊，一个一个推推动力啊，我们只有建立起明确的这种市场机制。

让数据贡献者能够受益对吧，能够通过咱们大模型，你贡献一份数据，你就能够享受到一份利益的话，那么谁不愿意贡献数据呢，啊现在很大的问题是对吧，这个啊这个啊都要啊张罗大家来贡献数据对吧。

那凭人家凭什么要白白的贡献数据对吧，一定要让这个贡献者能够受益的话，如果我们建立起这种明确的市场机制的话，那我相信大家都是愿意把数据共享出来，当然有前提啊，前提就是你不能违规。

你不能违反这个数据的相关的，这个法律和条规啊，但实际上现在大家实际上这个缺乏这个动力，当然这背后当然也有很多其他的一些原因，还有就是一些啊，主要是一些机制上还不明，尤其是市场机制不明。

但不配套的市场机制呢，我们还要要有刚才这个林院长说的，这种相关的这个法律法规啊来配套，但是呢我想还是要再想再补充一点，就是如果市场机制弄好之后呢，哦我相信可能会有很多数据，但事实上呢。

我觉得像今天我们整个研讨会也到最后了对吧，我们今天整个想的就是说啊，都都是在做加法啊，数据要越做越多，其实我们也可以去想想减法啊，我们真的要那么多数据吗，有时候我想问问这个问题对吧。

虽然我们大家号称都要建大模型，那待会现在建数据集，其实有点我感觉是有点盲目的啊，就好像越多就越好，大家都很喜欢用数字啊，我有多少个数据了是吧，那那我就要问一句，那是不是越多就越好啊，可能不是的啊。

我今天上午跟那个冯老师，我们在聊聊一个很有意思的问题，我们说2000年前的这个柏拉图的吧，他们哲学家很聪明，孔子也是2000年前的很聪明，他们那个时代有多少书啊，他们读过多少书啊，但是他们很聪明。

我们现在大模型读的书比他多得多得多对吧，读的数据多得多，但是我们现在大模型真的智商就比他们高吗，我也不觉不觉得，也就是古人为什么能够读那么少的书，却能够形成达到我们今人这么高的智力水平呢。

那这是值得我们去思考的，也就他们当时没有那么多书读啊，但是人家却能达到很高的智力水平啊，所以很有可能啊，我们因为缺失了高质量训练数据集的这个标准，我们现在并不知道什么叫好的数据集。

所以我们的数据构建是不是有点盲目呢，啊所以尽快建立这个标准呢可能是更重要的啊，那么其次呢啊我们也要去想一想，是不是所有的数据都要塞到大模型里，也不是的，刚才有专家也说，这个问题就是大家很痛苦对吧。

行业的问题，大模型一用都不行啊，事实上我们现在可能到了一种，对于大模型寄予了过度厚望的阶段，事实上很多数据它就不该进大模型，大模型主要还是侧重在去再现人的智力水平，能力，对吧啊，记住了一些很琐碎的事实。

比如说我们说金融行业的什么交易的，股票交易价格，今天的汇率，对于大模型的智商提升并没有任何作用，所以有很多数据，尤其是那个事务型的数据，它该放数据库里，还放数据库里面。

这些数据的处理该用小模型还用小模型，该用我们传统的规则还用规则，所以并不是所有的事情都还要让大模型，我们现在对大模型有一点过度期望，是似乎everything大模型，所以大家现在遇到很多这种问题啊。

如果大家如果摆正了这种观念的话哦，你知道哦，未来其实落地并不是说只靠大模型，也并不是所有数据都要放到大模型里面啊，而应该是什么有所筛选的啊，有所依据的，那么大家对很多问题的这个。

我觉得这个结论就很清晰了对吧，我们可能没有必要盲目的去建那么多数据，可能要更重要的是它的这个质量，或者对于行业的这个啊能力的提升啊，所以我们觉得我们我们今天可以到最后阶段，也可以反过来去想想这些问题啊。

特别特别感谢那个确实是其实做到一定的程度，就像人家说这个中年人做到一定的时候，要做减法一样，其实嗯我正好谈到这个话题，我想也这都是大家的一个重点，所以我在想就是针对不是所有的数据都有隐私。

不是所有书都这真的需要保密的，我觉得把数据还明，比如说我们的互联网数据，其实就是老百姓产生的，那这时候数据其实来源它不是某一家公司的，它就是我们大众产生的，那这样的数据，其实应该谁是真正的数据的拥有方。

像这种老百姓就是它的拥有方，我产生了，其实这种情况下，就像我我们中国人说东北人都是活雷锋，好像其实活雷锋挺少的，在数据这个领域，你像我们大家都用com crowd，人家也积累那么多年。

其实大家也都拿来用了，其实会确实促进了社会的发展，所以我就是在这种通史的，其实可以把数据还明，我觉得这部分确实怎么样，我们能把这个真正的共享分享啊的，这这个功能真能做出来。

我想会有我们的通识数据会解决极大一部分，针对行业的，我觉得那种高价值的针对行业，直接可以带来很多价值的数据，确实是我们要解决这个，这个就像就像你说我们原来用货币交易，现在用这种刷卡，就就是这个扫码。

就可以找到一种快速的一种交易方式，能够让这个东西真正流通出来，我觉得以前我们说数据库，然后我们说数据湖，现在大漠新时代，可能需要怎么才能汇聚到一个数据的海洋，其实这个这个量级上的不同哈，就这个确实是。

之之之前那个肖老师讲到这个价值，我觉得如果是水往低处流，那数据应该从低价值相交，高价值去流，最终才能汇入这个大海啊，其实我觉得需要需要修通一些这些价值渠道，让数据在这上面流通。

能真正汇到我们这个数据海洋中去，来哈啊时间关系哈，就是呃现在还有十十几分钟时间哈，嗯我我一般主持圆桌，我会先给老师们发一些问题，然后等他们来了，坐下来问的问题都不是那个纸上的哈。

今晚这种模式哈啊这个今天呃快结束的时候，我觉得也是就国家在提AI加的这个，心智生产力吧，嗯其实我觉得嗯其实有几层，一层是我们的基础部分，怎么让我们的基础模型的智能做好，还有不是我们产业升级的部分。

呃其实我觉得这个也很重要，如果如果我们呃像我们国家，有很多产业是领先的，但如果在这次大的智能化升级中，我们跟不上这个时代，我觉得会让产业全面的这个落后，所以在这个AI加的这个部分，我觉得非常非常核心的。

其实像呃在座的也有，大家听了一下午也很辛苦啊，看看老师们在AI加生产力中，如果您给业界提一个建议，简短的话啊，看您觉得我们最核心的，尤其企业的，我们应该抓住哪些问题呃，来推动AI加生产力的真正的形成。

因为因为我自己觉得在企业中这么多年吧，啊然后我看嗯刚才两位老师讲讲完，我们要不要从彭总先来，然后我们就今天啊老师们回答完这个问题，我们就结束今天的这个啊，好的，这个这个我这个问题其实也也是有挑战性的。

别人本身心智生产力是一个比较新的新，新的概念，然后这个大模型啊，人工智能也好，也是个概念，新的概念嗯，冲我的我们的理解呢就说呃我们讲人工智能，强调数据，算力，算法三三大核心要素，其实在我们在实践中呃。

我们自己又加了一个要素叫场景化落地，嗯啊因为为什么要加这个要素，就是因为AI最终是要解决问题的，是要替代人去工作的呃，或者是去帮助机器更加智能化的，那这从这个维度呢，就那都这个是要放到具体场景里边去的。

那具体的场景呢反过来基于场景，它对数据有要求，它对算法有要求，它对算力也有要求，所以从这个维度呢，就说我我们我我想提的建议就是，希望大家除了关注大模型，除了关注其他，更多都要关注场景。

我们每一家企业在推动自己的数字化和智能化，过程中，要选好自己的一个场景，以场景驱动去选一个最对自己可能最重要的，会最能带来效益的场景，去推动它的数字化和智能化，只有这样，我们我们的数据去整合。

我们的这个这个这个这个算法，不一定非要用大模型，刚才说了，不一定大模型，我们就实践过程中就是要大模型，小模型结合起来去去去做，所以说我的建议就是呃大家关注场景化呃，推动行业的场景化。

推动企业的场景化落地，去让AI更好的服务我们企业，服务我们行业，谢谢彭总啊，这场景非常重要，其实我们通过如果真的打穿一个场景，其实也学到了，找到了一种模式来赵总嗯，那个嗯因为我们所处的这个民航业嘛。

是一个典型的服务业，所以呢整个行业全行业的这个收入的这个来源，就一个就是旅客的客票收入，所以旅客的满意度，然后旅客的这个出行的便捷性，以及我们整个行业效率的这个运营。

就是对我我们民航业来说就是核心竞争力呃，整个民航的话，特别急需大模型的加持，呃，因为大家都知道，我们在面临高铁的强有力的竞争，所以我们这个航信呢也是也是在在积极寻求，这种呃这种啊大模型的这种落地的场景。

那么我们的建议呢哈就是说呃大模型啊，加上呃行业知识库，再加上呃智能化的行业应用，这三者相结合，然后来去产生更更高的这个生产力，那举举一个具体的例子，就是说啊比方说我们的这个呃。

那个那个那个机票销售的这个场景，然后我们可以就是向前延伸到一个这个，出行规划啊，我们可以结合大模型，就是精准的深度的理解客户的需求啊，再加上呃呃就是分析把握客户的偏好，那么从从中呢就是帮助客户啊。

打造一个最优的这个出行方案，那同时的话呢再加上我们的业务系统啊，可以可以直接驱动这个啊，后台的这个订票和处理，从而就是提升整个行业运营的效率，所以这个呢具体的其实也是，跟彭总的这个意见相一致。

就是说在这个大拇这个落地的过程中，要找准具体的场景，不要嫌小，其实能有一个嗯能够发挥价值啊，能够提高效率，能够提升客户的满意度，哦那个我这边也也也说一下，因为我很赞同刚两位专家的意见，从企业界来看。

我们其实就是以场景触发的，我们很多的这个做人工智能大模型的初衷，其实就是为了提高自身生产经营的效率，提高我们整个企业的运营这个质量，能提升我们整个企业的这个这个增长啊，各方面的这这些相关的这个要求。

所以从这个方面来说，我这我就我把它归纳成一个一个方向，叫产业自身的这个升级，这是人工智能带来一个，毫无疑问的一个非常重要的一个作用，但另外一方面，我觉得从自身作为央企来说，除了自身的产业发展。

我们还有一个很重要的一个责任，就是国之大者，我们要承担着带动整个国家整个发展，社社会经济发展，还有整个产业发展这么一个角色，所以从这一条里面呢，我觉得我要给个建议，就是说可能除了我们看待我们自身的企业。

在这个过程中的不断发展，还要注重整个生态，整个这个普惠，对人工智能，普惠能够服务于这我们大众的这种呃，更多人去享受到人工智能当模型带来的好处的，这块的一些作用跟角色，就是你不仅仅除除了你自身的发展。

你可能还要在整个行业里面，你要带动更多的这个产业，产业，产业上下游的这些我们的这些单位一起来，更多的让更多的这个我们的呃民众能够受益，这个我觉得也是人工智能发展非常重要的一个，很核心的一个方向。

所以两者结合起来，我觉得才是就我们作为企业来说，在推动人工智能发展的过程中，要去考深度考虑的问题，好我就提一个建议，谢谢谢谢，国之大者确实是，其实大部分央企都有这样一个双重的角色，来肖老师对我完全赞同。

前面三位专家其实本质上我们答案都一样的啊，只不过我再换一种说法，用一种更通俗的说法，最首要的是什么，先用起来啊，不管它好不好用，先用起来啊，这个我当时我接触过一个企业家。

他要求所有的员工都必须用上大模型，在他的工作岗位里面，而且必须要用到什么比例，如果不用辞退啊，他以这样一个要求来要求他的企业员工，来逼着员工必须拥抱这个大模型，那么这样的话。

大模型一定会在他的各种工作环节，多多少少提质提效，从而形成生产力，所以博物馆AI技术啊多先进对吧，先要鼓励大家先用起来啊，你看我们学校里面的很多学生啊，就自从CHSGB出来之后。

这个论文的生产力提升了对吧，极大提升，哎这这当然这个有很多负面的不好的事对吧，但是哎你看同学们拥抱了这生产力啊，显得我们比以前更轻松了啊，再也不用再去哭闹语言的问题了是吧，所以你先用起来。

它就一定能够形成生产力啊，当然再往深了再挖一步，那么怎么才能用起来呢，其实先学起来对吧，其实如果我们真的去做一个调研啊，真正现在用上大模型呢，已经在工作中是切切实实提质提效的。

估计这个比例在整个人群中啊，在咱们国家可能还不高啊，我们在座的可能因为各位从事这个行业，可能用的比较多，但是如果我们再广泛一点，在其他行业呢，我们到底有多少人在用这些大模型呢。

啊实际上可能还是打一个大大的问号，所以呢还是要先学起来先教起来，所以啊又回到我们老本行对吧，因为我从事教育工作，所有未来可能啊大量的教育的工作，可能我们需要开展啊，什么是大模型，怎么用好。

大模型怎么练好，大模型是吧，在行业中怎么去富呢，所以学起来用起来啊，这是我的一个观点，谢谢肖老师，那个，因为前面几位的专家都已经说到这个场景啊，那我补充一个，就是说质量就说其实AI呃落地呃。

呃AI加新智生产力，如果要成功，要大范围的那个行业落地，那实际上它不在乎是今天的大模型问题，其实过去过去10年，那个在AI的发展小模型阶段，其实大家也希望它广泛的落地各个行业，呃。

但是呢就是说呃我们看到的就本身，我们因为是从事AI就知道是说其实有很多嗯，实际上它是呃可以被AI来实现它一个数字化，智能化，但是呃最终并没有大范围使用，就是因为最后一公里的质量问题没能够满足。

是说我们利用从80%到90%，甚至95%的这样一个准确性，那这样子必然是会呃迟迟迟缓，这个大范围的使用，尤其是用到一些核心的，因为今天我看到大模型，大量的可以作为人的助手，去帮我们去做一些事情。

然后当我们发现他做的不够好，反anyway，我们有人在边上就可以给他去的输出进行修改，后，一次不行，我就再多来一次，这个没问题，但如果我们希望是说，用到一些更核心的一些，对他们的一些智能化的一个升级。

那这一块我觉得是属于我们从事AI，或是我们在锻造这个基于大模型好，AI也好的这些智能化的这些呃呃能力的时候，我必须要考虑，怎么把这个它的准确率进一步提升，那这里头背后其实还是需要我们呵。

从技术这方来不断的往前进，嗯好谢谢啊，刚才那个老师们，都快速的给了自己的真知灼见哈，嗯也是嗯就接着刚才李院长讲的，其实其实我觉得在这么多年，人工智能发展过程中，我自己是在这个领域30年了。

已经我我觉得其实我们做了更多的人工智能，智障产品，不是人工智能智就智能产品啊，其实我们很多这个产品，如果我们我就说你有这个技术和没有这个技术，别人的生活，尤其业务方的会因为你而怎么样不同。

所以我其实想呃，就是最后也是就是大家有特别年轻的，不管是就是贡献智能的，就是你是智能的供给的从业者，还是你是智能的使用者，还是我们智能的管理者还是设计者，其实我在我觉得在这里面有一个非常核心的点。

就是呃一一个建议吧，希望我们真诚以待，就是我想我们可能在西就是呃，我们说你写一篇文章，你想感动别人，你首先得感动自己，所以你有一个赤子之心在里面，你想想，那我们做成事情其实更难。

就是如果你出发点就是我们从业者本身就，有的时候感觉这个技术是个热点，如果只是雁过拔毛，我觉得这个事情就就做不成了，就很多时候就是我们不管是从顶层的设计，刚才我说达到AI加的时代，我们需要一些顶层设计。

不管是用顶层设计还是我们供给还是使用，还是我们监管，我觉得能真诚以待，我觉得这事情就会更好的往前推动，就我们放进去的都是一个加法，而少一些呃，追热点少一些呃，觉得这个东西是一个什么样的机会，什么样。

我觉得智能化时代它不是一时会过去，它会陪伴我们很多年，我觉得可以更加理性的，更加真诚的来到这个行业，在这个行业当中，我想可能是对我们这个一个比较大的一个，推动作用哈，呃今天我们前面的耽误了很多时间啊。

我希望我快速的这个我们今天的援助，给大家找回了一些时间，希望大家有所收获，我们最后以热烈的掌声，谢谢几位老师们。



# 2024北京智源大会-多模态模型 - P1：论坛背景与嘉宾介绍-主持人：李亚州 - 智源社区 - BV1sT421a7FU

好的，各位嘉宾老师，现场及线上的观众朋友们，大家早上好，欢迎大家来到北京志愿大会，多模态模型专题论坛，我是今天这场论坛的主持人，机器之心主编李亚洲，我们知道让大模型具备多模态能力。

是当前整个大模型社区非常重要的一个研究方向，特别是GPT-4O发布时那种自然流畅的语音，视觉以及文字的多模态交互能力，令人印象深刻，所以说我们今天这场专题论坛，就显得非常有价值。

邀请到了这个领域多位有代表性的专家学者，为大家做主题分享，在主题分享结束后，也会有一场圆桌讨论，为大家提供一个思想碰撞的机会，希望我们今天这场论坛，能够让现场的观众朋友们收获满满，不虚此行，好的。

那我话不多说，我们今天的活动就正式开始，首先让我们有请今天的第一位分享嘉宾，智研研究院视觉模型研究中心负责人王新龙老师，他的分享主题是生成式多模态模型。



# 2024北京智源大会-多模态模型 - P2：生成式多模态模型-王鑫龙 - 智源社区 - BV1sT421a7FU

2014。05。22 上海当代艺术博物馆 李冠辉。 东方太模型，大家好，今天很荣幸有这个机会跟大家分享，我们最近在东方太模型上面的一些思考跟最新的一些进展，首先先说一下背景。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_1.png)

大家都不用去强调我们语言视觉各种模态的一个作用，我们显而易见的每时每刻都是生活在一个，包括语言视觉等各种模态的一个context，一个上下文里面，然后去做各种的任务。

可以理解成我们的最大的context lens是100年，当然这个不是一个无损的context，只是说我们在这种动态上下文里面去接受它的信号，同时完成各种动态的任务，所以说在这样的一个环境里面。

动态的这种上下文能力就显得非常重要，这是对应我们今天说生成式动态的动态这个词，生成式大家相信也很熟悉，跟生成式相对的，大家一般会说判别式，discriminative，比如说我们以前在img。ly上面。

选一个1000类的图像分类模型，我们说它是一个判别式的图像分类模型，跟generative一般经常出现的，就是unsupervised，我们认为比如像GBT，它可以在text上面做生成式训练。

generative protraining transformer，实现一种无监督的学习，这样学完之后，最后它变成一个generalist，就是一个通才的模型，与此相对的是一个specialist。

就像刚刚说到的，我们在图像分类，或者一个任务上训练一个专门的模型，对应的就叫specialist，所以我们可以看到，整个GBT系列的成功，它其实很好的对应了，它是一个在文本上，unsupervised。

generative protraining的一个generalist，然后我们思考，我们做这个，最近的一个动机是，成功能不能复制到，包括视觉跟动态的领域，然后也是今天想跟大家分享的一些内容。

首先可以先回顾一下，这个GBT的成功，它带来了一个很强的。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_3.png)

上下文学习的能力，我们叫incontext learning，可以简单回顾一下，就是说这个是，GB3 paper里面的case，跟它的定义，左边这个例子很好理解，我们这个原模型训好之后。

我们给它几个这样的例子，比如说把这个顺序编对，然后虽然它训练里面，没见过这种任务，但是你可以在，推理的时候test time的时候，给它一些example，然后它可以实现新的任务，也就是说它通过。

预测未来会发生什么，来完成一些训练里面没见过的任务，这个我们看到在语言里面，这种incontext learning的能力，取得了很大的成功，所以我们，比较早的一个工作，当时就是想。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_5.png)

把这个成功复制到视觉领域，就是当时。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_7.png)

一个很大的动机就是觉得，说图像的语言，images speaking images，我到现在还是很喜欢，起的这个名字，我觉得这个潜力还没被完全打开吧，就是说图像可以作为一个，通用的接口。

表达跟语言不一样的东西，当然这个工作当时，二二年的工作这个动机是，把图像作为接口去统一各种视觉任务，然后实现一个视觉的上下文的能力，就像刚刚的语言一样，我们给它一些example。

然后期待它能完成已有的，包括新的这个任务，然后它把图片本身，一个RGB的图片本身，当作输入输出跟prompt，然后实现了很多任务的统一。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_9.png)

然后我们就接着这个想法，后来把它focus到分割这个任务，就是希望在上下文里面去分割，任意的目标物体，然后这个也是说，我们因为很难通过，纯靠训练本身来便利各种的case，那我们如果能在测试的时候。

给它一些比如左边这个，分割Loss spike这种case，那它能够在测试的时候，自动的学到这种能力，是我们觉得是视觉上下文学习能力，一个很好的体现，当然也包括视频里面视频分割，我们可以给一帧或者少帧。

例子作为输入，然后它可以分割类似的物体，然后这里有乱吧，然后后来应该是去年底，还是今年初，Burghley的Large Vision Models，相信大家都看到了，它把更多的数据。

它汇总了应该我记得是50个数据集，然后变成一个序列，去做这种autographic的训练，然后展现了更强的上下文学习的能力，比如说下面的这个填图的case，我把前面的这些例子码掉，然后最后给一个。

类似解答这张题的题目，然后它可以去预测，相当于通过impending，去解这一道逻辑推理的题目，当然我觉得纯图像的，应该在Lending目前还是比较局限的，我觉得两个原因可以分享一下，一个是说。

一个数据本身就是，面向视觉任务的数据，它的diversity是不够cover，我们理想中视觉任务的diversity，因为视觉任务diversity是非常大的，那我们以前的传统的，每一个数据集。

其实很难去提供一个，很完备的数据，然后另一点是，这个图像本身，它的context是比较弱的，比如说我们像语言，它的context是很强的，你一个词可能对比较长之后的，一个词产生很大的影响。

但对一张图像来说，这个上下文关系是很弱的，所以这也导致了，如果只从图像本身，它很难学到非常强的应该的能力，这也是为什么我们，前面要手动去构造一些，比较规则的context或上下文。

让它学到一个固定的能力，然后从视觉到，除了刚刚说的纯图像本身，那我们另外思考的一个问题是，能不能把它再往前走一步，走到包括图像，视频多姆态的领域，能不能实现类似GPT-3的，一个上下文学习的能力。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_11.png)

然后这里就必须得，回顾一下，sorry 这个应该是格式的问题，就是这个Flamingo，是上半年的模型，它们其实是比较早的，做这种上下文理解的能力，比如说每一行它相当于是一个任务，比如说算术这个。

我觉得是比较有意思，就是给它一张图，然后给它一个式子，然后你下面给它两个example之后，再给它一张图，它去自动地完成，图像理解的任务，但是Flamingo应该是比较早来说这个东西的。

那我们其实也是很受Flamingo的启发。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_13.png)

然后当时的，包括Flamingo包括GPT，当时的一个动机是，我们知道GPT是在文字序列里面，预测下一个词，那一个很简单的动机就是，能不能在多姆态数据里面。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_15.png)

进行生成式的训练，然后它能够学到什么新的能力，包括什么新的上小文学习能力，是我们非常关心的一个点，因为这里的数据就不只局限在文字了，它可以是图像 视频，可以是图文交错的文档，可以是视频文本交错的数据。

甚至音频交错的数据，所以带着这个动机。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_17.png)

我们去年上半年的时候，到去年底，探索了，这里是1米1跟1米2，它应该又乱码了，就是说探索生成式的多姆态训练，就是我们在多姆态序列里面，去预测下一个，那对于图像我们可能预测下一个patch。

对于这个视频我们预测下一帧，然后对于text我们预测下一个texttoken，然后实现这样一个多姆态统一的，生成式训练，然后这样训练完之后，我们的意思是去看，它能学到什么新的能力。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_19.png)

这里主要想分享的，就是它的一些代表性的能力，比如说我们刚刚介绍的flamingo的，这种in-context learning的能力，那它这个能力能不能被进一步地，就是通用或者泛化。

是我们很关心的一个问题，我们首先去测了它在captioning，就是图像描述上面的一些上下文学系的能力。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_21.png)

比如说，我们可以用比较复杂的captioning，就是给它一个括号，类别冒号数量，这样的一个固定的格式，相当于让模型同时做分类跟数数的这么一个任务，这个任务训练员没见过，但是我们给它三个example。

你再给它一张图片，它自动完成一个组合式的，包含分类跟数数的这么一个新的任务，比如说它就知道这里有三个啤酒。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_23.png)

两个香蕉，另外更进一步就是我们同时，我们有一些数据是在我们训练图片里面没有的，比如说我们图片上可能想画一些prompt，或者画一些这样的标记，对于我们project里面它可能很少有这种数据。

我们能不能在有一个这样的模型之后，能不能直接在测试的时候，给它例子它就能学到新的这种，视觉提示的识别能力，所以比如说这个例子就是，我们画一个圈，对应的文字是这个圈里描述的内容，给它三个例子。

就是我画摩托车的轮子，它就知道要完成这个任务，然后你再给它一张图片，画一个圈，你可能画其他的物体，它知道我现在要描述这个红圈里面的物体，相当于是在上下文里面，去理解我们给的视觉提示，除了理解。

因为刚刚提到，我们上座的是一个统一的，就包括生成和理解在内的，一个上下文学习的能力跟模型，除了理解还有就是，我们的生成，我们知道一般我们会给一句话生成一张图片，在一个上下文学习的框架里面。

也是类似的道理。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_25.png)

我们可以给文图作为例子，相当于给它比如说几个例子之后，再给一句话，它在上下文里面参照你的文图，去生成一个对应的风格，类别的物体的图片，或者是我们说可以做主体。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_27.png)

因为我们现在一般来说。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_29.png)

想要做一个主体的图像生成，我们会专门选一个模型，我们希望去尝试的是说，在一个生成式多姆态的预训模型里面，它pre-train完，是不是就有一点这样的能力，虽然说这个图像质量本身不会特别好。

因为它是一个预训链的模型，不是专门针对图像生成优化的，但这个能力是可以看到的，就是我们给它subject的，不同的文字跟图片，然后在测试的时候，另外给一句，比如说subject A。

戴着一个什么样的帽子，它给参考前面的上下文，就参考前面多姆态的上下文，去完成一个领养本的视觉生成的任务，除了钉性的一些case。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_31.png)

我们主要，钉量的比较呢，主要是在跟刚刚提到的Flamingo，然后它的80B模型这个比较，Flamingo2已经出来之后，大家社区包括一直在尝试复现，但是都没有取得比较好的一个效果。

包括Hugging Face的IDFace，然后我们发现这个E-Me2这个模型，在很多的future-world任务上，已经能取得更好的一个效果，就是它的上下文学系能力，不仅是在生成上有新的能力。

同时在理解上也是取得更好的一个效果。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_33.png)

然后另外的除了上下文学系能力本身，它的应用的场景，就是当然理解大家都可能比较熟悉了，在生成里面我觉得一个比较意思的点是，现在的生成大多是基于一句话，去生成一张图或者一段视频。

比如大家知道的这个Cyber Diffusion Dali，或者这个SORA，但我们想要实现一个更通用的接口的时候，有一个多派的上下文是会很有帮助的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_35.png)

比如说我们如果只给一句话，它可能生成的图片不是我们很满意的。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_37.png)

那我们可以给更具体的位置，可以给位置跟图片的组合。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_39.png)

就相当于我们可以把多张图片跟文字串起来，交错起来，然后作为一个Prompt，然后去实现一个，更满足我们的目的的，一个图像或者视频的生成。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_41.png)

但对于视频也是一样的，就是你可以把你家的宠物狗拍个照片，或者跟你的角色拍个照片，扔进去让它生成一段视频，这个是去年的一个结果，跟现在Zsota的，比如SORA，这视频生成效果当然是有很大的Diff。

但我们主要是想看在能力上，就是这种新的生成式的动态模型，能不能带来新的包括生成，当然也包括理解的能力，然后另外想分享的，就是我们谈到这种生成式动态模型，包括现在大家越来越关注的，生成跟理解的统一。

包括动态统一，里面最关键的，我觉得现在有三个问题，除了刚刚提到的可能Protraining这里很多的问题，其他两个更多的是，一个是Data，就是到底什么样的数据是满足，我们接下来的动态任务的需求的。

第二个是Encoder，也包括我们说Tokenizer，或者包括CLIP在内的这种，语义的Encoder，就是到底什么样的Encoder，是可以满足后面的，不管是生成理解，或者是统一的动态任务的需求的。

对 然后先说一下Data。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_43.png)

Data我们从两个方面，做了一个探索，一个是，就是数据它能不能满足下一代需求，主要是体现在它的形式跟内容上，然后从形式上，我们之前大多是图文队，在Emu这个工作里面，我们探索了一种。

就是把Video当作一个Interleaved，就是交错的视频文本的数据，因为我们在看YouTube视频，或者看其他视频的时候，也在接受的是这种Interleaved，这种VisionText的数据。

它提供了很好的一个上下文的相关性，然后我们发现，对它上下文学习的能力，有一个很大的提升，比如说这个例子，就是你有一段视频，比如说纪录片，它描述了一个故事，我们可以把它的文字跟视觉图片，给对应起来。

在时间戳上对齐，这就是一种，我觉得是一种新的形式，那后面相信大家会，可能会挖掘更多的形式，因为图文队本身可能不足以，满足我们后面的需求。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_45.png)

另一个就是除了数据形式，就是数据的质量，然后我们发现，之前大家用的很多Lion2B，或者Lion2Coco这些数据，它都有很多的问题，特别是在我们想要规模化的，虚拟动态模型的时候。

Lion2B的这个数据，这个原始的数据，它很难有比较好的性能，因为它一般是比较Noisy的，一些这种AutoText，Lion2Coco，它是一个Synthetic的数据，就是我们去人去标。

它这个东西它是不Scalable的，它没有很强的这种Word Knowledge，就是右边这个曲线，可以很明显地看到，就是如果我们用，这个黄色的这种RAW Data，它很难有比较好的性能。

用这个绿色Synthetic Data，它其实你很难逊的，你越逊可能是越差的，所以一个比较简单的解法，我觉得也是现在。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_47.png)

看起来比较Work的一个解法，是，对 先说一下原因吧，就是最后的原因主要是在于，我们在构造这些数据的时候，我们扔掉了很多的Word Knowledge，就是我们叫这些，应该中文叫世界知识。

然后所以构造了比如说，Coco或者CC3Million，它数据里面本身就。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_49.png)

没有这种信息了，那一个比较简单的解法，我们叫Peps Fusion，这个最近也用到不同的方法里面，就是我们可以把它，做一个简单的融合，然后去融合。

并且Refine原始跟Synthetic的Caption，然后把它变到一个规模化的量级，也就是说我们把原始的，比如AutoText跟我们Synthetic的标注，可以简单地融合起来之后。

它这个事情就很Scalable，就是我们就可以打造，比较大规模的，我们当时先做120Million的一个数据，发现这个效果就已经非常好了。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_51.png)

除了Data，另一个比较关键的就是Encoder，也可以叫Tokenizer，就是我们这几年大家都看到很多的，不管是这种连续空间的，离散空间的视觉的Encoder，当然大家解决的问题可能不太一样。

我们可能有的想注入语义，比如说Clip，有的想把它Tokenize到，一个离散的Token，那这里我们，我觉得这里可能是现在最，一个比较大的Blownack，就是往后面想做统一的，深声诗多么泰模型。

我们自己比较喜欢叫，这里有一个不可能三角，就是比如说我们想要把图像，跟语言一样Tokenize成一样Token的时候，这个不可能三角是Compact，就是紧凑的，我们想要用很少的Token去表达。

这个图片或者视频，第二个是Lossless，就是无损的，我们希望它可以完美地重建，你这个图像或者视频，第三个是Context，就是离散的，然后这三个现在只能满足两个，所以我们叫它不可能三角。

但是理想情况下就真的想实现，我觉得理想情况下，希望是都能实现，但是目前还是有一个Blownack，我们过去主要是从不同方面，在Encoder这里做一些探索，包括Encoder最大能到什么程度。

Encoder是不是可以没有Encoder，然后Encoder能不能是Sparse的，然后下面简单介绍一下，首先一个是，之前我们思考的比较多的一个问题，是视觉的比如说Clip，最大能大到多大。

然后它能产生什么样新的效果，我们最早是在2022年底的时候，当时训了一个实验参数的Eva Clip，然后当然也被用到了各种的任务里面，所以我们后面一直在思考的是，这个规模化，比如说在Clip里面。

它能产生什么样新的性质，然后这个是去年底今年初的时候，我们开源了一个180亿的Eva Clip模型，这个应该是目前开源能获取到最大的，视觉Encoder或者叫Clip模型，我们比较有意思的是说。

首先在GeoSource各种任务上是有提升的，然后在图样上是有全面的提升的，但最有意思的是在Video上，就是在视频的领样本分类上，它有一个质的提升，当我们其实没有专门的去优化，数据是一样的。

然后我发现这个参数量级，规模号到180亿参数的时候，它在Video领样本分类的提升是更明显的，然后我觉得这个也是里面比较大的一个价值，也是值得更多的关注的一个点，就是当我们在讨论视觉的规模化的时候。

除了更大的Clip，当时在Tether他们做的Segment Ending之后，我们当时思考的一个问题是，这个东西能不能对我们的Encoder，或者Tokenizer有一个借鉴。

就是我们能不能做一个Sparse的，同时是Prompting的Tokenizer，我们可以按需求去Tokenize这个图片，然后相当于说我们希望Tokenize，包括它的像素的分割，包括它的类别。

包括它的Caption，然后同时它又能够重建出来，它对应的我们想要输出的信号，实现这样的一个按需的Tokenize，那最后能实现一个还可以的效果，比如说我们可以把这张图片的所有的物体。

同时的分割分类Caption出来，我们还讨论到Encoder的时候，另外一个不得不思考的问题就是，那能不能扔掉Encoder，就是我们看到去年付予，最早是付予Barbi，她把Encoder扔掉。

我们送Patch进去，然后做Vision Language Model，做视觉理解的任务，但是当然它现在看，当时效果是非常差的，然后我们当时思考的一个问题是，当我们在面向，包括深圳式多模特模型。

包括视觉这个Vision Language Model的时候，能不能扔掉Encoder，也就是能不能用Patch作为视觉单元，当时做的时候，SORA其实还没有放出来，然后我们就是希望去探索一下。

把Patch作为视觉单元，它是不是可行的，至少在一个具体的任务上面，它的性能是怎么样的，但我们发现当，比如说我们希望去付现付予的时候，因为付予没有看远，我们希望看看付予，它到底训练的性质是怎么样的。

我们发现碰到两个问题，一个是它性能很差，就是比如说我们Virus，现在最好的Lava的模型，它性能是有很大的gap的，在很多的视觉理解任务上面，第二个是它训练很不稳定，这也是为什么。

大家一直没有很好的付现的，我相信一个原因，我们的实验里面，它是很容易崩的，就是我们如果直接用Patch，这个送进去的时候，每个阶段都很容易崩，所以为了解决这个问题。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_53.png)

我们应该下周会放出来，也是今年上半年的一个探索的工作，就是能不能把Encoder全部扔掉，同时我们希望填补中间性能的差距，然后解决训练不稳定的问题，这里有两个关键我们发现，一个是说想要填补性能差距。

我们想要达到甚至超过Lava的性能，里面一个很关键的点，是我们需要视觉识别的监督，为什么呢，因为Lava或者更多的模型，它是用CLEAP，包括刚刚介绍的CLEAP，这样的在上Billion级别的图片上。

去训练过的，如果我们直接送Patch，它是没有这个显眼的，所以有一个辅助的监督，对这里是很有帮助的，第二点是解决训练不稳定的问题，这个Patch Embedding，说实话是很关键，这个也对应到之前。

很多做自监督的一些工作，我们发现在这里同样是一个，导致他训练不稳定的一个关键，所以右边就是可以看到，解决了这些问题之后，他训练下面的曲线可以是很丝滑，同时可以达到比较好的一个效果，总结一下。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_55.png)

刚主要跟大家分享了，简单分享一下两个点，一个是我们从视觉上效能学习，到动态上效能学习的一个探索，然后包括我们想做，下一代深圳式动态模型，它能产生什么新的能力，以及中间的关键的技术问题。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_57.png)

对然后，我们刚提到的这些都已经，或者即将开源在GitHub上面，也欢迎大家更多的同学，想要我们一起做视觉跟动态技术模型的，可以加入我们，谢谢大家。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/6348b8618ebb24b90d5f0ba3762d9ce7_59.png)

謝謝。

# 2024北京智源大会-多模态模型 - P3：AI是否需要更强的视觉基础来实现理解和意义--谢赛宁 - 智源社区 - BV1sT421a7FU

好，对 这个大家好，然后很久没有用中文直接跟大家对话了，然后我希望今天能够讲得清楚，但如果我讲不清楚了，我希望在座的观众可以随时打断我，就是你可以举手或者直接打断我就好，我想讨论的事情是。

Language models 或者说AI in general，到底需不需要更好的viewer grounding，或者更广泛地说是智能智能智能。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_1.png)

来达到理解的意义，我想先zoom out一下，先讨论讨论一些哲学的问题，其实在这个问题上，比如说我们说AI到底需不需要，所谓的智能智能智能，就是一种感知，来达到这种理解的意义，其实这件事情。

已经有很长很长时间的讨论，比如说在AI里面，在1990年的时候，这个Stefan Hanna他们就讨论了这种，Symbol grounding的problem，这个时候。

也不是deep learning的时代，但是那时候大家在讨论的事情是，就是大家说的这个话，或者我们计算机里面的code，它们作为symbols，其实本质上都是没有意义的，它们之所以会被赋予意义。

是因为我们把它会associate，with some form of sensory grounding，这时候他们会讨论所谓的，Semantic gap的这个概念，这意思是说。

如果我们现在要teach一个，比如说一个human child，to learn what is an apple，我们只是在他耳边说，Apple Apple APPLE，他是学不到什么东西的。

我们必须让他明白，这个不同angle的这种，Apple的view的capture，或者说它的taste，它的feeling，然后才能够让至少人。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_3.png)

知道什么才是一个apple，再往前倒推一点，其实在哲学里面，像13世纪的时候，阿奎纳也讨论过类似的事情，然后他说过这样一句话，There's nothing in mind。

that wasn't first in senses，就是你的感知会最先出现，然后我们才可以讨论，你的心智。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_5.png)

你的认知的问题，当然后来还会有，各种各样的哲学的学派，比如说Sansiem，然后他们的观点是，No cognition without sensation，也再一次强调了sensation的重要性。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_7.png)

当然了，既然是一个哲学的遍体，而且已经是长达可能上百年，上千年的哲学遍体，那我们当然有反方的观点，其实这个阿奎纳，在一千年的时候，他讨论过这样一个思维实验，就是所谓的。

Avicenna's floating mind，浮在空中的一个人，他的所谓的thought experiment，其实说的是，现在想象有一个人，他就天天浮在空中，然后他就可以这样飞行。

但他其实没有办法，有任何的sensory grounding，因为他up in the air，但是他其实可以思考很多很多的东西，他可以思考他自己，关于他自己的事情，他也可以思考。

其他各种各样丰富的东西，比如说数学 逻辑 哲学，等等一切，这些东西都不需要，external reality。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_9.png)

但是这些哲学的讨论，就留给哲学家去做吧，我觉得其实对于，今天的AI来说，我们更希望有一个，less philosophical question，就是说，当然Chad Chabit，非常非常有用。

然后他也是一个revolution，但是pure language models，只有text inputs and outputs，然后他并没有这种human style senses。

我们至少可以问的一个问题是，如果我们给这些language models，更好的sensing capability，我们能不能去boost我们的thinking，to a new level。

in language models，我们能不能更好地提升，我们的language understanding，and meaning capability，而且这件事情不止对于。

human language成立，并且对于general intelligent creation。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_11.png)

我觉得也是一样，这件事情要说回到，可能这个字体有点问题，这个所谓的韩五纪的时候的，生物大爆炸的过程，至少有一个理论是说，在当初的时候，在538个million years ago，地球上这些海洋里。

刚刚出现了一些生物，然后大家都很弱，其实一开始也没有什么视觉，但是直到有一些，这些初等的生物，开始develop出来一些，视觉的信号，他们就能更好地去躲避天敌，获取实物，这件事情就激发了。

这种所谓的arms race，开始了这种视觉的军备竞赛，如果你想要获得更多的实物，然后避免自己被捕食，那你就必须要develop，better and better vision。

to be more and more intelligent，所以这是，至少是一个hypothesis，解释了为什么在韩五纪的时候，会出现这样的生物大爆炸，然后，这个好像slides有点问题。

但是anyway，就是我觉得很多，这些想法也来自于一样的influence，至少在这一部分的观点上，我跟他还是比较一致的，所以他其实也在讨论，LM和sensory grounding之间的一些关系。

我这里面可能选取了他的两个言论吧，然后我觉得我是非常同意的，比如他说，大部分的human knowledge，人的这个知识，以及基本上全部的动物的knowledge，其实都是来源于我们的这种。

感知的这种experience，of the physical world，就是我们在这个真实世界里面的感知，然后他同时也说，language is icing on the cake。

we need cake to support icing，我觉得这其实是某种，LeCun cake的2。0版本，当然我们比较熟悉的1。0版本，是在讨论self-supplied learning。

supervised reinforcement learning，但我觉得在这里面，他其实讨论的是说，我们其实需要更好的sensory experience modeling，在这个之上。

我们才可以去讨论一些language modeling的问题，还有一个他的观点，我觉得我是比较认同的，是说如果现在假设，我们过早的或者过强的，引入language信号，我们始终会有一个风险。

这个风险是说，有可能我们的view representation learning，我们的sensory modeling，其实做得很差，但是由于这种非常强的language prior。

它能够让我们走一个捷径，并且让我们觉得我们很有智能，但实际上这件事情可能不是这样，有可能当我们真的要，AI develop的一个阶段，我们需要对这个robustness，对这个reliability。

或者说对于我们要解决的问题的难度，有本质的提升的时候，可能这些weak vision system。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_13.png)

会变成一个bottleneck，所以我现在的感觉是，如果单纯language model来说，它是一个非常knowledgeable的系统，但是同时它又是一个像盲人模像一般，眼睛被遮住的系统。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_15.png)

当然了今天我们的讨论，是在这个多模态论坛里面，所以其实最近的几年的时间里，然后在我觉得对于multi-model来说，或者对于general vision的研究来说，也是一个新的时代吧。

比如说从GB4V的时候的出现，然后大家开始discuss，这个LMMs，然后discuss各种各样的非常surprising的，在传统的视觉的人看起来，其实真的不知道该怎么做的。

这些问题的setup上面，multi-model system通过LMMs辅助，都能得到很好的很好的效果，我觉得一个当然现在LMMs，也有不同的流派，也有不同的技术路线，但是我觉得现在一个比较经典的。

至少在开源社区里面，大家用的最多的最广泛的一个系统，当然是这种Lava based的系统，这样的系统里面，它其实构造非常非常简单，它会leverage几个pertrain的system。

我们会有language model，我们会有一个vim encoder，我们会有一个非常非常简单的connection module，把它们两个连在一起，然后接下来你要做的事情。

就是把vim encoder得到的这些vim tokens，projected到language space，然后把它丢给Large Range Model。

然后我们可能可以分两个stage的training，pertraining stage，然后会有一个instruction fine tuning stage，这样的话我们就可以leverage。

这些不同的model，包括在vim的model还有language model，来达到这个multi-model的capability。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_17.png)

但在过去很长一段时间里面，我们可以看到在vim encoder的部分，或者说在language的部分，其实是百花齐放的，我们会有越来越强越来越大的模型，但在vim encoder的部分。

大家会不约而同地使用一个model，就是clip model，并且这个clip model，就是exactly open eye release的checkpoint，对吧。

就是这个VIT large的model，把它作为一个vim encoder。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_19.png)

对，clip我希望，这个大家已经都比较熟悉了，这个paper也是看不到，但它是2021年的工作，然后它通过contrast learning的方法，去align text和这个image input。

然后它的encoder可以被拿出来。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_21.png)

去transfer到其他task里面去，然后我觉得我们现在想问的一个问题，其实是说，如果我们现在想要build一个multimodal system。

我们到底是不是应该只用一个clip model就够了，或者说我们要问的问题是，我们现有的vim representation learning的系统，到底是不是足够好。

对于language的understanding的命令来说。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_23.png)

所以第一篇我想介绍的论文，也是马上下一周，我们将在这个CPR presenter工作，然后它的名字叫SYShud。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_25.png)

Exploring Virial Shortcomings of Multimodal Large-Range Models，所以可以先看一些example。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_27.png)

这些都是GPT-4 V-Turbo的一个snapshot。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_29.png)

可以看到说，其实我们discover了一些，比较简单比较基础的问题，比如说从camera的视角来看，这个狗到底朝左边还是朝右边，我现在第二个图里面说，你能不能看到一个窗户，我们很明显可以在后面。

可以看到一个很小的窗子，比如说像这几个人，他到底是面朝前还是面朝后，然后比如说这只鹰，然后我们到底能看见一只眼睛还是两只眼睛，而这辆车我们能看见一个轮子还是多个轮子，非常surprisingly。

所有的这些问题上，然后GPT-4 V都会回答失败，当然了现在的GPT-4 O的model，可能在这些问题上，已经有了长足的进步，但至少在GPT-4 V的时候，我们会找到很多这样的。

非常trivial的这个问题，但是GPT-4 V也做不好，比如说像这个图是说，这个新的边缘到底是白色的黑色的，然后GPT-4 V会说这是一个dark color edge，然后像我说的一样。

就是我们可以systematically identify instances，然后找到这些样例，使得我们能够怎么说呢，击败这个GPT-4 V，或者说让GPT-4 V在这些list上面失败。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_31.png)

我们是怎么做到这件事情的呢，其实我们是我们的一个目标，也是说要develop一个新的benchmark，我们叫它MMVP benchmark，然后我们会设计一个，找到这样或者construct。

这样benchmark的方法，来找到它这个clip-blind的pairs，这件事情其实非常简单，我们第一步只需要去找到一些image pairs，然后这些pairs我们可以从一些。

existing的data set拿到，包括image net以及包括line，然后我们可以用两套embedding system，一个比如说是clip model。

然后另外一个是一个vision only，soft-supplied learning model，然后在这个model的过程中，我们可以去在他们的embedding space下面。

measure这个pair的distance，然后我们希望找到的这个pair，是说它在clip的embedding space下面，它们的similarity score会非常非常的高。

但是在一个vision only的soft-supplied learning model下面，它的这个score会相对来说比较低，这件事情是什么意思呢，是说我们希望找到这样的pairs。

使得对于clip model来说，它分不清楚这两个图片到底有什么区别，但是对于一个vision only的soft-supplied learning model来说，它会发现这两个图还是差别很大。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_33.png)

然后有了这样的setting之后。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_35.png)

我们就可以把这样的pairs交给一些human annotator，让他们去尝试找到在这样的pairs之中，到底有哪些viral differences。

所以这里面其实是有human in the loop，但因为我们已经通过这种方式filter出来了，这些在clip space比较接近，然后在dino space比较远的sample。

所以这件事情对于annotator来说，其实是一个比较容易的事情，比如说他看到这两张图的时候，就可以比较容易地去come up with这个question。

我们就说这个狗的脑袋到底在地毯上还是在地板上，这样的话我们就可以把它再去formulate成一个question。

是说where is the yellow animals head lying in this image，然后我们可以有这样的multiple choices。

比如说A是floor B是carpet，所以在我们construct这样的benchmark之后。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_37.png)

我们就可以拿这样的benchmark去evaluate，各种各样的multimodal models，包括开源跟闭源的系统，然后我们的判断标准是，必须对于这两张图来说。

这个multimodal model必须同时回答正确才算对，就加一分，然后如果要是有一个错了那就不得分。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_39.png)

所以我觉得这个benchmark的结果，在我们当初看来还是比较令人惊讶的，就是说对于human来说这些问题都不是任何问题，你只需要看到这两张图，你自然而然可以找到他们的这些。

即使非常nuance的这种variable differences，然后回答清楚这些问题，但是大量的系统，现在的multimodal的系统，却在这件事上做得非常非常差，比如说Gemini可能有40。

7的performance accuracy，包括之前的GP4-V可能有更差的38。7的accuracy，但是除此之外，其他的所有的model包括Lava。

然后其他比如说mini-GP4之类的model，都甚至比random guess还要差，但是同时human可以做到几乎完美的performance。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_41.png)

所以这是一些example，以及一些model的behavior，大家可以看到，其实在很多这样的，看起来很简单的例子上面，这些系统的performance，是不是很consistent的。

所以在做完这样的一个benchmark之后，我们希望能够更深入的了解一下，到底发生了什么，为什么会发生这样的事情，所以我们相当于有点post hoc的，再去重新看一下我们收集的这个benchmark。

然后总结它的question之中，到底这些human annotator，到底提出了哪些的问题，然后我们通过比如说play with gpt，然后总结下来，其实一共有九种view patterns。

然后现有的multimodal system会经常出错，比如说包括orientation direction，比如说包括state direction，quantity， count， color。

 appearance， text， view point， perspective等等，这九种view patterns。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_43.png)

然后我们现在可以重新去，相当于重整一下我们之前的这个existing benchmark，把它变成一个image text matching的problem，我们之所以做这件事情的目的。

是因为我们有一个hypothesis，大部分虽然我们不知道GP4V，用了什么样的model，但大部分情况下，刚才许诺也说了。

其实clip model还是一个非常dominant的variant encoder，所以我们的一个猜测是，如果说这些view shortcoming。

会在这些multimodal system里面被看到，那很有可能是clip也会出了问题，所以我们可以去，现在reorganize我们的benchmark，然后通过这种image matching的方式。

去先去benchmark clip，我们可以看到，其实在clip model上，然后做这九个view pattern的，这种matching task，结果也是非常非常差，虽然不同的model。

会有不同的performance的好坏，in general可能更好的image net zero short的performance的model，也会在MMVP的benchmark上面。

也会有比较好的结果，但是这个也不完全是这样，还是会有一些ranking的swall，但当我们把所有的这些结果，plot在一个figure里面，然后把它通过这些不同的view patterns。

来bucket一下的时候，就会看到一个比较明显的behavior，是说其实在clip做不好的地方，我们接下来的multi model system也做不好，但是在clip能做对的情况下。

比如说在这些color的question上面，clip做的还不错，虽然可能也只有比如说less than 50%accuracy，但是这些multi model system，其实做的也不错。

所以有一个clear的correspondence，correlation between clip model，like ourview encoder。

and the subsequent multi model system。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_45.png)

所以当我们发现这件事情的时候，其实比较显然的一个事情是说，我们其实可以尝试去补足clip model的短板，那既然我们已经是通过这个方式，去discover这些clip pair的。

那一个也比较显然的做法，是说我们可以去在clip encoder的部分，加入一些vision only的soft-supplied learning model，我们其实设计了不同的strategy。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_47.png)

包括比如说直接把它们加到一起，我们可以看到一些performance behavior，比如说你加的dynol feature。

或者说vision soft-supplied learning feature，越多在MMVP的performance上面，它会saturate 但它会不断涨。

但是对于这个lava的performance，它会变得越来越差，但这个主要还是因为可能，直接这种naive的token混合。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_49.png)

会破坏原有的feature的性质，但我们可以做一些其他的尝试，比如说我们可以直接把soft-supplied learning feature，跟这个clip feature。

在special上面interleave到一起，在这种情况下面，我们其实可以看到，我们可以在MMVP的benchmark上面，有很大的提升，并且可以在其他的这些VQA的benchmark上面。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_51.png)

也不掉点，对 然后当然了就是大家可能会问。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_53.png)

这件事情是不是有点自说自话，因为我们一开始discover这些clip，blot and pair的时候，我们已经用了dynol feature和clip feature。

那是不是这件事情只是我们有点overset。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_55.png)

我们的setup，其实不是这样，我觉得这里面我们看到的现象是，对于其他的vision soft-supplied learning backbone，我觉得这个conclusion也是成立的。

一个general behavior是说，vision soft-supplied learning，还是能够去complement像clip这样的style的，这种一开始像刚刚说的。

把language part提早introduce进来之后的这种model。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_57.png)

我觉得一些take away吧，我个人而言觉得clip，虽然我觉得我们当然可以做更好的scaling，然后我觉得这件事情都有很大的潜力，但是clip已经待在这个领域太久了。

所以在急需有一个alternative pipeline，可能是会fundamentally不一样，然后能够在keep clip的某些，这些好处的情况下，也能够去fix clip的一些问题。

因为我之前做了很多vision soft-supplied learning，我觉得这也是一个例子，说vision soft-supplied learning，其实我觉得没有，怎么说呢。

失去它的意义吧，然后我觉得我们可能还是需要去，在vision soft-supplied learning上面，做更多的尝试，但是我们需要有fundamentally different ways。

to pursue the problem，我觉得像过去一样，比如像Moco M1的时代里面，我们在这种imagenet的data center，做training。

然后通过linear probing，跟安全functioning的方式，在imagenet以及这些cocoa，AD20k上面test，这种方式已经不再是一个好的。

或者合适的一个evaluation pipeline，所以我们可能没办法真正，达到我们想要的目标，然后最后一点也是说，回答一开始我们title里面的问题。

就是可能better visual understanding，还是一个非常重要的事情，对于language understanding和meaning来说。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_59.png)

接下来我想要介绍另一篇CDPR的工作，然后我觉得它会是另外一种，一套思路，但是它想要解决，或者它想揭示的问题，其实是相通的，这篇paper叫做V-STAR。

然后它叫做Guided Visual Search，as a Core Mechanism in Multimodal Language Models。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_61.png)

所以我想先讨论的是，到底什么叫做visual search，这个东西其实在psychology，或者cognitive science里面，也是有明确的定义的，其实这件事情很简单。

我们需要actively search for targets，from distractors and background，我们会有phobia的系统，在我们的眼睛里面。

我们虽然有每天可以process，很多的visual information，但其实我们的注意力，不是要把所有东西照单全收的，然后其实我们会有，我们自己关注的地方，然后一旦我们失去了。

我们这个关注的焦点，然后我们可能在生活中，又犯一些错误，在这个biology上面，我们的phobia的这一部分，其实只有1%不到的retina size，但是其实它会activate。

大于50%的visual cortex，所以这是一个非常surprising的behavior。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_63.png)

对，然后我们什么时候会做这样的visual search呢，我觉得是可以说是所有时候，比如说对于我们这个everyday task，然后可能在大家办公桌上，有很多很多的杂物，然后我们现在要去找一支笔。

或者一本书，我们就需要去conduct，这种visual search的behavior，或者我们要处理一些。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_65.png)

比较complex task的时候，比如说我们要去识别一个diagram，比如说像这样的进化的图谱之中，我现在要问说，这个长颈鹿在什么地方，或者它的祖先是什么。

那我需要去conduct这个visual search，才能去target到这个目标。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_67.png)

从而能够回答这个问题，我觉得我们可以有一个更concrete的example，是说我现在给大家一个，非常high resolution的一幅图，对吧，然后我现在想要问的问题是。

这个塑料吸管到底是什么颜色的，对吧，然后对于这个问题来说，我们现有的视觉系统是怎么处理它的呢，它是这么处理的，它会从左上角开始，当然可能你不需要follow order，但它会逐行扫描。

然后会把所有的图里面的所有的信息，全部encode进去，然后再去process，然后再去understand，但很显然这件事情对于人来说是不可思议的，对吧，如果是一个人来做这件事情的话。

我们讨论到吸管的事情，他可能会想，那我们应该可能先看看，这个桌子上有没有这个东西，因为可能吸管，更容易出现在这个coffee shop的这个桌子上，发现这个桌子上没有，我们再看看另外一张桌子。

发现这有一个杯子，杯子里面有个吸管，那我们现在可以回答说，这个吸管是黑色的，对吧，这其实是一个很自然很自然的过程，并且这件事情对于人来说是非常必要的，如果我们现在每天都需要去逐行扫描，所有的事情。

然后才能去回答一个问题的话，大家可以想象这个cognitive load，并且这个efficiency是会非常非常差的，对，然后我们到底是怎么样去做这个view search的呢。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_69.png)

其实，again，这个认知科学家以及心理学家，他们其实做过很多的讨论，就是这个里面其实有很多种不同的cures，比如说我们会有这种bottom up，silence to guidance，对吧。

然后比如说我们现在看到这样的一个图，我们可以ask which items pop out from this image。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_71.png)

大家很明显可以看到一些，一些一些一些一些这个，怎么说呢，一些outlier对吧，在这个distribution之内，它会变得很显著，然后这件事情会guide我们的view search。

然后还有一些其他的top down feature的guidance，对吧，比如说我们知道，我们想要找到的物体，它有一些性质，或者说它有一些这些attributes。

然后还有就是这种thin guidance，我们会leverage我们的所谓的这种，这种对于世界的知识，然后或者一些semantic information，来帮我们去搜索。

比如像之前这个example里面，我们要从桌子上找杯子，从杯子里面找吸管，这其实是因为我们的大脑里面，已经有这样的sense，比如这样。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_73.png)

另外一个例子，我现在要问这个这个这个枕头在哪，对吧，你可能第一眼会去床上去找，如果找不到可能会去沙发上找，但你可能不会去厨房去找，或者说餐桌上去找。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_75.png)

对，当然还有一些其他的，这个这个很重要的cue，比如说，我们不断的去perform这样的search task，然后我们我们我们会有，我们大脑里会maintain，这种search history。

然后有可能你今天找过一次，明天你就会回到这个同样的地方，去再找同样的东西，对吧，因为我们可能有已经有这样的prior，对，然后当然还会有些其他的。

是说这个可能perceive value of the atoms，我们会倾向于去找一些，这个价值更高的东西。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_77.png)

然后在machine learning里面，也会有，当然这些都是古早的工作，比如说06年Antonio他们做的工作，也是说讨论visual search。

这种human的cognitive ability，到底在machine learning里面，到底有什么意义。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_79.png)

Again，会有不同的人在尝试这些事情，但是这些事情，其实跟主流的computer vision research，或者说跟AI还是不太相关，因为大家可能真正care的事情。

是说我们能够怎么样更好去follow，这个人类的这种gazing trajectory，比如说你的眼洞的信号呀，或者怎么样对吧，然后可能大家handle的image。

也是这种limited resolution，然后可能更多的，也没有很多learning在里面，可能更多的是要依赖于，一些statistical correlation。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_81.png)

然后我们到底应该怎么样去design，一个更好的visual search model呢，Again我觉得我们还是可以去，borrow一些common sense的discussion。

比如说我们可以去依赖于，一些bottom up，或者依赖于一些top down，feature guidance，以及一些thing guidance，但这里面其实有一个key observation。

这件事情在几年前，或十几年前是不成立的，就是说我们现在确实有一个，更好的系统，就是我们的large image model，真正的能够去encode一些比较rich。

并且比较靠谱的word knowledge，对吧，然后所以对于一个large image model来说，我们一开始说了，它可能是blindfolded，虽然它看不见，而且它也不reliable。

但它是一个很好的guide，它可以去告诉我们，应该去哪里找东西，一个东西可能会出现在哪里，所以在这个基础之上。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_83.png)

我们提出了一个framework，这个framework叫做SIL，然后我们把view search的capability，想要去integrate到这个。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_85.png)

multi-model large image model里面，这个SIL的意思是，show， search， and tell，这一面就想要多说两句，就是说现在对于这种model。

multi-model large image model来说，其实问题也不仅仅只在这个clip上面，对吧，然后包括比如说，我们之前说了，可能view encoder。

大家通常会take a perturbed model，可能会keep it frozen，然后另外一件事情是，因为它没有这种view search的capability，所以它没办法去focus在。

critical view information上面，然后再包括，现有的系统很多时候，如果它看不见一个东西，它不会说它自己看不见，它只会给你re-listen it，然后编造一个答案，对。

并且还有一点是说，它也没有办法有一个，像人一样的active的这种，search request的这种mechanism，使得我们能够去。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_87.png)

在它看不见的时候，去寻找到这些它们看不见的object，这一面又要把GP4V拿出来了，对，这也是另外两个例子，说GP4V，我们去问说，比如说。

What is the instrument held by the ape，对吧，这个猩猩手里拿的乐器是什么，大家可以看一眼，我觉得应该可能在一秒两秒之内，大家可以找到猩猩在哪里。

它拿的手上的东西是一个吉他，对吧，然后GP4V告诉我们答案是说，这是一个saxophone，这显然是不对的，然后另外一个是说，这个color of the mug，对吧，这个杯子的颜色是什么。

这个可能难度会更大一点，但是如果你定睛一看的话，你可能还是会看到，这有一个蓝色的杯子，对吧，但是可能GP4V就会被distracted，然后回答说，这个杯子是白色的。

所以我们的Virial Search Model，其实就是inspired by，这个human的这些cognitive science的一些study，所以我们其实会有一个这个multi-round。

然后guided by large-range model的系统，我会skip一些detail，但核心是说，我们现在会有一个variant backbone，然后并且我们会有一个。

multi-model large-range model，来帮我们去做Virial Search的部分，然后这个multi-model large-range model会输出。

或者说它会接着两个不同的decoder，这两个decoder分别是某种search queue的decoder，以及某种target localization decoder，一个具体的例子是说。

比如在这个图里面，我们要问，What is the most likely location of the orange luggage？你其实是找不到，或者太小了，或者说对于现在有的系统来说。

collaborative resolution没办法去support，直接能够回答出这个问题，那我们的model会告诉我们说。

这个orange luggage is most likely to appear next to a person，所以这一部分其实是所谓的word knowledge，然后我们接下来。

我们系统会自动化的去找到说，这个person在哪里，它有可能更靠近这个城墙，然后这样的话，我们就会得到一个所谓的search queue，它会以一个heat map的形式存在。

Everything is probability，但我们就会可以通过这个search map，找到这个probability最大的地方，然后再进行下一轮的搜索，这个时候因为我们可以zoom in。

去找到这些，更可能出现我们要target的，寻找的物体的部分，那我们这样的话就可以找到，这个orange luggage，然后到最后我们可以输出的是，这个具体的。

这个orange luggage的一个坐标。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_89.png)

这样我们可以有一个binding box，我escape具体的这个设计，但这部分的设计，其实跟SAM的model其实很像的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_91.png)

特特一会可能也会讲到，然后我们具体的这个virtual search的操作，其实就是说，given一张image，我们现在需要把这张图不断地做切分，其实是一个地规的系统，我们先会把一张大图切成小图。

我们可以先分四份，在每一份上去做virtual search，然后靠这个large image model，word knowledge，让我们一步一步地，递归到更深入的一层。

然后更高的resolution。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_93.png)

然后去找到我们想要的物体，这也是另外一个具体的example，当我们面对这样的一个图的时候，我们想要找到说这个guitar在哪里，一开始现有的模型是看不到的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_95.png)

但是这个contextual kill，通过我们的large image model辅助，会得到以下的信号，它会说。

the guitar is most likely to appear on the stage，你的guitar可能更容易出现在这个舞台上。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_97.png)

因为它识别出来这个场景，可能是一个音乐厅的场景，接下来我们就可以去zoom in，crop出来这个image的patch，然后这时候，我们就会有这个target specific kill。

然后因为我们这时候，我们的virtual model已经能够看到，我们的guitar在哪里了。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_99.png)

然后我们现在继续zoom in，然后我们可以找到这个target。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_101.png)

然后我们可以把它crop出来，然后我们为什么叫它V*呢，是因为这件事情跟A*的algorithm，跟A* search其实是有很强的关系的，只不过我们的有一些细微的差别。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_103.png)

在我们的object定义上，所以我想说的是，就是Sale其实是一个meta architecture，我们做这个工作不是为了说，我们要claim state of the art。

或者说我们希望这件事情，在接下来的一个月两个月，就会成为一个很好的，这个multi-model，image model的系统，我们的目标其实是说，这样的一个architecture，即使在现在不需要。

即使现在我们可以通过，很暴力的方式，把它通过直接increase resolution方式，回答出来这些问题，但是in the long run，这件事情一定是需要，所以把它抽象出来之后。

我们其实看到我们的这个architecture，其实是有这么几部分的模型，第一部分模型是说一个，我们直接target这个vqa的lm，就是我们要进行问答的。

这个vqa的这个large image model，然后它会initiate一个，所谓的viral working memory，就是我们的像人一样，我们会有一个，这个记忆的系统，然后当我们看不到东西。

需要寻找东西的时候，我们可以去activate，一个viral search的model，这个viral search的model，要去帮我们寻找到相关的信息，把这些信息拿到之后，把它填充到我们这个。

viral working memory里面去，然后我们vqa的large image model，会从我们的viral working memory里面，去fetch相关的信息，再次去回答问题。

所以其实这变成了，从原来的一个非常原生的，我们拿到vim的feature，直接把它tokenize之后，丢给large image model来说，这已经是一个。

有这种system to reasoning的一个系统，我们的这个viral working memory里面，其实是可以包含各种各样的东西，比如说我们可以，把原始的问题放在里面，我们可以把一个。

global context放在里面，当然最重要的是，我们会把viral search model，给我们的search targets，以及这些target的location，当作这些信息。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_105.png)

放在这个memory里面，使得我们的vqa能够更reliable地，回答这些问题，这是一个high level的流程图，然后我们可以看一些例子，对，我现在没有一些比较有趣的例子。

比如说像这个杯子上面的logo，到底是什么，GPOV是回答不了的，但对于seal这样的系统来说，其实是可以看到。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_107.png)

是一个seagraph的标志，这个例子是说，这个例子可能比较好玩，就是我们看到这样有一个杯子，然后如果你zooming仔细看的话，你会看到一个starbucks的logo，然后我们的问题是说。

你应该从哪里可以买到这样的杯子，那你应该回答说，可以去starbucks去买，但GPOV很明显，它就会被其他的部分的，这些viral information所distract。

它被辐射里面的辐射小子所干扰，然后就说这是一个nuka cola，然后blah blah blah，可以摆放amazon，然后这个就complete hallucination，对，包括一些其他的例子。

然后我想再强调一件事情，就是说这件事情，其实不只是一个engineering的hack，然后我其实还是蛮相信这件事的，就是其实我们现在有的multimodal，large-range model的系统。

sooner or later，它需要做到以下的几件事情，第一是如果它一开始的，这个viral information不够清楚，或者看不到的话，它得要能够去acknowledge这件事情。

它不能直接回答这个问题，第二件事情是，它得要能够去list你这些，如果它看不到这些信息的话，它得要能够list到底哪些信息，我是看不到，我需要去得到的，然后它得要去能够understand。

and integrate这个search results，after the viral search process，然后最重要一点是说，其实像人来说也是一样，我们在handle不同的。

这种complexity level的task的时候，我们会allocate不同level的compute，日常生活中的大部分情况下，我们都是非常subconsciously。

就可以去perform一些task，但我们现在如果要去考试了，或者说我们到了一个陌生的城市，需要去找路了，我们现在立刻就会变得紧张起来，我们就会调动我们大脑的资源。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_109.png)

去做一些更复杂的viral reasoning，然后我们在这个基础之上。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_111.png)

还提出了一些新的benchmark，然后我们会有这些high-resolution image，然后我们可以看到，通过加入这种viral search的capability，我们可以做到。

比如说在这些benchmark上，拿到75%左右的结果，但对于GP4V等等系统，可能大概只有50%左右的结果，我觉得还可以再强调一点，就是比如说最近可能VSTAR bench。

也会被各种各样的这些大的公司在用，然后比如说Google他们的flash，Gemini flash的这个model，可以通过比较暴力的方式，不加这种system to reasoning的方式。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_113.png)

把结果push到比如说60多70多，这件事情都没有问题，但是我们可以跳过这一部分。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_115.png)

但是我想说的是，像这样的这种search的这种behavior，viral search的capability，在这种internet image的场景下面，可能真的不是必须的。

可能它会真的有一些overhead，我们还不如直接把所有的viral information，全部通过一个vim encoder，接收到一起，然后直接做好了，但是大家可以想一想。

如果我们以后要handle video，我们当我们现在要问一个问题，然后是一个很长的two hours video的时候，我们是不是得要必须从头看到尾，我们是不是会跳一跳，然后可能向前拖一拖。

向后拖一拖，大家看B站可能还是很习惯这样的，viral search behavior，或者说in 3D environment，或者说在embedded agent environment里面。

我觉得这件事情也是成立的，在这些task里面，我觉得我们就会对vim encoder的设计，以及这个观点，就是我们到底需不需要像这种system 2，的viral search capability。

才能让我们的multi-model system，达到一个更好的效果，我觉得这件事情可能会更有意义。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_117.png)

我们会跳过这一部分，然后当然我们也会做一些其他的，更多的vim centric，更多的discussion，比如说我们发现，另外一个比较好的载体是。

在这种art的domain上面去做formal analysis，我们找了这个世界上500，排名前500的这个名画，然后我们去ask一些非常detail的formal analysis，就是所谓的这种。

我不知道怎么翻译，但是对于art的professional来说，是很重要的一种分析能力，然后这件事情也可以拿来去benchmark，multi-model system。

然后最后我想要简单介绍的一个工作是，我们另外一个有点benchmarking，或者说一个新的environment，我们叫它VIRL。

Grounding Virtual Intelligence in Real Life。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_119.png)

然后它的出发点是说，我们现在会有很多的agents相关的工作，但是很多这些agents的工作，还是会被deploy在这个，比如说sandbox game，这种沙盒游戏里面。

或者说robotics当然非常非常重要。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_121.png)

但是很多时候我们还是会受到一些硬件的限制，或者说大家会讨论在vim里面，什么叫做open world perception，但是这些讨论更像是open internet perception。

因为我们的所有这些VIRL信息的来源，可能还是来自于我们internet的这些，我们user uploaded and captured的这些images，我觉得因为时间有限。

我可以只通过一个video的形式来介绍一下，我们这个工作，不知道能不能放出来，我可以在旁边稍微解说一下，就是说我们会创建不同的agents，然后他们会有自己的behavior，他们会有自己的性格。

但是我们的environment，一个比较有意思的地方，它是在真实的环境下面部署的，然后并且所有的这些agents。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_123.png)

他们也会有真实的intention，好像有点卡，然后我们的这个agents environment，其实就是我们的city，我们当然需要用large image models。

我们当然也不需要用large vision models，所以它是一个比较复杂的系统。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_125.png)

会定义environment，然后把它跟vision language，combine到一起，使得我们的agents能够有一些，它自己的intention，大家先看吧。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_127.png)

这是一个比较有趣的例子。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_129.png)

我们部署了这个agents到纽约的中央公园里，然后我们可以数出来，中央公园里面一共有多少个垃圾桶，agents之间也可以通过合作的方式。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_131.png)

去做navigation的选项，然后它还可以帮你去plan一些。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_133.png)

你的这些每天的行动，那我觉得一个更重要的事情是。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_135.png)

我们这个environment，可以作为一个很好的衡量，large image model跟vision model的一个performance的一个benchmark。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_137.png)

因为我们可以有更diverse的这些场景，它其实是整个世界上很多很多的city，然后可以做place recognition，可以做v2a等等，然后我们一共，这个好卡，包括在亚洲，在纽约，在澳大利亚。

在日本，我们发现其实对于，对于这样的agent的系统来说，我们发现，其实一旦我们把我们的vision的research，把它extend到这种真实的世界场景里面，我们发现。

其实在这个世界有非常非常多的问题，对吧，我们发现，比如说我举一个例子，更多例子可以从Pivot源找到，比如说我们发现，现在的large image model。

以及这个multi-model system，在这些发达的城市里面，比如在纽约，在巴黎都没有什么问题，但是一旦我们现在要去做同样的task，比如navigation或place recognition。

在非洲的城市，或者在一些不是English，作为dominant语言的城市，比如在东京 在香港，performance就会降得特别差，虽然现在大家会claim。

我们现在这些数据都是multilingual，然后会有billion scale的数据，但是当我们在这种真实的场景下面，部署的时候，我们就会发现，其实还是会有很多的问题，值得我们去解决。

然后我觉得这个framework，现在也是完全open source，然后我们也希望有更多的research，可以在这样一个，跟我们真实的生活跟世界，联系得非常非常紧密的一个environment里面。

去develop不管是embodied agent，不管是generated agent，还是这些core foundational的。

representation learning的这些technique，最后还有可能一两分钟的时间。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_139.png)

我想讨论一下更基础的东西，就是说，我们一开始说supervised learning，做得很不好，然后一个原因是因为。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_141.png)

如果我们只是想把这种，非常diverse的这种input，强行把它map到，最后的一个label上面去，我们所有这些chair都是chair，我们现在只告诉neural network一件事说。

所有这些事情都是chair，其实network做不了什么太多的事情，它要么会依赖于，这种sperious correlation，要么它就只能去memorize，这件事情导致。

我们会claim supervised learning，其实不是一个很好的，一个基础学习的模式，因为它的generalization是很差的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_143.png)

然后再之后我们会讨论，soft supervised learning，为什么要做soft supervised learning呢，是因为我们想要去build。

这种background knowledge，and approximate form of common sense。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_145.png)

在AI的system里面去，但我想说的一个观点是说，CLIP其实是一个，strongly supervised learning的model，它不是，很多时候会有些misconception。

大家会觉得CLIP，是一个weak supervised learning，但它真的不是，因为language能够给你提供的，supervision是要远远强于。

just a few categorical labels，然后我觉得我们现在面临的问题，也是我们想要继续去在，这个virtual supervised learning的，这个领域去发展。

因为我们 至少我个人而言，我还是倾向于，subvised learning，能给我们一些，不一样的一些behavior，能让我们真的能够去学到，某种common sense。

和这种background knowledge，但我也要承认，在soft supervised learning，工作了这么长时间之后，我发现，其实现在这个领域，是有点getting stuck。

大家不知道该做什么。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_147.png)

what is next thing to do，然后我觉得可能，我们可以回顾一下。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_149.png)

这个soft supervised learning的历史，在2015年16年的时候，大家要对标的东西是说，image net pertaining to performance，在那个时候，这个就是。

这个ultimate的，这个representation learning的approach，然后那时候会有各种各样的，这个soft supervised learning的model。

比如说像context encoder，但那时候领域还是比较宽容的，就是那时候大家跟，这个supervised learning比起来，一般会差，比如10%到20%个点，但大家也不care。

我们会develop，各种各样的pretext task，然后我们继续去push，这个reaction往前走。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_151.png)

直到比如说到2019年，比如说凯明的moco出来之后，然后大家发现，其实这个soft supervised learning，也能work，并且它可以去超过，image net pertaining。

然后在各种各样的，variant task下面，但之后会有MAE，会有dino等等。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_153.png)

然后我现在想说的一件事情，其实是说，clip with strong language supervision，其实在当前这个时代，就是新的image net。

supervised learning的counterpart，然后我们现在，为什么还要做vision SSL呢，我觉得也是因为，说可能clip，它也会有各种各样，自己的问题，我觉得这些问题。

很多时候跟supervised image net，pertaining，其实也是很相关的，然后但是，还是像我一开始说的这样，我们怎么去做。

vision soft supervised learning，这个方式可能要发生一些变化。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_155.png)

所以可能下周，希望吧，我们会release一个新的paper，我们叫它Cabrian 1，它是一个fully open，variant centric exploration。

of multi-model large image models，所以我们就make了这个analogy，在原来的时候，我们会要去develop，这种各种各样的vision model。

比如说不管是MOCO也好，MAE也好，然后我们会有一个，evaluation protocol，比如说我们会拍一个，linear probing，或者说有end-to-end tuning。

然后我们会在，image net classification上，或者cohoid detection，或者segmentation这样的task上面，去衡量我的。

view representation learning的好坏，我觉得一个比较可行的，在现阶段去study，vision soft supervised learning的方式，是说我们把像LAVA。

这样的multi-model system，把它当作一个，对于view representation learning，study的一个pipeline，我们还是会有。

pertained vision models，我们会design connector，然后只不过之前，我们会用linear probing，现在我们会用。

view instruction tuning，之前我们会有比较受限的，这些benchmark，但现在我们会有，much more diverse benchmarks。

all structured in this VQA format，但其实大家可以看到。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_157.png)

这两件事情，是有一些analogy，所以我们会从头，搭了一些infra，然后我们所有的实验，是在Google TPU上面做的，然后会release，一系列tutorial。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_159.png)

包括Petrochex， LA， and Chex，然后我们会重新去，整合现有的这些，instruction tuning dataset，然后去create一个新的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_161.png)

instruction tuning的，比较大的一个data set，然后当然最重要的事情是说，我们因为希望有这样的一个，新的evaluation的。

view representation learning的，一个pipeline，我们会benchmark，各种各样的view representation learning。

with multi-modelized models，然后我们会有，很多的findings，insights from tuning，and benchmarking，大概超过20个。

不同的vision models，它包括比如说，clipped model，as a learning model，也包括像depth prediction model，diffusion model。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_163.png)

and segmentation model，对，然后我们整个的工作，希望能够成为一种，某种open cookbook，for instruction tuning。

multi-modelized language models，所以我们这个工作里面，会涉及到五个不同的pilot，包括怎么样去，选择，以及使用，各种各样的view representations。

怎么样去design一个更好的，vision-centric connector，怎么样去设计，instruction tuning data，以及各种。

相配套的instruction tuning recipe，以及最后怎么样去，能够去interpret，我们的results，因为现在还有一个问题是，multi-model。

这个large-language model的benchmark，实在是太多了，然后大家会arbitrary的选择，5到10个这个benchmark，来report the performance。

但是，hopefully we can do better，对。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/86a11da2d01a1796e9d9adc7b72af794_165.png)

然后，这是，这个乱码，已经结束了，好，对，这个乱码，我看好像没有时间，对，这个乱码其实是我最后问了，Chai-Chi-P一个问题，我说我想要结束我的talk，然后你能不能，给我一句话总结一下。

这个关于improved vision capability，跟language understanding的，这个关系，然后Chai-Chi-P告诉我说，说，他大概说的意思是说，更好的vision。

不只是让我们能看得更远，也是能让我们理解得更深，这是Chai-Chi-P的回答，好，謝謝。