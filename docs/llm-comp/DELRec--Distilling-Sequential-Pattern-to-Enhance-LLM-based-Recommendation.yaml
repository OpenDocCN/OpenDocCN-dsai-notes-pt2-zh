- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 19:05:48'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.11156](https://ar5iv.labs.arxiv.org/html/2406.11156)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Guohao Sun Donghua UniversitySongjiang QuShanghai ShiChina [111@dhu.com](mailto:111@dhu.com)
     and  Haoyi Zhang Donghua UniversitySongjiang QuShanghai ShiChina [222@dhu.com](mailto:222@dhu.com)(2018;
    20 February 2007; 12 March 2009; 5 June 2009)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Sequential recommendation (SR) tasks enhance recommendation accuracy by capturing
    the connection between users’ past interactions and their changing preferences.
    Conventional models often focus solely on capturing sequential patterns within
    the training data, neglecting the broader context and semantic information embedded
    in item titles from external sources. This limits their predictive power and adaptability.
    Recently, large language models (LLMs) have shown promise in SR tasks due to their
    advanced understanding capabilities and strong generalization abilities. Researchers
    have attempted to enhance LLMs’ recommendation performance by incorporating information
    from SR models. However, previous approaches have encountered problems such as
    1) only influencing LLMs at the result level; 2) increased complexity of LLMs
    recommendation methods leading to reduced interpretability; 3) incomplete understanding
    and utilization of SR models information by LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address these problems, we proposes a novel framework, DELRec, which aims
    to extract knowledge from SR models and enable LLMs to easily comprehend and utilize
    this supplementary information for more effective sequential recommendations.
    DELRec consists of two main stages: 1) SR Models Pattern Distilling, focusing
    on extracting behavioral patterns exhibited by SR models using soft prompts through
    two well-designed strategies; 2) LLMs-based Sequential Recommendation, aiming
    to fine-tune LLMs to effectively use the distilled auxiliary information to perform
    SR tasks. Extensive experimental results conducted on three real datasets validate
    the effectiveness of the DELRec framework.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Large language Model, Sequential Recommendation, Pattern Distillation^†^†copyright:
    acmlicensed^†^†journalyear: 2018^†^†doi: XXXXXXX.XXXXXXX^†^†conference: Make sure
    to enter the correct conference title from your rights confirmation emai; June
    03–05, 2018; Woodstock, NY^†^†isbn: 978-1-4503-XXXX-X/18/06^†^†ccs: Information
    systems Recommender systems'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. INTRODUCTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sequential recommendation (SR) tasks aim to improve the accuracy of recommendations
    by understanding and modeling the relationship between users’ interaction history
    and their evolving preferences. However, traditional SR models only capture sequential
    patterns within training data, often overlooking the broader context and semantic
    information embedded in item titles that can be obtained from external sources.
    These limitations restrict their predictive ability and adaptability to constantly
    changing scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, large language models (LLMs) have shown promise in SR tasks due to
    their advanced comprehension abilities and powerful generalization capabilities.
    As LLMs are trained on vast datasets containing abundant information, including
    inherent item features and details, they can infer user preferences and predict
    future actions by leveraging LLMs’ understanding of item attributes and reasoning
    based on world knowledge. However, using LLMs directly as sequential recommenders
    can pose certain problems. For instance, due to a lack of domain-specific expertise
    in recommendation or an incomplete understanding of the recommendation patterns
    in SR tasks, LLMs often exhibit poor performance when directly used as recommender.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, researchers have previously proposed providing LLMs with auxiliary
    information from conventional SR models. These approaches aim to assist LLMs in
    making more accurate recommendations when performing SR tasks. We can roughly
    categorize the alignment of SR models with LLMs’ recommendation into three paradigms:
    1) providing SR models information in textual form to LLMs; 2) combining the embeddings
    from SR models encodings with those from LLM encodings; 3) supplying LLMs with
    embeddings derived from SR models encodings. They are illustrated in Figure [1](#S1.F1
    "Figure 1 ‣ 1\. INTRODUCTION ‣ DELRec: Distilling Sequential Pattern to Enhance
    LLM-based Recommendation"). However, previous methods have encountered certain
    issues.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2c4c381867900f7ec3bcf7388cb02a04.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. Demonstration of three paradigms of the alignment of SR models with
    LLMs’ recommendation
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLMs Prompt with SR Text: This paradigm typically involves directly incorporating
    the recommendation results or textual information from conventional SR models
    into the prompt. However, this paradigm often suffers from subpar recommendation
    performance due to the limited information provided by the prompt. The prompt
    can only assist LLMs in making decisions based on the results but cannot guide
    LLMs from the perspective of the recommendation process. One fundamental reason
    is that natural language is often insufficient for accurately and comprehensively
    describing the specific recommendation behavior patterns of SR models.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLMs Encoding with SR Embedding: This paradigm instead of using LLMs as recommenders
    and utilizes their encoding and representation capabilities. It typically involves
    utilizing LLMs to encode a given text or sequence and simultaneously employing
    conventional models to obtain item or user encodings. Subsequently, these two
    types of embeddings are combined and processed in various ways to generate recommendation
    scores for items. Although this paradigm enables the integration of information
    from both SR models and LLMs, it also introduces challenges in comprehending and
    interpreting recommendations. This may potentially undermine some key advantages
    of using LLMs for recommendations, such as their simplicity and interpretability.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLMs Prompt with SR Embedding: This paradigm combines some advantages from
    the previous paradigms by typically merging embeddings from SR models with a prompt
    before inputting them into LLMs to generate item recommendations. This paradigm
    uses embeddings encoded by SR models as auxiliary information for the recommendation
    process provided to LLMs and often involves a projector to align the dimensions
    of SR model’s embeddings with the language space of LLMs. However, due to poor
    projector design or changes in embedding dimensions that result in information
    loss, LLMs may not fully comprehend the meanings conveyed by these embeddings.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To tackle the aforementioned problems, we propose Distilling Sequential Pattern
    to Enhance LLM-based Recommendation (DELRec) framework, which aims to distill
    the behavioral patterns of SR models and empower LLMs to easily comprehend and
    leverage this supplementary information for more effective sequential recommendations.
    DELRec is roughly shown in Figure [2](#S1.F2 "Figure 2 ‣ 1\. INTRODUCTION ‣ DELRec:
    Distilling Sequential Pattern to Enhance LLM-based Recommendation"), and it contains:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SR Models Pattern Distilling: Rather than inputting encoded information from
    SR models or LLMs as previous methods did, the approach of SR Models Pattern Distilling
    is inspired by knowledge distillation techniques used in LLMs. The objective is
    to distill the recommendation patterns and information of conventional SR models
    understandable to LLMs. This involves using LLMs to extract useful knowledge into
    soft prompts. Through two learning components, namely SR Models Temporal Analysis
    and Recommendation Pattern Simulating, LLMs are empowered to comprehend and simulate
    recommendation process employed by SR models effectively. This is a process of
    transforming the knowledge of SR models into a form that LLMs can understand and
    use.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLMs-based Sequential Recommendation: After getting the distilled SR knowledge
    in the first stage for SR tasks, we propose LLMs-based Sequential Recommendation
    for effectively instructing LLMs. Instead of using a projector for embedding mapping,
    we insert the learned soft prompts directly into the prompt, and then fine-tune
    the LLMs to adapt to the learning tasks that utilize auxiliary information.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fe3a850704dfedd8ddd08e04e18c31d9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. Demonstration of the paradigm of DELRec with proposed learning components
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 'The main contributions of our work are summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proposing two novel components in DELRec to distill the sequential recommendation
    patterns of SR models in soft prompts as accurately as possible.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing an ingenious method to fine-tune LLMs to enable them to use the distilled
    auxiliary information appropriately, thereby reducing information loss.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting extensive experiments to demonstrate the effectiveness of DELRec.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. PRELIMINARY
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1\. Task Formulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We consider a recommender system with a set of users $U$.
  prefs: []
  type: TYPE_NORMAL
- en: Different from conventional SR models, we leverage LLMs to solve the recommendation
    task in an instruction following paradigm. Specifically, for each user $u$.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Prompt Tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Prompt tuning stands out as a sophisticated technique that refines the ability
    of LLMs to conform to specific linguistic tasks and patterns, through allowing
    soft prompts within the prompt $P$ with an emphasis on the target learning objective:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $1$2 |  |'
  prefs: []
  type: TYPE_TB
- en: where $\Phi$.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. Parameter Efficient Fine-Tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The comprehensive fine-tuning of all parameters within LLMs demands considerable
    time and computational resources. To mitigate this issue, the approach of Parameter-Efficient
    Fine-Tuning (PEFT) concentrates on adjusting a minimal subset of parameters, thereby
    reducing computational demands while maintaining notable performance levels. An
    example of a PEFT method is AdaLoRA (Adaptive LoRA), which is a method to optimize
    the number of trainable parameters for weight matrices and layers, unlike LoRA
    which evenly distributes parameters across all modules. It allocates more parameters
    to important weight matrices and layers, while less important ones receive fewer
    parameters. The optimization goal for AdaLoRA is formulated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $1$2 |  |'
  prefs: []
  type: TYPE_TB
- en: where AdaLoRA introduces the parameters $\Theta$.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1ecbe8efcd0166c9117d676a4c602215.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. Illustrating the proposed DELRec that distills the recommendation
    behavior patterns and information of conventional SR models, with soft prompts
    can more easily align with LLMs and facilitate their understanding.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: 3\. METHODOLOGY
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To distill the recommendation behavior patterns of conventional SR models that
    LLMs can understand, and to utilize them in sequential recommendation tasks based
    on LLMs, we propose the DELRec framework, as presented in Figure [3](#S2.F3 "Figure
    3 ‣ 2.3\. Parameter Efficient Fine-Tuning ‣ 2\. PRELIMINARY ‣ DELRec: Distilling
    Sequential Pattern to Enhance LLM-based Recommendation"). Specifically, it involves
    two key stages. In the first stage, We do not directly use discrete hard prompts
    in the whole prompt as usual to add auxiliary information of SR models to LLMs
    or manually describe the recommendation process of SR models. Instead, we insert
    a series of soft prompts into the prompt and freeze the parameters of LLMs, allowing
    LLMs to learn the recommendation information and patterns of conventional SR models
    through our proposed SR Models Pattern Distilling.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, in the second stage, align the knowledge distilled from the SR models
    with LLM-based recommendation tasks, namely, insert the soft prompts learned in
    the first stage into the prompt and freeze the parameters of soft prompts. Then,
    fine-tune LLMs to make more accurate sequential recommendations using the auxiliary
    information from SR models. We now turn our attention to the specific architecture
    and training approach of DELRec.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Hybrid Prompt Construction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First, we will introduce the concepts of hard prompt and soft prompt involved
    in the DELRec framework, as well as the construction of our hybrid prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hard Prompt. In conventional LLM recommendation tasks, hard prompts are commonly
    used to construct the prompt or directly provide guidance information within the
    general prompt for LLMs, ($e.g.$ as depicted in Figure [4](#S3.F4 "Figure 4 ‣
    3.1\. Hybrid Prompt Construction ‣ 3\. METHODOLOGY ‣ DELRec: Distilling Sequential
    Pattern to Enhance LLM-based Recommendation") ).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9388e19153306bec18883c4151253a24.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Demonstration of a general prompt that typically relies entirely
    on hard prompts to provide information for LLMs. We use movie recommendations
    as the background for the prompt and SASRec as the example SR model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hard prompts also known as discrete prompts, are composed of specific vocabulary.
    These prompts are artificially designed and do not change during the training
    process of the LLMs. Explicitly, They are a set of fixed words that instruct the
    models how to perform in specific tasks. Denote hard prompts as $hp_{i}$ is entirely
    constructed by hard prompts:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $\displaystyle P_{0}=\{hp_{1},hp_{2},...,hp_{l}\},$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'here, $l$ is processed by the LLM tokenizer and word embedding layer, it will
    become the corresponding embeddings in the language space. We can represent this
    process as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (4) |  | $\displaystyle E_{0}=\sum_{i=1}^{l}f_{tkz}(hp_{i})\in\mathbb{R}^{l\times
    d^{n}},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $E_{0}$ indicates the LLM tokenizer and word embedding layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Soft Prompt. Although hard prompts usually correspond to natural language and
    are easily understood by humans, the purpose of prompt construction is to find
    a method that allows LLMs to effectively perform a task. Rather than being for
    human consumption, it is not necessary to limit the prompt to human-interpretable
    natural language. Therefore, unlike the general prompt $P_{0}$, we will insert
    a portion of soft prompts into the construction of the hybrid prompt, as shown
    in Figure [5](#S3.F5 "Figure 5 ‣ 3.1\. Hybrid Prompt Construction ‣ 3\. METHODOLOGY
    ‣ DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/09c83b987baa0ac833fbf1bc1ec2d939.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. Demonstration of a hybrid prompt inserting a series of soft prompts
    when constructs the prompt, and these soft prompts are directly randomly initialized
    as word embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: 'These soft prompts remove the constraint of hard prompts that the embedding
    of the prompt words can only be the embedding of natural language words. These
    soft prompts can be adjusted according to the training data from downstream tasks,
    allowing us to provide some ”only LLMs understand” knowledge to the LLMs in the
    prompt, and this knowledge is difficult or impossible for us to describe in natural
    language. Formally, we denote soft prompts as $sp_{j}$ is constructed by both
    hard and soft prompts:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (5) |  | $1$2 |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $k$ will also become word embeddings. However, unlike hard prompts that
    will correspond to a fixed position in the language space, soft prompts will be
    processed into randomly initialized embeddings. As LLMs learn the target task,
    the position of the soft prompts in the language space will change:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (6) |  | $\displaystyle E_{1}=\sum_{j=1}^{k}f_{iniz}(sp_{j})\in\mathbb{R}^{k\times
    d^{n}},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $E_{1}$ indicates the process of randomly initializing to the same dimension
    as the word embeddings in the language space of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Design. In our prompt design, inspired by previous research, since LLMs
    cannot understand the semantic information of id-based item representations well,
    we will use pure text to represent the user’s interaction sequence and candidate
    item set ( $e.g.,$ L.A. Story (1991), Tin Cup (1996), …, Men in Black (1997) ).
    And based on the aforementioned hard prompts and soft prompts, we will design
    various hybrid prompts corresponding to different tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, our prompt design will be different in two stages. In the SR Models
    Pattern Distilling stage, we will design different prompts for each of the two
    components, aiming to better distill the recommendation behavior patterns and
    information of SR models. In the LLMs-based sequential recommendation stage, the
    goal of our prompt design is to enable LLMs to better use the information distilled
    in the first stage to make accurate recommendations. The two stages described
    above are introduced next.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. SR Models Pattern Distilling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Previous research has shown that providing LLMs with information from conventional
    recommendation models will enhance the performance of LLMs as recommenders. Inspired
    by this, we will provide LLMs with better, more understandable and usable information.
    To this end, we propose the SR Models Pattern Distilling, and use the soft prompts
    mentioned above to more accurately capture the recommendation behavior patterns
    of conventional SR models for LLMs. Specifically, the SR Models Pattern Distilling
    stage is divided into two components, namely SR Models Temporal Analysis and Recommendation
    Pattern Simulating. Next, we will introduce these in detail one by one.
  prefs: []
  type: TYPE_NORMAL
- en: SR Models Temporal Analysis. Since one of the focuses of SR tasks is to recommend
    items that are temporally closer based on the user’s interaction sequence, which
    exhibits strong temporal dynamics, it is crucial to perform a temporal analysis
    of SR models and providing similar temporal knowledge to LLMs in order to better
    simulate the recommendation patterns of SR models.
  prefs: []
  type: TYPE_NORMAL
- en: Most SR models ($e.g.$ SASRec) achieve this by aggregating the features of items
    in user interaction sequence to the most recent item in the sequence. Our idea
    is to enable LLMs to similarly recognize and learn the importance of ”the most
    recent item”, thereby acquiring relevant temporal knowledge. Therefore, our proposed
    strategy is to provide the interaction sequence and target item, and let the LLMs
    predict the most recent item in the sequence——a behavior we refer to as PMRI (Predicting
    Most Recent Item).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/751f29802883923cc3e1dff58fd6b3b1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. Demonstration of the prompt for SR Models Temporal Analysis. The
    previous part of the interaction sequence is used as ICL to provide LLMs with
    examples that bridge the gap between previous and subsequent parts. LLMs are then
    tasked with PMRI, enabling them to learn a similar process to temporal feature
    aggregation of SR models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, our strategy will allow LLMs to perform PMRI on the sequences
    and we will also provide In-Context Learning (ICL) in an ingenious way to not
    only help LLMs enhance their learning efficiency and quality, but also increase
    LLMs’ awareness of temporal coherence, our strategy is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Given the user interaction sequence $$I_{1:n-1}=(I_{1},I_{2},...,I_{\alpha-1},\\
  prefs: []
  type: TYPE_NORMAL
- en: 'I_{\alpha},...,I_{n-2},I_{n-1})$$, then we inform LLMs that the $\alpha$ are
    optimized by minimizing the loss function of SR Models Temporal Analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (7) |  | $1$2 |  |'
  prefs: []
  type: TYPE_TB
- en: where $D_{0}=\{(x_{i}^{0},y_{i}^{0})\}_{i=1,...,N}$ contains the prompt and
    masked item in the aforementioned.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation Pattern Simulating. Besides SR Models Temporal Analysis, it is
    also essential for LLMs to be able to simulate conventional SR models in making
    similar recommendations, which enables the distillation from the recommendation
    knowledge of SR models into soft prompts.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/563c2fe9ba573091dbd7057517334b16.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. Demonstration of the prompt for Recommendation Pattern Simulating.
    We will use LLMs to learn from the recommendation results of SR models, thereby
    simulating the recommendation patterns of SR models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will have LLMs simulate the recommendation patterns of SR
    models as closely as possible and let LLMs predict the recommendation results
    of SR models ( rather than the ground truth ) based on the user interaction sequence.
    This process can be described as: given the user interaction sequence $I_{1:n-1}=(I_{1},I_{2},...,I_{n-1})$,
    LLMs update the parameters of soft prompts, allowing LLMs to fit the results of
    the SR model well. The prompt of the task is shown in Figure [7](#S3.F7 "Figure
    7 ‣ 3.2\. SR Models Pattern Distilling ‣ 3\. METHODOLOGY ‣ DELRec: Distilling
    Sequential Pattern to Enhance LLM-based Recommendation"). Specifically, the loss
    function of Recommendation Pattern Simulating task can be formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (8) |  | $1$2 |  |'
  prefs: []
  type: TYPE_TB
- en: where $D_{1}=\{(x_{i}^{1},y_{i}^{1})\}_{i=1,...,N}$ consists of the prompt and
    SR models predicted item in the aforementioned Recommendation Pattern Simulating
    step.
  prefs: []
  type: TYPE_NORMAL
- en: 'After obtaining the loss functions for SR Models Temporal Analysis and Recommendation
    Pattern Simulating, we will proceed to update the parameters of soft prompts in
    a multi-task learning (MTL) manner, allowing LLMs to learn from two target tasks
    simultaneously, thereby achieving the distillation of recommendation behavior
    patterns for SR models. The learning objective can be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (9) |  | $1$2 |  |'
  prefs: []
  type: TYPE_TB
- en: where $\lambda_{1}$ during training.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3\. LLMs-based Sequential Recommendation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the first stage (SR Models Pattern Distilling), we successfully distilled
    the recommendation patterns from the SR models. In previous research, to enable
    LLMs to utilize auxiliary information from conventional SR models (such as item
    embeddings), people often used projectors ($e.g.,$ MLP, Tiny Transformers) to
    map the embeddings into the language space of LLMs. However, this approach often
    suffers from poorly designed projectors, which may fail to fully convey the information
    embedded in the original embeddings to LLMs or limit their generalization capabilities,
    etc. Therefore, the soft prompts we distilled can achieve plug-and-play and overcome
    these issues. The prompt is shown in Figure [8](#S3.F8 "Figure 8 ‣ 3.3\. LLMs-based
    Sequential Recommendation ‣ 3\. METHODOLOGY ‣ DELRec: Distilling Sequential Pattern
    to Enhance LLM-based Recommendation").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d04d8809104a2e30bc92f8cac8fba59f.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8\. Demonstration of the prompt for LLMs-based Sequential Recommendation.
    We will provide LLMs with the recommendation patterns and information of SR models
    ($i.e.,$ the soft prompts) distilled from the first phase and guide the LLMs to
    use this auxiliary information to predict the ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we directly incorporate the learned soft prompts $sp_{1:k}=(sp_{1},sp_{2},...,sp_{k})$:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (10) |  | $\displaystyle I_{n}=LLM(P1(sp_{1:k}))$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $P1(\cdot)$ indicates that LLMs utilize the prompt to perform SR tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs Fine-tuning. However, considering there may be noise or harmful information
    in soft prompts, which may guide LLMs to make predictions that are more inclined
    to SR models’ predictions than to ground truth. Therefore, we need to fine-tune
    the parameters of LLMs to guide them to regard soft prompts as reference more.
    Formally, given a user interaction sequence $I_{1:n-1}=(I_{1},I_{2},...,I_{n-1})$
    and fine-tune the LLMs using PEFT (AdaLora). Formally, the learning objectives
    of the LLMs-based Sequential Recommendation can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (11) |  | $1$2 |  |'
  prefs: []
  type: TYPE_TB
- en: where $\overline{D}=\{(\overline{x_{i}},\overline{y_{i}})\}_{i=1,...,N}$.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. EXPERIMENTS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we assess the performance of our proposed framework, DELRec,
    on three real-world datasets. We compare it against various baselines, including
    conventional SR models and LLMs-based models.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ1: Whether the proposed framework outperforms baseline methods, including
    the deep learning models and other LLM based models, for SR?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ2: Are our proposed DELRec able to learn meaningful recommendation behavior
    patterns or information?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ3: How can key components affect our proposed method. Specifically, how is
    the efficacy of the proposed SR Models Temporal Analysis and Recommendation Pattern
    Simulating?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ4: How do hyperparameters influence DELRec?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 4.1\. Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 4.1.1\. Datasets.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We evaluate the proposed DELRec and baseline methods on three real-world datasets
    in sequential recommendations, namely MovieLens-1M and Beauty, as well as Steam.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MovieLens-1M is a commonly used movie recommendation dataset that includes ratings
    given by users to movies and the titles of those movies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beauty is a dataset containing user feedback on beauty products from Amazon
    website.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steam not only contains user reviews of video games on the Steam Store, but
    also covers a variety of game titles.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We show the detailed statistics of the datasets in Table [1](#S4.T1 "Table
    1 ‣ 4.1.1\. Datasets. ‣ 4.1\. Setup ‣ 4\. EXPERIMENTS ‣ DELRec: Distilling Sequential
    Pattern to Enhance LLM-based Recommendation"). For all datasets, we follow [SASRec]
    in treating users’ implicit feedback as interactions between users and items,
    and determine the sequence order of inputs based on timestamps. Subsequently,
    we filter out users and items with fewer than 5 interactions. Meanwhile, we arrange
    them in chronological order as [LLaRA] do, and divide the data into training,
    validation, and test sets in an 8:1:1 ratio. This division method ensures that
    interactions used for training do not appear in subsequent data, thereby avoiding
    any potential information leakage.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1\. Statistics of Datasets
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | $\#$interaction |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| MovieLens | 6,040 | 3,416 | 100,000 |'
  prefs: []
  type: TYPE_TB
- en: '| Steam | 11,938 | 3,581 | 274,726 |'
  prefs: []
  type: TYPE_TB
- en: '| Beauty | 22,363 | 12,099 | 198,474 |'
  prefs: []
  type: TYPE_TB
- en: 4.1.2\. Baselines.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To demonstrate the effectiveness of our DELRec framework, we use two types of
    baselines.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conventional SR Models: The first type includes conventional SR models: GRU4Rec[16]
    (based on RNN), Caser[44] (based on CNN) and SASRec[25] (based on attention),
    which are often used as standard comparisons.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LLMs-based Models: The second type of baseline includes: (1) Bert-Large is
    a milestone LLM capable of performing Masked language modeling (MLM) tasks. (2)
    FLan-T5-Large/XXL are well-known open-source LLMs with an encoder-decoder structure.
    (3) LlamaRec uses a traditional model to recall items and construct a candidate
    set and a verbalizer to directly output item rankings. (4) RecRanker cleverly
    samples items and users and inputs the results of conventional recommendation
    models into the prompt. (5) LLaRA inserts the embedding of items encoded by the
    SR model into the prompt. For the validity of the experiment, we have replaced
    the backbone of LLMs-based baselines with FLan-T5-XL.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 4.1.3\. Implementation Details.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For our proposed DELRec framework, we choose FLan-T5-XL as our backbone and
    we will also use FLAN-T5-Large to perform ablation experiments. It’s worth noting
    that the backbone of our proposed framework can also use open-source Decoder-Only
    structured LLMs, such as Llama2[Llama], and is not constrained by the types of
    LLMs. For the training of conventional SR models, we use the Adam optimizer, with
    a learning rate of 1e-3 and a batch size of 128\. For the first stage of DELRec
    (SR Models Pattern Distilling), for the length of user interaction sequences $n$
    as in the first stage, and also use AdaLoRA and Lion optimizer, with a learning
    rate of 1e-4 and weight decay of 1e-6.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.4\. Evaluation Metrics.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For ranking evaluation, we use top-$k$5.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2\. Overall Performance
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | MovieLens-1M | Steam | Beauty |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | HR@1 | HR@5 | HR@1 | HR@5 | HR@1 | HR@5 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Caser | 0.3150 | 0.6340 | 0.3767 | 0.6680 | 0.2241 | 0.4187 |'
  prefs: []
  type: TYPE_TB
- en: '| Conventional | GRU4Rec | 0.3062 | 0.6295 | 0.3786 | 0.6835 | 0.2369 | 0.4544
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | SASRec | 0.3341 | 0.6704 | 0.3852 | 0.6977 | 0.2573 | 0.4629 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Bert-Large | 0.0306 | 0.0821 | 0.0201 | 0.0424 | 0.0166 | 0.0354 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Flan-T5-Large | 0.0375 | 0.0703 | 0.0240 | 0.0493 | 0.0195 | 0.0346 |'
  prefs: []
  type: TYPE_TB
- en: '| LLMs-based | Flan-T5-XL | 0.0938 | 0.2441 | 0.0723 | 0.1662 | 0.0652 | 0.1071
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | LlamaRec | 0.2870 | 0.5873 | 0.3511 | 0.6478 | 0.2361 | 0.4418 |'
  prefs: []
  type: TYPE_TB
- en: '|  | RecRanker | 0.3246 | 0.6292 | 0.3724 | 0.6537 | 0.2670 | 0.4943 |'
  prefs: []
  type: TYPE_TB
- en: '|  | LLaRA | 0.3523 | 0.6553 | 0.4035 | 0.6911 | 0.3152 | 0.6063 |'
  prefs: []
  type: TYPE_TB
- en: '|  | DALRec (Caser) | 0.3664 | 0.6804 | 0.4157 | 0.6946 | 0.3249 | 0.6175 |'
  prefs: []
  type: TYPE_TB
- en: '| Ours | DALRec (GRU4Rec) | 0.3635 | 0.6722 | 0.4296 | 0.7099 | 0.3413 | 0.6229
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | DALRec (SASRec) | 0.3701 | 0.6919 | 0.4372 | 0.7285 | 0.3477 | 0.6513
    |'
  prefs: []
  type: TYPE_TB
- en: 4.2\. Performance Comparison (RQ1)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [2](#S4.T2 "Table 2 ‣ 4.1.4\. Evaluation Metrics. ‣ 4.1\. Setup ‣ 4\.
    EXPERIMENTS ‣ DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation")
    presents the performance of our method DELRec and various baselines under three
    evaluation metrics. Comparing DELRec with the aforementioned baseline models,
    we can derive the following observations.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DELRec outperforms all baseline models on the MovieLens-1M, Beauty, and Steam
    datasets. It achieves the highest HR@1, HR@5, and NDCG@5 scores compared to conventional
    SR models that only recommend through user interactions or LLMs that lack recommendation
    knowledge. The key reason behind this superior performance is that DELRec effectively
    combines the information from conventional SR models with the powerful reasoning
    capabilities and extensive world knowledge of LLMs to complete more accurate recommendations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When comparing with some original open-source LLMs ($e.g.$, BERT, Flan-T5),
    it is evident that these baseline models not only underperform DELRec in recommendation
    tasks but also exhibit lower metrics compared to conventional SR models and other
    LLMs-based recommendation methods. The reason behind this discrepancy lies in
    the fact that while these LLMs possess strong generalization capabilities, they
    lack domain-specific knowledge and understanding of recommendation patterns, which
    hinders their performance in recommendation tasks. Therefore, providing appropriate
    auxiliary information to adapt LLMs to specific recommendation tasks becomes crucial.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When considering the other LLMS-based improvements we have chosen, the reasons
    for DELRec’s superior performance can be analyzed from several perspectives. Firstly,
    while some methods enable LLMs to perform recommendation tasks ($e.g.$, LLaRA),
    while containing some pattern information from SR models, suffer from loss of
    information due to inconsistent dimensions and may not align perfectly with the
    linguistic meaning of LLMs, resulting in lower performance compared to DELRec.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 4.3\. Ablation Studies (RQ2 & RQ3)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To address RQ2, we conducted an experiment on the soft prompts distilled in
    the initial stage of DELRec and we use SASRec as the backbone model. As these
    soft prompts do not correspond to natural language and are not easily interpretable
    by humans, we performed three transformations on a portion of the soft prompts
    to verify if they truly capture meaningful recommendation behavior patterns or
    information. These transformations include:'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3\. Ablation analysis for learned soft prompts on three datasets (HR@1).
  prefs: []
  type: TYPE_NORMAL
- en: '|  | MovieLens-1M | Steam | Beauty |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| No Soft Prompts | 0.3020 | 0.3426 | 0.2965 |'
  prefs: []
  type: TYPE_TB
- en: '| Manual Construction | 0.3106 | 0.3608 | 0.2898 |'
  prefs: []
  type: TYPE_TB
- en: '| Random Soft Prompts | 0.2752 | 0.2977 | 0.2284 |'
  prefs: []
  type: TYPE_TB
- en: '| Default | 0.3701 | 0.4372 | 0.3477 |'
  prefs: []
  type: TYPE_TB
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'No Soft Prompts: We removed the soft prompts section and the part of instruction
    that directs LLMs to refer to auxiliary information from the SR models.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Manual Construction: Similar to the general prompt where hard prompts are used
    to construct auxiliary information, for constructing auxiliary information, we
    attempted to describe the recommendation process of SASRec model in natural language
    and replaced the original soft prompts with it.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Random Soft Prompts: Soft prompts that have not undergone distillation in the
    first stage were directly initialized randomly and inserted into our prompt.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, the three transformed methods are compared with the complete DELRec
    after fine-tuning in the second stage. Table [3](#S4.T3 "Table 3 ‣ 4.3\. Ablation
    Studies (RQ2 & RQ3) ‣ 4\. EXPERIMENTS ‣ DELRec: Distilling Sequential Pattern
    to Enhance LLM-based Recommendation") shows the measurement metrics of DELRec
    under four different conditions. Based on our observations, we make the following
    inferences.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In methods that solely utilize pure hard prompts without soft prompts or manual
    construction, the Manual Construction method enhances LLMs by describing the recommendation
    patterns of the SR model in nature language. However, due to inaccuracies or insufficient
    information in these descriptions, the metrics of this method only show slight
    improvements compared to the No Soft Prompts method.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Among the few baselines we selected, the Random Soft Prompts method performs
    poorly in terms of metrics. This can be attributed to random soft prompts being
    scattered throughout the semantic space with no meaningful context, resulting
    in strong noise and providing little assistance or potentially misleading LLMs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Soft prompts that have undergone our designed SR Models Pattern Distilling approach
    surpass all three methods mentioned above. This indicates that our distillation
    method is able to effectively extract valuable recommendation patterns and information
    from SR models for LLMs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will verify the impact of various components in DELRec on the framework
    through the following ablation experiments (RQ3). The results are shown in Table
    [4](#S4.T4 "Table 4 ‣ 4.3\. Ablation Studies (RQ2 & RQ3) ‣ 4\. EXPERIMENTS ‣ DELRec:
    Distilling Sequential Pattern to Enhance LLM-based Recommendation"). We introduce
    the variants and analyze their effect respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'w/o SMPD (SR Models Pattern Distilling): By eliminating the process of distilling
    recommendation behavior patterns from SR models in the first stage of DELRec,
    we observed a decline in performance. This is because LLMs lack auxiliary information
    from SR models, which hinders their ability to guide the recommendation process
    effectively.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'w/o LSR (LLMs-based Sequential Recommendation): After distillation in the first
    stage, excluding the fine-tuning process of LLMs in the second stage resulted
    in a decrease in metrics. This can be attributed to using information extracted
    directly from SR models, which introduces noise that may interfere with LLM recommendations.
    Additionally, LLMs are more likely to favor the items predicted by the SR model
    rather than the ground truth.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'w/o SMTA (SR Models Temporal Analysis): Removing SR Models Temporal Analysis
    during the first stage leads to distilled soft prompts lacking temporal characteristics.
    As a result, there is insufficient guidance for LLMs to mimic feature aggregation
    processes similar to those employed by SR models.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'w/o RPS (Recommendation Pattern Simulating): Eliminating Recommendation Pattern
    Simulating during the first stage disrupts alignment between prediction results
    of LLMs and those of SR models. Consequently, it becomes challenging for LLMs
    to effectively simulate overall recommendation behavior patterns exhibited by
    SR models.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'w Flan-T5-Large: In addition to conducting ablation experiments on components
    within DELRec framework, we also explored using Flan-T5-Large as a smaller-scale
    backbone language model within our framework. The experimental results indicated
    that both size and capacity of LLMs have an impact on DELRec’s performance.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Table 4\. Ablation analysis (HR@1) on three datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | MovieLens-1M | Steam | Beauty |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| w/o SMPD | 0.3020 | 0.3426 | 0.2965 |'
  prefs: []
  type: TYPE_TB
- en: '| w/o LSR | 0.2814 | 0.3235 | 0.2666 |'
  prefs: []
  type: TYPE_TB
- en: '| w/o SMTA | 0.3425 | 0.3710 | 0.2949 |'
  prefs: []
  type: TYPE_TB
- en: '| w/o RPS | 0.3379 | 0.3555 | 0.3103 |'
  prefs: []
  type: TYPE_TB
- en: '| w Flan-T5-Large | 0.2592 | 0.3018 | 0.2384 |'
  prefs: []
  type: TYPE_TB
- en: '| Default | 0.3701 | 0.4372 | 0.3477 |'
  prefs: []
  type: TYPE_TB
- en: 4.4\. Hyperparameter Analysis (RQ4)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will conduct experiments on the hyperparameters in our proposed DELRec, including
    soft prompts size $k$, SASRec).
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Soft Prompts Size: Regarding the size of soft prompts, we examined its impact
    on DELRec’s performance. As depicted in Figure [9](#S4.F9 "Figure 9 ‣ 1st item
    ‣ 4.4\. Hyperparameter Analysis (RQ4) ‣ 4\. EXPERIMENTS ‣ DELRec: Distilling Sequential
    Pattern to Enhance LLM-based Recommendation"), we observed that DELRec’s performance
    metrics initially improve with an increase in $k$. However, after reaching a certain
    value, these metrics start to level off. This can be attributed to the fact that
    while soft prompts enhance prompt information through LLMs’ learning process,
    an excessive amount of soft prompts may introduce noise or potentially lead to
    overfitting. Consequently, after soft prompts reach a certain size, they will
    not significantly contribute to the improvement of overall performance.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c661d43391f996bbaab62615c22f0bef.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 9\. Performance comparison w.r.t different soft prompts size $k$ for
    training DELRec on the three datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Recommended Items Size: We investigated how the overall performance changes
    with varying sizes $h$ and overall performance. The variation observed can be
    explained by considering that providing SR model-recommended items helps LLMs
    understand recommendation patterns. However, if too large recommended items size
    is set, it may not only mislead LLMs but also result in excessively long prompts
    which could potentially impact LLMs’ attention mechanism.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/aeac882b6fb1d20473f6e28e4288322f.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10\. Performance comparison w.r.t different recommended items size $h$
    for training DELRec on the three datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5\. Case Study
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to further investigate the effectiveness of integrating recommendation
    behavior patterns from SR models with the world knowledge of LLMs, we conducted
    a comparative case study among FLan-T5-XL, SASRec, and DELRec.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we choose a distinct example. For a user with a movie viewing history
    that includes ”American Beauty (1999)”, ”Legends of the Fall (1994)”, ”Gladiator
    (2000)”, ”Out of Sight (1998)”, ”GoldenEye (1995)”, ”Mission: Impossible (1996)”,
    ”Malice (1993)”, ”Amistad (1997)”, ”Jurassic Park (1993)” and ”Men in Black (1997)”.
    We have utilized Flan-T5-XL, SASRec, and DELRec to generate recommendations for
    this particular user.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in Figure [11](#S4.F11 "Figure 11 ‣ 4.5\. Case Study ‣ 4\. EXPERIMENTS
    ‣ DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation"),
    we observe that based on the knowledge contained in Flan-T5-XL, it recommended
    the sequel film ”Men in Black II (2002)” to the user since their last watched
    movie was ”Men in Black (1997)”. On the other hand, SASRec predicted recommendations
    by considering the user’s most recent viewing history and suggested an action/sci-fi
    film called ”Aliens (1986)” which aligns with the theme of ”Men in Black (1997)”.
    In contrast, DELRec combined conventional recommendation patterns with rich world
    knowledge. It took into account the changing preferences of users from drama/classic
    to action/sci-fi genres and it recommended ”Back to the Future (1985)”, which
    indeed was the next interaction by the user.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/83701a0e38e3db486eb92a366a3f5188.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11\. Case study comparison results of the effectiveness of three models
    in recommending movies: FLan-T5-XL, SASRec and DELRec.'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. RELATED WORK
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we provide a literature review on LLMs for Sequential Recommendation
    and Prompt Tuning for Recommendation. Our work in this paper draws inspiration
    from these approaches to align SR models with LLMs-based recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. LLMs for Sequential Recommendation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the field of SR, recognizing the sequence of user interactions is crucial
    for predicting their next preference. Modern Sequential Recommender Systems (SRS)
    employ various techniques such as RNNs, CNNs, or transformers to identify sequential
    pattern in user interactions. For example, GRU4Rec utilizes GRU for analyzing
    session-based data, while Caser uses CNNs to model interactive data across multiple
    dimensions. SASRec incorporates an attention mechanism to assign weights automatically
    to different interactive items.
  prefs: []
  type: TYPE_NORMAL
- en: With the ongoing development of LLMs, researchers are exploring methods to integrate
    SR models with LLMs [33,55,51] in order to enhance the performance of SR tasks.
    LLM-TRSR segments a user’s historical behavior into multiple blocks and summarizes
    them using an LLM-based summarizer before inputting them into prompts for sequential
    recommendation. Tempura employs three incentive strategies to increase the temporal
    awareness of LLMs and uses prompt learning to enable LLMs to return and integrate
    multiple results. LLaRA leverages multimodal mapping by inserting prompts with
    item embeddings encoded by SR models then fine-tunes LLMs with item interaction
    relationships. However, previous methods have encountered challenges such as LLMs
    not fully utilizing this information and excessive complexity among other issues.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Prompt Tuning for Recommendation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Prompt tuning is an effective paradigm where, specifically in the field of
    prompt tuning, prompts can be classified into two categories: hard and soft prompts.
    Hard prompts provide explicit textual information to language models for a given
    task prompt, while soft prompts can adapt and change based on specific tasks,
    thereby enhancing the performance of language models in recommendation tasks.
    Currently, most recommendation systems that are based on language models primarily
    utilize pure hard prompts to generate prompts for the language models. However,
    only a few methods have explored the use of prompt tuning in recommendation systems.
    For instance, RA-Rec[71] employs ID embeddings as soft prompts and incorporates
    an innovative alignment module along with an effective tuning method using a custom
    data structure for alignment.'
  prefs: []
  type: TYPE_NORMAL
- en: Although soft prompts are widely utilized in various other tasks involving LMs,
    they are rarely employed in LLM-based SR tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. CONCLUSION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work introduces a novel framework, DELRec, which aims to enhance the performance
    of LLMs in SR tasks. The framework achieves this by extracting behavioral patterns
    from conventional SR models. Through two main components, namely SR Models Pattern
    Distilling and LLM-based Sequential Recommendation. DELRec not only reduces information
    loss but also improves the recommendation effectiveness of LLMs. Extensive experiments
    on three real-world datasets have been conducted to validate the effectiveness
    of our proposed framework. Overall, DELRec offers a new perspective and approach
    for utilizing LLMs in complex sequential recommendation tasks, particularly in
    capturing semantic information and global context that traditional SR models fail
    to capture. The introduction of DELRec also provides valuable insights for future
    researchers in designing more efficient and accurate recommendation systems.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Citations and Bibliographies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some examples. A paginated journal article (Abril and Plant, [2007](#bib.bib3)),
    an enumerated journal article (Cohen et al., [2007](#bib.bib11)), a reference
    to an entire issue (Cohen, [1996](#bib.bib10)), a monograph (whole book) (Kosiur,
    [2001](#bib.bib24)), a monograph/whole book in a series (see 2a in spec. document)
    (Harel, [1979](#bib.bib18)), a divisible-book such as an anthology or compilation
    (Editor, [2007](#bib.bib13)) followed by the same example, however we only output
    the series if the volume number is given (Editor, [2008](#bib.bib14)) (so Editor00a’s
    series should NOT be present since it has no vol. no.), a chapter in a divisible
    book (Spector, [1990](#bib.bib35)), a chapter in a divisible book in a series
    (Douglass et al., [1998](#bib.bib12)), a multi-volume work as book (Knuth, [1997](#bib.bib23)),
    a couple of articles in a proceedings (of a conference, symposium, workshop for
    example) (paginated proceedings article) (Andler, [1979](#bib.bib4); Hagerup et al.,
    [1993](#bib.bib16)), a proceedings article with all possible elements (Smith,
    [2010](#bib.bib34)), an example of an enumerated proceedings article (Gundy et al.,
    [2007](#bib.bib15)), an informally published work (Harel, [1978](#bib.bib17)),
    a couple of preprints (Bornmann et al., [2019](#bib.bib8); Anzaroot et al., [2014](#bib.bib7)),
    a doctoral dissertation (Clarkson, [1985](#bib.bib9)), a master’s thesis: (Anisi,
    [2003](#bib.bib5)), an online document / world wide web resource (Thornburg, [2001](#bib.bib36);
    Ablamowicz and Fauser, [2007](#bib.bib2); Poker-Edge.Com, [2006](#bib.bib28)),
    a video game (Case 1) (Obama, [2008](#bib.bib27)) and (Case 2) (Novak, [2003](#bib.bib26))
    and (Lee, [2005](#bib.bib25)) and (Case 3) a patent (Scientist, [2009](#bib.bib33)),
    work accepted for publication (Rous, [2008](#bib.bib30)), ’YYYYb’-test for prolific
    author (Saeedi et al., [2010a](#bib.bib31)) and (Saeedi et al., [2010b](#bib.bib32)).
    Other cites might contain ’duplicate’ DOI and URLs (some SIAM articles) (Kirschmer
    and Voight, [2010](#bib.bib22)). Boris / Barbara Beeton: multi-volume works as
    books (Hörmander, [1985b](#bib.bib20)) and (Hörmander, [1985a](#bib.bib19)). A
    couple of citations with DOIs: (IEEE, [2004](#bib.bib21); Kirschmer and Voight,
    [2010](#bib.bib22)). Online citations: (TUG, [2017](#bib.bib37); Thornburg, [2001](#bib.bib36);
    Veytsman, [2017](#bib.bib38)). Artifacts: (R Core Team, [2019](#bib.bib29)) and
    (Anzaroot and McCallum, [2013](#bib.bib6)).'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ablamowicz and Fauser (2007) Rafal Ablamowicz and Bertfried Fauser. 2007. *CLIFFORD:
    a Maple 11 Package for Clifford Algebra Computations, version 11*. Retrieved February
    28, 2008 from [http://math.tntech.edu/rafal/cliff11/index.html](http://math.tntech.edu/rafal/cliff11/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abril and Plant (2007) Patricia S. Abril and Robert Plant. 2007. The patent
    holder’s dilemma: Buy, sell, or troll? *Commun. ACM* 50, 1 (Jan. 2007), 36–44.
    [https://doi.org/10.1145/1188913.1188915](https://doi.org/10.1145/1188913.1188915)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andler (1979) Sten Andler. 1979. Predicate Path expressions. In *Proceedings
    of the 6th. ACM SIGACT-SIGPLAN symposium on Principles of Programming Languages*
    *(POPL ’79)*. ACM Press, New York, NY, 226–236. [https://doi.org/10.1145/567752.567774](https://doi.org/10.1145/567752.567774)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anisi (2003) David A. Anisi. 2003. *Optimal Motion Control of a Ground Vehicle*.
    Master’s thesis. Royal Institute of Technology (KTH), Stockholm, Sweden.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anzaroot and McCallum (2013) Sam Anzaroot and Andrew McCallum. 2013. *UMass
    Citation Field Extraction Dataset*. Retrieved May 27, 2019 from [http://www.iesl.cs.umass.edu/data/data-umasscitationfield](http://www.iesl.cs.umass.edu/data/data-umasscitationfield)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anzaroot et al. (2014) Sam Anzaroot, Alexandre Passos, David Belanger, and Andrew
    McCallum. 2014. Learning Soft Linear Constraints with Application to Citation
    Field Extraction. arXiv:1403.1349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bornmann et al. (2019) Lutz Bornmann, K. Brad Wray, and Robin Haunschild. 2019.
    Citation concept analysis (CCA)—A new form of citation analysis revealing the
    usefulness of concepts for other researchers illustrated by two exemplary case
    studies including classic books by Thomas S. Kuhn and Karl R. Popper. arXiv:1905.12410 [cs.DL]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clarkson (1985) Kenneth L. Clarkson. 1985. *Algorithms for Closest-Point Problems
    (Computational Geometry)*. Ph. D. Dissertation. Stanford University, Palo Alto,
    CA. UMI Order Number: AAT 8506171.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cohen (1996) Jacques Cohen (Ed.). 1996\. Special issue: Digital Libraries.
    *Commun. ACM* 39, 11 (Nov. 1996).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cohen et al. (2007) Sarah Cohen, Werner Nutt, and Yehoshua Sagic. 2007. Deciding
    equivalances among conjunctive aggregate queries. *J. ACM* 54, 2, Article 5 (April
    2007), 50 pages. [https://doi.org/10.1145/1219092.1219093](https://doi.org/10.1145/1219092.1219093)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Douglass et al. (1998) Bruce P. Douglass, David Harel, and Mark B. Trakhtenbrot.
    1998. Statecarts in use: structured analysis and object-orientation. In *Lectures
    on Embedded Systems*, Grzegorz Rozenberg and Frits W. Vaandrager (Eds.). Lecture
    Notes in Computer Science, Vol. 1494\. Springer-Verlag, London, 368–394. [https://doi.org/10.1007/3-540-65193-4_29](https://doi.org/10.1007/3-540-65193-4_29)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Editor (2007) Ian Editor (Ed.). 2007. *The title of book one* (1st. ed.). The
    name of the series one, Vol. 9. University of Chicago Press, Chicago. [https://doi.org/10.1007/3-540-09237-4](https://doi.org/10.1007/3-540-09237-4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Editor (2008) Ian Editor (Ed.). 2008. *The title of book two* (2nd. ed.). University
    of Chicago Press, Chicago, Chapter 100. [https://doi.org/10.1007/3-540-09237-4](https://doi.org/10.1007/3-540-09237-4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gundy et al. (2007) Matthew Van Gundy, Davide Balzarotti, and Giovanni Vigna.
    2007. Catch me, if you can: Evading network signatures with web-based polymorphic
    worms. In *Proceedings of the first USENIX workshop on Offensive Technologies*
    *(WOOT ’07)*. USENIX Association, Berkley, CA, Article 7, 9 pages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hagerup et al. (1993) Torben Hagerup, Kurt Mehlhorn, and J. Ian Munro. 1993.
    Maintaining Discrete Probability Distributions Optimally. In *Proceedings of the
    20th International Colloquium on Automata, Languages and Programming* *(Lecture
    Notes in Computer Science, Vol. 700)*. Springer-Verlag, Berlin, 253–264.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Harel (1978) David Harel. 1978. *LOGICS of Programs: AXIOMATICS and DESCRIPTIVE
    POWER*. MIT Research Lab Technical Report TR-200\. Massachusetts Institute of
    Technology, Cambridge, MA.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Harel (1979) David Harel. 1979. *First-Order Dynamic Logic*. Lecture Notes in
    Computer Science, Vol. 68. Springer-Verlag, New York, NY. [https://doi.org/10.1007/3-540-09237-4](https://doi.org/10.1007/3-540-09237-4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hörmander (1985a) Lars Hörmander. 1985a. *The analysis of linear partial differential
    operators. III*. Grundlehren der Mathematischen Wissenschaften [Fundamental Principles
    of Mathematical Sciences], Vol. 275. Springer-Verlag, Berlin, Germany. viii+525
    pages. Pseudodifferential operators.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hörmander (1985b) Lars Hörmander. 1985b. *The analysis of linear partial differential
    operators. IV*. Grundlehren der Mathematischen Wissenschaften [Fundamental Principles
    of Mathematical Sciences], Vol. 275. Springer-Verlag, Berlin, Germany. vii+352
    pages. Fourier integral operators.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IEEE (2004) IEEE 2004. IEEE TCSC Executive Committee. In *Proceedings of the
    IEEE International Conference on Web Services* *(ICWS ’04)*. IEEE Computer Society,
    Washington, DC, USA, 21–22. [https://doi.org/10.1109/ICWS.2004.64](https://doi.org/10.1109/ICWS.2004.64)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kirschmer and Voight (2010) Markus Kirschmer and John Voight. 2010. Algorithmic
    Enumeration of Ideal Classes for Quaternion Orders. *SIAM J. Comput.* 39, 5 (Jan.
    2010), 1714–1747. [https://doi.org/10.1137/080734467](https://doi.org/10.1137/080734467)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Knuth (1997) Donald E. Knuth. 1997. *The Art of Computer Programming, Vol.
    1: Fundamental Algorithms (3rd. ed.)*. Addison Wesley Longman Publishing Co.,
    Inc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kosiur (2001) David Kosiur. 2001. *Understanding Policy-Based Networking* (2nd.
    ed.). Wiley, New York, NY.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee (2005) Newton Lee. 2005. Interview with Bill Kinder: January 13, 2005.
    Video. *Comput. Entertain.* 3, 1, Article 4 (Jan.-March 2005). [https://doi.org/10.1145/1057270.1057278](https://doi.org/10.1145/1057270.1057278)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Novak (2003) Dave Novak. 2003. Solder man. Video. In *ACM SIGGRAPH 2003 Video
    Review on Animation theater Program: Part I - Vol. 145 (July 27–27, 2003)*. ACM
    Press, New York, NY, 4. [https://doi.org/99.9999/woot07-S422](https://doi.org/99.9999/woot07-S422)
    [http://video.google.com/videoplay?docid=6528042696351994555](http://video.google.com/videoplay?docid=6528042696351994555)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obama (2008) Barack Obama. 2008. A more perfect union. Video. Retrieved March
    21, 2008 from [http://video.google.com/videoplay?docid=6528042696351994555](http://video.google.com/videoplay?docid=6528042696351994555)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poker-Edge.Com (2006) Poker-Edge.Com. 2006. Stats and Analysis. Retrieved June
    7, 2006 from [http://www.poker-edge.com/stats.php](http://www.poker-edge.com/stats.php)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'R Core Team (2019) R Core Team. 2019. *R: A Language and Environment for Statistical
    Computing*. R Foundation for Statistical Computing, Vienna, Austria. [https://www.R-project.org/](https://www.R-project.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rous (2008) Bernard Rous. 2008. The Enabling of Digital Libraries. *Digital
    Libraries* 12, 3, Article 5 (July 2008). To appear.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saeedi et al. (2010a) Mehdi Saeedi, Morteza Saheb Zamani, and Mehdi Sedighi.
    2010a. A library-based synthesis methodology for reversible logic. *Microelectron.
    J.* 41, 4 (April 2010), 185–194.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saeedi et al. (2010b) Mehdi Saeedi, Morteza Saheb Zamani, Mehdi Sedighi, and
    Zahra Sasanian. 2010b. Synthesis of Reversible Circuit Using Cycle-Based Approach.
    *J. Emerg. Technol. Comput. Syst.* 6, 4 (Dec. 2010).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scientist (2009) Joseph Scientist. 2009. The fountain of youth. Patent No. 12345,
    Filed July 1st., 2008, Issued Aug. 9th., 2009.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Smith (2010) Stan W. Smith. 2010. An experiment in bibliographic mark-up: Parsing
    metadata for XML export. In *Proceedings of the 3rd. annual workshop on Librarians
    and Computers* *(LAC ’10, Vol. 3)*, Reginald N. Smythe and Alexander Noble (Eds.).
    Paparazzi Press, Milan Italy, 422–431. [https://doi.org/99.9999/woot07-S422](https://doi.org/99.9999/woot07-S422)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spector (1990) Asad Z. Spector. 1990. Achieving application requirements. In
    *Distributed Systems* (2nd. ed.), Sape Mullender (Ed.). ACM Press, New York, NY,
    19–33. [https://doi.org/10.1145/90417.90738](https://doi.org/10.1145/90417.90738)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thornburg (2001) Harry Thornburg. 2001. *Introduction to Bayesian Statistics*.
    Retrieved March 2, 2005 from [http://ccrma.stanford.edu/~jos/bayes/bayes.html](http://ccrma.stanford.edu/~jos/bayes/bayes.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TUG (2017) TUG 2017. *Institutional members of the TeX Users Group*. Retrieved
    May 27, 2017 from [http://wwtug.org/instmem.html](http://wwtug.org/instmem.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Veytsman (2017) Boris Veytsman. 2017. *acmart—Class for typesetting publications
    of ACM*. Retrieved May 27, 2017 from [http://www.ctan.org/pkg/acmart](http://www.ctan.org/pkg/acmart)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
