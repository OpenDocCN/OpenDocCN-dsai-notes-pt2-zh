- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 19:04:32'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.18297](https://ar5iv.labs.arxiv.org/html/2406.18297)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \copyrightclause
  prefs: []
  type: TYPE_NORMAL
- en: Copyright for this paper by its authors. Use permitted under Creative Commons
    License Attribution 4.0 International (CC BY 4.0).
  prefs: []
  type: TYPE_NORMAL
- en: \conference
  prefs: []
  type: TYPE_NORMAL
- en: 'CLEF 2024: Conference and Labs of the Evaluation Forum, September 09–12, 2024,
    Grenoble, France'
  prefs: []
  type: TYPE_NORMAL
- en: '[orcid=0009-0008-8740-4994, email=yufeng.li@qmul.ac.uk ] \cormark[1] \fnmark[1]'
  prefs: []
  type: TYPE_NORMAL
- en: '[orcid=0000-0002-1403-2236, email=r.panchendrarajan@qmul.ac.uk ] \cormark[1]
    \fnmark[1]'
  prefs: []
  type: TYPE_NORMAL
- en: '[orcid=0000-0003-4583-3623, email=a.zubiaga@qmul.ac.uk, url=www.zubiaga.org,
    ]'
  prefs: []
  type: TYPE_NORMAL
- en: \cortext
  prefs: []
  type: TYPE_NORMAL
- en: '[1]Corresponding author. \fntext[1]These authors contributed equally.'
  prefs: []
  type: TYPE_NORMAL
- en: Yufeng Li School of Electronic Engineering and Computer Science, Queen Mary
    University of London    Rrubaa Panchendrarajan    Arkaitz Zubiaga(2024)
  prefs: []
  type: TYPE_NORMAL
- en: Notebook for the CheckThat! Lab at CLEF 2024
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yufeng Li School of Electronic Engineering and Computer Science, Queen Mary
    University of London    Rrubaa Panchendrarajan    Arkaitz Zubiaga(2024)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The rapid dissemination of information through social media and the Internet
    has posed a significant challenge for fact-checking, among others in identifying
    check-worthy claims that fact-checkers should pay attention to, i.e. filtering
    claims needing fact-checking from a large pool of sentences. This challenge has
    stressed the need to focus on determining the priority of claims, specifically
    which claims are worth to be fact-checked. Despite advancements in this area in
    recent years, the application of large language models (LLMs), such as GPT, has
    only recently drawn attention in studies. However, many open-source LLMs remain
    underexplored. Therefore, this study investigates the application of eight prominent
    open-source LLMs with fine-tuning and prompt engineering to identify check-worthy
    statements from political transcriptions. Further, we propose a two-step data
    pruning approach to automatically identify high-quality training data instances
    for effective learning. The efficiency of our approach is demonstrated through
    evaluations on the English language dataset as part of the check-worthiness estimation
    task of CheckThat! 2024\. Further, the experiments conducted with data pruning
    demonstrate that competitive performance can be achieved with only about 44% of
    the training data. Our team ranked first in the check-worthiness estimation task
    in the English language.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Check-worthiness \sepClaim detection \sepFact-checking \sepLanguage Models \sepLLM
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the significant development of the Internet and social media over the past
    decades, the practical challenges associated with fact-checking have become more
    complex [[1](#bib.bib1), [2](#bib.bib2)]. Social media platforms have facilitated
    the rapid dissemination of information, which increases the difficulty of distinguishing
    misinformation from accurate information [[3](#bib.bib3)]. Concurrently, the general
    agreement on what should be fact-checked has expanded to include online content
    and claims made by politicians, resulting in a wide range of claims to be verified.
    As the initial step in the fact-checking process, claim detection plays a crucial
    role in efficiently identifying check-worthy claims, allowing for quicker progression
    to subsequent stages of verification [[4](#bib.bib4)]. Therefore, research on
    check-worthy claim detection is essential for advancing the field of fact-checking,
    where the CheckThat! shared task has played a significant role in recent years
    [[5](#bib.bib5)].
  prefs: []
  type: TYPE_NORMAL
- en: Since the beginning of the CheckThat! competition, traditional machine learning
    models and neural network models have been commonly employed for the task of claim
    check-worthiness detection. At CheckThat! 2018, the top submission was achieved
    by a team using Support Vector Machines and Multilayer Perceptrons [[6](#bib.bib6)],
    while the highest scores at CheckThat! 2019 were obtained using Long Short-Term
    Memory (LSTM) networks [[7](#bib.bib7)]. Although BERT [[8](#bib.bib8)] was introduced
    in 2018, the exploration of this transformer-based model for claim check-worthiness
    detection began only in 2020\. In that year, the team utilizing RoBERTa secured
    the first position in the English category [[9](#bib.bib9)].
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the application of machine learning models, various techniques have been
    explored throughout the CheckThat! competition. Feature representation methods,
    including word embeddings, Bag of Words, Named Entity Recognition, and Part of
    Speech tagging [[6](#bib.bib6), [7](#bib.bib7), [9](#bib.bib9)] have been widely
    used to enhance model understanding of the task. More sophisticated representation
    techniques, such as LIWC [[10](#bib.bib10)] and ELMo [[11](#bib.bib11)], have
    also been investigated. Additionally, statistics related to word usage, such as
    subjectivity and sentiment, have been incorporated. To address the challenge of
    imbalanced datasets, data augmentation strategies have been explored, with common
    methods including machine translation and sampling [[4](#bib.bib4)].
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) have seen remarkable advancements in recent years,
    with GPT [[12](#bib.bib12)] models predominantly utilized as the latest and most
    effective solution in CheckThat! competitions. Several teams have shown competitive
    and winning performance of the model in various CheckThat! tasks, including check-worthiness
    estimation in multiple languages [[13](#bib.bib13), [14](#bib.bib14)]. Although
    GPT models have demonstrated competitive performance in CheckThat! tasks, their
    fine-tuning and inference entail associated costs. Simultaneously, numerous open-source
    LLMs have also demonstrated substantial advancements showing equivalent performance
    to GPT models. This enables the global community of researchers to benefit by
    transferring the knowledge of these powerful models cost-effectively by fine-tuning
    them on various downstream tasks. While fine-tuned BERT-based and GPT models have
    been extensively and routinely examined in the domain of check-worthiness estimation
    [[4](#bib.bib4)], open-source LLMs, as emerging language models, have not yet
    been thoroughly investigated within this specific field. Therefore, this study
    aims to explore a wide range of open-source LLMs while leveraging their capabilities
    through prompt engineering for check-worthiness estimation.
  prefs: []
  type: TYPE_NORMAL
- en: This paper presents the experiments conducted for CheckThat! 2024 task 1 [[15](#bib.bib15),
    [16](#bib.bib16)], check-worthiness estimation in the English language. The task
    involves identifying check-worthy statements from political transcriptions. Drawing
    inspiration from the impressive performance of LLMs in the recent CheckThat! competitions,
    we explore eight popular open-source LLMs, specifically Llama2-7b, Llama2-13b
    [[17](#bib.bib17)], Llama3-8b, Mistral [[18](#bib.bib18)], Mixtral [[19](#bib.bib19)],
    Phi3-Mini-4K [[20](#bib.bib20)], Falcon [[21](#bib.bib21)], and Gemma-7b [[22](#bib.bib22)]
    with prompt engineering for identifying check-worthy statements. Considering the
    noisy and imbalanced nature of the training data, we propose a two-step data pruning
    process to isolate high-quality training data instances for effective learning
    with LLMs. Especially, we identify the informative sentences first and apply an
    under-sampling technique, Condensed Nearest Neighbour [[23](#bib.bib23)], to create
    a balanced training dataset. Our fine-tuned Llama2-7b [[17](#bib.bib17)] model
    on the original training data shared by the task organizers scored the highest
    F1-score in the task 1 leaderboard in the English language. However, the experimental
    results indicate that similar or better performance can be achieved with data
    pruning techniques while retaining only about 44% of high-quality data instances
    from the original training data. Furthermore, this approach resulted in a reduction
    in fine-tuning time by a similar proportion, which could significantly lower the
    resource demands for fine-tuning larger models. All relevant source code and data
    are available on GitHub,¹¹1[https://github.com/isyufeng/FactFinders](https://github.com/isyufeng/FactFinders)
    and the fine-tuned model can be accessed on Huggingface.²²2[https://huggingface.co/Rrubaa/factFinders-checkworthy-estimation](https://huggingface.co/Rrubaa/factFinders-checkworthy-estimation)
  prefs: []
  type: TYPE_NORMAL
- en: 'The remainder of the paper is structured as follows. Section [2](#S2 "2 Methodology
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning") presents the methodology with the introduction to
    the LLMs experimented, prompts used and the data pruning techniques proposed.
    Section [3](#S3 "3 Results ‣ FactFinders at CheckThat! 2024: Refining Check-worthy
    Statement Detection with LLMs through Data Pruning") discusses the experiment
    results, followed by section [4](#S4 "4 Conclusion ‣ FactFinders at CheckThat!
    2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning")
    concluding the key findings and future directions.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our goal was to automatically refine the training data to obtain high-quality
    training data instances and fine-tune open-source Large Language Models (LLMs)
    to identify check-worthy statements from political transcriptions. This section
    introduces the dataset, LLMs used in the experiments, prompt engineering carried
    out, fine-tuning process, and the two-step data pruning we applied to the training
    data for effective learning.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The dataset provided by CheckThat! 2024 comprises the train, dev, and dev-test
    partitions, containing 23,849 sentences from political transcriptions, along with
    a later release of test partition, bringing the total to 24,163 sentences. Table
    LABEL:tab:data_statisitcs presents the statistics for each partition. From this
    table, it is evident that the dataset is imbalanced, posing a challenge for the
    check-worthy statement detection task. Furthermore, Figure [1](#S2.F1 "Figure
    1 ‣ 2.1 Dataset ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024: Refining Check-worthy
    Statement Detection with LLMs through Data Pruning") illustrates the distribution
    of text lengths across each partition, revealing that the median length of the
    sentences is approximately 10-14 words in each partition, with 28%-42% of sentences
    containing fewer than 10 words. This indicates that the dataset not only suffers
    from class imbalance but also contains predominantly short sentences, hence implying
    a limited amount of information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Statistics of the Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '| Partition | Check-worthy | Non-check-worthy | Total |'
  prefs: []
  type: TYPE_TB
- en: '| Train | 5,413 | 17,086 | 22,499 |'
  prefs: []
  type: TYPE_TB
- en: '| Dev | 238 | 794 | 1,032 |'
  prefs: []
  type: TYPE_TB
- en: '| Dev-Test | 108 | 210 | 318 |'
  prefs: []
  type: TYPE_TB
- en: '| Test | 88 | 253 | 341 |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/1c83f3ce09e8591fb1402e1af41108cb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Distribution of Text Length in each Partition'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 LLMs for Check-worthy Statement Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Open-source LLMs offer substantial advantages in terms of cost, transparency,
    community support, and ethical considerations. Consequently, we investigated eight
    prominent open-source LLMs, as detailed in Table LABEL:tab:model_info by fine-tuning
    them for check-worthy statement detection.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Large Language Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Llama2-7b, Llama2-13b [[17](#bib.bib17)], and Llama3-8b are part of the Llama
    family, developed by Meta, and are available in various sizes. The most recent
    release, Llama3-8b, was made available in April 2024\. These models have been
    optimized for text generation and dialogue applications. Similarly, Mistral [[18](#bib.bib18)]
    and Mixtral [[19](#bib.bib19)] are both developed by Mistral AI. Mistral mainly
    focuses on optimizing transformer models for language tasks, achieving high efficiency
    and performance in a compact form. Mixtral, with its hybrid approach, aims to
    integrate the best of various AI methodologies, offering flexibility and scalability
    for complex applications. Compared to this bigger model, Phi3-Mini-4K [[20](#bib.bib20)]
    is a smaller variant of the Phi-3-mini, developed by Microsoft, designed to provide
    capabilities similar to its larger counterparts but with a reduced number of parameters,
    making it more accessible and easier to run on less powerful hardware. Similarly,
    Falcon [[21](#bib.bib21)], developed by TII, stands as one of the most powerful
    open-source models and consistently achieves top positions on the OpenLLM leaderboard
    hosted on Hugging Face. One of the latest models we experimented with, Gemma-7b
    [[22](#bib.bib22)] belongs to the Gemma family developed by Google DeepMind, which
    is designed to offer a balance between computational efficiency and advanced capabilities
    in generating text and understanding complex language queries. We fine-tuned these
    eight open-source LLMs published in Huggingface platforms (links listed in Table
    LABEL:tab:model_info) for check-worthy statement detection from political transcriptions.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 Prompt Engineering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Table 2: Open-Source LLMs Used.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Number of Parameters | Release Date |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-7b³³3[https://huggingface.co/meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)
    | 7 billion | July 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13b⁴⁴4[https://huggingface.co/meta-llama/Llama-2-13b-hf](https://huggingface.co/meta-llama/Llama-2-13b-hf)
    | 13 billion | July 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama3-8b⁵⁵5[https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
    | 8 billion | April 2024 |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral⁶⁶6[https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)
    | 7 billion | September 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral⁷⁷7[https://huggingface.co/mistralai/Mixtral-8x7B-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)
    | 45 billion | December 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| Phi-3-Mini-4K⁸⁸8[https://huggingface.co/microsoft/Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)
    | 3.8 billion | April 2024 |'
  prefs: []
  type: TYPE_TB
- en: '| Falcon⁹⁹9[https://huggingface.co/tiiuae/falcon-7b](https://huggingface.co/tiiuae/falcon-7b)
    | 7 billion | March 2023 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-7b^(10)^(10)10[https://huggingface.co/google/gemma-7b](https://huggingface.co/google/gemma-7b)
    | 7 billion | February 2024 |'
  prefs: []
  type: TYPE_TB
- en: 'Given the critical role of prompts in the performance of LLMs, we initially
    came up with a simple yet direct prompt, as illustrated in Prompt [2](#prompt2
    "Prompt 2 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement
    Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024: Refining Check-worthy
    Statement Detection with LLMs through Data Pruning"). Observing that this initial
    prompt resulted in lengthy responses with redundant information in the zero-shot
    setting, and lacked a clear definition of check-worthiness, we employed ChatGPT-4
    to refine and improve the prompt, resulting in Prompt [1](#prompt1 "Prompt 1 ‣
    2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement Detection ‣
    2 Methodology ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement
    Detection with LLMs through Data Pruning"). All eight LLMs were fine-tuned using
    this refined prompt to generate ‘Yes’ or ‘No’ answers indicating the check-worthiness
    of the input statement. Furthermore, we observed that a significant proportion
    of sentences in the training data utilized pronouns to refer to political entities,
    thereby increasing uncertainties and ambiguities. Therefore, we experimented with
    an expanded version of Prompt [1](#prompt1 "Prompt 1 ‣ 2.2.3 Effective Fine-tuning
    ‣ 2.2 LLMs for Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders
    at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through
    Data Pruning") (i.e. Prompt [3](#prompt3 "Prompt 3 ‣ 2.2.3 Effective Fine-tuning
    ‣ 2.2 LLMs for Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders
    at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through
    Data Pruning")) to evaluate whether explicitly indicating that the pronouns in
    the input statement may refer to political entities could enhance the performance
    of the fine-tuned model. However, the initial experiments on prompt engineering
    revealed that neither the compressed prompt (Prompt [2](#prompt2 "Prompt 2 ‣ 2.2.3
    Effective Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement Detection ‣ 2 Methodology
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning")) nor the expanded (Prompt [3](#prompt3 "Prompt 3 ‣
    2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement Detection ‣
    2 Methodology ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement
    Detection with LLMs through Data Pruning")) improved the performance of fine-tuned
    models (refer to Table [6](#S3.T6 "Table 6 ‣ 3.5 Effect of Prompt Engineering
    ‣ 3 Results ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement
    Detection with LLMs through Data Pruning")).'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.3 Effective Fine-tuning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Fine-tuning an LLM is a challenging task due to the resource requirements,
    especially the memory demand. While this challenge can be escalated by training
    only certain layers of the LLM, still the computational requirement associated
    with gradient updates requires a lot of GPU memory. Therefore we use the Low-Rank
    Adaption technique (LoRA) for fine-tuning the LLMs. Instead of updating the weights
    directly, LoRA keeps track of the changes through low-rank perturbations requiring
    only minimal GPU memory. The LoRA configuration used for the fine-tuning is listed
    in Section [3.1](#S3.SS1 "3.1 Hyper-parameters and Environment Setting ‣ 3 Results
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning"). To ensure experimental control, consistent hyperparameters
    were applied across all eight LLMs (see Table [3](#S3.T3 "Table 3 ‣ 3.1 Hyper-parameters
    and Environment Setting ‣ 3 Results ‣ FactFinders at CheckThat! 2024: Refining
    Check-worthy Statement Detection with LLMs through Data Pruning")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The performance of each model on check-worthy statement detection is presented
    in Table [4](#S3.T4 "Table 4 ‣ 3.3 Comparison of LLMs ‣ 3 Results ‣ FactFinders
    at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through
    Data Pruning"). Unfortunately, we could only compare the performance of the Llama
    family, Mistral, and Mixtral models during the testing phase of the competition.
    Therefore, the Phi-3-Mini-4k, the best-performing model in the Dev-Test partition
    wasn’t considered for the remaining experiments. Considering the competitive performance
    of the Llama2-7b model and the time and memory required, the rest of the experiments
    were carried out by fine-tuning the Llama2-7b using Prompt [1](#prompt1 "Prompt
    1 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement Detection
    ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement
    Detection with LLMs through Data Pruning").'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Prompt 1 Check-worthy Statement Detection
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Prompt 2 Check-worthy Statement Detection - Compressed
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Prompt 3 Check-worthy Statement Detection - Expanded
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Data Pruning for Effective Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As previously mentioned, the training data is highly imbalanced, mostly containing
    shorter sentences with limited information. Recent studies [[14](#bib.bib14)]
    have demonstrated that instead of using the entire training data for fine-tuning,
    using only the high-quality labels improves the performance of check-worthy statement
    detection from political transcriptions. Inspired by this direction, we experimented
    with a two-step data pruning approach to automatically identify high-quality data
    instances for effective learning.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Step 1 - Identifying Informative Sentences
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We began with identifying informative sentences in the training data that could
    potentially convey meaningful information for the training. In other words, we
    intended to remove the noisy instances from the training data as the first step
    of the data-pruning process. We define a political statement as informative if
    it meets one of the following four criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Check-worthy status is "Yes": If the class label of the statement is "Yes",
    then it is informative.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Contains a named entity: If the statement contains a named entity, it is highly
    likely to discuss information related to that entity. Hence the statement is informative.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Contains an informative verb: If the statement contains an informative verb,
    it is highly likely to discuss an informative action. Hence the statement is informative.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lengthy enough: If the statement is lengthy enough, it is likely to convey
    meaningful information.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: While the first criteria check-worthy status is straightforward, the other criteria
    require extracting further information to determine the informative status of
    a sentence. We used the BERT model [[24](#bib.bib24)] fine-tuned^(11)^(11)11[https://huggingface.co/dslim/bert-base-NER](https://huggingface.co/dslim/bert-base-NER)
    for the Named Entity Recognition (NER) task to identify the presence of a named
    entity. The NER model identifies four types of named entities, person, organization,
    location, and miscellaneous from the input text. We noticed that only $37.8\%$
    of the training data mentions a person’s name. This indicates the prevalent use
    of pronouns to refer to the political entities in the transcriptions, which makes
    the task more challenging.
  prefs: []
  type: TYPE_NORMAL
- en: In order to identify informative verbs, we first extracted all the verbs presented
    in the training data using the Part-of-Speech tagger from NLTK library.^(12)^(12)12[https://www.nltk.org/api/nltk.tag.pos_tag.html](https://www.nltk.org/api/nltk.tag.pos_tag.html)
    Extracted verbs were lemmatized further to bring them to their base form. This
    resulted in 3838 verbs in the training data to be identified as informative or
    not. We wanted to automatically classify each verb as either informative or not
    based on whether it conveys any check-worthy action. However, performing this
    binary classification in a zero-shot setting using a language model is a challenging
    task as explicitly defining an informative verb in the prompt may result in ambiguous
    classification. Therefore, we performed a fine-grained categorization of the verbs
    into the following 10 categories.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Physical Actions: e.g. Run'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Mental Actions: e.g. Think'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Changes in State: e.g. Grow'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Creation or Destruction: e.g. Build'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Communication: e.g. Discuss'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Movement: e.g. Walk'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '7.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Emotion: e.g. Hope'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '8.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Perception: e.g. See'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '9.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Linking verbs : e.g. is, has'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '10.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'None: Any verb that does not fit into the other categories'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The first 8 categories were obtained by prompting ChatGPT with the question
    "What are the types of action verbs?". In addition to the 8 action verb categories,
    we added Linking verbs and None resulting in 10 categories of verbs. The option
    "None" was added to the categories to indicate that the verb does not fit into
    any of the other 9 categories.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Prompt 4 Verb Classification
  prefs: []
  type: TYPE_NORMAL
- en: 'We utilized Mixtral [[19](#bib.bib19)] in a zero-shot setting to classify a
    verb into one of the 10 categories using the Prompt [4](#prompt4 "Prompt 4 ‣ 2.3.1
    Step 1 - Identifying Informative Sentences ‣ 2.3 Data Pruning for Effective Learning
    ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement
    Detection with LLMs through Data Pruning"). Among the 10 categories, we chose
    the verb types Physical Actions, Changes in State, Creation or Destruction, Communication,
    and Movement as the informative verbs, as the other verb types are less likely
    to represent a check-worthy action.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fc173852a88c3dcec4fdac84ed55d273.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Word cloud indicating verb types and their frequencies in the training
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/749903196ad563874fb3142d688ffe0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Distribution of verb types in the training data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [2](#S2.F2 "Figure 2 ‣ 2.3.1 Step 1 - Identifying Informative Sentences
    ‣ 2.3 Data Pruning for Effective Learning ‣ 2 Methodology ‣ FactFinders at CheckThat!
    2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning")
    shows the word cloud of verbs present in the training data. Informative verbs
    are highlighted in green color and non-informative verbs are highlighted in red
    color in the Figure. It can be observed that most of the verbs are classified
    into the two groups correctly. Figure [3](#S2.F3 "Figure 3 ‣ 2.3.1 Step 1 - Identifying
    Informative Sentences ‣ 2.3 Data Pruning for Effective Learning ‣ 2 Methodology
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning") presents the verb type distribution in the training
    data. Interestingly the occurrences of informative verb categories are relatively
    high compared to non-informative verb categories. We further noticed that $88.2\%$
    for non-check-worthy statements.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The final factor determining an informative sentence, minimum length is difficult
    to define explicitly. Therefore, we choose the minimum length value that reaches
    the optimal F1-score in the dev-test data by varying the value from 3 - 10\. We
    excluded the stop words^(13)^(13)13[https://www.nltk.org/search.html?q=stopwords](https://www.nltk.org/search.html?q=stopwords)
    while calculating the length of a statement. We observed that the most informative
    sentences are obtained when the minimum length factor is set to 8 (refer to Section
    [3.6](#S3.SS6 "3.6 Effect of Data Pruning ‣ 3 Results ‣ FactFinders at CheckThat!
    2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning")
    for the results). With this optimal setting, the first step of data pruning resulted
    in a reduced training data with 20,141 sentences. In other words, 2358 sentences
    ($10.5\%$ of original training data) were filtered out as non-informative sentences
    at this stage of the data pruning process.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Step 2 - Under Sampling using Condensed Nearest Neighbour
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The informative sentences identified in the previous stage are still imbalanced
    in class. Therefore, we executed an under-sampling technique, Condensed Nearest
    Neighbour (CNN) [[23](#bib.bib23)], to generate class-balanced training data.
    We retained all the minority data instances (check-worthy statements) and sampled
    only the majority data instances (non-check-worthy statements). The idea behind
    CNN sampling is to identify a subset of data instances that can be used to correctly
    classify all the other unsampled data instances using the 1-Nearest Neighbour
    rule. This makes sure that the sampled data distribution is the same as the original
    data distribution without any information loss.
  prefs: []
  type: TYPE_NORMAL
- en: CNN requires the input data to be represented as vectors to iteratively sample
    data points from a vector space and perform the 1-Nearest Neighbour classification
    in the unsampled data points. We used BERT [[24](#bib.bib24)] embeddings to convert
    the sentences in the training data to a vector representation of length 768\.
    The imbalanced^(14)^(14)14[https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html)
    python library was used to perform CNN sampling. This resulted in a sampled data
    with 9907 sentences ($44\%$ negative instances.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/53065ee00f27c6069a8ac3d0a867e74e.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Original training data (before applying step 1 & 2)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7e5c64dda33ce9e49ae716b8e99a07fd.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Original training data with uninformative sentences (filtered during step
    1) highlighted
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e658b321762497fc9e19b6f29f3a05c0.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) High-quality training data obtained after data pruning (after step 1 & 2)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: 2D visualization of the Training Data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [4](#S2.F4 "Figure 4 ‣ 2.3.2 Step 2 - Under Sampling using Condensed
    Nearest Neighbour ‣ 2.3 Data Pruning for Effective Learning ‣ 2 Methodology ‣
    FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning") visualizes the training data points in 2 dimensions
    at each stage of the data pruning process. It can be observed that uninformative
    data points filtered during step 1 (Figure [4(b)](#S2.F4.sf2 "In Figure 4 ‣ 2.3.2
    Step 2 - Under Sampling using Condensed Nearest Neighbour ‣ 2.3 Data Pruning for
    Effective Learning ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024: Refining
    Check-worthy Statement Detection with LLMs through Data Pruning")) are concentrated
    around the bottom-left corner of the plot. Further, the CNN samples a similar
    distribution of non-check-worthy data points (Figure [4(c)](#S2.F4.sf3 "In Figure
    4 ‣ 2.3.2 Step 2 - Under Sampling using Condensed Nearest Neighbour ‣ 2.3 Data
    Pruning for Effective Learning ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning")) for
    obtaining balanced training data.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discuss the experiment results in this section, especially the hyper-parameters
    used to fine-tune the LLMs, the environment setting used, the performance of various
    LLMs with the consistency analysis, effect of prompt engineering, and the impact
    of training data pruning on check-worthy statement detection task.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Hyper-parameters and Environment Setting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 3: Hyper-parameters used for Fine-tuning.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Parameter | Value |'
  prefs: []
  type: TYPE_TB
- en: '| Epochs | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Training batch size | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Gradient accumulation steps | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Optimizer | Paged AdamW 32bit |'
  prefs: []
  type: TYPE_TB
- en: '| Learning rate | 2e-4 |'
  prefs: []
  type: TYPE_TB
- en: '| Weight decay | 0.001 |'
  prefs: []
  type: TYPE_TB
- en: '| Maximum gradient norm | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Warmup ratio | 0.03 |'
  prefs: []
  type: TYPE_TB
- en: '| Temperature | 0.03 |'
  prefs: []
  type: TYPE_TB
- en: '| Lora Alpha | 16 |'
  prefs: []
  type: TYPE_TB
- en: '| Lora dropout | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Lora rank | 64 |'
  prefs: []
  type: TYPE_TB
- en: 'Hyper-parameters used to fine-tune the LLMs in our experiments are listed in
    Table [3](#S3.T3 "Table 3 ‣ 3.1 Hyper-parameters and Environment Setting ‣ 3 Results
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning"). Most of the hyper-parameters were the same for all
    the LLMs we experimented with, except the training batch size which was reduced
    to 1 for Mixtral, due to its memory demand. Consequently, the gradient accumulation
    steps for this model was increased to 4\. All the experiments were conducted using
    Queen Mary’s Apocrita HPC facility, supported by QMUL Research-IT [[25](#bib.bib25)].
    Specifically, 1 GPU (Volta V100 or Ampere A100) with 8 CPU cores, each composed
    of 11 GB memory was used to train and test all the models.'
  prefs: []
  type: TYPE_NORMAL
- en: While generating the predictions by the fine-tuned models for evaluation, we
    noticed that a language model may generate different predictions for the same
    prompt and input sentence. Therefore, we ran each fine-tuned language model 5
    times and obtained the majority prediction as the final prediction of the model.
    Further, we fine-tuned each model 3 times and reported the average performance
    of 3 fine-tuned models. We use the partitions train and dev for training and validation
    of the models, and the performance of the models is reported on the other two
    partitions dev-test and test.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Evaluation Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The official evaluation metric for CheckThat! 2024 task 1, check-worthiness
    estimation is F1-Score over the positive class. However, since one metric could
    have a bias toward the comparison, we report average accuracy, precision, and
    recall along with the F1-score. Further, we computed consistency@K of the fine-tuned
    models indicating the fraction of data instances for which the model generated
    the same output class in all K iterations. Consistency score report in the following
    subsections was computed over 5 iterations (consistency@5).
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Comparison of LLMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 4: Performance of LLMs on the Test and Dev-Test Partitions.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Partition | Model | Accuracy | Precision | Recall | F1-Score | Consistency
    |'
  prefs: []
  type: TYPE_TB
- en: '| Test | Llama2-7b | 0.905 $\pm$ 0.013 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13b | 0.897 $\pm$ 0.005 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama3-8b | 0.907 $\pm$ 0.002 |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral | 0.889 $\pm$ 0.01 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral | 0.891 $\pm$ 0.011 |'
  prefs: []
  type: TYPE_TB
- en: '| Phi3-Mini-4K | 0.897 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Falcon | 0.891 $\pm$ 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-7b | 0.9 $\pm$ 0.01 |'
  prefs: []
  type: TYPE_TB
- en: '| Dev-Test | Llama2-7b | 0.944 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13b | 0.941 $\pm$ 0.009 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama3-8b | 0.921 $\pm$ 0.002 |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral | 0.932 $\pm$ 0.001 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral | 0.939 $\pm$ 0.007 |'
  prefs: []
  type: TYPE_TB
- en: '| Phi3-Mini-4K | 0.955 $\pm$ 0.007 |'
  prefs: []
  type: TYPE_TB
- en: '| Falcon | 0.931 $\pm$ 0 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Gemma-7b | 0.942 $\pm$ 0.024 |'
  prefs: []
  type: TYPE_TB
- en: 'We compare the performance of the eight open-source LLMs in test and dev-test
    partitions and Table [4](#S3.T4 "Table 4 ‣ 3.3 Comparison of LLMs ‣ 3 Results
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning") reports their average accuracy, precision, recall,
    F1-score, and consistency@5\. Since the class distribution of dev-test and test
    partitions are different, we can observe that the performance in each partition
    varies for all the LLMs. While Phi3-Mini-4K obtains the highest F1-score in the
    dev-test portion, Llama2 models stand out as the best-performing models in the
    test partition based on F1-score. Further, both Llama2-7b and Phi3-Mini-4K demonstrate
    greater consistency in predicting class labels across both partitions compared
    to other models. On the other hand, Llama3-8b, one of the latest models from the
    Llama family reaches the highest accuracy and precision in the test partition.
    However, the model fails to outperform the other models in terms of F1-score due
    to poor recall. Similarly, Mixtral, the largest model we compared, fails to give
    a consistent performance across both partitions. Moreover, both Mistral and Falcon
    remain as the lower-performing models in both partitions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: Average Fine-tuning Time of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Average Fine-tuning Time |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-7b | 6.3h |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13b | 11.9h |'
  prefs: []
  type: TYPE_TB
- en: '| Llama3-8b | 6.7h |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral | 6.82h |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral | 33.86h |'
  prefs: []
  type: TYPE_TB
- en: '| Phi3-Mini-4K | 4h |'
  prefs: []
  type: TYPE_TB
- en: '| Falcon | 6.26h |'
  prefs: []
  type: TYPE_TB
- en: 'Table [5](#S3.T5 "Table 5 ‣ 3.3 Comparison of LLMs ‣ 3 Results ‣ FactFinders
    at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through
    Data Pruning") lists the fine-tuning time of each LLM. Except for Mixtral and
    Phi3-Mini-4K, the largest and smallest models compared respectively, all the other
    models’ fine-tuning time remains between 6-12 hours. As expected, the fine-tuning
    time increases with the number of parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: As we already mentioned, we were able to compare only the Llama models, Mistral,
    and Mixtral during the testing phase of the competition. Therefore, considering
    the performance of these models in terms of F1-score in the dev-test partition
    and the time and memory required to fine-tune the model, we chose Llama2-7b as
    the optimal LLM for the remaining experiments.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Consistency Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since LLMs are text generation models, they tend to generate different output
    for the same input text even in a fine-tuned environment. Therefore, we analyze
    their consistency in predicting the same output class label over K iterations
    with the metric consistency@K. Figure [5](#S3.F5 "Figure 5 ‣ 3.4 Consistency Analysis
    ‣ 3 Results ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement
    Detection with LLMs through Data Pruning") presents the change in consistency
    with the number of iterations varied from 2 to 25 in the test and dev-test partition.
    It can be observed that the consistency declines with the increase in the number
    of iterations and becomes stable after around 11-12 iterations. While the model
    could reach a stable consistency in both partitions, the percentage of drop in
    consistency (difference between initial consistency when K=2, and the stable consistency)
    is nearly double for the test partition (3.1% vs 5.9%).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/83b5d5f7f9d6a41b979625eec50a4b03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Consistency of Llama2-7b with Iterations'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Effect of Prompt Engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 6: Performance of Llama2-7b with Prompt Variation.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Partition | Prompt | Accuracy | Precision | Recall | F1-Score | Consistency
    |'
  prefs: []
  type: TYPE_TB
- en: '| Test | Prompt [1](#prompt1 "Prompt 1 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2
    LLMs for Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat!
    2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning")
    | 0.905 $\pm$ 0.013 |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt [2](#prompt2 "Prompt 2 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for
    Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning") | 0.906
    $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt [3](#prompt3 "Prompt 3 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for
    Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning") | 0.902
    $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| No Instruction | 0.894 $\pm$ 0.018 |'
  prefs: []
  type: TYPE_TB
- en: '| Dev-Test | Prompt [1](#prompt1 "Prompt 1 ‣ 2.2.3 Effective Fine-tuning ‣
    2.2 LLMs for Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at
    CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data
    Pruning") | 0.944 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt [2](#prompt2 "Prompt 2 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for
    Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning") | 0.927
    $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt [3](#prompt3 "Prompt 3 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for
    Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning") | 0.936
    $\pm$ 0.005 |'
  prefs: []
  type: TYPE_TB
- en: '| No Instruction | 0.927 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: 'We conducted experiments using three proposed versions of prompts discussed
    in Section [2.2.2](#S2.SS2.SSS2 "2.2.2 Prompt Engineering ‣ 2.2 LLMs for Check-worthy
    Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024: Refining
    Check-worthy Statement Detection with LLMs through Data Pruning") along with a
    prompt without any instruction to analyze the impact of prompt engineering on
    Llama2-7b model performance. Table [6](#S3.T6 "Table 6 ‣ 3.5 Effect of Prompt
    Engineering ‣ 3 Results ‣ FactFinders at CheckThat! 2024: Refining Check-worthy
    Statement Detection with LLMs through Data Pruning") presents the evaluation results
    on the test and dev-test partitions. While all three prompts proposed reach a
    similar F1-score in the test partition, their impact is quite evident in the dev-test
    partition. We can observe that Prompt [1](#prompt1 "Prompt 1 ‣ 2.2.3 Effective
    Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement Detection ‣ 2 Methodology ‣
    FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning") achieves the best overall scores across all metrics.
    It is worth noting, that the expanded prompt Prompt [3](#prompt3 "Prompt 3 ‣ 2.2.3
    Effective Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement Detection ‣ 2 Methodology
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning"), shows a notably high recall score and consistency
    in the test partition possibly due to the attention given to the pronouns in the
    instruction. Moreover, a substantial performance decline is observed when no instructions
    are included in the prompt highlights the importance of prompt engineering in
    achieving optimal results from LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Average fine-tuning time vs Instruction length in the Prompts.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Prompt | Average Fine-tuning Time | Instruction Length (Number of Words)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt [1](#prompt1 "Prompt 1 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for
    Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning") | 6.3h
    | 60 |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt [2](#prompt2 "Prompt 2 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for
    Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning") | 4.3h
    | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Prompt [3](#prompt3 "Prompt 3 ‣ 2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for
    Check-worthy Statement Detection ‣ 2 Methodology ‣ FactFinders at CheckThat! 2024:
    Refining Check-worthy Statement Detection with LLMs through Data Pruning") | 7.1h
    | 72 |'
  prefs: []
  type: TYPE_TB
- en: '| No Instruction | 3.1h | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'In addition to performance metrics, Table [7](#S3.T7 "Table 7 ‣ 3.5 Effect
    of Prompt Engineering ‣ 3 Results ‣ FactFinders at CheckThat! 2024: Refining Check-worthy
    Statement Detection with LLMs through Data Pruning") indicates that the fine-tuning
    time increases with the length of the instruction. According to the competition’s
    settings, we primarily consider the F1-score performance of each prompt in the
    dev-test partition. Consequently, we selected Prompt [1](#prompt1 "Prompt 1 ‣
    2.2.3 Effective Fine-tuning ‣ 2.2 LLMs for Check-worthy Statement Detection ‣
    2 Methodology ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement
    Detection with LLMs through Data Pruning") as the optimal one for the remaining
    experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Effect of Data Pruning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7efcdef2cf8d2355900400cf4bf0c80a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Average F1-score in Dev-Test partition with the change in minimum
    length factor used for data pruning'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we discussed earlier, we leave the minimum length factor as a parameter
    of the data pruning process. Therefore we varied the minimum length from 3-10
    and observed the performance of the Llama2-7b model fine-tuned on the pruned dataset.
    Figure [6](#S3.F6 "Figure 6 ‣ 3.6 Effect of Data Pruning ‣ 3 Results ‣ FactFinders
    at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through
    Data Pruning") shows the F1-score of the fine-tuned model in the dev-test partition.
    It can be observed that Step 1 alone is not sufficient enough to identify high-quality
    training data, and Step 2 always boosts the performance when combined with Step
    1 except when the minimum length factor is set to very low (3-4). The optimal
    performance for the two-step data pruning is obtained when the minimum length
    factor is set to 8.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: Performance of Llama2-7b with Data Pruning.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Partition |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Pruning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Technique &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Accuracy | Precision | Recall | F1-Score | Consistency |'
  prefs: []
  type: TYPE_TB
- en: '| Test | None | 0.905 $\pm$ 0.013 |'
  prefs: []
  type: TYPE_TB
- en: '| Step 1 only | 0.886 $\pm$ 0.004 |'
  prefs: []
  type: TYPE_TB
- en: '| Step 2 only | 0.907 $\pm$ 0.005 |'
  prefs: []
  type: TYPE_TB
- en: '| Step 1 & 2 | 0.891 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Dev-Test | None | 0.944 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Step 1 only | 0.929 $\pm$ 0.012 |'
  prefs: []
  type: TYPE_TB
- en: '| Step 2 only | 0.953 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Step 1 & 2 | 0.95 $\pm$ 0.003 |'
  prefs: []
  type: TYPE_TB
- en: 'Table [8](#S3.T8 "Table 8 ‣ 3.6 Effect of Data Pruning ‣ 3 Results ‣ FactFinders
    at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through
    Data Pruning") presents the performance of Llama2-7b on the original and pruned
    training data. It can be observed that the model trained using only the step 2
    data pruning approach yields the highest F1-score and accuracy in the dev-test
    partition and its performance in the test partition is close to the model trained
    without any data pruned. While the two-step data pruning approach reaches a slightly
    lower F1 score in the test partition, it stands out as the high recall model in
    both partitions. Further, it is worth noting that this model resulted in a better
    precision-recall trade-off in the dev-test partition compared to the models trained
    with individual pruning steps (step 1 only and step 2 only). Moreover, the consistency
    of the models in predicting the same output class ranged from 0.9-0.95, while
    the lower range is always observed in the dev-test partition. During the testing
    phase of the completion, we could not compare the average performance of the models
    due to time limitations. Therefore, we submitted the class labels predicted by
    the Llama2-7b model fine-tuned without the data pruning process for the CheckThat!
    2024 task1 leader board, as it yielded a slightly higher F1-score compared to
    other approaches. This submission was ranked 1st place in the leaderboard with
    the highest F1-score of 0.802\. While this score is lower than the average F1-score
    reported in Table [8](#S3.T8 "Table 8 ‣ 3.6 Effect of Data Pruning ‣ 3 Results
    ‣ FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with
    LLMs through Data Pruning"), the standard deviation indicates that the model performance
    could vary from 0.801 to 0.839.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9: Training Data Size and Average Fine-tuning Time with Data Pruning.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Pruning Technique | Training data size |'
  prefs: []
  type: TYPE_TB
- en: '&#124; % of data retained &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; during pruning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Average Fine-tuning Time |'
  prefs: []
  type: TYPE_TB
- en: '| None | 22,499 | 100% | 6.3h |'
  prefs: []
  type: TYPE_TB
- en: '| Step 1 only | 20,141 | 89% | 5.7h |'
  prefs: []
  type: TYPE_TB
- en: '| Step 2 only | 10,227 | 45.5% | 3h |'
  prefs: []
  type: TYPE_TB
- en: '| Step 1 & 2 | 9,907 | 44% | 2.9h |'
  prefs: []
  type: TYPE_TB
- en: 'Table [9](#S3.T9 "Table 9 ‣ 3.6 Effect of Data Pruning ‣ 3 Results ‣ FactFinders
    at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through
    Data Pruning") reports the training data size and their corresponding average
    fine-tuning time. This demonstrates that using data pruning strategies allows
    competitive performance on both test and dev-test data while utilizing only about
    44%-44.5% of the original training data. Further, the fine-tuning time is reduced
    in a similar proportion, cutting the training time by more than half compared
    to using the original training data. This indicates that obtaining high-quality
    training data is crucial for developing effective check-worthy statement detection
    models from political transcriptions.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper demonstrates the experiments conducted by the FactFinders team for
    CheckThat! 2024 task 1, check-worthiness estimation in English. We experimented
    with eight open-source LLMs with fine-tuning and prompt engineering to identify
    check-worthy statement detection from political transcriptions. Results using
    our Llama2-7b model fine-tuned on the training data secured the 1st position in
    the leaderboard among a total of 26 participants, with F1-scores surpassing the
    baseline for the task. This demonstrates that open-source models are powerful
    in check-worthy statement detection in the English language. Further, we demonstrated
    the role of data pruning in identifying high-quality training data for effective
    learning. Our results show that competitive or better performance can be obtained
    by utilizing only about 44% of training data by saving the fine-tuning time in
    a similar proportion. Apart from the fine-tuned LLMs for check-worthy statement
    detection, we utilized LLMs for refining prompts and identifying informative verbs
    in zero-shot setting.
  prefs: []
  type: TYPE_NORMAL
- en: The key challenges we faced while utilizing LLMs for check-worthy statement
    detection were the memory requirements and their inconsistent response in predicting
    the class label for the same input statement. We used the Low-Rank Adaption technique
    (LoRA) for effective fine-tuning with low GPU memory usage to conquer the memory
    requirements. While we tried to overcome the consistency issue by running the
    fine-tuned models 5 times and obtaining the majority prediction, our consistency
    analysis reveals that the consistency score itself is unstable during early iterations,
    and may have a drop of around 6% while reaching stability. This behavior of LLMs
    highly questions their adaptation for classification tasks in general as inconsistent
    responses may result in less reproducible results.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rrubaa Panchendrarajan is funded by the European Union and UK Research and Innovation
    under Grant No. 101073351 as part of Marie Skłodowska-Curie Actions (MSCA Hybrid
    Intelligence to monitor, promote, and analyze transformations in good democracy
    practices). Yufeng Li is funded by China Scholarship Council (CSC).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Zeng et al. [2021] X. Zeng, A. S. Abumansour, A. Zubiaga, Automated fact-checking:
    A survey, Language and Linguistics Compass 15 (2021) e12438.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. [2022] Z. Guo, M. Schlichtkrull, A. Vlachos, A survey on automated
    fact-checking, Transactions of the Association for Computational Linguistics 10
    (2022) 178–206.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allcott et al. [2019] H. Allcott, M. Gentzkow, C. Yu, Trends in the diffusion
    of misinformation on social media, Research & Politics 6 (2019) 2053168019848554.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Panchendrarajan and Zubiaga [2024] R. Panchendrarajan, A. Zubiaga, Claim detection
    for automated fact-checking: A survey on monolingual, multilingual and cross-lingual
    research, Natural Language Processing Journal 7 (2024) 100066.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nakov et al. [2018] P. Nakov, A. Barrón-Cedeno, T. Elsayed, R. Suwaileh, L. Màrquez,
    W. Zaghouani, P. Atanasova, S. Kyuchukov, G. Da San Martino, Overview of the clef-2018
    checkthat! lab on automatic identification and verification of political claims,
    in: Experimental IR Meets Multilinguality, Multimodality, and Interaction: 9th
    International Conference of the CLEF Association, CLEF 2018, Avignon, France,
    September 10-14, 2018, Proceedings 9, Springer, 2018, pp. 372–387.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Atanasova et al. [2018] P. Atanasova, A. Barron-Cedeno, T. Elsayed, R. Suwaileh,
    W. Zaghouani, S. Kyuchukov, G. D. S. Martino, P. Nakov, Overview of the clef-2018
    checkthat! lab on automatic identification and verification of political claims.
    task 1: Check-worthiness, arXiv preprint arXiv:1808.05542 (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Atanasova et al. [2019] P. Atanasova, P. Nakov, G. Karadzhov, M. Mohtarami,
    G. Da San Martino, Overview of the clef-2019 checkthat! lab: Automatic identification
    and verification of claims. task 1: Check-worthiness. (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. [2017] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,
    A. N. Gomez, Ł. Kaiser, I. Polosukhin, Attention is all you need, Advances in
    neural information processing systems 30 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shaar et al. [2020] S. Shaar, A. Nikolov, N. Babulkov, F. Alam, A. Barrón-Cedeno,
    T. Elsayed, M. Hasanain, R. Suwaileh, F. Haouari, G. Da San Martino, et al., Overview
    of checkthat! 2020 english: Automatic identification and verification of claims
    in social media., CLEF (working notes) 2696 (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shaar et al. [2021] S. Shaar, M. Hasanain, B. Hamdan, Z. S. Ali, F. Haouari,
    A. Nikolov, M. Kutlu, Y. S. Kartal, F. Alam, G. Da San Martino, et al., Overview
    of the clef-2021 checkthat! lab task 1 on check-worthiness estimation in tweets
    and political debates., in: CLEF (working notes), 2021, pp. 369–392.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nakov et al. [2022] P. Nakov, A. Barrón-Cedeño, G. Da San Martino, F. Alam,
    R. Míguez, T. Caselli, M. Kutlu, W. Zaghouani, C. Li, S. Shaar, et al., Overview
    of the clef-2022 checkthat! lab task 1 on identifying relevant claims in tweets,
    in: 2022 Conference and Labs of the Evaluation Forum, CLEF 2022, CEUR Workshop
    Proceedings (CEUR-WS. org), 2022, pp. 368–392.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. [2020] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
    A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., Language models are few-shot
    learners, Advances in neural information processing systems 33 (2020) 1877–1901.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agresti et al. [2022] S. Agresti, S. A. Hashemian, M. J. Carman, Polimi-flatearthers
    at checkthat!-2022: Gpt-3 applied to claim detection., in: CLEF (Working Notes),
    2022, pp. 422–427.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sawiński et al. [2023] M. Sawiński, K. Węcel, E. P. Księżniak, M. Stróżyna,
    W. Lewoniewski, P. Stolarski, W. Abramowicz, Openfact at checkthat! 2023: head-to-head
    gpt vs. bert-a comparative study of transformers language models for the detection
    of check-worthy claims, Working Notes of CLEF (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Barrón-Cedeño et al. [2024] A. Barrón-Cedeño, F. Alam, J. M. Struß, P. Nakov,
    T. Chakraborty, T. Elsayed, P. Przybyła, T. Caselli, G. Da San Martino, F. Haouari,
    C. Li, J. Piskorski, F. Ruggeri, X. Song, R. Suwaileh, Overview of the CLEF-2024
    CheckThat! Lab: Check-worthiness, subjectivity, persuasion, roles, authorities
    and adversarial robustness, in: L. Goeuriot, P. Mulhem, G. Quénot, D. Schwab,
    L. Soulier, G. M. Di Nunzio, P. Galuščáková, A. García Seco de Herrera, G. Faggioli,
    N. Ferro (Eds.), Experimental IR Meets Multilinguality, Multimodality, and Interaction.
    Proceedings of the Fifteenth International Conference of the CLEF Association
    (CLEF 2024), 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hasanain et al. [2024] M. Hasanain, R. Suwaileh, S. Weering, C. Li, T. Caselli,
    W. Zaghouani, A. Barrón-Cedeño, P. Nakov, F. Alam, Overview of the CLEF-2024 CheckThat!
    lab task 1 on check-worthiness estimation of multigenre content, in: G. Faggioli,
    N. Ferro, P. Galuščáková, A. García Seco de Herrera (Eds.), Working Notes of CLEF
    2024 - Conference and Labs of the Evaluation Forum, CLEF 2024, Grenoble, France,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. [2023] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,
    Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al., Llama 2: Open
    foundation and fine-tuned chat models, arXiv preprint arXiv:2307.09288 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. [2023] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S.
    Chaplot, D. d. l. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al.,
    Mistral 7b, arXiv preprint arXiv:2310.06825 (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. [2024] A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary,
    C. Bamford, D. S. Chaplot, D. d. l. Casas, E. B. Hanna, F. Bressand, et al., Mixtral
    of experts, arXiv preprint arXiv:2401.04088 (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abdin et al. [2024] M. Abdin, S. A. Jacobs, A. A. Awan, J. Aneja, A. Awadallah,
    H. Awadalla, N. Bach, A. Bahree, A. Bakhtiari, H. Behl, et al., Phi-3 technical
    report: A highly capable language model locally on your phone, arXiv preprint
    arXiv:2404.14219 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Almazrouei et al. [2023] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cappelli,
    R. Cojocaru, M. Debbah, É. Goffinet, D. Hesslow, J. Launay, Q. Malartic, et al.,
    The falcon series of open language models, arXiv preprint arXiv:2311.16867 (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Team et al. [2024] G. Team, T. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju,
    S. Pathak, L. Sifre, M. Rivière, M. S. Kale, J. Love, et al., Gemma: Open models
    based on gemini research and technology, arXiv preprint arXiv:2403.08295 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hart [1968] P. Hart, The condensed nearest neighbor rule (corresp.), IEEE transactions
    on information theory 14 (1968) 515–516.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. [2018] J. Devlin, M. Chang, K. Lee, K. Toutanova, BERT: pre-training
    of deep bidirectional transformers for language understanding, CoRR abs/1810.04805
    (2018). URL: [http://arxiv.org/abs/1810.04805](http://arxiv.org/abs/1810.04805).
    [arXiv:1810.04805](http://arxiv.org/abs/1810.04805).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'King et al. [2017] T. King, S. Butcher, L. Zalewski, Apocrita - High Performance
    Computing Cluster for Queen Mary University of London, 2017\. URL: [https://doi.org/10.5281/zenodo.438045](https://doi.org/10.5281/zenodo.438045).
    doi:[10.5281/zenodo.438045](https:/doi.org/10.5281/zenodo.438045).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
