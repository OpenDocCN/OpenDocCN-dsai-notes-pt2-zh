- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:51:45'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.08682](https://ar5iv.labs.arxiv.org/html/2408.08682)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yuqi Ye¹, Wei Gao¹ Corresponding author. Under review.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The key to effective point cloud compression is to obtain a robust context model
    consistent with complex 3D data structures. Recently, the advancement of large
    language models (LLMs) has highlighted their capabilities not only as powerful
    generators for in-context learning and generation but also as effective compressors.
    These dual attributes of LLMs make them particularly well-suited to meet the demands
    of data compression. Therefore, this paper explores the potential of using LLM
    for compression tasks, focusing on lossless point cloud geometry compression (PCGC)
    experiments. However, applying LLM directly to PCGC tasks presents some significant
    challenges, i.e., LLM does not understand the structure of the point cloud well,
    and it is a difficult task to fill the gap between text and point cloud through
    text description, especially for large complicated and small shapeless point clouds.
    To address these problems, we introduce a novel architecture, namely the Large
    Language Model-based Point Cloud Geometry Compression (LLM-PCGC) method, using
    LLM to compress point cloud geometry information without any text description
    or aligning operation. By utilizing different adaptation techniques for cross-modality
    representation alignment and semantic consistency, including clustering, K-tree,
    token mapping invariance, and Low Rank Adaptation (LoRA), the proposed method
    can translate LLM to a compressor/generator for point cloud. To the best of our
    knowledge, this is the first structure to employ LLM as a compressor for point
    cloud data. Experiments demonstrate that the LLM-PCGC outperforms the other existing
    methods significantly, by achieving -40.213% bit rate reduction compared to the
    reference software of MPEG Geometry-based Point Cloud Compression (G-PCC) standard,
    and by achieving -2.267% bit rate reduction compared to the state-of-the-art learning-based
    method.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/12051a1a50a35ad5f025f369246daf56.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Comparison of training schemes between the proposed LLM-PCGC method
    and other learning-based methods for point cloud geometry compression. Different
    from existing methods adopting the end-to-end training manner, our method implements
    a point cloud compressor by fine-tuning a pre-trained text generator LLM to achieve
    efficient cross-modality representation alignment.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Point cloud is a critical and valuable data structure for autonomous driving
    and virtual reality. Recently, with the development of deep neural networks, more
    and more learning-based architectures for the lossless PCGC task (Que, Lu, and
    Xu [2021](#bib.bib14); Fu et al. [2022](#bib.bib5); Wang et al. [2022](#bib.bib18))
    are proposed, which have demonstrated remarkable performance in the task of lossless
    PCGC. For these methods, they can be divided into two main categories, i.e., voxel-based
    and tree-based. Whether voxel-based or tree-based methods, the key to compression
    performance is the establishment of a strong and robust context model. However,
    the context capabilities of previous methods remain significantly restricted due
    to the limitations in data volume and model size, as discussed in the scaling
    law for large language models (LLMs) (Kaplan et al. [2020](#bib.bib7)). This inspires
    us to directly replace the original context model with LLM, which has large-scale
    context and generation capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/acad5362d20c65234e272d92c1b6c661.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: LLM-PCGC encoding pipline. Given a 3D point cloud, the encoding pipeline
    starts with clustering, followed by normalization and K-Tree structuring. It then
    employs token mapping invariance for token conversion. Subsequently, a trained
    LoRA model with a frozen LLM is used to compute the probability distribution for
    the next token. These distribution are then fed into an arithmetic encoder, resulting
    in the generation of the encoded bitstream.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The emerging viewpoint illustrates that the essence of LLMs fundamentally lies
    in their ability to compress information (Delétang et al. [2024](#bib.bib3); Li
    et al. [2024](#bib.bib9); Valmeekam et al. [2023](#bib.bib17); Yu et al. [2024](#bib.bib23)).
    However, prior research works only generally discuss the compact feature representation
    in LLM from the perspective of compression, but ignore the potential of data compression
    with LLM. Although in (Delétang et al. [2024](#bib.bib3)), the discussion centers
    on the lossless compression capabilities of a text-only trained LLM across different
    modalities of 1D and 2D data, including text, image, and speech. Two limitations
    emerge from the analysis: 1) This work neglects the compression problem for 3D
    point clouds. Different from the simple 1D and 2D data, 3D structural data requires
    a more elaborated and powerful context model. Therefore, as a more complex data
    type, point cloud owns unique 3D structural characteristics, leading to new challenges
    for compression task. 2) The exploration of the LLM’s data compression capability
    is restricted to in-context learning, without any additional parameter training.
    This shows the inherent data compression potential of LLM model, while the performance
    improvement is still unknown after tailore training for the compression task.
    In this paper, we propose a completely new architecture, namely the Large Language
    Model-based Point Cloud Geometry Compression (LLM-PCGC) method, which can better
    adapt to the lossless PCGC compression task.'
  prefs: []
  type: TYPE_NORMAL
- en: Converting text-based LLM to LLM-PCGC is a cross-modal problem. Since LLM is
    a model based on text, the current multi-modal large language model (MM-LLM) in
    order to process multi-modal data, the unified approach is to map other modal
    tokens to the text space and then generate the modal data through text description
    (Yin et al. [2023](#bib.bib22); Hong et al. [2023](#bib.bib6); Xu et al. [2023](#bib.bib20)).
    On the one hand, for coding tasks, we do not really need text data, and there
    is no text data to pair with multimodality. On the other hand, we utilize LLMs
    for their potent generative and contextual understanding capabilities, yet for
    encoding tasks, the text-based features are extraneous. Hence, we seek to discard
    the text-specific aspects while maintaining the essential generative and contextual
    functions. Inspired by (Mirchandani et al. [2023](#bib.bib11)), we are the first
    to fine-tune the pre-trained LLM to achieve cross-modality via token mapping invariance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Through the above methods, we propose large language model-based point cloud
    geometry compression (LLM-PCGC). As shown in Fig. [1](#S0.F1 "Figure 1 ‣ LLM-PCGC:
    Large Language Model-based Point Cloud Geometry Compression"), a comparison is
    made with existing end-to-end deep learning training methods. Our approach, LLM-PCGC,
    fine-tunes a pre-trained text generator LLM with point cloud data, achieving cross-modality
    and serving as a point cloud compressor. In the encoding phase, the procedure
    begins with the clustering of the input 3D point clouds. Subsequently, each cluster
    is processed in parallel through a series of steps. First, the coordinates are
    normalized by subtracting an offset, and a K-tree structure is organized to systematize
    the point cloud data. Then, the hierarchical tree structure is flattened and divided
    into segments. Subsequently, a codebook is utilized to translate the point cloud
    tokens into text tokens to construct an analogous linguistic sentence. Finally,
    a trained LoRA architecture is employed with a frozen LLM to predict the probability
    distribution of the next token, which is integrated with an arithmetic encoder
    to complete the encoding process. The decoding phase mirrors the aforementioned
    steps in reverse order, thereby reconstructing the original point cloud geometry
    from the encoded data.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f8637fc4a4d1fff912886866571ddd3e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: LLM-PCGC decoding pipline. In decoding, binary bits are split, converted
    to decimals, and the main bitstream is processed in parallel. Through arithmetic
    decoder, bitstream is decoded by probabilities using LoRA and LLM, and then further
    mapped into point cloud patches. These patches are aligned and merged by offsets
    and indices. In the final decoding phase, big patches are structured into a K-Tree
    for clustered point cloud reconstruction. In the final post-reconstruction, offsets
    are applied to rebuild the original point cloud.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our contributions are summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We propose a novel architecture, namely LLM-PCGC, which is the first to apply
    LLM as a compressor to point cloud compression within the “Generator is compressor”
    framework. To the best of our knowledge, LLM-PCGC is also the first to transform
    LLM to a large model that can understand point cloud structure without any text
    information assistance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We propose utilize different adaptation techniques for cross-modality representation
    alignment and semantic consistency, including clustering, K-tree, token mapping
    invariance, and LoRA, the proposed method can translate LLM to a compressor/generator
    for point cloud. The approach of token mapping invariance can be transferred to
    other modalities, offering a new paradigm for multimodal and cross-modal applications
    of LLMs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experiments demonstrate that the LLM-PCGC outperforms the other existing methods
    significantly, by achieving -40.213% bit rate reduction compared to the G-PCC,
    and by achieving -2.267% bit rate reduction compared to the state-of-the-art learning-based
    method. As the first LLM-based point compression method, the proposed LLM-PCGC
    method achieves superior performances.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Framework Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Encoding Pipline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The LLM-PCGC encoding pipeline is depicted in Fig. [2](#Sx1.F2 "Figure 2 ‣
    Introduction ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression").
    The encoding phase initiates with the clustering of input 3D point clouds, where
    each cluster undergoes parallel processing. This process involves several key
    steps, including normalization of coordinates through offset subtraction, organization
    of data using a K-tree structure, flattening and chunking of the hierarchical
    tree structure, and translation of the point cloud’s patch tokens into text tokens
    with a codebook. Special tokens, such as $<$ to denote the end token id, are incorporated
    to construct analogous linguistic sentences. The encoding process culminates with
    the employment of a trained LoRA architecture in conjunction with a frozen LLM
    to predict the next token’s probability distribution, which is then encoded using
    an arithmetic encoder.'
  prefs: []
  type: TYPE_NORMAL
- en: Decoding Pipline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The LLM-PCGC decoding pipeline is depicted in Fig. [3](#Sx1.F3 "Figure 3 ‣
    Introduction ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression").
    In the decoding phase, the parallel-received binary files are segmented to identify
    the corresponding offset, $<$, and the main bitstream for each bitstream. These
    identifiers are converted from binary to decimal values, facilitating the processing
    of the main bitstream through a trainable LoRA and a frozen LLM model to obtain
    a probability distribution for the next token, which is decoded using an arithmetic
    coder. The codebook then translates text tokens back into point cloud patch tokens,
    which are aligned and merged based on their common offset and chunk indexes. An
    algorithm is applied to reconstruct trees and coordinates. This algorithm ingeniously
    restores coordinates by counting the number of one, due to the lack of ancestral
    information. Finally, the cluster point clouds are adjusted by their respective
    offsets, reconstructing the full point cloud to its original form.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Bpp performance gains compared to G-PCC and SparsePCGC anchors on
    MPEG 8i and Owlii datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Frame |'
  prefs: []
  type: TYPE_TB
- en: '&#124; G-PCC &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; v14 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SparsePCGC &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 8-stage &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; LLM-PCGC &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; (Ours) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Gain over &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; G-PCC &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Gain over &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SparsePCGC &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| MPEG 8i | Longdress_vox10_1300 | 1.015 | 0.643 | 0.631 | -37.882% | -1.944%
    |'
  prefs: []
  type: TYPE_TB
- en: '| Redandblack_vox10_1550 | 1.100 | 0.714 | 0.703 | -36.100% | -1.555% |'
  prefs: []
  type: TYPE_TB
- en: '| Soldier_vox10_0690 | 1.013 | 0.653 | 0.634 | -38.456% | -2.925% |'
  prefs: []
  type: TYPE_TB
- en: '| Loot_vox10_1200 | 0.970 | 0.614 | 0.597 | -38.454% | -2.769% |'
  prefs: []
  type: TYPE_TB
- en: '| Owlii | Basketball_player_vox11_0200 | 0.898 | 0.497 | 0.490 | -45.479% |
    -1.410% |'
  prefs: []
  type: TYPE_TB
- en: '| Dancer_vox11_0001 | 0.880 | 0.500 | 0.485 | -44.909% | -3.079% |'
  prefs: []
  type: TYPE_TB
- en: '| Average |  | 0.982 | 0.603 | 0.590 | -40.213% | -2.267% |'
  prefs: []
  type: TYPE_TB
- en: Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Training and Testing Setting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data Processing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given the current methods which autoregressive methods like OctAttention (Fu
    et al. [2022](#bib.bib5)), VoxelDNN (Nguyen et al. [2021a](#bib.bib12)), MSVoxelDNN
    (Nguyen et al. [2021b](#bib.bib13)), and NNOC (Kaya and Tabus [2021](#bib.bib8))
    utilize Microsoft Voxelized Upper Bodies (MVUB) (Loop et al. [2016](#bib.bib10))
    and 8i Voxelized Full Bodies (MPEG 8i) (d’Eon et al. [2017](#bib.bib4)) datasets
    for training, and other approaches like SparsePCGC (Wang et al. [2022](#bib.bib18))
    are trained on ShapeNet (Chang et al. [2015](#bib.bib2)), we aim to ensure fair
    comparison by training two sets of LLM-PCGC parameters on similar datasets.
  prefs: []
  type: TYPE_NORMAL
- en: In our experimental comparison with SparsePCGC, we group ModelNet40 (Wu et al.
    [2015](#bib.bib19)) point cloud data into 12 clusters, then organize 3D point
    cloud clusters in a K-Tree structure with K=12 for training. For testing, we follow
    the common test condition (CTC) (Schwarz et al. [2018](#bib.bib15)), which recommend
    to evaluate two public datasets, i.e., MPEG 8i and Owlii (Xu, Lu, and Wen [2017](#bib.bib21)).
  prefs: []
  type: TYPE_NORMAL
- en: In relation to autoregressive methods such as OctAttention, VoxelDNN, MSVoxelDNN,
    and NNOC, we align with the norm by employing widely-used sequences for training.
    Specifically, we use the point cloud sequences of Andrew10, David10, and Sarah10
    from the MVUB, as well as the point cloud sequences of Longdress10 and Soldier10
    from MPEG 8i for training. We do a similar clustering process with the cluster
    number of 240 and K-Tree structure with K=12 for the chosen data. For testing,
    we select two point clouds from MPEG 8i, Thaidancer and Boxer, which both are
    downsampled from 12-bit to 10-bit resolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Trainable parameters of LLaMA2-7B (Touvron et al. [2023](#bib.bib16))
    used in the proposed LLM-PCGC.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Configuration | LoRA | Embedding |'
  prefs: []
  type: TYPE_TB
- en: '| Component | [q, v, k, o, gate, up, down] in all layers | [lm_head, embed_tokens]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Hyperparameters | $r=64$ | —— |'
  prefs: []
  type: TYPE_TB
- en: '| Trainable params | 159,907,840 | 295,698,432 |'
  prefs: []
  type: TYPE_TB
- en: '| LLaMA2-7B params | 6,738,415,616 | 6,738,415,616 |'
  prefs: []
  type: TYPE_TB
- en: '| Trainable% | 2.37% | 4.39% |'
  prefs: []
  type: TYPE_TB
- en: Base Model and LoRA Setting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Based on LLaMA (Touvron et al. [2023](#bib.bib16)), an open-source LLM that
    competes in performance with GPT-3 (Brown et al. [2020](#bib.bib1)), and taking
    into consideration the hardware resources available, we choose the smallest model,
    LLaMA2-7B, as our foundational model for this experiment. As delineated in Table
    [2](#Sx3.T2 "Table 2 ‣ Data Processing ‣ Training and Testing Setting ‣ Experiments
    ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression"), we
    provide a detailed description of the LoRA and Embedding modules of LLaMA2-7B.
    The total number of trainable parameters amounts to only 6.7% of the original
    base LLaMA2-7B model’s parameters. Our model is developed in PyTorch and runs
    on a system with Intel Xeon Gold 6248R CPUs and only an NVIDIA A40 GPU with 48GB
    of memory.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/badfc099344346999fab4793219c1521.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Comparison of bpp among autoregressive methods and traditional method
    G-PCC.'
  prefs: []
  type: TYPE_NORMAL
- en: Experiment Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For experimental comparison with SparsePCGC, we attempt to reproduce SparsePCGC
    using the similar synthetic ModelNet40 dataset, with bits per point (bpp) performance
    results presented in Table [1](#Sx2.T1 "Table 1 ‣ Decoding Pipline ‣ Framework
    Overview ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression").
    For MPEG 8i and Owlii dataset, our proposed LLM-PCGC method achieves -40.213%
    bit rate reduction compared to the reference software G-PCC v14 on average and
    up to 44.909% for Dancer_vox11_0001 and 45.479% for Basketball_player_vox11_0200\.
    Our method also outperforms achieves -2.267% bit rate reduction compared to the
    state-of-the-art learning-based SparsePCGC method.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Regrettably, for the other autoregressive methods, we are not able to reproduce
    their results by ourselves due to the lack of source codes and relevant materials.
    Consequently, we reference the performance metrics directly as reported in their
    original publications. It should be noted that the Thaidancer_vox10 and Boxer_vox10
    datasets serve as the shared test sets for the evaluation of other autoregressive
    methods. Accordingly, our examination is confined to the evaluation of compression
    efficacy on these two specific point cloud datasets, as shown in Fig. [4](#Sx3.F4
    "Figure 4 ‣ Base Model and LoRA Setting ‣ Training and Testing Setting ‣ Experiments
    ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression"). Building
    upon the identical G-PCC benchmark, the proposed LLM-PCGC achieves the lowest
    bpp rate. For instance, it records an average of 0.52 bpp for the MPEG 8i dataset.
    This marks a reduction of 0.20 bpp from the results achieved by both MSVoxelDNN
    and fNNOC. In contrast to the OctAttention, which necessitates the inclusion of
    1024 neighboring nodes for context modeling, our LLM-PCGC leverages a more robust
    context model. Remarkably, even in the absence of assistance from ancestor nodes,
    it still manages to achieve a reduction of 0.10 bpp compared to OctAttention.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we propose the LLM-PCGC method, which is the first to employ
    LLM as compressor for the point cloud compression task within the “Generator is
    compressor” framework. We utilize different adaptation techniques, i.e., clustering,
    K-tree, token mapping invariance, and LoRA, to achieve efficient cross-modality
    representation alignment and semantic consistency. Without any text data, a text
    generator can be translated to a point cloud compressor. Experimental results
    show that the proposed LLM-PCGC method achieves superior compression performance
    over G-PCC and the state-of-the-art learning-based method, demonstrating the potential
    of LLMs in data compression. Although as the first attempt to develop a LLM-based
    point compression method, the proposed LLM-PCGC method achieves superior performances,
    future research efforts can be made for optimizing the issues on the excessive
    memory consumption and the long inference time of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Brown et al. (2020) Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;
    Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; et al. 2020.
    Language models are few-shot learners. *Advances in neural information processing
    systems*, 33: 1877–1901.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chang et al. (2015) Chang, A. X.; Funkhouser, T.; Guibas, L.; Hanrahan, P.;
    Huang, Q.; Li, Z.; Savarese, S.; Savva, M.; Song, S.; Su, H.; et al. 2015. Shapenet:
    An information-rich 3d model repository. *arXiv preprint arXiv:1512.03012*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delétang et al. (2024) Delétang, G.; Ruoss, A.; Duquenne, P.; Catt, E.; Genewein,
    T.; Mattern, C.; Grau-Moya, J.; Wenliang, L. K.; Aitchison, M.; Orseau, L.; Hutter,
    M.; and Veness, J. 2024. Language Modeling Is Compression. In *ICLR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'd’Eon et al. (2017) d’Eon, E.; Harrison, B.; Myers, T.; and Chou, P. A. 2017.
    8i voxelized full bodies-a voxelized point cloud dataset. *ISO/IEC JTC1/SC29 Joint
    WG11/WG1 (MPEG/JPEG) input document WG11M40059/WG1M74006*, 7(8): 11.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu et al. (2022) Fu, C.; Li, G.; Song, R.; Gao, W.; and Liu, S. 2022. Octattention:
    Octree-based large-scale contexts model for point cloud compression. In *Proceedings
    of the AAAI conference on artificial intelligence*, volume 36, 625–633.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong et al. (2023) Hong, Y.; Zhen, H.; Chen, P.; Zheng, S.; Du, Y.; Chen, Z.;
    and Gan, C. 2023. 3d-llm: Injecting the 3d world into large language models. *Advances
    in Neural Information Processing Systems*, 36: 20482–20494.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaplan et al. (2020) Kaplan, J.; McCandlish, S.; Henighan, T.; Brown, T. B.;
    Chess, B.; Child, R.; Gray, S.; Radford, A.; Wu, J.; and Amodei, D. 2020. Scaling
    laws for neural language models. *arXiv preprint arXiv:2001.08361*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaya and Tabus (2021) Kaya, E. C.; and Tabus, I. 2021. Neural network modeling
    of probabilities for coding the octree representation of point clouds. In *2021
    IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP)*, 1–6\.
    IEEE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2024) Li, Y.; Guo, Y.; Guerin, F.; and Lin, C. 2024. Evaluating Large
    Language Models for Generalization and Robustness via Data Compression. *arXiv
    preprint arXiv:2402.00861*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Loop et al. (2016) Loop, C.; Cai, Q.; Escolano, S. O.; and Chou, P. A. 2016.
    Microsoft voxelized upper bodies-a voxelized point cloud dataset. *ISO/IEC JTC1/SC29
    Joint WG11/WG1 (MPEG/JPEG) input document m38673 M*, 72012: 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mirchandani et al. (2023) Mirchandani, S.; Xia, F.; Florence, P.; Ichter, B.;
    Driess, D.; Arenas, M. G.; Rao, K.; Sadigh, D.; and Zeng, A. 2023. Large Language
    Models as General Pattern Machines. In *Proceedings of the 7th Conference on Robot
    Learning (CoRL)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nguyen et al. (2021a) Nguyen, D. T.; Quach, M.; Valenzise, G.; and Duhamel,
    P. 2021a. Lossless coding of point cloud geometry using a deep generative model.
    *IEEE Transactions on Circuits and Systems for Video Technology*, 31(12): 4617–4629.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nguyen et al. (2021b) Nguyen, D. T.; Quach, M.; Valenzise, G.; and Duhamel,
    P. 2021b. Multiscale deep context modeling for lossless point cloud geometry compression.
    In *2021 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)*,
    1–6\. IEEE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Que, Lu, and Xu (2021) Que, Z.; Lu, G.; and Xu, D. 2021. Voxelcontext-net:
    An octree based framework for point cloud compression. In *Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 6042–6051.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schwarz et al. (2018) Schwarz, S.; Martin-Cocher, G.; Flynn, D.; and Budagavi,
    M. 2018. Common test conditions for point cloud compression. *Document ISO/IEC
    JTC1/SC29/WG11 w17766, Ljubljana, Slovenia*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,
    M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; et al. 2023.
    Llama: Open and efficient foundation language models. *arXiv preprint arXiv:2302.13971*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Valmeekam et al. (2023) Valmeekam, C. S. K.; Narayanan, K.; Kalathil, D.; Chamberland,
    J.-F.; and Shakkottai, S. 2023. Llmzip: Lossless text compression using large
    language models. *arXiv preprint arXiv:2306.04050*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2022) Wang, J.; Ding, D.; Li, Z.; Feng, X.; Cao, C.; and Ma, Z.
    2022. Sparse tensor-based multiscale representation for point cloud geometry compression.
    *IEEE Transactions on Pattern Analysis and Machine Intelligence*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2015) Wu, Z.; Song, S.; Khosla, A.; Yu, F.; Zhang, L.; Tang, X.;
    and Xiao, J. 2015. 3d shapenets: A deep representation for volumetric shapes.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*,
    1912–1920.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023) Xu, R.; Wang, X.; Wang, T.; Chen, Y.; Pang, J.; and Lin, D.
    2023. Pointllm: Empowering large language models to understand point clouds. *arXiv
    preprint arXiv:2308.16911*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu, Lu, and Wen (2017) Xu, Y.; Lu, Y.; and Wen, Z. 2017. Owlii dynamic human
    mesh sequence dataset. In *ISO/IEC JTC1/SC29/WG11 m41658, 120th MPEG Meeting*,
    volume 1, 8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yin et al. (2023) Yin, F.; Chen, X.; Zhang, C.; Jiang, B.; Zhao, Z.; Fan, J.;
    Yu, G.; Li, T.; and Chen, T. 2023. ShapeGPT: 3D Shape Generation with A Unified
    Multi-modal Language Model. arXiv:2311.17618.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. (2024) Yu, Y.; Buchanan, S.; Pai, D.; Chu, T.; Wu, Z.; Tong, S.; Haeffele,
    B.; and Ma, Y. 2024. White-box transformers via sparse rate reduction. *Advances
    in Neural Information Processing Systems*, 36.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
