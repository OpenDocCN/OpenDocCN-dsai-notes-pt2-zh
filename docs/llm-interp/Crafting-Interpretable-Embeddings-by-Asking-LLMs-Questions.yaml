- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 17:34:34'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Crafting Interpretable Embeddings by Asking LLMs Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.16714](https://ar5iv.labs.arxiv.org/html/2405.16714)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Vinamra Benara*
  prefs: []
  type: TYPE_NORMAL
- en: UC Berkeley &Chandan Singh*
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Research &John X. Morris
  prefs: []
  type: TYPE_NORMAL
- en: Cornell University &Richard Antonello
  prefs: []
  type: TYPE_NORMAL
- en: UT Austin Ion Stoica
  prefs: []
  type: TYPE_NORMAL
- en: UC Berkeley &Alexander G. Huth
  prefs: []
  type: TYPE_NORMAL
- en: UT Austin &Jianfeng Gao
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Research
  prefs: []
  type: TYPE_NORMAL
- en: '*Equal contribution'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large language models (LLMs) have rapidly improved text embeddings for a growing
    array of natural-language processing tasks. However, their opaqueness and proliferation
    into scientific domains such as neuroscience have created a growing need for interpretability.
    Here, we ask whether we can obtain interpretable embeddings through LLM prompting.
    We introduce question-answering embeddings (QA-Emb), embeddings where each feature
    represents an answer to a yes/no question asked to an LLM. Training QA-Emb reduces
    to selecting a set of underlying questions rather than learning model weights.
  prefs: []
  type: TYPE_NORMAL
- en: We use QA-Emb to flexibly generate interpretable models for predicting fMRI
    voxel responses to language stimuli. QA-Emb significantly outperforms an established
    interpretable baseline, and does so while requiring very few questions. This paves
    the way towards building flexible feature spaces that can concretize and evaluate
    our understanding of semantic brain representations. We additionally find that
    QA-Emb can be effectively approximated with an efficient model, and we explore
    broader applications in simple NLP tasks.¹¹1All code for QA-Emb is made available
    on Github at [\faGithub github.com/csinva/interpetable-embeddings](https://github.com/csinva/interpretable-embeddings).
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text embeddings are critical to many applications, including information retrieval,
    semantic clustering, retrieval-augmented generation, and language neuroscience.
    Traditionally, text embeddings leveraged interpretable representations such as
    bag-of-words or BM-25 [[1](#bib.bib1)]. Modern methods often replace these embeddings
    with representations from large language models (LLMs), which may better capture
    nuanced contexts and interactions [[2](#bib.bib2), [3](#bib.bib3), [4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7)]. However, these embeddings are
    essentially black-box representations, making it difficult to understand the predictive
    models built on top of them (as well as why they judge different texts to be similar
    in a retrieval context). This opaqueness is detrimental in scientific fields,
    such as neuroscience [[8](#bib.bib8)] or social science [[9](#bib.bib9)], where
    trustworthy interpretation itself is the end goal. Moreover, this opaqueness has
    debilitated the use of LLM embeddings (for prediction or retrieval) in high-stakes
    applications such as medicine [[10](#bib.bib10)], and raised issues related to
    regulatory pressure, safety, and alignment [[11](#bib.bib11), [12](#bib.bib12),
    [13](#bib.bib13), [14](#bib.bib14)].
  prefs: []
  type: TYPE_NORMAL
- en: To ameliorate these issues, we introduce question-answering embeddings (QA-Emb),
    a method that builds an interpretable embedding by repeatedly querying a pre-trained
    autoregressive LLM with a set of questions that are selected for a problem ([Fig. 1](#S1.F1
    "In 1 Introduction ‣ Crafting Interpretable Embeddings by Asking LLMs Questions")).
    Each element of the embedding represents the answer to a different question asked
    to an LLM, making the embedding human-inspectable. For example, the first element
    may be the answer to the question Does the input mention time? and the output
    would map yes/no to 1/0. Training QA-Emb requires only black-box access to the
    LLM (it does not require access to the LLM internals) and modifies only natural-language
    prompts, rather than LLM parameters. The learning problem is similar to the optimization
    faced in natural-language autoprompting [[15](#bib.bib15), [16](#bib.bib16)] or
    single-neuron explanation [[17](#bib.bib17), [18](#bib.bib18)], but seeks a set
    of questions rather than an individual prompt.
  prefs: []
  type: TYPE_NORMAL
- en: We focus on a single neuroscience problem in close collaboration with neuroscientists.
    Grounding in a neuroscience context allows us to avoid common pitfalls in evaluating
    interpretation methods [[19](#bib.bib19), [20](#bib.bib20)] that seek to test
    “interpretability” generally. Additionally, this focus allows to more realistically
    integrate domain knowledge to select and evaluate the questions needed for QA-Emb,
    one of its core strengths. Nevertheless, QA-Emb may be generally applicable in
    other domains where it is important to meaningfully interpret text embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: In our neuroscience setting, we build QA-Emb representations from natural-language
    questions that can predict human brain responses measured by fMRI to natural-language
    stimuli. This allows for converting informal verbal hypotheses about the semantic
    selectivity of the brain into quantitative models, a pressing challenge in fields
    such as psychology [[21](#bib.bib21)]. We find that predictive models built on
    top of QA-Embs are quite accurate, providing a 26% improvement over an established
    interpretable baseline [[22](#bib.bib22)] and even slightly outperforming a black-box
    BERT baseline [[23](#bib.bib23)]. Additionally, QA-Emb yields concise embeddings,
    outperforming the interpretable baseline (that consists of 985 features) with
    only 29 questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We investigate two major limitations of QA-Emb in [Sec. 5](#S5 "5 Evaluating
    the limitations of QA-Emb ‣ Crafting Interpretable Embeddings by Asking LLMs Questions").
    First, with regards to computational efficiency, we find that we can drastically
    reduce the computational cost of QA-Emb by distilling it into a model that computes
    the answers to all selected questions in a single feedforward pass by using many
    classification heads. Second, we evaluate the accuracy of modern LLMs at reliably
    answering diverse yes/no questions. Finally, [Sec. 6](#S6 "6 Secondary results:
    evaluating QA-Emb in simple NLP tasks ‣ Crafting Interpretable Embeddings by Asking
    LLMs Questions") explores broader applications for QA-Emb in a simple information
    retrieval setting and text-clustering setting.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0c409600e08dfcba9f1c37e4545a7895.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: QA-Emb produces an embedding for an input text by prompting an LLM
    with a series of yes/no questions. This embedding can then be used in downstream
    tasks such as fMRI response prediction or information retrieval.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: QA-Emb is an intuitive method to generate text embeddings from a pre-trained
    autoregressive LLM ([Fig. 1](#S1.F1 "In 1 Introduction ‣ Crafting Interpretable
    Embeddings by Asking LLMs Questions")). Given a text input, QA-Emb builds an interpretable
    embedding by querying the LLM with a set of questions about the input. Each element
    of the embedding represents the answer to a different question asked to an LLM.
    This procedure allows QA-Emb to capture nuanced and relevant details in the input
    while staying interpretable.
  prefs: []
  type: TYPE_NORMAL
- en: Learning a set of yes/no questions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'QA-Emb requires specifying a set of yes/no questions $Q\in\mathcal{Q}_{\text{yes/no}}$
    that yield a binary embedding $v_{Q}(x)\in\{0,1\}^{d}$ for an input string $x$.
    The questions are chosen to yield embeddings that are suitable for a downstream
    task. In our fMRI prediction task, we optimize for supervised linear regression:
    given a list of $n$ input strings $X$ and a multi-dimensional continuous output
    $Y\in\mathbb{R}^{nxd}$, we seek embeddings that allow for learning effective ridge
    regression models:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Q=\underset{Q\in\mathcal{Q}_{\text{yes/no}}}{\text{argmin}}\left[\underset{\theta\in\mathbb{R}^{d}}{\min}\sum_{i}^{n}&#124;&#124;Y^{(i)}-\theta^{T}v_{Q}(X^{(i)})&#124;&#124;+\lambda&#124;&#124;\theta&#124;&#124;_{2}\right],$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $\theta$ is a learned coefficient vector for predicting the fMRI responses
    and $\lambda$ is the ridge regularization parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Directly optimizing over the space of yes/no questions is difficult, as it requires
    searching over a discrete space with a constraint set $\mathcal{Q}_{\text{yes/no}}$
    that is hard to specify. Instead, we heuristically optimize the set of questions
    $Q$, by prompting a highly capable LLM (e.g. GPT-4 [[24](#bib.bib24)]) to generate
    questions relevant to our task, e.g. Generate a bulleted list of questions with
    yes/no answers that is relevant for {{task description}}. Customizing the task
    description helps yield relevant questions. The prompt can flexibly specify more
    prior information when available. For example, it can include examples from the
    input dataset to help the LLM identify data-relevant questions. Taking this a
    step further, questions can be generated sequentially (similar to gradient boosting)
    by having the LLM summarize input examples that incur high prediction error to
    generate new questions focused on those examples. While we focus on optimizing
    embeddings for fMRI ridge regression in [Eq. 1](#S2.E1 "In Learning a set of yes/no
    questions ‣ 2 Methods ‣ Crafting Interpretable Embeddings by Asking LLMs Questions"),
    different downstream tasks may require different inner optimization procedures,
    e.g. maximizing the similarity of relevant documents for retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: Post-hoc pruning of $Q$.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The set of learned questions $Q$ can be easily pruned to be made compact and
    useful in different settings. For example, in our fMRI regression setting, a feature-selection
    procedure such as Elastic net [[25](#bib.bib25)] can be used to remove redundant/uninformative
    questions from the specified set of questions $Q$. Alternatively, an LLM can be
    used to directly adapt $Q$ to yield task-specific embeddings. Since the questions
    are all in natural language, they can be listed in a prompt, and an LLM can be
    asked to filter the task-relevant ones, e.g. Here is a list of questions:{{question
    list}} List the subset of these questions that are relevant for {{task description}}.
  prefs: []
  type: TYPE_NORMAL
- en: 'Limitations: computational cost and LLM inaccuracies.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: While effective, the QA-Emb pipeline described here has two major limitations.
    First, QA-Emb is computationally intensive, requiring $d$ LLM calls to compute
    an embedding. This is often prohibitively expensive, but may be worthwhile in
    high-value applications (such as our fMRI setting) and will likely become more
    tenable as LLM inference costs continue to rapidly decrease. We find that we can
    dramatically reduce this cost by distilling the QA-Emb model into a single LLM
    model with many classification heads in [Sec. 5.1](#S5.SS1 "5.1 Improving computational
    efficiency via model distillation ‣ 5 Evaluating the limitations of QA-Emb ‣ Crafting
    Interpretable Embeddings by Asking LLMs Questions"). Otherwise, LLM inference
    costs are partially mitigated by the ability to reuse the KV-cache for each question
    and the need to only generate a single token for each question. While computing
    embeddings with QA-Emb is expensive, searching embeddings is made faster by the
    fact that the resulting embeddings are binary and often relatively compact.
  prefs: []
  type: TYPE_NORMAL
- en: Second, QA-Emb requires that the pre-trained LLM can faithfully answer the given
    yes-no questions. If an LLM is unable to accurately answer the questions, it hurts
    explanation’s faithfulness. Thus, QA-Emb requires the use of fairly strong LLMs
    and the set of chosen questions should be accurately answered by these LLMs ([Sec. 5.2](#S5.SS2
    "5.2 Evaluating question-answering faithfulness ‣ 5 Evaluating the limitations
    of QA-Emb ‣ Crafting Interpretable Embeddings by Asking LLMs Questions") provides
    analysis on the question-answering accuracy of different LLMs).
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter settings
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For answering questions, we average the answers from Mistral-7B [[26](#bib.bib26)]
    (mistralai/Mistral-7B-Instruct-v0.2) and LLaMA-3 8B [[27](#bib.bib27)] (meta-llama/Meta-Llama-3-8B-Instruct)
    with two prompts. All perform similarly and averaging their answers yields a small
    performance improvement ([Table A2](#A1.T2 "In A.2 fMRI prediction results extended
    ‣ Appendix A Appendix ‣ Crafting Interpretable Embeddings by Asking LLMs Questions")).
    For generating questions, we prompt GPT-4 [[24](#bib.bib24)] (gpt-4-0125-preview).
    Experiments were run using 64 AMD MI210 GPUs, each with 64 gigabytes of memory,
    and reproducing all experiments in the paper requires approximately 4 days (initial
    explorations required roughly 5 times this amount of compute). All prompts used
    and generated questions are given in the appendix or on Github.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Related work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Text embeddings
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Text embeddings models, which produce vector representations of document inputs,
    have been foundational to NLP. Recently, transformer-based models have been trained
    to yield embeddings in a variety of ways [[2](#bib.bib2), [3](#bib.bib3), [4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7)], including producing embeddings
    that are sparse [[28](#bib.bib28)] or have variable lengths [[29](#bib.bib29)].
    Recent works have also leveraged autoregressive LLMs to build embeddings, e.g.
    by repeating embeddings [[30](#bib.bib30)], generating synthetic data [[6](#bib.bib6),
    [31](#bib.bib31)], or using the last-token distribution of an autoregressive LLM
    as an embedding [[32](#bib.bib32)]. Similar to QA-Emb, various works have used
    LLM answers to multiple prompts for different purposes, e.g. text classification [[33](#bib.bib33),
    [34](#bib.bib34)] or data exploration [[35](#bib.bib35)].
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting representations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A few works have focused on building intrinsically interpretable text representations,
    e.g. word or ngram-based embeddings such as word2vec [[36](#bib.bib36)], Glove [[37](#bib.bib37)],
    and LLM word embeddings. Although their dimensions are not natively interpretable,
    for some tasks, such as classification, they can be projected into a space that
    is interpretable [[38](#bib.bib38)], i.e. a word-level representation. Note that
    it is difficult to learn a sparse interpretable model from these dense embeddings,
    as standard techniques (e.g. Elastic net) cannot be directly applied.
  prefs: []
  type: TYPE_NORMAL
- en: When instead using black-box representations, there are many post-hoc methods
    to interpret embeddings, e.g. probing [[39](#bib.bib39), [40](#bib.bib40)], categorizing
    elements into categories [[41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43),
    [44](#bib.bib44)], categorizing directions in representation space [[45](#bib.bib45),
    [46](#bib.bib46), [47](#bib.bib47)], or connecting multimodal embeddings with
    text embeddings/text concepts [[48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50),
    [51](#bib.bib51), [52](#bib.bib52)]. For a single pair of text embeddings, prediction-level
    methods can be applied to approximately explain why the two embeddings are similar [[53](#bib.bib53),
    [54](#bib.bib54)].
  prefs: []
  type: TYPE_NORMAL
- en: Natural language representations in fMRI
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Using LLM representations to help predict brain responses to natural language
    has recently become popular among neuroscientists studying language processing [[55](#bib.bib55),
    [56](#bib.bib56), [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59), [60](#bib.bib60)]
    (see [[61](#bib.bib61), [62](#bib.bib62)] for reviews). This paradigm of using
    “encoding models” [[63](#bib.bib63)] to better understand how the brain processes
    language has been applied to help understand the cortical organization of language
    timescales [[64](#bib.bib64), [65](#bib.bib65)], examine the relationship between
    visual and semantic information in the brain [[66](#bib.bib66)], and explore to
    what extent syntax, semantics, or discourse drives brain activity [[22](#bib.bib22),
    [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69), [70](#bib.bib70), [71](#bib.bib71),
    [72](#bib.bib72), [73](#bib.bib73), [18](#bib.bib18)]. The approach here extends
    these works to build an increasingly flexible, interpretable feature space for
    modeling fMRI responses to text data.
  prefs: []
  type: TYPE_NORMAL
- en: '4 Main results: fMRI interpretation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A central challenge in neuroscience is understanding how and where semantic
    concepts are represented in the brain. To meet this challenge, we extend the line
    of study that fits models to predict the response of different brain voxels (i.e.
    small regions in the brain) to natural language stimuli. Using QA-Emb, we seek
    to bridge models that are interpretable [[1](#bib.bib1), [22](#bib.bib22)] with
    more recent LLM models that are accurate but opaque [[55](#bib.bib55), [56](#bib.bib56),
    [57](#bib.bib57)].
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 fMRI experimental setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We analyze data from two recent studies [[74](#bib.bib74), [75](#bib.bib75)]
    (released under the MIT license), which contain fMRI responses for 3 human subjects
    listening to 20+ hours of narrative stories from podcasts. We extract text embeddings
    from the story that each subject hears and fit a ridge regression to predict the
    fMRI responses ([Eq. 1](#S2.E1 "In Learning a set of yes/no questions ‣ 2 Methods
    ‣ Crafting Interpretable Embeddings by Asking LLMs Questions")). Each subject
    listens to either 79 or 82 stories (consisting of 27,449 time points) and 2 test
    stories (639 time points); Each subject’s fMRI data consists of approximately
    100,000 voxels; we preprocess it by running principal component analysis (PCA)
    and extracting the coefficients of the top 100 components.
  prefs: []
  type: TYPE_NORMAL
- en: Regression modeling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We fit ridge regression models to predict these 100 coefficients and evaluate
    the models in the original voxel space (by applying the inverse PCA mapping and
    measuring the correlation between the response and prediction for each voxel).
    We deal with temporal sampling following [[22](#bib.bib22), [57](#bib.bib57)];
    an embedding is produced at the timepoint for each word in the input story and
    these embeddings are interpolated using Lanczos resampling. Embeddings at each
    timepoint are produced from the ngram consisting of the 10 words preceding the
    current timepoint. We select the best-performing hyperparameters via cross-validation
    on 5 time-stratified bootstrap samples of the training set. We select the best
    ridge parameters from 12 logarithmically spaced values between 10 and 10,000.
    To model temporal delays in the fMRI signal, we also select between adding 4,
    8, or 12 time-lagged duplicates of the stimulus features.
  prefs: []
  type: TYPE_NORMAL
- en: Generating QA-Emb questions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To generate the questions underlying QA-Emb, we prompt GPT-4 with 6 prompts
    that aim to elicit knowledge useful for predicting fMRI responses (precise prompts
    in [Sec. A.3](#A1.SS3 "A.3 Prompts ‣ Appendix A Appendix ‣ Crafting Interpretable
    Embeddings by Asking LLMs Questions")). This includes directly asking the LLM
    to use its knowledge of neuroscience, to brainstorm semantic properties of narrative
    sentences, to summarize examples from the input data, and to generate questions
    similar to single-voxel explanations found in a prior work [[18](#bib.bib18)].
    This process yields 674 questions ([Fig. 1](#S1.F1 "In 1 Introduction ‣ Crafting
    Interpretable Embeddings by Asking LLMs Questions") and [Table A1](#A1.T1 "In
    A.1 fMRI question details ‣ Appendix A Appendix ‣ Crafting Interpretable Embeddings
    by Asking LLMs Questions") show examples, see all questions on Github). We perform
    feature selection by running multi-task Elastic net with 20 logarithmically spaced
    regularization parameters ranging from $10^{-3}$ to 1 and then fit a Ridge regression
    to the selected features.²²2We run Elastic net using the MultiTaskElasticNet class
    from scikit-learn [[76](#bib.bib76)]. See extended details on the fMRI experimental
    setup in [Sec. A.1](#A1.SS1 "A.1 fMRI question details ‣ Appendix A Appendix ‣
    Crafting Interpretable Embeddings by Asking LLMs Questions") and all prompts in
    [Sec. A.3](#A1.SS3 "A.3 Prompts ‣ Appendix A Appendix ‣ Crafting Interpretable
    Embeddings by Asking LLMs Questions").
  prefs: []
  type: TYPE_NORMAL
- en: Baselines
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We compare QA-Emb to Eng1000, an interpretable baseline developed in the neuroscience
    literature specifically for the task of predicting fMRI responses from narrative
    stories [[22](#bib.bib22)]. Each element in an Eng1000 embedding corresponds to
    a cooccurence statistic with a different word, allowing full interpretation of
    the underlying representation in terms of related words. We additionally compare
    to embeddings from BERT [[23](#bib.bib23)] (bert-base-uncased) and LLaMA models [[77](#bib.bib77),
    [27](#bib.bib27)]. For each subject, we sweep over 5 layers from LLaMA-2 7B (meta-llama/Llama-2-7b-hf,
    layers 6, 12, 18, 24, 30), LLaMA-2 70B (meta-llama/Llama-2-70b-hf, layers 12,
    24, 36, 48, 60), and LLaMA-3 8B (meta-llama/Meta-Llama-3-8B, layers 6, 12, 18,
    24, 30), then report the test performance for the model that yields the best cross-validated
    accuracy (see breakdown in [Table A3](#A1.T3 "In A.2 fMRI prediction results extended
    ‣ Appendix A Appendix ‣ Crafting Interpretable Embeddings by Asking LLMs Questions")).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 fMRI predictive performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: \begin{overpic}[width=212.47617pt]{figs/corr_best.pdf} \put(3.0,70.0){{A}} \end{overpic}\begin{overpic}[width=212.47617pt]{figs/sparsity.pdf}
    \put(3.0,70.0){{B}} \end{overpic}\begin{overpic}[width=212.47617pt]{figs/flatmaps/S03_qa_flatmap.pdf}
    \put(3.0,50.0){{C}} \end{overpic}\begin{overpic}[width=212.47617pt]{figs/flatmaps/S03_qa-bert_flatmap.pdf}
    \put(3.0,50.0){{D}} \end{overpic}![Refer to caption](img/28afb7cdb9627bd6e6ea3f526a197d19.png)![Refer
    to caption](img/897be02afc2ba08b905ac88825f20c83.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: Predictive performance for QA-Emb compared to baselines. (A) Test
    correlation for QA-Emb outperforms the interpretable Eng1000 baseline, is on par
    with the black-box BERT baseline, and is worse than the best-performing LLaMA
    model. (B) Test correlation for method quickly grows as a function of the number
    of included questions. (C) Test correlation per voxel for QA-Emb. (D) Difference
    in the test correlation per voxel for subject between QA-Emb and BERT. Error bars
    for (A) and (B) (standard error of the mean) are within the points (all are below
    0.001). (B), (C), and (D) show results for subject S03.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We find that QA-Emb predicts fMRI responses fairly well across subjects ([Fig. 2](#S4.F2
    "In 4.2 fMRI predictive performance ‣ 4 Main results: fMRI interpretation ‣ Crafting
    Interpretable Embeddings by Asking LLMs Questions")A), achieving an average test
    correlation of 0.116. QA-Emb significantly outperforms the interpretable baseline
    Eng1000 (26% average improvement). Comparing to the two transformer-based baselines
    (which do not yield straightforward interpretations), we find that QA-Emb slightly
    outperforms BERT (5% improvement) and worse than the best cross-validated LLaMA-based
    model (7% decrease). Trends are consistent across all 3 subjects.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To yield a compact and interpretable model, [Fig. 2](#S4.F2 "In 4.2 fMRI predictive
    performance ‣ 4 Main results: fMRI interpretation ‣ Crafting Interpretable Embeddings
    by Asking LLMs Questions")B further investigates the compressibility of the two
    interpretable methods (through Elastic net regularization). Compared to Eng1000,
    QA-Emb improves performance very quickly as a function of the number of features
    included, even outperforming the final Eng1000 performance with only 29 questions
    (mean test correlation 0.122 versus 0.118). [Table A1](#A1.T1 "In A.1 fMRI question
    details ‣ Appendix A Appendix ‣ Crafting Interpretable Embeddings by Asking LLMs
    Questions") shows the 29 selected questions, which constitute a human-readable
    description of the entire model.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Fig. 2](#S4.F2 "In 4.2 fMRI predictive performance ‣ 4 Main results: fMRI
    interpretation ‣ Crafting Interpretable Embeddings by Asking LLMs Questions")C-D
    further break down the predictive performance across different brain regions for
    a particular subject (S03). The regions that are well-predicted by QA-Emb ([Fig. 2](#S4.F2
    "In 4.2 fMRI predictive performance ‣ 4 Main results: fMRI interpretation ‣ Crafting
    Interpretable Embeddings by Asking LLMs Questions")C) align with language-specific
    areas that are seen in the literature [[56](#bib.bib56), [78](#bib.bib78)]. They
    do not show any major diversions from transformer-based encoding models ([Fig. 2](#S4.F2
    "In 4.2 fMRI predictive performance ‣ 4 Main results: fMRI interpretation ‣ Crafting
    Interpretable Embeddings by Asking LLMs Questions")D), with the distribution of
    differences being inconsistent across subjects (see  [Fig. A1](#A1.F1 "In A.2
    fMRI prediction results extended ‣ Appendix A Appendix ‣ Crafting Interpretable
    Embeddings by Asking LLMs Questions")).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/19f7d60d7ba61044eda6ab7fd680170d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Learned feature weights for 3 example questions capture known selectivity
    and are consistent across subjects. All feature weights are jointly rescaled to
    the range (-1, 1) for visualization. Abbreviations: Pr = precuneus, pTemp = posterior
    temporal cortex, PFC = prefrontal cortex, IPS = intraparietal sulcus, RSC = retrosplenial
    complex, OPA = occipital place area, PPA = parahippocampal place area, Broca =
    Broca’s area, sPMv = superior premotor ventral speech area, AC = auditory cortex.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Interpreting the fitted representation from QA-Emb
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The QA-Emb representation enables not only identifying which questions are
    important for fMRI prediction, but also mapping their selectivity across the cortex.
    We analyze the QA-Emb model which uses 29 questions and visualize the learned
    regression weights for different questions. [Fig. 3](#S4.F3 "In 4.2 fMRI predictive
    performance ‣ 4 Main results: fMRI interpretation ‣ Crafting Interpretable Embeddings
    by Asking LLMs Questions") shows example flatmaps of the regression coefficients
    for 3 of the questions across the 2 best-predicted subjects (S02 and S03). Learned
    feature weights for the example questions capture known selectivity and are highly
    consistent across subjects. In particular, the weights for the question "Does
    the sentence involve a description of a physical environment or setting?" captures
    classical place areas including occipital place area [[79](#bib.bib79)] and retrosplenial
    complex [[80](#bib.bib80)], as well as intraparietal sulcus [[81](#bib.bib81)].
    The weights for the question "Is the sentence grammatically complex?" bear striking
    similarity to the language network [[78](#bib.bib78), [82](#bib.bib82)], which
    is itself localized from a contrast between sentences and nonwords. Other questions,
    such as "Does the sentence describe a physical action?", which has strong right
    laterality, do not have a strong basis in prior literature. These questions point
    to potentially new insights into poorly understood cortical regions.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Evaluating the limitations of QA-Emb
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1 Improving computational efficiency via model distillation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 1: Mean test correlation when comparing QA-Emb computed via many LLM
    calls to QA-Emb computed via a single distilled model. Distillation does not significantly
    degrade performance. All standard errors of the mean are below $10^{-3}$.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | QA-Emb | QA-Emb (distill, binary) | QA-Emb (distill, probabilistic) |
    Eng1000 |'
  prefs: []
  type: TYPE_TB
- en: '| UTS01 | 0.081 | 0.083 | 0.080 | 0.077 |'
  prefs: []
  type: TYPE_TB
- en: '| UTS02 | 0.124 | 0.118 | 0.118 | 0.096 |'
  prefs: []
  type: TYPE_TB
- en: '| UTS03 | 0.136 | 0.132 | 0.142 | 0.117 |'
  prefs: []
  type: TYPE_TB
- en: '| AVG | 0.114 | 0.111 | 0.113 | 0.097 |'
  prefs: []
  type: TYPE_TB
- en: To reduce the computational cost of running inference with QA-Emb, we explore
    distilling the many LLM calls needed to compute QA-Emb into a single model with
    many classification heads. Specifically, we finetune a RoBERTa model [[83](#bib.bib83)]
    (roberta-base) with 674 classification heads to predict all answers required for
    QA-Emb in a single feedforward pass. We finetune the model on answers from LLaMA-3
    8B with a few-shot prompt for 80% of the 10-grams in the 82 fMRI training stories
    (123,203 examples), use the remaining 20% as a validation set for early stopping
    (30,801 examples), and evaluate on all 10-grams in the 2 testing stories (4,594
    examples). We finetune using AdamW [[84](#bib.bib84)] with a learning rate of
    $5\cdot 10^{-5}$.
  prefs: []
  type: TYPE_NORMAL
- en: When evaluated on the fMRI prediction task, the distilled model (QA-Emb (distill,
    binary) in [Table 1](#S5.T1 "In 5.1 Improving computational efficiency via model
    distillation ‣ 5 Evaluating the limitations of QA-Emb ‣ Crafting Interpretable
    Embeddings by Asking LLMs Questions")) yields a performance only slightly below
    the original model. If we relax the restriction that the finetuned model yields
    binary embeddings and instead use the predicted probability for yes, the performance
    rises slightly to nearly match the original model (0.113 instead of 0.114 average
    test correlation) and maintains a significant improvement over the Eng1000 baseline.
    Note that the distilled model achieves an 88.5% match for yes/no answers on 10-grams
    for the test set. Nevertheless, the fMRI prediction for any given timepoint is
    computed from many questions and ngrams, mitigating the effect of individual errors
    in answering a question.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Evaluating question-answering faithfulness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a11f4237d0772061cb3a3ca5828f29c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Performance of question-answering for underlying LLMs on the D3 collection
    of binary classification datasets. Each point shows an individual dataset and
    error bars show the 95% confidence interval.'
  prefs: []
  type: TYPE_NORMAL
- en: We evaluate the faithfulness of our question-answering models on a recent diverse
    collection of 54 binary classification datasets [[85](#bib.bib85), [86](#bib.bib86)]
    (see data details in [Table A4](#A1.T4 "In A.5 Details on question-answering evaluation
    datasets ‣ Appendix A Appendix ‣ Crafting Interpretable Embeddings by Asking LLMs
    Questions")). These datasets are difficult, as they are intended to encompass
    a wider-ranging and more realistic list of questions than traditional NLP datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '[Fig. 4](#S5.F4 "In 5.2 Evaluating question-answering faithfulness ‣ 5 Evaluating
    the limitations of QA-Emb ‣ Crafting Interpretable Embeddings by Asking LLMs Questions")
    shows the classification accuracy for the 3 LLMs used previously along with GPT-3.5
    (gpt-3.5-turbo-0125). On average, each of the LLMs answers these questions with
    fairly high accuracy, with GPT-4 slightly outperforming the other models. However,
    we observe poor performance on some tasks, which we attribute to the task difficulty
    and the lack of task-specific prompt engineering. For example, the dataset yielding
    the lowest accuracy asks the question Is the input about math research?. While
    this may seem like a fairly simple question for an LLM to answer, the examples
    in the negative class consist of texts from other quantitative fields (e.g. chemistry)
    that usually contain numbers, math notation, and statistical analysis. Thus the
    LLMs answer yes to most examples and achieve accuracy near chance (50%). Note
    that these tasks are more difficult than the relatively simple questions we answer
    in the fMRI experiments, especially since the fMRI input lengths are each 10 words,
    whereas the input lengths for these datasets are over 50 words on average (with
    some inputs spanning over 1,000 words).'
  prefs: []
  type: TYPE_NORMAL
- en: '6 Secondary results: evaluating QA-Emb in simple NLP tasks'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 6.1 Benchmarking QA-Emb for information retrieval
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we investigate applying QA-Emb to a simplified information
    retrieval task. We take a random subset of 4,000 queries from the MSMarco dataset
    ([[87](#bib.bib87)], Creative Commons License) and their corresponding groundtruth
    documents, resulting in 5,210 documents. We use 25% of the queries to build a
    training set and keep the remaining 75% for testing. For evaluation, we calculate
    the cosine similarity match between the embeddings for each query and its groundtruth
    documents using mean reciprocal rank and recall.
  prefs: []
  type: TYPE_NORMAL
- en: To compute QA-Emb, we first generate 2,000 questions through prompting GPT-4
    based on its knowledge of queries in information retrieval (see prompts in the
    Github). We use a regex to slightly rewrite the resulting questions for queries
    to apply to documents (e.g. Is this query related to a specific timeframe? $\to$
    Is this text related to a specific timeframe?). We then answer the questions both
    for each query and for each corpus document, again using LLaMA-3 8B. Rather than
    fitting a ridge regression as in [Eq. 1](#S2.E1 "In Learning a set of yes/no questions
    ‣ 2 Methods ‣ Crafting Interpretable Embeddings by Asking LLMs Questions"), we
    use the training set to learn a scalar for each question that multiplies its binary
    output to change both its sign and magnitude in the embedding (optimization details
    in [Sec. A.4](#A1.SS4 "A.4 Information retrieval details ‣ Appendix A Appendix
    ‣ Crafting Interpretable Embeddings by Asking LLMs Questions")).
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 2](#S6.T2 "In 6.1 Benchmarking QA-Emb for information retrieval ‣ 6
    Secondary results: evaluating QA-Emb in simple NLP tasks ‣ Crafting Interpretable
    Embeddings by Asking LLMs Questions") shows the information retrieval results.
    Combining BM-25 with QA-Emb achieves a small but significant improvement over
    the interpretable baselines. QA-Emb on its own achieves modest performance, slightly
    improving slightly over a bag-of-words representation, but significantly underperforming
    BM-25. Nevertheless, its size is considerably smaller than the other interpretable
    baselines making it quicker to interpret and to use for retrieval.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Information retrieval results for different interpretable embedding
    models. QA-Emb in combination with BM-25 achieves a slight improvement over the
    interpretable baselines. QA-Emb additionally yields reasonably strong performance
    compared to its embedding size. ^†Note that QA-Emb embeddings are binary, so the
    raw number of dimensions overrepresents the embedding’s size relative to other
    methods. Error bars show standard error of the mean.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Mean reciprocal rank | Recall@1 | Recall@5 | Size |'
  prefs: []
  type: TYPE_TB
- en: '| Bag of words | 0.37$\pm$.01 | 0.28$\pm$.02 | 0.42$\pm$.02 | 27,677 |'
  prefs: []
  type: TYPE_TB
- en: '| Bag of bigrams | 0.39$\pm$.01 | 0.30$\pm$.02 | 0.44$\pm$.02 | 197,924 |'
  prefs: []
  type: TYPE_TB
- en: '| Bag of trigrams | 0.39$\pm$.02 | 0.30$\pm$.02 | 0.44$\pm$.02 | 444,403 |'
  prefs: []
  type: TYPE_TB
- en: '| QA-Emb | 0.45$\pm$.01 | 0.34$\pm$.01 | 0.50$\pm$.01 | ^†2,000 |'
  prefs: []
  type: TYPE_TB
- en: '| BM-25 | 0.77$\pm$.01 | 0.69$\pm$.01 | 0.82$\pm$.01 | 27,677 |'
  prefs: []
  type: TYPE_TB
- en: '| BM-25 + QA-Emb | 0.80$\pm$.01 | 0.71$\pm$.01 | 0.84$\pm$.01 | 29,677 |'
  prefs: []
  type: TYPE_TB
- en: 6.2 Zero-shot adaptation in text clustering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We now investigate QA-Emb in a simplified text clustering setting. To do so,
    we study 4 text-classification datasets: Financial phrasebank ([[88](#bib.bib88)],
    creative commons license), Emotion [[89](#bib.bib89)] (CC BY-SA 4.0 license),
    AGNews [[90](#bib.bib90)], and Rotten tomatoes [[91](#bib.bib91)]. For each dataset,
    we treat each class as a cluster and evaluate the clustering score, defined as
    the difference between the average inter-class embedding distance and the average
    intra-class embedding distance (embedding distance is measured via Euclidean distance).
    A larger clustering score suggests that embeddings are well-clustered within each
    class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our experiment, we build a 100-dimensional embedding by prompting GPT-4
    to generate 25 yes/no questions related to the semantic content of each dataset
    (e.g. for Rotten tomatoes, Generate 25 yes/no questions related to movie reviews).
    We then concatenate the answers for all 100 questions to form our embedding. These
    general embeddings do not yield particularly strong clustering scores ([Table 3](#S6.T3
    "In 6.2 Zero-shot adaptation in text clustering ‣ 6 Secondary results: evaluating
    QA-Emb in simple NLP tasks ‣ Crafting Interpretable Embeddings by Asking LLMs
    Questions") top), as the questions are diverse and not particularly selective
    for each dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, simply through prompting, we can adapt these general embeddings to
    each individual dataset. We call GPT-4 with a prompt that includes the full list
    of questions and ask it to select a subset of questions that are relevant to each
    task. The result embeddings ([Table 3](#S6.T3 "In 6.2 Zero-shot adaptation in
    text clustering ‣ 6 Secondary results: evaluating QA-Emb in simple NLP tasks ‣
    Crafting Interpretable Embeddings by Asking LLMs Questions") bottom) yield higher
    clustering scores, suggesting that QA-Emb can be adapted to each task in a zero-shot
    manner (in this simplified setting). Moreover, the resulting task-specific embeddings
    are now considerably smaller.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Clustering scores before and after zero-shot adaptation (higher is
    better). Errors give standard error of the mean.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Rotten tomatoes | AG News | Emotion | Financial phrasebank | AVG | Embedding
    size (AVG) |'
  prefs: []
  type: TYPE_TB
- en: '| Original | 0.126$\pm$0.011 | 0.124$\pm$0.007 | 0.046$\pm$0.007 | 0.084$\pm$0.008
    | 0.095 | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| Adapted | 0.248$\pm$0.016 | 0.166$\pm$0.012 | 0.057$\pm$0.010 | 0.292$\pm$0.017
    | 0.191 | 25.75$\pm$0.95 |'
  prefs: []
  type: TYPE_TB
- en: 7 Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We find that QA-Emb can effectively produce interpretable and high-performing
    text embeddings. While we focus on a language fMRI setting, QA-Emb may be able
    to help flexibly build an interpretable text feature space in a variety of domains,
    such as social science [[9](#bib.bib9)], medicine [[10](#bib.bib10)], or economics [[92](#bib.bib92)],
    where meaningful properties of text can help discover something about an underlying
    phenomenon or build trust in high-stakes settings. Alternatively, it could be
    used in mechanistic interpretability, to help improve post-hoc explanations of
    learned LLM representations.
  prefs: []
  type: TYPE_NORMAL
- en: As LLMs improve in both efficiency and capability, QA-Emb can be incorporated
    into a variety of common NLP applications as well, such as RAG or information
    retrieval. For example, in RAG systems such as RAPTOR [[93](#bib.bib93)] or Graph-RAG [[94](#bib.bib94)],
    explanations may help an LLM not only retrieve relevant texts, but also specify
    why they are relevant and how they may be helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Learning text questions rather than model weights is a challenging research
    area, furthering work in automatic prompt engineering [[15](#bib.bib15), [16](#bib.bib16)].
    Our approach takes a heuristic first step at solving this problem, but future
    work could explore more directly optimizing the set of learned questions $Q$ in
    [Eq. 1](#S2.E1 "In Learning a set of yes/no questions ‣ 2 Methods ‣ Crafting Interpretable
    Embeddings by Asking LLMs Questions") via improved discrete optimization approaches
    and constraints. One possible approach may involve having LLMs themselves identify
    the errors the current model is making and improving based on these errors, similar
    to general trends in LLM self-improvement and autoprompting [[95](#bib.bib95),
    [96](#bib.bib96), [97](#bib.bib97), [98](#bib.bib98)]. Another approach may involve
    improving the explanation capabilities of LLMs to help extract more questions
    more faithfully from data [[99](#bib.bib99), [100](#bib.bib100)].
  prefs: []
  type: TYPE_NORMAL
- en: Broader Impacts
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: QA-Emb seeks to advance the field of LLM interpretation, a crucial step toward
    addressing the challenges posed by these often opaque models. Although LLMs have
    gained widespread use, their lack of transparency can lead to significant harm,
    underscoring the importance of interpretable AI. There are many potential positive
    societal consequences of this form of interpretability, e.g., facilitating a better
    understanding of scientific data and models, along with a better understanding
    of LLMs and how to use them safely. Nevertheless, as is the case with most ML
    research, the interpretations could be used to interpret and potentially improve
    an LLM or dataset that is being used for nefarious purposes. Moreover, QA-Emb
    requires substantial computational resources, contributing to increased concerns
    over sustainability.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Stephen Robertson, Hugo Zaragoza, et al. The probabilistic relevance framework:
    Bm25 and beyond. Foundations and Trends® in Information Retrieval, 3(4):333–389,
    2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using
    siamese bert-networks. arXiv preprint arXiv:1908.10084, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Omar Khattab and Matei Zaharia. Colbert: Efficient and effective passage
    search via contextualized late interaction over bert. In Proceedings of the 43rd
    International ACM SIGIR Conference on Research and Development in Information
    Retrieval, SIGIR ’20, New York, NY, USA, 2020\. Association for Computing Machinery.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Tianyu Gao, Xingcheng Yao, and Danqi Chen. Simcse: Simple contrastive learning
    of sentence embeddings. arXiv preprint arXiv:2104.08821, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Niklas Muennighoff. Sgpt: Gpt sentence embeddings for semantic search.
    arXiv preprint arXiv:2202.08904, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder, and
    Furu Wei. Improving text embeddings with large language models. arXiv preprint
    arXiv:2401.00368, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan
    Zhang. Towards general text embeddings with multi-stage contrastive learning.
    arXiv preprint arXiv:2308.03281, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Shailee Jain, Vy A Vo, Leila Wehbe, and Alexander G Huth. Computational
    language modeling and the promise of in silico experimentation. Neurobiology of
    Language, 5(1):80–106, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi
    Yang. Can large language models transform computational social science? arXiv
    preprint arXiv:2305.03514, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Xiao Zhang, Dejing Dou, and Ji Wu. Learning conceptual-contextual embeddings
    for medical text. In Proceedings of the AAAI Conference on Artificial Intelligence,
    volume 34, pages 9579–9586, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Bryce Goodman and Seth Flaxman. European union regulations on algorithmic
    decision-making and a" right to explanation". arXiv preprint arXiv:1606.08813,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman,
    and Dan Mané. Concrete problems in ai safety. arXiv preprint arXiv:1606.06565,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Iason Gabriel. Artificial intelligence, values, and alignment. Minds and
    machines, 30(3):411–437, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, and Jianfeng
    Gao. Rethinking interpretability in the era of large language models. arXiv preprint
    arXiv:2402.01761, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu
    Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt
    engineers. arXiv preprint arXiv:2211.01910, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Chandan Singh, John X Morris, Jyoti Aneja, Alexander M Rush, and Jianfeng
    Gao. Explaining patterns in data with language models via interpretable autoprompting.
    arXiv preprint arXiv:2210.01848, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Steven Bills, Nick Cammarata, Dan Mossing, William Saunders, Jeff Wu,
    Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever, and Jan Leike. Language models
    can explain neurons in language models. [https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html](https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html),
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Chandan Singh, Aliyah R Hsu, Richard Antonello, Shailee Jain, Alexander G
    Huth, Bin Yu, and Jianfeng Gao. Explaining black box text modules in natural language
    with language models. arXiv preprint arXiv:2305.09863, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz
    Hardt, and Been Kim. Sanity checks for saliency maps. In Advances in Neural Information
    Processing Systems, pages 9505–9515, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Finale Doshi-Velez and Been Kim. A roadmap for a rigorous science of interpretability.
    arXiv preprint arXiv:1702.08608, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Tal Yarkoni. The generalizability crisis. Behavioral and Brain Sciences,
    45:e1, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Alexander G Huth, Wendy A De Heer, Thomas L Griffiths, Frédéric E Theunissen,
    and Jack L Gallant. Natural speech reveals the semantic maps that tile human cerebral
    cortex. Nature, 532(7600):453–458, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert:
    Pre-training of deep bidirectional transformers for language understanding. arXiv
    preprint arXiv:1810.04805, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] OpenAI. GPT-4 technical report. arXiv:2303.08774, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Hui Zou and Trevor Hastie. Regularization and variable selection via the
    elastic net. Journal of the Royal Statistical Society Series B: Statistical Methodology,
    67(2):301–320, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier, LÃ©lio Renard Lavaud, Marie-Anne Lachaux, Pierre
    Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, TimothÃ©e Lacroix, and William El
    Sayed. Mistral 7b, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] AI@Meta. Llama 3 model card. 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Kyoung-Rok Jang, Junmo Kang, Giwon Hong, Sung-Hyon Myaeng, Joohee Park,
    Taewon Yoon, and Heecheol Seo. Ultra-high dimensional sparse representations with
    binarization for efficient text retrieval. arXiv preprint arXiv:2104.07198, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Aditya Kusupati, Gantavya Bhatt, Aniket Rege, Matthew Wallingford, Aditya
    Sinha, Vivek Ramanujan, William Howard-Snyder, Kaifeng Chen, Sham Kakade, Prateek
    Jain, et al. Matryoshka representation learning. Advances in Neural Information
    Processing Systems, 35:30233–30249, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Jacob Mitchell Springer, Suhas Kotha, Daniel Fried, Graham Neubig, and
    Aditi Raghunathan. Repetition improves language model embeddings. arXiv preprint
    arXiv:2402.15449, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Jinhyuk Lee, Zhuyun Dai, Xiaoqi Ren, Blair Chen, Daniel Cer, Jeremy R.
    Cole, Kai Hui, Michael Boratko, Rajvi Kapadia, Wen Ding, Yi Luan, Sai Meher Karthik
    Duddu, Gustavo Hernandez Abrego, Weiqiang Shi, Nithi Gupta, Aditya Kusupati, Prateek
    Jain, Siddhartha Reddy Jonnalagadda, Ming-Wei Chang, and Iftekhar Naim. Gecko:
    Versatile text embeddings distilled from large language models, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Shengyao Zhuang, Xueguang Ma, Bevan Koopman, Jimmy Lin, and Guido Zuccon.
    Promptreps: Prompting large language models to generate dense and sparse representations
    for zero-shot document retrieval, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Chandan Singh, John Morris, Alexander M Rush, Jianfeng Gao, and Yuntian
    Deng. Tree prompting: Efficient task adaptation without fine-tuning. In Proceedings
    of the 2023 Conference on Empirical Methods in Natural Language Processing, pages
    6253–6267, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Josh Magnus Ludan, Qing Lyu, Yue Yang, Liam Dugan, Mark Yatskar, and Chris
    Callison-Burch. Interpretable-by-design text classification with iteratively generated
    concept bottleneck. arXiv preprint arXiv:2310.19660, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Letian Peng, Yuwei Zhang, Zilong Wang, Jayanth Srinivasa, Gaowen Liu,
    Zihan Wang, and Jingbo Shang. Answer is all you need: Instruction-following text
    embedding via answering the question. arXiv preprint arXiv:2402.09642, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation
    of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove:
    Global vectors for word representation. In Proceedings of the 2014 conference
    on empirical methods in natural language processing (EMNLP), pages 1532–1543,
    2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Chandan Singh, Armin Askari, Rich Caruana, and Jianfeng Gao. Augmenting
    interpretable models with large language models during training. Nature Communications,
    14(1):7913, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Alexis Conneau, German Kruszewski, Guillaume Lample, Loïc Barrault, and
    Marco Baroni. What you can cram into a single vector: Probing sentence embeddings
    for linguistic properties. arXiv preprint arXiv:1805.01070, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] Frederick Liu and Besim Avci. Incorporating priors with feature attribution
    on text classification. arXiv preprint arXiv:1906.08286, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba.
    Network dissection: Quantifying interpretability of deep visual representations.
    In Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 6541–6549, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] David Bau, Jun-Yan Zhu, Hendrik Strobelt, Agata Lapedriza, Bolei Zhou,
    and Antonio Torralba. Understanding the role of individual units in a deep neural
    network. Proceedings of the National Academy of Sciences, 117(48):30071–30078,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii,
    and Dimitris Bertsimas. Finding neurons in a haystack: Case studies with sparse
    probing, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Nicholas Bai, Rahul A Iyer, Tuomas Oikarinen, and Tsui-Wei Weng. Describe-and-dissect:
    Interpreting neurons in vision networks with language models. arXiv preprint arXiv:2403.13771,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Sarah Schwettmann, Evan Hernandez, David Bau, Samuel Klein, Jacob Andreas,
    and Antonio Torralba. Toward a visual concept vocabulary for gan latent space.
    In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages
    6804–6812, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Ruochen Zhao, Shafiq Joty, Yongjie Wang, and Tan Wang. Explaining language
    models’ predictions with high-impact concepts. arXiv preprint arXiv:2305.02160,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Yibo Jiang, Bryon Aragam, and Victor Veitch. Uncovering meanings of embeddings
    via partial orthogonality. Advances in Neural Information Processing Systems,
    36, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] Tuomas Oikarinen and Tsui-Wei Weng. Clip-dissect: Automatic description
    of neuron representations in deep vision networks. arXiv preprint arXiv:2204.10965,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Tuomas Oikarinen, Subhro Das, Lam M Nguyen, and Tsui-Wei Weng. Label-free
    concept bottleneck models. arXiv preprint arXiv:2304.06129, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Usha Bhalla, Alex Oesterling, Suraj Srinivas, Flavio P Calmon, and Himabindu
    Lakkaraju. Interpreting clip with sparse linear concept embeddings (splice). arXiv
    preprint arXiv:2402.10376, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Yue Yang, Artemis Panagopoulou, Shenghao Zhou, Daniel Jin, Chris Callison-Burch,
    and Mark Yatskar. Language in a bottle: Language model guided concept bottlenecks
    for interpretable image classification. In Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pages 19187–19197, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Aya Abdelsalam Ismail, Julius Adebayo, Hector Corrada Bravo, Stephen Ra,
    and Kyunghyun Cho. Concept bottleneck generative models. In The Twelfth International
    Conference on Learning Representations, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] Ruoyu Chen, Jingzhi Li, Hua Zhang, Changchong Sheng, Li Liu, and Xiaochun
    Cao. Sim2word: Explaining similarity with representative attribute words via counterfactual
    explanations. ACM Trans. Multimedia Comput. Commun. Appl., 19(6), jul 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] Karthikeyan Natesan Ramamurthy, Amit Dhurandhar, Dennis Wei, and Zaid Bin
    Tariq. Analogies and feature attributions for model agnostic explanation of similarity
    learners. arXiv preprint arXiv:2202.01153, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Martin Schrimpf, Idan Asher Blank, Greta Tuckute, Carina Kauf, Eghbal A
    Hosseini, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina Fedorenko. The neural
    architecture of language: Integrative modeling converges on predictive processing.
    Proceedings of the National Academy of Sciences, 118(45):e2105646118, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Richard Antonello, Aditya Vaidya, and Alexander Huth. Scaling laws for
    language encoding models in fmri. Advances in Neural Information Processing Systems,
    36, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Shailee Jain and Alexander Huth. Incorporating context into language encoding
    models for fmri. Advances in neural information processing systems, 31, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] Leila Wehbe, Ashish Vaswani, Kevin Knight, and Tom Mitchell. Aligning
    context-based statistical models of language with brain activity during reading.
    In Proceedings of the 2014 Conference on Empirical Methods in Natural Language
    Processing (EMNLP), pages 233–243, Doha, Qatar, October 2014\. Association for
    Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Mariya Toneva and Leila Wehbe. Interpreting and improving natural-language
    processing (in machines) with natural language-processing (in the brain). In H. Wallach,
    H. Larochelle, A. Beygelzimer, F. d''Alché-Buc, E. Fox, and R. Garnett, editors,
    Advances in Neural Information Processing Systems, volume 32\. Curran Associates,
    Inc., 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Ariel Goldstein, Zaid Zada, Eliav Buchnik, Mariano Schain, Amy Price,
    Bobbi Aubrey, Samuel A. Nastase, Amir Feder, Dotan Emanuel, Alon Cohen, Aren Jansen,
    Harshvardhan Gazula, Gina Choe, Aditi Rao, Catherine Kim, Colton Casto, Lora Fanda,
    Werner Doyle, Daniel Friedman, Patricia Dugan, Lucia Melloni, Roi Reichart, Sasha
    Devore, Adeen Flinker, Liat Hasenfratz, Omer Levy, Avinatan Hassidim, Michael
    Brenner, Yossi Matias, Kenneth A. Norman, Orrin Devinsky, and Uri Hasson. Shared
    computational principles for language processing in humans and deep language models.
    Nature Neuroscience, 25(3):369–380, March 2022. Number: 3 Publisher: Nature Publishing
    Group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] John T. Hale, Luca Campanelli, Jixing Li, Shohini Bhattasali, Christophe
    Pallier, and Jonathan R. Brennan. Neurocomputational models of language processing.
    Annual Review of Linguistics, 8(1):427–446, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] Shailee Jain, Vy A. Vo, Leila Wehbe, and Alexander G. Huth. Computational
    Language Modeling and the Promise of in Silico Experimentation. Neurobiology of
    Language, pages 1–27, March 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Michael C.-K. Wu, Stephen V. David, and Jack L. Gallant. Complete functional
    characterization of sensory neurons by system identification. Annual Review of
    Neuroscience, 29:477–505, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] Shailee Jain, Vy Vo, Shivangi Mahto, Amanda LeBel, Javier S Turek, and
    Alexander Huth. Interpretable multi-timescale models for predicting fmri responses
    to continuous natural speech. In H. Larochelle, M. Ranzato, R. Hadsell, M. F.
    Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems,
    volume 33, pages 13738–13749\. Curran Associates, Inc., 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] Catherine Chen, Tom Dupré la Tour, Jack Gallant, Daniel Klein, and Fatma
    Deniz. The cortical representation of language timescales is shared between reading
    and listening. bioRxiv, pages 2023–01, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Sara F Popham, Alexander G Huth, Natalia Y Bilenko, Fatma Deniz, James S
    Gao, Anwar O Nunez-Elizalde, and Jack L Gallant. Visual and linguistic semantic
    representations are aligned at the border of human visual cortex. Nature neuroscience,
    24(11):1628–1636, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Charlotte Caucheteux, Alexandre Gramfort, and Jean-Remi King. Disentangling
    syntax and semantics in the brain with deep networks. In Proceedings of the 38th
    International Conference on Machine Learning, pages 1336–1348\. PMLR, July 2021.
    ISSN: 2640-3498.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Carina Kauf, Greta Tuckute, Roger Levy, Jacob Andreas, and Evelina Fedorenko.
    Lexical semantic content, not syntactic structure, is the main contributor to
    ann-brain similarity of fmri responses in the language network. bioRxiv, pages
    2023–05, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] Aniketh Janardhan Reddy and Leila Wehbe. Can fMRI reveal the representation
    of syntactic structure in the brain? preprint, Neuroscience, June 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] Alexandre Pasquiou, Yair Lakretz, Bertrand Thirion, and Christophe Pallier.
    Information-Restricted Neural Language Models Reveal Different Brain Regions’
    Sensitivity to Semantics, Syntax and Context, February 2023. arXiv:2302.14389
    [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] Khai Loong Aw and Mariya Toneva. Training language models for deeper understanding
    improves brain alignment, December 2022. arXiv:2212.10898 [cs, q-bio].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] Sreejan Kumar, Theodore R. Sumers, Takateru Yamakoshi, Ariel Goldstein,
    Uri Hasson, Kenneth A. Norman, Thomas L. Griffiths, Robert D. Hawkins, and Samuel A.
    Nastase. Reconstructing the cascade of language processing in the brain using
    the internal computations of a transformer-based language model. Technical report,
    bioRxiv, June 2022. Section: New Results Type: article.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] Subba Reddy Oota, Manish Gupta, and Mariya Toneva. Joint processing of
    linguistic properties in brains and language models, December 2022. arXiv:2212.08094
    [cs, q-bio].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] Amanda LeBel, Lauren Wagner, Shailee Jain, Aneesh Adhikari-Desai, Bhavin
    Gupta, Allyson Morgenthal, Jerry Tang, Lixiang Xu, and Alexander G Huth. A natural
    language fmri dataset for voxelwise encoding models. bioRxiv, pages 2022–09, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Jerry Tang, Amanda LeBel, Shailee Jain, and Alexander G Huth. Semantic
    reconstruction of continuous language from non-invasive brain recordings. Nature
    Neuroscience, pages 1–9, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Fabian Pedregosa, Ga ë l Varoquaux, Alexandre Gramfort, Vincent Michel,
    Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss,
    Vincent Dubourg, et al. Scikit-learn: Machine learning in python. the Journal
    of machine Learning research, 12(Oct):2825–2830, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
    Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
    et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] Evelina Fedorenko, Anna A Ivanova, and Tamar I Regev. The language network
    as a natural kind within the broader landscape of the human brain. Nature Reviews
    Neuroscience, pages 1–24, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Joshua B Julian, Jack Ryan, Roy H Hamilton, and Russell A Epstein. The
    occipital place area is causally involved in representing environmental boundaries
    during navigation. Current Biology, 26(8):1104–1109, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Anna S Mitchell, Rafal Czajkowski, Ningyu Zhang, Kate Jeffery, and Andrew JD
    Nelson. Retrosplenial cortex and its role in spatial cognition. Brain and neuroscience
    advances, 2:2398212818757098, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] Ilenia Salsano, Valerio Santangelo, and Emiliano Macaluso. The lateral
    intraparietal sulcus takes viewpoint changes into account during memory-guided
    attention in natural scenes. Brain Structure and Function, 226(4):989–1006, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] Saima Malik-Moraleda, Dima Ayyash, Jeanne Gallée, Josef Affourtit, Malte
    Hoffmann, Zachary Mineroff, Olessia Jouravlev, and Evelina Fedorenko. An investigation
    across 45 languages and 12 language families reveals a universal language network.
    Nature Neuroscience, 25(8):1014–1019, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen,
    Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly
    optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization.
    arXiv preprint arXiv:1711.05101, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] Ruiqi Zhong, Kristy Lee, Zheng Zhang, and Dan Klein. Adapting language
    models for zero-shot learning by meta-tuning on dataset and prompt collections.
    arXiv preprint arXiv:2104.04670, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] Ruiqi Zhong, Charlie Snell, Dan Klein, and Jacob Steinhardt. Describing
    differences between text distributions with natural language. In International
    Conference on Machine Learning, pages 27099–27116\. PMLR, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan
    Majumder, and Li Deng. Ms marco: A human-generated machine reading comprehension
    dataset. 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] P. Malo, A. Sinha, P. Korhonen, J. Wallenius, and P. Takala. Good debt
    or bad debt: Detecting semantic orientations in economic texts. Journal of the
    Association for Information Science and Technology, 65, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Elvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang, Junlin Wu, and Yi-Shin
    Chen. CARER: Contextualized affect representations for emotion recognition. In
    Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,
    pages 3687–3697, Brussels, Belgium, October-November 2018\. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional
    networks for text classification. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama,
    and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 28\.
    Curran Associates, Inc., 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships
    for sentiment categorization with respect to rating scales. In Proceedings of
    the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),
    pages 115–124, Ann Arbor, Michigan, June 2005\. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] Anton Korinek. Language models and cognitive automation for economic research.
    Technical report, National Bureau of Economic Research, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh Khanna, Anna Goldie,
    and Christopher D Manning. Raptor: Recursive abstractive processing for tree-organized
    retrieval. arXiv preprint arXiv:2401.18059, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva
    Mody, Steven Truitt, and Jonathan Larson. From local to global: A graph rag approach
    to query-focused summarization. arXiv preprint arXiv:2404.16130, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] Ruiqi Zhong, Peter Zhang, Steve Li, Jinwoo Ahn, Dan Klein, and Jacob Steinhardt.
    Goal driven discovery of distributional differences via language descriptions.
    arXiv preprint arXiv:2302.14233, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou,
    and Xinyun Chen. Large language models as optimizers. arXiv preprint arXiv:2309.03409,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang,
    Nebojsa Jojic, Eric P Xing, and Zhiting Hu. Promptagent: Strategic planning with
    language models enables expert-level prompt optimization. arXiv preprint arXiv:2310.16427,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar,
    Jing Xu, and Jason Weston. Self-rewarding language models. arXiv preprint arXiv:2401.10020,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] Afra Feyza Akyürek, Ekin Akyürek, Leshem Choshen, Derry Wijaya, and Jacob
    Andreas. Deductive closure training of language models for coherence, accuracy,
    and updatability. arXiv preprint arXiv:2401.08574, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] Yanda Chen, Chandan Singh, Xiaodong Liu, Simiao Zuo, Bin Yu, He He, and
    Jianfeng Gao. Towards consistent natural-language explanations via explanation-consistency
    finetuning. arXiv preprint arXiv:2401.13986, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization.
    arXiv preprint arXiv:1412.6980, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A.1 fMRI question details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table A1: Questions list for model with 29 questions. Importance denotes the
    average absolute coefficient for each question (normalized by the importance of
    the top question).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Question | Importance |'
  prefs: []
  type: TYPE_TB
- en: '| Is the sentence expressing skepticism or disbelief towards something or someone?
    | 1.000 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence include dialogue? | 0.983 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence describe a relationship between people? | 0.924 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence involve the mention of a specific object or item? | 0.900
    |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence include technical or specialized terminology? | 0.882 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence contain a proper noun? | 0.861 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the input involve planning or organizing? | 0.861 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence include numerical information? | 0.850 |'
  prefs: []
  type: TYPE_TB
- en: '| Is time mentioned in the input? | 0.844 |'
  prefs: []
  type: TYPE_TB
- en: '| Is the sentence grammatically complex? | 0.815 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence include dialogue or thoughts directed towards another character?
    | 0.811 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence describe a physical action? | 0.809 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence include a conditional clause? | 0.782 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence describe a visual experience or scene? | 0.771 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the input include a philosophical or reflective thought? | 0.759 |'
  prefs: []
  type: TYPE_TB
- en: '| Is the sentence conveying the narrator’s physical movement or action in detail?
    | 0.749 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence describe a physical sensation? | 0.744 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence involve a discussion about personal or social values? |
    0.739 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence reference a specific time or date? | 0.719 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence express a philosophical or existential query or observation?
    | 0.705 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence involve a description of physical environment or setting?
    | 0.693 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the input describe a sensory experience? | 0.688 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence involve planning or decision-making? | 0.684 |'
  prefs: []
  type: TYPE_TB
- en: '| Is the sentence a command? | 0.682 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence describe a specific sensation or feeling? | 0.672 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence contain a cultural reference? | 0.667 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the input include dialogue between characters? | 0.594 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence mention a specific location or place? | 0.547 |'
  prefs: []
  type: TYPE_TB
- en: '| Does the sentence reference a specific location or place? | 0.545 |'
  prefs: []
  type: TYPE_TB
- en: A.2 fMRI prediction results extended
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: \begin{overpic}[width=433.62pt,trim=0.0pt 0.0pt 284.52756pt 0.0pt,clip]{figs/flatmaps/S01_qa_flatmap.pdf}
    \put(45.0,50.0){{S01}} \end{overpic}![Refer to caption](img/27ff14a25a717cf56107c25bc2c2788b.png)  \begin{overpic}[width=433.62pt]{figs/flatmaps/S02_qa_flatmap.pdf}
    \put(45.0,50.0){{S02}} \end{overpic}![Refer to caption](img/c018af15732ad01ddeafc3391b8aa7b1.png)  \begin{overpic}[width=433.62pt]{figs/flatmaps/S03_qa_flatmap.pdf}
    \put(45.0,50.0){{S03}} \end{overpic}![Refer to caption](img/ac788dd9972f6930fac08c158fee5dba.png)
  prefs: []
  type: TYPE_NORMAL
- en: \begin{overpic}[width=433.62pt,trim=0.0pt 0.0pt 284.52756pt 0.0pt,clip]{figs/flatmaps/S01_qa-bert_flatmap.pdf}
    \put(45.0,50.0){{S01}} \end{overpic}![Refer to caption](img/df248e161c85abe7ae8d6d4c7902b4e4.png)  \begin{overpic}[width=433.62pt]{figs/flatmaps/S02_qa-bert_flatmap.pdf}
    \put(45.0,50.0){{S02}} \end{overpic}![Refer to caption](img/38b141140e5f7177180f04648ab6f891.png)  \begin{overpic}[width=433.62pt]{figs/flatmaps/S03_qa-bert_flatmap.pdf}
    \put(45.0,50.0){{S03}} \end{overpic}![Refer to caption](img/691a0137d967d2d2b798813bd862f771.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure A1: Predictive performance for QA-Emb (top row) and the difference between
    QA-Emb and BERT (bottom row).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table A2: Mean test correlation for QA-Emb with different settings: varying
    the underlying prompts to source questions and the LLM used to answer the questions
    (fixing the number of time-lagged delays to 8). Ensemble generally provides a
    small boost over other models and Mistral slightly underperforms LLaMA-3 (8B).'
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble LLaMA-3 (8B) LLaMA-3 (8B)-fewshot Mistral (7B) Subject Questions S01
    Prompts 1-3 (376 questions) 0.081 0.078 0.078 0.076 Prompts 1-5 (518 questions)
    0.089 0.085 0.085 0.082 Prompts 1-6 (674 questions) 0.084 0.081 0.085 0.076 S02
    Prompts 1-3 (376 questions) 0.120 0.112 0.119 0.112 Prompts 1-5 (518 questions)
    0.118 0.120 0.121 0.114 Prompts 1-6 (674 questions) 0.124 0.119 0.121 0.108 S03
    Prompts 1-3 (376 questions) 0.132 0.131 0.127 0.126 Prompts 1-5 (518 questions)
    0.137 0.136 0.135 0.129 Prompts 1-6 (674 questions) 0.141 0.136 0.136 0.132 AVG
    Prompts 1-3 (376 questions) 0.111 0.107 0.108 0.104 Prompts 1-5 (518 questions)
    0.115 0.114 0.114 0.108 Prompts 1-6 (674 questions) 0.116 0.112 0.114 0.105
  prefs: []
  type: TYPE_NORMAL
- en: 'Table A3: Mean test correlation for different baseline models as a function
    of hyperparameters (number of time-lagged delays and layer for extracting embeddings)'
  prefs: []
  type: TYPE_NORMAL
- en: Subject S01 S02 S03 AVG Delays 4 8 12 4 8 12 4 8 12 4 8 12 BERT 0.084 0.080
    0.075 0.114 0.108 0.107 0.136 0.139 0.136 0.111 0.109 0.106 Eng1000 0.079 0.067
    0.077 0.096 0.092 0.082 0.110 0.117 0.116 0.095 0.092 0.092 LLaMA-2 (70B) (lay
    12) 0.055 0.055 0.054 0.101 0.095 0.085 0.143 0.144 0.130 0.100 0.098 0.089 LLaMA-2
    (70B) (lay 24) 0.075 0.059 0.049 0.097 0.104 0.092 0.149 0.153 0.152 0.107 0.105
    0.098 LLaMA-2 (70B) (lay 36) 0.058 0.068 0.057 0.131 0.101 0.084 0.153 0.156 0.152
    0.114 0.108 0.098 LLaMA-2 (70B) (lay 48) 0.093 0.060 0.052 0.114 0.094 0.091 0.148
    0.151 0.149 0.118 0.102 0.098 LLaMA-2 (70B) (lay 60) 0.095 0.048 0.050 0.119 0.089
    0.088 0.148 0.152 0.150 0.121 0.097 0.096 LLaMA-2 (7B) (lay 06) 0.074 0.067 0.039
    0.120 0.088 0.084 0.138 0.144 0.133 0.111 0.100 0.085 LLaMA-2 (7B) (lay 12) 0.097
    0.058 0.053 0.116 0.111 0.087 0.150 0.155 0.152 0.121 0.108 0.097 LLaMA-2 (7B)
    (lay 18) 0.079 0.076 0.042 0.123 0.103 0.090 0.143 0.153 0.150 0.115 0.111 0.094
    LLaMA-2 (7B) (lay 24) 0.088 0.057 0.068 0.129 0.100 0.106 0.144 0.148 0.149 0.120
    0.102 0.108 LLaMA-2 (7B) (lay 30) 0.057 0.045 0.045 0.130 0.098 0.099 0.139 0.149
    0.148 0.109 0.097 0.097 LLaMA-3 (8B) (lay 06) 0.071 0.066 0.054 0.122 0.119 0.095
    0.144 0.147 0.148 0.112 0.111 0.099 LLaMA-3 (8B) (lay 12) 0.089 0.073 0.050 0.110
    0.099 0.095 0.146 0.151 0.153 0.115 0.108 0.099 LLaMA-3 (8B) (lay 18) 0.073 0.052
    0.052 0.125 0.102 0.096 0.153 0.154 0.155 0.117 0.103 0.101 LLaMA-3 (8B) (lay
    24) 0.090 0.053 0.047 0.106 0.113 0.095 0.146 0.149 0.148 0.114 0.105 0.097 LLaMA-3
    (8B) (lay 30) 0.082 0.066 0.060 0.120 0.117 0.101 0.147 0.151 0.148 0.117 0.111
    0.103
  prefs: []
  type: TYPE_NORMAL
- en: A.3 Prompts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A.3.1 Prompts for question generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Prompt 1
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generate a bulleted list of 500 diverse, non-overlapping questions that can
    be used to classify an input based on its semantic properties. Phrase the questions
    in diverse ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some example questions: {{examples}}'
  prefs: []
  type: TYPE_NORMAL
- en: Return only a bulleted list of questions and nothing else
  prefs: []
  type: TYPE_NORMAL
- en: Prompt 2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generate a bulleted list of 100 diverse, non-overlapping questions that can
    be used to classify sentences from a first-person story. Phrase the questions
    in diverse ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some example questions: {{examples}}'
  prefs: []
  type: TYPE_NORMAL
- en: Return only a bulleted list of questions and nothing else
  prefs: []
  type: TYPE_NORMAL
- en: Prompt 3
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generate a bulleted list of 200 diverse, non-overlapping questions that can
    be used to classify sentences from a first-person story. Phrase the questions
    in diverse ways.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some example questions: {{examples}}'
  prefs: []
  type: TYPE_NORMAL
- en: Return only a bulleted list of questions and nothing else
  prefs: []
  type: TYPE_NORMAL
- en: Prompt 4
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Based on what you know from the neuroscience and psychology literature, generate
    a bulleted list of 100 diverse, non-overlapping yes/no questions that ask about
    properties of a sentence that might be important for predicting brain activity.
  prefs: []
  type: TYPE_NORMAL
- en: Return only a bulleted list of questions and nothing else
  prefs: []
  type: TYPE_NORMAL
- en: Prompt 5
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Example narrative sentences {{example sentences from dataset}}
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Example yes/no questions {{example questions already asked}}
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generate a bulleted list of 100 specific, non-overlapping yes/no questions that
    ask about aspects of the example narrative sentences that are important for classifying
    them. Focus on the given narrative sentences and form questions that combine shared
    properties from multiple sentences above. Do not repeat information in the example
    questions that are already given above. Instead, generate complementary questions
    that are not covered by the example questions. Return only a bulleted list of
    questions and nothing else.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt 6
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generate more diverse questions that may occur for a single sentence in a first-person
    narrative story
  prefs: []
  type: TYPE_NORMAL
- en: See exact prompts with examples in the Github repo.
  prefs: []
  type: TYPE_NORMAL
- en: A.3.2 Prompts for question answering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Standard prompt <User>: Input text: {example}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: Answer with yes or no, then give an explanation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Few-shot prompt <System>: You are a concise, helpful assistant.'
  prefs: []
  type: TYPE_NORMAL
- en: '<User>: Input text: and i just kept on laughing because it was so'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: Does the input mention laughter?'
  prefs: []
  type: TYPE_NORMAL
- en: Answer with Yes or No.
  prefs: []
  type: TYPE_NORMAL
- en: '<Assistant>: Yes'
  prefs: []
  type: TYPE_NORMAL
- en: '<User> Input text: what a crazy day things just kept on happening'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: Is the sentence related to food preparation?'
  prefs: []
  type: TYPE_NORMAL
- en: Answer with Yes or No.
  prefs: []
  type: TYPE_NORMAL
- en: '<Assistant>: No'
  prefs: []
  type: TYPE_NORMAL
- en: '<User> Input text: i felt like a fly on the wall just waiting for'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: Does the text use a metaphor or figurative language?'
  prefs: []
  type: TYPE_NORMAL
- en: Answer with Yes or No.
  prefs: []
  type: TYPE_NORMAL
- en: '<Assistant>: Yes'
  prefs: []
  type: TYPE_NORMAL
- en: '<User> Input text: he takes too long in there getting the pans from'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: Is there a reference to sports?'
  prefs: []
  type: TYPE_NORMAL
- en: Answer with Yes or No.
  prefs: []
  type: TYPE_NORMAL
- en: Answer with Yes or No.
  prefs: []
  type: TYPE_NORMAL
- en: '<Assistant>: No'
  prefs: []
  type: TYPE_NORMAL
- en: '<User> Input text: was silent and lovely and there was no sound except'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: Is the sentence expressing confusion or uncertainty?'
  prefs: []
  type: TYPE_NORMAL
- en: Answer with Yes or No.
  prefs: []
  type: TYPE_NORMAL
- en: '<Assistant>: No'
  prefs: []
  type: TYPE_NORMAL
- en: '<User> Input text: {example}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: Answer with Yes or No.
  prefs: []
  type: TYPE_NORMAL
- en: '<Assistant>:'
  prefs: []
  type: TYPE_NORMAL
- en: See exact prompts with examples in the Github repo.
  prefs: []
  type: TYPE_NORMAL
- en: A.4 Information retrieval details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Optimization details
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When fitting our QA-Emb model for information retrieval, we learn a single scalar
    per-question that is multiplied by each embedding before computing a similarity.
    To learn these scalars, we minimize a two-part loss. The first loss is the negative
    cosine similarity between each query and its similar documents. The second loss
    is the cosine similarity between each query and the remaining documents. We weight
    the first loss as 10 times higher than the second loss and optimize using Adam [[101](#bib.bib101)]
    with a learning rate of $10^{-4}$. We run for 8 epochs, when the training loss
    seems to plateau.
  prefs: []
  type: TYPE_NORMAL
- en: A.5 Details on question-answering evaluation datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table A4: 54 binary classification datasets along with their underlying yes/no
    question and corpus statistics from a recent collection [[85](#bib.bib85), [86](#bib.bib86)].'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset name | Dataset topic | Underlying yes/no question | Examples | Unique
    unigrams |'
  prefs: []
  type: TYPE_TB
- en: '| 0-irony | sarcasm | contains irony | 590 | 3897 |'
  prefs: []
  type: TYPE_TB
- en: '| 1-objective | unbiased | is a more objective description of what happened
    | 739 | 5628 |'
  prefs: []
  type: TYPE_TB
- en: '| 2-subjective | subjective | contains subjective opinion | 757 | 5769 |'
  prefs: []
  type: TYPE_TB
- en: '| 3-god | religious | believes in god | 164 | 1455 |'
  prefs: []
  type: TYPE_TB
- en: '| 4-atheism | atheistic | is against religion | 172 | 1472 |'
  prefs: []
  type: TYPE_TB
- en: '| 5-evacuate | evacuation | involves a need for people to evacuate | 2670 |
    16505 |'
  prefs: []
  type: TYPE_TB
- en: '| 6-terorrism | terrorism | describes a situation that involves terrorism |
    2640 | 16608 |'
  prefs: []
  type: TYPE_TB
- en: '| 7-crime | crime | involves crime | 2621 | 16333 |'
  prefs: []
  type: TYPE_TB
- en: '| 8-shelter | shelter | describes a situation where people need shelter | 2620
    | 16347 |'
  prefs: []
  type: TYPE_TB
- en: '| 9-food | hunger | is related to food security | 2642 | 16276 |'
  prefs: []
  type: TYPE_TB
- en: '| 10-infrastructure | infrastructure | is related to infrastructure | 2664
    | 16548 |'
  prefs: []
  type: TYPE_TB
- en: '| 11-regime change | regime change | describes a regime change | 2670 | 16382
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12-medical | health | is related to a medical situation | 2675 | 16223 |'
  prefs: []
  type: TYPE_TB
- en: '| 13-water | water | involves a situation where people need clean water | 2619
    | 16135 |'
  prefs: []
  type: TYPE_TB
- en: '| 14-search | rescue | involves a search/rescue situation | 2628 | 16131 |'
  prefs: []
  type: TYPE_TB
- en: '| 15-utility | utility | expresses need for utility, energy or sanitation |
    2640 | 16249 |'
  prefs: []
  type: TYPE_TB
- en: '| 16-hillary | Hillary | is against Hillary | 224 | 1693 |'
  prefs: []
  type: TYPE_TB
- en: '| 17-hillary | Hillary | supports hillary | 218 | 1675 |'
  prefs: []
  type: TYPE_TB
- en: '| 18-offensive | derogatory | contains offensive content | 652 | 6109 |'
  prefs: []
  type: TYPE_TB
- en: '| 19-offensive | toxic | insult women or immigrants | 2188 | 11839 |'
  prefs: []
  type: TYPE_TB
- en: '| 20-pro-life | pro-life | is pro-life | 213 | 1633 |'
  prefs: []
  type: TYPE_TB
- en: '| 21-pro-choice | abortion | supports abortion | 209 | 1593 |'
  prefs: []
  type: TYPE_TB
- en: '| 22-physics | physics | is about physics | 10360 | 93810 |'
  prefs: []
  type: TYPE_TB
- en: '| 23-computer science | computers | is related to computer science | 10441
    | 93947 |'
  prefs: []
  type: TYPE_TB
- en: '| 24-statistics | statistics | is about statistics | 9286 | 86874 |'
  prefs: []
  type: TYPE_TB
- en: '| 25-math | math | is about math research | 8898 | 85118 |'
  prefs: []
  type: TYPE_TB
- en: '| 26-grammar | ungrammatical | is ungrammatical | 834 | 2217 |'
  prefs: []
  type: TYPE_TB
- en: '| 27-grammar | grammatical | is grammatical | 826 | 2236 |'
  prefs: []
  type: TYPE_TB
- en: '| 28-sexis | sexist | is offensive to women | 209 | 1641 |'
  prefs: []
  type: TYPE_TB
- en: '| 29-sexis | feminism | supports feminism | 215 | 1710 |'
  prefs: []
  type: TYPE_TB
- en: '| 30-news | world | is about world news | 5778 | 13023 |'
  prefs: []
  type: TYPE_TB
- en: '| 31-sports | sports news | is about sports news | 5674 | 12849 |'
  prefs: []
  type: TYPE_TB
- en: '| 32-business | business | is related to business | 5699 | 12913 |'
  prefs: []
  type: TYPE_TB
- en: '| 33-tech | technology | is related to technology | 5727 | 12927 |'
  prefs: []
  type: TYPE_TB
- en: '| 34-bad | negative | contains a bad movie review | 357 | 16889 |'
  prefs: []
  type: TYPE_TB
- en: '| 35-good | good | thinks the movie is good | 380 | 17497 |'
  prefs: []
  type: TYPE_TB
- en: '| 36-quantity | quantity | asks for a quantity | 1901 | 5144 |'
  prefs: []
  type: TYPE_TB
- en: '| 37-location | location | asks about a location | 1925 | 5236 |'
  prefs: []
  type: TYPE_TB
- en: '| 38-person | person | asks about a person | 1848 | 5014 |'
  prefs: []
  type: TYPE_TB
- en: '| 39-entity | entity | asks about an entity | 1896 | 5180 |'
  prefs: []
  type: TYPE_TB
- en: '| 40-abbrevation | abbreviation | asks about an abbreviation | 1839 | 5045
    |'
  prefs: []
  type: TYPE_TB
- en: '| 41-defin | definition | contains a definition | 651 | 4508 |'
  prefs: []
  type: TYPE_TB
- en: '| 42-environment | environmentalism | is against environmentalist | 124 | 1117
    |'
  prefs: []
  type: TYPE_TB
- en: '| 43-environment | environmentalism | is environmentalist | 119 | 1072 |'
  prefs: []
  type: TYPE_TB
- en: '| 44-spam | spam | is a spam | 360 | 2470 |'
  prefs: []
  type: TYPE_TB
- en: '| 45-fact | facts | asks for factual information | 704 | 11449 |'
  prefs: []
  type: TYPE_TB
- en: '| 46-opinion | opinion | asks for an opinion | 719 | 11709 |'
  prefs: []
  type: TYPE_TB
- en: '| 47-math | science | is related to math and science | 7514 | 53973 |'
  prefs: []
  type: TYPE_TB
- en: '| 48-health | health | is related to health | 7485 | 53986 |'
  prefs: []
  type: TYPE_TB
- en: '| 49-computer | computers | related to computer or internet | 7486 | 54256
    |'
  prefs: []
  type: TYPE_TB
- en: '| 50-sport | sports | is related to sports | 7505 | 54718 |'
  prefs: []
  type: TYPE_TB
- en: '| 51-entertainment | entertainment | is about entertainment | 7461 | 53573
    |'
  prefs: []
  type: TYPE_TB
- en: '| 52-family | relationships | is about family and relationships | 7438 | 54680
    |'
  prefs: []
  type: TYPE_TB
- en: '| 53-politic | politics | is related to politics or government | 7410 | 53393
    |'
  prefs: []
  type: TYPE_TB
