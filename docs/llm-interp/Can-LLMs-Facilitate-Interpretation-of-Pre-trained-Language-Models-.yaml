- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 17:35:15'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Can LLMs Facilitate Interpretation of Pre-trained Language Models?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.13386](https://ar5iv.labs.arxiv.org/html/2305.13386)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Basel Mousi            Nadir Durrani            Fahim Dalvi
  prefs: []
  type: TYPE_NORMAL
- en: Qatar Computing Research Institute, HBKU, Doha, Qatar
  prefs: []
  type: TYPE_NORMAL
- en: '{bmousi,ndurrani,faimaduddin}@hbku.edu.qa'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Work done to uncover the knowledge encoded within pre-trained language models
    rely on annotated corpora or human-in-the-loop methods. However, these approaches
    are limited in terms of scalability and the scope of interpretation. We propose
    using a large language model, ChatGPT, as an annotator to enable fine-grained
    interpretation analysis of pre-trained language models. We discover latent concepts
    within pre-trained language models by applying agglomerative hierarchical clustering
    over contextualized representations and then annotate these concepts using ChatGPT.
    Our findings demonstrate that ChatGPT produces accurate and semantically richer
    annotations compared to human-annotated concepts. Additionally, we showcase how
    GPT-based annotations empower interpretation analysis methodologies of which we
    demonstrate two: probing frameworks and neuron interpretation. To facilitate further
    exploration and experimentation in the field, we make available a substantial
    ConceptNet dataset (TCN) comprising 39,000 annotated concepts.¹¹1[https://neurox.qcri.org/projects/transformers-concept-net/](https://neurox.qcri.org/projects/transformers-concept-net/)'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A large body of work done on interpreting pre-trained language models answers
    the question: *What knowledge is learned within these models?* Researchers have
    investigated the concepts encoded in pre-trained language models by probing them
    against various linguistic properties, such as morphological (Vylomova et al.,
    [2017](#bib.bib46); Belinkov et al., [2017a](#bib.bib5)), syntactic (Linzen et al.,
    [2016](#bib.bib35); Conneau et al., [2018](#bib.bib10); Durrani et al., [2021](#bib.bib18)),
    and semantic (Qian et al., [2016](#bib.bib42); Belinkov et al., [2017b](#bib.bib7))
    tasks, among others. Much of the methodology used in these analyses heavily rely
    on either having access to an annotated corpus that pertains to the linguistic
    concept of interest Tenney et al. ([2019](#bib.bib45)); Liu et al. ([2019a](#bib.bib36));
    Belinkov et al. ([2020](#bib.bib6)), or involve human-in-the-loop Karpathy et al.
    ([2015](#bib.bib29)); Kádár et al. ([2017](#bib.bib28)); Geva et al. ([2021](#bib.bib21));
    Dalvi et al. ([2022](#bib.bib14)) to facilitate such an analysis. The use of pre-defined
    linguistic concepts restricts the scope of interpretation to only very general
    linguistic concepts, while human-in-the-loop methods are not scalable. *We circumvent
    this bottleneck by using a large language model, ChatGPT, as an annotator to enable
    fine-grained interpretation analysis.*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fcb4c4d6751f069fb12292f161f4242d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: ChatGPT as an annotator: Human annotation or taggers trained on pre-defined
    concepts, cover only a fraction of a model’s concept space. ChatGPT enables scaling
    up annotation to include nearly all concepts, including the concepts that may
    not have been manually annotated before.'
  prefs: []
  type: TYPE_NORMAL
- en: Generative Pre-trained Transformers (GPT) have been trained on an unprecedented
    amount of textual data, enabling them to develop a substantial understanding of
    natural language. As their capabilities continue to improve, researchers are finding
    creative ways to leverage their assistance for various applications, such as question-answering
    in financial and medical domains Guo et al. ([2023](#bib.bib24)), simplifying
    medical reports Jeblick et al. ([2022](#bib.bib27)), and detecting stance Zhang
    et al. ([2023](#bib.bib49)). We carry out an investigation of whether GPT models,
    specifically ChatGPT, can aid in the interpretation of pre-trained language models
    (pLMs).
  prefs: []
  type: TYPE_NORMAL
- en: A fascinating characteristic of neural language models is that words sharing
    any linguistic relationship cluster together in high-dimensional spaces Mikolov
    et al. ([2013](#bib.bib41)). Recent research Michael et al. ([2020](#bib.bib40));
    Fu and Lapata ([2022](#bib.bib20)); Dalvi et al. ([2022](#bib.bib14)) has built
    upon this idea by exploring representation analysis through latent spaces in pre-trained
    models. Building on the work of Dalvi et al. ([2022](#bib.bib14)) we aim to identify
    encoded concepts within pre-trained models using agglomerative hierarchical clustering
    Gowda and Krishna ([1978](#bib.bib23)) on contextualized representations. The
    underlying hypothesis is that these clusters represent latent concepts, capturing
    the language knowledge acquired by the model. Unlike previous approaches that
    rely on predefined concepts Michael et al. ([2020](#bib.bib40)); Sajjad et al.
    ([2022b](#bib.bib44)) or human annotation Alam et al. ([2023](#bib.bib2)) to label
    these concepts, we leverage the ChatGPT model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our findings indicate that the annotations produced by ChatGPT are semantically
    richer and accurate compared to the human-annotated concepts (for instance BERT
    Concept NET). Notably, ChatGPT correctly labeled the majority of concepts deemed
    uninterpretable by human annotators. Using an LLM like ChatGPT improves scalability
    and accuracy. For instance, the work in Dalvi et al. ([2022](#bib.bib14)) was
    limited to 269 concepts in the final layer of the BERT-base-cased Devlin et al.
    ([2019](#bib.bib15)) model, while human annotations in Geva et al. ([2021](#bib.bib21))
    were confined to 100 keys per layer. Using ChatGPT, the exploration can be scaled
    to the entire latent space of the models and many more architectures. We used
    GPT to annotate 39K concepts across 5 pre-trained language models. Building upon
    this finding, we further demonstrate that GPT-based annotations empowers methodologies
    in interpretation analysis of which we show two: i) probing framework Belinkov
    et al. ([2017a](#bib.bib5)), ii) neuron analysis Antverg and Belinkov ([2022](#bib.bib3)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/068a4679820f32018d75d52eac4502f3.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Hyphenated Superlatives
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0767f76a6494c889bfb352a25154e0e8.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Verbs
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/59bfd14190292ac90b825dc81a8822a2.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Arab Names
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: Illustrative Examples of Concept Learned in BERT: word groups organized
    based on (a) Lexical, (b) Parts of Speech, and (c) Semantic property'
  prefs: []
  type: TYPE_NORMAL
- en: Probing Framework
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We train probes from GPT-annotated concept representations to explore concepts
    that go beyond conventional linguistic categories. For instance, instead of probing
    for named entities (e.g. NE:PER), we can investigate whether a model distinguishes
    between male and female names or probing for “Cities in the southeastern United
    States” instead of NE:LOC.
  prefs: []
  type: TYPE_NORMAL
- en: Neuron Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another line of work that we illustrate to benefit from GPT-annotated latent
    concepts is the neuron analysis i.e. discovering neurons that capture a linguistic
    phenomenon. In contrast to the holistic view offered by representation analysis,
    neuron analysis highlights the *role of individual neurons* (or groups of them)
    within a neural network (Sajjad et al. ([2022a](#bib.bib43)). We obtain neuron
    rankings for GPT-annotated latent concepts using a neuron ranking method called
    Probeless Antverg and Belinkov ([2022](#bib.bib3)). Such fine-grained interpertation
    analyses of latent spaces enable us to see *how neurons distribute in hierarchical
    ontologies.* For instance, instead of simply identifying neurons associated with
    the POS:Adverbs, we can now uncover how neurons are distributed across sub-concepts
    such as adverbs of time (e.g., “tomorrow”) and adverbs of frequency (e.g., “daily”).
    Or instead of discovering neurons for named entities (e.g. NE:PER), we can discover
    neurons that capture “Muslim Names” versus “Hindu Names”.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, we make the following contributions in this work:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our demonstration reveals that ChatGPT offers comprehensive and precise labels
    for latent concepts acquired within pLMs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We showcased the GPT-based annotations of latent concepts empower methods in
    interpretation analysis by showing two applications: Probing Classifiers and Neuron
    Analysis.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We release *Transformers Concept-Net*, an extensive dataset containing 39K annotated
    concepts to facilitate the interpretation of pLMs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discover latent concepts by applying clustering on feature vectors (§[2.1](#S2.SS1
    "2.1 Concept Discovery ‣ 2 Methodology ‣ Can LLMs Facilitate Interpretation of
    Pre-trained Language Models?")). They are then labeled using ChatGPT (§[2.2](#S2.SS2
    "2.2 Concept Annotation ‣ 2 Methodology ‣ Can LLMs Facilitate Interpretation of
    Pre-trained Language Models?")) and used for fine-grained interpretation analysis
    (§[2.3](#S2.SS3 "2.3 Concept Probing ‣ 2 Methodology ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?") and [2.4](#S2.SS4 "2.4 Concept Neurons ‣ 2 Methodology
    ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?")). A visual
    representation of this process is shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?").
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Concept Discovery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Contextualized word representations learned in pre-trained language models,
    can identify meaningful groupings based on various linguistic phenomenon. These
    groups represent concepts encoded within pLMs. Our investigation expands upon
    the work done in discovering latent ontologies in contextualized representations
    Michael et al. ([2020](#bib.bib40)); Dalvi et al. ([2022](#bib.bib14)). At a high
    level, feature vectors (contextualized representations) are first generated by
    performing a forward pass on the model. These representations are then clustered
    to discover the encoded concepts. Consider a pre-trained model $\mathbf{M}$ with
    $L$ layers: ${l_{1},l_{2},\ldots,l_{L}}$. Using dataset ${\mathbb{D}}={w_{1},w_{2},...,w_{N}}$,
    we generate feature vectors ${\mathbb{D}}\xrightarrow{\mathbb{M}}\mathbf{z}^{l}={\mathbf{z}^{l}_{1},\dots,\mathbf{z}^{l}_{n}}$.²²2$z_{i}$
    denotes the contextualized representation for word $w_{i}$ Agglomerative hierarchical
    clustering is employed to cluster the words. Initially, each word forms its own
    cluster. Clusters are then merged iteratively based on Ward’s minimum variance
    criterion, using intra-cluster variance as dissimilarity measure. The squared
    Euclidean distance evaluates the similarity between vector representations. The
    algorithm stops when $K$ clusters (encoded concepts) are formed, with $K$ being
    a hyper-parameter.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Concept Annotation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Encoded concepts capture latent relationships among words within a cluster,
    encompassing various forms of similarity such as lexical, syntactic, semantic,
    or specific patterns relevant to the task or data. Figure [2](#S1.F2 "Figure 2
    ‣ 1 Introduction ‣ Can LLMs Facilitate Interpretation of Pre-trained Language
    Models?") provides illustrative examples of concepts encoded in the BERT-base-cased
    model.
  prefs: []
  type: TYPE_NORMAL
- en: This work leverages the recent advancements in prompt-based approaches, which
    are enabled by large language models such as GPT-3 Brown et al. ([2020](#bib.bib8)).
    Specifically, we utilize a zero-shot learning strategy, where the model is solely
    provided with a natural language instruction that describes the task of labeling
    the concept. We used ChatGPT with zero-shot prompt to annotate the latent concepts
    with the following settings:³³3We experimented with several prompts, see Appendix
    [A.1](#A1.SS1 "A.1 Optimal Prompt ‣ Appendix A Prompts ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?") for details.
  prefs: []
  type: TYPE_NORMAL
- en: Assistant is a large language model trained by OpenAI
  prefs: []
  type: TYPE_NORMAL
- en: 'Instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Give a short and concise label that best describes the following list of words:
    [‘‘word 1’’, ‘‘word 2’’, ..., ‘‘word N’’]'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Concept Probing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our large scale annotations of the concepts in pLMs enable training probes
    towards fine-grained concepts that lack pre-defined annotations. For example we
    can use probing to assess whether a model has learned concepts that involve biases
    related to gender, race, or religion. By tracing the input sentences that correspond
    to an encoded concept $C$ in a pre-trained model, we create annotations for a
    particular concept. We perform fine-grained concept probing by extracting feature
    vectors from annotated data through a forward pass on the model of interest. Then,
    we train a binary classifier to predict the concept and use the probe accuracy
    as a qualitative measure of how well the model represents the concept. Formally,
    given a set of tokens ${\mathbb{W}}=\{w_{1},w_{2},...,w_{N}\}\in C$, we generate
    feature vectors, a sequence of latent representations: ${\mathbb{W}}\xrightarrow{\mathbb{M}}\mathbf{z}^{l}=\{\mathbf{z}^{l}_{1},\dots,\mathbf{z}^{l}_{n}\}$
    for each word $w_{i}$ by doing a forward pass over $s_{i}$. We then train a binary
    classifier over the representations to predict the concept $C$ minimizing the
    cross-entropy loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}(\theta)=-\sum_{i}\log P_{\theta}(\mathbf{c}_{i}&#124;\mathbf{w}_{i})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $P_{\theta}(\mathbf{c}_{i}|\mathbf{z}_{i})=\frac{\exp(\theta_{l}\cdot\mathbf{z}_{i})}{\sum_{c^{\prime}}\exp(\theta_{l^{\prime}}\cdot\mathbf{z}_{i})}$
    is the probability that word $\mathbf{x}_{i}$ is assigned concept $\mathbf{c}$.
    We learn the weights $\theta\in\mathbb{R}^{D\times L}$ using gradient descent.
    Here $D$ is the dimensionality of the latent representations $\mathbf{z}_{i}$
    and $L$ is the size of the concept set which is 2 for a binary classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Concept Neurons
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An alternative area of research in interpreting NLP models involves conducting
    representation analysis at a more fine-grained level, specifically focusing on
    individual neurons. Our demonstration showcases how the extensive annotations
    of latent concepts enhance the analysis of neurons towards more intricate concepts.
    We show this by using a neuron ranking method called Probeless Antverg and Belinkov
    ([2022](#bib.bib3)) over our concept representations. The method obtains neuron
    rankings using an accumulative strategy, where the score of a given neuron $n$
    towards a concept $C$ is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $R(n,\mathcal{C})=\mu(\mathcal{C})-\mu(\hat{\mathcal{C}})$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mu(\mathcal{C})$ is the average of all activations $z(n,w)$, $w\in\mathcal{C}$,
    and $\mu(\hat{\mathcal{C}})$ is the average of activations over the random concept
    set. Note that the ranking for each neuron $n$ is computed independently.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Experimental Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Latent Concept Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We used a subset of the WMT News 2018 dataset, containing 250K randomly chosen
    sentences ($\approx$5M tokens). We set a word occurrence threshold of 10 and restricted
    each word type to a maximum of 10 occurrences. This selection was made to reduce
    computational and memory requirements when clustering high-dimensional vectors.
    We preserved the original embedding space to avoid information loss through dimensionality
    reduction techniques like PCA. Consequently, our final dataset consisted of 25,000
    word types, each represented by 10 contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Concept Discovery
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We apply agglomerative hierarchical clustering on contextualized feature vectors
    acquired through a forward pass on a pLM for the given data. The resulting representations
    in each layer are then clustered into 600 groups.⁴⁴4Dalvi et al. ([2022](#bib.bib14))
    discovered that selecting $K$ within the range of $600-1000$ struck a satisfactory
    balance between the pitfalls of excessive clustering and insufficient clustering.
    Their exploration of other methods ELbow and Silhouette did not yield reliable
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Concept Annotation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We used ChatGPT available through Azure OpenAI service⁵⁵5[https://azure.microsoft.com/en-us/products/cognitive-services/openai-service](https://azure.microsoft.com/en-us/products/cognitive-services/openai-service)
    to carryout the annotations. We used a *temperature* of 0 and a *top p* value
    of 0.95\. Setting the temperature to 0 controls the randomness in the output and
    produces deterministic responses.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our study involved several 12-layered transformer models, including BERT-cased
    (Devlin et al., [2019](#bib.bib15)), RoBERTa Liu et al. ([2019b](#bib.bib38)),
    XLNet Yang et al. ([2019](#bib.bib48)), and ALBERT Lan et al. ([2019](#bib.bib32))
    and XLM-RoBERTa (XLM-R) (Conneau et al., [2020](#bib.bib9)).
  prefs: []
  type: TYPE_NORMAL
- en: Probing and Neuron Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For each annotated concept, we extract feature vectors using the relevant data.
    We then train linear classifiers with a categorical cross-entropy loss function,
    optimized using Adam Kingma and Ba ([2014](#bib.bib30)). The training process
    involved shuffled mini-batches of size 512 and was concluded after 10 epochs.
    We used a data split of 60-20-20 for train, dev, test when training classifiers.
    We use the same representations to obtain neuron rankings. We use NeuroX toolkit
    Dalvi et al. ([2023a](#bib.bib11)) to train our probes and run neuron analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '| Q1 | Acceptable | Unacceptable |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Majority | 244 | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| Fliess Kappa | 0.71 ("Substantial agreement") |'
  prefs: []
  type: TYPE_TB
- en: '| Q2 | Precise | Imprecise |'
  prefs: []
  type: TYPE_TB
- en: '| Majority | 181 | 60 |'
  prefs: []
  type: TYPE_TB
- en: '| Fliess Kappa | 0.34 ("Fair agreement") |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Inter-annotator agreement with 3 annotators. Q1: Whether the label
    is acceptable or unacceptable? Q2: Of the acceptable annotations how many are
    precise versus imprecise?'
  prefs: []
  type: TYPE_NORMAL
- en: '| Q3 | GPT $\uparrow$ | Equal | BCN $\uparrow$ | No Majority |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Majority | 82 | 121 | 58 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| Fliess Kappa | 0.56 ("Moderate agreement") |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Annotation for Q3 with 3 choices: GPT is better, labels are equivalent,
    human annotation is better.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Evaluation and Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To validate ChatGPT’s effectiveness as an annotator, we conducted a human evaluation.
    Evaluators were shown a concept through a word cloud, along with sample sentences
    representing the concept and the corresponding GPT annotation. They were then
    asked the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Q1: Is the label produced by ChatGPT Acceptable or Unacceptable? Unacceptable
    annotations include incorrect labels or those that ChatGPT was unable to annotate.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Q2: If a label is Acceptable, is it Precise or Imprecise? While a label may
    be deemed acceptable, it may not convey the relationship between the underlying
    words in the concept accurately. This question aims to measure the precision of
    the label itself.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Q3: Is the ChatGPT label Superior or Inferior to human annotation? BCN labels
    provided by Dalvi et al. ([2022](#bib.bib14)) are used as human annotations for
    this question.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the first half of Table [1](#S3.T1 "Table 1 ‣ Probing and Neuron Analysis
    ‣ 3 Experimental Setup ‣ Can LLMs Facilitate Interpretation of Pre-trained Language
    Models?"), the results indicate that $90.7\%$ of the ChatGPT labels were considered
    Acceptable. Within the acceptable labels, $75.1\%$ were deemed Precise, while
    $24.9\%$ were found to be Imprecise (indicated by Q2 in Table [1](#S3.T1 "Table
    1 ‣ Probing and Neuron Analysis ‣ 3 Experimental Setup ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?")). We also computed Fleiss’ Kappa (Fleiss et al.,
    [2013](#bib.bib19)) to measure agreement among the 3 annotators. For Q1, the inter-annotator
    agreement was found to be $0.71$ which is considered *substantial* according to
     Landis and Koch ([1977](#bib.bib33)). However, for Q2, the agreement was $0.34$
    (indicating a fair level of agreement among annotators). This was expected due
    to the complexity and subjectivity of the task in Q2 for example annotators’ knowledge
    and perspective on precise and imprecise labels.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT Labels versus Human Annotations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Next we compare the quality of ChatGPT labels to the human annotations using
    BERT Concept Net, a human annotated collection of latent concepts learned within
    the representations of BERT. BCN, however, was annotated in the form of Concept
    Type:Concept Sub Type (e.g., SEM:entertainment:sport:ice_hockey) unlike GPT-based
    annotations that are natural language descriptions (e.g. Terms related to ice
    hockey). Despite their lack of natural language, these reference annotations prove
    valuable for drawing comparative analysis between humans and ChatGPT. For Q3,
    we presented humans with a word cloud and three options to choose from: whether
    the LLM annotations are better, equalivalent, or worse than the BCN annotations.
    We found that ChatGPT outperformed or achieved equal performance to BCN annotations
    in $75.5\%$ of cases, as shown in Table [2](#S3.T2 "Table 2 ‣ Probing and Neuron
    Analysis ‣ 3 Experimental Setup ‣ Can LLMs Facilitate Interpretation of Pre-trained
    Language Models?"). The inter-annotator agreement for Q3 was found to be $0.56$
    which is considered *moderate*.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Annotation | SEM | LEX | Morph | SYN | Unint. |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT | 85.5 | 1.1 | 3.0 | X | 3.3 |'
  prefs: []
  type: TYPE_TB
- en: '| BCN | 68.4 | 16.7 | 3.0 | 2.2 | 9.7 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Distribution (percentages) of concept types in ChatGPT Labels vs.
    Human Annotations: Semantic, Lexical, Morphological, Syntactic, Uninterpretable'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Error Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/324bd6088f6c06e6594ed4da47c49c74.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Crime and Assault
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fa647bb21e902f879d94c03338818916.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) 3rd Person Singular Present-tense
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b1151e1ece906b97d33103424d136ee1.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Rock Bands and Artists in the US
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/eeea7c592072fdec5ce4246a0be9dad3.png)'
  prefs: []
  type: TYPE_IMG
- en: A total of 285 could prove to be rather impressive on a pitch that was turning
    almost from the first ball .
  prefs: []
  type: TYPE_NORMAL
- en: But there were runs at Cheltenham , where Gloucestershire finished on 315 for
    seven , with the only century of the entire Championship day going to Ryan Higgins
    , out for a 161-ball 105 .
  prefs: []
  type: TYPE_NORMAL
- en: Back in Nottingham , it was the turn of Australia ’s bowlers to be eviscerated
    this time as Eoin Morgan ’s team rewrote the record books once again by making
    a phenomenal 481 for six in this third one-day international .
  prefs: []
  type: TYPE_NORMAL
- en: (d) Cricket Scores
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Failed cases for ChatGPT labeling: a) Non-labeled concepts due to
    LLM content policy, b) Failing to identify correct linguistic relation, c) Imprecise
    labeling d) Imprecise labels despite providing context'
  prefs: []
  type: TYPE_NORMAL
- en: The annotators identified 58 concepts where human annotated BCN labels were
    deemed superior. We have conducted an error analysis of these instances and will
    now delve into the cases where GPT did not perform well.
  prefs: []
  type: TYPE_NORMAL
- en: Sensitive Content Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In 10 cases, the API calls triggered one of the content policy models and failed
    to provide a label. The content policy models aim to prevent the dissemination
    of harmful, abusive, or offensive content, including hate speech, misinformation,
    and illegal activities. Figure [3(a)](#S4.F3.sf1 "In Figure 3 ‣ 4.2 Error Analysis
    ‣ 4 Evaluation and Analysis ‣ Can LLMs Facilitate Interpretation of Pre-trained
    Language Models?") shows an example of a sensitive concept that includes words
    related to crime and assault. This problem can be mitigated by using a version
    of LLM where content policy models are not enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Linguistic Ontologies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In 8 of the concepts, human annotations (BCN) were better because the concepts
    were composed of words that were related through a lexical, morphological, or
    syntactic relationship. The default prompt we used to label the concept tends
    to find semantic similarity between the words, which did not exist in these concepts.
    For example, Figure [3(b)](#S4.F3.sf2 "In Figure 3 ‣ 4.2 Error Analysis ‣ 4 Evaluation
    and Analysis ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?")
    shows a concept composed of 3rd person singular present-tense verbs, but ChatGPT
    incorrectly labels it as Actions/Events in News Articles. However, humans are
    robust and can fall back to consider various linguistic ontologies.
  prefs: []
  type: TYPE_NORMAL
- en: The BCN concepts are categorized into semantic, syntactic, morphological, and
    lexical groups (See Table [3](#S4.T3 "Table 3 ‣ ChatGPT Labels versus Human Annotations
    ‣ 4.1 Results ‣ 4 Evaluation and Analysis ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?")). As observed, both humans and ChatGPT found
    semantic meaning to the concept in majority of the cases. However, humans were
    also able to identify other linguistic relations such as lexical (e.g. grouped
    by a lexical property like abbreviations), morphological (e.g. grouped by the
    same parts-of-speech), or syntactic (e.g. grouped by position in the sentence).
    Note however, that prompts can be modified to capture specific linguistic property.
    We encourage interested readers to see our experiments on this in Appendix [A.2](#A1.SS2
    "A.2 Prompts For Lexical Concepts ‣ Appendix A Prompts ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?")-[A.3](#A1.SS3 "A.3 Prompts for POS Concepts
    ‣ Appendix A Prompts ‣ Can LLMs Facilitate Interpretation of Pre-trained Language
    Models?").
  prefs: []
  type: TYPE_NORMAL
- en: Insufficient Context
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Sometimes context contextual information is important to correctly label a
    concept. While human annotators (of the BCN corpus) were provided with the sentences
    in which the underlying words appeared, we did not provide the same to ChatGPT
    to keep the prompt cost-effective. However, providing context sentences in the
    prompt⁶⁶6We gave 10 context sentences to ChatGPT. along with the concept to label
    resulted in improved labels for 11 of the remaining 40 error cases. Figure [3(d)](#S4.F3.sf4
    "In Figure 3 ‣ 4.2 Error Analysis ‣ 4 Evaluation and Analysis ‣ Can LLMs Facilitate
    Interpretation of Pre-trained Language Models?") shows one such example where
    providing contextual information made ChatGPT to correctly label the concept as
    Cricket Scores as opposed to Numerical Data the label that it gives without seeing
    contextual information. However, providing context information didn’t consistently
    prove helpful. Figure [3(c)](#S4.F3.sf3 "In Figure 3 ‣ 4.2 Error Analysis ‣ 4
    Evaluation and Analysis ‣ Can LLMs Facilitate Interpretation of Pre-trained Language
    Models?") shows a concept, where providing contextual information did not result
    in the accurate label: Rock Bands and Artists in the US, as identified by the
    humans.'
  prefs: []
  type: TYPE_NORMAL
- en: Uninterpretable Concepts
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Conversely, we also annotated concepts that were considered uninterpretable
    or non-meaningful by the human annotators in the BCN corpus and in 21 out 26 cases,
    ChatGPT accurately assigned labels to these concepts. The proficiency of ChatGPT
    in processing extensive textual data enables it to provide accurate labels for
    these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Concept-based Interpretation Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have established the capability of large language models like ChatGPT
    in providing rich semantic annotations, we will showcase how these annotations
    can facilitate extensive fine-grained analysis on a large scale.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Probing Classifiers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| tag | Label | ALBERT | XLNet |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| c301 | Gender-related Nouns and pronouns | 0.95 | 0.86 |'
  prefs: []
  type: TYPE_TB
- en: '| c533 | LGBTQ+ | 0.97 | 0.97 |'
  prefs: []
  type: TYPE_TB
- en: '| c439 | Sports commentary terms | 0.91 | 0.81 |'
  prefs: []
  type: TYPE_TB
- en: '| c173 | Football team names and stadiums | 0.96 | 0.94 |'
  prefs: []
  type: TYPE_TB
- en: '| c348 | Female names and titles | 0.98 | 0.94 |'
  prefs: []
  type: TYPE_TB
- en: '| c149 | Tennis players’ names | 0.95 | 0.92 |'
  prefs: []
  type: TYPE_TB
- en: '| c487 | Spanish Male Names | 0.96 | 0.94 |'
  prefs: []
  type: TYPE_TB
- en: '| c564 | Cities and Universities in southeastern US | 0.97 | 0.90 |'
  prefs: []
  type: TYPE_TB
- en: '| c263 | Locations in New York City | 0.95 | 0.92 |'
  prefs: []
  type: TYPE_TB
- en: '| c247 | Scandinavian/Nordic names and places | 0.98 | 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '| c438 | Verbs for various actions and outcomes | 0.94 | 0.87 |'
  prefs: []
  type: TYPE_TB
- en: '| c44 | Southeast Asian Politics and Ethnic Conflict | 0.97 | 0.94 |'
  prefs: []
  type: TYPE_TB
- en: '| c421 | Names of people and places in the middle east | 0.94 | 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '| c245 | Middle East conflict | 1.00 | 0.93 |'
  prefs: []
  type: TYPE_TB
- en: '| c553 | Islamic terminology | 0.96 | 0.89 |'
  prefs: []
  type: TYPE_TB
- en: '| c365 | Criminal activities | 0.93 | 0.89 |'
  prefs: []
  type: TYPE_TB
- en: '| c128 | Medical and Healthcare terminology | 0.98 | 0.95 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Using latent concepts to make cross-model comparison using Probing
    Classifiers'
  prefs: []
  type: TYPE_NORMAL
- en: 'Probing classifiers is among the earlier techniques used for interpretability,
    aimed at examining the knowledge encapsulated in learned representations. However,
    their application is constrained by the availability of supervised annotations,
    which often focus on conventional linguistic knowledge and are subject to inherent
    limitations Hewitt and Liang ([2019](#bib.bib26)). We demonstrate that using GPT-based
    annotation of latent concepts learned within these models enables a direct application
    towards fine-grained probing analysis. By annotating the latent space of five
    renowned pre-trained language models (pLMs): BERT, ALBERT, XLM-R, XLNet, and RoBERTa
    – we developed a comprehensive Transformers Concept Net. This net encompasses
    39,000 labeled concepts, facilitating cross-architectural comparisons among the
    models. Table [4](#S5.T4 "Table 4 ‣ 5.1 Probing Classifiers ‣ 5 Concept-based
    Interpretation Analysis ‣ Can LLMs Facilitate Interpretation of Pre-trained Language
    Models?") showcases a subset⁷⁷7For a larger sample of concepts and additional
    models, please refer to Appendix [B](#A2 "Appendix B Probing Classifiers ‣ Can
    LLMs Facilitate Interpretation of Pre-trained Language Models?"). of results comparing
    ALBERT and XLNet through probing classifiers.'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the model learns concepts that may not directly align with the
    pre-defined human onotology. For example, it learns a concept based on Spanish
    Male Names or Football team names and stadiums. Identifying how fine-grained concepts
    are encoded within the latent space of a model enable applications beyond interpretation
    analysis. For example it has direct application in model editing Meng et al. ([2023](#bib.bib39))
    which first trace where the model store any concept and then change the relevant
    parameters to modify its behavior. Moreover, identifying concepts that are associated
    with gender (e.g., Female names and titles), religion (e.g. Islamic Terminology),
    and ethnicity (e.g., Nordic names) can aid in elucidating the biases present in
    these models.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Neuron Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Super Concept | # Sub Concepts | Alignment |'
  prefs: []
  type: TYPE_TB
- en: '| Adverbs | 17 | 0.36 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c155: Frequency and manner | 0.30 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c136: Degree/Intensity | 0.30 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c057: Frequency | 0.40 |'
  prefs: []
  type: TYPE_TB
- en: '| Nouns | 13 | 0.28 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c231: Activities and Objects | 0.60 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c279: Industries/Sectors | 0.60 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c440: Professions | 0.10 |'
  prefs: []
  type: TYPE_TB
- en: '| Adjectives | 17 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c299: Product Attributes | 0.30 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c053: Comparative Adjectives | 0.30 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c128: Quality/Appropriateness | 0.40 |'
  prefs: []
  type: TYPE_TB
- en: '| Numbers | 17 | 0.23 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c549: Prices | 0.50 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c080: Quantities | 0.10 |'
  prefs: []
  type: TYPE_TB
- en: '| $\hookrightarrow$ c593: Monetary Values | 0.10 |'
  prefs: []
  type: TYPE_TB
- en: 'Figure 4: Neuron Analysis on *Super Concepts* extracted from BERT-base-cased-POS
    model. The alignment column shows the intersection between the top 10 neurons
    in the Super concept and the Sub concepts. For detailed results please check Appendix
    [C](#A3 "Appendix C Neuron Analysis Results ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?") (See Table [10](#A3.T10 "Table 10 ‣ Neurons
    Associated with the Names concepts ‣ Appendix C Neuron Analysis Results ‣ Can
    LLMs Facilitate Interpretation of Pre-trained Language Models?"))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bbd8a7d26e0ecda89a3d572f662979ac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Neuron overlap between an Adverb Super Concept and sub concepts.
    Sub concepts shown are Adverbs of frequency and manner (c155), Adverbs of degree/intensity
    (c136), Adverbs of Probability and Certainty (c265), Adverbs of Frequency (c57),
    Adverbs of manner and opinion (c332), Adverbs of preference/choice (c570), Adverbs
    indicating degree or extent (c244), Adverbs of Time (c222).'
  prefs: []
  type: TYPE_NORMAL
- en: Neuron analysis examines the individual neurons or groups of neurons within
    neural NLP models to gain insights into how the model represents linguistic knowledge.
    However, similar to general interpretability, previous studies in neuron analysis
    are also constrained by human-in-the-loop Karpathy et al. ([2015](#bib.bib29));
    Kádár et al. ([2017](#bib.bib28)) or pre-defined linguistic knowledge Hennigen
    et al. ([2020](#bib.bib25)); Durrani et al. ([2022](#bib.bib17)). Consequently,
    the resulting neuron explanations are subject to the same limitations we address
    in this study.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our work demonstrates that annotating the latent space enables neuron analysis
    of intricate linguistic hierarchies learned within these models. For example,
    Dalvi et al. ([2019](#bib.bib12)) and Hennigen et al. ([2020](#bib.bib25)) only
    carried out analysis using very coarse morphological categories (e.g. adverbs,
    nouns etc.) in parts-of-speech tags. We now showcase how our discovery and annotations
    of fine-grained latent concepts leads to a deeper neuron analysis of these models.
    In our analysis of BERT-based part-of-speech tagging model, we discovered 17 fine-grained
    concepts of adverb (in the final layer). It is evident that BERT learns a highly
    detailed semantic hierarchy, as maintains separate concepts for the adverbs of
    frequency (e.g., “rarely, sometimes”) versus adverbs of manner (e.g., “quickly,
    softly”). We employed the *Probeless* method Antverg and Belinkov ([2022](#bib.bib3))
    to search for neurons associated with specific kinds of adverbs. We also create
    a super adverb concept encompassing all types of adverbs, serving as the overarching
    and generic representation for this linguistic category and obtain neurons associated
    with the concept. We then compare the neuron ranking obtained from the super concept
    to the individual rankings from sub concepts. Interestingly, our findings revealed
    that the top-ranking neurons responsible for learning the super concept are often
    distributed among the top neurons associated with specialized concepts, as shown
    in Figure [5](#S5.F5 "Figure 5 ‣ 5.2 Neuron Analysis ‣ 5 Concept-based Interpretation
    Analysis ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?")
    for adverbial concepts. The results, presented in Table [5](#S5.F5 "Figure 5 ‣
    5.2 Neuron Analysis ‣ 5 Concept-based Interpretation Analysis ‣ Can LLMs Facilitate
    Interpretation of Pre-trained Language Models?"), include the number of discovered
    sub concepts in the column labeled # Sub Concepts and the Alignment column indicates
    the percentage of overlap in the top 10 neurons between the super and sub concepts
    for each specific adverb concept. The average alignment across all sub concepts
    is indicated next to the super concept. This observation held consistently across
    various properties (e.g. Nouns, Adjectives and Numbers) as shown in Table [5](#S5.F5
    "Figure 5 ‣ 5.2 Neuron Analysis ‣ 5 Concept-based Interpretation Analysis ‣ Can
    LLMs Facilitate Interpretation of Pre-trained Language Models?"). For further
    details please refer to Appendix [C](#A3 "Appendix C Neuron Analysis Results ‣
    Can LLMs Facilitate Interpretation of Pre-trained Language Models?")).'
  prefs: []
  type: TYPE_NORMAL
- en: Note that previously, we couldn’t identify neurons with such specific explanations,
    like distinguishing neurons for numbers related to currency values from those
    for years of birth or neurons differentiating between cricket and hockey-related
    terms. Our large scale concept annotation enables locating neurons that capture
    the fine-grained aspects of a concept. This enables applications such as manipulating
    network’s behavior in relation to that concept. For instance, Bau et al. ([2019](#bib.bib4))
    identified “tense” neurons within Neural Machine Translation (NMT) models and
    successfully changed the output from past to present tense by modifying the activation
    of these specific neurons. However, their study was restricted to very few coarse
    concepts for which annotations were available.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the ever-evolving capabilities of the LLMs, researchers are actively exploring
    innovative ways to harness their assistance. Prompt engineering, the process of
    crafting instructions to guide the behavior and extract relevant knowledge from
    these oracles, has emerged as a new area of research Lester et al. ([2021](#bib.bib34));
    Liu et al. ([2021](#bib.bib37)); Kojima et al. ([2023](#bib.bib31)); Abdelali
    et al. ([2023](#bib.bib1)); Dalvi et al. ([2023b](#bib.bib13)). Recent work has
    established LLMs as highly proficient annotators. Ding et al. ([2022](#bib.bib16))
    carried out evaluation of GPT-3’s performance as a data annotator for text classification
    and named entity recognition tasks, employing three primary methodologies to assess
    its effectiveness. Wang et al. ([2021](#bib.bib47)) showed that GPT-3 as an annotator
    can reduce cost from 50-96% compared to human annotations on 9 NLP tasks. They
    also showed that models trained using GPT-3 labeled data outperformed the GPT-3
    few-shot learner. Similarly, Gilardi et al. ([2023](#bib.bib22)) showed that ChatGPT
    achieves higher zero-shot accuracy compared to crowd-source workers in various
    annotation tasks, encompassing relevance, stance, topics, and frames detection.
    Our work is different from previous work done using GPT as annotator. We annotate
    the latent concepts encoded within the embedding space of pre-trained language
    models. We demonstrate how such a large scale annotation enriches representation
    analysis via application in probing classifiers and neuron analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The scope of previous studies in interpreting neural language models is limited
    to general ontologies or small-scale manually labeled concepts. In our research,
    we showcase the effectiveness of Large Language Models, specifically ChatGPT,
    as a valuable tool for annotating latent spaces in pre-trained language models.
    This large-scale annotation of latent concepts broadens the scope of interpretation
    from human-defined ontologies to encompass all concepts learned within the model,
    and eliminates the human-in-the-loop effort for annotating these concepts. We
    release a comprehensive GPT-annotated Transformers Concept Net (TCN) consisting
    of 39,000 concepts, extracted from a wide range of transformer language models.
    TCN empowers the researchers to carry out large-scale interpretation studies of
    these models. To demonstrate this, we employ two widely used techniques in the
    field of interpretability: probing classifiers and neuron analysis. This novel
    dimension of analysis, previously absent in earlier studies, sheds light on intricate
    aspects of these models. By showcasing the superiority, adaptability, and diverse
    applications of ChatGPT annotations, we lay the groundwork for a more comprehensive
    understanding of NLP models.'
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We list below limitations of our work:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While it has been demonstrated that LLMs significantly reduce the cost of annotations,
    the computational requirements and response latency can still become a significant
    challenge when dealing with extensive or high-throughput annotation pipeline like
    ours. In some cases it is important to provide contextual information along with
    the concept to obtain an accurate annotation, causing the cost go up. Nevertheless,
    this is a one time cost for any specific model, and there is optimism that future
    LLMs will become more cost-effective to run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existing LLMs are deployed with content policy filters aimed at preventing the
    dissemination of harmful, abusive, or offensive content. However, this limitation
    prevents the models from effectively labeling concepts that reveal sensitive information,
    such as cultural and racial biases learned within the model to be interpreted.
    For example, we were unable to extract a label for racial slurs in the hate speech
    detection task. This restricts our concept annotation approach to only tasks that
    are not sensitive to the content policy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The information in the world is evolving, and LLMs will require continuous updates
    to reflect the accurate state of the world. This may pose a challenge for some
    problems (e.g. news summarization task) where the model needs to reflect an updated
    state of the world.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Abdelali et al. (2023) Ahmed Abdelali, Hamdy Mubarak, Shammur Absar Chowdhury,
    Maram Hasanain, Basel Mousi, Sabri Boughorbel, Yassine El Kheir, Daniel Izham,
    Fahim Dalvi, Majd Hawasly, Nizi Nazar, Yousseif Elshahawy, Ahmed Ali, Nadir Durrani,
    Natasa Milic-Frayling, and Firoj Alam. 2023. [Benchmarking arabic ai with large
    language models](http://arxiv.org/abs/2305.14982).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alam et al. (2023) Firoj Alam, Fahim Dalvi, Nadir Durrani, Hassan Sajjad, Khan,
    Abdul Rafae, and Jia Xu. 2023. Conceptx: A framework for latent concept analysis.
    In *Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence
    (AAAI, Poster presentation)*, pages 16395–16397.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Antverg and Belinkov (2022) Omer Antverg and Yonatan Belinkov. 2022. [On the
    pitfalls of analyzing individual neurons in language models](https://openreview.net/forum?id=8uz0EWPQIMu).
    In *International Conference on Learning Representations*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bau et al. (2019) Anthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani,
    Fahim Dalvi, and James Glass. 2019. [Identifying and controlling important neurons
    in neural machine translation](https://openreview.net/forum?id=H1z-PsR5KX). In
    *Proceedings of the Seventh International Conference on Learning Representations*,
    ICLR ’19, New Orleans, USA.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belinkov et al. (2017a) Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan
    Sajjad, and James Glass. 2017a. [What do neural machine translation models learn
    about morphology?](https://doi.org/10.18653/v1/P17-1080) In *Proceedings of the
    55th Annual Meeting of the Association for Computational Linguistics*, ACL ’17,
    pages 861–872, Vancouver, Canada. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belinkov et al. (2020) Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan
    Sajjad, and James Glass. 2020. On the linguistic representational power of neural
    machine translation models. *Computational Linguistics*, 45(1):1–57.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Belinkov et al. (2017b) Yonatan Belinkov, Lluís Màrquez, Hassan Sajjad, Nadir
    Durrani, Fahim Dalvi, and James Glass. 2017b. [Evaluating layers of representation
    in neural machine translation on part-of-speech and semantic tagging tasks](https://www.aclweb.org/anthology/I17-1001).
    In *Proceedings of the Eighth International Joint Conference on Natural Language
    Processing (Volume 1: Long Papers)*, pages 1–10, Taipei, Taiwan. Asian Federation
    of Natural Language Processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. [Language models are few-shot learners](http://arxiv.org/abs/2005.14165).
    *CoRR*, abs/2005.14165.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conneau et al. (2020) Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav
    Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer,
    and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning
    at scale. In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics*, pages 8440–8451\. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Conneau et al. (2018) Alexis Conneau, German Kruszewski, Guillaume Lample,
    Loïc Barrault, and Marco Baroni. 2018. [What you can cram into a single $&!#*
    vector: Probing sentence embeddings for linguistic properties](https://doi.org/10.18653/v1/P18-1198).
    In *Proceedings of the 56th Annual Meeting of the Association for Computational
    Linguistics*, ACL ’18, pages 2126–2136, Melbourne, Australia. Association for
    Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dalvi et al. (2023a) Fahim Dalvi, Nadir Durrani, and Hassan Sajjad. 2023a.
    Neurox library for neuron analysis of deep nlp models. In *Proceedings of the
    61st Annual Meeting of the Association for Computational Linguistics: System Demonstrations*,
    pages 75–83, Toronto, Canada. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dalvi et al. (2019) Fahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov,
    D. Anthony Bau, and James Glass. 2019. What is one grain of sand in the desert?
    analyzing individual neurons in deep nlp models. In *Proceedings of the Thirty-Third
    AAAI Conference on Artificial Intelligence (AAAI, Oral presentation)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dalvi et al. (2023b) Fahim Dalvi, Maram Hasanain, Sabri Boughorbel, Basel Mousi,
    Samir Abdaljalil, Nizi Nazar, Ahmed Abdelali, Shammur Absar Chowdhury, Hamdy Mubarak,
    Ahmed Ali, Majd Hawasly, Nadir Durrani, and Firoj Alam. 2023b. [Llmebench: A flexible
    framework for accelerating llms benchmarking](http://arxiv.org/abs/2308.04945).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dalvi et al. (2022) Fahim Dalvi, Abdul Rafae Khan, Firoj Alam, Nadir Durrani,
    Jia Xu, and Hassan Sajjad. 2022. [Discovering latent concepts learned in BERT](https://openreview.net/forum?id=POTMtpYI1xH).
    In *International Conference on Learning Representations*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language
    understanding. In *Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies*,
    NAACL-HLT ’19, pages 4171–4186, Minneapolis, Minnesota, USA. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ding et al. (2022) Bosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing, Shafiq
    Joty, and Boyang Li. 2022. [Is gpt-3 a good data annotator?](http://arxiv.org/abs/2212.10450)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Durrani et al. (2022) Nadir Durrani, Fahim Dalvi, and Hassan Sajjad. 2022.
    [Linguistic correlation analysis: Discovering salient neurons in deepnlp models](http://arxiv.org/abs/2206.13288).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Durrani et al. (2021) Nadir Durrani, Hassan Sajjad, and Fahim Dalvi. 2021.
    How transfer learning impacts linguistic knowledge in deep nlp models? In *Findings
    of the Association for Computational Linguistics: ACL 2021*, Online. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fleiss et al. (2013) Joseph L Fleiss, Bruce Levin, and Myunghee Cho Paik. 2013.
    *Statistical methods for rates and proportions*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu and Lapata (2022) Yao Fu and Mirella Lapata. 2022. [Latent topology induction
    for understanding contextualized representations](https://doi.org/10.48550/ARXIV.2206.01512).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geva et al. (2021) Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy.
    2021. [Transformer feed-forward layers are key-value memories](https://doi.org/10.18653/v1/2021.emnlp-main.446).
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing*, pages 5484–5495, Online and Punta Cana, Dominican Republic. Association
    for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gilardi et al. (2023) Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. 2023.
    [Chatgpt outperforms crowd-workers for text-annotation tasks](http://arxiv.org/abs/2303.15056).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gowda and Krishna (1978) K Chidananda Gowda and G Krishna. 1978. Agglomerative
    clustering using the concept of mutual nearest neighbourhood. *Pattern recognition*,
    10(2):105–112.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2023) Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie,
    Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023. [How close is chatgpt to human
    experts? comparison corpus, evaluation, and detection](http://arxiv.org/abs/2301.07597).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hennigen et al. (2020) Lucas Torroba Hennigen, Adina Williams, and Ryan Cotterell.
    2020. [Intrinsic probing through dimension selection](https://doi.org/10.18653/v1/2020.emnlp-main.15).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 197–216, Online. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hewitt and Liang (2019) John Hewitt and Percy Liang. 2019. [Designing and interpreting
    probes with control tasks](https://doi.org/10.18653/v1/D19-1275). In *Proceedings
    of the 2019 Conference on Empirical Methods in Natural Language Processing and
    the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)*,
    pages 2733–2743, Hong Kong, China.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jeblick et al. (2022) Katharina Jeblick, Balthasar Schachtner, Jakob Dexl,
    Andreas Mittermeier, Anna Theresa Stüber, Johanna Topalis, Tobias Weber, Philipp
    Wesp, Bastian Sabel, Jens Ricke, and Michael Ingrisch. 2022. [Chatgpt makes medicine
    easy to swallow: An exploratory case study on simplified radiology reports](http://arxiv.org/abs/2212.14882).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kádár et al. (2017) Akos Kádár, Grzegorz Chrupała, and Afra Alishahi. 2017.
    Representation of linguistic form and function in recurrent neural networks. *Computational
    Linguistics*, 43(4):761–780.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karpathy et al. (2015) Andrej Karpathy, Justin Johnson, and Li Fei-Fei. 2015.
    Visualizing and understanding recurrent networks. *arXiv preprint arXiv:1506.02078*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kingma and Ba (2014) Diederik Kingma and Jimmy Ba. 2014. Adam: A Method for
    Stochastic Optimization. *arXiv preprint arXiv:1412.6980*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kojima et al. (2023) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2023. [Large language models are zero-shot reasoners](http://arxiv.org/abs/2205.11916).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lan et al. (2019) Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel,
    Piyush Sharma, and Radu Soricut. 2019. [ALBERT: a lite BERT for self-supervised
    learning of language representations](http://arxiv.org/abs/1909.11942). *ArXiv:1909.11942*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Landis and Koch (1977) J Richard Landis and Gary G Koch. 1977. The measurement
    of observer agreement for categorical data. *biometrics*, pages 159–174.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lester et al. (2021) Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. [The
    power of scale for parameter-efficient prompt tuning](https://doi.org/10.18653/v1/2021.emnlp-main.243).
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing*, pages 3045–3059, Online and Punta Cana, Dominican Republic. Association
    for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linzen et al. (2016) Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg. 2016. Assessing
    the Ability of LSTMs to Learn Syntax-Sensitive Dependencies. *Transactions of
    the Association for Computational Linguistics*, 4:521–535.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019a) Nelson F. Liu, Matt Gardner, Yonatan Belinkov, Matthew E.
    Peters, and Noah A. Smith. 2019a. [Linguistic knowledge and transferability of
    contextual representations](https://www.aclweb.org/anthology/N19-1112). In *Proceedings
    of the 2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies*, NAACL ’19, pages 1073–1094, Minneapolis,
    Minnesota, USA. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2021) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. 2021. [Pre-train, prompt, and predict: A systematic
    survey of prompting methods in natural language processing](http://arxiv.org/abs/2107.13586).
    *CoRR*, abs/2107.13586.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019b) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019b.
    [RoBERTa: A robustly optimized BERT pretraining approach](https://arxiv.org/abs/1907.11692).
    *ArXiv:1907.11692*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meng et al. (2023) Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.
    2023. [Locating and editing factual associations in gpt](http://arxiv.org/abs/2202.05262).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Michael et al. (2020) Julian Michael, Jan A. Botha, and Ian Tenney. 2020. [Asking
    without telling: Exploring latent ontologies in contextual representations](https://doi.org/10.18653/v1/2020.emnlp-main.552).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing*, EMNLP ’20, pages 6792–6812, Online. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mikolov et al. (2013) Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
    2013. Efficient estimation of word representations in vector space. In *Proceedings
    of the ICLR Workshop*, Scottsdale, AZ, USA.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qian et al. (2016) Peng Qian, Xipeng Qiu, and Xuanjing Huang. 2016. [Investigating
    Language Universal and Specific Properties in Word Embeddings](http://www.aclweb.org/anthology/P16-1140).
    In *Proceedings of the 54th Annual Meeting of the Association for Computational
    Linguistics*, ACL ’16, pages 1478–1488, Berlin, Germany. Association for Computational
    Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sajjad et al. (2022a) Hassan Sajjad, Nadir Durrani, and Fahim Dalvi. 2022a.
    [Neuron-level interpretation of deep NLP models: A survey](https://doi.org/10.1162/tacl_a_00519).
    *Transactions of the Association for Computational Linguistics*, 10:1285–1303.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sajjad et al. (2022b) Hassan Sajjad, Nadir Durrani, Fahim Dalvi, Firoj Alam,
    Abdul Rafae Khan, and Jia Xu. 2022b. Analyzing encoded concepts in transformer
    language models. In *Proceedings of the 2022 Conference of the North American
    Chapter of the Association for Computational Linguistics*, NAACL ’22, Seattle,
    Washington, USA. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tenney et al. (2019) Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019. [BERT
    rediscovers the classical NLP pipeline](https://doi.org/10.18653/v1/P19-1452).
    In *Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics*, pages 4593–4601, Florence, Italy. Association for Computational
    Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vylomova et al. (2017) Ekaterina Vylomova, Trevor Cohn, Xuanli He, and Gholamreza
    Haffari. 2017. [Word representation models for morphologically rich languages
    in neural machine translation](https://doi.org/10.18653/v1/W17-4115). pages 103–108.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2021) Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu, and Michael
    Zeng. 2021. [Want to reduce labeling cost? gpt-3 can help](http://arxiv.org/abs/2108.13487).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2019) Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R
    Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining
    for language understanding. *Advances in neural information processing systems*,
    32.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023) Bowen Zhang, Daijun Ding, and Liwen Jing. 2023. [How would
    stance detection techniques evolve after the launch of chatgpt?](http://arxiv.org/abs/2212.14548)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Appendix A Prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A.1 Optimal Prompt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Initially, we used a simple prompt to ask the model to provide labels for a
    list of words keeping the system description unchanged:'
  prefs: []
  type: TYPE_NORMAL
- en: Assistant is a large language model trained by OpenAI
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt Body: Give the following list of words a short label: [‘‘word 1’’, ‘‘word
    2’’, ..., ‘‘word N’’]'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output format from the first prompt was unclear as it included illustrations,
    which was not our intention. After multiple design iterations, we developed a
    prompt that returned the labels in the desired format. In this revised prompt,
    we modified the system description as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Assistant is a large language model trained by OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instructions: When asked for labels, only the labels and nothing else should
    be returned.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We also modified the prompt body to:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Give a short and concise label that best describes the following list of words:
    [‘‘word 1’’, ‘‘word 2’’, ..., ‘‘word N’’]'
  prefs: []
  type: TYPE_NORMAL
- en: Figure [6](#A1.F6 "Figure 6 ‣ A.1 Optimal Prompt ‣ Appendix A Prompts ‣ Can
    LLMs Facilitate Interpretation of Pre-trained Language Models?") shows some sample
    concepts learned in the last layer of BERT-base-cased along with their labels.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/de81423447673da21d0076a0f16a09d9.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Geographic Locations in the US
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bcf293a76e02e1ebd1e9ec9d9e0a5bc8.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Middle East Conflict
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/76e298077d4b7620ea47e1aa6ad77814.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) LGBTQ+
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9c7864361c26febfa0c261e7542f0c38.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Female Names and titles
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d3d714a3b83ca93a49dbdd2440f8227e.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) Spanish Male Names
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bdf16269bd981e057e590ae0579d0868.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) Gender related nouns and pronouns
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/68b836b98e5e4416ba0f1e8313ebae2c.png)'
  prefs: []
  type: TYPE_IMG
- en: (g) Geographic Locations in California
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d6257e3ebb75b8baef2044150360c075.png)'
  prefs: []
  type: TYPE_IMG
- en: (h) SE Asian Politics and Ethnic Conflict
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/00f1cf55d4b56bded1718ca9bad778f7.png)'
  prefs: []
  type: TYPE_IMG
- en: (i) List of cities and universities in southeastern US
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Sample Concepts Learned in the last layer of BERT'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/05d90564a47d55da295557e69cc12895.png)'
  prefs: []
  type: TYPE_IMG
- en: (a)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5930f5ab222ee0ac77e3794d73d50e1a.png)'
  prefs: []
  type: TYPE_IMG
- en: (b)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4c987d6d1908b5bf7d85d150e39c1230.png)'
  prefs: []
  type: TYPE_IMG
- en: (c)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/05d90564a47d55da295557e69cc12895.png)'
  prefs: []
  type: TYPE_IMG
- en: (d)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4cb4af64fb109c53d75d93883f83585a.png)'
  prefs: []
  type: TYPE_IMG
- en: (e)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dae2ce1bc7bee24e902341f88d4eb5f5.png)'
  prefs: []
  type: TYPE_IMG
- en: (f)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7: Failed Requests in Albert'
  prefs: []
  type: TYPE_NORMAL
- en: '| Tag | Human Label | 1 Label Response | 3-Keyword Response |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| c533 | LEX:hyphenated | Superlative and ordinal adjectives. | [’second’,
    ’highest’, ’biggest’] |'
  prefs: []
  type: TYPE_TB
- en: '| c84 | LEX:hyphenated | Accomplishments and Awards | [’Award-winning’, ’Nominated’,
    ’Multi-time’] |'
  prefs: []
  type: TYPE_TB
- en: '| c783 | LEX:hyphenated | Sports scores and point differentials. | [’points’,
    ’wins’, ’scores’] |'
  prefs: []
  type: TYPE_TB
- en: '| c621 | LEX:hyphenated | Describing people’s relationships and family status.
    | [family, relationships, parenthood] |'
  prefs: []
  type: TYPE_TB
- en: '| c869 | LEX:hyphenated | Tennis Scores. | [’Tennis’, ’Scores’, ’Games’] |'
  prefs: []
  type: TYPE_TB
- en: '| c833 | LEX:hyphenated | Location-based adjectives | [based, area, listed]
    |'
  prefs: []
  type: TYPE_TB
- en: '| c588 | LEX:hyphenated | US political party affiliations by state and district.
    | [Republican, Democrat, State Abbreviations] |'
  prefs: []
  type: TYPE_TB
- en: '| c639 | LEX:hyphenated | Football scores. | [’Scores’, ’Football’, ’Winning’]
    |'
  prefs: []
  type: TYPE_TB
- en: '| c934 | LEX:hyphenated | Sports scores. | [’scores’, ’victories’, ’defeats’]
    |'
  prefs: []
  type: TYPE_TB
- en: '| c850 | LEX:case:title_case | Philippine Places and Names | [’Philippines’,
    ’Tourism’, ’Volcano’] |'
  prefs: []
  type: TYPE_TB
- en: '| c286 | LEX:case:title_case | List of surnames. | [Last names, English, List]
    |'
  prefs: []
  type: TYPE_TB
- en: '| c982 | LEX:case:title_case | Sports-related terms. | [’Football’, ’Sports’,
    ’Legends’] |'
  prefs: []
  type: TYPE_TB
- en: '| c231 | SYN:position:first_word | Sports Terminology | [’Footballers’, ’Tries’,
    ’Substitutes’] |'
  prefs: []
  type: TYPE_TB
- en: '| c784 | SYN:position:first_word | Numerical data. | [Numbers, Decimals, List]
    |'
  prefs: []
  type: TYPE_TB
- en: '| c728 | SYN:position:first_word | Action-oriented verbs and adjectives. |
    [Improving, Ensuring, Capturing] |'
  prefs: []
  type: TYPE_TB
- en: '| c672 | SYN:position:first_word | Verbs describing actions and states. | [Fluent,
    Struggling, Showcasing] |'
  prefs: []
  type: TYPE_TB
- en: '| c886 | LEX:case:title_case | Describing communication actions. | [Referring,
    Recalling, Revealing] |'
  prefs: []
  type: TYPE_TB
- en: '| c865 | LEX:case:title_case | Baseball player names. | [Bregman, Scherzer,
    Puig] |'
  prefs: []
  type: TYPE_TB
- en: '| c734 | LEX:case:title_case | Island names. | [’Islands’, ’Caribbean’, ’Indian
    Ocean’] |'
  prefs: []
  type: TYPE_TB
- en: '| c818 | LEX:case:title_case | Ethnicities and Cities in the Balkans | [’Bosnian’,
    ’Albanian’, ’Yugoslavia’] |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Prompting ChatGPT to label a concept with keywords instead of one
    label'
  prefs: []
  type: TYPE_NORMAL
- en: A.2 Prompts For Lexical Concepts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: During the error analysis (Section [4.2](#S4.SS2 "4.2 Error Analysis ‣ 4 Evaluation
    and Analysis ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?")),
    we discovered that GPT struggled to accurately label concepts composed of words
    sharing a lexical property, such as a common suffix. However, we were able to
    devise a solution to address this issue by curating the prompt to effectively
    label such concepts. We modified the prompt to identify concepts that contain
    common n-grams.
  prefs: []
  type: TYPE_NORMAL
- en: Give a short and concise label describing the common ngrams between the words
    of the given list
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Only one common ngram should be returned. If there is no common ngram
    reply with ‘NA’'
  prefs: []
  type: TYPE_NORMAL
- en: Using this improved we were able to correct 100% of the labeling errors in the
    concepts having lexical coherence. See Figure [8](#A1.F8 "Figure 8 ‣ A.3 Prompts
    for POS Concepts ‣ Appendix A Prompts ‣ Can LLMs Facilitate Interpretation of
    Pre-trained Language Models?")a for example. With the default prompt it was labelled
    as Superlative and ordinal adjectives and with the modified prompt, it was labeled
    as Hyphenated, cased & -based suffix.
  prefs: []
  type: TYPE_NORMAL
- en: A.3 Prompts for POS Concepts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Similarly we were able to modify the prompt to correctly label concepts that
    were made from words having common parts-of-speech. From the prompts we tested,
    the best performing one is below:'
  prefs: []
  type: TYPE_NORMAL
- en: Give a short and concise label describing the common part of speech tag between
    the words of the given list
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: The part of speech tag should be chosen from the Penn Treebank. If there’s
    no common part of speech tag reply with ‘NA’'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Figure [8](#A1.F8 "Figure 8 ‣ A.3 Prompts for POS Concepts ‣ Appendix A
    Prompts ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?")b,
    we present an example of a concept labeled as Surnames with ‘Mc’ prefix. However,
    it is important to note that not all the names in this concept actually begin
    with the “Mc” prefix. The appropriate label for this concept would be NNP: Proper
    Nouns or SEM: Irish Names. With the POS-based prompt, we are able to achieve the
    former.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a864683d5c02f87042dc868ca20b70d4.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Hyphenated,cased & -based suffix
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/72c33cd6eb157b27b1bd594aca632e83.png)'
  prefs: []
  type: TYPE_IMG
- en: '(b) NNP: Proper Nouns'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: Illustrating lexical and POS concepts: (a) A concept that exhibits
    multiple lexical properties, such as being hyphenated and cased. ChatGPT assigns
    a label based on the shared "-based" ngram found among most words in the cluster.
    (b) ChatGPT labeled this concept as NNP (proper noun)'
  prefs: []
  type: TYPE_NORMAL
- en: A.4 Providing Context
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our analysis revealed that including contextual information is crucial for accurately
    labeling concepts in certain cases. As shown in Figure [9](#A1.F9 "Figure 9 ‣
    A.4 Providing Context ‣ Appendix A Prompts ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?"), concepts were incorrectly labeled as Numerical
    Data despite representing different entities. Incorporating context enables us
    to obtain more specific labels. However, we face limitations in the number of
    input tokens we can provide to the model, which impacts the quality of the labels.
    Using context of 10 sentences we were able to correct 9 of the 38 erroneous labels.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e66e1e00b1c4eb80626e33ea6e9575e6.png)'
  prefs: []
  type: TYPE_IMG
- en: (a)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a4e0d19a27a8d73740a1b2c5409f1aa6.png)'
  prefs: []
  type: TYPE_IMG
- en: (b)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/63b75ff82b27819a26839f0d0d202c9d.png)'
  prefs: []
  type: TYPE_IMG
- en: (c)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9: Highlighting the Significance of Context: (a) Money Figures (b) Percentages
    (c) Baseball Scores. All of these concepts were mislabeled as Numerical values
    by ChatGPT. Providing the context sentences we are able to obtain the correct
    label'
  prefs: []
  type: TYPE_NORMAL
- en: A.5 Other Details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tokens Versus Types
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We observed that the quality of labels is influenced by the word frequency in
    the given list. Using tokens instead of types leads to more meaningful labels.
    However, when the latent concept includes hate speech words, passing a token list
    results in failed requests due to content policy violations. In such cases, we
    opted to pass the list of types instead. Although this mitigates the issue to
    a certain extent, it does not completely resolve it. Refer to Figure [7](#A1.F7
    "Figure 7 ‣ A.1 Optimal Prompt ‣ Appendix A Prompts ‣ Can LLMs Facilitate Interpretation
    of Pre-trained Language Models?") for examples of failed requests with Albert.
  prefs: []
  type: TYPE_NORMAL
- en: Keyword prompts
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We also explored prompts to return 3 keywords that describe the concept instead
    of returning a concise label in an effort to produce multiple labels like BCN.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: When asked for keywords, only the keywords and nothing else should be returned.
  prefs: []
  type: TYPE_NORMAL
- en: If asked for 3 keywords, the keywords should be returned in the form of [keyword_1,
    keyword_2, keyword_3]
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure compliance with our desired output format, we introduced a second
    instruction since the model was not following the first instruction as intended.
    We also modified the prompt body to:'
  prefs: []
  type: TYPE_NORMAL
- en: Give 3 keywords that best describe the following list of words
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this prompt did not provide accurate labels, as illustrated in
    Table [5](#A1.T5 "Table 5 ‣ A.1 Optimal Prompt ‣ Appendix A Prompts ‣ Can LLMs
    Facilitate Interpretation of Pre-trained Language Models?").
  prefs: []
  type: TYPE_NORMAL
- en: '| tag | Label | BERT | Sel | ALBERT | Sel | XLNet | Sel | XLM-R | Sel | RoBERTa
    | Sel |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| c301 | Gender-related Nouns and pronouns | 0.98 | 0.16 | 0.95 | 0.14 | 0.86
    | 0.24 | 0.94 | 0.23 | 0.95 | 0.26 |'
  prefs: []
  type: TYPE_TB
- en: '| c533 | LGBTQ+ | 1 | 0.18 | 0.97 | 0.33 | 0.97 | 0.43 | 1 | 0.25 | 1 | 0.14
    |'
  prefs: []
  type: TYPE_TB
- en: '| c439 | Sports commentary terms | 0.94 | 0.2 | 0.91 | 0.18 | 0.81 | 0.05 |
    0.87 | 0.11 | 0.86 | 0.09 |'
  prefs: []
  type: TYPE_TB
- en: '| c173 | Football team names and stadiums | 0.94 | 0.2 | 0.96 | 0.27 | 0.94
    | 0.24 | 0.95 | 0.2 | 0.97 | 0.34 |'
  prefs: []
  type: TYPE_TB
- en: '| c348 | Female names and titles | 0.98 | 0.29 | 0.98 | 0.29 | 0.94 | 0.21
    | 0.96 | 0.16 | 0.97 | 0.24 |'
  prefs: []
  type: TYPE_TB
- en: '| c149 | Tennis players’ names | 0.98 | 0.27 | 0.95 | 0.25 | 0.92 | 0.19 |
    0.92 | 0.17 | 0.92 | 0.19 |'
  prefs: []
  type: TYPE_TB
- en: '| c487 | Spanish Male Names | 0.95 | 0.26 | 0.96 | 0.07 | 0.94 | 0.37 | 0.91
    | 0.25 | 0.98 | 0.28 |'
  prefs: []
  type: TYPE_TB
- en: '| c564 | Cities and Universities in southeastern US | 0.97 | 0.12 | 0.97 |
    0.11 | 0.9 | 0.18 | 0.97 | 0.29 | 0.96 | 0.22 |'
  prefs: []
  type: TYPE_TB
- en: '| c263 | Locations in New York City | 0.95 | 0.25 | 0.95 | 0.22 | 0.92 | 0.26
    | 0.95 | 0.26 | 0.95 | 0.17 |'
  prefs: []
  type: TYPE_TB
- en: '| c247 | Scandinavian/Nordic names and places | 0.97 | 0.22 | 0.98 | 0.27 |
    0.95 | 0.29 | 0.96 | 0.21 | 0.98 | 0.29 |'
  prefs: []
  type: TYPE_TB
- en: '| c438 | Verbs for various actions and outcomes | 0.97 | 0.12 | 0.94 | 0.09
    | 0.87 | 0.23 | 0.92 | 0.11 | 0.92 | 0.14 |'
  prefs: []
  type: TYPE_TB
- en: '| c44 | Southeast Asian Politics and Ethnic Conflict | 0.97 | 0.17 | 0.97 |
    0.19 | 0.94 | 0.25 | 0.93 | 0.09 | 0.95 | 0.16 |'
  prefs: []
  type: TYPE_TB
- en: '| c421 | Names of people and places in the middle east | 0.97 | 0.06 | 0.94
    | 0.28 | 0.95 | 0.22 | 0.93 | 0.31 | 0.92 | 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '| c245 | Middle East conflict | 0.98 | 0.26 | 1 | 0.25 | 0.93 | 0.29 | 0.93
    | 0.25 | 0.95 | 0.22 |'
  prefs: []
  type: TYPE_TB
- en: '| c553 | Islamic terminology | 1 | 0.15 | 0.96 | 0.4 | 0.89 | 0.29 | 0.89 |
    0.16 | 0.95 | 0.26 |'
  prefs: []
  type: TYPE_TB
- en: '| c365 | Criminal activities | 0.97 | 0.15 | 0.93 | 0.17 | 0.89 | 0.35 | 0.9
    | 0.15 | 0.93 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| c128 | Medical and Healthcare terminology | 0.98 | 0.17 | 0.98 | 0.21 | 0.95
    | 0.15 | 0.94 | 0.24 | 0.95 | 0.27 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: Training Probes towards latent concepts discovered in various Models.
    Reporting classifier accuracy on test-set along with respective selectivity numbers'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Probing Classifiers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: B.1 Running Probes At Scale
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Probing For Fine-grained Semantic Concepts
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We used the NeuroX toolkit to train a linear probe for several concepts chosen
    from layers 3, 9 and 12 of BERT-base-cased. We used a train/val/test splits of
    0.6, 0.2, 0.2 respectively. Tables [7](#A2.T7 "Table 7 ‣ Probing For Fine-grained
    Semantic Concepts ‣ B.1 Running Probes At Scale ‣ Appendix B Probing Classifiers
    ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?") and [8](#A2.T8
    "Table 8 ‣ Probing For Fine-grained Semantic Concepts ‣ B.1 Running Probes At
    Scale ‣ Appendix B Probing Classifiers ‣ Can LLMs Facilitate Interpretation of
    Pre-trained Language Models?") show the data statistics and the probe results
    respectively. Table [9](#A2.T9 "Table 9 ‣ Probing For Fine-grained Semantic Concepts
    ‣ B.1 Running Probes At Scale ‣ Appendix B Probing Classifiers ‣ Can LLMs Facilitate
    Interpretation of Pre-trained Language Models?") shows results of probes trained
    on concepts chosen from multiple layers of ALBERT. In Table [6](#A1.T6 "Table
    6 ‣ Keyword prompts ‣ A.5 Other Details ‣ Appendix A Prompts ‣ Can LLMs Facilitate
    Interpretation of Pre-trained Language Models?") we carried out a cross architectural
    comparison across the models by training probes towards the same set of concepts.
  prefs: []
  type: TYPE_NORMAL
- en: '| Layer | Tag | Label | Tokens | Types | Sents | Train | Val | Test |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c90 | Financial terms. | 220 | 22 | 214 | 285 | 95 | 96 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c336 | Photography-related terms. | 290 | 29 | 273 | 388 | 130 | 130
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c112 | Middle Eastern Conflict | 620 | 62 | 523 | 992 | 331 | 331 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c506 | Diversity and Ethnicity. | 240 | 24 | 225 | 331 | 111 | 112 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c390 | List of surnames. | 4298 | 430 | 4049 | 5530 | 1844 | 1844 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c331 | Emotions/Feelings. | 400 | 40 | 396 | 484 | 162 | 162 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c592 | Animal names. | 220 | 22 | 208 | 268 | 90 | 90 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c25 | Keywords related to discrimination and inequality. | 340 | 34 |
    325 | 440 | 147 | 147 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c500 | List of female names. | 2913 | 292 | 2735 | 3867 | 1289 | 1290
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c414 | Healthcare | 510 | 51 | 475 | 752 | 251 | 251 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c31 | List of male first names. | 1130 | 113 | 1078 | 1422 | 474 | 474
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c173 | Animals | 760 | 76 | 704 | 994 | 332 | 332 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c72 | Natural Disasters and Weather Events | 701 | 71 | 635 | 1022 |
    341 | 341 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c514 | English counties | 297 | 30 | 286 | 373 | 124 | 125 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c178 | Body Parts | 430 | 43 | 405 | 588 | 196 | 196 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c340 | Media and Journalism. | 379 | 38 | 365 | 518 | 173 | 173 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c432 | Power and Status. | 310 | 31 | 306 | 385 | 128 | 129 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c8 | Verbs | 1028 | 103 | 1018 | 1243 | 414 | 415 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c408 | -Verbs ending in "-ing" | 510 | 51 | 504 | 615 | 205 | 206 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c479 | City names | 130 | 13 | 127 | 159 | 53 | 54 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c343 | Surnames | 490 | 49 | 464 | 613 | 204 | 205 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c577 | Disability-related terms. | 140 | 14 | 133 | 172 | 58 | 58 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c26 | Negative sentiment. | 798 | 118 | 782 | 1036 | 346 | 346 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c122 | Security Measures | 457 | 70 | 446 | 584 | 195 | 195 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c423 | Label: Islamic Extremism/Terrorism | 248 | 30 | 222 | 357 | 119
    | 120 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c299 | Middle Eastern and North African countries and cities | 531 |
    57 | 460 | 844 | 282 | 282 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c192 | Diversity and Identity | 314 | 50 | 279 | 506 | 169 | 169 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c468 | Russian male names. | 125 | 18 | 123 | 153 | 51 | 52 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c588 | Gender-related terms. | 161 | 19 | 146 | 236 | 79 | 79 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c74 | Financial terms | 672 | 96 | 607 | 1118 | 373 | 373 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c503 | Middle East Conflict. | 230 | 27 | 185 | 404 | 135 | 135 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c325 | Violent Crimes | 292 | 60 | 287 | 386 | 129 | 129 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c535 | Academic Research. | 233 | 26 | 227 | 332 | 111 | 111 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c256 | List of names | 1069 | 149 | 1026 | 1375 | 458 | 459 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c507 | Positive Adjectives | 389 | 69 | 380 | 505 | 168 | 169 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c345 | List of Chinese surnames. | 407 | 65 | 378 | 567 | 189 | 190 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c259 | List of names | 223 | 174 | 221 | 273 | 91 | 92 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c62 | Adverbs | 1221 | 351 | 1133 | 3769 | 1256 | 1257 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c128 | Medical and Healthcare Terminology. | 395 | 70 | 369 | 662 |
    221 | 221 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c301 | Gender-related nouns and pronouns. | 418 | 74 | 377 | 883 | 294
    | 295 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c37 | List of male names. | 872 | 372 | 807 | 1460 | 487 | 487 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c281 | Adverbs | 928 | 264 | 927 | 1178 | 393 | 393 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c220 | List of surnames. | 3886 | 832 | 3652 | 6378 | 2126 | 2126 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c432 | List of Male Names | 279 | 159 | 227 | 474 | 158 | 158 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c439 | Sports commentary terms. | 250 | 181 | 189 | 687 | 229 | 230
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c173 | List of football team names and stadiums. | 373 | 81 | 287 |
    849 | 283 | 284 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c348 | List of female names and titles. | 575 | 301 | 571 | 774 | 258
    | 258 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c142 | Conflict and War | 407 | 106 | 385 | 582 | 194 | 194 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c245 | Middle East Conflict | 249 | 42 | 196 | 453 | 151 | 152 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c210 | List of male first names. | 317 | 205 | 268 | 470 | 157 | 157
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c564 | List of cities and universities in the southeastern United States.
    | 175 | 21 | 162 | 229 | 76 | 77 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c533 | LGBTQ+ | 131 | 15 | 118 | 188 | 63 | 63 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c19 | Complex relationships and interactions between family members
    and partners. | 346 | 56 | 333 | 546 | 182 | 182 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c263 | Locations in New York City | 205 | 48 | 186 | 386 | 129 | 129
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c487 | List of Spanish male names. | 184 | 63 | 174 | 242 | 81 | 81
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c247 | Scandinavian/Nordic names and places. | 334 | 64 | 305 | 502
    | 168 | 168 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c44 | Southeast Asian Politics and Ethnic Conflict | 210 | 33 | 149
    | 332 | 111 | 111 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c438 | Verbs for various actions and outcomes. | 896 | 377 | 847 | 1600
    | 534 | 534 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c421 | Names of people and places in the Middle East | 270 | 48 | 230
    | 361 | 120 | 121 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c553 | Islamic Terminology. | 164 | 26 | 146 | 253 | 84 | 85 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c149 | List of tennis players’ names. | 238 | 82 | 183 | 394 | 132 |
    132 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c365 | Criminal activities | 365 | 88 | 337 | 496 | 166 | 166 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7: Statistics for concepts extracted from Bert-base-cased and the training,
    dev, test splits used to train the classifier'
  prefs: []
  type: TYPE_NORMAL
- en: '| Layer | Tag | Label | val acc | val C acc | sel val | test acc | test c acc
    | sel test |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c90 | Financial terms. | 0.98 | 0.65 | 0.33 | 0.98 | 0.78 | 0.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c336 | Photography-related terms. | 0.99 | 0.74 | 0.25 | 1 | 0.76 | 0.24
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c112 | Middle Eastern Conflict | 0.99 | 0.89 | 0.10 | 1 | 0.86 | 0.14
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c506 | Diversity and Ethnicity. | 1 | 0.78 | 0.22 | 0.98 | 0.75 | 0.23
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c390 | List of surnames. | 0.97 | 0.82 | 0.15 | 0.97 | 0.82 | 0.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c331 | Emotions/Feelings. | 0.98 | 0.82 | 0.16 | 0.99 | 0.78 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c592 | Animal names. | 1 | 0.68 | 0.32 | 1 | 0.73 | 0.27 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c25 | Keywords related to discrimination and inequality. | 0.99 | 0.81
    | 0.18 | 0.98 | 0.77 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c500 | List of female names. | 0.98 | 0.82 | 0.16 | 0.99 | 0.83 | 0.16
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c414 | Healthcare | 1 | 0.77 | 0.23 | 1 | 0.79 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c31 | List of male first names. | 0.99 | 0.85 | 0.14 | 1 | 0.83 | 0.17
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c173 | Animals | 0.99 | 0.78 | 0.21 | 0.99 | 0.75 | 0.24 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c72 | Natural Disasters and Weather Events | 0.99 | 0.80 | 0.19 | 0.99
    | 0.78 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c514 | English counties | 1 | 0.74 | 0.26 | 1 | 0.76 | 0.24 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c178 | Body Parts | 0.99 | 0.84 | 0.15 | 0.98 | 0.89 | 0.9 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c340 | Media and Journalism. | 0.98 | 0.76 | 0.22 | 1 | 0.78 | 0.22 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c432 | Power and Status. | 0.99 | 0.79 | 0.20 | 1 | 0.78 | 0.22 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c8 | Verbs | 0.99 | 0.88 | 0.11 | 0.99 | 0.89 | 0.10 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c408 | -Verbs ending in "-ing" | 1 | 0.68 | 0.32 | 1 | 0.73 | 0.27 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c479 | City names | 0.98 | 0.68 | 0.30 | 1 | 0.83 | 0.17 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c343 | Surnames | 1 | 0.74 | 0.26 | 0.98 | 0.74 | 0.24 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c577 | Disability-related terms. | 1 | 0.82 | 0.18 | 1 | 0.78 | 0.22
    |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c26 | Negative sentiment. | 0.98 | 0.79 | 0.19 | 0.99 | 0.8 | 0.19 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c122 | Security Measures | 0.98 | 0.81 | 0.17 | 0.99 | 0.82 | 0.17 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c423 | Label: Islamic Extremism/Terrorism | 1 | 0.77 | 0.23 | 1 | 0.85
    | 0.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c299 | Middle Eastern and North African countries and cities | 0.99 |
    0.79 | 0.2 | 0.99 | 0.78 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c192 | Diversity and Identity | 0.99 | 0.88 | 0.11 | 0.98 | 0.88 | 0.1
    |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c468 | Russian male names. | 1 | 0.63 | 0.37 | 1 | 0.61 | 0.39 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c588 | Gender-related terms. | 1 | 0.69 | 0.31 | 0.99 | 0.76 | 0.23 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c74 | Financial terms | 0.99 | 0.86 | 0.13 | 0.97 | 0.83 | 0.14 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c503 | Middle East Conflict. | 0.99 | 0.75 | 0.24 | 0.99 | 0.71 | 0.28
    |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c325 | Violent Crimes | 0.99 | 0.78 | 0.21 | 0.98 | 0.82 | 0.16 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c535 | Academic Research. | 1 | 0.88 | 0.12 | 0.99 | 0.84 | 0.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c256 | List of names | 0.98 | 0.76 | 0.22 | 0.98 | 0.74 | 0.24 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c507 | Positive Adjectives | 0.98 | 0.78 | 0.2 | 0.98 | 0.79 | 0.19 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | c345 | List of Chinese surnames. | 0.99 | 0.86 | 0.13 | 1 | 0.87 | 0.13
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c259 | List of names | 0.98 | 0.89 | 0.09 | 0.99 | 0.89 | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c62 | Adverbs | 0.97 | 0.82 | 0.15 | 0.96 | 0.81 | 0.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c128 | Medical and Healthcare Terminology. | 0.99 | 0.8 | 0.19 | 0.98
    | 0.82 | 0.18 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c301 | Gender-related nouns and pronouns. | 0.98 | 0.8 | 0.18 | 0.98
    | 0.82 | 0.16 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c37 | List of male names. | 0.98 | 0.8 | 0.18 | 0.99 | 0.8 | 0.19 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c281 | Adverbs | 0.99 | 0.8 | 0.19 | 0.99 | 0.78 | 0.21 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c220 | List of surnames. | 0.97 | 0.86 | 0.11 | 0.96 | 0.85 | 0.11 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c432 | List of Male Names | 1 | 0.71 | 0.29 | 0.97 | 0.73 | 0.24 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c439 | Sports commentary terms. | 0.9 | 0.82 | 0.08 | 0.94 | 0.74 |
    0.20 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c173 | List of football team names and stadiums. | 0.99 | 0.82 | 0.17
    | 0.99 | 0.87 | 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c348 | List of female names and titles. | 0.99 | 0.75 | 0.24 | 0.98
    | 0.7 | 0.28 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c142 | Conflict and War | 0.97 | 0.86 | 0.11 | 0.96 | 0.86 | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c245 | Middle East Conflict | 0.99 | 0.76 | 0.23 | 0.98 | 0.72 | 0.26
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c210 | List of male first names | 0.97 | 0.71 | 0.26 | 0.97 | 0.74 |
    0.23 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c564 | List of cities and universities in the southeastern United States.
    | 0.99 | 0.76 | 0.23 | 0.97 | 0.85 | 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c533 | LGBTQ+ | 1 | 0.71 | 0.29 | 1 | 0.82 | 0.18 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c19 | Complex relationships and interactions between family members
    and partners. | 0.98 | 0.79 | 0.19 | 0.98 | 0.81 | 0.17 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c263 | Locations in New York City | 0.95 | 0.67 | 0.28 | 0.95 | 0.7
    | 0.25 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c487 | List of Spanish male names. | 0.98 | 0.84 | 0.14 | 0.95 | 0.69
    | 0.26 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c247 | Scandinavian/Nordic names and places. | 0.98 | 0.77 | 0.21 |
    0.97 | 0.75 | 0.22 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c44 | Southeast Asian Politics and Ethnic Conflict | 0.96 | 0.85 | 0.11
    | 0.97 | 0.8 | 0.17 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c438 | Verbs for various actions and outcomes. | 0.97 | 0.83 | 0.14
    | 0.97 | 0.85 | 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c421 | Names of people and places in the Middle East | 0.98 | 0.91 |
    0.07 | 0.97 | 0.9 | 0.07 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c553 | Islamic Terminology. | 1 | 0.7 | 0.3 | 1 | 0.85 | 0.15 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c149 | List of tennis players’ names. | 0.95 | 0.73 | 0.22 | 0.98 |
    0.72 | 0.26 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c365 | Criminal activities | 0.95 | 0.77 | 0.18 | 0.97 | 0.82 | 0.15
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 8: Training Probing Classifiers for the concepts shown in Table [7](#A2.T7
    "Table 7 ‣ Probing For Fine-grained Semantic Concepts ‣ B.1 Running Probes At
    Scale ‣ Appendix B Probing Classifiers ‣ Can LLMs Facilitate Interpretation of
    Pre-trained Language Models?")'
  prefs: []
  type: TYPE_NORMAL
- en: '| Layer | Cluster Tag | Label | val acc | val C acc | sel val | test acc |
    test c acc | sel test |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c189 | Superlatives | 0.98 | 0.61 | 0.37 | 0.96 | 0.79 | 0.17 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c248 | Substance abuse. | 0.97 | 0.6 | 0.37 | 1 | 0.81 | 0.19 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c361 | LGBTQ+ and Gender-related Terms | 1 | 0.88 | 0.12 | 1 | 0.9 |
    0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c756 | Gender and Sex Labels | 0.87 | 0.72 | 0.15 | 1 | 0.8 | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c720 | Gender and Sex Labels | 1 | 0.74 | 0.26 | 1 | 0.55 | 0.45 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c402 | List of female names. | 0.97 | 0.72 | 0.25 | 0.98 | 0.82 | 0.16
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c127 | Geopolitical entities and affiliations. | 0.97 | 0.68 | 0.29
    | 0.98 | 0.57 | 0.41 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c707 | Names of US Presidents and Politicians | 1 | 0.55 | 0.45 | 1 |
    0.55 | 0.45 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | c101 | Speech verbs. | 0.98 | 0.84 | 0.14 | 1 | 0.7 | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c820 | Negative adjectives. | 1 | 0.81 | 0.19 | 0.97 | 0.86 | 0.11 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c769 | Food items. | 0.92 | 0.67 | 0.25 | 0.96 | 0.8 | 0.16 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c149 | Fruit and plant-related words. | 1 | 0.7 | 0.3 | 0.95 | 0.81 |
    0.14 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c705 | Tourism-related terms | 0.95 | 0.67 | 0.28 | 0.91 | 0.83 | 0.08
    |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c196 | Verbs of Authority and Request | 0.95 | 0.68 | 0.27 | 0.98 |
    0.89 | 0.09 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c398 | Energy sources. | 1 | 0.67 | 0.33 | 1 | 0.69 | 0.31 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | c185 | Gender-related terms | 0.98 | 0.64 | 0.34 | 0.96 | 0.68 | 0.28
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c213 | Finance and Taxation. | 0.97 | 0.81 | 0.16 | 0.98 | 0.65 | 0.33
    |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c92 | Descriptors of geographic regions and types of organizations. |
    1 | 0.73 | 0.27 | 0.98 | 0.84 | 0.14 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c659 | Locations in the United States | 1 | 0.88 | 0.12 | 1 | 0.61 |
    0.39 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c673 | List of Italian first names. | 1 | 0.93 | 0.07 | 0.89 | 0.8 |
    0.09 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c67 | List of male names. | 0.99 | 0.81 | 0.18 | 0.99 | 0.81 | 0.18 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c883 | Nouns | 0.97 | 0.83 | 0.14 | 0.99 | 0.81 | 0.18 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | c898 | TV Networks | 1 | 0.68 | 0.32 | 1 | 0.55 | 0.45 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | c653 | List of years. | 1 | 0.9 | 0.1 | 1 | 0.91 | 0.09 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | c697 | Military Terminology | 1 | 0.62 | 0.38 | 1 | 0.62 | 0.38 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | c560 | Political ideologies and systems. | 1 | 0.58 | 0.42 | 0.94 | 0.75
    | 0.19 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 9: Probe Results for some concepts chosen from several layers in ALBERT'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Neuron Analysis Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Neurons Associated with POS concepts
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We performed an annotation process on the final layer of a fine-tuned version
    of BERT-base-cased, specifically focusing on the task of parts-of-speech tagging.
    Once we obtained the labels, we organized them into super concepts based on a
    shared characteristic among smaller concepts. For instance, we grouped together
    various concepts labeled as nouns, as well as concepts representing adjectives,
    adverbs, and numerical data. To assess the alignment between the sub concepts
    and the super concept, we calculated the occurrence percentage of the top 10 neurons
    from the sub concept within the top 10 neurons of the super concept. The outcomes
    of this analysis can be found in table [10](#A3.T10 "Table 10 ‣ Neurons Associated
    with the Names concepts ‣ Appendix C Neuron Analysis Results ‣ Can LLMs Facilitate
    Interpretation of Pre-trained Language Models?"), illustrating the average alignment
    between the sub concepts and the super concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Neurons Associated with the Names concepts
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We replicated the experiment using named entity concepts derived from the final
    layer of bert-base-cased. The findings are presented in table [11](#A3.T11 "Table
    11 ‣ Neurons Associated with the Names concepts ‣ Appendix C Neuron Analysis Results
    ‣ Can LLMs Facilitate Interpretation of Pre-trained Language Models?").
  prefs: []
  type: TYPE_NORMAL
- en: '| cluster | label | score |'
  prefs: []
  type: TYPE_TB
- en: '| c55 | Nouns | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c13 | Nouns | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c273 | Nouns | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c268 | Nouns | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c405 | Nouns | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| c315 | Nouns | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c231 | Nouns related to various activities and objects | 0.6 |'
  prefs: []
  type: TYPE_TB
- en: '| c468 | Nouns | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c524 | Nouns | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c387 | Nouns | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c279 | Nouns related to various industries and sectors | 0.6 |'
  prefs: []
  type: TYPE_TB
- en: '| c440 | Nouns related to various professions and groups | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c202 | Nouns | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c237 | Adjectives with no clear category or theme | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c299 | Adjectives describing attributes of products or services | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c96 | Adjectives describing ownership, operation or support of various entities
    and technologies | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c95 | Adjectives describing various types of related events or phenomena
    | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c198 | Adjectives with no clear label | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c53 | Comparative Adjectives | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c335 | Comparative Adjectives | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c531 | Comparative Adjectives | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c131 | Descriptive/Adjective Labels | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c505 | Location-based Adjectives | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c11 | Adjectives describing various types of entities | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| c466 | Adjectives describing ownership, operation, or support of various
    entities and technologies. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c419 | Adjectives describing negative or challenging situations. | 0.6 |'
  prefs: []
  type: TYPE_TB
- en: '| c128 | Adjectives describing the quality or appropriateness of something.
    | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c458 | Adjectives | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| c401 | Comparative Adjectives | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c444 | Time-related frequency adjectives | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| c52 | Adverbs. | 0.6 |'
  prefs: []
  type: TYPE_TB
- en: '| c155 | Adverbs of frequency and manner. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c136 | Adverbs of degree/intensity. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c58 | Adverbs of time and transition. | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c41 | Adverbs of degree and frequency. | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c589 | Adverb intensity/degree | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c265 | Adverbs of Probability and Certainty | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c251 | Adverbs of frequency and manner. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c57 | Adverbs of Frequency | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c555 | Temporal Adverbs. | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c302 | Frequency Adverbs | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c332 | Adverbs of manner and opinion. | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c546 | Adverbs of degree/intensity. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c570 | Adverbs of preference/choice. | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c244 | Adverbs indicating degree or extent. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c222 | Adverbs of Time | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c309 | Adverbs describing degree or intensity. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c487 | List of numerical values. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c179 | Numerical Data. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c420 | Numerical data. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c390 | List of numbers | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c287 | Numeric Data. | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| c101 | List of numerical values. | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c494 | List of numerical values. | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c579 | Numerical data. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c537 | List of numerical values. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c435 | Numerical data. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c528 | List of numerical values. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c549 | List of prices. | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c398 | Numerical Data. | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| c359 | List of numerical values. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c477 | List of monetary values. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c593 | List of monetary values. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c80 | Numeric quantities. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 10: Neuron Analysis Results on *Super Concepts* extracted from BERT-base-cased
    model. The alignment column shows the intersection between the top 10 neurons
    in the Super concept and the Sub concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f16b7a56f2876cfb7364423e417d95ef.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Political Figures
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b146a2ad326c2bec8b5e85d9dd5e204f.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) List of Months
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/66c925e76a001e76d87525f0e516d1af.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Energy Related terms
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a189b0c59f60f524961b26b16a44d5d5.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Verbs Ending in -ing
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7f6b962e1fb555a2906b3a19adcacc16.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) Measurement Units
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/31803c4444af20287cdf2dea51e6a5db.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) Verbs in Various Tense Forms
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dbde329106c8c364bed2d66548b663dc.png)'
  prefs: []
  type: TYPE_IMG
- en: (g) Royalty and Monarchy
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/10d2436a8450d5e5a2b720b21690c464.png)'
  prefs: []
  type: TYPE_IMG
- en: (h) Adjectives with less suffix
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6e5b0362f674211e71e44a2d610f41f5.png)'
  prefs: []
  type: TYPE_IMG
- en: (i) Monetary Values
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10: Sample Concepts learned in the ALBERT Model'
  prefs: []
  type: TYPE_NORMAL
- en: '| cluster | label | score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| c259 | List of names | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c37 | List of male names. | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c328 | List of names of politicians, public figures, and athletes. | 0.2
    |'
  prefs: []
  type: TYPE_TB
- en: '| c220 | List of surnames. | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c433 | List of names. | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| c262 | List of surnames | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c210 | List of male first names. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c231 | List of female names. | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c383 | List of names | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c280 | List of names. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c202 | List of surnames. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c344 | Irish surnames | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| c6 | Surnames | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c75 | List of female names. | 0.7 |'
  prefs: []
  type: TYPE_TB
- en: '| c269 | List of celebrity names | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c578 | List of surnames. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c535 | List of names | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c487 | List of Spanish male names. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c340 | Last names. | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c48 | List of surnames. | 0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| c70 | List of names. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c353 | List of names in the entertainment industry. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c568 | List of names. | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c378 | List of surnames. | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| c575 | Surnames | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c149 | List of tennis players’ names. | 0.4 |'
  prefs: []
  type: TYPE_TB
- en: '| c325 | List of names. | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c436 | List of sports players’ names | 0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| c594 | List of surnames. | 0.6 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11: Name clusters extracted from the last layer of BERT-base-cased'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8f0df01bfe02674af85f8706ee6bc8f5.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Motorsport Terminology
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dcea4b194094a2fce198162295dcb21e.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) US State Abbreviations
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e92b879eeac482b47d1c7393b7a7cd4e.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Education-related terms
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11: Example of concepts that were deemed uninterpretable in the BCN
    but were correctly labeled by ChatGPT'
  prefs: []
  type: TYPE_NORMAL
