# P72：p72 CS 285： Lecture 17, Part 2： RL Theory - 加加zero - BV1NjH4eYEyZ

在今天的讲座的第二部分，我们将对一种无模型的强化学习算法进行理论分析。

![](img/3907842b7d3a899a06da3bae1e266cb5_1.png)

这种算法与我们可能实际想要使用的算法有些相似，即现在拟合q迭代，当然，我们知道，一般来说，真实的拟合q迭代并不一定会收敛，所以我们将使用一种理想化的拟合q迭代模型，那就是，你知道。

比真实方法稍微简化一些。

![](img/3907842b7d3a899a06da3bae1e266cb5_3.png)

但是，它是易于理论分析的，所以，这是我们关于精确q迭代在精确q迭代中的抽象模型，我们将在每个迭代中设置q_k加1等于某个操作符，T乘以q_k，操作符T将是贝尔曼最优性操作符，所以。

T乘以q等于r加上gamma乘以p乘以对a的最大值。

![](img/3907842b7d3a899a06da3bae1e266cb5_5.png)

所以，这里的最大化操作符有点奇怪，因为q是s x s x a长度的矩阵，我们将说，对a的最大值可能是一个s长度的向量，抱歉，这将导致一个新的向量，其长度为s，所以，它是对a的最大值，但是。

它是一种块状最大值，其中，所有动作都对应相同的状态，它计算一个条目，这是那些动作的最大值，所以，这不是整个向量q的全面最大值，实际上，这是一种块状最大值，所以，有一些符号上的便利，嗯，无论如何。

不要害怕太多，如果我在这里的标记不清晰，tq基本上就是你想的那样，是的，它就是将q函数应用于最大贝尔曼备份的函数。



![](img/3907842b7d3a899a06da3bae1e266cb5_7.png)

嗯，这就是精确的q迭代，这就是我们如何建模近似拟合q迭代的，我们将说q hat k，加上一将进行某种最小化过q hat，以最小化q hat减去t hat q hat k，所以这里有两个误差来源。

一个是那不等于t，我稍后再谈谈那个，另一个是最小化也不会精确，所以嗯，Q hat k plus one实际上不等于t hat q hat k。



![](img/3907842b7d3a899a06da3bae1e266cb5_9.png)

所以我们将有一个近似的贝尔曼算子，我们将有一个近似的最小化，所以近似的贝尔曼算子，T hat q等于r hat plus gamma p hat。



![](img/3907842b7d3a899a06da3bae1e266cb5_11.png)

让我们拆开看看这个，所以，我们的帽子在这种情况下是为了这个分析的目的，只是所有我们看到状态s时的奖励的平均值，所以，我们对于a的帽子值就是样本平均值，除以你看到过的次数，s a次，对所有样本的ri的和。

对于所有si等于essay的ri，所以，基本上就是你认为的那样，它就是你看到过的那个状态的平均奖励，动作元组和p hat基本上与以前相同，是你看到状态转换的次数，s a s'，除以你现在看到的a的次数。

这可能看起来与我们之前在基于模型的分析中的想法相似，但请注意，这些都是不是模型。

![](img/3907842b7d3a899a06da3bae1e266cb5_13.png)

这是大数据中平均不同转换的效果，所以在真实的物理迭代算法中，我们会做，对于每个样本，我们有不同的损失。



![](img/3907842b7d3a899a06da3bae1e266cb5_15.png)

所以对于每个样本，我们有，你知道像ri这样的东西，我们有像q si a i - ri + gamma max这样的东西，s' q si'，s'的平方，或者是其他差异，你知道可能不是平方，可能绝对值。

然后我们会平均它们所有，我们在这个理想化的模型中做，我们基本上在说，平均这些不同损失的效果。

![](img/3907842b7d3a899a06da3bae1e266cb5_17.png)

看起来就像在这个经验模型下做备份，p hat和r hat基本上是经验模型的奖励和转换。

![](img/3907842b7d3a899a06da3bae1e266cb5_19.png)

从技术上讲，如果你将所有给定状态的目标值平均起来。

![](img/3907842b7d3a899a06da3bae1e266cb5_21.png)

动作元组a right，所以如果你看到了一篇论文五次，如果你将那些五次相同论文的目标值平均起来，你会得到完全相同的东西，就像如果你使用了这个版本的r hat和p hat，我现在在说所有这些。



![](img/3907842b7d3a899a06da3bae1e266cb5_23.png)

但这只是对这种理想化模型的一种解释，所以从这里开始，我们将只处理我们的帽子和p hats，所以所有那个解释都是为了，为什么将近似的q迭代视为这种t hat备份是合理的，它是合理的。

因为如果你只是平均那个状态动作元组的目标值。

![](img/3907842b7d3a899a06da3bae1e266cb5_25.png)

在所有包含那个状态动作元组的样本中。

![](img/3907842b7d3a899a06da3bae1e266cb5_27.png)

你会得到完全相同的东西，好的，嗯，到现在，你知道我们实际上在我们的分析中会看到什么，是r hat和p hat并不完全相同，当r和p导致一些误差时。



![](img/3907842b7d3a899a06da3bae1e266cb5_29.png)

我们称之为抽样误差，因为误差的原因是我们，是因为我们的帽子和p帽子不准确，因为我们有有限的样本数，如果我们有无限的样本数，那么我们的帽子将等于r，p帽子将等于p，但对于有限的样本数，我们遭受抽样误差。

但这不是误差的唯一来源，这最小化也会不准确，所以实际上我们无法得到q hat k，再加上一个来完美匹配t hat q hat k。



![](img/3907842b7d3a899a06da3bae1e266cb5_31.png)

因为它适合q迭代，并且这里有某种函数逼近或某种，嗯，你知道在不精确学习中正在进行，所以我们需要这个错误的模型，嗯，这里的一个重要事情是我们要使用哪种范数。



![](img/3907842b7d3a899a06da3bae1e266cb5_33.png)

所以我们在我们的物理迭代讨论中看到之前。

![](img/3907842b7d3a899a06da3bae1e266cb5_35.png)

在课程的开始，我们如果这样做以平方误差。

![](img/3907842b7d3a899a06da3bae1e266cb5_37.png)

问题是我们甚至无法证明算法的收敛性，那确实是一个重大的问题，尽管我们不能证明真实算法的收敛性，也许我们可以假设一种理想化的算法，至少研究在这种理想化算法中误差如何依赖于问题参数。



![](img/3907842b7d3a899a06da3bae1e266cb5_39.png)

所以我们需要对此进行一些理想化，为了理想化它，我们将假设我们实际上是在最小化无穷范数，此外。

![](img/3907842b7d3a899a06da3bae1e266cb5_41.png)

我们将假设我们可以将无穷范数减少到，等于或等于某个常数，所以我们假设我们每次计算这个近似贝尔曼备份时。



![](img/3907842b7d3a899a06da3bae1e266cb5_43.png)

q等于k，然后我们拟合新的q等于k，将这个t等于q等于k加上一，以小于或等于某个常数的无穷范数来拟合，我会稍后再回来讨论这个问题，所以这种假设主要是出于方便，因为，使用l2范数来做这个很难，好的。

那么我们想要深入研究的问题是什么，一个问题是当拟合q迭代的迭代次数趋近于无穷大时。

![](img/3907842b7d3a899a06da3bae1e266cb5_45.png)

q hat k实际上会趋近于什么，嗯，q hat k与q star的渐近差异有多大，当我们取无限多个q迭代的近似迭代次数时。



![](img/3907842b7d3a899a06da3bae1e266cb5_47.png)

我们的错误来自哪里，它们来自两个来源，一个是t不等于t hat，那就是抽样误差。

![](img/3907842b7d3a899a06da3bae1e266cb5_49.png)

另一个是q hat k，加上一不等于t hat q hat k。

![](img/3907842b7d3a899a06da3bae1e266cb5_51.png)

那就是我们叫它近似误差，基本上当我们近似备份之前的q q函数时。

![](img/3907842b7d3a899a06da3bae1e266cb5_53.png)

意味着目标值用一些新的q函数表示，我们遭受了一些近似误差。

![](img/3907842b7d3a899a06da3bae1e266cb5_55.png)

我们可以尝试量化这一点，所以让我们首先分析只抽样误差，所以我们只会分析我们从中获得的问题，事实是t不等于t hat，而且这将看起来与我们在上一节看到的类似。

所以我们基本上要找出我们做的实际事情是如何工作的，具有t hat q hat的那个与我们得到的不同，如果我们使用了t次q hat，所以特别是我们想要理解这个差异，t hat q与tq的差异有多大。

对于这个函数q的q来说，我们目前不关心q是什么，我们只是想要理解将t hat应用到它与将t应用到它之间的差异。



![](img/3907842b7d3a899a06da3bae1e266cb5_57.png)

所以如果我们把它写得好，让我们在那里替换定义中的t和t的帽子，然后我们会收集术语，所以我们会收集r术语和下一个值术语，我们得到r的帽子减去r。



![](img/3907842b7d3a899a06da3bae1e266cb5_59.png)

加上gamma乘以在p的帽子下期望的最大值，减去在p uh下期望的最大值。

![](img/3907842b7d3a899a06da3bae1e266cb5_61.png)

按照质量三角形的惯例，我们可以将这个绑定起来，我们可以对这个进行界限，这个的范数，嗯，与他们范数的和相加，所以我们得到嗯，R减去r，那个的范数加上嗯，Gamma乘以。



![](img/3907842b7d3a899a06da3bae1e266cb5_63.png)

期望差的范数，现在，这里的第一个值正好是连续随机变量的估计误差，我们学到了什么，使我们能够限制连续随机变量的近似误差。



![](img/3907842b7d3a899a06da3bae1e266cb5_65.png)

这就是霍廷斯在质量上的定义，所以，如果我们直接插入霍廷斯不等式的公式。

![](img/3907842b7d3a899a06da3bae1e266cb5_67.png)

嗯，我们就会得到，我们的帽子和r之间的差异只会小于，等于或等于两倍，可能的最大奖励，这基本上就是奖励的范围，b加减b加减um乘以根号下delta除以2n。



![](img/3907842b7d3a899a06da3bae1e266cb5_69.png)

所以我们的熟悉边界，嗯，误差的第二部分将按1除以根号n缩放。

![](img/3907842b7d3a899a06da3bae1e266cb5_71.png)

这就是对所有下一个状态的p hat和p的差的和，q s prime a prime动作的最大值。

![](img/3907842b7d3a899a06da3bae1e266cb5_73.png)

我们可以通过uh来限制它，将原式中的max(s_prime)替换为max(s_prime， prime)。



![](img/3907842b7d3a899a06da3bae1e266cb5_75.png)

这样会使得q项不再依赖于s_prime。

![](img/3907842b7d3a899a06da3bae1e266cb5_77.png)

因为如果你将，嗯，你知道一些向量的值，这些向量由相同的元素组成。

![](img/3907842b7d3a899a06da3bae1e266cb5_79.png)

且被，向量的最大值的和所限制。

![](img/3907842b7d3a899a06da3bae1e266cb5_81.png)

因为向量中的任一项都小于或等于其最大值，嗯，现在来看这个方程，嗯，希望你能识别出这是这个估计的p和p乘以的p之间的总变分距离。



![](img/3907842b7d3a899a06da3bae1e266cb5_83.png)

依赖于q的一些量。

![](img/3907842b7d3a899a06da3bae1e266cb5_85.png)

一些常数量，特别是那个常数量就是q的无穷范数，所以这正好等于估计的p和p乘以的p之间的总变分距离。

![](img/3907842b7d3a899a06da3bae1e266cb5_87.png)

q的无穷范数，我们已经有了对这个的界限，所以，这基本上就是要使用的，对于估计分类分布的浓度不平等性。

![](img/3907842b7d3a899a06da3bae1e266cb5_89.png)

因此，这被一些常数乘以所限制。

![](img/3907842b7d3a899a06da3bae1e266cb5_91.png)

q的无穷范数乘以，n除以delta的log的平方根除以1。

![](img/3907842b7d3a899a06da3bae1e266cb5_93.png)

所以再次，它以根n的比例缩放，并且来自维度和一些其他因素的常数会出现，和q的无穷范数，所以那是抽样误差，这是，你知道，大致遵循我们之前章节的逻辑。



![](img/3907842b7d3a899a06da3bae1e266cb5_95.png)

所以我们有，应用此方法与应用近似备份和真实备份之间的差异。

![](img/3907842b7d3a899a06da3bae1e266cb5_97.png)

这个经验性贝尔曼备份，近似备份和真实备份，嗯，被两个术语所限制，一个取决于奖励误差，另一个取决于动态误差，这意味着，q和t q之间的差异的无穷范数。



![](img/3907842b7d3a899a06da3bae1e266cb5_99.png)

基本上也具有这一形式，只是常数略有不同，并且，还有一些依赖于状态和动作数量的维度的术语，我们通过使用并集界来获得这一点，记住我们为什么需要使用并集界，是因为所有这些不等式都以概率1减去delta成立。

所以，如果你有n个不同的事件，但是，你需要对所有这些事件发生的概率进行限制，这就是并集界做的事情，好的，但你真的不必担心这个。



![](img/3907842b7d3a899a06da3bae1e266cb5_101.png)

所有这些实际上都随着常数的变化而变化，好的，所以现在是抽样误差，那么关于近似误差呢，让我们做一些假设，让我们假设当你将q hat k+1拟合到目标值时，我们将其称为t q hat k。

你的拟合在无穷范数误差中最大不超过epsilon k。

![](img/3907842b7d3a899a06da3bae1e266cb5_103.png)

我们现在将分析有精确备份的情况，但我们将后来返回近似备份，所以让我们暂时假设我们的备份是精确的。

![](img/3907842b7d3a899a06da3bae1e266cb5_105.png)

所以t和t hat没有区别，我们只是在研究拟合误差的影响，如果我们有一个精确的拟合，如果我们有一个精确的表格q迭代方法，那么q hat k+1将精确等于t q hat k，现在我们将假设它不是精确的。

它产生了一些误差，并且这个误差在无穷范数中被限制。

![](img/3907842b7d3a899a06da3bae1e266cb5_107.png)

这在现实中是一个强烈的假设，如果你在做监督学习。

![](img/3907842b7d3a899a06da3bae1e266cb5_109.png)

学习你的错误并不在无穷范数中被限制，它将被限制在某种像，你知道的。

![](img/3907842b7d3a899a06da3bae1e266cb5_111.png)

加权l2范数在期望下，在某个分布下，我们将假设它在无穷范数中被限制。

![](img/3907842b7d3a899a06da3bae1e266cb5_113.png)

这意味着对于最坏的状态动作对，你的错误不超过epsilon k。

![](img/3907842b7d3a899a06da3bae1e266cb5_115.png)

这是一个强烈的假设，但它会使这个非常方便，好的，所以现在我们要尝试理解的是uh，q hat k在迭代k和真实q star在无穷范数之间的差异，这就是我们要这样做的，嗯，我们将使用与以前相同的技巧。

我们将减去并添加某个量。

![](img/3907842b7d3a899a06da3bae1e266cb5_117.png)

我们特定的量是将放入t times q hat k-1。

![](img/3907842b7d3a899a06da3bae1e266cb5_119.png)

原因是我们正在拟合q hat k到t q hat k-1，如果我们放那个。

![](img/3907842b7d3a899a06da3bae1e266cb5_121.png)

那就是我们对抗的量，所以我们将减去它，我们将添加它，然后我们将这两个术语分组在一起，所以我们将有一个术语，是q hat k-t q hat k-1，所以那很方便，因为那是我们假设要限制的量。

然后我们有这个其他术语，它由q hat k-1的备份减去q star的备份组成。

![](img/3907842b7d3a899a06da3bae1e266cb5_123.png)

现在，q星是t的固定点，所以你总是可以替换q星为tq星。

![](img/3907842b7d3a899a06da3bae1e266cb5_125.png)

这就是我在这条线上做的，然后我们再次应用三角形性质，嗯，以将和函数的无穷范数绑定为它们无穷范数的和。

![](img/3907842b7d3a899a06da3bae1e266cb5_127.png)

这里的第一个项是q帽k减去t，q帽k-1只是受限于epsilonk-1。

![](img/3907842b7d3a899a06da3bae1e266cb5_129.png)

根据顶部的假设，索引错误了一个单位，这就是为什么它是k-1，所以现在我们只剩下第二个项了，对于第二个项，我们将识别一个我们在一天中很早就见过的有趣事实。



![](img/3907842b7d3a899a06da3bae1e266cb5_131.png)

当我们第一次学习q学习时，那就是贝尔曼备份是一个收缩。

![](img/3907842b7d3a899a06da3bae1e266cb5_133.png)

贝尔曼备份在无穷范数上的收缩的事实。

![](img/3907842b7d3a899a06da3bae1e266cb5_135.png)

意味着无穷范数中的，嗯，你通过应用t到两个不同的q函数得到的结果是小于或等于gamma乘以。

![](img/3907842b7d3a899a06da3bae1e266cb5_137.png)

那些q函数差异的无穷范数。

![](img/3907842b7d3a899a06da3bae1e266cb5_139.png)

使用t在gamma上的收缩事实。

![](img/3907842b7d3a899a06da3bae1e266cb5_141.png)

我们可以将这个限制为gamma乘以，q帽k-1减去q星，我们现在做的，我们已经将q帽k减去q星。

![](img/3907842b7d3a899a06da3bae1e266cb5_143.png)

递归地与q帽k-1减去q星相关联。

![](img/3907842b7d3a899a06da3bae1e266cb5_145.png)

但加上一个小误差项，epsilonk-1，好的，所以现在我们将展开这个递归，所以再次应用到q帽k-1减去q星上，我们将整个东西限制为epsilonk-1加上gamma。



![](img/3907842b7d3a899a06da3bae1e266cb5_147.png)

epsilonk-2加上gamma的平方乘以差异，我们可以再做一次，然后得到gamma的平方乘以。

![](img/3907842b7d3a899a06da3bae1e266cb5_149.png)

epsilonk-3加上gamma的立方和如此下去，等等，如果我们一直回溯到开始。

![](img/3907842b7d3a899a06da3bae1e266cb5_151.png)

那么我们最终将整个东西限制为这个gamma折扣的和，从i等于0到k-1，gamma到i次。

![](img/3907842b7d3a899a06da3bae1e266cb5_153.png)

对应的epsilon，加上gamma到k次q帽0和q星的差异，这告诉我们一个非常有趣和也非常有用的事情，那就是我们取越多的迭代，我们实际上就越忘记我们的初始化，因为当k趋近于无穷大时。

这个gamma到k项将消失，因为gamma小于1，这意味着我们起始点q帽0的影响将消失。

![](img/3907842b7d3a899a06da3bae1e266cb5_155.png)

那么这就意味着嗯。

![](img/3907842b7d3a899a06da3bae1e266cb5_157.png)

如果我们将极限设置为k趋近于无穷大，嗯，第二个项gamma的k次方消失，因为gamma的k次方趋近于零，对于第一个项，我们将它简化一点，我们将所有的epsilon。

k减去i减去一项替换为仅最大epsilon，我们遍历所有过程，这可能是合理的做。

![](img/3907842b7d3a899a06da3bae1e266cb5_159.png)

"因为如果我们在每个迭代中的拟合误差都有限"，"我们就说，我们也可以遍历所有过程迭代"，"现在我们得到了我们熟悉的几何形状"，嗯，系列，"从i等于0到无穷大，gamma的i次方的和等于某个常数的值"。

因此，这就等于一除以一减去伽马。"epsilon的无穷范数"，"当ε是一个较大的向量时"，"迭代中每个维度的错误值所在的K维空间"，所以这挺酷的，现在我们看到仅误差估计误差如何缩放，所以如果我们。

如果我们每一步都遭受一些epsilon拟合，那么总误差将会是epsilon乘以一除以一减去gamma。



![](img/3907842b7d3a899a06da3bae1e266cb5_161.png)

所以，我们的时间范围越长，实质上我们得到的错误就越多，这从直觉上，嗯，你可以把它想成说每次你后退一步。



![](img/3907842b7d3a899a06da3bae1e266cb5_163.png)

每一轮拟合都会导致你承担一些额外的误差，这是q迭代的误差，因此，因为你备份的数量等于你的视界。

![](img/3907842b7d3a899a06da3bae1e266cb5_165.png)

这就是你将看到的近似误差顺序，所以现在让我们把这两件事结合起来。

![](img/3907842b7d3a899a06da3bae1e266cb5_167.png)

我们有我们的采样误差，并且这量化了t和t之间的差异。

![](img/3907842b7d3a899a06da3bae1e266cb5_169.png)

我们有我们的近似误差，这是q hat k+1与t q hat k之间的差异量，它们会因为采样误差而差异，并且由于近似误差。



![](img/3907842b7d3a899a06da3bae1e266cb5_171.png)

所以本质上我们即将做的事情是，"我们将将抽样误差纳入到epsilon中"。

![](img/3907842b7d3a899a06da3bae1e266cb5_173.png)

"那样我们就能把这两部分连接起来"，所以嗯，"换个说法来说"，"从前一张幻灯片中的约束也可以重写为极限"。



![](img/3907842b7d3a899a06da3bae1e266cb5_175.png)

当k趋近于无穷大时，q等于k，"减去q星的数小于或等于1除以1"，"减去伽马乘以最大值"，"你所有关于q hat k和t q hat k减一的迭代"，正确，所以这包含两种类型的错误，因为那里有一个t。

所以如果你实际上是使用t hat而不是t来备份的，那里会有错误，它包含由于不完美的拟合导致的近似误差，所以让我们来看看这个数量是什么，Q hat k 减去 t q k 减去一，我们将输入。

嗯 t hat q hat k 减去一，所以我们会像以前那样减去并添加它，我们再次分组术语，所以整个东西都被q hat k减去t hat所绑定，q hat k减去一，加上t hat q k减去一。

减去t q hat k减去一，所以第二个术语基本上处理了抽样误差，而第一个术语处理了近似误差。

![](img/3907842b7d3a899a06da3bae1e266cb5_177.png)

所以我们知道第一个术语是epsilon k，而第二个术语是上面提到的大抽样误差。

![](img/3907842b7d3a899a06da3bae1e266cb5_179.png)

所以我们可以做的就是我们可以只取这两个术语，并将它们插入到这里。

![](img/3907842b7d3a899a06da3bae1e266cb5_181.png)

我们可以使用这个来计算q hat k和q star之间的差异在极限中。

![](img/3907842b7d3a899a06da3bae1e266cb5_183.png)

当k趋近于无穷大时，并将是1除以1减去gamma乘以一堆术语。

![](img/3907842b7d3a899a06da3bae1e266cb5_185.png)

基本上是三个术语的和，其中两个来自抽样误差，一个来自近似误差。

![](img/3907842b7d3a899a06da3bae1e266cb5_187.png)

这就是我们在上一滑块上提到的，嗯，我们可以在这里看到，错误随着迭代的地平线而累积，并且由于抽样。

![](img/3907842b7d3a899a06da3bae1e266cb5_189.png)

嗯，注意在抽样误差中，第二个术语实际上也是一除以一减去伽马阶的。

![](img/3907842b7d3a899a06da3bae1e266cb5_191.png)

因为q无穷大处于我们最大值除以一减去伽马阶的级别，我们之前讨论过。

![](img/3907842b7d3a899a06da3bae1e266cb5_193.png)

我们讨论了价值函数和q函数如何，基本上他们的大小是奖励乘以时间范围，所以它是r最大值除以一减去伽马阶，所以如果你想象会发生什么，如果我们将epsilon k加上采样误差代入那个第二个方程。

你前面有一个一除以一减去伽马阶的术语，然后你有一个和三个术语的和，其中一项本身也包含一个除以一减伽马再减一的项。



![](img/3907842b7d3a899a06da3bae1e266cb5_195.png)

所以总体误差的顺序将与除以一减伽马再减一的倒数的平方成正比，就像我们在第一部分看到的一样，嗯，现在到目前为止我们需要强大的。



![](img/3907842b7d3a899a06da3bae1e266cb5_197.png)

嗯，假设，嗯，特别是对错误产生的无限正态假设，这就是我们所处的情况，所以你知道那是一个相当强的假设，并不是总是成立的。



![](img/3907842b7d3a899a06da3bae1e266cb5_199.png)

实际上，在某些分布下，p范数可以导出更先进的结果。

![](img/3907842b7d3a899a06da3bae1e266cb5_201.png)

因此，无穷范数对于实际学习算法来说并不是真的很现实。

![](img/3907842b7d3a899a06da3bae1e266cb5_203.png)

我们可以使用p范数进行一些分析。

![](img/3907842b7d3a899a06da3bae1e266cb5_205.png)

你可以在rl理论书中了解更多关于这一点。

![](img/3907842b7d3a899a06da3bae1e266cb5_207.png)

在幻灯片的底部有参考，嗯，基本上，这个分析研究这种形式的范数。

![](img/3907842b7d3a899a06da3bae1e266cb5_209.png)

其中，pμ范数只是期望值。

![](img/3907842b7d3a899a06da3bae1e266cb5_211.png)

在μ下的差值的p次方，然后，整个东西被提高到1除以p，所以，如果p等于2，这实际上是我们熟悉的二次贝尔曼误差，所以我们可以用那个做其他事情，但我们也需要在那里做出一些假设。



![](img/3907842b7d3a899a06da3bae1e266cb5_213.png)