# P44：p44 CS 285： Lecture 10, Part 5 - 加加zero - BV1NjH4eYEyZ

今天的讲座最后部分一切顺利，我将简要讨论一个案例研究，这展示了最优控制算法的力量，在已知真实动态和我想要强调的点的情况下，这主要是为了激励我们研究基于模型的强化学习，同时也展示了这些东西确实起作用。

它们确实能做出一些比甚至最佳的无模型强化学习方法更令人印象深刻的事情，我要讨论的案例研究是这个论文，叫做在线轨迹优化中复杂行为的合成与稳定，但你们都向汤姆·埃尔雷兹和埃曼努埃尔·托夫投掷了。

这篇论文描述的是一个相当简单的，几乎教科书级别的算法，但实现了得很好，它使用迭代LQR作为模型预测控制中的一个内层循环，所以模型预测控制是一种使用基于模型的规划者的方法，在状态可能不可预测的设置中。

模型预测控制的主要思想非常简单，每次步骤你观察当前状态x_t，然后使用你最喜欢的规划或控制方法来确定一个计划，一个动作序列，U_t U_t+1等等，一直延伸到U_capital_t。

然后你只执行那个计划的第一个动作，丢弃其他动作，观察下一个发生的状态，并重新规划一切，所以实质上模型预测控制是一种华丽的说法，我们计划在每个时间步骤，这就是这篇论文做的。

这篇论文的大部分贡献实际上都在迭代LQR的特定实现上，如果你想知道，所有的细节和技巧，关于如何有效地实施迭代LQR，我鼓励你去查看它，我今天要展示的是来自那篇论文的视频结果。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_1.png)

所以我要播放视频并稍微解释一下，所以他们展示的是一个简单的杂技系统。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_3.png)

使用迭代LQR，他们将展示游泳者和小跳板。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_5.png)

以及一个更复杂的人型机器人。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_7.png)

这是杂技演员，只有两个自由度，只有一个控制维度。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_9.png)

一个非常简单的成本，首先他们只是让它被动运行，没有任何控制，然后他们打开控制器，你可以看到在实时中，控制器实际上发现了如何摆动杂技演员，没有任何学习，尽管你知道动态，但是嗯，令人印象深刻的是。

这种行为实际上是完全自动地并在实时中完全发现的，嗯，因为你是，他们在应用到系统上的扰动时使用模型创意控制。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_11.png)

机器人成功地从这些扰动中恢复。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_13.png)

这里有一条小游泳蛇，并且它的目标是到达绿色点，同时避免红色点，再次，有趣的是，这里的一件事，这起伏的游泳门实际上是由控制器自动通过优化发现的，不需要知道，预先知道或学习任何事情，除了当然，对于系统动态。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_15.png)

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_16.png)

这里是 hopper 系统。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_18.png)

所以这里他们要做的就是，嗯，他们首先，嗯，对它应用力量扰动，只是为了展示他们的物理引擎，然后应用了那些扰动力，他们会展示当你实际要求跳板站起来时发生的事情。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_20.png)

所以它会找出并知道如何跳起来站立，然后当他们应用它时，它对这些扰动反应并成功地保持直立，这里他们展示它可以对甚至非常极端的扰动反应。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_22.png)

这里他们在展示会发生什么，如果他们给它错误的动力，所以因为他们计划了每一步，实际上，他们可以得到一些稍微合理的结果，即使动力学被错误地指定，所以，真正的机器人只有控制器认为它一半的质量。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_24.png)

在这里，它有控制器认为它两倍的质量，所以，你可以看到质量翻倍，它稍微有些挣扎，但仍然做了一些事情，你知道，看似合理。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_26.png)

嗯，他们将在这里控制一个三维人型机器人。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_28.png)

这里的成本函数是，我应该说相当精细地工程化，所以仍然是一个相对较短的时间范围控制器。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_30.png)

它不规划到未来很远，因此，成本函数需要相当详细。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_32.png)

所以他们打开它，它找出如何站立的方法，它比实时慢一点。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_34.png)

所以他们不得不加快这个视频的速度来播放它，但是，嗯，能够做一些基本的步行，保持平衡并反应敏捷，即使在面对相当极端的干扰时。



![](img/3aa80e5ba4ff5c48b53276db8d5146f9_36.png)

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_37.png)

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_38.png)

好，如果你对这些主题有兴趣，我会推荐这个，嗯，由缅因和雅各布斯撰写的专著，所谓的差分动态规划是GDP算法的原始描述，我从中受到了IQR的启发，这是我刚刚为这个视频呈现的NPC论文的摘要。

这是一篇提供概率性表述和信任融合的论文，LQR的确定性线搜索替代方案，所以，如果你想知道如何在随机设置中处理这些类型的LQR问题，这可能值得一看，嗯，在下周的讲座中。

我们将将这个扩展到动态可能未知的情况，已知动态有什么不好，嗯，节点的动态很好，如果你在控制一些容易建模的系统，比如汽车的动力学，但如果你要让机器人折叠毛巾，或者在工厂中排序物体。

也许精确建模所有这些可能是非常困难甚至不可能的，在那些情况下也许我们可以学习我们的模型。

![](img/3aa80e5ba4ff5c48b53276db8d5146f9_40.png)