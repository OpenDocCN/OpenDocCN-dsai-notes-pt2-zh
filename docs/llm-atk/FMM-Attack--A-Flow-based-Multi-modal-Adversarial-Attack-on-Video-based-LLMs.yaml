- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:45:20'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.13507](https://ar5iv.labs.arxiv.org/html/2403.13507)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '¹¹institutetext: Tsinghua Shenzhen International Graduate School, Tsinghua
    University ²²institutetext: Tencent Technology (Beijing) Co.Ltd ³³institutetext:
    Tencent Lab 33 ⁴⁴institutetext: Peng Cheng Laboratory ⁵⁵institutetext: Peking
    University'
  prefs: []
  type: TYPE_NORMAL
- en: '⁵⁵email: {ljm22, gkf21}@mails.tsinghua.edu.cn,'
  prefs: []
  type: TYPE_NORMAL
- en: '{baiyang0522, zhang304973926}@gmail.com'
  prefs: []
  type: TYPE_NORMAL
- en: xiast@sz.tsinghua.edu.cn, yisen.wang@pku.edu.cnJinmin Li ^() 11    Yang Bai
    ^($\dagger$) 22    Jingyun Zhang 33    Shu-tao Xia 1144    Yisen Wang 55
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Despite the remarkable performance of video-based large language models (LLMs),
    their adversarial threat remains unexplored. To fill this gap, we propose the
    first adversarial attack tailored for video-based LLMs by crafting flow-based
    multi-modal adversarial perturbations on a small fraction of frames within a video,
    dubbed FMM-Attack. Extensive experiments show that our attack can effectively
    induce video-based LLMs to generate incorrect answers when videos are added with
    imperceptible adversarial perturbations. Intriguingly, our FMM-Attack can also
    induce garbling in the model output, prompting video-based LLMs to hallucinate.
    Overall, our observations inspire a further understanding of multi-modal robustness
    and safety-related feature alignment across different modalities, which is of
    great importance for various large multi-modal models. Our code is available at
    [https://github.com/THU-Kingmin/FMM-Attack](https://github.com/THU-Kingmin/FMM-Attack).
  prefs: []
  type: TYPE_NORMAL
- en: 'Keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Video-based large language models Adversarial attacks Multi-modal attacks¹¹footnotetext:
    Equal contribution.⁴⁴footnotetext: Corresponding author.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9d0ec0b597e2fefac7c86ae261851884.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Visualization of the transmission cross video and LLM features. In
    Fig. (a), when attacking in video feature space, the clustering effect of garbled
    video features can result in garbled clusters in LLM features. In Fig. (b), when
    attacking in LLM feature space, garbled videos barely form clusters in LLM features,
    let alone in video features. This illustrates the asymmetric transmission between
    video and LLM features.'
  prefs: []
  type: TYPE_NORMAL
- en: Recent advancements in multi-modal understanding are largely based on the combination
    of pretrained vision models with large language models (LLMs) [[26](#bib.bib26),
    [35](#bib.bib35), [13](#bib.bib13)]. However, these large multi-modal models are
    vulnerable to adversarial attacks [[18](#bib.bib18), [36](#bib.bib36), [8](#bib.bib8),
    [31](#bib.bib31)]. A recent study [[37](#bib.bib37)] found that the introduction
    of another modality makes models like vision large language models (VLLMs) even
    more susceptible to generating harmful output compared to their LLM counterparts.
    This can be attributed to not only their independent vulnerabilities within a
    single modality but also the suboptimal alignment between the two modalities,
    which can break the established safety alignment inside each modality, making
    the model more vulnerable.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, in particular, Sora^*^**https://openai.com/sora has shown extraordinary
    performances in creating realistic and imaginative scenes from text instructions,
    demonstrating the significance of large multi-modal models, especially across
    video and language modalities. Among them, video-based LLMs [[11](#bib.bib11),
    [32](#bib.bib32), [15](#bib.bib15)] have significantly enhanced general video
    understanding in zero-shot settings and achieved exceptional performance in a
    wide range of video-related tasks, such as video captioning [[25](#bib.bib25),
    [1](#bib.bib1), [33](#bib.bib33), [22](#bib.bib22)], video retrieval [[14](#bib.bib14),
    [7](#bib.bib7), [6](#bib.bib6)], and scene understanding [[5](#bib.bib5), [9](#bib.bib9),
    [28](#bib.bib28)]. Yet their adversarial robustness is under-explored.
  prefs: []
  type: TYPE_NORMAL
- en: 'To evaluate the adversarial robustness of video-based LLMs, we propose a flow-based
    multi-modal attack, dubbed FMM-Attack, to craft adversarial perturbations on video
    inputs for the first time. To be more specific, we utilize two objective functions
    in two modalities, namely video features shown in Fig. [1](#S1.F1 "Figure 1 ‣
    1 Introduction ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs")(a), and features of the last hidden layer of LLM shown in Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ FMM-Attack: A Flow-based Multi-modal Adversarial
    Attack on Video-based LLMs")(b) respectively. Also, a flow-based temporal mask
    is introduced to select the most effective frames in the video, which is inspired
    by the video clipping adopted in video understanding tasks, especially for video-based
    LLMs [[4](#bib.bib4), [30](#bib.bib30)]. Video clipping can effectively improve
    the performance of video-based learning due to its focused annotation, reducing
    complexity, improved temporal understanding, and efficient processing. Motivated
    by these benefits, we utilize a light-weighted flow-based mechanism, to conduct
    a similar splitting and selection operation on video frames. Extensive experiments
    have demonstrated the effectiveness, efficiency, and imperceptibility of our FMM-Attack
    on four benchmark video-based LLMs and two datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Surprisingly, we find that successful adversarial attacks on video-based large
    language models (LLMs) can result in the generation of either garbled nonsensical
    sequences (displayed in orange, such as ‘6.6.6.6.6.6.6’) or incorrect semantic
    sequences (displayed in orange) in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs").
    Moreover, there is a noticeable difference in cross-modal features, particularly
    for garbled videos. As shown in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs")(a), when video
    features are under attack, a clustering phenomenon can be observed, where the
    separation between garbled and natural video features is transmitted to that of
    LLM features. In contrast, in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs")(b), when attacking
    LLM features, no corresponding clustering phenomenon is transmitted between the
    different video features and LLM features. This asymmetric transmission between
    video and LLM features emphasizes the suboptimal nature of current alignment especially
    for safety-related features. These observations can inspire us to further understand
    multi-modal features and the alignment of their robustness.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, our main contribution can be outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To the best of our knowledge, we conduct the first comprehensive investigation
    regarding the adversarial vulnerability of video-based LLMs. We propose a novel
    flow-based multi-modal attack, dubbed FMM-Attack, on video-based LLMs for the
    first time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our observations on cross-modal feature attacks have inspired a further understanding
    of multi-modal robustness and their safety-related feature alignment, which is
    of great importance for various large multi-modal models.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extensive experiments show that our attack can effectively induce video-based
    LLMs to generate either garbled nonsensical sequences or incorrect semantic sequences
    with imperceptible perturbations added on less than 20% video frames.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 Video-based Large Language Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Video-based large language models (video-based LLMs) effectively integrate visual
    and temporal information from video data to gain significant achievement in multiple
    video-related tasks. Numerous approaches [[11](#bib.bib11), [15](#bib.bib15),
    [32](#bib.bib32)] have been proposed to address the challenges associated with
    video-based LLMs, such as incorporating different architectures and training processes
    to enhance the models’ ability to capture and process complex video information.
    Concretely, Video-ChatGPT [[15](#bib.bib15)] is based on the LLaVA framework and
    incorporates average pooling to improve the perception of temporal sequences.
    VideoChat [[11](#bib.bib11)] employs the QFormer to map visual representations
    to Vicuna, executing a two-stage training process. Video-LLaMA [[32](#bib.bib32)]
    integrates a frame embedding layer and ImageBind to introduce temporal and audio
    information into the LLM backbone. This alignment between videos and LLMs facilitates
    visual context-aware interaction, surpassing the capabilities of LLMs. However,
    these models are still susceptible to adversarial attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Adversarial Attack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Adversarial attacks [[27](#bib.bib27), [34](#bib.bib34)] have been widely studied
    in the context of classification models, where imperceptible and carefully crafted
    perturbations are applied to input data to mislead the model into producing incorrect
    predictions. Inspired by the adversarial vulnerability observed in vision tasks,
    early efforts are devoted to investigating adversarial attacks against large multi-modal
    models [[18](#bib.bib18), [36](#bib.bib36), [8](#bib.bib8), [31](#bib.bib31),
    [37](#bib.bib37)], such as vision large language models (VLLMs) [[35](#bib.bib35),
    [26](#bib.bib26), [13](#bib.bib13), [19](#bib.bib19)] or text-to-image diffusion
    models [[21](#bib.bib21)], etc. These adversarial attacks have been designed to
    manipulate these large multi-modal models into generating specific or even harmful
    outputs. Despite these advancements, the adversarial robustness in video-based
    LLMs remains unexplored. Addressing this gap, we introduce the first adversarial
    attacks specifically tailored for video-based LLMs in this paper.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we first describe the threat model and problem formulation,
    and subsequently outline the key objective functions of our proposed FMM-Attack.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8f4729fa6cfc74877730fbc0090d2b51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Schematics of our FMM-Attack. The figure demonstrates our attack
    approach for maximizing the video-video features as defined in Eq. [4](#S3.E4
    "Equation 4 ‣ 3.4 Optimization Objective ‣ 3 Methodology ‣ FMM-Attack: A Flow-based
    Multi-modal Adversarial Attack on Video-based LLMs") and the LLM-LLM features
    in Eq. [5](#S3.E5 "Equation 5 ‣ 3.4 Optimization Objective ‣ 3 Methodology ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"). We refer to
    adversarial examples generated by our attack strategies as  representing the adversarial
    perturbation.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Threat model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Goals and capabilities. The goal is to craft an imperceptible adversarial perturbation
    for videos, which can induce video-based LLMs to generate an incorrect sequence
    during the victim model’s deployment. Following the most commonly used constraint
    for the involved perturbation, it is restricted within a predefined magnitude
    in the $l_{p}$ norm, ensuring it is difficult to detect.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge and background. As suggested in [[2](#bib.bib2), [18](#bib.bib18)],
    we assume that the victim video-based LLMs can be accessed in full knowledge,
    including architectures and parameters. Additionally, we consider a more challenging
    scenario where the victim video-based LLMs are inaccessible, as detailed in the
    Appendix.
  prefs: []
  type: TYPE_NORMAL
- en: '3.2 Preliminary: the Pipeline of Video-based LLMs'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let , composed of a video feature extractor . Consider a clean video  for the
    video. To provide a response, video-based large language models , and subsequently,
    generate predefined prompts based on a consistent template to concatenate both
    video features and text queries as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'USER:  Assistant:'
  prefs: []
  type: TYPE_NORMAL
- en: Then, the predefined prompts are processed by LLMs . It is important to mention
    that, to ensure the loss function remains minimal, we use the hidden state $A_{hidden}$
    before the final layer in our FMM-Attack.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Problem Formulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The goal of generating adversarial examples , where , and formulate the overall
    objective function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\arg\min_{\Delta}\lambda\&#124;\Delta\&#124;_{2,1}-\ell(Y,\mathcal{F}_{\theta}(Q_{text},\hat{\mathbf{X}})),$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: 'where  and  is the loss function used to measure the difference between the
    predicted and ground truth answers. Furthermore, in a more realistic scenario,
    the ground truth answer  instead of $Y$. Therefore, the overall objective function
    in Eq. [1](#S3.E1 "Equation 1 ‣ 3.3 Problem Formulation ‣ 3 Methodology ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs") can be further
    formulated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: 'The $\ell_{2,1}$ norm [[27](#bib.bib27)] is employed to quantify the magnitude
    of the perturbation, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\&#124;\Delta\&#124;_{2,1}=\sum_{i}^{T}\&#124;\Delta_{i}\&#124;_{2},$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where -th frame in  norm applies the $l_{1}$ norm across frames, ensuring the
    sparsity of generated perturbations.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Optimization Objective
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our proposed FMM-Attack is to induce video-based LLMs to generate incorrect
    responses with imperceptible adversarial perturbations. Two losses are proposed
    from the perspective of video features  in Eq. [5](#S3.E5 "Equation 5 ‣ 3.4 Optimization
    Objective ‣ 3 Methodology ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack
    on Video-based LLMs"). Moreover, inspired by the idea that video clipping can
    improve video comprehension by selecting the most effective frames, a flow-based
    temporal mask  can filter out similar frames, ensuring the effectiveness of imperceptible
    adversarial perturbations while achieving increased sparsity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Video Features Loss. Video-based LLMs first use a video feature extractor .
    We simply adopt MSE loss to measure the distance of video features between the
    clean video . Hence, the video features loss can be formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where  and -th elements of the clean and adversarial video features, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'LLM Features Loss. In addition to the deviation of the original feature space
    in video domains of video-based LLMs, we also consider that in textual domains
    to enhance the attack effect. Given a hidden state from the final layer of LLMs  and
    the adversarial video $\hat{\mathbf{X}}$ can be formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $$\begin{split}\ell_{LLM}(A_{hidden},\hat{A}_{hidden})&amp;=\frac{1}{n}\sum_{i=1}^{n}(A_{hidden_{i}}-\hat{A}_{hidden_{i}})^{2}\\
    &amp;=\frac{1}{n}\sum_{i=1}^{n}(g_{\psi}(Q_{text},Q_{video})_{i}-g_{\psi}(Q_{text},\hat{Q}_{video})_{i})^{2}\\'
  prefs: []
  type: TYPE_NORMAL
- en: '&amp;=\frac{1}{n}\sum_{i=1}^{n}(g_{\psi}(Q_{text},f_{\phi}(\mathbf{X}))_{i}-g_{\psi}(Q_{text},f_{\phi}(\hat{\mathbf{X}}))_{i})^{2},\end{split}$$
    |  | (5) |'
  prefs: []
  type: TYPE_NORMAL
- en: where  are the  is the total number of elements in the features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Flow-based Temporal Mask. Video-based LLMs [[4](#bib.bib4), [30](#bib.bib30)]
    adopt video clipping to split and select the most effective frames in a video,
    which can enhance video understanding. Inspired by these advantages, we propose
    a flow-based temporal mask,  frames with the most significant movement and changes.
    See Sec. [4.3](#S4.SS3 "4.3 Discussions ‣ 4 Experiments ‣ FMM-Attack: A Flow-based
    Multi-modal Adversarial Attack on Video-based LLMs") for a detailed discussion.
    Specifically, we initialize a binary mask  assigns a value of 1 to the top , our
    proposed FMM-Attack can achieve more sparse adversarial perturbations in both
    temporal and spatial domains. For temporal sparsity, a flow-based temporal mask  norm
    of adversarial perturbations in Eq. [3](#S3.E3 "Equation 3 ‣ 3.3 Problem Formulation
    ‣ 3 Methodology ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs") is employed to constrain the spatial perturbation magnitude in each frame.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall Optimization Objective. To sum up, combined flow-based temporal mask  and
    $\ell_{LLM}$), the overall objective function in Eq. [1](#S3.E1 "Equation 1 ‣
    3.3 Problem Formulation ‣ 3 Methodology ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs") can be further formalized as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: 'where  correspond to the three loss weights, which aim to balance them during
    the optimization. Our overall attack procedure is described in Algorithm [1](#alg1
    "Algorithm 1 ‣ 3.4 Optimization Objective ‣ 3 Methodology ‣ FMM-Attack: A Flow-based
    Multi-modal Adversarial Attack on Video-based LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 FMM-Attack on Video-based LLMs Using PGD Optimization
  prefs: []
  type: TYPE_NORMAL
- en: '0:  Clean video , sparsity , LLM , iterations 1:  Compute video optical flow
    and obtain flow-based temporal mask 2:  Initialize perturbation  do4:     Calculate
    video features loss  using Eq. [5](#S3.E5 "Equation 5 ‣ 3.4 Optimization Objective
    ‣ 3 Methodology ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs")6:     Update perturbation 7:  end while8:  Compute adversarial video'
  prefs: []
  type: TYPE_NORMAL
- en: 'Extended Targeted Version of FMM-Attack. As previously mentioned, the proposed
    FMM-Attack is initially designed for untargeted adversarial attacks. However,
    its flexibility allows for an extension to a targeted version as well. In targeted
    scenarios, the goal is transformed to craft an imperceptible adversarial perturbation
    for videos, which can induce video-based LLMs to generate a targeted sequence.
    To achieve such a targeted adversarial attack, we first obtain the targeted video  in
    the untargeted objective of Eq. [6](#S3.E6 "Equation 6 ‣ 3.4 Optimization Objective
    ‣ 3 Methodology ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs") with the targeted video $\mathbf{X}_{t}$, the overall objective function
    of targeted FMM-Attack can be formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: 4 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we showcase the effectiveness of our proposed FMM-Attack, evaluated
    on zero-shot question-answer datasets. In addition, we conduct several ablation
    study experiments on the loss of different modalities, perturbation budget , ),
    and selection of video frames.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Implementation Details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Models and datasets. We assess open-source and state-of-the-art video-based
    LLMs such as Video-ChatGPT [[15](#bib.bib15)] and VideoChat [[11](#bib.bib11)]
    (VideoChat [[11](#bib.bib11)] is in the Appendix), ensuring reproducibility of
    our results. Concretely, we adopt Video-ChatGPT and VideoChat with a LLaMA-7B
    LLM [[23](#bib.bib23)]. In line with the Video-ChatGPT [[15](#bib.bib15)] methodology,
    we curate a test set based on the ActivityNet-200 [[3](#bib.bib3)] and MSVD-QA [[29](#bib.bib29)]
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Setups. The perturbation limit  and step size ,  are set to 2, 1, and 3 respectively.
    Each experiment is run on a single NVIDIA-V100 GPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'Baselines. For evaluation, we design three spatial baselines, including videos
    with random perturbations, black videos with all pixel values set to 0, and white
    videos with all pixel values set to 1\. In addition, we compare our proposed flow-based
    temporal mask with two straightforward temporal mask methods, serving as temporal
    mask baselines: the sequence temporal mask and the random temporal mask. Specifically,
    the sequence temporal mask consists of a continuous sequence of frame indices,
    while the random temporal mask comprises a randomly chosen sequence of frame indices.'
  prefs: []
  type: TYPE_NORMAL
- en: Metrics. We utilize a variety of evaluation metrics to assess the robustness
    of the models.
  prefs: []
  type: TYPE_NORMAL
- en: (a) CLIP Score. CLIP [[20](#bib.bib20)] score characterizes the semantic similarity
    between the adversarial answer and the ground-truth answer. A lower CLIP score
    signifies a lower semantic correlation between the adversarial answer and the
    ground-truth answer, indicating a more effective attack.
  prefs: []
  type: TYPE_NORMAL
- en: (b) Image Captioning Metrics. Various metrics such as BLEU [[17](#bib.bib17)],
    ROUGE-L [[12](#bib.bib12)], and CIDEr [[24](#bib.bib24)] are used to evaluate
    the quality of the adversarial answer generated by the model. A lower score corresponds
    to a more effective attack.
  prefs: []
  type: TYPE_NORMAL
- en: (c) GPT Score. Following Video-ChatGPT [[15](#bib.bib15)] and Video-LLaMA [[32](#bib.bib32)].
    We also employ an evaluation pipeline using the GPT-3.5 and GPT-4 models. The
    pipeline employs GPT to assign a score from 1 to 5, evaluating the similarity
    between the output sentence and the ground truth, and a binary score (0 or 1)
    to measure its accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: (d) Sparsity. Sparsity refers to the ratio of frames without perturbations (clean
    frames) to the total number of frames in a specific video. The sparsity , where  is
    the total number of frames in a video. The bigger the value of ${M}_{spa}$, the
    sparser the perturbation distribution, indicating that fewer video frames are
    attacked.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Main Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 1: White-box attacks against Video-ChatGPT [[15](#bib.bib15)] on the
    ActivityNet-200 [[3](#bib.bib3)] dataset and the MSVD-QA [[29](#bib.bib29)] dataset:
    Comparison of CLIP score, image caption metrics and GPT score for different attack
    types. Random spatial attack denotes random perturbations added to video frames,
    and Black spatial attack and White spatial attack denote video frames being all
    0 and all 1, respectively. The sparsity of the temporal mask is set to 0\. ${\Delta}$:
    the mean of the modified pixels. Our attack is optimized based on Eq. [6](#S3.E6
    "Equation 6 ‣ 3.4 Optimization Objective ‣ 3 Methodology ‣ FMM-Attack: A Flow-based
    Multi-modal Adversarial Attack on Video-based LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Type |  | Image Caption  | GPT-4 $\downarrow$ |'
  prefs: []
  type: TYPE_TB
- en: '| RN50 | RN101 | BLEU | ROUGE-L | Accurate | Score | Accurate | Score |'
  prefs: []
  type: TYPE_TB
- en: '| ActivityNet [[3](#bib.bib3)] | Clean | 0 | 0.7817 | 0.7827 | 0.2029 | 0.4820
    | 0.50 | 3.20 | 0.33 | 2.10 |'
  prefs: []
  type: TYPE_TB
- en: '| Random | 8 | 0.7637 | 0.7681 | 0.1986 | 0.4793 | 0.45 | 3.10 | 0.33 | 2.03
    |'
  prefs: []
  type: TYPE_TB
- en: '| Black | 100 | 0.7661 | 0.7676 | 0.1691 | 0.4570 | 0.30 | 2.50 | 0.17 | 0.96
    |'
  prefs: []
  type: TYPE_TB
- en: '| White | 148 | 0.7564 | 0.7534 | 0.1689 | 0.4545 | 0.31 | 2.60 | 0.19 | 1.24
    |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | 8 | 0.6211 | 0.6274 | 0.1336 | 0.3694 | 0.20 | 1.64 | 0.13 | 0.88 |'
  prefs: []
  type: TYPE_TB
- en: '| MSVD-QA [[29](#bib.bib29)] | Clean | 0 | 0.8322 | 0.8180 | 0.3864 | 0.6843
    | 0.62 | 3.84 | 0.60 | 3.12 |'
  prefs: []
  type: TYPE_TB
- en: '| Random | 8 | 0.8249 | 0.8141 | 0.4107 | 0.7042 | 0.58 | 3.72 | 0.60 | 3.08
    |'
  prefs: []
  type: TYPE_TB
- en: '| Black | 110 | 0.8145 | 0.7902 | 0.3548 | 0.6478 | 0.46 | 3.26 | 0.40 | 2.12
    |'
  prefs: []
  type: TYPE_TB
- en: '| White | 142 | 0.8057 | 0.8090 | 0.3969 | 0.6736 | 0.48 | 3.36 | 0.44 | 2.28
    |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | 8 | 0.7337 | 0.7181 | 0.3240 | 0.5746 | 0.36 | 2.92 | 0.34 | 1.84 |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/8e6647150c05fd765cf0dd4d2534e9b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Perturbed videos generated by Video-ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: White-box attacks against Video-ChatGPT [[15](#bib.bib15)] on the
    ActivityNet-200 [[3](#bib.bib3)] dataset. seq: sequence temporal mask. random:
    random temporal mask. FMM: our flow-based temporal mask attack. ${M}_{spa}$: Sparsity
    of temporal mask. Our attack is optimized based on Eq. [6](#S3.E6 "Equation 6
    ‣ 3.4 Optimization Objective ‣ 3 Methodology ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Metrics |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| seq | random | FMM | seq | random | FMM | seq | random | FMM | seq | random
    | FMM |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| RN50 | 0.7500 | 0.7142 | 0.6821 | 0.7578 | 0.7559 | 0.7460 | 0.7583 | 0.7671
    | 0.7510 | 0.7715 | 0.7813 | 0.7349 |'
  prefs: []
  type: TYPE_TB
- en: '| RN101 | 0.7568 | 0.7251 | 0.7085 | 0.7500 | 0.7588 | 0.7559 | 0.7764 | 0.7769
    | 0.7500 | 0.7788 | 0.7827 | 0.7637 |'
  prefs: []
  type: TYPE_TB
- en: '| BLEU | 0.1572 | 0.1590 | 0.1527 | 0.1606 | 0.1751 | 0.1485 | 0.1900 | 0.1894
    | 0.1830 | 0.2000 | 0.1957 | 0.1940 |'
  prefs: []
  type: TYPE_TB
- en: '| ROUGE-L | 0.4073 | 0.3996 | 0.4109 | 0.4323 | 0.4458 | 0.4053 | 0.4767 |
    0.4727 | 0.4713 | 0.4779 | 0.4658 | 0.4731 |'
  prefs: []
  type: TYPE_TB
- en: '| GPT3.5 | 2.02 | 2.01 | 2.00 | 2.45 | 2.24 | 2.22 | 2.64 | 2.63 | 2.62 | 2.76
    | 2.78 | 2.75 |'
  prefs: []
  type: TYPE_TB
- en: '| GPT4 | 1.09 | 1.08 | 1.07 | 1.35 | 1.34 | 1.33 | 1.63 | 1.63 | 1.61 | 1.99
    | 1.58 | 1.54 |'
  prefs: []
  type: TYPE_TB
- en: Quantitative Evaluation. We performed an extensive quantitative analysis using
    the popular open-ended question-answer datasets ActivityNet-200 [[3](#bib.bib3)]
    and MSVD-QA [[29](#bib.bib29)].
  prefs: []
  type: TYPE_NORMAL
- en: 'As depicted in the left of Table [1](#S4.T1 "Table 1 ‣ 4.2 Main Results ‣ 4
    Experiments ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs"), the random, black, white, and flow-based attacks all significantly decrease
    the clip score and image caption score compared to the original clean videos.
    Among these, our proposed FMM-Attack yields the most significant results. As demonstrated
    in the right of Table [1](#S4.T1 "Table 1 ‣ 4.2 Main Results ‣ 4 Experiments ‣
    FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"),
    the random, black, white, and flow-based attacks all significantly decrease the
    GPT scores and accuracies. Among them, the FMM-Attack achieves the most substantial
    results.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [2](#S4.T2 "Table 2 ‣ 4.2 Main Results ‣ 4 Experiments ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs") compares different
    mask ratios (sparsity) and temporal mask approaches. Our FMM-Attack outperforms
    the other two approaches across various sparsity levels, indicating the effectiveness
    of our proposed flow-based temporal mask, which leverages the concept of maximum
    flow prioritization. It demonstrates its potency in the realm of video-based LLM
    and its ability to maximize the extraction of video information. In the bottom
    of Table [2](#S4.T2 "Table 2 ‣ 4.2 Main Results ‣ 4 Experiments ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"), FMM-Attack
    consistently outperforms the other two approaches across various sparsity levels,
    resulting in a more significant reduction of GPT scores and accuracies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Qualitative Evaluation. We also present qualitative examples (see Fig. [3](#S4.F3
    "Figure 3 ‣ 4.2 Main Results ‣ 4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs")) of the attacked videos, in which the
    model produces garbled responses without any meaningful content. Fig. [3](#S4.F3
    "Figure 3 ‣ 4.2 Main Results ‣ 4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs") vividly illustrates the chaos induced
    in the model’s responses by our subtle and imperceptible attacks. This signals
    a clear need for enhancing the robustness of the model. It is noteworthy that
    the response generated from the clean video forms a coherent sentence strongly
    correlated to the corresponding question. However, in the case of the attacked
    video, the responses consist of repetitive words that lack meaningful context
    or incorrect answers. This clearly demonstrates the potent obfuscation effect
    of our attack.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bbaefb74b2e1ac546a14476c4c0b7260.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Relationship between optical flow and key frames. ‘Clip Score of
    Adjacent Frames’ describes the similarity between the current frame and its adjacent
    frames, the smaller this score is the more different the current frame is. ‘Clip
    Score of Answer and Current Frame’ indicates the similarity between the current
    frame and the answer corresponding to the user’s input question, the larger the
    score indicates that the current frame contains more information about the answer.
    The frames selected by flow-based masks in our FMM-Attack are key frames in the
    video.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Discussions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Essence of Flow-based Masks. We address the essence of flow-based temporal
    masks in our FMM-Attack. The flow-based masks by selecting key frames method is
    a powerful tool for video understanding and manipulation, which allows for precise
    control over specific elements in a video sequence, making it easier to edit and
    manipulate the video in a variety of ways. We use the clip image-image score of
    adjacent frames and clip text-image score between the answer and current frame
    to assess the importance and non-fungibility of our selected frames in FMM-Attack,
    where a smaller clip image-image score suggests less similarity between a frame
    and its adjacent frames, and a bigger clip text-image score suggests more similarity
    between the current frame and the answer of the user input. As depicted in Fig. [4](#S4.F4
    "Figure 4 ‣ 4.2 Main Results ‣ 4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs"), a larger optical flow corresponds to
    a higher inconsistency between the current frame and its neighboring frames, while
    containing more information about the answer. This observation suggests that the
    frames selected using our FMM-Attack are crucial frames in the video, and attacking
    them will yield more effective results.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Garbling Effect. Intriguingly, our proposed FMM-Attack induces garbling in
    the model output, while the other three attack methods do not cause such distortion.
    This suggests that the FMM-Attack not only diminishes the model’s cue information
    but also prompts the model to hallucinate. Furthermore, as shown in Fig. [5](#S4.F5
    "Figure 5 ‣ 4.3 Discussions ‣ 4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs"), we analyse the number of successfully
    attacked Video-ChatGPT in ActivityNet-200 [[3](#bib.bib3)], and find that video
    loss is more effective in inducing garbled contents, which is consistent with
    our observation in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ FMM-Attack: A
    Flow-based Multi-modal Adversarial Attack on Video-based LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/09352f91eda79dc943256501b443fb3f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Comparison of different types of attacks on the garbling rate. Max
    Modify denotes the maximum pixel value that can be modified, while the Garble
    Rate represents the percentage of responses that are garbled.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bf5aa52c0a07e19fff19b35ec4108366.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Illustration of the targeted attack.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Targeted Version of FMM-Attack. Fig. [6](#S4.F6 "Figure 6 ‣ 4.3 Discussions
    ‣ 4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs") illustrates an example of our targeted attack. We utilize the video features
    and LLM features of the target video as the attack target to generate $\Delta$
    as in Eq. [7](#S3.E7 "Equation 7 ‣ 3.4 Optimization Objective ‣ 3 Methodology
    ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs").
    As evident in Fig. [6](#S4.F6 "Figure 6 ‣ 4.3 Discussions ‣ 4 Experiments ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"), our implementation
    of the inconspicuous attack enables the video-based LLMs’ answer to closely resemble
    the target’s answer, while significantly differing from the clean video’s output.
    Despite the target video and clean video being entirely distinct, we can achieve
    the desired targeted attack, demonstrating the effectiveness of the proposed FMM-Attack.
    More analyses can be found in the Appendix.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Potential Defense. As shown in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣
    FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"),
    the video features transfer better across different modalities, especially for
    garbled samples. Improving the robustness of clip/video modules is thus of great
    importance for video-based LLMs or even other vision-related multi-modal models.
    In addition, more attention should be paid to safety-based alignment, which could
    greatly protect video-based LLMs from being attacked. Moreover, common data preprocessing
    methods, which remove adversarial perturbations by compressing or generative models,
    should be beneficial in defending our FMM-Attack.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Ablation Studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will conduct some ablation and exploratory experiments.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f3b8191c8e29fefe972e2e6e76199d36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Ablation Studies of different attack settings. (a) Comparison of
    different max modify pixels: Despite varying max modify pixels, the mean value
    of the modified video remains the same due to the sparse loss. (b) Comparison
    of different random select percentages: The select rate represents the percentage
    of attacked video frames that the victimized model samples from. For the baseline
    without attack, the values on each of the five metrics are 0.7817, 0.7827, 0.8096,
    0.8115, and 0.7231, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Comparison of different attack types on Clip Score and Image Captioning
    Metrics. video: represents attacks targeting video features, LLM: represents attacks
    targeting LLM features, and video + LLM: represents combined attacks on both video
    and LLM features. Lower scores indicate better attack performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Type | Clip Score  |'
  prefs: []
  type: TYPE_TB
- en: '| RN50 | RN101 | ViT-B/16 | ViT-B/32 | ViT-L/14 | BLEU | ROUGE-L | CIDEr |'
  prefs: []
  type: TYPE_TB
- en: '| Clean | 0.7817 | 0.7827 | 0.8096 | 0.8115 | 0.7231 | 0.2029 | 0.4820 | 1.6364
    |'
  prefs: []
  type: TYPE_TB
- en: '| video | 0.7403 | 0.7524 | 0.7690 | 0.7744 | 0.6811 | 0.1975 | 0.4345 | 1.5862
    |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | 0.7153 | 0.6904 | 0.7334 | 0.7515 | 0.6387 | 0.1042 | 0.3226 | 0.8350
    |'
  prefs: []
  type: TYPE_TB
- en: '| video + LLM | 0.6491 | 0.6060 | 0.6836 | 0.6968 | 0.5566 | 0.0230 | 0.1585
    | 0.1601 |'
  prefs: []
  type: TYPE_TB
- en: 'Loss of Different Modalities. In Table [3](#S4.T3 "Table 3 ‣ 4.4 Ablation Studies
    ‣ 4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs"), the video + LLM attack outperforms the individual video and LLM attacks
    across all metrics, demonstrating the superior performance of the combined approach.
    This can be attributed to the complementary nature of video and LLM features,
    which, when targeted simultaneously, leads to a more potent attack that effectively
    disrupts the model’s output, resulting in lower scores.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perturbation Budget . It’s important to note that the mean of . As in Fig. [7](#S4.F7
    "Figure 7 ‣ 4.4 Ablation Studies ‣ 4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs") (a),  is, the greater the potential modification
    of individual pixels, but on the other hand, due to the sparse loss, the amount
    of pixels that can be modified with a larger  seems to be a better trade-off.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Percentage of Selected Frames. In some instances, while we launch attacks on
    all video frames, video-based LLMs only randomly sample a subset of the video
    frames. As demonstrated in Fig. [7](#S4.F7 "Figure 7 ‣ 4.4 Ablation Studies ‣
    4 Experiments ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs") (b), the potency of the attack escalates with an increasing number of sampled
    video frames. Interestingly, even when a minor fraction (40%, 20%) of video frames
    are sampled, we observe a substantial decline in the Clip score relative to the
    baseline. Surprisingly, a 20% sampling rate seems to yield superior results than
    a 40% rate. We speculate this unexpected outcome could be due to inherent fluctuations
    when a limited number of video frames are sampled, coupled with our stream-based
    approach that assures a certain minimum attack effectiveness. To make this engagement
    more compelling, we intend to delve deeper into this phenomenon with additional
    experiments in future studies.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we introduce the Flow-based Multi-modal Attack (FMM-Attack),
    the first of its kind against video-based LLMs. Our comprehensive experiments
    demonstrate that our attack can effectively induce video-based LLMs to generate
    either garbled nonsensical sequences or incorrect semantic sequences with imperceptible
    perturbations added on less than 20% video frames. Furthermore, our insights into
    cross-modal feature attacks contribute to a deeper understanding of multi-modal
    robustness and the critical alignment of safety-related features. These findings
    hold significant implications for various large multi-modal models, underscoring
    the relevance and impact of our work.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Aafaq, N., Akhtar, N., Liu, W., Gilani, S.Z., Mian, A.: Spatio-temporal
    dynamics and semantic attribute enriched visual encoding for video captioning.
    In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition.
    pp. 12487–12496 (2019)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Bagdasaryan, E., Hsieh, T.Y., Nassi, B., Shmatikov, V.: (ab) using images
    and sounds for indirect instruction injection in multi-modal llms. arXiv preprint
    arXiv:2307.10490 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Caba Heilbron, F., Escorcia, V., Ghanem, B., Carlos Niebles, J.: Activitynet:
    A large-scale video benchmark for human activity understanding. In: Proceedings
    of the ieee conference on computer vision and pattern recognition. pp. 961–970
    (2015)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Chen, T.S., Siarohin, A., Menapace, W., Deyneka, E., Chao, H.w., Jeon,
    B.E., Fang, Y., Lee, H.Y., Ren, J., Yang, M.H., et al.: Panda-70m: Captioning
    70m videos with multiple cross-modality teachers. arXiv preprint arXiv:2402.19479
    (2024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson,
    R., Franke, U., Roth, S., Schiele, B.: The cityscapes dataset for semantic urban
    scene understanding. In: Proceedings of the IEEE conference on computer vision
    and pattern recognition. pp. 3213–3223 (2016)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Dong, J., Li, X., Xu, C., Yang, X., Yang, G., Wang, X., Wang, M.: Dual
    encoding for video retrieval by text. IEEE Transactions on Pattern Analysis and
    Machine Intelligence 44(8), 4065–4080 (2021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Gabeur, V., Sun, C., Alahari, K., Schmid, C.: Multi-modal transformer for
    video retrieval. In: Computer Vision–ECCV 2020: 16th European Conference, Glasgow,
    UK, August 23–28, 2020, Proceedings, Part IV 16\. pp. 214–229\. Springer (2020)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Gong, Y., Ran, D., Liu, J., Wang, C., Cong, T., Wang, A., Duan, S., Wang,
    X.: Figstep: Jailbreaking large vision-language models via typographic visual
    prompts. arXiv preprint arXiv:2311.05608 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Hu, W., Zhao, H., Jiang, L., Jia, J., Wong, T.T.: Bidirectional projection
    network for cross dimension scene understanding. In: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition. pp. 14373–14382 (2021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Hui, T.W., Tang, X., Loy, C.C.: Liteflownet: A lightweight convolutional
    neural network for optical flow estimation. In: Proceedings of the IEEE conference
    on computer vision and pattern recognition. pp. 8981–8989 (2018)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Li, K., He, Y., Wang, Y., Li, Y., Wang, W., Luo, P., Wang, Y., Wang, L.,
    Qiao, Y.: Videochat: Chat-centric video understanding. arXiv preprint arXiv:2305.06355
    (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Lin, C.Y.: Rouge: A package for automatic evaluation of summaries. In:
    Text summarization branches out. pp. 74–81 (2004)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Liu, H., Li, C., Li, Y., Lee, Y.J.: Improved baselines with visual instruction
    tuning. In: NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following
    (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Luo, H., Ji, L., Zhong, M., Chen, Y., Lei, W., Duan, N., Li, T.: Clip4clip:
    An empirical study of clip for end to end video clip retrieval and captioning.
    Neurocomputing 508, 293–304 (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Maaz, M., Rasheed, H., Khan, S., Khan, F.S.: Video-chatgpt: Towards detailed
    video understanding via large vision and language models. arXiv preprint arXiv:2306.05424
    (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep
    learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083
    (2017)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Papineni, K., Roukos, S., Ward, T., Zhu, W.J.: Bleu: a method for automatic
    evaluation of machine translation. In: Proceedings of the 40th annual meeting
    of the Association for Computational Linguistics. pp. 311–318 (2002)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Qi, X., Huang, K., Panda, A., Wang, M., Mittal, P.: Visual adversarial
    examples jailbreak large language models. arXiv preprint arXiv:2306.13213 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S.,
    Sastry, G., Askell, A., Mishkin, P., Clark, J., et al.: Learning transferable
    visual models from natural language supervision. In: International conference
    on machine learning. pp. 8748–8763\. PMLR (2021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S.,
    Sastry, G., Askell, A., Mishkin, P., Clark, J., et al.: Learning transferable
    visual models from natural language supervision. In: International conference
    on machine learning. pp. 8748–8763\. PMLR (2021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution
    image synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF
    conference on computer vision and pattern recognition. pp. 10684–10695 (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Seo, P.H., Nagrani, A., Arnab, A., Schmid, C.: End-to-end generative pretraining
    for multimodal video captioning. In: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition. pp. 17959–17968 (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix,
    T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., et al.: Llama: Open and efficient
    foundation language models. arXiv preprint arXiv:2302.13971 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Vedantam, R., Lawrence Zitnick, C., Parikh, D.: Cider: Consensus-based
    image description evaluation. In: Proceedings of the IEEE conference on computer
    vision and pattern recognition. pp. 4566–4575 (2015)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Venugopalan, S., Rohrbach, M., Donahue, J., Mooney, R., Darrell, T., Saenko,
    K.: Sequence to sequence-video to text. In: Proceedings of the IEEE international
    conference on computer vision. pp. 4534–4542 (2015)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Wang, W., Chen, Z., Chen, X., Wu, J., Zhu, X., Zeng, G., Luo, P., Lu,
    T., Zhou, J., Qiao, Y., et al.: Visionllm: Large language model is also an open-ended
    decoder for vision-centric tasks. Advances in Neural Information Processing Systems
    36 (2024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Wei, X., Zhu, J., Yuan, S., Su, H.: Sparse adversarial perturbations for
    videos. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 33,
    pp. 8973–8980 (2019)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Wu, Y.H., Liu, Y., Zhan, X., Cheng, M.M.: P2t: Pyramid pooling transformer
    for scene understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence
    (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Xu, D., Zhao, Z., Xiao, J., Wu, F., Zhang, H., He, X., Zhuang, Y.: Video
    question answering via gradually refined attention over appearance and motion.
    In: Proceedings of the 25th ACM international conference on Multimedia. pp. 1645–1653
    (2017)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Xue, H., Hang, T., Zeng, Y., Sun, Y., Liu, B., Yang, H., Fu, J., Guo,
    B.: Advancing high-resolution video-language representation with large-scale video
    transcriptions. In: Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition. pp. 5036–5045 (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Yang, D., Bai, Y., Jia, X., Liu, Y., Cao, X., Yu, W.: Cheating suffix:
    Targeted attack to text-to-image diffusion models with multi-modal priors. arXiv
    preprint arXiv:2402.01369 (2024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Zhang, H., Li, X., Bing, L.: Video-llama: An instruction-tuned audio-visual
    language model for video understanding. arXiv preprint arXiv:2306.02858 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Zhang, Z., Qi, Z., Yuan, C., Shan, Y., Li, B., Deng, Y., Hu, W.: Open-book
    video captioning with retrieve-copy-generate network. In: Proceedings of the IEEE/CVF
    conference on computer vision and pattern recognition. pp. 9837–9846 (2021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Zhao, Y., Pang, T., Du, C., Yang, X., Li, C., Cheung, N.M.M., Lin, M.:
    On evaluating adversarial robustness of large vision-language models. Advances
    in Neural Information Processing Systems 36 (2024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Zhu, D., Chen, J., Shen, X., Li, X., Elhoseiny, M.: Minigpt-4: Enhancing
    vision-language understanding with advanced large language models. arXiv preprint
    arXiv:2304.10592 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Zhuang, H., Zhang, Y., Liu, S.: A pilot study of query-free adversarial
    attack against stable diffusion. In: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition. pp. 2384–2391 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Zong, Y., Bohdal, O., Yu, T., Yang, Y., Hospedales, T.: Safety fine-tuning
    at (almost) no cost: A baseline for vision large language models. arXiv preprint
    arXiv:2402.02207 (2024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this Appendix, we provide further implementation details in Section [0.A](#Pt0.A1
    "Appendix 0.A Implementation Details ‣ FMM-Attack: A Flow-based Multi-modal Adversarial
    Attack on Video-based LLMs"), including flow-based temporal mask, threat model
    specifics, datasets, and experimental setups. Following that, we present additional
    experimental results in Section [0.B](#Pt0.A2 "Appendix 0.B Additional Experimental
    Results ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs"), featuring extended video question-answer methods (VideoChat [[11](#bib.bib11)])
    and comprehensive evaluation metrics. We also report our findings from transfer-based
    black-box attack experiments in Section [0.C](#Pt0.A3 "Appendix 0.C Transfer-based
    Black-box Attacks ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on
    Video-based LLMs"), showcasing the impressive transferability of our attack method.
    Moreover, we offer more visual comparisons in Section [0.D](#Pt0.A4 "Appendix
    0.D Additional Visualization Results ‣ FMM-Attack: A Flow-based Multi-modal Adversarial
    Attack on Video-based LLMs"). Ethics statement and reproducibility statement can
    be found in Section [0.E](#Pt0.A5 "Appendix 0.E Ethics Statement ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs") and Section [0.F](#Pt0.A6
    "Appendix 0.F Reproducibility Statement ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs"), respectively. Finally, we discuss the
    limitations of this paper in Section [0.G](#Pt0.A7 "Appendix 0.G Limitation ‣
    FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 0.A Implementation Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Models. We assess open-source and state-of-the-art video-based LLMs such as
    Video-ChatGPT [[15](#bib.bib15)] and VideoChat [[11](#bib.bib11)], ensuring reproducibility
    of our results. Video-ChatGPT is a multi-modal model that seamlessly combines
    a video-adapted visual encoder (CLIP [[20](#bib.bib20)]) with a LLM, which is
    proficient in comprehending and generating intricate conversations related to
    videos. VideoChat integrates video foundation models and large language models
    via a learnable neural interface.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8a74061813c7e7797145a56669b2af06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Relationship between optical flow and key frames. ‘Clip Score of
    Adjacent Frames’ describes the similarity between the current frame and its adjacent
    frames, the smaller this score is the more different the current frame is. The
    frames selected by flow-based masks in our FMM-Attack are key frames in the video.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Flow-based Temporal Mask. In addition to the statistical analyses presented
    in the main manuscript, we visualize flow-based methods to enhance interpretability.
    As depicted in Fig. [8](#Pt0.A1.F8 "Figure 8 ‣ Appendix 0.A Implementation Details
    ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"),
    the brightness represents the magnitude of the optical flow, and the color indicates
    the motion direction. The motion flow magnitude varies across different frames,
    with a larger optical flow signifying more significant motion. Our FMM method
    tends to select the video frames with the largest optical flow as the key frame
    of the video. In other words, we tend to prioritize frames with substantial motion
    changes. Furthermore, the frames we select exhibit low similarity with their neighboring
    frames, indicating their importance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Algorithm [2](#alg2 "Algorithm 2 ‣ Appendix 0.A Implementation Details ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs") delineates the
    process of generating the selected set . The optical flow is computed using a
    pre-trained liteflownet [[10](#bib.bib10)]. For the random temporal mask, we generate
    the selected set  elements from the total set  represents the set of frame indices,  denotes
    the total number of frames in the video. For the sequence temporal mask, we construct
    the selected set  elements from the total set  comprises a sequence of frames
    from total frames  or .'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 2 Select Top K Frames with Maximum Flow
  prefs: []
  type: TYPE_NORMAL
- en: 0:  video_frames 0:  U, a subset with 1:  for each frame in video_frames do2:     Compute
    optical flow between adjacent frames3:  end for4:  for each optical flow do5:     Convert
    optical flow to color and magnitude components6:     Normalize the magnitude component7:  end for8:  Sort
    the frames based on the average value of the magnitude component9:  Select the
    top K frame indices with the highest flow values as the set U
  prefs: []
  type: TYPE_NORMAL
- en: Datasets. In line with the Video-ChatGPT [[15](#bib.bib15)] methodology, we
    curate a test set based on the ActivityNet-200 [[3](#bib.bib3)] and MSVD-QA [[29](#bib.bib29)]
    datasets, featuring videos with rich, detailed descriptive captions and associated
    question-answer pairs obtained from human annotations. Utilizing this test set
    to generate adversarial examples, we effectively and quantitatively assess the
    adversarial robustness of video-based LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Experimental setups. For evaluation, we design three spatial baselines, including
    videos with random perturbations, black videos with all pixel values set to 0,
    and white videos with all pixel values set to 1\. In addition, we compare our
    proposed flow-based temporal mask with two straightforward temporal mask methods,
    serving as temporal mask baselines: the sequence temporal mask and the random
    temporal mask. Specifically, the sequence temporal mask consists of a continuous
    sequence of frame indices, while the random temporal mask comprises a randomly
    chosen sequence of frame indices. We utilize a variety of evaluation metrics to
    assess the robustness of the models. CLIP [[20](#bib.bib20)] score characterizes
    the semantic similarity between the adversarial answer and the ground-truth answer.
    A lower CLIP score signifies a lower semantic correlation between the adversarial
    answer and the ground-truth answer, indicating a more effective attack. Various
    Image Captioning metrics such as BLEU [[17](#bib.bib17)], ROUGE-L [[12](#bib.bib12)],
    and CIDEr [[24](#bib.bib24)] are used to evaluate the quality of the adversarial
    answer generated by the model. A lower score corresponds to a more effective attack.
    BLEU measures the overlap of n-grams between the generated and reference captions.
    ROUGE-L computes the longest common subsequence between them, reflecting their
    sentence-level similarity. CIDEr emphasizes the importance of semantically meaningful
    words in the captions. Following Video-ChatGPT [[15](#bib.bib15)] and Video-LLaMA [[32](#bib.bib32)].
    We also employ an evaluation pipeline using the GPT-3.5 and GPT-4 models. The
    pipeline employs GPT to assign a score from 1 to 5, evaluating the similarity
    between the output sentence and the ground truth, and a binary score (0 or 1)
    to measure its accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: White-box attacks against VideoChat [[11](#bib.bib11)] on the ActivityNet-200 [[3](#bib.bib3)]
    dataset and the MSVD-QA [[29](#bib.bib29)] dataset: Comparison of image caption
    metrics and GPT score for different attack types. Random spatial attack denotes
    random perturbations added to video frames, and Black spatial attack and White
    spatial attack denote video frames being all 0 and all 1, respectively. The sparsity
    of the temporal mask is set to 0\. ${\Delta}$: the mean of the modified pixels.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Type |  | GPT-3.5  |'
  prefs: []
  type: TYPE_TB
- en: '| BLEU | ROUGE | CIDEr | Accurate | Score | Accurate | Score |'
  prefs: []
  type: TYPE_TB
- en: '| ActivityNet [[3](#bib.bib3)] | Clean | 0 | 0.0765 | 0.3358 | 0.3379 | 0.35
    | 2.87 | 0.28 | 1.79 |'
  prefs: []
  type: TYPE_TB
- en: '| Random | 8 | 0.0870 | 0.3446 | 0.4225 | 0.47 | 3.04 | 0.34 | 2.06 |'
  prefs: []
  type: TYPE_TB
- en: '| Black | 110 | 0.0726 | 0.3104 | 0.3599 | 0.16 | 2.17 | 0.10 | 0.66 |'
  prefs: []
  type: TYPE_TB
- en: '| White | 152 | 0.0828 | 0.3226 | 0.3698 | 0.18 | 2.25 | 0.11 | 0.79 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | 2 | 0.0626 | 0.2474 | 0.2859 | 0.06 | 1.43 | 0.06 | 0.40 |'
  prefs: []
  type: TYPE_TB
- en: '| MSVD-QA [[29](#bib.bib29)] | Clean | 0 | 0.0415 | 0.2643 | 0.1183 | 0.70
    | 3.66 | 0.68 | 3.20 |'
  prefs: []
  type: TYPE_TB
- en: '| Random | 8 | 0.0594 | 0.2679 | 0.2182 | 0.64 | 3.44 | 0.54 | 2.78 |'
  prefs: []
  type: TYPE_TB
- en: '| Black | 110 | 0.0479 | 0.2674 | 0.2185 | 0.38 | 2.80 | 0.26 | 1.60 |'
  prefs: []
  type: TYPE_TB
- en: '| White | 153 | 0.0594 | 0.2734 | 0.4154 | 0.44 | 3.00 | 0.20 | 1.46 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | 2 | 0.0388 | 0.2001 | 0.2554 | 0.12 | 1.58 | 0.12 | 1.42 |'
  prefs: []
  type: TYPE_TB
- en: Appendix 0.B Additional Experimental Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we present additional experiments. Firstly, we execute an attack
    on another video-based LLM model, VideoChat [[11](#bib.bib11)]. Following that,
    we provide experimental results from other datasets and introduce more comprehensive
    evaluation metrics. Finally, we investigate the impact of varying the weights
    of the features loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additional Video-based LLMs. In addition to the attack on Video-ChatGPT [[15](#bib.bib15)]
    described in the main text, we also attack VideoChat [[11](#bib.bib11)], as illustrated
    in Table [4](#Pt0.A1.T4 "Table 4 ‣ Appendix 0.A Implementation Details ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"). Our proposed
    FMM significantly diminishes VideoChat’s question-answering capability, resulting
    in gibberish outputs. This is substantiated by a notable decrease in both image
    caption scores and GPT scores. Specific visualization results are provided in
    subsequent sections.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: White-box attacks against surrogate model Video-ChatGPT [[15](#bib.bib15)]
    on the MSVD-QA [[29](#bib.bib29)] dataset: Comparison of CLIP Score and Image
    Captioning Metrics for different attack types. Random attack denotes random perturbations
    added to video frames, Black attack and White attack denote video frames being
    all 0 and all 1, respectively. seq: sequence temporal mask. random: random temporal
    mask. flow: flow-based temporal mask. : the mean of the modified pixels.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Type |  | Image Caption $\downarrow$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| RN50 | RN101 | ViT-B/16 | ViT-B/32 | ViT-L/14 | BLEU | ROUGE | CIDEr |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Clean | 0 | 0.8322 | 0.8180 | 0.8299 | 0.8533 | 0.8675 | 0.3864 | 0.6843
    | 3.6792 |'
  prefs: []
  type: TYPE_TB
- en: '| Random | 8 | 0.8249 | 0.8141 | 0.8299 | 0.8376 | 0.7446 | 0.4107 | 0.7042
    | 4.0715 |'
  prefs: []
  type: TYPE_TB
- en: '| Black | 100 | 0.8145 | 0.7902 | 0.8334 | 0.8376 | 0.7280 | 0.3548 | 0.6478
    | 3.4367 |'
  prefs: []
  type: TYPE_TB
- en: '| White | 148 | 0.8057 | 0.8090 | 0.8390 | 0.8435 | 0.7580 | 0.3969 | 0.6736
    | 3.9245 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | 8 | 0.7337 | 0.7181 | 0.7645 | 0.7796 | 0.6460 | 0.3240 | 0.5746 |
    3.1420 |'
  prefs: []
  type: TYPE_TB
- en: 'Comprehensive Evaluation Metrics. Owing to space constraints in the main text,
    we include more extensive experimental results in Table [5](#Pt0.A2.T5 "Table
    5 ‣ Appendix 0.B Additional Experimental Results ‣ FMM-Attack: A Flow-based Multi-modal
    Adversarial Attack on Video-based LLMs") and Table [6](#Pt0.A2.T6 "Table 6 ‣ Appendix
    0.B Additional Experimental Results ‣ FMM-Attack: A Flow-based Multi-modal Adversarial
    Attack on Video-based LLMs"). Table 2 contains five evaluation metrics related
    to Clip score and three metrics associated with image caption. These eight metrics
    display a consistent pattern, demonstrating that our approach significantly reduces
    the correlation between questions and answers. As a result, the scores experience
    a considerable decline, indicating the effectiveness of our proposed method in
    disrupting the performance of the targeted models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [6](#Pt0.A2.T6 "Table 6 ‣ Appendix 0.B Additional Experimental Results
    ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs")
    includes a comparison of the temporal mask. We compare the four baselines - ‘Clean’,
    ‘Random’, ‘Black’, and ‘White’ - when the temporal mask is set to 0\. As evident
    from the table, our method significantly outperforms the two attack methods, ‘Black’
    and ‘White’, even though we only modify 8 pixel values compared to their modification
    of more than 100 pixel values. Additionally, when the temporal mask is not set
    to 0, we establish two alternative comparison methods: sequential (‘seq’) and
    ‘random’. The ‘seq’ method involves inputting frames with consecutive masks, while
    the ‘random’ method requires inputting frames with randomly assigned masks. Our
    proposed method, FMM, is based on the maximum flow algorithm (see Algorithm [2](#alg2
    "Algorithm 2 ‣ Appendix 0.A Implementation Details ‣ FMM-Attack: A Flow-based
    Multi-modal Adversarial Attack on Video-based LLMs")). It selects frames corresponding
    to the top K largest flows according to their flow magnitude.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: White-box attacks against surrogate model Video-ChatGPT [[15](#bib.bib15)]
    on the ActivityNet-200 [[3](#bib.bib3)] dataset: Comparison of CLIP Score and
    Image Captioning Metrics for different attack types. Random attack denotes random
    perturbations added to video frames, Black attack and White attack denote video
    frames being all 0 and all 1, respectively. seq: sequence temporal mask. random:
    random temporal mask. flow: flow-based temporal mask. : the mean of the modified
    pixels. seq: sequence temporal mask. random: random temporal mask. flow: flow-based
    temporal mask. : the mean of the modified pixels.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Type |  | Clip Score  |'
  prefs: []
  type: TYPE_TB
- en: '| RN50 | RN101 | ViT-B/16 | ViT-B/32 | ViT-L/14 | BLEU | ROUGE | CIDEr |'
  prefs: []
  type: TYPE_TB
- en: '| Clean | $0\%$ | 0 | 0.7817 | 0.7827 | 0.8096 | 0.8115 | 0.7231 | 0.2029 |
    0.4820 | 1.6364 |'
  prefs: []
  type: TYPE_TB
- en: '| Random | $0\%$ | 8 | 0.7637 | 0.7681 | 0.7920 | 0.7974 | 0.6909 | 0.1986
    | 0.4793 | 1.5552 |'
  prefs: []
  type: TYPE_TB
- en: '| Black | $0\%$ | 100 | 0.7661 | 0.7676 | 0.7959 | 0.8018 | 0.7105 | 0.1691
    | 0.4570 | 1.3246 |'
  prefs: []
  type: TYPE_TB
- en: '| White | $0\%$ | 148 | 0.7564 | 0.7534 | 0.7813 | 0.7837 | 0.6836 | 0.1689
    | 0.4545 | 1.3431 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | $0\%$ | 8 | 0.6211 | 0.6274 | 0.6748 | 0.7036 | 0.5435 | 0.1336 | 0.3694
    | 0.9864 |'
  prefs: []
  type: TYPE_TB
- en: '| seq | $20\%$ | 7 | 0.7500 | 0.7568 | 0.7856 | 0.7905 | 0.7041 | 0.1572 |
    0.4073 | 1.2312 |'
  prefs: []
  type: TYPE_TB
- en: '| random | $20\%$ | 7 | 0.7142 | 0.7251 | 0.7564 | 0.7637 | 0.6436 | 0.1590
    | 0.3996 | 1.2858 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | ${20\%}$ | 7 | 0.6821 | 0.7085 | 0.7163 | 0.7446 | 0.6314 | 0.1527
    | 0.4109 | 1.1696 |'
  prefs: []
  type: TYPE_TB
- en: '| seq | $40\%$ | 5 | 0.7578 | 0.7500 | 0.7749 | 0.7954 | 0.7012 | 0.1606 |
    0.4323 | 1.1940 |'
  prefs: []
  type: TYPE_TB
- en: '| random | $40\%$ | 5 | 0.7559 | 0.7588 | 0.7847 | 0.7925 | 0.6914 | 0.1751
    | 0.4458 | 1.4057 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | ${40\%}$ | 5 | 0.7460 | 0.7559 | 0.7759 | 0.7896 | 0.6797 | 0.1485
    | 0.4053 | 1.1327 |'
  prefs: []
  type: TYPE_TB
- en: '| seq | $60\%$ | 4 | 0.7583 | 0.7764 | 0.8027 | 0.7993 | 0.7031 | 0.1900 |
    0.4767 | 1.6175 |'
  prefs: []
  type: TYPE_TB
- en: '| random | $60\%$ | 4 | 0.7671 | 0.7769 | 0.8042 | 0.8032 | 0.7158 | 0.1894
    | 0.4727 | 1.4461 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | ${60\%}$ | 4 | 0.7510 | 0.7500 | 0.7710 | 0.7871 | 0.6714 | 0.1830
    | 0.4713 | 1.4462 |'
  prefs: []
  type: TYPE_TB
- en: '| seq | $80\%$ | 2 | 0.7715 | 0.7788 | 0.7964 | 0.7954 | 0.7119 | 0.2000 |
    0.4779 | 1.6175 |'
  prefs: []
  type: TYPE_TB
- en: '| random | $80\%$ | 2 | 0.7813 | 0.7827 | 0.8052 | 0.8071 | 0.7178 | 0.1957
    | 0.4658 | 1.5905 |'
  prefs: []
  type: TYPE_TB
- en: '| FMM | ${80\%}$ | 2 | 0.7349 | 0.7637 | 0.7783 | 0.7886 | 0.6826 | 0.1940
    | 0.4731 | 1.4555 |'
  prefs: []
  type: TYPE_TB
- en: 'Hyperparameters. We aimed to investigate the impact of varying the weights
    of the video features loss and LLM features loss on the attack effectiveness.
    As shown in Table [7](#Pt0.A2.T7 "Table 7 ‣ Appendix 0.B Additional Experimental
    Results ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs"), different combinations of weights can lead to varying degrees of attack
    effectiveness (Note that  and $\lambda_{3}=3$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Influence of the weights on the attack effectiveness. We fix the sparsity
    loss weight $\lambda_{1}$ and vary the weights of the video features loss and
    LLM features loss to explore their relative relationship. Lower scores indicate
    better attack effectiveness.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Clip Score  |'
  prefs: []
  type: TYPE_TB
- en: '| RN50 | RN101 | ViT-B/16 | ViT-B/32 | ViT-L/14 | BLEU | ROUGE-L | CIDEr |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 0.7339 | 0.7383 | 0.7544 | 0.7656 | 0.6641 | 0.2133 | 0.4843 | 1.6687
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2 | 0.7011 | 0.6665 | 0.7036 | 0.7461 | 0.6167 | 0.0602 | 0.2248 | 0.4535
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 3 | 0.6491 | 0.6060 | 0.6836 | 0.6968 | 0.5566 | 0.0230 | 0.1585 | 0.1601
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 4 | 0.7373 | 0.7192 | 0.7612 | 0.7705 | 0.6724 | 0.1710 | 0.3869 | 1.5064
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 5 | 0.7192 | 0.7061 | 0.7393 | 0.7539 | 0.6392 | 0.1207 | 0.3276 | 0.9869
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1 | 0.6621 | 0.6499 | 0.6997 | 0.7285 | 0.5942 | 0.0624 | 0.2159 | 0.4087
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 1 | 0.7129 | 0.7227 | 0.7432 | 0.7534 | 0.6470 | 0.1142 | 0.3648 | 1.0183
    |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1 | 0.7188 | 0.7217 | 0.7398 | 0.7744 | 0.6616 | 0.1670 | 0.4418 | 1.4612
    |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 1 | 0.7559 | 0.7578 | 0.7891 | 0.8018 | 0.7173 | 0.2047 | 0.4734 | 1.8045
    |'
  prefs: []
  type: TYPE_TB
- en: Appendix 0.C Transfer-based Black-box Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d46069ce0268acf4b8ad085f641c4363.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Transfer-based black-box attack on VideoChat.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: Black-box attacks against VideoChat [[11](#bib.bib11)] on the ActivityNet-200 [[3](#bib.bib3)]
    dataset: Comparison of image caption metrics and GPT score for different attack
    types. The sparsity of the temporal mask is set to 0\. ${\Delta}$: the mean of
    the modified pixels. We apply the attack video on Video-ChatGPT [[15](#bib.bib15)]
    and directly transfer it to VideoChat [[11](#bib.bib11)].'
  prefs: []
  type: TYPE_NORMAL
- en: '| Type |  | GPT-3.5  |'
  prefs: []
  type: TYPE_TB
- en: '| BLEU | ROUGE | CIDEr | Accurate | Score | Accurate | Score |'
  prefs: []
  type: TYPE_TB
- en: '| Clean | 0 | 0.0765 | 0.3358 | 0.3379 | 0.35 | 2.87 | 0.28 | 1.79 |'
  prefs: []
  type: TYPE_TB
- en: '| Transfer-based Attack | 2 | 0.0638 | 0.2492 | 0.2870 | 0.08 | 1.56 | 0.10
    | 1.32 |'
  prefs: []
  type: TYPE_TB
- en: 'In addition to white-box attacks, we have also investigated the transferability
    of these attacks. We conduct a black-box attack on VideoChat [[11](#bib.bib11)].
    Specifically, we employ the FMM-Attack method to perform a white-box attack on
    Video-ChatGPT [[15](#bib.bib15)], resulting in the attack video  is then directly
    used as input for VideoChat [[11](#bib.bib11)], with the experimental results
    displayed in Table [8](#Pt0.A3.T8 "Table 8 ‣ Appendix 0.C Transfer-based Black-box
    Attacks ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs"). It is evident that the model’s answer accuracy decreases significantly.
    Even without obtaining the gradient of VideoChat [[11](#bib.bib11)], the attack
    is successful, and there are instances of garbled text. The visualization results
    is shown in Fig. [9](#Pt0.A3.F9 "Figure 9 ‣ Appendix 0.C Transfer-based Black-box
    Attacks ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 0.D Additional Visualization Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we provide supplementary visualization results to further illustrate
    the impact of our attack method on the targeted models. The additional visualizations
    complement the main text’s qualitative analysis, offering a more in-depth understanding
    of our attack’s effectiveness and its implications on various models.
  prefs: []
  type: TYPE_NORMAL
- en: 'As depicted in Fig. [10](#Pt0.A4.F10 "Figure 10 ‣ Appendix 0.D Additional Visualization
    Results ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs"), when attacking Video-ChatGPT[[15](#bib.bib15)], the model consistently
    generates garbled responses, such as the repetition of the number "666666". This
    figure emphasizes the potency of our attack method, as it renders the model incapable
    of producing meaningful and contextually relevant responses. The consistent generation
    of garbled output highlights the vulnerability of the Video-ChatGPT model to adversarial
    attacks. In Fig.[11](#Pt0.A4.F11 "Figure 11 ‣ Appendix 0.D Additional Visualization
    Results ‣ FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based
    LLMs"), we present the results of our attack on VideoChat[[11](#bib.bib11)]. Similar
    to the case of Video-ChatGPT, the model generates garbled responses, although
    the format differs. Notably, VideoChat sometimes tends to answer with phrases
    like "It’s not clear…", which also signifies the success of our attack, as it
    effectively erases the video information. This result underlines the transferability
    of our attack method across different models and its ability to disrupt their
    performance.'
  prefs: []
  type: TYPE_NORMAL
- en: These additional visualization results, combined with the main text’s analysis,
    provide a comprehensive understanding of the impact of our attack method on the
    targeted models. They emphasize the need for enhancing the robustness of these
    models against adversarial attacks and demonstrate the importance of considering
    different attack scenarios and their consequences. Furthermore, these results
    highlight the potential challenges in developing robust video question-answering
    systems and underscore the importance of addressing these vulnerabilities to ensure
    the reliability and security of such models in real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ac7674fc42354815424295492ee5eabc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Perturbed videos generated by Video-ChatGPT, showcasing the impact
    of our attack method on the model’s responses. The figure illustrates the garbled
    responses produced by the model, such as the repetition of the number "666666",
    highlighting the vulnerability of Video-ChatGPT to our adversarial attack.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f7de05236c1b7a8fe13a5ce2b4724bde.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Perturbed videos generated by VideoChat, demonstrating the effects
    of our attack method on the model’s responses. The figure displays the garbled
    responses produced by the model, including phrases like "It’s not clear…", emphasizing
    the vulnerability of VideoChat to our adversarial attack.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 0.E Ethics Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Please note that we restrict all experiments in the laboratory environment and
    do not support our FMM-Attack in the real scenario. The purpose of our work is
    to raise the awareness of the security concern in availability of video-based
    LLMs and call for practitioners to pay more attention to the adversarial robustness
    of video-based LLMs and model trustworthy deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 0.F Reproducibility Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The detailed descriptions of models, datasets, and experimental setups are
    provided in Section [0.A](#Pt0.A1 "Appendix 0.A Implementation Details ‣ FMM-Attack:
    A Flow-based Multi-modal Adversarial Attack on Video-based LLMs"). We provide
    part of the codes to reproduce our FMM-Attack in the supplementary material. We
    will provide the remaining codes for reproducing our method upon the acceptance
    of the paper.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix 0.G Limitation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our FMM-Attack is primarily concentrated on the digital world, operating under
    the assumption that input videos are fed directly into the models. However, as
    technology advances, we anticipate that video-based LLMs will be increasingly
    deployed in more complex, real-world scenarios. These scenarios could include
    autonomous driving, where input videos are not pre-recorded but rather captured
    in real-time from physical environments via cameras. Future research should explore
    the execution and impact of adversarial attacks in the physical world. This would
    provide a more comprehensive evaluation of the security of video-based LLMs, contributing
    to the development of more robust and reliable systems for real-world deployment.
  prefs: []
  type: TYPE_NORMAL
