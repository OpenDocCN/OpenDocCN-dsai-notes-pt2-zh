- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:43:33'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Towards Automatic Hands-on-Keyboard Attack Detection Using LLMs in Endpoint
    Detection and Remediation (EDR) Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.01993](https://ar5iv.labs.arxiv.org/html/2408.01993)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Amit Portnoy [amitportnoy@microsoft.com](mailto:amitportnoy@microsoft.com) [0000-0001-6491-5814](https://orcid.org/0000-0001-6491-5814
    "ORCID identifier") ,  Ehud Azikri [ehudazikri@microsoft.com](mailto:ehudazikri@microsoft.com)
     and  Shay Kels [shkels@microsoft.com](mailto:shkels@microsoft.com) Microsoft
    Security AI Research(28 May 2024)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Endpoint Detection and Remediation (EDR) platforms are essential for identifying
    and responding to cyber threats. This study presents a novel approach using Large
    Language Models (LLMs) to detect Hands-on-Keyboard (HOK) cyberattacks. Our method
    involves converting endpoint activity data into narrative forms that LLMs can
    analyze to distinguish between normal operations and potential HOK attacks. We
    address the challenges of interpreting endpoint data by segmenting narratives
    into windows and employing a dual training strategy. The results demonstrate that
    LLM-based models have the potential to outperform traditional machine learning
    methods, offering a promising direction for enhancing EDR capabilities and apply
    LLMs in cybersecurity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hands-on-Keyboard (HOK) Attack Detection, Large Language Models (LLMs) in Cybersecurity,
    Endpoint Detection and Response (EDR)^†^†ccs: Security and privacy^†^†ccs: Computing
    methodologies Natural language processing'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cybersecurity has become an ever-present concern in our increasingly digital
    world. As organizations and individuals become more reliant on technology, the
    impact of cyberattacks has grown in both frequency and severity. In recent years,
    attackers have often focused on Hands-on-Keyboard (HOK) attacks, where adversaries
    engage directly with their target’s systems. These attacks are often meticulously
    planned and executed, allowing attackers to maneuver through networks undetected,
    making them a considerable challenge for security professionals (LiveAction, [2022](#bib.bib15);
    CrowdStrike, [2023](#bib.bib6); Microsoft Learn, [2022](#bib.bib16)).
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, cybersecurity detection methods focused on matching known patterns
    of malicious activity against observed events. However, this approach is less
    effective against HOK attacks, which frequently employ novel techniques and can
    vary significantly between instances. Anomaly detection systems offer an alternative
    by identifying deviations from baseline behaviors, yet they too struggle with
    the subtlety and sophistication of HOK attacks, often resulting in high false
    positive rates.
  prefs: []
  type: TYPE_NORMAL
- en: The limitations of these conventional methods have spurred interest in more
    advanced and adaptive security measures. In recent years, the rise of machine
    learning (ML) and artificial intelligence (AI) has provided new tools for threat
    detection and response. ML-based systems can learn from data to identify complex
    patterns and predict future events, offering the potential to recognize and react
    to HOK attacks more effectively (Buczak and Guven, [2015](#bib.bib5); Sahani et al.,
    [2023](#bib.bib19)).
  prefs: []
  type: TYPE_NORMAL
- en: Among the various AI technologies, Large Language Models (LLMs) have emerged
    as a particularly promising avenue for cybersecurity applications. These models,
    exemplified by OpenAI’s GPT series (Brown et al., [2020](#bib.bib4)), have demonstrated
    remarkable abilities in natural language understanding and generation. By training
    on vast corpora of text, LLMs can infer context, identify relationships between
    entities, and even emulate human reasoning to some extent (Liu et al., [2023](#bib.bib14)).
    The prospect of applying LLMs to cybersecurity hinges on their potential to process
    and interpret the vast amounts of unstructured text data generated by security
    systems, such as logs, alerts, and reports. Having a deeper understanding and
    stored knowledge, LLMs can identify narratives and patterns that are indicative
    of HOK activity, which might be overlooked by traditional systems.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we explore the integration of LLMs into Endpoint Detection and
    Response (EDR) solutions to enhance the detection of HOK cyberattacks. We propose
    a novel approach that transforms endpoint data into structured narratives, which
    we term ”endpoint stories.” These stories are designed to capture the essence
    of security events, providing a coherent and contextualized account that can be
    analyzed by LLMs to discern between benign operations and potential threats.
  prefs: []
  type: TYPE_NORMAL
- en: The complexity and volume of endpoint data, the need for models that can interpret
    technical and domain-specific language, and the requirement to maintain high accuracy
    while minimizing false positives all present significant hurdles. Furthermore,
    the operational deployment of LLMs and their response latency must be carefully
    considered, given the computational resources required and the critical need for
    real-time analysis in cybersecurity operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'This work addresses these challenges and demonstrates the viability of using
    LLMs for HOK attack detection. The integration of LLMs into cybersecurity practices
    represents not just a technical enhancement but a paradigm shift in how we conceptualize
    and implement security measures. Our main contributions include: (a) A new way
    to transform endpoint behavior into human-readable text admissible to processing
    by methods leveraging modern LLMs; and (b) An LLM based pipeline for classification
    of text extracted from endpoint behaviors that provides a practical solution for
    dealing with long context-lengths through a separate training of embeddings and
    the classification head.'
  prefs: []
  type: TYPE_NORMAL
- en: In Section [2](#S2 "2\. Related Work ‣ Towards Automatic Hands-on-Keyboard Attack
    Detection Using LLMs in Endpoint Detection and Remediation (EDR) Solutions"),
    we provide a review of related work, highlighting past approaches to cyberattack
    detection and the evolution of AI and LLMs in cybersecurity. Section [3](#S3 "3\.
    Methodology ‣ Towards Automatic Hands-on-Keyboard Attack Detection Using LLMs
    in Endpoint Detection and Remediation (EDR) Solutions") details our methodology,
    encompassing data collection, preparation, and the development of our LLM-based
    detection framework. Specifically, in Sub-section [3.1](#S3.SS1 "3.1\. Data Preparation
    and Collection ‣ 3\. Methodology ‣ Towards Automatic Hands-on-Keyboard Attack
    Detection Using LLMs in Endpoint Detection and Remediation (EDR) Solutions"),
    we delve into the specifics of our data handling practices, ensuring both the
    richness of the data for model training and adherence to privacy standards. Section
    [4](#S4 "4\. EVALUATION ‣ Towards Automatic Hands-on-Keyboard Attack Detection
    Using LLMs in Endpoint Detection and Remediation (EDR) Solutions") describes the
    experimental setup, including the model training process, the evaluation metrics
    employed, and the testing protocols. It includes an analysis of the performance
    of our approach in detecting HOK attacks and compares it to traditional methods.
    Finally, section [5](#S5 "5\. Conclusion ‣ Towards Automatic Hands-on-Keyboard
    Attack Detection Using LLMs in Endpoint Detection and Remediation (EDR) Solutions"),
    concludes the paper by summarizing our contributions and envisaging the impact
    of our research on the future landscape of cybersecurity defenses.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The domain of cybersecurity has witnessed a surge in research efforts aimed
    at detecting and mitigating Hands-on-Keyboard (HOK) cyberattacks. Previous studies
    have emphasized the importance of detecting these threats due to their targeted
    and interactive nature, which often results in significant damage to affected
    networks and systems (Alraizza and Algarni, [2023](#bib.bib2); Razaulla et al.,
    [2023](#bib.bib18)). Traditional approaches to HOK attack detection have focused
    on signature-based methods, which rely on known patterns of malicious activity,
    and anomaly detection techniques, which aim to identify deviations from normal
    behavior (Jeffrey et al., [2023](#bib.bib12)).
  prefs: []
  type: TYPE_NORMAL
- en: With the increasing sophistication of cyberattacks, these conventional methods
    have faced challenges in keeping pace with the evolving tactics employed by attackers.
    This has led to the exploration of machine learning and artificial intelligence
    (AI) as tools for enhancing detection capabilities. In particular, supervised
    and unsupervised machine learning models have been employed for pattern recognition
    and to learn from historical data, enabling more proactive and dynamic defense
    mechanisms (Alraizza and Algarni, [2023](#bib.bib2)).
  prefs: []
  type: TYPE_NORMAL
- en: Recently, the application of Large Language Models (LLMs) in cybersecurity has
    opened new avenues for research. LLMs, such as OpenAI’s GPT-3 (Brown et al., [2020](#bib.bib4)),
    have demonstrated remarkable capabilities in understanding and generating human-like
    text, which can be leveraged to interpret the contextual information within security
    logs (Boffa et al., [2024](#bib.bib3); Sai et al., [2024](#bib.bib20)). LLMs have
    also been instrumental in automating threat intelligence tasks, such as phishing
    email identification and malware classification based on textual descriptions
    (Hafzullah, [2024](#bib.bib9); Hassanin and Moustafa, [2024](#bib.bib10)). These
    advancements suggest that the integration of LLMs into cybersecurity tools could
    significantly enhance the ability to detect complex threats such as HOK attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the potential of recent LLMs, in relation to HOK detection or related
    intrusion detection, current work focus on custom models that lack wide knowledge
    and are relatively tiny in number of parameters and context length (Lai, [2023](#bib.bib13);
    Ferrag et al., [2024](#bib.bib8)). This is mainly due to the computational resources
    required to train and deploy LLMs at the scale in which such systems operate.
  prefs: []
  type: TYPE_NORMAL
- en: Our work is the first to our knowledge that attempts tapping into the full potential
    of modern LLMs and present a novel methodology that not only harnesses their power
    for detecting HOK attacks but also addresses the practical considerations for
    deployment within an endpoint protection platform. In the next section, we present
    our model architectures and efficient training techniques that maintain high performance
    while reducing resource demands.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our approach to detecting Hands-on-Keyboard (HOK) cyberattacks employs a novel
    integration of Large Language Models (LLMs) with endpoint security data. This
    section outlines the comprehensive methodology we adopted, encompassing data preparation,
    collection, and the application of LLMs for early attack detection.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Data Preparation and Collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The foundation of our methodology lies in the careful preparation and collection
    of endpoint security data. We began by accumulating a vast dataset of endpoint
    logs, which consist of detailed records of the following types of events:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Telemetry—raw events, such as process creation, file operations (create/delete/move),
    registry operations, logon attempts, etc.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security observations—Manual expertise based security events that aggregate
    some telemetry events and represent low fidelity signals of possible malicious
    activity but are not enough to raise an alert without further evidence. These
    observations correlate with many that exist in MITRE ATT&CK framework (MITRE Corporation,
    [[n. d.]](#bib.bib17)), but are highly curated for our purpose. An example of
    such an observation could be multiple failed login attempts from the same user
    during a brief time span.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning (ML) observations—Scores of proprietary ML models aimed to
    detect types of malicious activities obtained during that time frame. These include
    suspicious command lines, registry activity, etc.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The data has undergone a rigorous anonymization process that strips away any
    personally identifiable information (PII) while preserving the essential characteristics
    of the events for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the data was anonymized, we embarked on the process of transforming these
    logs into a more structured and consumable format, which we refer to as ”endpoint
    stories.” These narratives are designed to concisely convey the sequence and context
    of events, facilitating the subsequent application of LLMs. The transformation
    process involves several key steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dcb44c732635eeeb856a7e708a4dac78.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. An example of an endpoint story segment.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evidence Aggregation—aggregate the evidence from the endpoint during a timeframe
    and sort events by the time of occurrence.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering—To reduce the story length, we filter events that, based on expert
    knowledge, do not contribute to HOK classification.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rephrasing—rephrase the evidence to a consistent format starting with user information,
    followed by evidence type and source and terminated by specific evidence details.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deduplication—Deduplicating the evidence by temporal/source logic. To further
    reduce the endpoint story size, similar evidence (e.g., all the process creation
    events triggered by the same parent process) occurring in a single second are
    grouped and formatted as single evidence.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalization—Normalizing evidence content by enumeration. To preserve consistency
    and reduce story size, references of long entities, such as file names, process,
    etc.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For training a classification model, we collect malicious and benign training
    examples. In view of the immense throughput of our EDR solution, the endpoint
    stories are generated when there is an initial and low-confidence indication of
    a possible HOK attacks, such as a single EDR alert. The malicious training examples
    correspond to endpoint stories taken from machines that correspond to HOK incidents
    that have been reviewed and validated by security experts. Benign training examples
    are collected from endpoints for which there was only one EDR alert in the preceding
    days, and this alert was not indicative of an HOK attack. Benign examples are
    not manually reviewed due to volume, thus may have a labeling noise to some small
    degree.
  prefs: []
  type: TYPE_NORMAL
- en: To obtain results indicative of the true performance of the model, we split
    the data into training and test by time. The training set contains 2.7K equally
    balanced examples. Figure [1](#S3.F1 "Figure 1 ‣ 3.1\. Data Preparation and Collection
    ‣ 3\. Methodology ‣ Towards Automatic Hands-on-Keyboard Attack Detection Using
    LLMs in Endpoint Detection and Remediation (EDR) Solutions") includes an example
    of a few lines taken from an endpoint story.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Model Architecture and Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the endpoint stories prepared, we proceeded to the model training phase.
    We utilized a state-of-the-art LLM that was further fine-tuned on our specific
    dataset to ensure high relevance to the cybersecurity domain. The model was trained
    to classify endpoint stories into benign or potential HOK attack categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'To train our models over long endpoint stories we split our text into windows,
    we use a pre-trained LLM to create a per-window embedding and then pass all the
    windows through an additional classification head. We evaluated two approaches
    for the training process: (1) training the window model and the classification
    head in tandem; and (2) training a model for creating per-window embedding and
    separately training a model for classifying a sequence of window embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: When training the windows with the classification head, we use the well-known
    BERT-small model (Devlin et al., [2019](#bib.bib7)), which is smaller and easily
    fits in GPU memory with an entire security log sample served as a single batch
    of $\sim$80 windows. For the classification head, we attach a bidirectional LSTM
    layer of each window CLS token.
  prefs: []
  type: TYPE_NORMAL
- en: For the second approach, we fine-tune the Phi-2 model (Javaheripi et al., [2023](#bib.bib11)),
    which is a general purpose LLM that is still small enough to process multiple
    windows with low latency (2.7B parameters). Since Phi-2 is a generative model,
    we suffix each window with a few tokens designed to extract expressive embedding.
    Specifically, we append ‘[[classification:negative’ or ‘[[classification:positive’
    for each window depending on whether it originates from a clean (negative) or
    an HoK attack (positive) sample. We then take the embedding of the colon (‘:’)
    token from the last layer as a representation of the window. For training the
    classification head, we concatenate the embeddings of all windows and pass them
    as a sequence to a BERT-like model with 4 transformer layers with 10 attention
    heads in each. For comparison purposes, we also describe a classifier that only
    uses the fine-tuned Phi-2 base model and outputs the average probability of predicting
    the ‘positive’ token over all the windows of the story.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. EVALUATION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We evaluate our models over data collected from global production EDR deployments
    labeled as described in the previous sections. Our primary metric for assessing
    a model for HOK attacks detection is True-Positive Rate (TPR, aka, recall) at
    False-Positive Rate (FPR) of 1%. We enforce a low FPR because EDR operates in
    an extremely high volume and false positives translate to a very high cost and
    friction with clients. For completeness, we also include the Area Under the Receiver
    Operating Characteristic Curve (AUC) score, we emphasis it is not appropriate
    for our business needs as it does not take into consideration our focus on precision
    over recall.
  prefs: []
  type: TYPE_NORMAL
- en: As a baseline classification model, we compare our models to LIghtGBM, which
    is a well-known Gradient boosting technique, which does not account for the token
    order in the text. We also test two additional techniques to gain insight on our
    approach. In the first, ”Phi-2 + Avg. ’positive’ token”, we run our fine-tuned
    Phi-2 over each models and take the score of predicting ’positive’ as the next
    token. We then take the average of those scores. With this techniques we effectively
    only learn over windows of endpoint stories. In the second technique we just takes
    the average score of both our BERT-bases and Phi-2-based models.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | AUC | TPR at FPR 1% |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| LightGBM | 0.977 | 0.524 |'
  prefs: []
  type: TYPE_TB
- en: '| BERT + LSTM head | 0.968 | 0.694 |'
  prefs: []
  type: TYPE_TB
- en: '| Phi-2 + Avg. ’positive’ token | 0.929 | 0.463 |'
  prefs: []
  type: TYPE_TB
- en: '| Phi-2 + Transformer-head | 0.971 | 0.725 |'
  prefs: []
  type: TYPE_TB
- en: '| Average of BERT + Phi-2 | 0.979 | 0.754 |'
  prefs: []
  type: TYPE_TB
- en: Table 1\. Model Performance Metrics
  prefs: []
  type: TYPE_NORMAL
- en: The results of the study presented in Table [1](#S4.T1 "Table 1 ‣ 4\. EVALUATION
    ‣ Towards Automatic Hands-on-Keyboard Attack Detection Using LLMs in Endpoint
    Detection and Remediation (EDR) Solutions"). We note that the ”Phi-2 + Avg. ’positive’
    token” method produced reasonable results but it is considerably inferior to other
    methods which suggest that many windows simply do not have enough data for accurate
    prediction. The LightGBM model, while having a high AUC, has a lower TPR at FPR
    1% compared to the other models, indicating that it may not be as effective in
    detecting HOK attacks at high precision. Phi-2 with the transformer is notably
    the best standalone model followed by the BERT + LSTM head model, while both considerably
    outperform LightGBM in our low-FPR regime. Lastly, BERT + Phi-2 average has the
    highest AUC and TPR at FPR 1%. This demonstrates that even a simple combination
    of LLMs can lead to improved performance and suggests that ensemble methods should
    be considered whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our research represents a critical step forward in the detection of Hands-on-Keyboard
    (HOK) cyberattacks. The use of Large Language Models (LLMs) to analyze structured
    narratives, or ”endpoint stories,” has proven to be a promising approach in distinguishing
    between benign and malicious activities within an endpoint protection framework.
    Our experimental results have demonstrated that LLMs can outperform traditional
    detection methods, providing a higher degree of accuracy while maintaining a manageable
    false positive rate.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this study, we have addressed several challenges, including the transformation
    of complex endpoint data into a format amenable to LLM processing, the development
    of an effective training pipeline which allow for long context input. Our research
    has shown that it is possible to leverage the power of advanced machine learning
    techniques to improve cybersecurity defenses significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Looking ahead, there are numerous avenues for future work. Enhancing the interpretability
    of LLM decisions, reducing the resource requirements for model training and inference,
    and further refining the models to adapt to the evolving tactics of cyber adversaries
    are all critical areas for continued research and experimenting with alternative
    techniques for long-context detection.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alraizza and Algarni (2023) Amjad Alraizza and Abdulmohsen Algarni. 2023. Ransomware
    Detection Using Machine Learning: A Survey. *Big Data and Cognitive Computing*
    7, 3 (2023). [https://doi.org/10.3390/bdcc7030143](https://doi.org/10.3390/bdcc7030143)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Boffa et al. (2024) Matteo Boffa, Idilio Drago, Marco Mellia, Luca Vassio,
    Danilo Giordano, Rodolfo Valentim, and Zied Ben Houidi. 2024. LogPrécis: Unleashing
    language models for automated malicious log analysis: Précis: A concise summary
    of essential points, statements, or facts. *Computers & Security* 141 (2024),
    103805.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. Language models are few-shot learners. In *Proceedings of the 34th
    International Conference on Neural Information Processing Systems* (¡conf-loc¿,
    ¡city¿Vancouver¡/city¿, ¡state¿BC¡/state¿, ¡country¿Canada¡/country¿, ¡/conf-loc¿)
    *(NIPS ’20)*. Curran Associates Inc., Red Hook, NY, USA, Article 159, 25 pages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buczak and Guven (2015) Anna L Buczak and Erhan Guven. 2015. A survey of data
    mining and machine learning methods for cyber security intrusion detection. *IEEE
    Communications surveys & tutorials* 18, 2 (2015), 1153–1176.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CrowdStrike (2023) CrowdStrike. 2023. Why You Need AI and Machine Learning to
    Combat Hands-on-Keyboard Attacks. [https://www.crowdstrike.com/blog/why-you-need-ai-and-machine-learning-to-combat-hands-on-keyboard-attacks/](https://www.crowdstrike.com/blog/why-you-need-ai-and-machine-learning-to-combat-hands-on-keyboard-attacks/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding. In *Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies,
    Volume 1 (Long and Short Papers)*, Jill Burstein, Christy Doran, and Thamar Solorio
    (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186.
    [https://doi.org/10.18653/v1/N19-1423](https://doi.org/10.18653/v1/N19-1423)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ferrag et al. (2024) Mohamed Amine Ferrag, Mthandazo Ndhlovu, Norbert Tihanyi,
    Lucas C. Cordeiro, Merouane Debbah, Thierry Lestable, and Narinderjit Singh Thandi.
    2024. Revolutionizing Cyber Threat Detection With Large Language Models: A Privacy-Preserving
    BERT-Based Lightweight Model for IoT/IIoT Devices. *IEEE Access* 12 (2024), 23733–23750.
    [https://doi.org/10.1109/ACCESS.2024.3363469](https://doi.org/10.1109/ACCESS.2024.3363469)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hafzullah (2024) İŞ Hafzullah. 2024. LLM-Driven SAT Impact on Phishing Defense:
    A Cross-Sectional Analysis. In *2024 12th International Symposium on Digital Forensics
    and Security (ISDFS)*. IEEE, 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hassanin and Moustafa (2024) Mohammed Hassanin and Nour Moustafa. 2024. A Comprehensive
    Overview of Large Language Models (LLMs) for Cyber Defences: Opportunities and
    Directions. *arXiv preprint arXiv:2405.14487* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Javaheripi et al. (2023) M. Javaheripi, S. Bubeck, M. Abdin, J. Aneja, S. Bubeck,
    C.C.T. Mendes, W. Chen, A. Del Giorno, R. Eldan, S. Gopi, S. Gunasekar, M. Javaheripi,
    P. Kauffmann, Y.T. Lee, Y. Li, A. Nguyen, G. de Rosa, O. Saarikivi, A. Salim,
    S. Shah, M. Santacroce, H.S. Behl, A.T. Kalai, X. Wang, R. Ward, P. Witte, C.
    Zhang, and Y. Zhang. 2023. Phi-2: The Surprising Power of Small Language Models.
    Microsoft Research Blog. https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jeffrey et al. (2023) Nicholas Jeffrey, Qing Tan, and José R Villar. 2023. A
    review of anomaly detection strategies to detect threats to cyber-physical systems.
    *Electronics* 12, 15 (2023), 3283.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lai (2023) Hsiaofan Lai. 2023. Intrusion Detection Technology Based on Large
    Language Models. In *2023 International Conference on Evolutionary Algorithms
    and Soft Computing Techniques (EASCT)*. 1–5. [https://doi.org/10.1109/EASCT59475.2023.10393509](https://doi.org/10.1109/EASCT59475.2023.10393509)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2023) Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou,
    and Yue Zhang. 2023. Evaluating the logical reasoning ability of chatgpt and gpt-4.
    *arXiv preprint arXiv:2304.03439* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LiveAction (2022) LiveAction. 2022. Hands On Keyboard Attack: Why Detection
    Just Became Critical. [https://www.liveaction.com/resources/blog-post/hands-on-keyboard-attack-why-detection-just-became-critical/](https://www.liveaction.com/resources/blog-post/hands-on-keyboard-attack-why-detection-just-became-critical/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Learn (2022) Microsoft Learn. 2022. What is ransomware? [https://learn.microsoft.com/en-us/security/ransomware/human-operated-ransomware](https://learn.microsoft.com/en-us/security/ransomware/human-operated-ransomware).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MITRE Corporation ([n. d.]) MITRE Corporation. [n. d.]. MITRE ATT&CK. [https://attack.mitre.org](https://attack.mitre.org).
    Accessed: 2024-05-28.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Razaulla et al. (2023) Salwa Razaulla, Claude Fachkha, Christine Markarian,
    Amjad Gawanmeh, Wathiq Mansoor, Benjamin CM Fung, and Chadi Assi. 2023. The age
    of ransomware: A survey on the evolution, taxonomy, and research directions. *IEEE
    Access* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sahani et al. (2023) Nitasha Sahani, Ruoxi Zhu, Jin-Hee Cho, and Chen-Ching
    Liu. 2023. Machine learning-based intrusion detection for smart grid computing:
    A survey. *ACM Transactions on Cyber-Physical Systems* 7, 2 (2023), 1–31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sai et al. (2024) Siva Sai, Utkarsh Yashvardhan, Vinay Chamola, and Biplab
    Sikdar. 2024. Generative ai for cyber security: Analyzing the potential of chatgpt,
    dall-e and other models for enhancing the security space. *IEEE Access* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
