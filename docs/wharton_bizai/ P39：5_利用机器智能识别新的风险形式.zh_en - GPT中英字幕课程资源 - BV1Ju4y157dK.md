# 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P39：5_利用机器智能识别新的风险形式.zh_en - GPT中英字幕课程资源 - BV1Ju4y157dK

 I want to bring your awareness to what are the kinds of issues that can happen when you。



![](img/2b6bb46c8e2b9282e02c4d0ad534ba9c_1.png)

 start using machine learning and AI modules。 So we've talked a lot about customer journey。

 We've talked a lot about all the different things that a machine learning algorithm or。

 AI software can do for you。 But at the same time， I think it's important to understand what are the risks that are。

 appearing as well。 So one example of the risk is understanding where the data is from。

 I'll give you two examples， but I think these examples， of course， you will see is in some。

 sense tip of the iceberg。 These examples come from Amazon。 Again， of course Amazon is a big company。

 There are many other companies which are also involved in some of these examples。

 But I just want to give you an example from Amazon， but you will see how general these。

 examples are。 One example is this idea of Amazon scrapping a secret AI recruiting tool。

 What was the problem here？ The problem here was that Amazon， like many of the companies。

 perhaps have a lot of people， who want to， in some sense， become employees at Amazon。 Well。

 they had a lot of people submitting their resumes。 And in this case。

 it was about software developers， if I remember correctly。

 And so many people want to become software developers at Amazon。 So what did they want to do？

 They wanted to speed up that process。 So how did they do it？ They basically said。

 wouldn't it be great if you could have an AI tool that goes through。

 some of these resumes and tries to figure out which resumes perhaps have the highest。

 chance of becoming successful， which people？ And what did they benchmark against？

 They benchmarked against their current employees and their own resumes that they had。

 And then they started looking at how best to predict。 What was the issue？

 The issue was that the historical data that they had， which is the data of their current， employees。

 were largely male software developers。 So what did they end up doing？ Unfortunately。

 the AI tool ended up biasing against women。 So I can notice it's not the fault of the tool per se。

 It's the fault of the data。 So thinking very carefully about where the data is coming from。

 how generalizable is， that data， there are many， many other issues of that kind。

 Let me give you one more example。 And this is the example of Amazon and the racist algorithms that you see here。

 Again， obviously very controversial。 So let's discuss this example。

 And then we'll also talk about the controversy。 Now in this case。

 Amazon was thinking about expanding their Amazon Prime service that， they were offering in the US。

 So this example and this issue was especially in the Boston area。

 Now what happened there was the following。 They were looking at where to offer Amazon Prime。

 They were looking at different zip codes。 And then they basically did the following calculation。

 So let's offer it in certain zip codes where there's a chance to become more profitable。

 which makes sense。 Once they started looking at that， now those of us who are from Boston。

 they might recognize， this。 There's an area called Roxbury in Boston。

 which is a slightly lower income area。 So this ended up becoming what they call the Amazon problem。

 which is like a donut， which， is in all areas around Roxbury。

 they were offering Amazon Prime but for Roxbury。 But you can imagine this was a very controversial。

 On the other hand， you can also imagine that people in Roxbury who did not have many stores。

 around them， those will actually be the people who benefit the most from Amazon Prime。

 Now why did this happen？ Because again， they were looking at data but they didn't follow through to kind of see。

 what those algorithms are doing。 So first issue I wanted to be aware of as you start using your customer data to predict。

 the journey， shorten the journey， whatever the case might be。

 The first thing about how generalizable that data is is touching all different customers。

 that you have and starting to think very carefully about how representative the data is。

 The next issue is around data sets and privacy。 First customer privacy is a huge issue。

 So in Europe， you have the GDPR in California， you have the California Privacy Act。 There are many。

 many other such privacy acts that will be coming forth。

 And I would advise you as you start thinking about using your customer data to then perhaps。

 target customers， meet the journey， the customizable， personalizing the journey， whatever the case。

 might be。 Start thinking very carefully about a and showing customer privacy and what can you do。

 to make sure that you don't infringe their privacy。 Let me give you an example。

 This example comes from this company called Strava。

 Now Strava is a company that in some sense was building a global heat map so to speak。

 That's what they talked about。 It's a big social network for people who are very active。

 If you're on Strava， you can put it up， you can say， "Well， I went ahead and jogged， five miles。

" and so on and so forth。 So they had in some sense noted the fact that they are building a global heat map of all。

 the people who are very active。 What happened？ Well。

 their own data was anonymized and they made very sure that their data set perhaps。

 is not in some sense identifiable。 But what did some people do？

 They ended up imposing a Google map on top of that。 What ended up happening？ Well， in some sense。

 they were able to find people， I believe in Afghanistan and so on。

 who were the US Army that was stationed there。 So clearly， that's what this headline talks about。

 the Strava heat map and the end of， secrets。 What is the big idea here？

 The big idea here is your own data set might be anonymized， but increasingly， there are， many。

 many people out there who are putting data sets together。

 And that's something to be very careful about， which is it's not just your data sets that。

 should ensure privacy， but think very carefully about how data sets coming together might。

 end up taking care of privacy。 A third issue is how are you using machine learning。

 This relates to the idea that we had brought up earlier about data itself， but it's more。

 than just the representativeness of data。 It's the idea of how often your data is getting updated。

 which is， you know， are you using， data from two years ago， a year ago。

 look at the customer journey， look at how frequently， customers are buying your products。

 What's the journey like？ Which parts of the customer journey are sticky？ Which parts are changing？

 Because of course， as new technology comes in， as new competitors come in， all of that。

 journey changes。 So thinking carefully about how you're using your data， you're using your models。

 and how， often is the data getting updated in terms of how the journey is changing is critical。

 And of course， there's no data for free。 What that means is。

 I think when you start thinking about using new technology， be it， machine learning， be it AI。

 whatever the case might be， you need to have a proactive approach。

 perhaps doing a little bit of testing and learning， collect some data， cue new models， see how。

 well that new data that you've collected， how well your models are predicting that。



![](img/2b6bb46c8e2b9282e02c4d0ad534ba9c_3.png)

 So the more you do that， the more you can be agile in terms of understanding how your。

 machine learning in AI software is quote unquote getting updated in terms of new data coming。

 in and how those older models perhaps need to be tweaked as well。 Thank you。 [BLANK_AUDIO]。



![](img/2b6bb46c8e2b9282e02c4d0ad534ba9c_5.png)