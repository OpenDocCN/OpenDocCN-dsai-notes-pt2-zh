- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P92：29_解释性重要的示例.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Explainability or interpretability as it's sometimes called can be important
    in a variety。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_1.png)'
  prefs: []
  type: TYPE_IMG
- en: of different contexts。 Sometimes if you're just trying to make a prediction
    it may not matter so much but a。
  prefs: []
  type: TYPE_NORMAL
- en: lot of business contexts being able to understand why the algorithm comes to
    the decision it。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_3.png)'
  prefs: []
  type: TYPE_IMG
- en: does really matter。 So consider for example a medical context where you have
    a deep learning system that's。
  prefs: []
  type: TYPE_NORMAL
- en: recommending whether a patient should get a treatment or not。
  prefs: []
  type: TYPE_NORMAL
- en: When you have a highly specialized doctor who disagrees with that assessment
    it's not。
  prefs: []
  type: TYPE_NORMAL
- en: very easy to resolve if the system is just saying something different。
  prefs: []
  type: TYPE_NORMAL
- en: The doctor is going to want to know exactly how it came to that decision and
    what is being。
  prefs: []
  type: TYPE_NORMAL
- en: incorporated into that decision making flow。 And so that's one example where
    interpretability can be very important。
  prefs: []
  type: TYPE_NORMAL
- en: It turns out in the HR context interpretability is also particularly important
    because there。
  prefs: []
  type: TYPE_NORMAL
- en: are a number of guidelines and legal protections in HR that require HR organizations
    or the。
  prefs: []
  type: TYPE_NORMAL
- en: HR side of organizations to be able to cleanly and clearly document how they
    come to decisions。
  prefs: []
  type: TYPE_NORMAL
- en: So for example there are EEOC Equal Employment Opportunity Commission rules
    on the types。
  prefs: []
  type: TYPE_NORMAL
- en: of employees that you hire on being able to document various decisions that
    you make。
  prefs: []
  type: TYPE_NORMAL
- en: And the notion that you're going to just throw data into a deep learning system
    have it make。
  prefs: []
  type: TYPE_NORMAL
- en: a prediction that you're then going to use isn't that sustainable in a context
    like this where。
  prefs: []
  type: TYPE_NORMAL
- en: you really want to have very clean documentation of why you came to a decision
    where you want。
  prefs: []
  type: TYPE_NORMAL
- en: to make sure that you're following guidelines related to employment protection
    law that。
  prefs: []
  type: TYPE_NORMAL
- en: have a long historical basis。 And so these kinds of restrictions make it very
    hard to use systems that are not interpretable。
  prefs: []
  type: TYPE_NORMAL
- en: If you can't step back and say why is this decision being made or why is it
    making this。
  prefs: []
  type: TYPE_NORMAL
- en: decision or if you can't step back and adjust the system in a way that can allow
    you to meet。
  prefs: []
  type: TYPE_NORMAL
- en: the guidelines you need to meet this makes things much more difficult。
  prefs: []
  type: TYPE_NORMAL
- en: This is an example where interpretability matters and this is why an HR in particular。
  prefs: []
  type: TYPE_NORMAL
- en: interpretability or explainability tends to make a big difference。
  prefs: []
  type: TYPE_NORMAL
- en: Another place where it's having a big impact in the HR domain is related to
    new data privacy。
  prefs: []
  type: TYPE_NORMAL
- en: laws that are emerging in a number of different areas。
  prefs: []
  type: TYPE_NORMAL
- en: So consider the general data protection regulation notice the GDPR in the EU
    the European Union。
  prefs: []
  type: TYPE_NORMAL
- en: There's a similar California law CCPA as well。 And these kinds of laws place
    restrictions on employer's ability to use data provided。
  prefs: []
  type: TYPE_NORMAL
- en: by potential applicants。 And so when it says that they some of these laws mandate
    that when you do use automated。
  prefs: []
  type: TYPE_NORMAL
- en: decision making you need to be able to explain how you came to a decision you
    need to be。
  prefs: []
  type: TYPE_NORMAL
- en: able to provide the logic that was used when coming or arriving at a final decision。
  prefs: []
  type: TYPE_NORMAL
- en: And so in the absence of interpretable systems it makes it very difficult to
    adhere to the。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_5.png)'
  prefs: []
  type: TYPE_IMG
- en: guidelines laid out by these laws。 So explainability it turns out is a key issue
    when thinking about HR tech adoption。
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately there's a lot of resources being put into this question。
  prefs: []
  type: TYPE_NORMAL
- en: A lot of companies especially big tech companies are increasingly invested in
    this issue。
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of new tools that are emerging that provide AI support at
    a more interpretable。
  prefs: []
  type: TYPE_NORMAL
- en: level。 Government through various agencies are also invested in providing resources
    to build more。
  prefs: []
  type: TYPE_NORMAL
- en: explainable AI systems for different industries。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_7.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next video we will talk about some of the challenges some of the trade-offs
    that。
  prefs: []
  type: TYPE_NORMAL
- en: arise when making systems more explainable。 [BLANK_AUDIO]。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_9.png)'
  prefs: []
  type: TYPE_IMG
