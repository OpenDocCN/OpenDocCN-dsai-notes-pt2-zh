# 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P110：9_自动机器学习的傲慢经济学.zh_en - GPT中英字幕课程资源 - BV1Ju4y157dK

 One of the conversations related to the rollout of tools like AutoML that make it extremely。



![](img/ad1eff9b3d7a0f72db833a59a818e913_1.png)

 easy to develop AI applications for almost anyone who has access to a strong data set。

 is the question of whether AI can in a sense be too easy。

 What that means is that issues related to things like bias in AI or potential misuse。

 in AI may be amplified with users who have little or no understanding of how algorithms。



![](img/ad1eff9b3d7a0f72db833a59a818e913_3.png)

 are built。 The absence of tools like these， anyone who builds an algorithm has to get somewhat into。

 the internals to understand the data where the data issues might arise and where prediction。

 engines might be hitting problems related to that data or where they may be producing。

 results that are biased or otherwise misleading。 With AutoML it happens so easily the question then arises are we able to pay close enough。

 attention from a user perspective to what the algorithm is doing before deploying it。

 to really do a good job of governance and making sure that we're not putting into production。

 algorithms that are causing social harm。 There are a number of concerns arising about AutoML hubris I've heard it called。

 the， notion that a lack of understanding about the inner workings will lead to problems especially。

 if we develop a type of arrogance around AI that emerges around AI being particularly。



![](img/ad1eff9b3d7a0f72db833a59a818e913_5.png)

 easy to deploy or to put into production。 This is likely to fuel a rapid increase into people who can grapple with the implications。

 of algorithmic decisions。 There might be more demand safer AI ethicists or people who really understand how the decision。



![](img/ad1eff9b3d7a0f72db833a59a818e913_7.png)

 was arrived at and can think about what that means from an algorithmic perspective and what。

 some of the pitfalls and danger points might be。 Thank you。 [BLANK_AUDIO]。

