- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P12：11_具体的机器学习方法深度潜水.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P12：11_具体的机器学习方法深度潜水.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
- en: In this lecture， we're going to deep dive into some machine learning models
    and look at how exactly they work。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次讲座中，我们将深入探讨一些机器学习模型，并看看它们究竟是如何工作的。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_1.png)'
- en: Now， one warning I'd like to offer is that this lecture is perhaps going to
    be more technical than probably every other lecture in this course。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我想提醒的是，这次讲座可能比本课程中的其他讲座更具技术性。
- en: For those of you who don't have an experience or background in data analysis。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些没有数据分析经验或背景的人。
- en: you might find this lecture harder to understand than some of the other lectures。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会发现这次讲座比其他讲座更难理解。
- en: I think it's okay if you don't understand everything I describe in this lecture。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为如果你不理解我在这次讲座中描述的所有内容也是可以的。
- en: high level understanding or even a qualitative sense of how these machine learning
    models work is perhaps sufficient。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些机器学习模型的高水平理解或甚至定性理解或许足够。
- en: and will nonetheless be very useful for you as you interact with data scientists。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 并且在你与数据科学家互动时仍然会非常有用。
- en: And if not anything else， I hope you get that out of this lecture。 And of course。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有其他，我希望你能从这次讲座中得到这个。当然。
- en: if you're able to understand the details of these models。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能理解这些模型的细节。
- en: then it'll be even more useful in your work when you interact with data scientists。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这样在你与数据科学家互动时，它会对你的工作更有用。
- en: So I mentioned previously that at the end of the day。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我之前提到，归根结底。
- en: given any set of input variables x and an outcome variable y。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 给定任何一组输入变量x和一个结果变量y。
- en: that the machine learning model is trying to predict。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型试图预测的。
- en: the job of a machine learning algorithm is to figure out some transformation
    or some function f that takes the input x and transforms it and makes a prediction
    of y。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法的工作是找出某种变换或某个函数f，输入x并进行变换，以预测y。
- en: There are many different types of algorithms and each of them corresponds to
    a different choice of that function f。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同类型的算法，每种算法对应于该函数f的不同选择。
- en: So in this discussion， I'll look at a few of these choices。 I'll begin with
    logistic regression。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这次讨论中，我会看一下其中一些选择。我将从逻辑回归开始。
- en: which is one of the simplest classification models。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最简单的分类模型之一。
- en: These models are useful for classifying or prediction problems where the outcome
    can take only a few values。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型对于分类或预测问题是有用的，其中结果只能取少数几个值。
- en: For example， we're trying to predict whether an email is spam or not。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们试图预测一封电子邮件是否为垃圾邮件。
- en: So that's a yes or no decision。 Or we're trying to predict whether a consumer
    will click on an ad or not。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是一个是或否的决定。或者我们试图预测消费者是否会点击广告。
- en: That's again a binary decision。 Often logistic regression is built for binary
    models。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是一个二元决策。通常，逻辑回归是为二元模型构建的。
- en: but it is straightforward to extend logistic regression for situations where
    the outcome can take multiple but a finite small set of values。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但将逻辑回归扩展到结果可以取多个有限小值的情况是相对简单的。
- en: for example， four or five values。 Now logistic regression is one of the most
    useful and popular techniques used in data science and in statistics and is a
    very successful and effective approach for classification algorithms。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，四或五个值。现在逻辑回归是数据科学和统计中最有用和最流行的技术之一，是分类算法非常成功有效的方法。
- en: Now one question that often arises when someone uses logistic regression is
    whether it is really machine learning or not。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用逻辑回归时经常出现的一个问题是，它是否真的算作机器学习。
- en: especially given that logistic regression actually has its origins in the 19th
    century。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是考虑到逻辑回归实际上起源于19世纪。
- en: And has been used in the field of statistics for a long period of time。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 并且在统计学领域已经使用了很长一段时间。
- en: It is indeed true that logistic regression has a nice long history and in fact
    predates some of the modern developments in machine learning。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归确实有着悠久的历史，实际上早于一些现代机器学习的发展。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_3.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_3.png)'
- en: But I would argue that that distinction doesn't matter。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但我认为这个区分并不重要。
- en: It is a very important technique that should be in the arsenal of all data scientists。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一项非常重要的技术，应该在所有数据科学家的工具箱中。
- en: Now essentially what a logistic regression is trying to do is given a set of
    input variables x1， x2。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，逻辑回归试图做的是给定一组输入变量 x1，x2。
- en: x3 and so on。 It's trying to predict the probability of a given outcome。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: x3 等等。它试图预测给定结果的概率。
- en: Now in a binary prediction problem where there's only two possible outcomes
    that is whether an email is spam or not or whether a credit card transaction is
    fraudulent or not。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在一个二元预测问题中，只有两个可能的结果，即邮件是否是垃圾邮件，或者信用卡交易是否欺诈。
- en: then the logistic regression boils down to the function you see here where the
    log of the probability that an email is spam divided by 1 minus the probability
    of email being spam is a linear function of the input variables。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后逻辑回归归结为你在这里看到的函数，其中邮件是垃圾邮件的概率的对数除以1减去邮件是垃圾邮件的概率是输入变量的线性函数。
- en: And essentially the logit model or the logistic regression model takes the inputs
    x1， x2。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，logit模型或逻辑回归模型接受输入 x1，x2。
- en: x3 and so on and computes the probability of an event。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: x3 等等，并计算事件的概率。
- en: For example the probability of spam or the probability that a transaction is
    fraudulent。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，垃圾邮件的概率或一笔交易是欺诈的概率。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_5.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_5.png)'
- en: Now one can intuitively think about a logistic regression as something that's
    trying to create a best fit plane or a line that is separating all our data。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以直观地将逻辑回归视为试图创建一个最佳拟合平面或线，从而分离我们所有的数据。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_7.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_7.png)'
- en: So for example if you look at this chart here we have data about customers。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你看看这张图表，我们有关于客户的数据。
- en: we have their age and we have their income。 Both of these are mean centered
    meaning that an age of zero indicates that this person has an age which is equal
    to the mean in the population。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有他们的年龄和收入。这两者都是均值中心化的，意味着年龄为零表示这个人的年龄等于人群的均值。
- en: Any values of age greater than the mean have a positive value here。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 任何大于均值的年龄值在这里都是正值。
- en: Any value of age that is less than the mean has negative value on this graph。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 任何低于均值的年龄值在这张图上都有负值。
- en: Now both income and age are mean centered here and we have this data and we
    are trying to predict whether a customer will purchase a product or not。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在收入和年龄都在这里进行均值中心化，我们有这些数据，并且我们正在尝试预测客户是否会购买产品。
- en: The red data points are essentially data corresponding to users who have purchased
    in the past。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 红色数据点基本上对应的是过去已经购买的用户。
- en: The blue data points correspond to users who have not purchased in the past。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝色数据点对应的是过去没有购买的用户。
- en: Logistic regression essentially is trying to figure out a line that partitions
    the data into two regions。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归基本上是在试图找出一条将数据划分为两个区域的线。
- en: One corresponding to customers who are likely to buy and another corresponding
    to customers who are likely to not buy。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一种对应于可能购买的客户，另一种对应于可能不购买的客户。
- en: In essentially it tries many different ways of partitioning this plane。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，它尝试了许多不同的方式来划分这个平面。
- en: many different ways of placing a line on this graph and finds the best possible
    such line。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这张图上有很多不同的方式来放置一条线，并找到最佳可能的线。
- en: That's the intuition behind what a logistic regression is trying to do。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是逻辑回归试图做的直觉。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_9.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_9.png)'
- en: Another technique that is commonly used is a technique known as decision trees。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常用的技术是决策树技术。
- en: Decision trees are very easy to interpret models and essentially what they do
    is they take the data and they create a tree that helps to partition our data
    into different groups。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是非常易于解释的模型，基本上它们的作用是利用数据创建一个树，帮助将数据划分为不同的组。
- en: For example， suppose we are trying to predict whether it's going to rain today
    or not and we have data on temperature。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们在试图预测今天是否会下雨，并且我们有温度的数据。
- en: we have data on wind speed and we also have data on the air pressure。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有风速的数据，也有气压的数据。
- en: Now we might use this past data where we have the input data meaning temperature
    wind and pressure on any given day and we have the output data meaning whether
    it's rain that day or not。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可能会使用过去的数据，其中输入数据指的是某一天的温度、风速和气压，输出数据指的是那天是否下雨。
- en: Decision tree looks at the data and creates a tree that is trying to predict
    whether it's going to rain or not。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树查看数据，并创建一棵试图预测是否会下雨的树。
- en: In this tree you observe that the first step in this decision is to ask whether
    the temperature is greater than 70 degrees Fahrenheit or not。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这棵树中，你会注意到这个决策的第一步是问温度是否大于70华氏度。
- en: If the answer is yes， then next the decision tree looks at what is the wind
    speed and then based on the wind speed it proceeds。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果答案是肯定的，那么接下来决策树会查看风速，然后根据风速继续进行。
- en: But if the temperature is not greater than 70 degrees Fahrenheit。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果温度不大于70华氏度。
- en: it again looks at the wind speed but it looks at a different question whether
    the wind speed is greater or less than 4。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它再次查看风速，但它关注的是一个不同的问题，即风速是大于还是小于4。
- en: 5 miles per hour。 And it proceeds in this manner until it eventually makes a
    prediction of whether it will rain or not。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 5英里每小时。它以这种方式继续进行，直到最终做出是否会下雨的预测。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_11.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_11.png)'
- en: Of course， a natural question to ask here is how exactly did this model decide
    which variables to split on at each branch and also which value to use at each
    branch。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这里自然会问，这个模型到底是如何决定在每个分支上选择哪些变量进行分裂，以及使用哪些值的。
- en: For example， why did the tree decide in the very first branch to ask whether
    the temperature is greater than 70 degrees？
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，为什么树在第一分支决定问温度是否大于70华氏度？
- en: Why not 60 degrees？ Now the mathematical answer to that question is that the
    decision tree selects the variables and the splits so as to minimize what's known
    as the entropy of the data set。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不是60华氏度？这个问题的数学答案是决策树选择变量和分裂，以最小化数据集的熵。
- en: In very simple terms， the idea is you want to choose a variable or a way to
    split your tree so that you have the maximum predictive power。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 用非常简单的术语来说，想法是选择一个变量或分裂树的方法，以便你拥有最大的预测能力。
- en: In the first branch of the tree， the decision tree will consider all of our
    variables。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在树的第一分支中，决策树将考虑我们所有的变量。
- en: meaning it will consider air pressure， it will consider wind speed and it will
    consider the temperature as well。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着它会考虑气压、风速和温度。
- en: It will try and figure out which one is most predictive of rain and it chooses
    that as the first branch of the tree。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 它会试图找出哪个因素对下雨的预测最有效，并将其作为树的第一分支。
- en: It continues in this manner and at each step it asks what is the way to partition
    our data so that we can best predict the outcome。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 它以这种方式继续进行，每一步都在问如何划分数据，以便我们可以最好地预测结果。
- en: And this is how decision trees work and they actually work quite well in practice。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是决策树的工作原理，并且它们在实践中实际上效果很好。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_13.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_13.png)'
- en: Another machine learning technique that is commonly used is random forest。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常用的机器学习技术是随机森林。
- en: A random forest is an example of what's called an ensemble algorithm。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是所谓的集成算法的一个例子。
- en: These are algorithms that combine multiple other algorithms to make their predictions。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法结合了多个其他算法，以进行预测。
- en: And a random forest combines multiple decision trees to make its predictions。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林将多个决策树结合在一起，以做出预测。
- en: Random forests are actually quite effective in practice and therefore they're
    also quite popular among machine learning and data scientists。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林在实践中实际上非常有效，因此在机器学习和数据科学家中也很受欢迎。
- en: The basic idea in machine learning is to take any data set and to randomly partition
    it into a bunch of smaller sub data sets。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的基本思想是将任何数据集随机划分为一堆更小的子数据集。
- en: For each subset of the data you might train a decision tree that is trying to
    make the best possible prediction given the subset of data available。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据的每个子集，你可能会训练一棵决策树，试图在可用数据的子集上做出最佳预测。
- en: And now once you have multiple decision trees each trying to make the best possible
    prediction given the sub sample or the subset of data that is available to each
    decision tree。
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一旦你有多棵决策树，每棵都在试图根据可用的子样本或数据子集做出最佳预测。
- en: Then we ultimately combine the predictions of all of these decision trees and
    the combined prediction becomes the prediction of the random forest。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们最终结合所有这些决策树的预测，结合的预测成为随机森林的预测。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_15.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_15.png)'
- en: So it's called a random forest because it combines multiple decision trees。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因此称为随机森林，因为它结合了多个决策树。
- en: So again let's consider an example here。 In this example we have a very large
    data set which consists of many features or many input variables。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们再考虑一个例子。在这个例子中，我们有一个非常大的数据集，包含许多特征或输入变量。
- en: Now a random forest algorithm might break up that data set into multiple subsamples。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，随机森林算法可能会将数据集分成多个子样本。
- en: Each subsample might have a different set of features。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 每个子样本可能具有不同的特征集。
- en: So the first decision tree is built using the features available in that subsample。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 所以第一个决策树是基于该子样本中的可用特征构建的。
- en: The second decision tree is built using the data available in that subsample
    and similarly a large number of decision trees are made。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 第二棵决策树是基于该子样本中可用的数据构建的，类似地，生成了大量决策树。
- en: Each decision tree tries to make a prediction。 For example each decision tree
    might predict whether a given credit card transaction is fraudulent or not。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 每棵决策树尝试做出预测。例如，每棵决策树可能会预测给定的信用卡交易是否是欺诈。
- en: The random forest takes the prediction of all of these decision trees combines
    them。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林结合了所有这些决策树的预测。
- en: For example by saying it's going to use the majority votes or the most popular
    prediction and choose that as the prediction of the forest。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可以通过使用多数票或最受欢迎的预测来选择作为森林的预测。
- en: And that's how random forest work。 Now what's interesting to note here is that
    each of the decision trees within a random forest actually use a subset of the
    data。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是随机森林的工作原理。值得注意的是，随机森林中的每棵决策树实际上都使用数据的一个子集。
- en: And therefore each decision tree is not as good as a decision tree that is built
    with a complete data set。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每棵决策树不如基于完整数据集构建的决策树那么优秀。
- en: But when you combine multiple decision trees as part of a random forest together
    they tend to perform in practice better than an individual decision tree built
    on the full data set。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 但当你将多个决策树作为随机森林的一部分结合在一起时，它们的表现通常在实践中优于在完整数据集上构建的单棵决策树。
- en: In some ways this is like the wisdom of crowds or like prediction markets。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在某种程度上，这就像群众智慧或预测市场。
- en: The idea behind prediction markets or behind the wisdom of crowd is that if
    you take predictions made by a bunch of lay people and you combine them then the
    combined prediction of the crowd sometimes equals and sometimes might even beat
    the prediction of an expert。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 预测市场或群众智慧的背后理念是，如果你结合一群外行人所做的预测，那么群体的结合预测有时会等于，甚至可能超过专家的预测。
- en: It is really interesting that a bunch of lay people together can beat the prediction
    of an expert even though individually each of these people cannot beat the expert。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 非常有趣的是，一群外行人加在一起可以超越专家的预测，尽管这些人单独来看无法超越专家。
- en: This is because each lay person has different information。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为每个外行人拥有不同的信息。
- en: has different decision making criteria and when we combine them we start to
    get something that looks like an expert or like true intelligence。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 具有不同的决策标准，当我们将它们结合时，我们开始得到一些看起来像专家或真正智能的东西。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_17.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_17.png)'
- en: A random forest is similar where it has multiple decision trees each of which
    has access to partial data and makes decisions based on the data available to
    each。
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林类似于拥有多个决策树，每棵树都可以访问部分数据，并根据每棵树可用的数据做出决策。
- en: Each of which is not a very good prediction model but when you combine these
    models you get a high performing random forest。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 每个决策树都不是一个很好的预测模型，但当你将这些模型结合起来时，你会得到一个高效的随机森林。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_19.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_19.png)'
- en: And that is partly why random forest perform well and are used quite frequently
    in practice。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分原因解释了为什么随机森林表现良好，并在实践中被广泛使用。
- en: Next let's talk about neural networks which is another advanced machine learning
    technique。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们来谈谈神经网络，这是一种先进的机器学习技术。
- en: Neural networks are loosely inspired by biological neurons。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络在某种程度上受到生物神经元的启发。
- en: Now neurons in our brains take inputs from other neurons they apply some transformations
    to those signals and then they pass on a new signal to other neurons they are
    connected to。
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们大脑中的神经元从其他神经元接收输入，对这些信号进行一些转换，然后将新的信号传递给与之连接的其他神经元。
- en: Similarly a digital neuron might take inputs from other neurons。
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，一个数字神经元可能从其他神经元接收输入。
- en: It takes these inputs and applies some transformations to these inputs。
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 它接收这些输入并对其进行一些转换。
- en: So in this example on this slide the inputs are values x1， x2， x3 all the way
    to xn。
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这个幻灯片的例子中，输入是值x1，x2，x3，一直到xn。
- en: Each of these inputs has a weight applied to it so you have w1， x1， w2， x2，
    w3， x3 and so on。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 每个输入都有一个权重应用于它，所以你有w1，x1，w2，x2，w3，x3，等等。
- en: And finally a transformation f is applied and a new signal or a new value is
    created and that is the output of the neuron。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后应用一个变换f，生成一个新信号或新值，这就是神经元的输出。
- en: Neural nets essentially consist of many of these neurons that are interconnected
    with each other in the form of a network。
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络本质上由许多相互连接的神经元组成，形成一个网络。
- en: Deep neural nets are a specific kind of neural net in which the neurons are
    organized in the form of several layers。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络是一种特定类型的神经网络，其中神经元按多层的形式组织。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_21.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_21.png)'
- en: Let's consider an example。 Suppose one is trying to use a neural network specifically
    a deep neural network to try and do face recognition。
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个例子。假设一个人试图使用神经网络，特别是深度神经网络，进行面部识别。
- en: The input to this neural network might essentially consist of a set of neurons
    that correspond to the pixel values of the different pixels in this image。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个神经网络的输入可能基本上由一组神经元组成，这些神经元对应于该图像中不同像素的像素值。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_23.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_23.png)'
- en: '![](img/abe8409dd88ef580f00a918d2de80643_24.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_24.png)'
- en: If it's a black and white image then each neuron might correspond to the value
    of the pixel in that image。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是黑白图像，则每个神经元可能对应于该图像中像素的值。
- en: If it's a color image then you might have RGB or red green blue values associated
    with that pixel and neurons might capture the values of these pixels。
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是彩色图像，则可能与该像素相关联的是RGB或红绿蓝值，神经元可能捕捉这些像素的值。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_26.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_26.png)'
- en: The final layer of this deep neural network essentially has the outputs that
    we want from the neural network。
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个深度神经网络的最终层基本上具有我们希望从神经网络中获得的输出。
- en: For example， suppose we are trying to identify people's faces then the final
    layer might have the actual names of the people we are trying to identify。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们试图识别人的面孔，那么最终层可能有我们试图识别的人的实际名字。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_28.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_28.png)'
- en: In this image we have just three neurons in the final layer and so let's assume
    we are trying to identify three specific people in our face recognition task。
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这张图中，我们在最终层只有三个神经元，所以我们假设我们正在面部识别任务中识别三个人。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_30.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_30.png)'
- en: In between the input layer and the output layer are a series of hidden layers。
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入层和输出层之间是一系列隐藏层。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_32.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_32.png)'
- en: Now in a biological neuron when you have certain combinations of neurons firing
    then it causes certain other neurons that are connected to them to also fire。
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在生物神经元中，当某些神经元组合激发时，会导致与其连接的某些其他神经元也激发。
- en: Similarly in a neural network based on the value of neurons in one layer certain
    neurons in the next layer get activated。
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在神经网络中，基于一层神经元的值，下一层的某些神经元会被激活。
- en: So based on the values of the pixel in the input image some neurons in the input
    layer get activated。
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基于输入图像中像素的值，输入层中的某些神经元被激活。
- en: Now based on the pattern of neurons activated in the input layer some very specific
    neurons in the very next layer which is a hidden layer gets activated。
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，基于输入层中激活的神经元模式，紧接着的隐藏层中一些非常特定的神经元被激活。
- en: In turn based on the neurons that are activated in hidden layer one certain
    specific neurons in the next layer get activated。
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 反过来，基于在隐藏层一中激活的神经元，下一层中的某些特定神经元被激活。
- en: And this proceeds in a certain manner until the penultimate layer has certain
    neurons that are activated。
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程以某种方式进行，直到倒数第二层激活了某些神经元。
- en: The hope is that through these series of activations we are capturing certain
    features of people's faces。
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 希望通过这些激活系列，我们能够捕捉到人脸的某些特征。
- en: So for example in the penultimate layer if the shape of a person's face is oval
    a certain layer might be activated。
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在倒数第二层，如果一个人的脸形状是椭圆形，则可能会激活某一层。
- en: If the shape of their face is more round then a different neuron might be activated。
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果他们的脸形状更圆，则可能会激活不同的神经元。
- en: If the shape of their eye is like an almond then certain layers might be activated。
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果他们的眼睛形状像杏仁，则可能会激活某些层。
- en: If the color of their eyes are a certain way then certain neurons are activated。
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果他们眼睛的颜色是某种方式，则会激活某些神经元。
- en: Based on the combination of neurons that are activated then we can recognize
    the person's face。
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 基于激活的神经元组合，我们可以识别出这个人的脸。
- en: That is the idea behind a neural network。 Now essentially the hope is that this
    pattern of neuron activations captures certain aspects of people's faces。
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是神经网络背后的思想。现在，期望是这种神经元激活模式捕捉到人脸的某些特征。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_34.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_34.png)'
- en: and ultimately based on the pattern of neurons that are activated we make a
    prediction which is who is exactly in a given image。
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，基于激活的神经元模式，我们做出预测，即在给定图像中到底是谁。
- en: Now neural networks have become very successful in recent years。
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，神经网络已经变得非常成功。
- en: In many machine learning competitions online with large datasets neural network
    actually ends up performing very well。
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多在线机器学习竞赛中，使用大型数据集的神经网络实际上表现得非常好。
- en: And this is especially true when the input data consists of images or audio
    or video in other words unstructured data。
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入数据由图像、音频或视频等非结构化数据组成时，这一点尤其真实。
- en: Now if you look at why neural networks are so successful as we looked at the
    structure of a neural network we saw that it has many layers。
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们看看神经网络为何如此成功，观察其结构时，我们会发现它有许多层。
- en: Within a given layer there are so many different parameters for example the
    weights assigned to all the different signals that are coming in from a previous
    layer。
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定的一层内，有很多不同的参数，例如从前一层输入的所有不同信号所分配的权重。
- en: the functional form or the transformation。 So there is indeed many parameters
    that allows us to build very complex models so that given any input x that transformation
    f of x can be quite complex。
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 功能形式或转换。确实存在许多参数，使我们能够构建非常复杂的模型，以便对于任何输入 x，转换 f(x) 可以相当复杂。
- en: Also there have been lots of recent advances in computational power specialized
    processors known as GPUs have been developed。
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，最近在计算能力方面取得了很多进展，专用处理器称为 GPU 已经被开发出来。
- en: There are specialized algorithms that have been developed which allows neural
    networks to have more and more layers and allows us to build complex models。
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 已经开发出专门的算法，使神经网络能够拥有越来越多的层，并允许我们构建复杂的模型。
- en: and yet estimate these models quite rapidly。
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些模型的估计可以非常迅速。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_36.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_36.png)'
- en: Now even though neural networks come with a lot of horsepower and flexibility
    and high predictive performance。
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管神经网络具有强大的能力、灵活性和高预测性能。
- en: the flip side is that neural networks can be very hard to interpret and understand。
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，神经网络的解释和理解可能非常困难。
- en: So for example we might know the input layers we might know the output layers
    but the middle layers are hard for us to interpret。
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可能知道输入层，也可能知道输出层，但中间层对我们来说很难解释。
- en: The face recognition task I mentioned the hope is that the middle layers are
    capturing ideas such as the shape of the face or the shape of the eye。
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我提到的人脸识别任务，期望中间层捕捉到的概念如脸的形状或眼睛的形状。
- en: In practice that's not always the case。 So looking at the previous layers will
    not allow us to understand why the neural network made a certain prediction。
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，情况并非总是如此。因此，查看前面的层并不能让我们理解神经网络为何做出某个特定预测。
- en: And thus even though you have very accurate models you have models that are
    not highly understandable。
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，即使你拥有非常准确的模型，这些模型的可理解性也不高。
- en: There's a lot of work going on these days in computer science to try and build
    models that are more interpretable or to take high performing neural network models
    but to actually interpret their decisions a little bit better。
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在计算机科学领域正在进行很多工作，试图构建更易解释的模型，或者让高性能的神经网络模型能够更好地解释它们的决策。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_38.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_38.png)'
- en: '![](img/abe8409dd88ef580f00a918d2de80643_39.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_39.png)'
- en: We will talk about the challenges with interpretations in a later module。
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面的模块中讨论解释方面的挑战。
- en: Now I've mentioned several different machine learning techniques in this lecture。
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我在这次讲座中提到了一些不同的机器学习技术。
- en: These are by no means exhaustive or even representing the vast majority of techniques。
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这些绝对不是详尽无遗的，也并不代表大多数技术。
- en: There are a bunch of other techniques out there for example boosting techniques。
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他技术，例如提升技术。
- en: support vector machines。 Even neural networks can be of many different types
    and there are also other regression techniques。
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机。即使神经网络也有许多不同类型，还有其他回归技术。
- en: So regression techniques might be plain old regressions。
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 所以回归技术可能只是普通的回归。
- en: There are other more advanced regression techniques like LASO and RIDGE weighted
    regressions and so on。
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他更高级的回归技术，比如LASSO和Ridge加权回归等。
- en: For a detailed discussion of these techniques I would recommend that you can
    look at a computer science course or machine learning course and it isn't really
    in the scope of a course that's looking at business implications of AI。
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些技术的详细讨论，我建议你查看计算机科学课程或机器学习课程，这不在关注AI商业影响的课程范围内。
- en: '![](img/abe8409dd88ef580f00a918d2de80643_41.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/abe8409dd88ef580f00a918d2de80643_41.png)'
- en: So I'm not going to go into the details of this model but hopefully you got
    a rough sense of what exactly is being done by these machine learning techniques
    where they take in input data。
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我不会深入探讨这个模型，但希望你对这些机器学习技术处理输入数据的方式有个大致的了解。
- en: they make predictions and often based on cleanly labeled data that is available
    from past transactions or past data that can be used to train these algorithms。
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 它们进行预测，通常基于过去交易或可用于训练这些算法的过去数据中的干净标记数据。
- en: '[BLANK_AUDIO]。'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[BLANK_AUDIO]。'
