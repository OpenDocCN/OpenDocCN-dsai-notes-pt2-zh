# 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P130：29_可解释的AI是什么.zh_en - GPT中英字幕课程资源 - BV1Ju4y157dK

 A key challenge with the use of AI systems is related to explainability。



![](img/0417c3fc4047062ddcec8b70c338bd6e_1.png)

 So AI explainability is the use of methods in AI systems where why the algorithm arrived。

 at a particular result can be easily understood by human experts。

 This is closely related to the notion of interpretability， which is understanding why。

 a decision was arrived at by an algorithm。 Even if you can。

 it may not be able to necessarily explain that logic。

 And this contrasts with kind of a black box approach that's normally associated with。

 some types of more complex machine learning and particularly deep learning。



![](img/0417c3fc4047062ddcec8b70c338bd6e_3.png)

 So just to contrast these a little bit， if we have a decision that's made on basic business， rules。

 normally these are easy to explain。 How did we arrive at the decision？

 What factors mattered for coming to that decision？ Some of the simpler machine learning models。

 models based in decision trees for instance， are also relatively easy to interpret。

 One can look at a decision tree and sort of get a sense of how a particular decision was。



![](img/0417c3fc4047062ddcec8b70c338bd6e_5.png)

 arrived at or what factors mattered that led to that decision。 By contrast。

 when we think about deep learning models based， for instance on neural networks。

 especially complex ones based on a lot of data， they become relatively more difficult。



![](img/0417c3fc4047062ddcec8b70c338bd6e_7.png)

 to interpret。 Sometimes harder to look inside the algorithm and understand what it is that led to that。

 decision being made。 There is this major trade-off with more complex models where on the one hand they're able。

 to handle enormous amounts of data and make very accurate predictions。 But on the other hand。

 they can be difficult to explain the logic。 And so explainability， it turns out。

 is key to adoption though in many contexts。 When you think about implementation。

 even if a model is really accurate， an inability， to explain how it arrives at a decision is going to be a major impediment to adoption。

 We'll talk about some examples of that。 But explainability is a key initiative right now in AI。

 It's key frontier。 Big tech companies are currently heavily invested in this issue。

 There are also efforts by the government， for instance， that are funding programs to。



![](img/0417c3fc4047062ddcec8b70c338bd6e_9.png)

 develop better explainable AI。 [BLANK_AUDIO]。

![](img/0417c3fc4047062ddcec8b70c338bd6e_11.png)