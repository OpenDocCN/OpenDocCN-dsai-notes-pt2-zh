- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P81：18_招聘作为一个例子.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this segment， we're going to illustrate some of the issues around data science
    as。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96fdc03340602f663804b1fbf2a21f35_1.png)'
  prefs: []
  type: TYPE_IMG
- en: applied to managing people issues in the context of one very practical， really
    important problem。
  prefs: []
  type: TYPE_NORMAL
- en: And that is hiring。 So Matthew talked a little bit about the general context
    in which managing people decisions。
  prefs: []
  type: TYPE_NORMAL
- en: had been made and actions had been made before data science came along。
  prefs: []
  type: TYPE_NORMAL
- en: We're going to drill down on this a little bit now in hiring。 By hiring， because
    this is by far。
  prefs: []
  type: TYPE_NORMAL
- en: at least right now， the most important people management， issue。
  prefs: []
  type: TYPE_NORMAL
- en: it's the one on which most money is spent。 The administrative costs alone of
    replacing somebody。
  prefs: []
  type: TYPE_NORMAL
- en: even the lowest level workers， about， $4，000。 When you start looking at the
    costs of turnover and you move up higher in the organization。
  prefs: []
  type: TYPE_NORMAL
- en: it's not uncommon to hear estimates that about two years salary is the equivalent
    cost of。
  prefs: []
  type: TYPE_NORMAL
- en: having to bring in a new person。 If you make a mistake and that person quits，
    a bad hire。
  prefs: []
  type: TYPE_NORMAL
- en: that's really expensive。 There's an industry， about $200 billion industry of
    helping companies fill positions。
  prefs: []
  type: TYPE_NORMAL
- en: It's a really big， big business that we're talking about here。 How's it supposed
    to work？ Well。
  prefs: []
  type: TYPE_NORMAL
- en: just as a reminder， most of you probably live through this。
  prefs: []
  type: TYPE_NORMAL
- en: If you look at a textbook on how hiring works， they'll say， you start with a
    job description。
  prefs: []
  type: TYPE_NORMAL
- en: Here's what will be required。 Here's the kind of person we're looking for。
  prefs: []
  type: TYPE_NORMAL
- en: Then you post and add someplace， wait for people to apply。 Once you get your
    applications。
  prefs: []
  type: TYPE_NORMAL
- en: then you try to whittle them down to a short list。 Short list， you use more
    expensive whittling。
  prefs: []
  type: TYPE_NORMAL
- en: Basically， maybe you interview these people and give them tests。 Then at the
    end of this。
  prefs: []
  type: TYPE_NORMAL
- en: you make a hiring decision。 The reality doesn't look at all like this now。
  prefs: []
  type: TYPE_NORMAL
- en: The census reports or data from the census reported last year that the majority
    of people。
  prefs: []
  type: TYPE_NORMAL
- en: who changed employers were not looking to move。 They weren't searching for a
    job。
  prefs: []
  type: TYPE_NORMAL
- en: Somebody came and got them or enticed them to move。 That process of creating
    a short list。
  prefs: []
  type: TYPE_NORMAL
- en: these days that's done by applicant tracking software。
  prefs: []
  type: TYPE_NORMAL
- en: People aren't even touching the resumes anymore。 It's automation on keywords。
  prefs: []
  type: TYPE_NORMAL
- en: It's not artificial intelligence。 It's not even data science。 It's just keyword
    tracking。
  prefs: []
  type: TYPE_NORMAL
- en: It's just looking to see in your resume whether you use the magic words in some
    cases。
  prefs: []
  type: TYPE_NORMAL
- en: Because this is complicated， a lot of people outsource it in their companies。
  prefs: []
  type: TYPE_NORMAL
- en: A company that may hire more people than anybody else in the US is a company
    you may not have。
  prefs: []
  type: TYPE_NORMAL
- en: heard of。 It's a company called PeopleScout。 They are a recruitment process
    outsource。
  prefs: []
  type: TYPE_NORMAL
- en: They hire for other companies。 They hire 300，000 people per year。 Put that in
    perspective。
  prefs: []
  type: TYPE_NORMAL
- en: The US army brings in maybe 120，000 new recruits every year。 People scout is
    hiring 300，000。
  prefs: []
  type: TYPE_NORMAL
- en: It's a big， big operation with a lot of scale。 We look at how things are done
    right now。
  prefs: []
  type: TYPE_NORMAL
- en: There's a real big push on passive candidates。 That means let's see if we can
    find people who are not applying and go grab them and bring。
  prefs: []
  type: TYPE_NORMAL
- en: them into our system。 The goal of most employers seems to be to get more and
    more and more people to apply to。
  prefs: []
  type: TYPE_NORMAL
- en: their positions。 The way to think about this in most organizations， which by
    the way。
  prefs: []
  type: TYPE_NORMAL
- en: I think is a mistake。 I'll come to this in a second， is to think about this
    as a funnel。
  prefs: []
  type: TYPE_NORMAL
- en: We're trying to get lots and lots of people to apply at the very top。
  prefs: []
  type: TYPE_NORMAL
- en: Then we'll screen them down with applicant tracking systems。 And then from there。
  prefs: []
  type: TYPE_NORMAL
- en: we will try to use other screens to pull them down into the bottom of， the funnel。
  prefs: []
  type: TYPE_NORMAL
- en: If 100 people apply at the very beginning here at the top of our funnel， how
    many of。
  prefs: []
  type: TYPE_NORMAL
- en: those people are going to get job offers？ Well， the evidence seems to suggest
    about 2%。
  prefs: []
  type: TYPE_NORMAL
- en: Your odds on getting a job offer when you toss your application into an electronic
    hiring， model。
  prefs: []
  type: TYPE_NORMAL
- en: go to a company and apply that way or you go to job boards like Indeed and apply，
    that way。
  prefs: []
  type: TYPE_NORMAL
- en: about a 2% chance that you will get a job offer。 The reason for that is because
    there are so many people applying for jobs because the。
  prefs: []
  type: TYPE_NORMAL
- en: probability is low， we have people applying for 20 jobs。 30 jobs， 100 jobs。
  prefs: []
  type: TYPE_NORMAL
- en: We made it easy for people to apply and so that's what they do。
  prefs: []
  type: TYPE_NORMAL
- en: That's the reality here and it's followed by an incredibly strange finding and
    that is。
  prefs: []
  type: TYPE_NORMAL
- en: when companies look to see how they're hiring， whether doing a good job or bad
    job， here's。
  prefs: []
  type: TYPE_NORMAL
- en: what they track。 How long does it take for us to fill a position？
  prefs: []
  type: TYPE_NORMAL
- en: How much do we spend to fill a position？ What they don't track。
  prefs: []
  type: TYPE_NORMAL
- en: so maybe only a quarter try to look at this， is whether we make good， hires
    or not。
  prefs: []
  type: TYPE_NORMAL
- en: Think about this。 We're measuring how expensive it is and how fast we can do
    it。
  prefs: []
  type: TYPE_NORMAL
- en: but not whether we do a， good job。 If you were to think about reviewing， let's
    say。
  prefs: []
  type: TYPE_NORMAL
- en: restaurants this way and the way you judge， restaurants was fast and cheap。
  prefs: []
  type: TYPE_NORMAL
- en: that Michelin star guide would really look different。 If all you cared about
    is fast and cheap。
  prefs: []
  type: TYPE_NORMAL
- en: When we start talking about hiring， one of the things to recognize is first，
    the way things。
  prefs: []
  type: TYPE_NORMAL
- en: are going now doesn't look like the textbook and second， for most employers，
    we have no。
  prefs: []
  type: TYPE_NORMAL
- en: idea whether we're doing a good job or not。 It's not going to be hard to do
    better than what we're doing right now。
  prefs: []
  type: TYPE_NORMAL
- en: Let's talk about how we do better and how we apply data science to making hiring
    decisions。
  prefs: []
  type: TYPE_NORMAL
- en: Two issues， the first issue is applicants and a lot of data science energy is
    going into。
  prefs: []
  type: TYPE_NORMAL
- en: trying to find those passive applicants， people who might look like the ones
    who are going。
  prefs: []
  type: TYPE_NORMAL
- en: to be good。 Then the second which gets even more attention is let's look at
    applicants and see if we can。
  prefs: []
  type: TYPE_NORMAL
- en: pick which ones are the ones we should offer jobs to。 How do we start？ With
    data science。
  prefs: []
  type: TYPE_NORMAL
- en: you start the same way you would have before data science came along。
  prefs: []
  type: TYPE_NORMAL
- en: We're trying to figure out now what is a good hire。 Rather than saying as we
    did before。
  prefs: []
  type: TYPE_NORMAL
- en: let's look at what the job requires and then we're。
  prefs: []
  type: TYPE_NORMAL
- en: going to build an applicant tracking screening system or something like that。
    We say。
  prefs: []
  type: TYPE_NORMAL
- en: '"Tell me who your best workers are。"， The first thing we got to do is figure
    out who''s good and who''s bad。'
  prefs: []
  type: TYPE_NORMAL
- en: How are we going to do that？ We got this data problem as well here。
  prefs: []
  type: TYPE_NORMAL
- en: Maybe there's not a single good measure but we're going to take a measure and
    maybe it's。
  prefs: []
  type: TYPE_NORMAL
- en: performance appraisals。 We use that one。 What we're going to do once we've defined
    what's good is we are going to try to identify what。
  prefs: []
  type: TYPE_NORMAL
- en: we know about those people。 Where did they go to school？ What kind of training
    did they have？
  prefs: []
  type: TYPE_NORMAL
- en: If they had test scores， what were those test scores like？
  prefs: []
  type: TYPE_NORMAL
- en: The way we did it before is we relied on measures that mainly psychologists
    have said， "We looked。
  prefs: []
  type: TYPE_NORMAL
- en: at these and these really do predict。"， With data science， we don't care。
  prefs: []
  type: TYPE_NORMAL
- en: Tell us everything you know about them because we don't have to look at them
    one at a time。
  prefs: []
  type: TYPE_NORMAL
- en: These attributes are characteristics。 We're going to pile them all in together
    and build one model out of this。
  prefs: []
  type: TYPE_NORMAL
- en: Once we identify everything about our best employees， then we're going to say，
    "Okay。
  prefs: []
  type: TYPE_NORMAL
- en: now let's see if you can give me that information about you're not good employees
    because we。
  prefs: []
  type: TYPE_NORMAL
- en: need variation。"， Just as we're looking for ball bearings。
  prefs: []
  type: TYPE_NORMAL
- en: we want to see the ones that break but we want， to see ones that don't break
    too to figure out when they break what causes it。
  prefs: []
  type: TYPE_NORMAL
- en: We're trying to figure out here what is associated with being a good employee
    and also what is。
  prefs: []
  type: TYPE_NORMAL
- en: associated with being a not good employee。 The difference with data science
    is that we don't care what those measures look like。
  prefs: []
  type: TYPE_NORMAL
- en: It could be， "Just tell me whatever you know about the person because we are
    completely。
  prefs: []
  type: TYPE_NORMAL
- en: agnostic about where the explanation is going to be driven by。"， As you know。
  prefs: []
  type: TYPE_NORMAL
- en: with a machine learning model and the algorithm that it produces， it is。
  prefs: []
  type: TYPE_NORMAL
- en: a really complicated nonlinear combination of all kinds of attributes about
    that person。
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the day， it's going to produce a one number score for us。
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we do is we look at our workforce and that data we've got。 We
    cut it in half。
  prefs: []
  type: TYPE_NORMAL
- en: We have the training data on which the machine learning software is going to
    learn。
  prefs: []
  type: TYPE_NORMAL
- en: That is it's going to build a model that predicts the performance score that
    we're using to。
  prefs: []
  type: TYPE_NORMAL
- en: identify good versus bad workers。 We're going to use the second set of the data。
  prefs: []
  type: TYPE_NORMAL
- en: the second half of it to test it and see how， well it does。 Assuming it does
    a pretty good job。
  prefs: []
  type: TYPE_NORMAL
- en: then what we're going to do is we're going to try to。
  prefs: []
  type: TYPE_NORMAL
- en: go to applicants and get their measures on all those attributes that we included
    in our。
  prefs: []
  type: TYPE_NORMAL
- en: model of our own employees， where they went to school， how they did there， where
    they worked。
  prefs: []
  type: TYPE_NORMAL
- en: before， where they lived。 Anything we think might be relevant that we used in
    our first model on the training data。
  prefs: []
  type: TYPE_NORMAL
- en: to build the algorithm， we got to ask those same questions of our applicants
    and get all。
  prefs: []
  type: TYPE_NORMAL
- en: that same data。 When we do that， at the end of the process。
  prefs: []
  type: TYPE_NORMAL
- en: what we get is a score for each candidate。 The score is going to be how well
    do they match on to our best-performing employees。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96fdc03340602f663804b1fbf2a21f35_3.png)'
  prefs: []
  type: TYPE_IMG
- en: You're going to get a one-number score。 Before this， in the old days。
  prefs: []
  type: TYPE_NORMAL
- en: you might give people personality tests， you might give them， IQ tests or dexterity
    tests。
  prefs: []
  type: TYPE_NORMAL
- en: three different tests， three different measures。 They do interviews， you get
    an interview score。
  prefs: []
  type: TYPE_NORMAL
- en: maybe there's something about their references， you get a score for those， you
    get five scores。
  prefs: []
  type: TYPE_NORMAL
- en: and then you turn it over to some recruiter， or some expert you hope who's going
    to look across those five and make a decision。
  prefs: []
  type: TYPE_NORMAL
- en: We move to machine learning and algorithms， you get one number。
  prefs: []
  type: TYPE_NORMAL
- en: That number is the score and that's what you get。 What do we know about this
    model？
  prefs: []
  type: TYPE_NORMAL
- en: It is likely to be much better at predicting than anything that you were doing
    before， because。
  prefs: []
  type: TYPE_NORMAL
- en: it's only got one goal， and that is to predict how well somebody is going to
    look like the。
  prefs: []
  type: TYPE_NORMAL
- en: people who performed well here or before。 It doesn't have to be something which
    psychologists or economists or anybody else has said in。
  prefs: []
  type: TYPE_NORMAL
- en: the past predicts。 All we care about is association。
  prefs: []
  type: TYPE_NORMAL
- en: Do these attributes that we're measuring and capturing for applicants？ Those
    measures。
  prefs: []
  type: TYPE_NORMAL
- en: are they associated with good performers and if they are， you get a good， score。
  prefs: []
  type: TYPE_NORMAL
- en: What else do we need here？ We need lots of data。 We need thousands of applicants
    to build a machine learning model。
  prefs: []
  type: TYPE_NORMAL
- en: That's going to be tricky unless you're a big employer。
  prefs: []
  type: TYPE_NORMAL
- en: That's going to make an argument for trying to use vendors who might have access
    to lots。
  prefs: []
  type: TYPE_NORMAL
- en: and lots of applicants across many different companies， but there are issues
    there that。
  prefs: []
  type: TYPE_NORMAL
- en: are legal ones that we'll come back to a little later here。 Let's talk about
    the question of bias。
  prefs: []
  type: TYPE_NORMAL
- en: bias has gotten a lot of attention in the discussion of machine learning hiring。
  prefs: []
  type: TYPE_NORMAL
- en: Here's the good news about algorithms that are generated by machine learning。
  prefs: []
  type: TYPE_NORMAL
- en: The good news is they treat every candidate the same。 For example。
  prefs: []
  type: TYPE_NORMAL
- en: if we're thinking about how much should a college degree matter and that's。
  prefs: []
  type: TYPE_NORMAL
- en: all we tell them is college degree， it's going to treat all college degrees
    the same。
  prefs: []
  type: TYPE_NORMAL
- en: It's not going to treat college degrees for men differently than for women。
    Recruiters。
  prefs: []
  type: TYPE_NORMAL
- en: when they're looking at this stuff and their heads are full of bias， their judgments。
  prefs: []
  type: TYPE_NORMAL
- en: are going to be full of bias as well。 When you're using an algorithm。
  prefs: []
  type: TYPE_NORMAL
- en: you don't get any of that bias。 Everybody is treated consistently。
  prefs: []
  type: TYPE_NORMAL
- en: The bad news is that if there is bias in the training data that built the algorithm，
    there's。
  prefs: []
  type: TYPE_NORMAL
- en: going to be bias in the algorithm itself。 It gets repeated。
  prefs: []
  type: TYPE_NORMAL
- en: The example that gets a lot of attention from this is that Amazon built an algorithm
    to。
  prefs: []
  type: TYPE_NORMAL
- en: do its hiring for it。 The motivation for this was a perfectly reasonable one。
  prefs: []
  type: TYPE_NORMAL
- en: Let's see if we can get better at hiring and also cheaper。 Because if we get
    a good algorithm。
  prefs: []
  type: TYPE_NORMAL
- en: we don't need recruiters， we don't have to bother with， this interviewing。 It
    could be cheaper。
  prefs: []
  type: TYPE_NORMAL
- en: faster， and by the way， maybe better。 What Amazon discovered when it started
    to use its algorithm is that when you looked at。
  prefs: []
  type: TYPE_NORMAL
- en: the scores， it appeared that women were getting lower scores than otherwise
    equivalent men。
  prefs: []
  type: TYPE_NORMAL
- en: which was a puzzle。 What they did is they went back in and they took out anything
    that might identify the sex。
  prefs: []
  type: TYPE_NORMAL
- en: or the gender of the applicant。 Took out names， for example。
  prefs: []
  type: TYPE_NORMAL
- en: made sure that there was nothing that had a feminine masculine。
  prefs: []
  type: TYPE_NORMAL
- en: pronoun and it took out all that stuff。 What they discovered was that the results
    didn't change very much。
  prefs: []
  type: TYPE_NORMAL
- en: The reason was because in the training data， which was based on prior employees
    in Amazon。
  prefs: []
  type: TYPE_NORMAL
- en: current ones too， what was there was that men on average had gotten higher scores
    than， women。
  prefs: []
  type: TYPE_NORMAL
- en: Maybe some of this was simply because there were more men in the data disproportionately，
    there。
  prefs: []
  type: TYPE_NORMAL
- en: but no doubt there was bias in promotion rates and in overall performance scores
    as， well。
  prefs: []
  type: TYPE_NORMAL
- en: What was happening， the Amazon algorithm was looking for anything that might
    show up a。
  prefs: []
  type: TYPE_NORMAL
- en: relationship with gender。 If for example you had taken a women's studies course。
  prefs: []
  type: TYPE_NORMAL
- en: it assumed that it's highly correlated， with women， women do worse。
  prefs: []
  type: TYPE_NORMAL
- en: you're going to get a lower score。 If the algorithm worse than what was happening
    without it。
  prefs: []
  type: TYPE_NORMAL
- en: we will never know。 The difference was because you're using this algorithm and
    you're applying it to everybody。
  prefs: []
  type: TYPE_NORMAL
- en: you can see the bias instantly because you can look at those scores， look at
    them for， men。
  prefs: []
  type: TYPE_NORMAL
- en: look at them for women， see what appears to be different about them for the
    same job。
  prefs: []
  type: TYPE_NORMAL
- en: same education level， same other things that the courts and lawyers might care
    about and。
  prefs: []
  type: TYPE_NORMAL
- en: you'll see if there's a difference。 Particularly if you're worried about getting
    sued。
  prefs: []
  type: TYPE_NORMAL
- en: here's the problem with using these algorithms。 They may be better than what
    you were doing before。
  prefs: []
  type: TYPE_NORMAL
- en: they may be less biased than what you， were doing before。
  prefs: []
  type: TYPE_NORMAL
- en: but you can see the bias easily and that's a problem。 The other issues about
    this。
  prefs: []
  type: TYPE_NORMAL
- en: if it's a good algorithm， you can get rid of these applicant， tracking systems。
  prefs: []
  type: TYPE_NORMAL
- en: You don't have to bother trying to screen out people based on this measure or
    that measure。
  prefs: []
  type: TYPE_NORMAL
- en: Just give them all to us and we'll just score them up because it's quick and
    easy and give。
  prefs: []
  type: TYPE_NORMAL
- en: them a score。 You might also find as some research has found as well that some
    people who turn out to be。
  prefs: []
  type: TYPE_NORMAL
- en: really good fits with your job don't have the attributes that you thought were
    important， before。
  prefs: []
  type: TYPE_NORMAL
- en: Our colleague at Columbia， Bo Kogel has done a study of this algorithm that
    was used for。
  prefs: []
  type: TYPE_NORMAL
- en: hiring and one of the things he discovered is that the algorithm was able to
    identify。
  prefs: []
  type: TYPE_NORMAL
- en: people who were good performers in jobs where they assumed you needed a college
    degree。
  prefs: []
  type: TYPE_NORMAL
- en: Some of those people who got good scores that is saying they're going to be
    good at this。
  prefs: []
  type: TYPE_NORMAL
- en: job did not have college degrees anymore。 The problem with that though is if
    you only hire people with college degrees you'll never。
  prefs: []
  type: TYPE_NORMAL
- en: know that。 In order to really make use of these algorithms you need to build
    them with data which doesn't。
  prefs: []
  type: TYPE_NORMAL
- en: begin with this selecting out of people already。 In the future in order to know
    that the algorithm continues to be good if for example the population。
  prefs: []
  type: TYPE_NORMAL
- en: changes or the jobs change you have to do some hiring that's random that doesn't
    begin with。
  prefs: []
  type: TYPE_NORMAL
- en: screening out people and with job requirements that say must have this， this
    or this。
  prefs: []
  type: TYPE_NORMAL
- en: That's by the way that's true in general of hiring but with algorithms it becomes
    even。
  prefs: []
  type: TYPE_NORMAL
- en: more obvious that if you're screening people out you'll never know whether you
    still need。
  prefs: []
  type: TYPE_NORMAL
- en: those screens and if they're still reasonable。 The other thing about algorithms
    is that you can get some results which don't seem particularly。
  prefs: []
  type: TYPE_NORMAL
- en: intuitive。 For example years ago there was a company that we had some dealings
    with here which discovered。
  prefs: []
  type: TYPE_NORMAL
- en: in their applications that the zip code where people were living was a pretty
    good predictor。
  prefs: []
  type: TYPE_NORMAL
- en: of turnover for call center jobs。 What was going on there was really a measure
    of distance to the workplace and these were。
  prefs: []
  type: TYPE_NORMAL
- en: jobs that didn't pay very well。 The farther the commuting distance was the more
    likely you were to be absent。
  prefs: []
  type: TYPE_NORMAL
- en: more likely， therefore you were to ultimately turn over or quit or whatever。
  prefs: []
  type: TYPE_NORMAL
- en: That was because low wage jobs you needed reliable transportation， public transportation。
  prefs: []
  type: TYPE_NORMAL
- en: wasn't always so good。 A really reliable car took maybe more money than many
    people had。
  prefs: []
  type: TYPE_NORMAL
- en: So nobody ever thought to look at commuting distance before and these folks
    discovered it。
  prefs: []
  type: TYPE_NORMAL
- en: But then you see other vendors and other people making claims as well。
  prefs: []
  type: TYPE_NORMAL
- en: So a well known one is a company that was claiming that facial expressions predicted。
  prefs: []
  type: TYPE_NORMAL
- en: your job performance。 Well how were they doing that？
  prefs: []
  type: TYPE_NORMAL
- en: They were trying to map your facial expressions on to the facial expressions
    of their best。
  prefs: []
  type: TYPE_NORMAL
- en: employees in a company and then giving applicants a score based on how closely
    your facial expressions。
  prefs: []
  type: TYPE_NORMAL
- en: mapped onto the facial expressions of your best performers。 Well how do you
    feel about that？
  prefs: []
  type: TYPE_NORMAL
- en: Let's say it actually predicted would you be okay with that？
  prefs: []
  type: TYPE_NORMAL
- en: With a hiring model based on the facial expressions of your applicants would
    you be okay with that。
  prefs: []
  type: TYPE_NORMAL
- en: or not？ Look this more carefully this is something data science people refer
    to as explainability。
  prefs: []
  type: TYPE_NORMAL
- en: Probably heard that before by now。 Explainability means can you tell somebody
    why this works in a way that seems sensible。
  prefs: []
  type: TYPE_NORMAL
- en: If you had to go before a judge for example and it turned out that your facial
    expression。
  prefs: []
  type: TYPE_NORMAL
- en: measure gave worse scores to African Americans because reading facial expressions
    with cameras。
  prefs: []
  type: TYPE_NORMAL
- en: might be more difficult to do in that context。 Suppose that happened and you
    had to explain to the judge how you were hiring and you said。
  prefs: []
  type: TYPE_NORMAL
- en: based on facial expression。 Would you feel comfortable doing that？
  prefs: []
  type: TYPE_NORMAL
- en: Well it's not clear that that actually did predict afterwards when you looked
    at those。
  prefs: []
  type: TYPE_NORMAL
- en: outcomes not clear that that actually does predict but you might very well end
    up with。
  prefs: []
  type: TYPE_NORMAL
- en: some evidence suggesting at least initially that it does。
  prefs: []
  type: TYPE_NORMAL
- en: One of the problems here is that there's thousands of vendors now。
  prefs: []
  type: TYPE_NORMAL
- en: Each one selling a solution a hiring solution based on machine learning type
    algorithms。
  prefs: []
  type: TYPE_NORMAL
- en: One of the things you want to be very careful about in dealing with vendors
    and whatever。
  prefs: []
  type: TYPE_NORMAL
- en: their claims are is ask them can you show me the evidence that this works based
    on real。
  prefs: []
  type: TYPE_NORMAL
- en: job performance。 I understand how you built the algorithm but afterwards when
    you tested it and you hired。
  prefs: []
  type: TYPE_NORMAL
- en: people or selected people based on it did those people really perform well。
  prefs: []
  type: TYPE_NORMAL
- en: The final thing to remember about this is if you really want to be able to defend
    your。
  prefs: []
  type: TYPE_NORMAL
- en: hiring practices particularly against lawsuits that your criteria has an adverse
    impact against。
  prefs: []
  type: TYPE_NORMAL
- en: women or minorities or virtually any other protected group which includes everybody。
  prefs: []
  type: TYPE_NORMAL
- en: Can you do it with your own data？ If you can't show it with your own data that
    this algorithm really predicts then if it。
  prefs: []
  type: TYPE_NORMAL
- en: turns out that it has some adverse impact against people in any of those categories。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96fdc03340602f663804b1fbf2a21f35_5.png)'
  prefs: []
  type: TYPE_IMG
- en: which is basically everybody you're in trouble。 If a vendor tells you that it's
    valid that it predicts that's fine but it doesn't help。
  prefs: []
  type: TYPE_NORMAL
- en: you to demonstrate that your own hiring practices are good ones。
  prefs: []
  type: TYPE_NORMAL
- en: So one of the things you have to think about you can't just buy these things
    off the shelf。
  prefs: []
  type: TYPE_NORMAL
- en: even if a vendor can persuade you that their data looks good their evidence
    shows it works。
  prefs: []
  type: TYPE_NORMAL
- en: you have to be able to test it on your own data and do that。
  prefs: []
  type: TYPE_NORMAL
- en: So it's a complicated set of issues here when we start thinking about applying
    this to hiring。
  prefs: []
  type: TYPE_NORMAL
- en: which is where most of the action is right now。 [BLANK_AUDIO]。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96fdc03340602f663804b1fbf2a21f35_7.png)'
  prefs: []
  type: TYPE_IMG
