- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P39：5_利用机器智能识别新的风险形式.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I want to bring your awareness to what are the kinds of issues that can happen
    when you。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b6bb46c8e2b9282e02c4d0ad534ba9c_1.png)'
  prefs: []
  type: TYPE_IMG
- en: start using machine learning and AI modules。 So we've talked a lot about customer
    journey。
  prefs: []
  type: TYPE_NORMAL
- en: We've talked a lot about all the different things that a machine learning algorithm
    or。
  prefs: []
  type: TYPE_NORMAL
- en: AI software can do for you。 But at the same time， I think it's important to
    understand what are the risks that are。
  prefs: []
  type: TYPE_NORMAL
- en: appearing as well。 So one example of the risk is understanding where the data
    is from。
  prefs: []
  type: TYPE_NORMAL
- en: I'll give you two examples， but I think these examples， of course， you will
    see is in some。
  prefs: []
  type: TYPE_NORMAL
- en: sense tip of the iceberg。 These examples come from Amazon。 Again， of course
    Amazon is a big company。
  prefs: []
  type: TYPE_NORMAL
- en: There are many other companies which are also involved in some of these examples。
  prefs: []
  type: TYPE_NORMAL
- en: But I just want to give you an example from Amazon， but you will see how general
    these。
  prefs: []
  type: TYPE_NORMAL
- en: examples are。 One example is this idea of Amazon scrapping a secret AI recruiting
    tool。
  prefs: []
  type: TYPE_NORMAL
- en: What was the problem here？ The problem here was that Amazon， like many of the
    companies。
  prefs: []
  type: TYPE_NORMAL
- en: perhaps have a lot of people， who want to， in some sense， become employees at
    Amazon。 Well。
  prefs: []
  type: TYPE_NORMAL
- en: they had a lot of people submitting their resumes。 And in this case。
  prefs: []
  type: TYPE_NORMAL
- en: it was about software developers， if I remember correctly。
  prefs: []
  type: TYPE_NORMAL
- en: And so many people want to become software developers at Amazon。 So what did
    they want to do？
  prefs: []
  type: TYPE_NORMAL
- en: They wanted to speed up that process。 So how did they do it？ They basically
    said。
  prefs: []
  type: TYPE_NORMAL
- en: wouldn't it be great if you could have an AI tool that goes through。
  prefs: []
  type: TYPE_NORMAL
- en: some of these resumes and tries to figure out which resumes perhaps have the
    highest。
  prefs: []
  type: TYPE_NORMAL
- en: chance of becoming successful， which people？ And what did they benchmark against？
  prefs: []
  type: TYPE_NORMAL
- en: They benchmarked against their current employees and their own resumes that
    they had。
  prefs: []
  type: TYPE_NORMAL
- en: And then they started looking at how best to predict。 What was the issue？
  prefs: []
  type: TYPE_NORMAL
- en: The issue was that the historical data that they had， which is the data of their
    current， employees。
  prefs: []
  type: TYPE_NORMAL
- en: were largely male software developers。 So what did they end up doing？ Unfortunately。
  prefs: []
  type: TYPE_NORMAL
- en: the AI tool ended up biasing against women。 So I can notice it's not the fault
    of the tool per se。
  prefs: []
  type: TYPE_NORMAL
- en: It's the fault of the data。 So thinking very carefully about where the data
    is coming from。
  prefs: []
  type: TYPE_NORMAL
- en: how generalizable is， that data， there are many， many other issues of that kind。
  prefs: []
  type: TYPE_NORMAL
- en: Let me give you one more example。 And this is the example of Amazon and the
    racist algorithms that you see here。
  prefs: []
  type: TYPE_NORMAL
- en: Again， obviously very controversial。 So let's discuss this example。
  prefs: []
  type: TYPE_NORMAL
- en: And then we'll also talk about the controversy。 Now in this case。
  prefs: []
  type: TYPE_NORMAL
- en: Amazon was thinking about expanding their Amazon Prime service that， they were
    offering in the US。
  prefs: []
  type: TYPE_NORMAL
- en: So this example and this issue was especially in the Boston area。
  prefs: []
  type: TYPE_NORMAL
- en: Now what happened there was the following。 They were looking at where to offer
    Amazon Prime。
  prefs: []
  type: TYPE_NORMAL
- en: They were looking at different zip codes。 And then they basically did the following
    calculation。
  prefs: []
  type: TYPE_NORMAL
- en: So let's offer it in certain zip codes where there's a chance to become more
    profitable。
  prefs: []
  type: TYPE_NORMAL
- en: which makes sense。 Once they started looking at that， now those of us who are
    from Boston。
  prefs: []
  type: TYPE_NORMAL
- en: they might recognize， this。 There's an area called Roxbury in Boston。
  prefs: []
  type: TYPE_NORMAL
- en: which is a slightly lower income area。 So this ended up becoming what they call
    the Amazon problem。
  prefs: []
  type: TYPE_NORMAL
- en: which is like a donut， which， is in all areas around Roxbury。
  prefs: []
  type: TYPE_NORMAL
- en: they were offering Amazon Prime but for Roxbury。 But you can imagine this was
    a very controversial。
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand， you can also imagine that people in Roxbury who did not have
    many stores。
  prefs: []
  type: TYPE_NORMAL
- en: around them， those will actually be the people who benefit the most from Amazon
    Prime。
  prefs: []
  type: TYPE_NORMAL
- en: Now why did this happen？ Because again， they were looking at data but they didn't
    follow through to kind of see。
  prefs: []
  type: TYPE_NORMAL
- en: what those algorithms are doing。 So first issue I wanted to be aware of as you
    start using your customer data to predict。
  prefs: []
  type: TYPE_NORMAL
- en: the journey， shorten the journey， whatever the case might be。
  prefs: []
  type: TYPE_NORMAL
- en: The first thing about how generalizable that data is is touching all different
    customers。
  prefs: []
  type: TYPE_NORMAL
- en: that you have and starting to think very carefully about how representative
    the data is。
  prefs: []
  type: TYPE_NORMAL
- en: The next issue is around data sets and privacy。 First customer privacy is a
    huge issue。
  prefs: []
  type: TYPE_NORMAL
- en: So in Europe， you have the GDPR in California， you have the California Privacy
    Act。 There are many。
  prefs: []
  type: TYPE_NORMAL
- en: many other such privacy acts that will be coming forth。
  prefs: []
  type: TYPE_NORMAL
- en: And I would advise you as you start thinking about using your customer data
    to then perhaps。
  prefs: []
  type: TYPE_NORMAL
- en: target customers， meet the journey， the customizable， personalizing the journey，
    whatever the case。
  prefs: []
  type: TYPE_NORMAL
- en: might be。 Start thinking very carefully about a and showing customer privacy
    and what can you do。
  prefs: []
  type: TYPE_NORMAL
- en: to make sure that you don't infringe their privacy。 Let me give you an example。
  prefs: []
  type: TYPE_NORMAL
- en: This example comes from this company called Strava。
  prefs: []
  type: TYPE_NORMAL
- en: Now Strava is a company that in some sense was building a global heat map so
    to speak。
  prefs: []
  type: TYPE_NORMAL
- en: That's what they talked about。 It's a big social network for people who are
    very active。
  prefs: []
  type: TYPE_NORMAL
- en: If you're on Strava， you can put it up， you can say， "Well， I went ahead and
    jogged， five miles。
  prefs: []
  type: TYPE_NORMAL
- en: '" and so on and so forth。 So they had in some sense noted the fact that they
    are building a global heat map of all。'
  prefs: []
  type: TYPE_NORMAL
- en: the people who are very active。 What happened？ Well。
  prefs: []
  type: TYPE_NORMAL
- en: their own data was anonymized and they made very sure that their data set perhaps。
  prefs: []
  type: TYPE_NORMAL
- en: is not in some sense identifiable。 But what did some people do？
  prefs: []
  type: TYPE_NORMAL
- en: They ended up imposing a Google map on top of that。 What ended up happening？
    Well， in some sense。
  prefs: []
  type: TYPE_NORMAL
- en: they were able to find people， I believe in Afghanistan and so on。
  prefs: []
  type: TYPE_NORMAL
- en: who were the US Army that was stationed there。 So clearly， that's what this
    headline talks about。
  prefs: []
  type: TYPE_NORMAL
- en: the Strava heat map and the end of， secrets。 What is the big idea here？
  prefs: []
  type: TYPE_NORMAL
- en: The big idea here is your own data set might be anonymized， but increasingly，
    there are， many。
  prefs: []
  type: TYPE_NORMAL
- en: many people out there who are putting data sets together。
  prefs: []
  type: TYPE_NORMAL
- en: And that's something to be very careful about， which is it's not just your data
    sets that。
  prefs: []
  type: TYPE_NORMAL
- en: should ensure privacy， but think very carefully about how data sets coming together
    might。
  prefs: []
  type: TYPE_NORMAL
- en: end up taking care of privacy。 A third issue is how are you using machine learning。
  prefs: []
  type: TYPE_NORMAL
- en: This relates to the idea that we had brought up earlier about data itself， but
    it's more。
  prefs: []
  type: TYPE_NORMAL
- en: than just the representativeness of data。 It's the idea of how often your data
    is getting updated。
  prefs: []
  type: TYPE_NORMAL
- en: which is， you know， are you using， data from two years ago， a year ago。
  prefs: []
  type: TYPE_NORMAL
- en: look at the customer journey， look at how frequently， customers are buying your
    products。
  prefs: []
  type: TYPE_NORMAL
- en: What's the journey like？ Which parts of the customer journey are sticky？ Which
    parts are changing？
  prefs: []
  type: TYPE_NORMAL
- en: Because of course， as new technology comes in， as new competitors come in， all
    of that。
  prefs: []
  type: TYPE_NORMAL
- en: journey changes。 So thinking carefully about how you're using your data， you're
    using your models。
  prefs: []
  type: TYPE_NORMAL
- en: and how， often is the data getting updated in terms of how the journey is changing
    is critical。
  prefs: []
  type: TYPE_NORMAL
- en: And of course， there's no data for free。 What that means is。
  prefs: []
  type: TYPE_NORMAL
- en: I think when you start thinking about using new technology， be it， machine learning，
    be it AI。
  prefs: []
  type: TYPE_NORMAL
- en: whatever the case might be， you need to have a proactive approach。
  prefs: []
  type: TYPE_NORMAL
- en: perhaps doing a little bit of testing and learning， collect some data， cue new
    models， see how。
  prefs: []
  type: TYPE_NORMAL
- en: well that new data that you've collected， how well your models are predicting
    that。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b6bb46c8e2b9282e02c4d0ad534ba9c_3.png)'
  prefs: []
  type: TYPE_IMG
- en: So the more you do that， the more you can be agile in terms of understanding
    how your。
  prefs: []
  type: TYPE_NORMAL
- en: machine learning in AI software is quote unquote getting updated in terms of
    new data coming。
  prefs: []
  type: TYPE_NORMAL
- en: in and how those older models perhaps need to be tweaked as well。 Thank you。
    [BLANK_AUDIO]。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b6bb46c8e2b9282e02c4d0ad534ba9c_5.png)'
  prefs: []
  type: TYPE_IMG
