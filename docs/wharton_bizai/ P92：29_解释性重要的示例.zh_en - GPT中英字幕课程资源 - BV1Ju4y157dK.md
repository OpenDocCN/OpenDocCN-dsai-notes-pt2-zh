# 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P92：29_解释性重要的示例.zh_en - GPT中英字幕课程资源 - BV1Ju4y157dK

 Explainability or interpretability as it's sometimes called can be important in a variety。



![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_1.png)

 of different contexts。 Sometimes if you're just trying to make a prediction it may not matter so much but a。

 lot of business contexts being able to understand why the algorithm comes to the decision it。



![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_3.png)

 does really matter。 So consider for example a medical context where you have a deep learning system that's。

 recommending whether a patient should get a treatment or not。

 When you have a highly specialized doctor who disagrees with that assessment it's not。

 very easy to resolve if the system is just saying something different。

 The doctor is going to want to know exactly how it came to that decision and what is being。

 incorporated into that decision making flow。 And so that's one example where interpretability can be very important。

 It turns out in the HR context interpretability is also particularly important because there。

 are a number of guidelines and legal protections in HR that require HR organizations or the。

 HR side of organizations to be able to cleanly and clearly document how they come to decisions。

 So for example there are EEOC Equal Employment Opportunity Commission rules on the types。

 of employees that you hire on being able to document various decisions that you make。

 And the notion that you're going to just throw data into a deep learning system have it make。

 a prediction that you're then going to use isn't that sustainable in a context like this where。

 you really want to have very clean documentation of why you came to a decision where you want。

 to make sure that you're following guidelines related to employment protection law that。

 have a long historical basis。 And so these kinds of restrictions make it very hard to use systems that are not interpretable。

 If you can't step back and say why is this decision being made or why is it making this。

 decision or if you can't step back and adjust the system in a way that can allow you to meet。

 the guidelines you need to meet this makes things much more difficult。

 This is an example where interpretability matters and this is why an HR in particular。

 interpretability or explainability tends to make a big difference。

 Another place where it's having a big impact in the HR domain is related to new data privacy。

 laws that are emerging in a number of different areas。

 So consider the general data protection regulation notice the GDPR in the EU the European Union。

 There's a similar California law CCPA as well。 And these kinds of laws place restrictions on employer's ability to use data provided。

 by potential applicants。 And so when it says that they some of these laws mandate that when you do use automated。

 decision making you need to be able to explain how you came to a decision you need to be。

 able to provide the logic that was used when coming or arriving at a final decision。

 And so in the absence of interpretable systems it makes it very difficult to adhere to the。



![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_5.png)

 guidelines laid out by these laws。 So explainability it turns out is a key issue when thinking about HR tech adoption。

 Fortunately there's a lot of resources being put into this question。

 A lot of companies especially big tech companies are increasingly invested in this issue。

 There are a number of new tools that are emerging that provide AI support at a more interpretable。

 level。 Government through various agencies are also invested in providing resources to build more。

 explainable AI systems for different industries。

![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_7.png)

 In the next video we will talk about some of the challenges some of the trade-offs that。

 arise when making systems more explainable。 [BLANK_AUDIO]。



![](img/0f89fb50f02c2f3f650fcbce3ebc5d4e_9.png)