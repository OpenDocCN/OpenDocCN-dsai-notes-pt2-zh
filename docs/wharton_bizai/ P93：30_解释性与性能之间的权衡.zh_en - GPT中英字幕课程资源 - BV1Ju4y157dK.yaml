- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P93：30_解释性与性能之间的权衡.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've talked about interpretability being important for a number of different
    types。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_1.png)'
  prefs: []
  type: TYPE_IMG
- en: of business contexts。 We want to be able to understand why an algorithm is coming
    to the decision that it's coming。
  prefs: []
  type: TYPE_NORMAL
- en: to。 So why wouldn't we always make algorithms interpretable？ Well， it turns
    out there's a trade-off。
  prefs: []
  type: TYPE_NORMAL
- en: There's generally a trade-off between explainability and performance。
  prefs: []
  type: TYPE_NORMAL
- en: So just like with fairness or with bias， sometimes when you want to make an
    algorithm。
  prefs: []
  type: TYPE_NORMAL
- en: more explainable， it comes at the expense of performance。 And there's actually。
  prefs: []
  type: TYPE_NORMAL
- en: you can almost think about these as a spectrum with different machine。
  prefs: []
  type: TYPE_NORMAL
- en: learning models that are commonly used， where the more interpretable they get，
    the less。
  prefs: []
  type: TYPE_NORMAL
- en: predictive they get。 The ones that are very， that are least predictive sometimes
    are the easiest to go back and explain。
  prefs: []
  type: TYPE_NORMAL
- en: The ones that are really high， really predictive， deep learning models， neural
    network models。
  prefs: []
  type: TYPE_NORMAL
- en: tend to be very difficult to explain。 And we like， of course， to find ways to
    achieve both。
  prefs: []
  type: TYPE_NORMAL
- en: We like to find ways that kind of find the sweet spot between explainability
    and prediction。
  prefs: []
  type: TYPE_NORMAL
- en: But that， of course， is hard to do。 So in practice。
  prefs: []
  type: TYPE_NORMAL
- en: a precise prediction model often needs to be balanced by the ability to， justify
    the model。
  prefs: []
  type: TYPE_NORMAL
- en: And so organizations are often trying to find the balance between having a predictive，
    highly。
  prefs: []
  type: TYPE_NORMAL
- en: predictive model， but also being able to go back and justify it in the case
    of， say。
  prefs: []
  type: TYPE_NORMAL
- en: loan processing or something like that。 Or it is important to go back to， say。
  prefs: []
  type: TYPE_NORMAL
- en: customers or other stakeholders and explain why it is， a decision was arrived
    at。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_3.png)'
  prefs: []
  type: TYPE_IMG
- en: It does raise a difficult question， though， for lots of context， because both
    of these， things。
  prefs: []
  type: TYPE_NORMAL
- en: explainability is very important， so is accuracy。 Again， going back to the medical
    context。
  prefs: []
  type: TYPE_NORMAL
- en: it's hard to easily say they're both very important。
  prefs: []
  type: TYPE_NORMAL
- en: You want to be able to explain the decision for all the different stakeholders
    in healthcare。
  prefs: []
  type: TYPE_NORMAL
- en: and patients as well。 But it's also the case， of course。
  prefs: []
  type: TYPE_NORMAL
- en: that you want to have very accurate predictions when。
  prefs: []
  type: TYPE_NORMAL
- en: you're dealing with things that affect people's health。 So it's hard to say。
  prefs: []
  type: TYPE_NORMAL
- en: not necessarily an easy question to answer about how to make these。
  prefs: []
  type: TYPE_NORMAL
- en: trade-offs that depends on the organizational context or the business context。
    Some applications。
  prefs: []
  type: TYPE_NORMAL
- en: if you're thinking about predicting user clicks or maybe buying or selling，
    a financial asset。
  prefs: []
  type: TYPE_NORMAL
- en: it doesn't matter as much if you can go back and explain the decision。
  prefs: []
  type: TYPE_NORMAL
- en: You're not affecting people in the same way， so it doesn't matter as much whether
    you。
  prefs: []
  type: TYPE_NORMAL
- en: are able to go back and explain why the algorithm made the predictive decision
    that it did。
  prefs: []
  type: TYPE_NORMAL
- en: In that case， you may want to use a highly predictive model。 It doesn't need
    to be interpretable。
  prefs: []
  type: TYPE_NORMAL
- en: For something like employee promotions， it does matter。
  prefs: []
  type: TYPE_NORMAL
- en: You want to be able to go back and understand why the algorithm made the decision
    it did。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_5.png)'
  prefs: []
  type: TYPE_IMG
- en: And so for that type of application， an organization may try to strike a balance
    between an interpretable。
  prefs: []
  type: TYPE_NORMAL
- en: model and one that makes good predictive decisions。 [BLANK_AUDIO]。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dab4278f01173a133cc8b54b20a5261d_7.png)'
  prefs: []
  type: TYPE_IMG
