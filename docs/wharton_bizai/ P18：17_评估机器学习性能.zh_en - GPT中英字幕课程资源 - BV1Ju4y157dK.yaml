- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P18：17_评估机器学习性能.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we talk about building machine learning algorithms or training machine
    learning algorithms。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f040461bd947bde42f4b2188e5500659_1.png)'
  prefs: []
  type: TYPE_IMG
- en: there are a variety of ways to think about how to judge whether the algorithm
    is doing。
  prefs: []
  type: TYPE_NORMAL
- en: a good job or not。 When we build an algorithm， we're trying to teach it to predict
    based on some labels or。
  prefs: []
  type: TYPE_NORMAL
- en: examples we give it。 The question arises then， what should we tell the algorithm
    to optimize on？
  prefs: []
  type: TYPE_NORMAL
- en: Is it really trying to get as many of the labels right as possible or is it
    trying to。
  prefs: []
  type: TYPE_NORMAL
- en: optimize something else？ For example， there may be differing costs and benefits
    to getting things right versus getting。
  prefs: []
  type: TYPE_NORMAL
- en: things wrong in a business context。 I'll give you an example in a minute。
  prefs: []
  type: TYPE_NORMAL
- en: This may influence how we think about building a effective machine learning
    algorithm。
  prefs: []
  type: TYPE_NORMAL
- en: When building an algorithm， there are a number of loss functions or cost functions
    which are。
  prefs: []
  type: TYPE_NORMAL
- en: the thing that the algorithm is trying to optimize。
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of things that one might try to optimize on。 These have names
    like accuracy。
  prefs: []
  type: TYPE_NORMAL
- en: precision， recall， specificity。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f040461bd947bde42f4b2188e5500659_3.png)'
  prefs: []
  type: TYPE_IMG
- en: Why are there so many？ Let's do an example。 Imagine there's an application that's
    meant to identify fraudulent credit card transactions。
  prefs: []
  type: TYPE_NORMAL
- en: It's been a popular application of machine learning in recent years。 So。
  prefs: []
  type: TYPE_NORMAL
- en: trying to identify fraudulent credit card transactions。 In this case。
  prefs: []
  type: TYPE_NORMAL
- en: you have the actual value you're trying to predict。
  prefs: []
  type: TYPE_NORMAL
- en: You have some training data which is a dataset where you have the right answers
    and you're。
  prefs: []
  type: TYPE_NORMAL
- en: trying to predict in a way that gets as close to those as possible in some way。
  prefs: []
  type: TYPE_NORMAL
- en: You have the actual values in the training data whether a transaction was fraudulent
    or。
  prefs: []
  type: TYPE_NORMAL
- en: whether it was legitimate。 Then you have the predicted value。
  prefs: []
  type: TYPE_NORMAL
- en: Whether it was fraudulent or legitimate as predicted by the algorithm。
  prefs: []
  type: TYPE_NORMAL
- en: The question is how do we compare these columns to decide whether we're going
    to do a good， job。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f040461bd947bde42f4b2188e5500659_5.png)'
  prefs: []
  type: TYPE_IMG
- en: Imagine we train the algorithm and it makes a number of predictions and we now
    have to judge。
  prefs: []
  type: TYPE_NORMAL
- en: is the classifier doing a good job。 This is a slightly more complicated question
    than it looks like because it depends on what。
  prefs: []
  type: TYPE_NORMAL
- en: we care about in this context from a cost and benefit perspective。
  prefs: []
  type: TYPE_NORMAL
- en: It's not just a matter of getting as many answers right as possible。 For example。
  prefs: []
  type: TYPE_NORMAL
- en: you might ask is it more costly to miss a fraudulent transaction。
  prefs: []
  type: TYPE_NORMAL
- en: So one decision you could make is don't mind getting some wrong。
  prefs: []
  type: TYPE_NORMAL
- en: I just never want to miss a fraudulent transaction。 On the other hand。
  prefs: []
  type: TYPE_NORMAL
- en: it might be the case that it's very costly to put a valuable customer's。
  prefs: []
  type: TYPE_NORMAL
- en: credit card on hold accidentally。 And so it turns out that optimizing on these
    two different types of things。
  prefs: []
  type: TYPE_NORMAL
- en: One being that you never miss a fraudulent transaction。
  prefs: []
  type: TYPE_NORMAL
- en: Another being that you never accidentally flag a legitimate transaction is being
    fraudulent。
  prefs: []
  type: TYPE_NORMAL
- en: These are competing in some ways and when you're building an algorithm you have
    to choose which。
  prefs: []
  type: TYPE_NORMAL
- en: is more costly which has higher benefit。 And these different term specificity
    precision recall are meant to capture the notion that。
  prefs: []
  type: TYPE_NORMAL
- en: there are different costs and benefits of getting different types of labels
    wrong in。
  prefs: []
  type: TYPE_NORMAL
- en: the prediction task。 And this matters for deciding how we train the algorithm
    and what we care about。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f040461bd947bde42f4b2188e5500659_7.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next section we'll talk about some of these specific loss functions how
    they're。
  prefs: []
  type: TYPE_NORMAL
- en: computed and when some of them might be more important than others。 [BLANK_AUDIO]。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f040461bd947bde42f4b2188e5500659_9.png)'
  prefs: []
  type: TYPE_IMG
