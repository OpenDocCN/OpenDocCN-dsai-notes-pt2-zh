- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P94：31_一些可解释AI的方法.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've talked about explainable AI being very important in some business context，
    HR being。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b802c127602b2cf5b15fd71dd232720_1.png)'
  prefs: []
  type: TYPE_IMG
- en: one of them， and again companies， government are all putting resources into
    developing。
  prefs: []
  type: TYPE_NORMAL
- en: approaches that are more explainable。 So let's talk about a few of these。
  prefs: []
  type: TYPE_NORMAL
- en: just to give you a flavor of how people are thinking， about some of these problems。
  prefs: []
  type: TYPE_NORMAL
- en: So we'll talk about a few。 One of them is called SHAP。
  prefs: []
  type: TYPE_NORMAL
- en: and what this method does is it looks at the different pieces。
  prefs: []
  type: TYPE_NORMAL
- en: of information that are going into the predictive model， the different features
    that are being。
  prefs: []
  type: TYPE_NORMAL
- en: used to make the prediction。 And the output it will tell you essentially how
    much each feature is contributing to the。
  prefs: []
  type: TYPE_NORMAL
- en: prediction。 So imagine you have a bunch of pieces of information about an applicant
    you're making or an employee。
  prefs: []
  type: TYPE_NORMAL
- en: in the firm trying to make a decision about that employee， and it makes a decision。
  prefs: []
  type: TYPE_NORMAL
- en: It can then tell you how much each of the things， each of the pieces of information
    that have。
  prefs: []
  type: TYPE_NORMAL
- en: access to matters for the final decision that it made。 Another example called
    LIME。
  prefs: []
  type: TYPE_NORMAL
- en: what this basically does is it can start with a model that's very。
  prefs: []
  type: TYPE_NORMAL
- en: complex and very difficult to interpret or explain。
  prefs: []
  type: TYPE_NORMAL
- en: But what it can do is generate a simpler comparison that's accurate for people
    that look similar。
  prefs: []
  type: TYPE_NORMAL
- en: to the candidate in question。 So this type of approach might say。
  prefs: []
  type: TYPE_NORMAL
- en: it might be for a very complex model that as a whole。
  prefs: []
  type: TYPE_NORMAL
- en: is not interpretable across all of the people that is being used on。
  prefs: []
  type: TYPE_NORMAL
- en: But it might say that if I compare employee X to employee Y who's actually very
    similar。
  prefs: []
  type: TYPE_NORMAL
- en: but differ in this way， then we can create a simpler explanation that can work
    to explain。
  prefs: []
  type: TYPE_NORMAL
- en: what the differences are between these two that led to a decision for one versus
    another。
  prefs: []
  type: TYPE_NORMAL
- en: So it creates a simpler model that's locally accurate even if the whole model，
    the global。
  prefs: []
  type: TYPE_NORMAL
- en: model is relatively difficult to explain。 Another approach using surrogate trees。
  prefs: []
  type: TYPE_NORMAL
- en: this approach generates a simpler model that mimics。
  prefs: []
  type: TYPE_NORMAL
- en: the performance of the more complex model but is easy to interpret。
  prefs: []
  type: TYPE_NORMAL
- en: We talked about the idea that there are some types of models like decision trees
    that are。
  prefs: []
  type: TYPE_NORMAL
- en: fundamentally easy to interpret。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b802c127602b2cf5b15fd71dd232720_3.png)'
  prefs: []
  type: TYPE_IMG
- en: And so a surrogate tree approach might do is use a simpler model that behaves
    much like。
  prefs: []
  type: TYPE_NORMAL
- en: the more complex model in most， along most dimensions。
  prefs: []
  type: TYPE_NORMAL
- en: Maybe not 100% but along most dimensions but it's much easier to interpret。
  prefs: []
  type: TYPE_NORMAL
- en: So these two can be used in tandem to achieve some of the benefits of prediction
    but also。
  prefs: []
  type: TYPE_NORMAL
- en: some of the benefits of explanation。 And then there are new techniques emerging
    like auto encoders that basically take the。
  prefs: []
  type: TYPE_NORMAL
- en: data and boil them down to a smaller set of features that make the model output
    easier。
  prefs: []
  type: TYPE_NORMAL
- en: to interpret in terms of what it's using to make forward predictions。
  prefs: []
  type: TYPE_NORMAL
- en: These are just a number of different approaches that companies are investing
    in learning more。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b802c127602b2cf5b15fd71dd232720_5.png)'
  prefs: []
  type: TYPE_IMG
- en: about building up better technologies and tools that kind of achieve that sweet
    spot。
  prefs: []
  type: TYPE_NORMAL
- en: or try to achieve that sweet spot between having a model that's highly predictive
    but。
  prefs: []
  type: TYPE_NORMAL
- en: also that is explainable。 And so a number of initiatives from companies like
    IBM。
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft and others， they're putting， in a lot of energy into developing solutions
    and platforms that allow companies to use。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b802c127602b2cf5b15fd71dd232720_7.png)'
  prefs: []
  type: TYPE_IMG
- en: AI in a more explainable way。 Thank you。 [BLANK_AUDIO]。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b802c127602b2cf5b15fd71dd232720_9.png)'
  prefs: []
  type: TYPE_IMG
