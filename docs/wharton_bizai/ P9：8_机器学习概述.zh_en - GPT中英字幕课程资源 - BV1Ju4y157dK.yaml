- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P9：8_机器学习概述.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hi again。 In this lecture， we'll talk about machine learning and the different
    types of。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: machine learning。 The machine learning， as I mentioned， is a sub-field of artificial，
    intelligence。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: It's mostly focused on how do we get computers to learn from data without。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: explicitly programming them。 And they're often used for prediction tasks。 For
    example， we。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_3.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: might have data on past credit card transactions。 We might be interested in
    predicting whether。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: a new transaction is fraudulent or not。 So we might look at past data in order
    to make。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: this decision。 Or we might be interested in determining whether an email is
    spam or not。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: based on past data。 We might be looking at a task of analyzing images for a
    driverless。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: car and figuring out whether the object in front of a car is another vehicle
    or a person。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: or a tree or something else。 We might be interested in recognizing speech and
    understanding speech。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: like with Alexa or Siri。 In short， there are many kinds of prediction tasks
    that use machine。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_5.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: learning。 And these have applications in a variety of industries ranging from
    healthcare。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: to finance to manufacturing to human resources and so on。 Now， it's important
    to understand。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_7.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: machine learning is not one single technique。 There are really a large set of
    techniques。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: all of which come under the umbrella of machine learning。 And in fact， there
    are many types。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: of machine learning。 For example， one way to think of machine learning is in
    terms of。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: supervised techniques， unsupervised techniques and reinforcement learning techniques。
    Supervised。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_9.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: learning is the idea of building a predictive model based on past data。 And
    these data have。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: clearly labeled input and output data。 For example， we might have data on emails
    in the。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: past and nice and clear labels on which of those past emails are spam emails
    and which。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: ones are not。 And we might then want to learn from it。 So this is a classification
    task which。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: is using past data which has nice labels of inputs and outputs to learn how
    to label future。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_11.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: data。 Unsupervised techniques in contrast have lot of input data， but you don't
    have clear。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: labels on output。 And so these techniques are finding patterns in the input
    data。 For， example。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: you might have anomaly detection， which is the idea of finding certain data
    points。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: that look like anomalies or in other words， they look different from all other
    data in， there。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Similarly， we talked about clustering previously， which is the idea of grouping
    a。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: set of data points into different groups such that data points within a group
    are as similar。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: to each other and data points in different groups are as different from each
    other。 So。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 彼此之间的数据点在不同组中是如何相互不同的。因此。
- en: this is based on data， but we don't have clearly labeled output that is guiding
    us on how best。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是基于数据，但我们没有明确标记的输出来指导我们如何最佳。
- en: to actually break up the data into different clusters。 And lastly， we have reinforcement。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上将数据分成不同的聚类。最后，我们有强化学习。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_13.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_13.png)'
- en: learning， which is the idea of having a machine learning system， acquire new
    data by taking。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 学习，这个想法是让机器学习系统通过获取新数据来获得。
- en: actions and looking at the data to learn and improve its future action。 And
    we will look。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 行动和观察数据以学习并改善其未来行动。我们将会看。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_15.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_15.png)'
- en: at each of these techniques in greater detail。 Let's start with supervised learning。
    As I mentioned。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细地看每一种技术。让我们从监督学习开始。正如我提到的。
- en: supervised learning is the idea of learning from data where you have cleanly
    labeled output。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的理念是从数据中学习，其中你有明确标记的输出。
- en: and labeled input。 The inputs can be referred to as features or as covariates
    and the outputs。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 并标记输入。这些输入可以称为特征或协变量，输出则是。
- en: are often called targets of the model。 This is what we're trying to predict。
    For example。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通常被称为模型的目标。这是我们试图预测的内容。例如。
- en: as I mentioned， we have email data and the output that we're trying to predict
    is whether。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我提到的，我们有邮件数据，而我们试图预测的输出是是否。
- en: an email is spam or not。 And the inputs or the features of the covariates are
    the actual。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一封邮件是垃圾邮件还是不是。输入或协变量的特征是实际的。
- en: text in the email。 And with supervised learning， the idea is that we have cleanly
    labeled pass。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 邮件中的文本。通过监督学习，想法是我们有明确标记的通过。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_17.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_17.png)'
- en: '![](img/02c421482ce67aea3031900e6e9478d5_18.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_18.png)'
- en: data， which have a correct answer， meaning that certain data have been labeled
    as spam。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 数据，这些数据有正确的答案，意味着某些数据已被标记为垃圾邮件。
- en: and certain other data has been labeled as not being spam。 And now we need to
    learn how to。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 某些其他数据已被标记为不是垃圾邮件。现在我们需要学习如何。
- en: classify future emails。 Similarly， you might have a desire to predict sales
    next week based on。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对未来的电子邮件进行分类。同样，你可能希望根据预测下周的销售。
- en: historical data。 And we might use data on the season， the month of the year，
    the weather， and。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 历史数据。我们可能会使用关于季节、年份月份、天气的数据等。
- en: other such patterns to predict future sales。 And our training data is actually
    past data， which has。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 其他模式来预测未来销售。我们的训练数据实际上是过去的数据，这些数据。
- en: all these patterns， month， season， weather， and also the actual sales that were
    realized in the past。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些模式，月份、季节、天气，以及过去实现的实际销售。
- en: And now we're trying to make predictions in the future based on that。 Let's
    look at another example。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正试图根据这些数据进行未来的预测。我们来看另一个例子。
- en: of supervised learning。 In a recent research study。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的案例。在最近的一项研究中。
- en: my colleagues and I were interested in analyzing， social media posts posted
    by a number of companies on Facebook。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我同事和我对分析一些公司在Facebook上发布的社交媒体帖子感兴趣。
- en: So we gathered data on over 100，000 posts， submitted by large brands on Facebook。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们收集了超过100,000条由大型品牌在Facebook上提交的帖子的数据。
- en: And we wanted to identify what kinds of posts are， associated with the highest
    engagement。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要识别与最高参与度相关的帖子类型。
- en: that is our emotional posts associated with greater。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那是我们情感帖子与更大关联。
- en: engagement or humorous posts or posts that show deals and promotions to consumers
    or other kinds。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 参与度或幽默帖子，或向消费者展示交易和促销的帖子或其他类型。
- en: of posts。 Now it is very expensive to tag 100，000 posts and label each post
    as being humorous or not。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 帖子的内容。现在，标记100,000条帖子并标记每条帖子是否幽默是非常昂贵的。
- en: emotional or not， or as offering a price discount or not， and so on。 So we wanted
    to automate this。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 情感或不情感，或是否提供价格折扣，等等。因此，我们希望自动化这一过程。
- en: process。 So we use a supervised machine learning technique to do that。 To do
    that， we first need。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 过程。因此，我们使用监督机器学习技术来做到这一点。为此，我们首先需要。
- en: data， a training data set that has clearly labeled inputs and outputs。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据，一个有明确标记的输入和输出的训练数据集。
- en: The inputs are available to us。 These are the words the companies use in their
    posts。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 输入对我们是可用的。这些是公司在其帖子中使用的词。
- en: The output is essentially a label that says， whether the post is emotional or
    humorous or not。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输出本质上是一个标签，用来说明帖子是情感性的、幽默的还是其他。
- en: And so to do that， we took a sample of 5，000 posts， and had human beings label
    each of these posts。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们抽取了5,000个帖子样本，并让人类对这些帖子进行标记。
- en: Every one of these 5，000 posts was labeled by a。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这5,000个帖子中的每一个都由一位。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_20.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_20.png)'
- en: human being as being humorous or emotional or as offering a price discount or
    being a post that。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 被人类标记为幽默、情感性的，或者提供价格折扣的帖子。
- en: shares a remarkable fact and so on。 These labels were then used as a training
    data set for a。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 分享了一个显著的事实等等。这些标签随后被用作训练数据集。
- en: supervised machine learning algorithm that learned what kinds of words are predictive
    of whether a。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 学习了哪些词汇能够预测帖子是。
- en: post is emotional or humorous or not。 And then that algorithm was used to make
    predictions for。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 帖子是情感性的或幽默的，然后该算法用于进行预测。
- en: the remaining nearly 100，000 posts that hadn't been labeled by a human being。
    This is essentially。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的近100,000个帖子没有被人工标记。这本质上是。
- en: the idea of supervised machine learning， which is you need a training data set
    and you learn from that。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习的理念，即你需要一个训练数据集，并从中学习。
- en: and you apply that to future data。 And what we found in our study was that our
    machine learning。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将其应用于未来的数据。在我们的研究中发现，我们的机器学习。
- en: algorithm did well and often had accuracy of over 90， 95 percent and sometimes
    even greater than 99。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 算法表现良好，准确率通常超过90%，95%，有时甚至超过99%。
- en: percent in essentially being able to predict whether a post is humorous or whether
    a post is。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在能够预测帖子是幽默的或不是幽默的方面的准确率是百分之。
- en: emotional or not。 And in any business application， if you have good high quality
    training data set。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 是情感性的或非情感性的。在任何商业应用中，如果你有高质量的训练数据集。
- en: one can apply these techniques in order to make predictions about the future。
    The key is collecting。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 可以应用这些技术来预测未来。关键在于数据的收集。
- en: high quality data。 And that is the most important activity in supervised machine
    learning。
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 高质量数据。这是监督机器学习中最重要的活动。
- en: There are。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_22.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_22.png)'
- en: a number of very good high quality off the shelf algorithms that can be applied
    to make predictions。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一些非常优秀的现成算法可以应用于预测。
- en: if you've got high quality training data set for machine learning。 The next
    set of machine learning。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有高质量的机器学习训练数据集。下一组机器学习。
- en: techniques are unsupervised learning techniques。 Unsupervised learning techniques
    also take in data。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术是无监督学习技术。无监督学习技术也会接收数据。
- en: but they don't have clearly labeled output。 So for example， clustering algorithms
    that we。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 但它们没有明确标记的输出。例如，我们使用的聚类算法。
- en: discussed previously， they tend to cluster our data into different groups， but
    they're not told。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，它们倾向于将我们的数据聚类到不同的组中，但没有被告知。
- en: in advance to what the ideal clustering looks like， meaning there is no labeled
    output for them。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 事先对理想聚类的理解，即它们没有标记的输出。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_24.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_24.png)'
- en: Similarly， another example is anomaly detection。 Anomaly detection algorithms
    look at a bunch of。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，另一个例子是异常检测。异常检测算法查看一系列。
- en: data and identify data points that look dissimilar to most of the other data。
    Here again， there's a。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并识别出与其他数据看起来不同的数据点。在这里再次，有一个。
- en: lot of input data， but there's no clearly labeled output。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 有大量输入数据，但没有明确标记的输出。
- en: Another example is latent Dirichlet allocation， or LDA。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是潜在的狄利克雷分配（LDA）。
- en: which is a commonly used technique for topic modeling， meaning identifying what
    kinds of。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个常用的主题建模技术，意指识别出哪些类型的。
- en: topics a certain document might cover。 Typically， with LDA， you have an input
    data set which。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 某个文档可能涵盖的主题。通常，对于LDA，你会有一个输入数据集。
- en: consists of a large set of documents。 The idea behind LDA is that each document
    likely covers。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由大量文档组成。LDA背后的想法是每个文档可能涵盖。
- en: a small set of topics， and each topic itself tends to use the same set of words
    quite frequently。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一小组主题，每个主题往往会频繁使用相同的词汇。
- en: So for example， we might take a large data set of new stories published in all
    of the major。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可能会拿一个大型数据集，包含所有主要发布的新故事。
- en: newspapers and online news media outlets and feed that as an input to an LDA
    algorithm。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 报纸和在线新闻媒体，并将其作为输入提供给LDA算法。
- en: And LDA is trying to identify the topics that these documents cover， but is
    not given。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: LDA试图识别这些文档所涵盖的主题，但并没有被给定。
- en: clearly labeled outputs， meaning that the algorithm is not told that here's
    a document on politics and。
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 清晰标记的输出，意味着算法并未被告知这是关于政治的文档。
- en: here's a document on sports and so on。 LDA， as I said， assumes that each document
    covers very few。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于体育的文档，等等。正如我所说，LDA假设每个文档涵盖非常少的。
- en: topics and each topic has a few words that it uses frequently。 And when it takes
    a training。
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 每个主题都有几个频繁使用的词。当它接受一个训练。
- en: data set or an input data set rather， LDA might identify that a certain topic
    tends to use certain。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集或输入数据集时，LDA可能会识别出某个主题倾向于使用特定的。
- en: words quite frequently。 For example， it might say that here's a topic that tends
    to use the word。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 词频繁出现。例如，它可能会说这是一个倾向于使用该词的主题。
- en: Obama， the word Trump， the word speech， and a few other such words quite frequently，
    but it does。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 奥巴马、特朗普、演讲等词频繁出现，但它并不会。
- en: not tend to use words like pizza or baseball as frequently。 This clearly， we
    can infer is the topic。
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 不会像比萨或棒球那样频繁使用这些词。这显然，我们可以推断出这是主题。
- en: of politics， and that's something that the algorithm identifies on its own。
    Now， given any document。
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 政治的主题，而这是算法自己识别出的内容。现在，给定任何文档。
- en: LDA then looks at the kinds of words that are used in this document and identifies
    which topics。
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: LDA查看文档中使用的词的种类，并识别出哪些主题。
- en: it covers。 So given a document， LDA might say that a topic covers sports or
    a topic covers politics。
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 它所涵盖的主题。因此，给定一个文档，LDA可能会说某个主题涵盖体育或某个主题涵盖政治。
- en: and so on。 Once LDA has been trained using a large data set。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 等等。一旦LDA使用大型数据集进行训练。
- en: it can now be applied to any new document。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 它现在可以应用于任何新文档。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_26.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c421482ce67aea3031900e6e9478d5_26.png)'
- en: and it can automatically classify these documents and identify the topics in
    there。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以自动对这些文档进行分类，并识别出其中的主题。
- en: So in this example， you see a passage that LDA might analyze and it looks at
    certain words that are used in this document。
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，你可以看到一个LDA可能分析的段落，它查看文档中使用的某些词。
- en: And with each of these words， it identifies certain topics that these words
    are related to。
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些词，它识别出这些词相关的特定主题。
- en: For example， arts or education or children and then it identifies a set of topics
    that this document。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，艺术、教育或儿童，然后识别出该文档所涉及的一组主题。
- en: covers。 Now in addition to unsupervised learning， we also have this idea of
    reinforcement learning。
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在除了无监督学习，我们还有强化学习的概念。
- en: Reins enforcement learning usually does not take in large training datasets。
    Rather。
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习通常不需要大型训练数据集。相反。
- en: the algorithm learns by testing or trying various actions or strategies and
    observing what happens。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 算法通过测试或尝试各种行为或策略，并观察发生了什么来学习。
- en: and using those observations to learn something。 This is a very powerful method
    and has been used。
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些观察来学习一些东西。这是一种非常强大的方法，已经被广泛使用。
- en: in a number of robotics based applications。 It is also at the heart of a software
    created by。
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在多种基于机器人应用中也有应用。它也是由某家公司创建的软件的核心。
- en: Google which was called Alpha Zero which was an advanced version of Google's
    Go Playing Software。
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Google开发的一个称为Alpha Zero的围棋软件的高级版本。
- en: Alpha Go。 Alpha Go had used training dataset which was based on past Go games
    and Alpha Zero had no。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Alpha Go。Alpha Go使用的训练数据集基于过去的围棋比赛，而Alpha Zero没有。
- en: training dataset。 Instead， it learned the game of Go by playing Go against itself
    and once it played。
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集。相反，它是通过与自己对弈学习围棋的，一旦它进行了。
- en: millions of games against itself， that was in fact the training dataset that
    it used to develop。
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 数百万局自我对弈，这实际上是它用来发展的训练数据集。
- en: the best strategies for this game。 Of course， in many settings， experimentation
    isn't always free。
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这个游戏的最佳策略。当然，在许多场景中，实验并不总是免费的。
- en: and so you have to balance the cost of experimentation against exploiting the
    knowledge that we already。
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你必须平衡实验的成本与利用我们已有知识之间的关系。
- en: have。 Let's explore that through a reinforcement learning algorithm known as
    multi-armed bandit。
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个称为多臂强盗的强化学习算法来探讨这一点。
- en: To illustrate how bandit algorithms work， let's consider setting where you have
    two different。
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明强盗算法的工作原理，我们考虑一个有两个不同选择的场景。
- en: '![](img/02c421482ce67aea3031900e6e9478d5_28.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
- en: ad copies that we have designed and that we would like to try with our customers。
    We do not know。
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: which ad copy is more effective in engaging customers and attracting them to
    click on the ad。
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: We would like to ideally figure out which ad is the better ad to use。 One way
    to figure this out。
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: is to do what is known as A/B testing。 That is， we might show ad A to half the
    users and ad B to half。
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: the users and we might do this for some period of time， let's say a day。
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: then we observe which ad has， the higher click through rate and we might use
    that ad there on。
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: In this graph that you see on this， slide we have two ads， ad A and ad B。
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Ad A has a click through rate of 5% and ad B has a click through。
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: rate of 10% but we do not know this in advance。 So what we might end up doing
    is show ad A to some。
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: users and show ad B to some users。 If we have shown these ads in a randomized
    fashion to a large。
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: number of users， over time we learned that ad A has 5% click through rate。
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: ad B has 10% click through， rate and then we can use ad B from that point onwards。
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: But there is a cost of this learning because， some people were shown ad A and
    some people were shown ad B during this learning step。
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: the average click through rate that our ads experienced with 7。5% which is lower
    than we would。
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: have obtained if we had chosen the better performing ad。
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Now a banded algorithm can do better and it。
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_30.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: '![](img/02c421482ce67aea3031900e6e9478d5_31.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: can improve performance。 The way it does this is that it starts off initially
    like any A/B testing。
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: algorithm meaning it shows ad A and ad B equal number of times but it starts
    to observe what is。
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: happening and is learning。 For example it starts to observe that ad B is doing
    better than ad A。
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: and as it learns this it starts to show ad B more frequently than ad A。 It still
    will show ad A。
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: a few times so it still allows itself to learn and correct itself in case ad
    A actually will。
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: perform better。 But over time it starts to weigh ad B more and more and as a
    result if you observe at。
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: the end of a day or in this example at the end of a thousand sessions this ad
    which used a banded。
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: algorithm based allocation strategy ended up having a click through rate that
    was much higher than 7。
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 5%， that we obtained through A/B testing it was not quite equal to the 10% that
    ad B has but it's close。
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: enough because what it's able to do is it's able to experiment and learn and
    exploit that knowledge to。
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02c421482ce67aea3031900e6e9478d5_33.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
- en: also improve the outcomes。 So in short a reinforcement learning algorithm is
    essentially an algorithm。
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: that takes actions observe what happens and then improves its performance over
    time。
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: It's my pleasure to see you again。
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
