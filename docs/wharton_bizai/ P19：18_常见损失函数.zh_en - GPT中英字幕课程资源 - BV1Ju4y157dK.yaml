- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P19：18_常见损失函数.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's talk about some of the more common ways to measure error in machine learning
    output。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee32926febee5fe618fb5c24bb11950c_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Perhaps the simplest one to understand is accuracy。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: So let's go back to our example where we're thinking about fraudulent and legitimate
    transactions。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: So in one column we might have the actual true values of whether a transaction
    was legitimate。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: or fraudulent。 In another column we have the predicted value。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: our machine learning output of whether a transaction， was fraudulent or legitimate。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy simply indicates the fraction of times that we get the answer right。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: So it's basically comparing across the two columns and it's the fraction of
    times that。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: the one column matches the other column。 So that's accuracy。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Classification error is the inverse of that。 So it's basically the fraction
    of times that the two columns don't match。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: So that's accuracy。 Another common metric is precision。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Precision is asking what proportion of positive identifications were actually
    correct。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: So what's a positive identification？ So with machine learning output with a
    binary classifier is trying to predict whether something。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: is in one of two classes like legitimate or fraudulent。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: One of these two classes is indicated as positive。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: One is going to be a one so to speak and one is zero。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: So we might identify if fraudulent is the positive class in this case。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: What precision indicates is what proportion of the ones that we actually call
    fraudulent。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: are actually fraudulent。 So if we have a number of predictions that are fraudulent
    we're going to look at how。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: many of those， what fraction of those we got correct。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: And this in a sense ignores some other aspects of the data or the performance。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: It's basically looking at this particular piece， this particular measure of
    how often。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: what we called fraudulent was actually a fraudulent case。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Sensitivity is a different way of looking at the performance of machine learning
    output。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: So in this case this is looking at how many relevant instances did you catch？
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: So think about these two different columns here， the actual values and the predicted
    value。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: So if the actual values are legitimate， fraudulent， what sensitivity is asking
    is how many of the。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: fraudulent cases did you catch？ Did you let any of them slip through your net
    or were you able to get most of them？
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: So sensitivity， a highly sensitive classifier is basically one that lets very
    few of the。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: relevant instances， the actually fraudulent transactions slipped through its
    net。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: So it's looking at something quite different from precision。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Specificity is looking at the proportion of legitimate transactions in this
    case， the。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: negative case that were correctly identified as such。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: So of those transactions that were legitimate that were not fraudulent， how
    many of those。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee32926febee5fe618fb5c24bb11950c_3.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: were correctly identified。 So again， specificity， precision， accuracy。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: they're all looking at different aspects of， what you're getting right and wrong
    in terms of your prediction。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: When you're talking about using one of these versus the other to think about
    evaluating。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: machine learning output， which we're implicitly doing is putting different weights
    on what。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: you care about， whether it's more important to make sure， for instance， that
    you never。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: miss a fraudulent transaction or whether it's more important， for instance，
    to make sure。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: that you never accidentally call a legitimate transaction fraudulent。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: These are the different trade-offs when thinking about these different measures。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: And there's a variety of ways to think about which are used when。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: There's language that's used around the different costs of using one versus
    the other。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: You might hear about true positives， true negatives， false positives and false
    negatives。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: True positives and true negatives are how many you get correct or how many of
    the identifications。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: you get correct。 True positive is the fraction of times that you identify something
    in the positive class。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: in this case fraudulent as being fraudulent。 For a true negative is the fraction
    of times we identify legitimate as being a legitimate。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: transaction。 So true positives and true negatives together basically indicate
    the number of times or the。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: fraction of times we're getting something right。 False positives and false negatives
    refer to the errors and these are things that often。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: come with costs。 And so false positives and false negatives are two different
    kinds of errors that may。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: involve two different kinds of costs。 False positives are the fraction of times
    that we identify。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: for instance， something as， legitimate as fraudulent。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: False negatives is a fraction of times we identify something as fraudulent as
    legitimate。 So again。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: depending on whether it's more costly to miss a fraudulent transaction or。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: whether it's more costly to accidentally flag something legitimate as fraudulent，
    these。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: map to false positives and false negatives and the different costs。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: And depending on what we care about from a business context， we may want to
    optimize one。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee32926febee5fe618fb5c24bb11950c_5.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: versus the other。 There are a number of ways to represent these， to visualize
    these。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: to communicate these， to， different stakeholders。 One of these is called a confusion
    matrix。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: A confusion matrix is essentially a two by two matrix that lays out for a given
    case the。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: number of true positives， false positives， true negatives and false negatives。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee32926febee5fe618fb5c24bb11950c_7.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: Another popular way to represent machine learning output is called an ROC curve
    or。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: receiver operating characteristic curve。 And this maps false positives against
    true positives in a way that indicates essentially。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: what the trade-offs are between those two metrics。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee32926febee5fe618fb5c24bb11950c_9.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: These are some common loss functions。 We've defined them。 In the next video。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些常见的损失函数。我们已经定义了它们。在下一个视频中。
- en: let's talk about when it might be that some of them are preferable to， others。
    [BLANK_AUDIO]。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下在什么情况下它们中的某些函数可能比其他函数更可取。[BLANK_AUDIO]。
- en: '![](img/ee32926febee5fe618fb5c24bb11950c_11.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee32926febee5fe618fb5c24bb11950c_11.png)'
