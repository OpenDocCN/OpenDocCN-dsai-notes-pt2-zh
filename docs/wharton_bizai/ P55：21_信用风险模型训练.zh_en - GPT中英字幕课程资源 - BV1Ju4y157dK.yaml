- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P55：21_信用风险模型训练.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Okay， so now let's train our model。 Let's estimate it and see how it does on
    our training data。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d520fbd95e3f73aa780f77413b8cf7d_1.png)'
  prefs: []
  type: TYPE_IMG
- en: I'm going to use a logit model， which is a relatively elementary model。
  prefs: []
  type: TYPE_NORMAL
- en: to try and predict speculative grade and investment grade outcomes in our training
    data。
  prefs: []
  type: TYPE_NORMAL
- en: training sample。 And the table I'm showing you on the screen is something called
    the confusion matrix。
  prefs: []
  type: TYPE_NORMAL
- en: It's exactly what we spoke about in previous videos。
  prefs: []
  type: TYPE_NORMAL
- en: but these are the actual results from the model。 So remember。
  prefs: []
  type: TYPE_NORMAL
- en: the rows correspond to actual observations in the data。
  prefs: []
  type: TYPE_NORMAL
- en: the columns correspond to predictions from the model， a logit model in this
    case。
  prefs: []
  type: TYPE_NORMAL
- en: There are in total 8，432 observations in our training data。 And those 8。
  prefs: []
  type: TYPE_NORMAL
- en: 432 observations are allocated to these four different possible outcomes， in
    the following manner。
  prefs: []
  type: TYPE_NORMAL
- en: Now， the accurate predictions are along the diagonal。 So when a firm is actually
    expected of。
  prefs: []
  type: TYPE_NORMAL
- en: struggling today is actually speculative grade， and we predict speculative grade
    for that firm。
  prefs: []
  type: TYPE_NORMAL
- en: we're right 3，181 times。 Similarly， when a firm is investment grade。
  prefs: []
  type: TYPE_NORMAL
- en: and we predict its investment grade， we're right 3，330 times。 We're wrong just
    under 1。
  prefs: []
  type: TYPE_NORMAL
- en: 000 times in both cases。 So when we have an investment grade firm in the data。
  prefs: []
  type: TYPE_NORMAL
- en: but we predict speculative grade that happens 959 times。
  prefs: []
  type: TYPE_NORMAL
- en: and similarly for firms that are speculative grade。
  prefs: []
  type: TYPE_NORMAL
- en: but we predict investment grade that's 962 times。 And I've tallied up the row
    and column sums around the periphery of the table。
  prefs: []
  type: TYPE_NORMAL
- en: So I always find the confusion matrix to be， not confusing。
  prefs: []
  type: TYPE_NORMAL
- en: that's what you thought I was going to say， but I always find it to sort of
    be the basis for other statistics。
  prefs: []
  type: TYPE_NORMAL
- en: that I think are more informative。 And so I'm going to convert everything here
    to probabilities。
  prefs: []
  type: TYPE_NORMAL
- en: In particular， I'm going to take each number， let me go back。
  prefs: []
  type: TYPE_NORMAL
- en: I'm going to take each one of these numbers and divide it by 8432。
  prefs: []
  type: TYPE_NORMAL
- en: to get these four numbers in the middle of the matrix right here。 And then I'm
    going to， again。
  prefs: []
  type: TYPE_NORMAL
- en: compute the column sums and the row sums。 So these numbers are telling me probabilities。
  prefs: []
  type: TYPE_NORMAL
- en: which I think are a little bit easier to interpret。 So we are getting。
  prefs: []
  type: TYPE_NORMAL
- en: we are predicting speculative grade firms correctly， 37。7% of the time。
  prefs: []
  type: TYPE_NORMAL
- en: investment grade 39% of the time。 So we， our model has a score， a model score。
  prefs: []
  type: TYPE_NORMAL
- en: excuse me if you will， of 77。2%。 We are accurately classifying speculative grade。
  prefs: []
  type: TYPE_NORMAL
- en: and investment grade observations 77。2% of the time。 Now is that good？ Is that
    bad？ Again。
  prefs: []
  type: TYPE_NORMAL
- en: it depends upon how costly these errors are， right？ We've got 22。
  prefs: []
  type: TYPE_NORMAL
- en: 8% of the time we are making a mistake， but certainly this is significantly
    better than if we just flipped a coin。
  prefs: []
  type: TYPE_NORMAL
- en: in which case we'd have somewhere around a 50% accuracy score。
  prefs: []
  type: TYPE_NORMAL
- en: given the balanced nature of the data。 Half the， almost half the data is investment
    grade。
  prefs: []
  type: TYPE_NORMAL
- en: half a speculative grade。 So the model is actually doing well relative to that
    benchmark。
  prefs: []
  type: TYPE_NORMAL
- en: but we are making quite a few errors here。 Now， something I wanted to do in
    light of a previous discussion。
  prefs: []
  type: TYPE_NORMAL
- en: we had in an earlier video， is I wanted to see what happens。
  prefs: []
  type: TYPE_NORMAL
- en: if I drop a bunch of what I'll call redundant variables， right？ Originally，
    we have， in this model。
  prefs: []
  type: TYPE_NORMAL
- en: there are 11x variables going into predict this outcome。 What happens if I get
    rid of seven of them？
  prefs: []
  type: TYPE_NORMAL
- en: And I just focus on the current ratio， interest coverage， debt to EBITDA and
    debt to assets ratios。
  prefs: []
  type: TYPE_NORMAL
- en: In other words， I picked one from the liquidity coverage， and two from the leverage
    ratio category。
  prefs: []
  type: TYPE_NORMAL
- en: How well would that model do with only four input variables relative to the
    one with all of them？
  prefs: []
  type: TYPE_NORMAL
- en: And so here's the probability confusion matrix。 The model score in this case
    is lower， it's 76。5%。
  prefs: []
  type: TYPE_NORMAL
- en: but it's only 0。7% worse， than the model with 11 variables。 So， you know。
  prefs: []
  type: TYPE_NORMAL
- en: is that an important difference？ It may be。 That might be， that 0。7% might be
    very costly。
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand， we've got a very parsimonious model， a nice small compact
    model。
  prefs: []
  type: TYPE_NORMAL
- en: that is perhaps more likely to predict better out of sample than the larger。
  prefs: []
  type: TYPE_NORMAL
- en: more highly parameterized model with the 11 inputs。 I mean。
  prefs: []
  type: TYPE_NORMAL
- en: it doesn't cost us computationally to have the 11 variables versus the four。
  prefs: []
  type: TYPE_NORMAL
- en: but I am thinking in terms of overfitting on the sample and out of sample prediction。
  prefs: []
  type: TYPE_NORMAL
- en: when I moved to this more parsimonious model。 And in some sense。
  prefs: []
  type: TYPE_NORMAL
- en: it's not surprising that it does nearly as well， given the high correlations
    within each of the credit KPI groups。
  prefs: []
  type: TYPE_NORMAL
- en: liquidity coverage and leverage ratios。 The last thing I want to talk about
    in this video are some additional metrics at which we can look。
  prefs: []
  type: TYPE_NORMAL
- en: right？ We've sort of got some rich data here in terms of the actual and predicted
    outcomes。
  prefs: []
  type: TYPE_NORMAL
- en: On the model score， but there's some additional metrics that pop up， quite often。
  prefs: []
  type: TYPE_NORMAL
- en: especially in binary classification。 The notion of precision。
  prefs: []
  type: TYPE_NORMAL
- en: which is the probability of a true positive conditional on a positive， prediction。
    That is。
  prefs: []
  type: TYPE_NORMAL
- en: what is the probability of accurately classifying investment grade firms。
  prefs: []
  type: TYPE_NORMAL
- en: conditional on predicting that the observation was investment grade？
  prefs: []
  type: TYPE_NORMAL
- en: And you can actually get at this number， which is 76。5%， by taking the number
    of true positive。
  prefs: []
  type: TYPE_NORMAL
- en: outcomes， conditional on the total number of predicted positive outcomes。
  prefs: []
  type: TYPE_NORMAL
- en: Recall is the probability of a true positive outcome。
  prefs: []
  type: TYPE_NORMAL
- en: but this time conditional on the actual outcome， not the predicted outcome。
  prefs: []
  type: TYPE_NORMAL
- en: So I would take the number of accurately classified investment grade outcomes
    and divide。
  prefs: []
  type: TYPE_NORMAL
- en: them by the total number of investment grade observations in the data to get
    the recall。
  prefs: []
  type: TYPE_NORMAL
- en: in this case， 77。6%。 Now， there's a trade-off between precision and recall。
    If you improve on one。
  prefs: []
  type: TYPE_NORMAL
- en: you're going to do worse on another。 There's this push-pull tension between，
    the two。
  prefs: []
  type: TYPE_NORMAL
- en: And so there's this additional metric called an F1 score， which is just。
  prefs: []
  type: TYPE_NORMAL
- en: a fancy name or non-fancy name for what's called a harmonic mean。
  prefs: []
  type: TYPE_NORMAL
- en: just a weighted average of precision， and recall， which turns out to be about
    77。1%。 Look。
  prefs: []
  type: TYPE_NORMAL
- en: these are just other measures of which to be， aware。
  prefs: []
  type: TYPE_NORMAL
- en: and which one is more or less important depends upon what exactly you're trying
    to predict。
  prefs: []
  type: TYPE_NORMAL
- en: So just some closing thoughts to bring this all together。
  prefs: []
  type: TYPE_NORMAL
- en: Once we've got our model and it's predicting。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d520fbd95e3f73aa780f77413b8cf7d_3.png)'
  prefs: []
  type: TYPE_IMG
- en: we want to inspect its confusion matrix， the probability version of the confusion
    matrix。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d520fbd95e3f73aa780f77413b8cf7d_5.png)'
  prefs: []
  type: TYPE_IMG
- en: the model score。 But ultimately， whether we look at precision， recall， F1 score。
  prefs: []
  type: TYPE_NORMAL
- en: or just one specific， number in the confusion matrix， again， always depends
    upon our goal。
  prefs: []
  type: TYPE_NORMAL
- en: the cost of making different， types of errors， et cetera。
  prefs: []
  type: TYPE_NORMAL
- en: So it's critical that at the outside of the outside of this whole exercise。
  prefs: []
  type: TYPE_NORMAL
- en: we have a very clear goal in mind， which is what the scientific method is really
    trying to force。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d520fbd95e3f73aa780f77413b8cf7d_7.png)'
  prefs: []
  type: TYPE_IMG
- en: you to do。 Pin down and clearly articulate a specific question， have some hypotheses
    that you。
  prefs: []
  type: TYPE_NORMAL
- en: can take to the data to try and answer or goal you're trying to accomplish。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d520fbd95e3f73aa780f77413b8cf7d_9.png)'
  prefs: []
  type: TYPE_IMG
- en: '[BLANK_AUDIO]。'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d520fbd95e3f73aa780f77413b8cf7d_11.png)'
  prefs: []
  type: TYPE_IMG
