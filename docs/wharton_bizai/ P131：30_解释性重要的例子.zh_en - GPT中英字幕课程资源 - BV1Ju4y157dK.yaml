- en: 沃顿商学院《AI For Business（AI用于商业：AI基础／市场营销+财务／人力／管理）》（中英字幕） - P131：30_解释性重要的例子.zh_en
    - GPT中英字幕课程资源 - BV1Ju4y157dK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So explainability， again， is the ability to explain or understand why an algorithm
    arrives。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f508e338ab31d54d28cfa1b890e6589b_1.png)'
  prefs: []
  type: TYPE_IMG
- en: at a particular decision。 Why is it so important？ So let's talk about some examples
    of where explainability in algorithms may be particularly。
  prefs: []
  type: TYPE_NORMAL
- en: important。 One example is when applied to areas like medicine or HR where the
    decisions are being made on。
  prefs: []
  type: TYPE_NORMAL
- en: people。 There are lots of protections and guidelines around how those decisions
    can be made。
  prefs: []
  type: TYPE_NORMAL
- en: So we have to think about how our algorithms fit into that kind of legal framework。
  prefs: []
  type: TYPE_NORMAL
- en: So consider HR where you have something like an equal employment opportunity
    commission。
  prefs: []
  type: TYPE_NORMAL
- en: guideline which governs hiring and the types of hiring firms can do。
  prefs: []
  type: TYPE_NORMAL
- en: There's certain HR practice that governs how HR decisions are made。 There's
    many laws in place。
  prefs: []
  type: TYPE_NORMAL
- en: And a lot of the HR legal framework requires being able to very clearly document
    how a。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f508e338ab31d54d28cfa1b890e6589b_3.png)'
  prefs: []
  type: TYPE_IMG
- en: decision is made。 It relates to promotions or hiring or dismissals or other
    hiring types of actions。
  prefs: []
  type: TYPE_NORMAL
- en: And so in instances like that， when you're using an algorithm for say HR， it
    is critical。
  prefs: []
  type: TYPE_NORMAL
- en: that you understand very clearly how that algorithm arrives at a decision so
    we can go back and。
  prefs: []
  type: TYPE_NORMAL
- en: revisit those decisions and make sure that they are in compliance with the legal
    framework。
  prefs: []
  type: TYPE_NORMAL
- en: that governs those decisions。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f508e338ab31d54d28cfa1b890e6589b_5.png)'
  prefs: []
  type: TYPE_IMG
- en: Another example is autonomous vehicle systems。 So another big application of
    AI is in self-driving cars。
  prefs: []
  type: TYPE_NORMAL
- en: Lots of complex data coming in。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f508e338ab31d54d28cfa1b890e6589b_7.png)'
  prefs: []
  type: TYPE_IMG
- en: Lots of decisions being made by vehicles on the road that are meant to be self-driving。
  prefs: []
  type: TYPE_NORMAL
- en: You can imagine if something goes wrong， if there's an accident or if somebody
    is injured。
  prefs: []
  type: TYPE_NORMAL
- en: in a self-driving vehicle context and it's very important for the company to
    be able to。
  prefs: []
  type: TYPE_NORMAL
- en: go back and understand exactly what went wrong， what led to the accident occurring，
    what needs。
  prefs: []
  type: TYPE_NORMAL
- en: to be fixed but also to be able to explain from a PR perspective what the problem
    was。
  prefs: []
  type: TYPE_NORMAL
- en: where it arose。 And for that reason， among others， some of these vehicle companies。
  prefs: []
  type: TYPE_NORMAL
- en: the self-driving car， companies have become some of the leaders in efforts around
    explainable AI and making。
  prefs: []
  type: TYPE_NORMAL
- en: these frameworks more open and making them available to other companies。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f508e338ab31d54d28cfa1b890e6589b_9.png)'
  prefs: []
  type: TYPE_IMG
- en: Another example is with data privacy laws。 You may have heard of the GDPR general
    data protection regulation。
  prefs: []
  type: TYPE_NORMAL
- en: You may have heard of the CCPA， which is the California Act related to data
    privacy。
  prefs: []
  type: TYPE_NORMAL
- en: Some of these new privacy regulations， the GDPR， for instance， stipulate that
    when an algorithmic。
  prefs: []
  type: TYPE_NORMAL
- en: decision is made， the logic must be explainable to someone whom the decision
    pertains to。
  prefs: []
  type: TYPE_NORMAL
- en: So if a decision， an algorithmic decision is made on something that affects
    you， you。
  prefs: []
  type: TYPE_NORMAL
- en: have a right to ask for a meaningful explanation about the logic that was involved。
  prefs: []
  type: TYPE_NORMAL
- en: And that's only possible if the algorithm being used is an explainable algorithm。
  prefs: []
  type: TYPE_NORMAL
- en: And so we're thinking about using machine learning algorithms in a context that
    falls。
  prefs: []
  type: TYPE_NORMAL
- en: under the global data protection regulation in the EU， then the algorithms that
    are used。
  prefs: []
  type: TYPE_NORMAL
- en: there really need to be explainable。 So companies will be in compliance with
    that kind of legislation。
  prefs: []
  type: TYPE_NORMAL
- en: A final example is just in terms of customer service。
  prefs: []
  type: TYPE_NORMAL
- en: You think about financial lending or healthcare or other context for loan processing。
  prefs: []
  type: TYPE_NORMAL
- en: If you have customers coming in and you're using an algorithm to determine whether
    or。
  prefs: []
  type: TYPE_NORMAL
- en: not a customer meets the requirements for a loan or not， clearly it's something
    that you。
  prefs: []
  type: TYPE_NORMAL
- en: want to be able to explain， it's not sufficient to just say somebody fails or
    passes the screening。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f508e338ab31d54d28cfa1b890e6589b_11.png)'
  prefs: []
  type: TYPE_IMG
- en: test in terms of loan qualification。 You want to be able to reflect back exactly
    what it might have been that affected that。
  prefs: []
  type: TYPE_NORMAL
- en: type of decision。 So lots and lots of context， especially context where decisions
    are being made that affect。
  prefs: []
  type: TYPE_NORMAL
- en: humans directly where having the AI system be explainable is really critical
    for successful。
  prefs: []
  type: TYPE_NORMAL
- en: adoption。 [BLANK_AUDIO]。
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f508e338ab31d54d28cfa1b890e6589b_13.png)'
  prefs: []
  type: TYPE_IMG
