# 智源大会 2024（五）



# 2024北京智源大会-大模型前沿探索 - P5：大模型下的机器学习理论研究反思与机遇-黄 雷 - 智源社区 - BV1yS411A73A

[音樂]，喂 喂 喂，感謝李總和葉全博士的組織這次論壇，大家好 我是黃磊，來自北航人工智能研究院，現在是學院了，我的題目是，大模型下的機器學習理論研究，反思與機遇，給了這個題目的話大家在想。

大模型下到底有沒有理論，此人厲害 尤其是機器學習的理論，因為如果大家去聽各種報告，經常是關於數據方面，因為數據非常非常重要，其實模型基本上也就固定，那到底大模型下，有沒有可能有那個機器學習的理論。

還有一點就是，機器學習的理論，它到底有沒有用，因為以前的機器學習發展是非常快速，但是到了深度學習這個層面以後，慢慢緩下來，我今天的話我的報告就主要是，給大家回顧一下這段歷史。

然後再花一部分的時間來講一下，我在這個方向的一些工作，好了，那我們看一下機器學習問題的主要元素，這裡面有兩邊，先看主邊，主邊這一邊的話，一般是大家如果去上課的話，一般就是，講深度，如果，現在的機器學習。

基本上是往主邊這個方向講，有個數據集 輸入和輸出，我希望學一個函數，或者一個條件的概率分布，那麼我的目標是什麼，目標是發現數據中蘊含的規律，其實就定義一個Loss Function。

然後用優化的方式最小化，然後它期望會推廣到未見過的數據，這就是所謂的方法，這一般是，在深度學習這個背景下，大家講機器學習的時候，一般在主邊這個方式去講，那麼如果，我們再回到以前，大概深度學習出現之前。

應該是，2000年，像我以前當時讀書的時候，基本上按右邊那個方式去講，它會強調，我一個學習任務是什麼，它是來自一個未知的目標函數，就這個紅色的這一部分，然後我會採樣一個數據集，然後有了這個數據集以後。

我會有一個學習算法，然後這個學習算法從哪去學呢，就一個假設空間，這個假設空間其實就是，我們現在的一些模型，它給定了一個模型類，它從這裡面去，找出相關那些，它有可能是參數的模型，也有可能是非參數化的模型。

然後最終找到這麼一個假設，然後如果這個G，約等於這個F，那我就認為它是可學習的，這是以前，講機器學習基本上是這麼講，這個定義也非常明確，它有一個假設空間的概念，其實對應到現在假設空間，像大模型的話呢。

基本上就是一個transformer，你把那個參數給定了，就參數的數目給定了以後，包括它所有的連接方式給定了以後，它其實就形成了一個假設空間，然後它的每一個參數的配置，其實就是一個假設。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_1.png)

這是以前機器學習問題的一個主要元素，好的，那麼機器學習它的理論框架，它是怎麼建起來的，其實這個理論框架主要是，統計機器學習，從統計那個角度，因為它強調方化，那方化這個東西，它到底怎麼來。

這裡面就要從統計來，因為你想想，你未知的一些數據，那你能怎麼知道你這個模型，在未知的數據上效果好呢，所以這裡面就是統計它連接這麼一個概譜，那麼怎麼來的，其實就是大數據定律，但如果可以量化的話。

一般就是Hoff的不懂式，它基本上，這個，哦 這個有鼠標，這一部分，就是我訓練級的一個performance，這個就是我期望的outer，就是方化的那種performance。

所以這個不懂式它就確保了什麼，我現在有一個出入這個arrow吧，和它期望的出入它們之間這個概譜，它大於它的概率，它小於這麼一個項，這可以把它綁得住，但如果，這一項如果是一個小於1的值，其實是有意義的。

但是如果它很大，其實沒啥意義 為什麼，因為它概率大小於等於1，大家都知道，所以這是整個一個框架這麼來，所以這個理論框架它，它縮小了這個概譜，那麼之後，這個框架因為它是給定了一個H，那麼如果想把它擴展到。

在任意的假設空間裡面去做這件事情，那怎麼去弄，其實又，又有這麼一個把這個，用那個概率的一些方法，能夠得到這麼一個表達式，這裡面有個東西出來了，就是這個M，M是個假設的數目，這個假設的數目其實。

以前的簡單模型還好 是吧，它是可數的，那真實情況下，其實很多那個假設的數目是不可數的，最簡單的我們一個先行模型，你不同的參數配置，它就是一個假設，那肯定有無窮多種配置 是吧，所以它是不可數的。

所以這個也沒啥意義，注意啊 這個N是一樣的數碼，所以它其實有，GEM的這個陽力和這個performance之間的一個橋樑，好了 到這一步以後，接下來搞理論的又往前走了一步，好 這個是一個有限的 是吧。

那我如何把它搞成一個無限的，如果那個假設空間，其實就有，有那個什麼打散，包括打散 包括VCV的概念，這裡面我們就不細講了，基本上能夠得到這麼一個表達式，就是它的performance小於這個。

陽力 然後這麼一個表達式，這個DVC就是一個VCV，它是用來衡量這個模型打散數據的能力，其實就是它的一個表達能力，現在大模型的表達能力非常非常強，因為它可以打散各種各樣的陽力，所以從傳統來看。

基本上是到了這一步就行了，那麼之後如果讓它可用，就是從表達式上可用，那其實最終就得到了這麼一個表達式，這個表達式其實就建立了，機器學習的一個理論框架，那我們怎麼去看這個表達式呢。

它這個是它的一個方法誤差，這個是它的一個，就訓練級的一個誤差，然後如果你的訓練級的誤差，你得到一個小的performance，那你的方法誤差它肯定不會，它的差異不會超過這麼一個bond。

所以這個就建立了一個，方法誤差和一個訓練誤差之間的一個bond，這個bond它和哪些東西相關呢，和你的訓練陽力相關，和你的模型表達能力相關，然後這裡面這個Δ它是什麼，就是說你這個，因為它是概率的。

你說它小於它的這個概率，是這麼一個Δ，所以這是傳統的理論的，一個機器學習的一個框架。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_3.png)

好了 那麼我們，接下來我們講，沿著這個框架，就是在特徵工程時代，包括深度學習時代，包括現在大模型時代，它到底有哪些，就是哪些問題和哪些機遇，所以那麼沿著這麼一個表達式，其實搞機器學習的。

它之後就分成了三個理論方向，大致來看，第一個是它表達能力，就是你給了這麼個假設空間，它函數表達能力夠不夠，這個什麼意思呢，有這麼多訓練數據集，你可不可以把它分開，理論上你這個模型上能不能分開。

如果你分不開，那說明這個模型就不行，那麼第二個就是優化，你給了這個模型在這兒，你能夠，理論上能夠把它分開，你到底能不能找到這些相關的參數配置，這就是優化要解決的問題，叫參數能不能找得到。

然後最後一個就是，函數能不能舉一反三，這就是一個方法出入，所以這麼一個表達式，其實就把機器學習的三個方向給統一起來了，所以這是機器學習理論方向，好了 那我們現在講特種工程時代。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_5.png)

那麼機器學習理論按剛才講的話，其實它定義是什麼，它的輸入是一個相應空間，是一個固定的維度，是吧，它的輸出來它有可能是一個時數空間，如果是回歸，那有可能是分類的叫Binary空間。

所以這個表達式是基於在這上面建立的，這是機器學習要幹的一些事情，但我們人工智能的一些實際任務，自然語言處理，計算器視覺或者語音處理，我們先看它的輸入，它以前的輸入基本上都是分類問題，所以很簡單。

但是它輸入也不是那麼簡單，通常情況下，你如果這種表示成數的形式，有可能是一個相量，但是一個相量序列，所以那個M，注意這個M還是變化的，這是NLP 它比較麻煩，那麼同樣的圖像也是，這個H和W都是變化的。

然後是語音的話也是M，它也是變化的，那麼在這種情況下，感覺機器學習問題，在實際應用上感覺沒啥用 是吧，但還好 以前是特徵工程時代，為什麼呢，這些方向，它們有各自的叫一個研究領域。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_7.png)

它們要提個特徵工程以後，把它提完特徵以後，編成這個樣子，所以搞機器學習的人呢，我不管你是什麼樣的問題 是吧，我只管我的輸入是X屬於RD，並且我還可以給它一些假設，給了這些假設以後。

我就開始推我的一些理論，所以我可以用線性模型，然後可以各種各樣的，你可以加拉數 加各種係數，把那些參數那個，為什麼呢 都可以棒的做，可以能夠得到一些好的，表達能力的一些結果。

同樣 由於它是用了一些線性模型，它可以去優化，它有些是全局收斂的，屬於各種優化的那種收斂率，包括能不能達到那個，全局最優或者收斂率也是可以，同樣 用了這麼一個表達式，你可以引入更多的一些先驗。

能夠得到一些更精緻的，一些繁華的一些棒的，這一塊，那麼它把那些所有的，真實際問題，和這個它跟理論之間這個概譜，人給生了，人給搞計算機的 思覺的，人給搞NLP的，你們去提特徵吧，你們提到這以後。

然後我再來處理，你到底和理論的那個概譜，到底有多大，我不管，反正是你們的問題，這是傳統特徵工程的時代，好了 到了深度學習，深度學習這個來了以後，就有問題了，一個什麼樣的問題，就是，搞機器學習的人。

他會說深度學習，它是機器學習的一個方向 是吧，如果它是機器學習的一個方向，那麼這有一個問題是什麼，就是深度學習，它在處理這些視覺或者語言問題的時候，它是端到端的，它直接的處理的輸入，就是這些東西。

它的輸出有可能是分類，這是之前深度學習發展的不是那麼快的情況下，那麼之後發展的非常快的情況下，有各種，它那個輸出空間有可能比它還複雜，像各種深層模型，然後它也是變化的，所以在這種情況下。

機器學習它這個理論，它基本上就沒法子弄了，為什麼，首先之後我們再講一下，在這個背景下面，它到底有哪些問題，那麼當機器學習遇上深度神經網絡的時候，它首先有一個好的東西，就是深度神經網絡，它的表達能力很強。

所以在這個表達能力上，它是有很好的理論基礎的，最經典的是什麼，就是神經網絡的萬能近似理論，它基本上給出了，你給任意的一個函數，我都可以去理合，整個正面的思路其實也比較簡單，就像我們當時大學學數分的時候。

它用那種曲線理合，用折線或者用那種，把它分成一小段去證明，所以它無窮寬的或者無窮深的，或者有限寬有限深的都有一個結論，所以這個是可以去證明的，這是關於理論的一些結果，它表達能力非常強。

那麼表達能力非常強，它只是函數理合，那如何能夠這個東西給連上，其實也有一些方向，它是專門算神經網絡的V-server的，所以這個V-server它其實和那個參數數目，和那個乘數都有關係。

在這種情況下其實你那些參數的數目，其實就隱私地表達了一個模型的表達能力，這裡面是有一個理論的一個結果，當然同樣也有一個方向，就是就專門算這種linear region這個區域，但這塊我們就不展開講了。

所以這是表達能力，但表達能力這塊它的結果相對來說是比較穩定的，然後深入學習發展的過程當中，其實最重要的一點是什麼，就是優化，就是從2006年開始以後到2015年之間。

它從使用的角度發展的最有效的就是優化，因為以前的神經網絡學起來非常非常難，但是到了2015年以後，基本上咱們現在神經網絡的那些，勾架基本上都出來，比如說2015年的，2014年的話應該像BN出來。

然後2015年的話是殘差，殘差和BN的一個組合，這兩種的一種組合以後，就保證了它的訓練非常非常穩定相對來說，那麼在，但這裡面一個最核心的思想是什麼呢，其實就是我們做前向和反向傳播的過程當中。

這裡面有一個非常重要的哲學，就是在2015年之前，大家做的最多的事叫什麼，叫初始化，初始化它為了保證一個什麼效果呢，就是你每一層的，它之間的那個什麼一些統計量，比如說它的均值或者方差，他們希望他們是。

至少從初始化的情況下他們是相等的，那麼在這種情況下，你這個網絡才相對來說比較好訓，當然後面出了Luminar Racing，它直接在中間加了一些操作，的確就把這個結果給滿足了，但這個還不夠。

之後才有了殘差，才能夠訓到幾百層上千層，所以這是這麼一個問題，這在2015年之後解決了以後，其實深度神經網絡就發展得非常快，就各種各樣的應用，大家去解決任務的時候，那基本上都是什麼，都是根據一個任務。

然後設計點損失函數，然後或者改點模塊，反正能夠訓起來是吧，然後最終能夠得到一些好效果。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_9.png)

這是優化這一部分，那麼另外一部分，方化，這個東西的話基本上，首先第一機器學習，從深度神經網絡，從機器學習的角度有方化嗎，其實這個目前來看，基本上沒有一個什麼好的結果，只有一些empirical的結果。

但這裡面最經典的是，我記得是2017年的時候，艾克利爾的最佳論文，他們當時提的那個，讓大家去rethink，這個深度神經網絡的方化，但是rethink了以後，大家還是沒去think，因為這個很難。

所以這是從機器學習的角度去討論方化，但是從另外一個角度，搞計算器視覺的或者搞NLP的，其實是可以搞很多方化的，因為大家搞計算器視覺，尤其搞計算器視覺。

它本身就是在驗證級上去評價那個performance，包括它設計的一些模塊，它也會說這個方化效果好，那它的方化是怎麼來的，其實就把一些領域的知識給加進去，比如說像設計網絡架構的時候，用一些不變性。

網絡架構裡面設計，像平頁或者光照不變性，像Nominalization它可以做那種光照的不變性，還有一種是什麼，就是data augmentation，這個是最有效的，因為如果你看不到什麼。

那你先按這個方向，根據你的理解把它加點數據進去，然後能夠使得它方化，所以這是這個方向，好，那麼它的困難，這是它的困難，為什麼這個理論方向一直不好做，做不下去呢，其實這裡面最重要的原因是什麼。

就是剛才講的，它的輸入形式各異，因為你如果認為是機器學習要解決的問題，那它基本上，機器學習它只管它的理論，它只管它那個輸入是那個，一個低微的相量空間裡面，所以你這種，變化的這種維度它根本處理不了。

從數學上它沒有辦法刻劃，還有網絡架構各異，之前的所有升級網絡的，都在MLP上做的，這種簡單的，你一道循環升級網絡或者捲機，尤其加了各種殘差 全是FORM，每一個網絡你都要去分析一個理論。

所以那個非常非常複雜，所以整個東西也不好做，同樣它的輸出，更複雜，因為升級網絡效果出來了，然後做研究的人，把那個任務搞得越來越複雜，然後形式也更複雜，所以這個理論分析基本上就沒法做。

所以整個就形成了一個非常大的一個概譜，就是我們應用工程在往前走，但機器學習理論的，還是守著它那一畝三分地，那種傳統的方向，所以這個概譜會越來越大，導致中間就不太好弄，就是一些理論的結果大家就覺得。

好像深度神經網絡裡面好像沒啥理論的東西，好了 到了大模型時代，其實這是一個機遇，為什麼說這是一個機遇呢，大家想一想，大模型時代很重要的一個特徵，我們先不說它大那個參數，它最重要的一個特徵是什麼，統一。

它把所有的任務，你問的是什麼樣的輸入和輸出形式，你把它壓成那種輸入序列的形式，你用至少在NLP這裡面，它是Auto Regressive，輸入一直預測，它的輸入空間和輸出空間是一樣的。

這是從那個輸入輸出的一個表徵，這是一點，第二點，它那個網絡架構大家都用transformer，transformer在設計的時候，它每一層它的維度也是D，它每一層的維度，它的空間也是固定的。

所以其實你每一層之間，它其實有可能，從數學的角度，它們之間那種空間刻劃它是可以刻劃的，所以這個更簡化了以前深度神級網絡裡面，沒有法做的一些分析，那麼在這種情況下，然後第三個是什麼，就是它所有的。

我之前不是講，深度神級網絡有各種輸出嗎，那麼在大模型時代下，它的輸出全部，它的問題全部變成什麼，一種條件的分類問題，因為你真的是叫什麼，叫Predicted Next Token是吧。

你去遇上那個Token的時候，它本質上就是一個分類問題，它是一個分類問題，那只是我用了一些前面的一些上下文的一種條件，變成一種條件的分類問題，所以在這三種情況下，它三種都統一的方向下。

其實給出理論的研究，其實帶來的一些機遇。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_11.png)

這是，好了，那麼，機遇的話就是什麼，咱們，這是一方面剛才，還有一個就是，我們訓大模型的時候，通常強調是吧，數據量非常非常大，其實尤其像Scanning Law。

尤其是現在這些Empirical的一些結果，它發現，就是你只要把訓練Loss給降下去了以後，它基本上的翻滑效果也還不錯，那其實就，解決了一個什麼，也先不說解決，就這要從研究的角度，就把這個東西。

就是以前所有的機器學習理論，它通常要強調翻滑這個問題，你要強調翻滑這個問題的話，你如果，你不用統計那一套，你是沒法做翻滑的，好了 現在，既然你，數據量是無窮大是吧，那等於你能夠看到水流數據。

你最終把它變成一個優化問題，那如果你不去考慮翻滑，那其實機器學習的理論，那個方向發展，它其實還有更廣闊的一個空間，就以前就是被這個表是給束縛了，這個是我的理解，所以那麼在這種情況下。

最終其實你看現在的研究，無論是分析，其實就是表達能力和優化，它們之間的一個討論，從抽象的角度來看，就是你現在給的一個模型是吧，你是大的還是小的，你有沒有能力去擬合這些訓練數據級，有沒有能力。

好 你說現在這個階段是什麼，我大的相對來說，它肯定那個參數，從威懾為這個角度，它肯定擬合能力要強一點的，那麼第二個就是什麼，你有那個能力，我不見得好優化，這是以前會說，我網路越深我越難優化。

當然現在有了，有了lobalization叫殘差，這個也不一定，那麼現在，現在這個結果是什麼，你有了越大的模型，你會發現它優化起來，去擬合那個能力，它優化起來也很簡單，所以這裡面其實就變成了一個什麼。

就是一個表達能力和優化之間的一個tradeoff，就是你如果能夠有這個表達能力，你如果能夠很好的優化，那你整個東西是有意義的，所以這一塊的話，但從表達能力這個方向，其實它也有一些研究的空間。

就是因為你之前的表達能力，它只是去說一個先進層，一個非先進層，神經網絡它能夠無限的擬合，但是現在的神經網絡裡面，它有了各種lobalization層，包括殘差層，那麼這些分析在以前的理論裡面是沒有的。

同樣的，在訓練過程當中，如果我們能夠針對這種表達的空間，這種RD 這種固定的維度，我們能夠去設計，去研究它這個訓練的一個dynamics，這個對整個的網絡的一個訓練是有幫助的，所以基於整個這兩個點。

我在這裡面就快速地講一下，我們組織在這裡面的一些工作，首先第一，就是normalization，像neoliberalization或者arms norm。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_13.png)

我們理論上證明它的一個非先進表達能力，這個的話就是，我們知道層標準化，就是在全數form裡面這個基礎的模塊，但即使現在有些方向它為了提高效率，它用arms norm，它也是屬於它是一種推劃的方式。

就是這個方數操作，那麼方數操作它本質上是從這個，把壓力拉得到一個球的一個操球面，那麼我們從數學上，無論從算術推導還是幾何構造，我們證明這個neoliberalization，包括arms norm。

它是有一個非先進表達能力的，整個證明的思路簡單講一下，細節的話大家可以去看一下，證明的思路是什麼，我們提供了一個指標，然後這個指標我們證明了，你只要是先進層，和那些，只要是先進層吧。

你各種各樣的先進層疊加起來，它是沒法突破這個指標下限的，但是我們發現在中間，如果你加入一個neoliberalization，加入幾個層，它是能夠突破這個下限的，所以這一塊是證明了從算術推導方面。

這個指標也是挺有意義的，然後第二個方面是什麼，從幾何構造，這個就快點過一下吧，其實一何問題，大家說先進模型它是沒法去，就是你用先進分類器，它是沒法解決這個一何問題的，那麼我們發現。

你其實在這裡面用了這種投影，就是那個縮放，它可以通過這麼一種構造性的方式，能夠把這個一何問題給解決掉，所以這個縮放它肯定是非先進的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_15.png)

這是一個類似一個開胃菜，但我們這裡面最重要的結論是什麼，它的一個，就是一個先進層，加一個neoliberalization層，就這種網絡架構我們叫LNNet，它的那種萬能分類能力。

這個是以前的所有理論裡面都沒有的，以前的話要不就是先進層加ylow，或加seqmoy的，證明我們說我們可以把傳統的非先進層給去掉，你只加neoliberalization。

加neoliberalization或者arms normal，那它可以有萬能的分類能力，那麼我基本上證明了什麼，就是無窮深的LNNet，注意啊，萬能機制裡面當時最早的話是無窮寬的。

無窮寬的RedRule只有兩層，那麼無窮深的LNNet，能夠完全真正分類任意給力的一個樣本，但有個要求就是每一個，每一層的，如果你是用neoliberalization去證明。

它每一層的節點數它要大於三個，如果用arms normal去證明，它大於兩個就行了，這個是能夠證明的，就是你給任意的點，給它任意的一種，無論是二分類還是多分類，你給它任意的一個標籤。

這麼一個網絡它是可以把所有的這些樣例都區分開來的，這就是它的一個表達能力，那麼我們證明了失落，我個人相對來說特別喜歡這個失落，就是我個人覺得是可以寫入教科書的，為什麼 因為它從構造性上。

它把這個機器學習的問題我們轉變成了一個什麼，就是一個算法的一個merge的問題，就是這些點，你給定這麼些點以後，我去找它們的哪些點，可以用一種方式找到這些點，我可以把它merge。

這種merge的過程當中，只用先行編劃和這個投影程，它就可以把它merge，然後每一步都最終變成一個低軌跌倒的問題，最終能夠證明，所以有了這個結果以後。

我們最終就可以直接很快能夠推出整個網絡的一個VCV，我們說如果你有一個L層的網絡，它的VCV它最少是L+2，這是一個理論的結果，這個理論其實還非常弱勢，就是其實剛出來，類似於萬能機師理論它剛出來的時候。

其實沒啥用，但是這個理論還有很多改進的空間，就是你能夠每一層的神奇元節點數目變多了以後，你那個乘數是不是可以減小，或者你用無窮寬的，你只用一個Layer Luminizer，或者給它分組。

是不是能夠給它一般化，所以這一塊，但我們還做了一點，就從使用的這個角度，就是我們把一個Layer Luminizer分組，用Group Luminizer方式去做的時候。

我們能夠理論上證明它能強化ARM的分線性，所以這裡面其實從網絡設計的一個角度。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_17.png)

這個是一個數學的一個說明，然後一些實驗性的一個說明，這種分組的數目，都是用隨機標籤，就是你給所有的這些數據，你隨機地打標籤，我這種一些簡單的這種網絡，它能不能把它分散開來，那麼在這種情況下。

其實對於大家去設計網絡的時候其實有幫助，就是有可能你把Layer Luminizer，你把它分成組，每一組以後你再做，它的分線性是變強的，但這裡面，在這種情況下它分線性變強，但有一個缺點是什麼。

因為你其實加了更強的約束，這裡面也有可能，去限制那個模型的學習或表達能力，所以這裡面有一個缺點，好 這是表達這方面，那我快速地講一下優化。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_19.png)

這個好像時間有點超，行 那我把那個簡單講一下思路，就在深度神經網絡訓練過程當中，有一個非常重要的一個分析，叫尺度不變性分析，這個就是把所有的Luminizer，就是你每一層，你每一層你把那個權重。

你把它編大alpha倍以後，我就希望這個模型它那個表示不變，這有什麼樣的好處呢，就能夠使得你的訓練相對來說非常穩定，這是Luminizer進行，包括後面的很多網絡設計。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_21.png)

它最重要考慮的一點，就是，好了 那麼在一個網絡裡面，我們會簡單給一個結果吧，就，就如果，如果你把每一層都放大alpha倍，就是你在訓練過程當中，那你其實你單層，就特定的層，它其實受各個層的一個影響。

它那個尺度，但是如果你用了Luminizer，或者用了一些其他技巧，表示它保證這個網絡是scale不變的，那它基本上，它的那個尺度只受這一層的影響，所以這個結果對於穩定神經網絡。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_23.png)

非常非常重要，這是，那麼這個結果它能夠穩定網絡的訓練，但是它會帶來一個什麼樣的問題呢，會帶來某些層，它其實有可能不會學，這是什麼意思啊，就是因為當你如果那個尺度變大的過程當中，你那個梯度變小。

當你的梯度遠小於那個全中的數目的，全中那個參數的尺度的時候，那你整個模型它就不會，它基本上就不怎麼學，那麼在這種情況下，你有可能那個網絡不會divergence，但是有可能一些層它基本上是沒用的。

這也是為什麼以前，有很多各種各樣的網絡減資，就是因為它本身在訓練過程當中，它由於這種性質，它基本上就不學了，但是它也不會發散，因為它別的層在學，尤其是加了殘差以後，所以這一種方式是很方便。

去幫助大家去診斷，你那個模型裡面有一些層，它是不是它沒有怎麼學，所以它不影響整個那個網絡的發散，好 這個是尺度，就是每一個，那個樣例就是每一個每一層。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_25.png)

它那個什麼數字的範圍，還有一個是什麼，最經典的，在機器學習裡面就是spectra，就是你那個數據的斜方叉矩陣的特徵譜，這個東西就比那個什麼尺度更近一步，這種特徵譜它既和優化相關，它又和那個表示相關。

如果你那個是滿字的，說明那個表示比較充實，如果你有很多都是低字的，就很多都沒有字 沒有rank，就是只有維度很小，說明那個表示其實不充足，這一方面，同樣 如果越rank越白話。

你會發現它那個優化起來它會更容易，這是在傳統的機器學習裡面的一個結果，那麼在深度學習裡面也有一個，就是每一層裡面，如果你也滿足這種屬性，那它基本上也會得到一個好的結果，我快速過一下吧。

所以你這種表徵的分布，對於整個學習過程當中非常非常重要，尤其像基於這種SAMS，就在視覺裡面的那種自見的標準學習裡面，它容易發生這種collapse，或者dimensional collapse。

如果我們為了解決這個問題的話。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_27.png)

其實有很多方法，這裡面我簡單講解一下白話順勢，這個的話就其實什麼，我在訓的過程當中，我期望它每一個，就表徵這一塊，它的coherence是期望它是identity的，這樣的話就限制它去collapse。

這是一個regularization的作用，這是一個大的框架，但去實現的時候有很多種，像VS-REG一樣，加一些soft的，還有一種就是直接做一個變換，然後加一個理論的結果。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_29.png)

這裡面我簡單分析一下就是，我們得到一個結果是什麼，如果你按照那種之前所謂的硬白話的方法，做了一個白話變換，然後加了一個順勢以後，它得到的這個表徵的rank，它只是鼓勵它是一個滿字。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_31.png)

並不是鼓勵它白話，但是實際上另外一種，像這種軟白話的方法，它其實最終它是鼓勵它是白話的，但是你會發現，整個表徵它並不一定要fully whitening，因為你fully whitening的時候。

你這個表徵雖然表徵的美化很強，但是你在解決任務的時候，你還期望它有一定的方法效果，所以你希望它的pure，是類似於那種alpha，alpha的那種演繹的那種方式，就是有大的 然後比較平緩的。

這種可以去幫助你去診斷。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_33.png)

你那個訓練過程當中的pure，它的這種效果，還有一個工作就是，我們有一個方法就是，關於這種whitening loss，我們證明了，就是如果整個訓練過程當中，如果你學習力無窮小的情況下。

那你整個pure你初始化了以後，它整個訓練過程當中這種slavery rank，它是不變的 有這種，行 好的，那我這裡面之後就講一下我們這個，基於這些分析，然後我們也快速訓練，我們也訓練一個。

小尺寸多模態的一個大模型，叫Taginoma，那麼主要是接近於，到4年1月份，這個最早文本裡面它出了小尺寸模型，然後我們很快就組織了很多人，然後訓練一個小的這種Taginoma 1。4B。

那是1月11號就傳到HugFace，然後現在已經超過了15000多次，可以直接在3080那種上無序量化就可以做推理。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/e6213f966f9600e50f6acb4b99db4ef0_35.png)

這是最早的1。4B，然後我們就訓練各種各樣的模型，把它做了一個benchmark把它開圓了，然後基本上3。1B的話會比7。5B的要好點，這是小尺寸多模態的，然後基於在做的這個過程當中。

我們發現有一點很重要，就是那個代碼的質量非常非常重要，所以我們之後做完這個以後，我們就花了，就是組織了，就是包括和清華的一些老師。

組織開發了一個叫Taiwan Learning Factory的這麼一個項目，就是按照軟件設計的工廠模式設計理念，開發了一個模塊化一托展可複現的一個多模態，代碼一個平台，每個模塊集成器最新一種方法已經。

方便大家去定制多模態，然後這個Factory也開圓了，所以這是一個整體的架構，按照那種軟件工程，整個代碼的話我個人覺得是相對來說非常好用，特別適合高校，因為高校相對來說，卡比較少是吧。

我們的定位就不會遜3B以上的，因為為什麼，我們遜不了 這是事實，但是因為我們強調大模型，它最重要的一點是什麼，它那個統一表達能量，所以當我們把這個平台開發出來，如果大家再加入一些Feature以後。

很方便高校的人去做大模型的分析，甚至有可能做理論的分析的一個驗證，這是我們這個想法開源的一個平台，好 謝謝，感謝黃磊博士的精彩報告，下面有請觀眾提問，黃老師好，我有一個問題就是。

您在講座中講到了Transformer架構，它給我們帶來了很多，在機器學習理論上的優勢，比如說它統一了特徵的維度，統一了特徵維度都是D，這樣給我們有很大，給我們統一了這個維度之後。

我們有了很多分析上的便利，以及它的表達能力，達到了很大的增強，以及它可以增大它的規模，然後提升它的泛化能力，目前我們正在通往AGI的這樣一個道路上，但AGI的話它可能涉及，比如說我們人類。

會有更多的魔態的知識，我們會涉及語音，我們會涉及視覺，可能需要更多的魔態的知識，更多種感知的知識融合起來，才能達到這樣一個AGI的目的，您覺得Transformer這樣一種。

就是比較同質化的這樣一種模型架構，它是否是最終通往AGI的一條道路呢，你這個問題比較大，首先第一點呢，我不是說Transformer這個模型架構，它相對來說方便的理論分析，我是說在大模型時代下。

大家那種統一的思想，然後勾著這種統一的架構，然後它相對來說，包括任務統一，在這種架構下它相對來說方便了以前，在深度學習背景下，因為各種架構包括各種輸入形式，它比較難的那種分析，這是一方面。

但Transformer這個東西，其實它的理論分析也不容易，這是第一個，然後第二個就像您剛才說的，關於那個Transformer，它到底是不是通向AGI的一個架構，這個的話，我個人呢。

我覺得這個很難預測，因為至少目前來看，它有如果按機器學習那個道路，它有兩點是什麼，以前機器學習有兩類學習方式，一類叫參數化的模型，一類叫非參數化的模型，非參數化模型指的是什麼，就是你把那個數據存下來。

你用最精靈的方式去把它組合，其實Transformer裡面它本身，它含了這兩個東西，第一 它的碳性，本身就類似於KA的那種方式，去組合那些token，然後第二，它也考慮了參數化的模型。

像FFN它本身就是個全聯結層，就是個神奇網絡，所以這兩個的組合，至少從機器學習，如果大家覺得以機器學習這個方式往前走，能夠實現AGI，那我個人覺得Transformer，它其實從架構上它是沒問題的。

至少從表達能力，就像我剛才講的，你只要你的所有的任務，它是可以定義的，可以能夠，你知道可以定義你的數據組合好，它是可以把它的所有的任務解決的，至於我們大家構造的這些，任務的這些數據集。

它能不能涵蓋我們所有的AGI，這不是一個模型架構解決的事，這個偏哲學的，我也沒有辦法回答，好 謝謝，好 感謝黃磊博士。



# 2024北京智源大会-大模型前沿探索 - P6：无约束感知理解：从视觉垂域建模到多模态统一与多任务协同：赵 健 - 智源社区 - BV1yS411A73A

呃感谢呃叶泉老师的这个介绍，感谢永翔总和叶泉老师的这个精心组织呃，呃实际上这个刚才大家很多呃，专家老师呃介绍的都很全面了，然后从这个叶全老师一开始，介绍我们这个电信和智源研究院合作的。

这个全球首个稠密的大模型，到呃双勇老师介绍的这个呃，电信在大模型方面的一些呃，比较好的一些实践和探索，然后再到这个呃敖老师介绍的，大大小模型的这个协同，然后再到这个黄磊老师介绍的这个呃。

从机器学习到深度学习，再到这个大模型时代的呃一些理论分析嗯，所以我主要是结合着一个具体的呃，一个问题也好，或者是一个场景也好，或者是一个应用也好，来跟大家做一些我们在这个无约束感知理解呃。

从视觉垂域的建模，到多模态统一和多任务协同方面的一些呃，研究思考和体会，呃，刚才这个呃，叶璇老师已经呃对我做过了一些介绍，在这里我就不赘述了，那么人工智能发展到现在这个时期的话。

其实大家可能都有很多的这种感触，就是说以前我们的创新模式的话，实际上是学术界一直在引领工业界，那么现在大模型时代，多模态呃，生成式实际上就是很多的，很多程度上或者是某种程度上呃，是这个工业界在呃。

开始引领这个学术界，进行这种创新和应用的这种发展，所以这个我们电信的话呃，其实在这个数据，算力场景等等方面都有非常大的优势啊，那么我们现在也在呃，这个吸引这个一些人才的这个加盟呃。

所以如果大家呃有这个呃，自荐或者是推荐的一些优秀的候选人的话，欢迎呃跟我们取得联系，嗯然后呃这个视觉目标的感知理解的话，实际上是一个非常呃重要的，一个国家发展的这个需求呃，这个新时代的中国国防里面呃。

就指出这个复杂对抗环境下，国防安全任务艰巨繁重，那么需要重点发展视觉目标的感知理解呃，那么2022年，国自然的这个十四五的发展规划里面也指出呃，需要这个攻克多元异构信息的融合感知理解。

这个意义是十分重大的，所以迫切的需要呃，去这个视觉目标的感知理解呃，那么视觉目标的感知理解是什么呢，它实际上就是去获取我们图像，或者是视频里面呃，一些，比如说像人车物啊。

等等这样的一些目标的关键信息和关联属性呃，那么多年以来呃，他一直都是我们这个呃人工智能领域的，非常重要的这个科学问题啊，同时也在呃比如说像国防反恐，公共安全以及民生经济等等方面，有非常广阔的应用前景。

呃但是的话无约束条件下呃，我们的视觉目标感知理解，仍然面临很多的这种呃挑战，这是这些挑战，主要包括这个各种内外在因素的耦，合的这种影响，那么会对我们的这个呃视觉目标的感知理解呃。

造成这个呃求解建模上面的这种困难嗯，嗯比如说这个我们为了防患某个核心区啊，和它州界的这个安全威胁，那么我们需要对它的这个监控图像，视频里面的，这个重要目标的关键信息和关联属性。

而进行一种层次化的感知和理解，那么首先我们需要去对对这个态势信息，来进行这个感知啊，包括检测可疑目标的状态信息啊，来预测它的这个趋势信息，然后进而呃进行这个属性信息的关联啊，关联这个关注目标的属性信息。

得到它的这个属性的描述呃，再进而去这个理解它的这个精细化的，语义的信息啊，也也就是解析这个重点目标的呃，像素级的这个语义信息，来获取到他的这个呃精细化的这种特征呃。

那么实际上我们发现就是说在这个里面的话，在隐空间里面的话，他的这个各种挑战性因素啊，以及这个跟目标息息相关的，它的这种关键信息实际上是紧耦合的一个状态，那么这个不利于我们去对目标的它。

它所涉及到的一些信息，来进行这种呃感知和理解，所以这个里面一个关键的科学问题，就是说我们怎么去呃探究，在这个复杂要素耦合空间里面，来进行这个属性关系挖掘和识别的机理，呃。

所以我们也是呃这个围绕这样的一个科学问题，来提出了一个呃科学的呃思路，叫做数据与知识混合驱动的深度感知理解，那么我们也是呃进行了这个三项层层递进，相互支撑的呃研究工作啊。

包括这个多模融合学习的呃态势感知要素解耦，学习的属性关联啊，以及因果嵌套学习的呃语义理解，并且也分别进行了这个相应的这种呃创新嗯，首先我介绍一下这个第一项研究内容呃，也从一个每一个研究内容。

我都是从一个问题背景啊，来来来引入啊，呃这个第一项研究内容，他的这个问题背景，比如说我们现在这个国际上，大家都关注的一个问题，是这个反无人机的一个问题啊，就说为了保障某要地的低空安全。

我们需要对这个微小型无人机等等，一些可疑目标的这个时空关键信息，来进行这个感知取证啊，并且辅助一些这种呃反制的手段来进行管控嗯，那么在这个呃多模融合学习态势感知里面。

我们主要是研究怎么样去通过融合这个呃，红外呀，可见光啊等等一些多元信息，它的一些互补的优势，来实现这个目标的空间位置等等，状态信息的检测，和它的这个运动轨迹等等一些趋势信息的预测。

呃但是在这个里面其实存在很多挑战，比如说在我们所说的这个无约束条件下，或者是非配合条件下，那么目标它在运动的过程中会不断的受到速度，背景障碍物等等一些影响，那么会导致他的这个视觉观测会产生多变性。

那么会导致我们这个态势信息的获取啊不精确，那么呃针对这样的挑战呢，我们也是做了一系列的工作啊，那么在这个呃RGBT的这个呃，弱小目标跟踪的这样的一个场景下，那么传统方法呢，主要是针对这个基于这个。

一阶交互和静态模板的方式，那么呃会导致这个力度单一，表征低效，那么我们提出一个创新的思路，是这个双流知识迁移的多模融合，实力及目标跟踪呃，可以呃通过这个多接耦合双流极联呃。

联合着去感知它的这个全全局和局部的，这个信息，能够实现多接信息的这个融合互补呃，时空线索的联动建模和这个层级知识的呃，吉连迁移嗯，那么同时的话我们也构建了一个大规模的呃，这个多模融合的。

无人机跟踪的这个基准数据集呃，那么相比于此前呃，这个这个相关的一些这个数据的话，呃，我们有效标签实际上超服了35。9%，那么如果有有这个老师，或者是同学们关注我们这个方向的话。

我们这个方向叫NTUAV呃，如果有人关注我们这个方向的话，实际上也也会知道，就是说我们一直是围绕这个方向在进行深耕，国际上我们是首次提出来这个问题，就是反无人机这个这个这个问题。

然后我们也是多年来持续的在围绕这个方向，不断的在呃进行这个构建这个数据，然后不断的在这个像CVPRI，CCV这样的一些国际顶会上，是在组织这样的一些workshop和challenge。

来推动这个领域的发展和进步，然后接下来我们马上要依托CVP2025，组织这个第四届on t v v workshop and challenge，也也是欢迎大家关注和参参加呃。

然后我们的方法的话也是在这个复杂环境，复杂环境多重遮挡的这样的条件下呃，相比于此前这个呃最优的这个方法呃，呃这个呃相相对精度提升了有19。95个点，然后这个是国际上面的一些学者。

对我们方法的一些这个正面的一些评价，呃，然后我们的相关的算法也拿到了这个，比如说中国人工智能大赛A级证书，以及CVPR上面的一些比赛的奖项等等，呃，然后刚才我也介绍了，我也是这个呃。

多次作为第一负责人来在这个国际的顶会上，组织这样的这样的这个topic的一些呃，学术活动嗯，吸引了很多的这个国内外的这个机构，来进行这个呃参加嗯，然后我们的相关的成果，现在也落地到了这个一些呃。

包括一些国家的重要部门啊，我们也跟这个花样滑冰协会做了这个合作啊，开发了相关的一些系统，那目前估值也非常好，然后下面介绍我们的这个第二项工作呃，比如说我们在这个某个突发的公共，安全事件里面啊。

我们需要对这个实施违法行为的一些关注目标，他的这个面部的特征来进行这个感知呃，识别他的这个呃身份的信息呃，来实施这种追查布控，那么在这个要素解耦学习的属性关联里面，我们就需要研究。

怎么样去通过这个充分挖掘目标的呃，内在属性耦合的结构，和它的这种相互之间的这种关联关系，来发现属性和属性之间的这种复杂的依赖，来实现这个目标的身份啊，类别呀等等这样的一些信息的呃精确的识别呃。

但是在这个无约束条件下，实际上呃目标经常会受到这种呃姿态呀，等等一些内在属性的耦合影响，和这种视角啊，分辨率啊等等一些外在因素的干扰影响，那么就会导致它的这个属性识别的结果不够呃，精准呃。

那么我们也是做了很多的工作，来解决这样的一些挑战和难点咳。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8ef6b86adda6ce65bcc59d00cd9134e4_1.png)

那么传统方法的话主要是通过呃，比如说合成图像直接学习的方式，那么就会导致这个分布的差异和属性，耦合的一些挑战呃，我们提出这种规划，学习要素解耦的，属性及目标识别的这种呃解决思路呃。

通过这个多属性依赖的这种关系建模和归一化，学习要素解耦，可以充分的理清属性耦合的结构，然后统一的去处理各种各样的一些呃，挑战性的因素，然后实现这种呃各各种关联属性的归一化学习，我们的方法的话。

相比于呃这个之前马尔奖得主，and resistman的这个fisher，vector等等一些经典的算法，相对识别精度呃提升了超过50%呃，然后此外的话我们在呃一些大姿态，极端姿态等等一些条件下。

相比于之前的这个方法呃，相对识别精度也得到了大幅的这种提升，然后特别值得一提的是，我们呃也把我们的这个方法呃做了这个开源，在GITHUB上面。

我们release了一个rapper叫face evolve，呃，相信很多同学也都用过啊，目前在GITHUB上面反响非常好，有这个3000多次的这个star和700多次的fork，然后呢。

我们也对这个国产化的深度学习的这个框架，比如说百度的paddle，paddle以及清华的这个G图呃，进行了这种适配啊，并且被他们这个官方引入了呃，呃呃这个现在就是这个大家的反响和使用率啊，都非常的高。

也帮助了很多的学者，包括呃这个呃做了研究和转化，然后这个是国际上面的一些呃，评价的一些情况啊，然后我们的相关的算法的话也获得了呃，包括CCV2021的这个口罩，人脸识别竞赛的冠军呃。

因为当时正好赶上疫情呃，所以这个口罩人脸识别，也是一个比较热的一个话题，然后以及这个美国国家标准技术研究院呃，搞的一个无约束人脸识别竞赛，我们是在所有的track上面都拿到了冠军呃。

然后还有之前微软搞的这个，百万名人识别的一个呃比赛，我们也是在所有的track上面都拿到了冠军，然后也是因此我跟这个微软亚洲研究院的一，一些组织这些学术活动的老师呃，得到了这种很好的这种呃呃交往呃。

也成为了朋友，哈哈不打不相识，然后我们也是呃在这个方向上面，组织了很多的学术活动，我们组织了这个地面哨兵的挑战赛啊，以及WELS的这种系列的活动啊，然后我们的一些成果也成功的落地到了。

一些国家的重要部门，包括呃这呃，还有这个蚂蚁金服的这个可信，人脸识别系统里面呃，这个服务覆盖了1。2亿的用户，然后累计支持了150亿津贴的发放等等，咳然后呃下面介绍一下我们的呃这个第三项呃。

这个内容嗯啊比如说在某个聚集性的活动里面，我们这个重点目标通常是藏在人群里面的，那么我们需要分析不同目标的这种啊详细的呃，特征来这个理解他的这种精细化的语义信息，实施这个呃精细的这种检索。

所以这个因果嵌套的语义理解的话，主要是研究怎么样去逐步的呃，建建模这个复杂的场景，然后以及由自由粗到精信息的渐进式的反馈，把这种呃高复杂度的任务，向低复杂的任务进行这个分解和转化啊。

最终实现这种呃精细化的语义的理解呃，但是在无约束的条件下，因为呃人群里面这个目标的话，他可能这个距离比较远，会导致轮廓的这个模糊啊，并且这个呃，因为交互的问题或者是遮挡的问题呃，都比较严重。

会导致它的这个场景的复杂度呃，会产生这个多元性，那么就会呃导致我们最后的这个语义理解，不够精细呃，那么我们也是做了一系列的工作。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8ef6b86adda6ce65bcc59d00cd9134e4_3.png)

来解决这样的问题呃，传统方法呢主要是这种呃基于cascade的方式啊，就是多阶段呃相互独立，多阶段呃分开去进行这个处理，那么会导致这个特征没有关联，语义也容易混淆呃，那么我们提出这个局部全局信息关联的。

因果嵌套，像素及目标解析这样的一个方案呃，呃通过这个局部和全局的关联，以及因果嵌套的学习啊，可以实现这个特征的协同优化，和语义的因果推理呃，那么此外的话我们也是构建了这方面的一个。

大规模的细粒度的语义理解的数据集，呃，然后呢在这个数据的规模上，相比于之前的工作呃，超服了五倍呃，在这个数据标注的这个类别上呃，相比于之前工作超过了三倍，然后现在也被多个国际上面的。

知名机构所广泛的使用反响也非常好，然后我们的算法的话，相比于之前的，比如说m h passer等等一些这个经典的方法的话，在保证性能呃，基本呃有有这个呃些许提升的同时呃。

在个推理速度上也提升了这个十倍呃，相比于这个RESNET作者何凯明的一个，这个master r cn，我们的这个平均的精度提升了13。95个点，呃然后这个也得到了一些国际学者的这个评价。

呃然后我们的这个相关的这个算法的话，也拿到了一些，比如说像这个AC m multimedia的best student paper，然后以及这个新加坡模式识别协会的金奖，呃，然后同时的话我们也是呃。

组织了很多这方面的学术活动，来推动这个领域的发展和进步啊，我们的这个最后的学术成果，也成功地落地到了一些国家的重要部门啊，以及这个像奇虎，360啊等等这样的一些单位呃，取得了一些经济经济效益啊，咳。

Ok，那么我们在这个长期的这个，研究和实践的过程中，实际上发现就是说在视觉，视觉目标的感知理解方面的话，呃对只利用视觉信息，往往我们呃是获取到的这个有用的，这个呃信息的话，实际上是不全不够全面的。

然后只研究这个呃我们所谓的专用智能，或者是这个某个领域的这个针对某个问题的，所开发的这种呃模型的话，实际上他的这个认知能力是有限的，那么这样的话就是没有办法去应对这个多模态，非完整信息的呃。

感知理理解的这样的一个呃新的需求，因为我们人在感知这个世界的时候，实际上就是包括了呃呃触觉啊，听觉啊，嗅觉啊等等，它实际上本质上就是一个多模态的呃，但是在每种模态下，它所获取到的这些信息。

实际上呃更多的是这种非完整的信息，就是每种模态下面的这个信息是不完备的，那么怎么样去针对这种呃多模态非完整信息，这样的条件下获取到更精确的呃目标画像，来进行更好的感知理解，呃，实际上我们呃思考。

就是说从三个方面来进行扩展啊，一个是呃从视觉模态呃，来扩展到这个呃，各种各样的一些多模态相进行融合呃，另外一个呢是从这个从各个子问题，或者是各个垂域的专用模型来扩展到跨域的呃，通用模型。

然后呢呃面向的这个场景的话，实际上也是从这个之前的这种单一的场景，复杂度比较低的场景来，像这个多样化的一些场景呃，复杂度比较高的场景来进行拓展和延伸，那么最终的话呃，呃我们的目愿景的话是构建一个多模态。

多任务联合驱动的呃通用模型呃，那么实际上这个就是说从呃视觉垂域建模，到这个多模态统一和多任务协同，这个也是呃呃所谓的需求牵引突破瓶颈，有这样的属性，就是说它既符合这个国家的一些需求和指引。

那么同时的话也是呃，近几年这个国际上面的这个研究前沿，那么这个是我们所设计的一些呃，研究的这个思路性的一个一个架构啊，就是说呃针对这个探究多模态非完整信息，语义对齐和多任务协同机理，这样的一个科学问题。

我们从哪几个方面来入手，那么主要是从四个方面啊，一个是多元融合，就是解决这个呃多多模态理解的这个问题，然后再到这个通用模型的设计，解决模型的设计问题，然后再到这个多任务学习。

解决这个多多任务学习机理的这个这个问题嗯，再到这个增量学习呃，持续优化嗯，然后也分别呃去这个寻求一些不同层面的，这种呃创新，然后最后面向嗯比如说区域安防啊，聚神智能啊等等一些不同的应用的场景。

来进行这个呃验证和呃赋能呃，那么时间关系的话，我在这里面可能不会介绍一些特别细的，这种技术细节呃，主要是一些这种呃介绍这个不同呃，研究这个内容下面所面临的挑战，或者是一些呃这个纲领性的思路。

那么在这个多模态建模和语义对齐里面，实际上我们主要是想要解决这个，怎么样去实现呃，这个多元异构信息的优势互补和交互协作，那么得到各种各样的一些信息融合的这个，通用学习的这种啊框架，那么主要哦。

我们考虑的话就包括两个两个大的部分吧，一个是多模态数据的离散结构，表示一个是这个特征啊，语义空间的这种对齐嗯，呃就是把这个不同模态的数据来进行，隐空间的解耦啊，利用这个呃强鲁棒性的离散表征空间。

对这个数据进行建模，同时的话引入这个呃语义空间对齐的机制呃，实现这个呃多模态信息在这个隐空间的呃，真正的这种对齐呃，然后第二个这个内容的话，就是通用模型的设计和轻量化呃，这个里面主要是要考虑怎么去编码。

不同尺度的这个多模态的信号，来提取模态间和模态内的这个复杂的交互关系，并且在这个多任务学习呀等等呃，一些任务里面呃，来来这个减小我们的计算量啊，那么也是包括了两个部分，一个是多尺度的数据的长城建模。

还有这个多模态的呃联合表征学习呃，呃这个在多任务学习里面的话，我们主要是要考虑怎么去设计，这种多模态的输入和多类型任务的，一一种轻量化的这个模型的架构，来实现一体化的这个多任务联合的处理，呃。

实际上就是要研究清楚这个多任务学习的呃，机理和机制，因为大家都知道多任务学习的过程中，有些任务是相互促进的，有些任务是相互抑制的，呃我们要搞清楚这个机理和机制的话，才能更好的进行这个多模态呃。

多任务统一的这种呃学习和表示，然后最后一个的话是增量学习，就是说怎么去构建一个统一的优化框架，来不断的去处理我们这个现实世界里面的，这个连续的信息流呃，构建一个共享的这个表征空间。

来增强我们模型的呃小样本学习能力，零样本学习能力和泛化的能力，让我们的模型在实际的问题里面，能够呃不断的迭代，不断的进化啊，不断的这个变得越来越聪明啊，这个也是呃不管是学者也好。

还是这个呃产业界的这个这个同仁们也好，所关注的一个一个比较重要的一个问题啊，实际上我们现在就是在呃在基于这些方向的话，也在也在不断的去做一些研究和探索，然后很多研究成果的话，我们不久都会放出来。

嗯不久都会放出来，刚才这个双勇老师讲了一些成果的话。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8ef6b86adda6ce65bcc59d00cd9134e4_5.png)

实际上是里面的呃某一些维度，然后其他一些维度包括我刚才讲的呃。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8ef6b86adda6ce65bcc59d00cd9134e4_7.png)

后面我们不断的会有这个新的成果，会跟大家见面嗯。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8ef6b86adda6ce65bcc59d00cd9134e4_9.png)

然后最后的话做一个小的总结吧，就是说呃现在人工智能发展的非常快啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8ef6b86adda6ce65bcc59d00cd9134e4_11.png)

每一天都会有新的进展，每一天都会有新的呃这种啊突破啊，虽然这个未来可能呃是不确定的，但是我们相信这个未来一定会越来越好，然后呢我们也是希望跟各界的同仁们一起，我们一道呃，大家一起努力。

然后呃让一些不可能变成可能好谢谢。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/8ef6b86adda6ce65bcc59d00cd9134e4_13.png)

感谢赵建博士的精彩报告呃，让更多的不可能变成可能，然后下面有请观众提问一个问题，有吗好嗯，刚才老师说的那个关于无无人机的那个，就是它的距离控制和那个识别的问题，我也关注过这个一点嗯。

我是用那个想用那个什么呀，透视空间了，这就是找坐标，就是它没法聚焦和坐标去控制它的距离，到底是哪里，当时我刚才看到那个视频里面也有用光谱，用光谱来做，但光谱它的甘肃干干扰的那个因素太大。

其实它就是可以用呃，建筑物的坐标用地标是吧，这样子的话我觉得可能会解决这个问题，对啊，您说您说的这个很好啊，就是说我们实际在实际应用里面啊，在实际应用里面去，解决这个反无人机的问题的时候。

实际上是包括了三个子系统啊，一个是预警探测，一个是防御处置，还有一个是指挥控制呃，实际上跟这个感知相关的，就是在这个预警探测里面，那么在预警探测里面的话，我们是本是一个多模态的，是一个多模态的。

就是说除了视觉的这个设备以外，视觉的设备就是指指的这个光电探头，带转台的光电探头，有有这个红外的市场，也有可见光的市场，然后它上面带激光测距的嗯，然后呢，此外的话我们还包括了这个雷达的探测设备。

和无线电频谱的侦测设备，所以实际上就是一个多模态融合，来解决这个目标位置信息，和他的这个其他的一些关键信息的探，测的这样的一个问题，当然我们在做这个学术研究的时候，因为我们可能更多的。

比如说涉及到这个多媒体呀，涉及到CVE呀这样的一些问题的时候，我们可能主要关注这个在在一些视觉领域，怎么更好的解决这个目标的这个呃，状态和趋势信息的感知嗯。



# 2024北京智源大会-大模型前沿探索 - P7：圆桌讨论;主持人 - 智源社区 - BV1yS411A73A

啊感谢各位讲者，然后能够参加我们的圆桌，在开始我们的圆桌之前呃，有人问过我一一个问题，我想分享给大家，是这样的，就说呃大家说大模型时代来临了以后，给各行各业带来了很多的挑战，很多人都说很多行业没有了。

或者说就业机会产生了大量的萎缩，那么对于我们来说，如何应对这个挑战，在这一个问题，我给了一个比较形象的比喻的回答，是这样的，大模型时代来了，就有点类似于，在以前马车时代和汽车时代的一个变化。

马车时代来的时候，很多马车夫，然后养马的人员会说，我们未来是不是职业会消失了，然后我给出的一个答案是说，虽然说马车行业会消失了，但是汽车行业发展起来了，汽车的上下游的产业链，包括城市快速路。

高速公路等新鲜的事物都出来了，我们可能要看得更长久一些，然后发掘出来更多的机会，然后可能会对这些时代变革带来的挑战，会有一个比较好的应对，然后呢在今天我们想呃，针对大模型对我们所有人带来的挑战。

展开一个探讨，我们接下来将会从大模型的科研，技术创新的角度以及产业的角度，最后对诶，我们每个人可能会产生什么样的变化的角度，三个方面来阐述，然后下面开始我们的第一个议题啊，是大模型的幻觉和安全问题。

大家都知道大模型发展至今呃，虽然说幻觉问题，较两三年前已经有了很大的进步，但是还是面临着很多的挑战，包括安全问题，即使大模型的各个厂商做出来了非常大的努力，但是仍然有非常多的安全问题被攻破被出现。

所以说想请各位嘉宾来分享一下，幻觉和安全问题的一些理解，好谢谢，然后我们接下来由双永博士，按照这种方式来进行，您先第一个嗯好的好的嗯嗯啊，叶璇博士说这个问题啊是关于呃幻觉和安全，其实幻觉和安全。

这个我个人认为从两个方向来讲吧，因为刚才其实呃我也在讲呢，电信其实在做很多的应用场景的落地，那其实从应用角度来讲呢，确实对于幻觉是呃这个肯定是要避免安全问题，肯定是要这个也是要避免的。

所以这个其实是要从一个产品维度，带着产品维度的思考，那么怎么样从问题的维度，甚至说产产品形态，它的输入控制上做很多的一些限制，还有包括从答案生成的结果上，那我们怎么样。

通过这个也是在产品和系统维度做很多的一些，限制来控制这个，当然模型本身的持续提升肯定是要继续的哈，但是就像叶娟博士也提到，虽然这个幻觉和安全的问题我们持续在提升。

但是现在离这个100分还只是说差距越来越小，但是并不呃，从目前这个模型本身的它的原理来看哈，是基本是不太可能实现100分啊，完全控制的，所以还是要从上下游的这种输入，输出的产品形态也好啊。

系统维度去进行很多的控制，那这是一个方面哈，从应用场景那其实在大模型呃，我这里边当模型可能我们单指这个语义，当模型啊，那语义大模型本身来讲，那安全和幻觉在有些维度上，它可能是不希望限制啊。

比如说在真正的一些长文写作，或者在文学创作上，他可能就是需要一些幻觉，甚至说一些安全问题呃，甚至在在我们一些场景上，可能叫反社会反人类的这种这种话语，但是在出现在一个小说里，好像可是可以接受的啊。

所以这个可是不同的应用场景，所以其实说我们要给它一些不同的呃，一些定义吧，所以我觉得从这两个角度来讲，当然我们现在目前可能更关注的是第一点哈，从这个问题本身来讲，其实我们更关注的是第一点。

然后在这个维度上，其实刚才呃在技术上也提到了，从SFT啊，到DPO等等各种维度的这些限定上，我们要持续的加强，因为有些时候其实我们的限定啊，包括这个安全和幻觉的场景的限定。

其实也是在一个呃一个特定的维度上，甚至在这个问题本身，它是有一些呃国家和地域的一些不同的对吧，那同样的一个言论可能在不同的这个模型，不同的这个呃地域上，他可能对它的理解也不一样，所以其实呃就目前来讲。

那可能一个是这个世界维度的统一模型，那在这个问题上估计就做不到对吧，他可能在一些数学能力上，全世界是统一的，但这个维度上就相对来讲就很很难去统一，所以这个这也是一个点。

那这个其实也就涉及到我们在使用一些，因为现在可能有的厂商是自己做模型哈，还有的是用掉一些GBT等等的接口，那在这个问题上，可能涉及到的处理方式就又会不同，那时间问题可能要不我就先说这么多啊。

好像博士对我是比较同意那个宋博士观点啊，因为这幻觉也好，安全也好，就是在我看来你是针对用户说的对吧，那幻觉有人觉得幻觉不好，那幻觉还意味着创造力呢，就你从那个而且你从那个机理上看对吧。

他就是next token prediction对吧，我的预测空间放窄了，可能幻觉就小了，但我有的时候我就要它在很大的空间里面预测，所以看的是你要他什么能力吧，所以就是说反正我建议啊就是从技术上改进。

也没有必要对吧，那就是你像一个人读了好多书的时候，你人脑有的时候都记错了，都会生成幻，都会生成这个出现幻觉，你还还非要这个要求机器就是绝对不出现，那可能就没不太有必要吧。

对然后你又从那个应用的场景上对吧，那我们就可以挑一些，这个幻觉没那么大危害的场景，优先用一用对吧，然后你要说这个特别特别严格的这个场景，那我就干脆就不用或者是少用对吧，那那只能是从这个方向来限制。

就安全也是一样的，就有的时候可能叶璇你觉得安全，然后我觉得不安全，那我就说这模型不安全，那其实不是这样的，我们对这个模型来讲也是不公平的对吧，就还是针对用户来讲呢，就我个人观点啊，先说这么多啊，喂好啊。

刚才松博士和哦，不是刚才讲了，从从用户从应用那个角度来讲，那我就从基数这个角度来思考一下，幻觉和安全啊，首先是先讲幻觉啊，首先我个人觉得吧，幻觉这个词该怎么去定义大模型，如果纯N2P的大模型。

他他有他幻觉也许也许吧，但是像多模态的，就说你给个视，给个视觉的输入，然后让你去回答其他，这里面幻觉他有可能又不一样，为什么你去说是吧，你有可能你说的东西和那个图没啥关系，那这种算不算幻觉。

所以有些东西就看从技术上看如何去定义啊，那至于像刚才而不是说的，其实就是那个next predict，有可能你就像我们做成与兼容，从技术角度，你接错了一个词，那有可能后面接接接接接击鼓传花是吧。

你后来就传着传传传走了，你反正是找那些比较比较比较接近的，有可能在训练过程当中，有可能你船走了一步是吧，到后面就走走走走，然后他就产生那种幻觉，这是技术角度，但是是不是可先不从用户找到。

是不是可以解决呢，呃我觉得这个就在于什么，其实如果啊假设啊，假设你如果只是希望他是记这个东西啊，只是把那些数据集给记住啊，你的模型非常大，你那个数据集是有限的，如果记住你训练那个损失降得非常非常低啊。

并且你给的那个题目是一个ACTLY，就是一模一样的啊，如果你损失降低了，那这个东西其实它是不会产生幻觉的，但是在不会产生这种幻觉的过程当中，就像刚才而不是说的，有可能他没那个发发散力啊。

它有可能在做的过程当中，他没有那个diversity，有没有那种随机性，像很多生成模型，它其实要强调一个随机性，就像大家如果现在要做视觉，做扩散模型，为什么扩散模型它会比那个干效果好嘞。

是因为扩散模型它每一步它都有个APACTION，加加了点NOIZE，它那个信息量会大一点，传统的干它只是在刚开始的时候随机采样一个，之后就是个函数映射啊，属于这个diversity啊。

所以这里面要有个trader of，所以从技术的角度来看，我个人觉得幻觉这个问题，首先第一你要要很好的定义好是吧，你要要定义好了，你才知道它到底是不是问题啊，然后再帮你解决。

如果咱们要再去把它定义好了以后之后的话，要从技术手段，其实有可能是从那个什么优化，从礼盒或者从数据集有可能去往前去走的，而不是一个宽泛的，在从用户那个角度，他是个幻觉点，至于安全性这个问题。

这个就比较大了啊，安全的话它分两个层面吧，就是像王博士我们做那个项目，科技项目安全的话，如果从它有个呃security和一个safety，safety有可能是指什么，它有可能是指有些一些描述。

它有可能不是安全，这个安全对对A是有安全的，就比如说有些言论是吧，但是对B是不安全的，那另外一个安全性是什么，就从技术上像神经网络种脆弱性，它那种对抗鲁棒性，它本质啊本质上它有一些脆弱性。

像以前大模型出现之前啊，对对抗攻击，这个其实是一个非常active，至少在高校它是一个active的方向，是因为那个成本比较低，相对现在大部新来的一样，也是啊做做这个方向，相对来说你不需要训，你。

就只要用它，你去分析它就行了，所以在这个方向上，它其实就是本质上还是那个模型，那个鲁棒性啊，它本质上就是因为你我们需要梯度是吧，如果你能够超过那个梯度和最后的落实，那你这个东西解决不了的话。

他肯定会有方式，无论你是让他越狱还是对它进行攻击，还是进行一些其他的，让他想，你指定他去说什么还是下毒，他都有一种方式，从技术上能够使得它不安全啊，好这是我的一个见解啊，谢谢啊，好再见博士嗯。

这个大模型的这个幻觉问题，就是可能大家就是通常所说的，就是说在生成一些结果的时候，它可能会产生一些不准确的，或者是一些虚构的这样的一些信息，那么可能对于某一个领域的话，呃，某些领域的话确实会是这种挑战。

呃，刚才各位专家说的，我也都同意，那么呃这个幻觉问题是怎么产生呢，可能主要是因为就是说他在，它是在这个大规模的多样化的，这种数据上进行训练，然后呢呃这个模型的话呃。

是通过这个模仿这个数据里面的一些pattern，来来生成这个最后的结果，那么这样的设计的话，就会导致我们的呃这个模型在一些领域上面，它可以表现出来比较强大的，这种语言处理的能力啊。

比如说我们刚才呃也有专家讲到，就是在一些吟诗啊，或者是写作呀这种这种呃一些任务上面呃，这个可能幻觉问题反而是一个好事，嗯但是呢就是说在有些领域啊，比如说像我们这个问题里面提到的这个财务啊，金融融啊。

呃包括我们的一些医疗啊等等啊，包括决策呀等等一些领域，可能这个幻觉问题它是一个致命的问题，所以我们呃可能也需要一些策略，或者是一些措施来来缓解幻觉，或者解解决朝向。

解决这个问这个这个问题去去去做一些事情，那么比如说我们可以结合一些呃专家系统，或者是呃集成一些领域的这种呃专家知识呃，呃设定一些规则来来去缓解这样的一些问题，因为现在已经呃有这样的一些方式了。

比如说呃让这个大模型在输出结果的同时，也给出它所呃这个依据和参考的这个出处，那么这样的话可以在一定程度上缓解他的，这个呃缓解缓解问题嗯，嗯所以我们确实也还是需要在这个方向上面，做一些呃研究和探索呃。

来就是发挥这个大模型在呃处理这个大数据啊，处理一些复杂计算它的上面的一些优势的同时，然后呢也能够去降低它在一些领域上面，可能存在的一些风险和隐患，好谢谢好，谢谢谢谢，十位专家呃，我感到非常的开心。

是这样的，就是说在以前的时候，比如说去年的时候，大家讨论幻影的时候，很多观点都是说，幻觉安全问题是一个必须要解决的问题，但是今天的社会专家让我学习到了，可能幻觉安全之类的问题，我们要辩证性的看待。

甚至来说有些情况下，幻觉可能是属于创造力的源泉所在，在不同的场景，不同的应用中，我们可能要辩证性的看待这些问题，以及我们如何定义好幻觉问题，包括我们定义好这个问题以后，然后用什么样的技术方法。

技术手段去有针对性的解决缓解等等，甚至利用这一个信维度的信息，来去做好我们的应用，做好我们的科研工作等等，呃非常开心能够学到这些，然后下面一个问题，可能也是目前啊大火的一个问题，就是多模态方面。

目前的话啊，open AI在今年年初的时候领先发布了骚扰，然后目前一个趋势是，无论是国内还是国外，有实力的厂商都在大量的跟进，然后我想请问几位专家呃，如何看待这个方向，是跟进还是说不跟进。

是坚持语言模型还是要坚持多模态走巨神智能，还是说哪条路线，然后这次问题我们从赵建博士开始，然后反过来顺序，谢谢呃，我觉得这个现在确实是这个open i呃，一直在引领着这个全世界的这个人工智能呃。

前沿的这个发展和进步，然后这个国内的话还就是这个智远，一直在引领这个前沿的这个方向啊，嗯实际上我觉得呃，其实这个呃，我们也有很多很多独独特的这个优势呃，在国际上呃，我们现在的这个呃创新的能力啊。

创新的这个人人才也都在不断的呃提升呃，所以一方面我们是跟进他们的一些技术发展的，这个呃潮流和趋势，另外一个是也是利用我们的，一些既有的一些优势，比如说我们呃大场景嗯，大数据嗯。

我们我们在很多的这个子领域上有快速落地，有快速迭代的这样的一些呃这样的一些能力，所以我们也是可以在很多的这个实际应用里面，不断的去找到新的问题，然后呢不断的去找到新的方法，呃。

我我我觉得相比于这个国外的话，我们在这些方面是有是有优势的，然后也坚信我们后面会走出来一条，谢谢黄磊博士啊，这个问题好像有点大，比较偏前沿去预测，首先第一就是嗯大模型，其实多模态呃，在讲多模特态之前。

我还是再强调一下大模型，这点就是首先大模型它能统一的原因是什么，我们语言能够描述各种各样的任务，我们以前人工智能它是强调要任务，分任务是吧，现在我们语言能够描述任务，那么它其实至少语言这块它是个B级。

它的输入是语言，输出是语言，这个是个close的解压，所以大大我先先从圆这个方向走那么多模态，那这个就不一样，因为你动物态你看怎么定义你的，如果输出输入全部是动物态，你的输出是语言。

其实这一条路其实是没啥问题啊，为什么，因为现在大家的一个思路，至少在我做小尺寸读模态，大模型的时候，我发现你其实一个一个pipeline是怎么做嘞，就是利用现有的语言能力。

然后你自己做多模态的每一个模态，它和哪个它和语言之间，我做一个数据的一个ALAN这种非对比的，无论什么，这种是数据集是可以构造的啊，也不搞，就像克里普最早这么弄啊，然后再再去顺一遍啊。

再用无论是像语言模型训一样，把对齐了以后，用transform门，这套基本上是能够走通的，其实难就难在什么，你的输入是多模态的，你的输出是语音和多模态啊，如果你不经过语言这个枢纽。

就是现在有很多你经到了语言，然后语言在条件到到到到到输出是吧，那你难的难点是什么，你的那些动模态你能不能描述你的那个任务，这是一个最核心的一个难点，你如果描述不了那个，或者你有可能能够描述任务。

但是你那个信息量就是你那个有譬如说图像，因为我我最早做视觉是吧，视觉他那个描述它就非常不精确啊，你没法没法精确的描述，你就是现在有一些方向做纯视觉的大模型啊，只是说就是只把所有的任务的问题。

全部把它变成图像，就是你目标检测的话，我也不说什么，我就直接那个框给框出来，只以以视觉那个方式去做，的确是可以能够类似于那种接龙一样的方式，做出个效效果，但是那个效率非常低啊，训起来就会要非常多的数据。

然后效果也没那么好，但是一旦把语言介入，把语言做个输入，你会发现它的效率会非非常非常高啊，所以我个人觉得如果按照人去，按照以要通往AGM吧，我觉得语言还是个枢纽啊，虽然我不是做N2P的。

但是我我我我我不不可否认，的确语言是个枢纽啊，因为语言的话，至少我们从历史上文字是吧，我们是有了文字，我们才有个传承文字，那个信息量就非常大，我们能够能够读读读古是吧，同样的我们能够和人去交流。

也是语言啊，所以当那个信息量非常大的情况下，所以以它作为一个接口，我觉得再把动模态给接进来，我觉得这个我先不说是AJI，但是我觉得这应该是一个不错，应该是一个不错的一个方向，至少啊哦这是我的一个理解啊。

啊好像不是对我的观点是这样的啊，就是如果一味的跟进美国，那就一直被牵着鼻子走对吧，人家发布SORA也好对吧，GBTFO也好，人家可能有更先进的对吧，已经基本上ready了啊，然后过一阵就一发布。

然后咱就乌泱乌泱跟着去，这个就会就很被动啊，我感觉啊呃就刚才我其实特别同意，刚才黄老师讲的就是语言啊，是人类对这个世界的一种编码，嗯嗯而且编的还挺好对吧，就是比较高阶的一种编码，比你多模态对吧。

现在大家一说多模态就是啊视觉语音啊，语音可能跟文字还比较相关，特别是视觉视觉，可能是就是某种程度的低阶编码，我理解啊就至少没有语言编的那么好，所以就是说多模态模型，大模型我觉得可以做。

但是呢不一定是按照老美的那一套理解啊，就我的理解大概是说，你看如果说这个多模态的大模型是世界模型，是对世界的一种什么sam how，这个仿真也好，或者这个那个的那谁是生活在这个世界上的呢，是我们人啊。

就我们人每天感知世界的这个角度对吧，视觉也好，语言也好，那我们其实在这个世界上生活，还产生了好多数据，比如说咱们每天衣食住行轨迹的这些数据对吧，这些数据咱们中国比老美多多了对吧，那这也是一种模态啊。

那人在地球上生活所产生的这些数据，那也是对世界的一种编码对吧，那是不是我们可以去主导，就是训练一些，至少在这个模态上还增加一些轨迹类型的呀，或者是就是人在社会上生活所产生的这些数据。

这些数据可能一是美国没有我们多，第二就是人家可能也不想不能用对吧，隐私这那的啊啊，当然我们可能对这方面的要求，没有人家那么那么高对吧，就咱们可能对隐私的这个要求低一些，而且咱们有隐私计算框架嘛哈。

还是能保护咱们个人隐私的，就把这些东西拿起来，那是不是就可以扭转过来这个局势对吧，我们可以产生另外一种定义的多模态大模型啊，里面包含了人在社会上生活，所产生的这些数据啊，然后训练出来了以后。

是不是就能够牵着美国鼻子走啊，这是我的观点啊，啊好的呃，首先我是觉得哈多模态这个方向肯定是要做的，但是我非常同意郝老师说的，这个我们是不是要呃出SORA就学SORA，出SOO就学SOO。

这个可能一直就追不上这个例子，我在想这个可能举一个另外一个例子哈，比如这个中国的汽车，刚才您提到的是马车和汽车，我们现在提到是这个，我想提到的是这个传统汽车和新能源哈是吧，那真的按照原来的这个发展路径。

我们在这个燃油机，发动机，还有这个这个这个安全上，其实如果真的按传统汽车去追赶的话，那可能到现在我们就现在这个哎，追SORA和追SOO一样，但其实在新能源这个方向，其实走出来一个自己自己特色的路。

那其实在这个维度我也在想哈，照这样的追赶可能一直是在追赶，那其实在别的维度上，是不是有一些呃新的切入点呃，其实我自己想的是，比如就在无人机这个场景，那针对无人机它的这种感知上。

它可能不是这种像像语言类的哈，它可能就是各种声音类的，因为如果是战争无人机，它可能要对这种炮火声是吧，枪弹声它有更更更多的感知，那针对民用的话，可能是一些比如这个汽车鸣笛等等，避免碰撞等等。

其实在这个维度上，我们是不是可以有一些特色的这种，多模态的能力去产出，我就适配在无人机上，然后我就这个比如中国的这个假设，就比如大江这个品牌，那之后可能就是搭载了最适合无人机的。

这种多模态模型的一个更先进的一个，一个这样的一个一个能力，那其实我们在这个某些维度上去追去去去超越，其实还好，如果真的是在通用的这种呃文声视频也好，或者是这种多模态输入，多模态输出方向上。

那可能首先最难的一点就是在数据积累，因为这个数据积累其实不是说呃，比如像刚才我提到这个语义大模型那样，可能大段大段的文本拿过来做基础模型，这个以以前有的问答拿过来直接做SFT，它可能不是现成的。

好多数据是要重新去构建的，光是在数据构建这块可能追赶的时间就很长，所以我觉得是可以想别的切入点啊，这是我的一个输入，好感谢几位嘉宾啊，呃解答非常精彩，就比如说我举个例子。

然后敖博士刚才您提到的就是属于方向，是否要追随孙永博士提到的这个新能源汽车，确实可能对于我们来说呃，既要脚踏实地，还要仰望星空，我们可能要发现，对于我们来说，对于我国来说，我国的优势是啥。

我们的电子支付等等各种方面，生活娱乐方面都做的非常好，那么把这些相关的数据给收集整理起来，是不是就能够开辟一种新的路线，然后是不是可能会引领一下大模型的发展，我觉得这是属于我们在座的呃，青年科技工作者。

我们在座的都属于青年科技工作者了，可能都要常思考这些问题，有可能会走出来一条不一样的道路，最后达成商用模式，提到最后的目标，是不是我们也能在大模型领域能诞生出来，我们的一个大疆，如果能诞生出来。

那绝对是属于我们非常好的一个进步好，然后那我再接下来那个呃，跟各位嘉宾探讨下一个问题啊，呃也是一个比较宏大的问题，就是AGI它路在何方，然后像是昨天开复博士提到了一个问题，呃。

它目前像是聚神智能从来不投，然后他只投一些他认为现在能发展到的角度，但是呢呃有另外一些专家学者的观点，是属于可能是属于聚神智能，就是未来需要全部的凹进进去，那么呃以及是否还有其他的道路呢，有军事智能。

有其他的录制，有可能这个巨神智能不是人形的，也有可能是人形的，还是说其他形态，还是说各种其它的可能性，还是说一个纯物理呃，或者说纯信息时代的一个这种形态呢，比如说大家看过头号玩家这部电影。

它就是一个纯信息的一种形式上的这种AGI，不知道这一个问题大家怎么看，这次由那个双鱼博士来开始啊，好的，其实感觉这两个问题还是有很多的相关性哈，因为其实AGI呢通用人工智能。

那最开始语言大模型让大家看到这个希望，但其实现在感觉越来越不满足于这个，这个单模态哈，后来这个从文生视频到这个呃，文本语音和图像视频，但其实在我看来，好像这些模态先加入到这个AGI这个方向。

或者叫多模态大模型里面，是因为这些之前在机器学习领域做的比较深，但真的要谈到AHI或者叫聚生智能这个方向，或者叫世界模型，那我们模仿人类哈，人类其实听到的不光是别人说的话啊。

看到这个文字以及一些呃这种这种呃视频，其实在我看来，他可能听到的很呃，他可能吸收入到的信息是非常多样的，非常多样的，因为其实包括人的联想，那我看到这个视频，可能我想要后面有大屏幕，还有包括这个声音。

我可能听到的声音不光是大家在说话哈，可能这个各种什么汽车鸣笛啊，甚至惨叫对吧，都能让我想起什么古代的一首诗，其实这种维度，所以其实我们现在的这个多模态，离这个屈臣智能在我看来可能还是比较远。

它没有实现人的这种全面的一个功能哈，包括对我对自己，包括人其实还有一个点在于对历史的一个理解，那其实我对历史的理解是可能过去30多年，好多事情的一个总结，但是现在就这个模型本身来讲。

它的输入的限定长度是非常有限的，他不可能做到这一点，所以其实很多很多问题都还没有解决哈，呃所以可能只是在这个路上的一个，初步的探索啊，可能现在欢呼还有点早，好像不是我是我，我个人反正比较看好剧深嘛。

就是我觉得巨深，是这个把不同调技术路线给统一了，就其实就是咱们就是计算机学科，然后现在讲这个embody力的AI是吧，那人家那个机器人学科就一直都在做这个事，都多少年了啊，然后还有包括控制的。

那现在就是大家好不容易，就相当于是一个共识了对吧，但我觉得就是说embodied这个内涵，倒是可以探讨一下，就是他到底是说是呃人形的一个什么AI，然后去替代人，还是说跟人更好的什么那个叫做共生啊。

或者怎么样，就包括呃这个原来就很多人研究什么脑机接口，我觉得都可以纳入到所谓的这个，巨深的范畴里面来啊，然后可能更需要的是说呃，就特别是科研界吧，我就我这个自黑一下哈。

就科研界总是说哎我要去当那个老大对吧，就是就embodied，就我计算机学科要先做出来，而不是你控制领域，或者是你不能是你机器人领域，那其实到了现在这个阶段，我觉得大家还是应该这个合作吧。

就为了所谓的什么人类命运共同体也好，各个学科应该是贡献出来对吧，你擅长这个机械控制，你擅长机器人的，然后我们擅长算法的合作起来，大家共同实现这个东西，可能会加快这个所谓通向AJI吧。

否则的话还是各做各的，然后自己想呃，从自己的优势出发，把别人的这些全都包圆，那可能会比较低效啊，好啊哈哈哈，这个问题比较宏大，首先第一AGI这个概念这个定义啊，这个反正肯定有定义，这个本来是最最难的。

所以它本身就，但是我就感觉，现在我和我们好像对AI的要求太苛刻了是吧，又希望他能干啥都又需要比人好，各种各样的能力都好，都有是吧，我就这是这是这但这个是好的，这是什么，至少我们有一个目标在那啊。

这是这是这是这是好的，那么至于embodied，是不是通向AGI那条路或什么音，但我个人觉得就是embodied就是每一个技术，它它它的发展它肯定有个史，就是有个历史感啊，就到了这个点的话。

的确应该是EMBODIAI了，为什么这么说呢，就是如果我们是按照人AI是啊，我们是按照模仿人去的话，人的话其实叫什么，我们我们我们学院经常会提的就是感知，认知决策啊，这个我们经常说的那感知的东西是吧。

就视觉给它接进去认知的这块东西的话，也有可能有知识表示，但是N2P这块东西，它是能够得到一个输出是吧，就是像deep DeepMind他们做的时候，像他在做决策的过程当中，他也是把语言模型借出去。

有有那种action也是当这种语言的这种输出啊，所以之后就是真正的决策，决策的过程当中，你做完决策，你不是说我嘴巴说出来，或者写了一段字就行了是吧，但还得要一个actor，一个行动，就像我们人是吧。

我们嘴巴得动一下，我的声音才出去，我手动一下是吧，我才能够才能够干个啥是吧，那搅动一下才能够走啊，所以这个行动肯定是要必然的，如果按这个方向，那么那为什么那是这个时间点。

就是为什么in my body i，为什么红白是因为我们感知和认知，在大模型这个驱动下，大家觉得诶好像差不多了是吧，你如果你的输入实际上我像刚才讲的啊，如果你的输入呃是视觉的或者语言的。

你的输出是语言这个东西其实的应该是很快啊，我我这这个我不能这么说，但肯定是比较快，所以你只要你的决策，因为我们人去想这个决策的过程当中啊，你肯定是能够用语言能够能能描述的，这是可表达的，那这样一来。

那之后就是你一个行动了，所以这样串起来在这个时间点它就火，这也make个sense啊，所以这是我的一个理解啊，啊好赵建博士嗯，对这个AJI的话，可能大家就是普遍认为是。

它是跟人类的这个智力水平相当的一种，呃智能的这种呃状态，或者是能够完成人类所能完成的，一些这种智力水平的呃一些任务呃，这样的一个智能化的这种呃系统啊，嗯然后呢呃也有很多说法认为这个大模型啊。

或者是世界模型啊，是通往这个API的一些必由之路，嗯但是呢可能现在大家也都或多或少的认识到，大模型有这样那样的一些问题，然后世界模型它可能实现起来，就是说他要跟世界，他要能够理解世界。

然后要能够呃跟这个环境来进行一些交互，要有这个物理规律的这种认知呃，它可能实现起来是非常困难的，所以我认为这个AGI，它它的这个实现路径的话，可能呃嗯肯定是一个渐进式的，是一个分阶段的一个过程。

在不同的时期会有不同的呃代表性的，或者是大家聚焦的一些方向，来朝着这个这个这个最终的这个目标来，来这个演进呃，来演进呃，但是我觉得现阶段的话，跟这个AGI的这个目标还距离还是挺远的。

其实嗯就是从这个底层的这个学习机，机理或者是机制来讲的话，我觉得可能现在展咱们这个模型的，训练和学习的方式，跟人的这个学习方式就是有很大的区别的，现在大模型的这个，就包括咱们之前专家们做的这些报告。

现在大模型学习的这个方式，还是读万卷书的方式，可能人并不是这样的人，不需要去读一堆的书，我才能认识一个事物嗯，然后也不需要花费那么多的呃，这个所谓的算力或者是资源的开销，来去认识一个事物嗯。

它可能是一个长期的这个知识和经验的积累，然后再加上对于一些新事物的呃一些理解呃，但是这些理解可能是一些模糊的嗯，然后呢他他就会呃获取到这种呃新的知识，或者是新的技能。

所以我觉得现在咱们这个优化或者是学习的，这个呃方式的话，可能还是需要这种颠覆性的创新，那么未来才会有一个通往AGI的一个，更好的方式，好谢谢感谢感谢几位嘉宾啊，呃我觉得这几个问题我我我问的问对了。

然后学习到了很多啊，是这样的，就是说呃包括AGI，目前的话大家已经有了一个目标，但是呢如何实现它目前的路径是否可行，是否有更多的路径，是否可以探索出来，其它的形态，包括多和学科的融合。

不同技术的交互等等各种方式，目前的话确实是没有一个达成一个统一的状态，但是这正是我们巨大的机遇，如果像其他的一些已经成熟的技术那样，那可能这个对于我们来说，尤其对于我国现在的状态而言。

反而是一个呃不是那么有利的状态，但是现在这种状态下，反而这一个事情能成为一个有效，激励我们所有人长期前行的一个方向，下面那个向各位嘉宾请教一个产业呃，方向的一些问题啊，主要是两个方面。

第一个是属于产业的方向，然后目前的话大家都在，很多人都在讲AI加的场景，那么大家认为有哪些场景，会兼具这种研究和落地的价值，这是一个方向性的问题，然后另外有了方向很重要的一个点就是风险。

那么我们选中的方向，有哪些潜在的可能性的风险呢，会带来什么样的危害呢，以及有了这些风险，那么可能在座的各位专家，有什么应对风险的建议呢，好这一个问题请啊赵建博士那边呃，这个方向的话。

我觉得其实有很多方向都是非常有价值的，然后前期的话我们也经过了一些思考，和和这个论证，呃，我们觉得呃现在我我这边的话主要有三个呃，这个这个方向也在在探索啊，一个是刚刚才我也在报告中介绍过了。

就是这个呃无人机的这个综合管控，那么不管是呃，呃从这个反无人机的方向来来来来思考，还是说从这个低空经济运维的方向来思考，就是因为这个后面，咱们国家的这个低空资源也逐步放开了以后。

肯定也要建立一套空中的这种交通规则，那么需要这个对空中的这个目标，它的这个运行啊，包括这个一些情况来进行这个探测，来进行这个管控运维嗯，所以这个可能也是一个很好的方向。

包括跟各个领域的一些技术做一些结合，然后第二个的话就是这个林地安防，林地安防，我们认为仍然具有很大的，这个研究和落地的价值，因为现在不管人工智能，发展到什么样的一个程度呃。

大家都在做一些呃这样那样炫酷的一些研究，但是实际上人工智能最好落地的一些场景，还是在安防上，安防能够创造很大的价值，嗯包括在电信这边，我们有很多很在全国各地有很多很多的摄像头。

然后呃这个安防仍然是其中一个很重要的一个，一个一个一个方面嗯，然后在这个里面，就是刚才我讲的这个无约束条件下，其实还是存在很多种这个挑战，我们需要去解决，然后第三个的话，就是我们现在也是在结合大模型。

多模态和生成式做一些事情，就是做一些agent相关的这个，智能体相关的一些一些工作，因为这个呃文达不是也指出，这个智能体研究，可能有四个方面是比较有价值的嘛，啊一个是反思啊，一个是这个这个规划啊。

一个是使用工具的能力，然后还有一个是多智能体的协同嗯，我们现在主要是在做这个呃，利用大模型来做一些工具使用的一种呃，我们认为这这这些方向的话，可能未来构建这种智能化的私人助手呃，智智能化的这种助理呃。

会是一个很好玩很有价值的一个方向啊，然后这个安全风险的话呃，可能存在几个不同的方面吧，呃昨天我在那个新同苑开这个呃，开这个人工智能伦理方面的一个会，就是这个工信部那边制定了一个，关于这个人工呃。

人工智能科研和开发的一个人工智能呃，伦理方面审查的一个一个一个办法，然后在里面我们也提到了很多，这个可能潜在的风险和解决的对策，可能主要包括几个方面啊，一个是呃简要说一下，一个是数据的安全和隐私啊。

一个是模型的误导和不实信息的传播，还有一个是网络的攻击和模型的安全，然后还有一个是这个偏见和不公平，那么针对这样的几个呃风险的话，我们认为可能从几个方面来来进行，这个采取一些措施呃，可能有一些缓解呃。

一个是净化我们的这个训练数据的这个来源啊，还有一个是提升模型的准确性和透明度，然后再有一个是加强模型的安全性，测试和伦理安全方面的监管，好谢谢哈哈哦，我我在高校也不在产业，所以我这个没法给一个具体的。

那我就讲点虚的是吧，讲我感觉啊就是首先第一在咱们国家是吧，首先你要说产业方向，其实看上面那个文件一般是面向国家战略需求，面向人民的生命健康是吧，但还有一个像我们高校还是面向世界科学，科技前沿。

这个不是产业的事啊，所以这是一个虚的，那么之后如果要真要去要真要考虑方向的话，怎么去思考呢，这个我个人觉得就是，首先你得要知道你那个场景，那个产业的场景，因因为我我没做产业。

所以我只能只能根据我自己的理解，你那个产业的场景对于这个效果，就是它那个精度或者那种可控要求有多高啊，如果你是一个非常对于精度啊，就是让它回到非常就不能让他出错，或者不能让他弄的话。

我个人觉得目前大模型还没到这个，这个这个水平啊，这就是传统的那种小的小模型，专业化的模型，它其实也还还没到那个水平啊，所以这是这个，但如果你能够容忍他出错，有时候它还能够他出错，它还能够比较有趣是吧。

那种娱乐性质的，我个人觉得这是这是肯定是没什么问题的，但只要你能够让他输出控制啊，控制它输出的那些内容啊，不违反法律或者不违反一些什么样的事情啊，这个是这个是可以的，但这里面最重要的原因是什么。

还是从技术那个层面啊，就现在虽然这些模模型效果是不错，但是如果当你玩多了以后，他其实很大重大的一个问题是什么，它很多东西它不可控啊，这是一个最这是一个其实这是个技术问题啊。

但也有可能通过一种什么产品那个方式，像以前咱们做搜搜索引擎是吗，可以什么名单那些东西可以控制，但从技术手段上，从模型那个训练，包括他那个优化技那个层面，这个可控性的确是很难的一个问题啊，至少从技术上啊。

现在这个这个是我的一个理解啊，谢谢对我的理解就是反AI包罗万象啊，就我还是拿大模型举例子吧，然后同样是来自这个科研院所，所以场景举不出来，我就举行业吧，就反正我个人个人认为，就是行业数字化程度高的。

然后数据格式比较统一，规整的，肯定是优先落地的，然后就比如说金融啊，电信啊肯定是优先的对吧，然后相比其他的可能更传统的，比如说什么农业，可能的他可能就要稍微滞后一些啊，然后对我现在这一个风险。

我自己个人挺担心的啊，就是现在我看嗯，反正我接触到的啊，各个行业的这个同仁，都说我们要搞这个行业大模型啊，我我我跟金融企业合作比较多哈，就是这个四国有四大行，都要做自己的所谓的行业大模型啊。

每个行搞一个，就将来你真的说一旦这个大规模落地了以后，我对能源就很担心啊对吧，所有的你想所有的这个这个这个实体市场主体，然后都有自己的一个所谓什么垂玉大模型，然后每天跟那跑对吧。

那我们消耗的最多的其实最后是电力哦，那可能整个对这个国家的民生都造成影响对，所以我的建议就是说，大家在这个行业大模型的这个构建上，还是要稍微审慎一点，或者说得有一个统筹吧。

啊就就其实这个重复建设也没不太有必要，还是大家联合起来，可能比如说电信行业的一个大模型行不行对吧，这个银行业的就一个嘛，然后完了用的时候也是类似于共享，那这样的话可能也会造成避免嘛。

避免造成一些这个资源的浪费哦，我就说这么多啊，我个人理解其实AI加可以分成两个维度哈，第一个就是之前完全没有这个呃，使用AI的场景，那么现在添加到AI，然后还有就是之前其实已经是AI化的。

只是现在因为这种大模型啊或者技术的提升，把AI的能力的做进一步的也是对应的提升，可能分成这两个方面，那第一个呃我先说这个提升吧，其实现在因为大模型，最开始大家可能引起大家的这个注意呢。

就是在这个交互方式上，那突然他能这个问什么问题都能回答了，然后现在包括又添加了各种的模态，那其实我觉得在各类的传统的对话，相关的维度上都可以做一个AI加，相当于是AI技术的一个提升。

那比如像刚才提到智能客服，比如像这个家庭陪伴，还有甚至像这个博物馆讲解等等，但凡涉及到交互的，其实都可以做在这个AI维度上一个提升，然后另外一个点的话，就是这个之前完全没有AI。

现在要这个基于大模型也好，或者更新的这个AI技术的一个一个呃添加的话，其实现在反而倒不是很有明确有这样的方向哈，因为确实即使没有大模型出现之前，AI已经发展了很多年，但凡能AI化的。

其实都已经得到很多的探索，所以我觉得更多的还是一个AI技术的提升啊，这个AI加，我觉得是在原有AI的基础上，去加更多的AI的一个深度，就是这样一个点，然后我就补充这么一啊一点好，谢谢宋云博士呃。

感谢几位嘉宾啊，就是说各位嘉宾从AI家，从行业，从能源以及大模型的这个行业，大模型等等各种角度来分析了这个问题，让我感受到行业大模型目前的发展，探索之路可能还很漫长，需要我们所有人共同努力，然后接。

然后接下来的话，我们那个呃收集了现场的一些问题，然后这些现场的问题是针对每位嘉宾的，然后请为了节省时间，我们就每位嘉宾，然后直接简短的回答一下呃，第一个是给宋博的一个问题，在产业应用的层面。

强化学习是必要的吗，相对SFT有什么优劣势，怎么学习啊，强化学习强化学习啊，强化学习，这个其实跟我刚才讲的内容是很相关的哈，那其实在我们实践来看，强化学习确实是非常有必要的，因为呃就像我刚才也提到。

可能在不同的场景，我们对模型的要求也是不同的，而不管是电信也好，其他各个这个呃做这种产业化的厂商，那其实我们提供的能力，不管是对内对外，甚至就包括对内来讲，其实在不同的场景，我们也需要有不同能力呃。

模型能力的限定，那其实在这个基础上，我们不管是这个呃场景化的SFT，还是场景化的这种强化学习，包括这种PPO和DPO，其实都是非常有必要的，我们需要针对某些特定的场景化的能力，做定向的提升。

那这个时候的话就是呃，就会涉及到这样的一个点，所以我觉得这个问题的答案肯定是是啊，是是肯定的啊，嗯好对，谢谢邵云博士，下一个给敖翔博士的问题，请问在算力有限的情况下，您在大模型应用。

尤其是聚焦于对小模型的应用方面，有什么更多的思考与启发，对呃报告里展望也也提到嘛，就是说将来如果能够在这个参数训练层面，能够结合的话，可能是一种更好的方式，简短回答就是这些啊，哈哈好的，谢谢翱翔博士呃。

给黄雷博士的一个问题，在回归和生成任务上，LN网络是否有万能学习能力，在回归和生成是吧对哦，首先第一就是因为我刚才讲的那个是一个分类，然后因为机器学习就两个问题啊，因为包括数据也就只有两个。

一个是离散的，一个连续的离散的问题，基本上是分类，然后连续的问题是回归啊，回归这个问题，现在我们这个结果是没有，但是我们现在学生在做的，在过程当中，基本上从直观上应该是可行的，但是那个不是无穷深了。

有可能是无穷宽，还有一些别的机制，这里面简单透露一下，但是还在做，因为那个整个数学的证明非常非常长啊，所以这这是这是这一个结果，至于生成这块，因为刚才我讲的，因为生成这块的话，这怎么去定义啊。

因为我说过经济学就两个问题吧，一个回归和一个那个分类啊，如果你的生成如果是一个，如果像那种predict，像像token这种预测，它一个分类一个分类的一个那种，他就是个分类问题。

如果你是像那个什么视觉那种直接去拟合那个，那它就是个回归问题啊，所以你是可以拆解的，但至于这个拆解过程当中，如何把那个条件信息把这个理论给加进来，这个其实是也是一个理论的一个研究问题啊。

这种关于条件的这种主从数学上往上走啊，这是这是我的一个回答啊，谢谢啊，好谢谢，黄磊博士给赵建博士的问题，大模型会给各行各业赋能，当下呃，未来大模型行业会增加哪些就业岗位，对个人的技能学历有哪些基本要求。

最后一个是什么，对个人对个人的技能和学历有哪些基本要求啊，呃一个直观的感受，我觉得呃，现在我我不知道大家以前看deep learning的paper的话。

可能大家发现这个deep learning的paper里面的公式非常少，然后现在如果看大模型的配分的话，或者是跟看这个基于大模型做一些呃，其他问题的一些paper的话，可能基本上就找不到这个数学建模了。

嗯所以我觉得可能更多的这个技能的需求的话，是一个系统工程方面的这种技能，或者是系统工程方面的思维，就是说从一个呃解决问题的视角，问题导向或者是需求导向，然后去去做这个科研也好，或者是应用的创新也好。

嗯嗯未来的这个可能比较好的一些方向的话，我们现在是在做一些基于agent的方面的，一些研究和应用，就是围绕这个衣食住，行用等等不同的方面来构建这种呃智能体呃，或者是叫智能的私人助手。

那么实际上在不同的领域的话，都有一些关键的技术，可以去跟大模型做一些结合，然后呢捆绑在一起呃，构成一个整个的pipeline呃，来这个给老百姓的这个日常生活中，所面临的这个方方面面。

来提供这种呃赋能和智能化的支撑，实际上现在也有很多这方面的呃，研究在不断的涌现出来，包括这个智能医疗啊，智能法律顾问啊，嗯然后这种呃智能穿搭呀，呃智能剪辑呀等等，实际上我们也是呃现在不断的在。

在这些垂直的领域要结合大模型，多模态理解和生成式等等嗯，来做一些这种呃前沿的探索和应用的创新，嗯也是欢迎大家如果呃感兴趣的话，呃到我们电信研究院这边来，我们一起来这个做这这些方面的一些，有价值的事情。

谢谢好，谢谢赵建博士啊，最后一个问题是给我的，如何客观评估数据的质量，然后这个地方我的看法是这样的呃，首先你自己要定义好什么是高质量的数据，我举个例子，广告黄赌毒这类信息是你需要的数据吗。

很多人可能答案是否定的，但是我们从另外一个角度来思考这个问题，广告本质上来说是属于人类创意的一个结晶，很多广告的创意都非常好，那么你适当的学习下自己创意性比较行的广告，会对你的模型能力是否有提升。

这是第一个角度，第二个角度，黄赌毒相关的信息，我们举一个例子啊，一个小朋友，他在他的这个生长过程中，比如说从小学到大学，如果完全没有接触到黄赌毒的信息，那么当他步入社会以后，对黄赌毒信息之类的。

这种分辨力以及抵抗力会是什么样子的，但是如果在他的成长过程中，我们适当的教导他这方面的信息，告诉他什么是好的，什么是不好的，那么当他步入社会以后，会不会有其他的表现呢，这一个问题也可以反映在。

这个大模型的训练过程中，你对数据的理解好，我就讲这么多，最后非常感谢呃，全场的所有的观众和全场所有的嘉宾，谢谢大家。



# 2024北京智源大会-大语言模型 - P1：论坛背景与嘉宾介绍-赵鑫 - 智源社区 - BV1zE421N7UJ

尊敬的各位来宾，大家下午好，嗯非常嗯非常欢迎大家来到我们这个呃，大语言模型这个论坛啊，相信大模型啊，这个名词可能几乎来在座的所有所有的听众，应该都很清楚啊，这是是这个这两年最前沿的一个技术。

也是最有可能呃实现AGI到目前为止吧，最有可能实现AGI的一条技术路径啊，但同时就是我相信可能很有很多人，也有很多的一个疑问，比如说大模型是如何去训练出来的，然后大模型底层的工作机制是如何去建立的啊。

所以我我们今天这个论坛啊，就是不能对于针对所有的问题都给出，非常清楚的呃非常确切的一个答案，但是我们试图针对这些核心的问题去做一次，深入的一个呃探讨啊，所以我们这次技术论坛。

我整体上定位还是技术上应该是比较硬核的啊，我们也是邀请了可能呃全国这个呃顶尖高校，包括呃训练大模型的顶尖公司来的，青年的技术人呃，技术人员为我们来讲解呃，包括后面我们还有一个PO讨论。

去探讨这些最底层最核心的一些技术问题呃，那我们首先就先开始我们的第一个报告嗯，我们第一个报告是来自于北京大学的赫迪老师，我先简单介绍一下赫迪老师嗯，赫迪是赫迪老师，是呃北京大学智能学院助理教授。

然后前微软呃亚研院主管研究员，那么他所从事的方向主要是积极学习呃，算法与理论方向的研究工作，然后已经在呃呃重要的期刊会议上发表论文，多篇引用次数超过了8000啊，然后他所设计的模型和算法。

多次被deep man的open i呃，微软meta等国际顶尖机构所使用，然后也曾经获得机器学习顶级国际会议，ICLR的杰出论文奖，和ICLR2024的杰出论文提名奖啊。

那下面我们就呃邀请嗯请这个赫迪老师。

# 2024北京智源大会-大语言模型 - P2：是否所有Transformer结构都具备思维链推理能力？-贺 笛 - 智源社区 - BV1zE421N7UJ

呃大家好，我叫贺迪嗯，我们知道大语言模型实际上是一个，现在非常非常火热的话题，不仅是在工业界的时候在讨论这个问题，在学术界，甚至是在这种创业界都是在讨论大语言模型，它的问题是什么。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/30792d249317985b8a89af76a387746b_1.png)

并且大语言模型它能够解决的东西是什么，如果让我们去说这里面的几个说好，现在大语言模型发展得这么迅速，那么它背后最重要的一些技术是什么，那么对于我来说，我可能会说。

transformer这样的一个模型结构，是让大语言模型表现出这么强大的实力的，这样的一个最重要的环节之一，当然除了穿梭门这样一个模型结构呢，还有像英伟达这样，提供了非常非常多的这种训练资源的这种支持。

那对于穿梭门来说，实际上它也并不是没有竞争对手，或者是说现在其实有很多很多的工作，不仅是来自于国外，也是来自于国内的，很多很多的工作都在试图挑战穿梭门的王座，为什么这么说呢。

因为transformer本身它的确是有些问题的，其中一个最大的问题就是它的效率的问题，我们知道transformer，它里面有self attention这样的一个机制。

那么当他去放在这种比较长序列的上面的时候，self attention在处理长序列问题上的速度，实际上是非常非常慢的，这样就会导致你的序列非常长的时候，穿梭门需要花非常非常多的时间去理解。

或者是去生成这样的一个长序列的东西，那为了解决这样一个问题呢，其实学术界和工业界设计了非常非常多的方法，这些方法每个方法都有各自的名字，但是总体来说他们有一个字体，整体的一个名字。

他们都叫做这个efficient transformer，这种高效的穿梭门，大家会采用不同的技术路线，比如说第一种办法是说，我去减少一下这个key value pair的数量。

那么一般时候我们会管这样的模型叫做sparse，Transformer，他的代表工作呢是g b t two，比如说第二类方法，我是去reduce1些dimension。

尤其是涉及到长度的dimension，这样它对应的模型呢叫做low rank transformer，比如说像呃meta的informer就是类似的方法。

第三种呢是去reduce这个这个soft max，里边的一些computation，那这样对应的方法呢，一般我们叫做linear transformer，当然了，上面的三种方法是非常非常基础的方法。

它们之间可以相互之间的复合使用，那么会构造出非常非常多的模型的变种，比如说像我们现在知道的这个s four，包括像最近非常非常火的曼巴，包括曼巴two，包括国内的一些模型，像RWKV。

包括像微软的模型叫做RENET，都是围绕着类似的方法，试图去降低transformer的计算效率，但这个时候就会出现一个问题，就是当我们看到这么多的模型，有这么多的穿梭的变种。

那当我们面对一个实际的任务的时候，我们到底该如何选择模型去完成我的任务呢，或者问一个更本质的问题，就是有这么多的模型，到底哪一个模型是我们的真命天子，它可以真正的完美替代，传送门这样的一个结构呢。

那这个实际上就是一个非常非常重要的问题，那为了回答这样的问一个问题，我们先去看一下我们有可能得到什么样的答案，比如说我们现在面临一个task，我们管这个task叫AOK。

我们的目标是使用类似transformer这样的结构，去解决这样一个task，那我们可能碰到的第一个情况是说，所有的这些模型OK我采用相同宽度，相同深度这样的模型，这样的模型我都可以去解决。

这样的它一个task a，那在这种情况下，显而易见的，作为刚才我们提到的这些efficient transformer，它显然是能够解决task个A，并且它的速度比TRANSER快。

那这个时候毫无疑问的，我会选择这样的一个efficient的穿梭门，作为我的transformer的替代品，但第二种情况是什么呢，第二种情况是说以fusion的穿梭，而不管上面说的哪一种穿梭门。

它都没有办法解决这样一个task a，但是有可能transformer可以解决，那在这种情况下，我们显然就会得到一个结论，就刚才我们说的这些efficient transformer。

实际上它都并不太work，换句话说，如果这个task a是一个我们非常关心的task，我如果能够从理论上告诉大家，以pn transformer就是做不出来，那这条路可能就是走不通的。

那还有第三种比较tricky的setting，这个setting就是说，efficient的transformer也能够解决，但是呢只不过它需要的参数量，可能要比标准的穿梭门要大一些。

比如说它可能需要更多的层数，或者是更宽的宽度去解决这件事情，那对于这种情况下，我们就需要仔细地去算一下，以vision的transformer，去解决这个任务所花的计算时间。

和transformer解决这个任务所花的计算时间，到底哪个多，哪个低，哪个多哪个少，那这个实际上就引出了一个理论上，大家比较关心的问题，就是K我们看到了这么多的网络结构。

transformer r w k v曼巴，包括RTNET这样的结构，那这些结构他的表达能力到底是什么，他表达能力的上限到底是什么，它到底哪些任务他可以做哪些任务，他做不出来，那这样就引发我们去思考。

OK我看到这么多的模型，它的表达能力到底是什么，表达能力，实际上是在深度学习理论里面的一个，非常非常经典的问题，我觉得像呃，大概在座的所有人，应该都是做和深度学习相关的呃呃呃领域。

但是我觉得可能并不是所有的人都比较关心，穿梭呃，都比较关心深度学习的理论，因为深度学习理论这个东西，其实它真的指导实际的作用，相对来说是比较弱的，比如说在80年代的时候。

当我们知道的第一个深度学习的理论，实际上就告诉我们是说，OK深度学习的这些模型或者神经网络，它有着非常好的表达能力，因为它可以去拟合任何一个连续空，间的连续函数，当然我们会管这样的一个定理。

叫做universal approximation，也就是说我一个神经网络，只要你的足够宽足够深，不管是你是MLP还是什么复杂的网络，它都可以在一个连续的空间内去拟合，任何一个连续函数。

那这样的一个结论，大家去想它有什么实际的意义，或者是说它能够指导我们去设计，或者是理解我们现代的神经网络吗，那这个里边的指导意义可能相对来说比较小，但相对来说比较小的原因。

一个是说它这个这个这个考虑的网络，可能比较简单，但另外一个其实主要的原因是说，它所使用的这个假设相对来说是比较强的，所以比如说在这个里面我突出了两个地方，它都是假设continue。

也就是说我关心的是在一个连续的空间内，我的一个神经网络，我去逼近一个连续函数的能力，但是如果我们去看现在我们的大模型，实际上它这两个假设都是不满足的，比如说我们在大模型里面，我们的setting是什么。

我们的输入是离散的token，我们的输入是一个vocabulary，里面的一个一个token，而我们输出的也是这个WORKERLI空间里面的一个，一个token，那所以从这个角度上讲。

它实际上是一个sequence to sequence的mapping，那显然它不是一个这样的连续的空间，连续的这种抖妹上面的一个mapping，那它就满足不满足我们后面的这个continue的这样的。

一个要求，第二个很重要的问题是啥呢，第二个很重要的问题是说，我们所有现在训练大模型或者使用大模型，我们都实际上是用的finite precision，比如说你如果要训练非常大的模型。

你可能需要用BF16这样的一个精度去做，当然你如果训练一个比较小的模型，你可可能可以用这种FP16的精度去做，那在你这种精度限制的情况下，相当于是说不管是你的中间的输出，还是你的输入。

还是你最终得到的结果，在某种意义上，它实际上都不是连续的，那在这种情况下，实际上K我也不是一个连续的函数，那如果从这两个角度上来看好，我的模型，我不是一个连续的这样的一个映射。

我本身任务也不是一个连续的任务，那这个就相当于意味着我们80年代的时候，以为的这种万能的这种神经网络的表达能力，万能的这种神经网络逼近任何一个函数的能力，在我们现在的这样的一个setting下。

实际上它的意义并不是很大，那换句话也就是告诉我们说，我们其实现在对现在的我们的所使用的，这种language model，它的表达能力，它的上限是什么，它的limitation是什么。

我们实际上一无所知，那过去的这些theory，或者是一些theoretical的一些analysis，它其实在某种意义上也不一定说它是严格的，非常的适用于我们现在的这种实际的，这种使用的情形。

那我们也需要去开发一些新的SIRI出来，那讲完80年代的工作以后，我们再讲一些最新的工作，那最新的工作实际上主要都是围绕着，去理解这种大模型的表达能力，那大模型的表达能力很多，它可以做很多的事情。

那比如说我们最新在学术界，比较关心的就是大模型，它去解决推理问题，他去解决数学问题，他去解决这种规划问题的能力，因为这些问题实际上是大模型，相比过去的BERT所展示出来的新的东西。

嗯说BT已经解决了很好，相对来说比较好的解决了一些语义的理解，当然我们看到大模型里面，他做出了很多的这种推理呀，规划的能力，那我们会关心，为什么大模型可以做这样的一些，非常复杂的事情，那第一件事是。

我们在刚才我们讲述的这些更新的假设下，也就是说考虑到了这种sequence to sequence mapping，同时我们也考虑到了，整个我们的训练是在一个低精度下的训练。

我们最新得到的理论结论是什么呢，我们最新得到的理论结论是说，OK在我们的language model里面，这种思维链，它对于planning和reasoning是非常非常重要的，为了得到这件事情。

我们需要用两件事情来说明，第一件事情是说如果给了一个穿梭门，这个穿梭门是一个非常非常大的模型，我如果希望这个transformer能够直接生成，答问题的答案，比如说我们关心一些比较典型的问题。

比如像右边图里面展示出来这样的问题，就是一个典型的四则运算问题，那理论上我们可以证明，如果我们希望一个transformer，它能够直接生成一个四则运算问题的答案，这件事情在理论上面是没有任何可行性的。

为什么呢，理论上我们可以证明，如果一个transformer，我希望你这个transformer，直接去解决这个数学问题K的话，那我们可以得到的第一个东西是说，穿梭他的表达能力。

如果让他直接去解决这样的一个问题，的表达能力，它所对应的计算复杂度的类叫做TC0，TC0实际上是一个计算复杂度的类，它可以类比于P和NP，但实际上TC0是一个非常非常小的，计算复杂度的类。

并且很多很多的这种推理问题和，规划问题和数学问题，它们所对应的计算复杂度，是要远远比TC0大的，因此经过这个两个结论，我们就可以得到一个第一个比较重要的结论，就是说transformer。

你让他去解决这样的数学问题，你让它直接生成答案，这件事情是根本不可能，原因就是说因为它本身让它直接生成答案，所对应的计算复杂度是TC0，而其他的很多的这种planning和reasoning的问题。

它的计算复杂度都会远远超过这样的一个，TC0的这样的一个类，第二个结论是什么呢，第二个结论是说，我们可以证明对于很多的问题，比如说一些数学的这种这种K4则运算的问题，或者解线性方程组的问题。

我们都可以证明，如果我对transformer，我不是试图让它直接生成答案，而是说我希望你能够一步一步的帮我生成答案，也就是说我可能去生成第一个等号，后面我只是解决了这个整个的四则运算的。

最高优先级的一些操作，然后第二个等号呢，我是去解决第二优先级的一些操作，然后这样不断的等号下来，然后我们可以证明的一件事情是说，在你使用COT的情况下，如果transformer能够使用COT的话。

那它的表达能力，它能够解决的问题，实际上会远远的超过这样的一个TC0的class，这个大概想法是说，因为在CUT下，我实际上模型每次只需要吐出一个中间的步骤，比如说我给我一个问题以后。

我先生成第一个位置的token，然后把第一个位置的token丢进来，然后再生成第二个位置的token，然后经过一个很长很长的思维链，我最终才生成最终的结果，那在这个过程中，大家可以想象。

我从我的输入到最终的结果之间，实际上执行了非常非常多次的这样的，transformer的操作，那它所带来的非线性性的提升，实际上远远的比你让一个穿送门直接生成答案，要大得多的，那这个实际上也是告诉我们。

COT在让大语言模型去完成推理上面，是一个必不可少的环节，那同学可能会问说好，我如果是transformer和cot合在一起去做，那它能够解决的问题的上限是什么，这个实际上也是最近一个工作。

这个工作的结论是说，transformer加上思维链了以后，它能够解决所有的P问题，并且是在polynomial step下面，那这个实际上就是给整个的transformer的，表达能力。

以及transformer和COT合在一起的表达能力，给了一个非常非常强的刻画，也就是说比如说我们关心它解决问题，那所有的在图灵意义下，可能大家关心的都是P问题，那现在的结论实际上是会告诉你们。

是说OK我有一个大语言模型，然后我加上这种step by step的这种chal salt，那我其实理论上边说，我可以解决所有的POLYNOMIO的问题，那我们刚才讲的所有的结论。

都是围绕着穿出门这样的结构的，但是我我们也记得，在我们在一开始的几页slides里面的时候，我们说的是说除了transformer以外，实际上它有非常非常多的竞争对手，那我们关心的下一个问题。

就是说可刚才的理论相对来说比较清楚了，transformer本身自己能够解决的问题，和transformer加上COT以后，它能够解决的问题是什么，那我们下一个需要关心的问题。

其实就是对于我们刚才说的那些，efficient的transformer，那它到底是不是能够去解决，上面说的所有的问题，比如说一些reasoning的问题，比如说一些数学推理的问题。

那我们采用的这个看的问题的切入点是什么，我们选了一个比较有代表性的问题，也就是所有dynamic programming的问题，动态规划，我们如果假设这个reasoning length是L的话。

那么对于一个标准的穿梭门来说，它如果去完成整个的这样的一个，动态规划的推理来说，那它的计算复杂度是OL方，这个我们其实刚才也展示了，transformer加上chem so的。

它是完全可以解决DYNAMI个programming的，但是我们会比较关心以fusion的transformer，刚才我们提到的这些模型，它是不是足以去解决这样的dynamic programming。

但是非常遗憾的是什么，非常遗憾的是说，我们刚才提到的很多的efficient transformer，它本身是不具备解决任何一个dynamic programming，问题的能力，那换句话说。

我如果已经有一个EVISION的transformer，不管是说我刚才提到的一些中的一个还是什么，那我假设我的这个模型，我已经的size我已经定好了，比如说我模型的深度已经定好了。

我模型的宽度都已经定好了，那我们在理论上可以证明，这样的一个以皮神的transformer，它是不能够解决所有的dynamic programming的问题的。

那这个实际上是一个比较negative result，换句话说它相当于告诉我们，我们过去可能认为很多EVISION的结构，它实际上在解决一些复杂推理问题上，他会都遇会遇到一些本质的困难。

而且很有可能这些本质的困难，是没有办法被解决的，OK第一个点是说，一个constant size的EFUSION的transformer，没有解决这个问题，那没有办法解决这样的问题。

那到底一个什么样的efficient的transformer，有可能能够解决这样的一个问题呢，我们给出了一个结论是说，如果你希望一个efficient的transformer。

能够解决这些reasoning的问题，那么它的模型的大小，要比一个标准的transformer要稍微大一点，比如说我们给了两个结论，K展示了两种非常特殊的efficient transformer。

第一个是spars transformer，第一篇spars transformer，也是第一篇linear transformer，我们给出的结论是说。

如果这样的两个efficient transformer的结构，你期望它能够具备解决reasoning问题的能力，那么你需要这种模型的宽度，也就是说它的hidden dimension的宽度。

是要随着L有一个增长的，其中这个增长的skill大概是根号L，如果感兴趣的同学可以去算一下，如果你这样的一个以替身的穿梭门，如果你能够让它的模型的宽度，随着长度是去增加的，即使是在这种情况下。

你会发现这样的一个EFFICI的transformer，在这样的一个宽度设计下，实际上它去解决所有的dynamic programming的问题，它的计算复杂度你会发现它也是L方，那换句话说你会发现。

如果你要是为了去解决这样的推理问题，如果你希望一个efficient transformer，它足以去解决一个推理问题，那它的计算时间其实和标准的穿梭，没有任何区别，那这样意味着什么。

其实意味着我们刚才提到的很多的一批，TION的transformer，它首先本身不具备推理问题，第二如果你希望它具备推理问题的话，它实际上并不会节约任何的时间，我们针对这样的一个问题。

实际上也做了一些实验，但我们都做了些一些相对来说比较简单的实验，比如说我们会做四则运算这项的实验，那在一个比较简单的这样一个，四则运算的setting下，OK我的横轴是我的dimension。

而我的纵轴是我问题的难度，然后呢我把它是否解决这个问题，用颜色标出来，如果这个颜颜色越亮的话，就代表着我这个模型解决了这个问题，而我如果这个颜色越暗的话，就代表着我这个模型没有解决这个问题。

然后我们也比较了三种不同的模型结构，分别就是我们刚才说的一个标准的transformer，一个linear transformer，以及一个spars transformer，从这三张图里面。

从这三组图里面大家可以清楚地看到，首先一个标准的transformer，它这一横行，实际上它的黑上黑色的点非常少，那实际上就意味着是说，我可以在一个相对来说比较dimension，比较小的维度上面。

我可以比较EFFICI地解决所有的问题，但是大家也可以看到，对于这样的一个linear transformer，和对于一个spars transformer，他们去解决这样的推理问题，所需要的这个宽度。

会比标准的transformer更宽多一点，体现在就是下面的两张图里面，黑色的点非常多，而第一行的时候黑色点非常少，那实际上就显示K比如说最后一个，我如果看sparse transformer。

去解决最长上升子序列这样的问题，你会发现它的dimension，即使到了512或者1024，它都没有办法去解决，但是你如果看标准的穿梭门的话，他去解决最长上升子序列这样的问题。

DEM犬只要256就可以做到，这个实验基本上也佐证了我们的理论的发现，换句话说，如果你希望一个更快的transformer，你希望它去解决一些比较复杂的推理问题，那你就不能够使用的模型的size。

和一个标准的transformer一样，你就需要一个更大的size，然后以期望它能够去解决它，但是你当你size比较大的时候，那实际上这些更快的模型也失去了，他的这个这个所谓的这个效率的这个好的地方。

所以刚才所讲的内容，就是我今天想跟大家分享出来的内容，我们第一个想分享出来的东西，实际上就是说，我们可能对我们自己以为的，那些以fusion的transformer的能力过于乐观。

然而这句话也实际上也不是我说的，最近实际上有非常非常多的一系列的工作，那一系列的理论工作，这里面也包括我们自己的工作，都说明了一件事情。

就是efficient transformer实际上并不efficient，它其实跟标准的transformer，之间的差距是非常非常大，甚至这个差距是没有办法跨越的，第二个事情是什么呢。

第二个事情也是最近另外的一条路，也是最近比较火的一个东西，就是采用这种hybrid的model，比如说对于AI two，实际上他们design了一个hybrid的model。

如果大家真的去看微软的FI3，它的这个这个这个技术报告，然后它里面也会说它使用的是一个hybrid mode，这里的hybrid指的是说efficient layer。

和标准的dance attention layer相互叠，相互去这种交替的使用，但是它的优点是说好，它里面有相对来说比较少的这种DSLAYER，所以它相对比较快，同时呢从理论上讲它也能够避免很多的问题。

包括如果大家感兴趣的话，去看昨天挂出来的一个RKB，我也是刚刚看到，然后也是曼巴团队他们做的，他们实际上做了一个model，他们claim的效果是发现最好的，是一个曼巴hybrid，如果没有记错的话。

曼巴hybrid里面用了45%的，Mana layer，5%的dance attention layer，以及50%的MLPOK，他说这样的一个模型，他发现能够达到最好的效果。

并且也是一个比较好的EFUSION，自己的一个trade off，所以今天OK跟大家想share的，主要就是这样的一个东西，主要是关于transformer的一些理论的，能力的上限。

以及以fusion的穿梭门的理论的能力的上限。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/30792d249317985b8a89af76a387746b_3.png)

# 2024北京智源大会-大语言模型 - P3：理解与探索大模型能力涌现--东昱晓- - 智源社区 - BV1zE421N7UJ

然后大家下午好，我是来自清华计算机系的东云晓，然后今天给大家分享，我们其实在其实是我们做JL模型，系列模型做了很长一段时间，但是今天的报告可能更多的是过去半年的一些，呃成果，KOK那首先大家知道。

其实我们做大模型其实其实需要算力，需要数据，需要所有的这些，其实最终的一个前提是需要人对吧，需要我们过去呃，呃大约34年四五年的时间吧，很幸运，其实跟呃很多青年的同学，青年的同事呃，青年的老师。

还有那个那个在唐杰老师的带领下，其实我们一直在折腾大模型，然后我今天介绍的工作，其实主要是呃这几位年轻的同学和学者呃，在过去一段时间的一些成果，可那我们直接直入主题，其实我特别开心，那个赫迪老师。

刚才关于最后一个问题的那个答案，他如果说理论上已经证明了，我们我们应该怎么堆积木，或者是不需要堆积木，或者是怎么堆啊，堆多少，我觉得今天我这个报告就可以就轻松了，或者说我们接下来的这个这个工作就轻松了。

就不用像过去很长一段时间，相对来说非常焦虑的，这个跟大家就不得已的这种互卷大模型，互卷训练，互卷对齐等等一些情况，可那呃首先直入主题的话，大模型其实这张PPT或者这个截图。

应该大家在过去从ChatGPT出来之前吧，大家应该都经常看到这个图，就是那个JASONWEI他们在呃，那个在google和STANFORD一起合作的一个研究，他当时实际上就是empirical的呃。

揭示了一个现象，就是说随着就是比如说在这张图里，随着横坐标这个这个这个参模型参数量的大小，或者说计算量的大小，对相关的一些呃，这个学术的benchmark或者test set的一些成果呃。

一些这个这个所谓的performance性能，大家可以看当时的一个结论，核心它的一个imperial的一个核心的结论，就是说随着参数量的变大，实际上呃模型在呃达到一个阈值之前。

参数量或者是计算量达到阈值之前，效果其实没有呃，比随机猜，或者是这个普通的模型取得更好的一个呃，这个效果，那但是达到一个阈值，大约是一个百亿到接近千亿的一个规模时，大家就发现了所谓的这个量变引起质变。

这个现象，就所谓的他在论文中叫所谓的这个，Emergenability，咱们翻译成一般翻译成这个这个这个叫呃，大模型的这个能力涌现呸，那当然大家可能也知道。

去年的那个neurope outstanding paper，实际上是给了这篇这篇paper，核心也也当然也是来自STANFORD团队，他当他核心研究的一个，或者说它核心的一个结论是说。

实际上它从某种意义上是想说明说，其实这个emoderate ability，或者大模型的涌现能力，实际上可能与这个model的size，Model skill。

无论是by model size这个参数量的size，或者是by这个computer size，其实关系都不是很大，这是呃最上面那个title，实际上它是原文中的一句话，他就是说。

实际上可能更多的是我们使用的MATRIC相关诶，比如说他就说可能是，比如说左边的图和右边的图的对比，他就说如果我们用非线性的，或者这个非呃这个连续的这种metric。

实际上我们可能会观测到这个所谓的emergent，Ability，但是呢如果我们把它变成linear的这种score，或者是说呃连续的score这种metric的话。

实际上这个好像是随着模型的这个scale，up起来之后，其实效果并没出现所谓的那个faze transition，那个那个那个那个月变的那个过程，或者那个那个那个节点，可OK这是他们的一一个核心结论。

实际上对于我们来说，我们过去一段时间就是一直在训模型，其实也一直想了解说到底什么能够盖的，我们或者说决定帮我们做这个各种decision，当我们训练一个模型的时候，训多大，训多久，训多少数据量。

用多少计算量，实际上我们在做这个过程，最近呃应该是去年下半年，当然我们放出来是今年年初呃，我们有个同学叫郑晓，实际上他咳实际上也是GM的一作，它实际上就在呃训练大模型的前线呢，实际上就发现了一个规律。

那具体来说是，它实际上CONFIGU了大约七个不同的模型大小，比如说从3E参数55。400000000参数，一直到320亿参数，然后用不同的这个数据量的大小来训了，From scratch。

训了30几个这个所谓的大模型，然后看呃fix很多factor之后，看这个模型在这个这个downstream的各种task上，各种奔驰Mark上的一个效果，然后试图发现有没有一个潜在的规律，来帮我们呃。

指导我们更好的在做模型训练的各种decision诶，这是核心的呃一个结论或者一个观察吧，就大家可以看这个图的，每张图的横坐标是这个预训练的这个loss，就是loss是越来越呃越小。

然后纵坐标呢是在不同的benchmark上，它的一个效果，大家可以看上面四行呢，比如说在这样的数据集上，实际上大家可以看模型的效果，实际上与这个loss，当然这个是非常intuitive。

就是说非常直观的，随着loss的降低，效果其实是一个呃提升的呃一个现象，当然更重要的是大家可以看，实际上如果我们fix瑞星的话，大家如果忽略图中的颜色对吧，一点55亿模型呃，60亿320亿参数的模型。

如果大家完全忽略这个颜色的话，大家可以看，基本上这不同这个parameter size的模型，随着这个loss的这个降低，实际上它取得了不同的模型，在同样的loss情况下，实际上取得的效果是一样的。

K实际上某种程度上，我们如果想在某个奔驰Mark或者某些呃任务上，取得一个target的目标的话，target performance目标的话，实际上实际上最终一个中间的factor是这个loss。

但是当然loss又是由这个模型参数，当然计算量能够根据skin law能够决定出来的，K那更重要的是是下面这行大家可以看，当这个在相对相对来说比较复杂的一些任务，比如说MMLU呃。

还有GSM8K这些偏数学，偏推理的一些任务上，数据集上这个模型的loss随着模型loss降低，其实在前期我们发现它这个效果跟这个虚线的，黑色的虚线随机猜是差不多的，也就是说其实模型也没有产生相应的能力。

但是随着loss大约降到2。2到22。1之间，大家可以看这个模型的效果，其实突然有一个所谓的跟那个JSON，we第一页slide类似的现象，就有一个所谓的涌现的情况，就是模型突然开始有某种能力。

随着loss降低，不管你这个模型是320亿，还是这个这个15亿参数对，就是说，这个本质上其实与模型参数量大小没有关系，实际上更多的是与loss有关。

OK当然我们再回过头看去年NEUROX那篇best paper的，那个结论是说，实际上我们这个观察的现象，很有可能与我们所用的metric呃的连续性，metric的这个线性非线性与非线性相关是吧。

那我们经过这个所谓的算是abolition，也不算abolition吧，就算是一个对比实验，我们可以发现实际上按照NEUROPE那篇paper，Best paper。

outstanding paper的这个实验方法，我们采取不同的metric，实际上核心结论是没有变的，也就是说这个模型随着loss呃，我们预训练loss，降低模型的这个所谓的涌现能力。

仍然可以被观察到，可以，那因此的话，实际上我们就可以根据loss以及这个模型的size，当然结合之前那个open i的或者DeepMind的skin law，我们实际上可以把两个事结合起来。

就可以得到一个非常简单的，根据loss和模型size相关联的一个，关于EMERGENABILITY的一个定义，那最直接来说就是说，当模型loss小到一定的程度上，它才能涌现出来的能力。

我们叫做呃这个IMMORGAN呃ability，而不是原始paper当中，是说，当模型的大小，或者模型的计算量达到一定程度上，我们来呃这个出现的能力，才叫呃这个emergent ability，诶。

这是我们在呃这个模型，某种能力出现或者某种能力提升呃，前期做了很多观察，很多实验，但有了这个观察，实际上接下来我们就想，我们怎么真正的提升模型的能力，诶，那我们实际上从22年年初训这个千亿的GM。

130B模型，一直到呃去年年初的一代的对话模型，chat gm到二代到三代呃，其实上整个过程我们尝试把这个这个context sense，提升，尝试让模型有function call。

有这个多呃这个agent智能体的能力，那其实从诶其实在那之后呢，去年10月之后，我们其实更多是想怎么能够让呃，我们自己的GM系列模型，可以有更强的智能体系能力，可以在呃这个这个智能体相关的任务上。

取得更好的一个效果，其实主要的一个出发点或者动机，也是因为我们去年暑假其实想试一下，我们当时这个这个，这个整个LIM大模型的研究，或者是这个探索，其实关于这个智能体方面的这个理解，或者是是探索非常少。

然后我们发现就自己做了一个本benchmark，叫agent bench，就是说来看这个我们自己的模型，在这个智能体的各种任务上到底怎么样，然后做完发现，即使我们的模型包括其他开源的很多模型。

其实就是说在很多比如说MMU在gm m8K，在这个这个CEO等等数据集上，我们都可以取得接近或者差不多的一个效果，但是在智能体上，我们发现我们明显比，比如说当时的GB4那个版本。

当时的cloud那个版本有非常大的一个差距，但是我们就在想，怎么让我们模型可以有智能体的能力诶，那具体来说，比如说我们以GEM为例，如果想让它有智能体能力，有agent的能力，实际上就是说那类不同于呃。

也不能今天也不能叫传统的，不同于去年年初的那种对话模型，chat模型的话，实际上给定一个query，给定一个prompt，我们这个模型给一个呃。

next token prediction这样的一个任务呃，给呃一个response对吧，我们是希望这个模型本身，如果能不能基于这个模型作为一个智能体，然后如果我们问他相关的任务。

如果他自己能够判断说第一他能不能干这件事，如果不能干，他能不能自己planning，自己来靠外部的function，外部的工具来解决相应的任务，K这里图中是一个相应的例子，比如说我们让这个模型呃找呃。

找到从2000年到2023年全球的人口，并且把呃这个年均平呃，人口的这个平均呃年均增长率呃，呃这个年度增长率计算出来，K，那这个模型，首先如果不确定它是否有相关的信息，或者相关信息准不准。

这个模型可以自己做个判断，说我可以去上网搜，利用browser search engine来做，然后搜到了之后，自己可以打开相关的网页，自己决定打开哪些网页，拿到相关的结果，拿到相关的结果。

当需要算这个平均增长率的时候，他能够说我这个时候做一个DEDECISION，我需要自己写的代码，并且调这个外部的工具，把代码的执行了，得到相应的结果，然后返回来给我们这个用户呃。

这个以自然语言的方式返回相关的呃结果诶，这是我们的目标，那做这件事的呃怎么形容呢，做这件事要实现这件事，实现模型除了要有这个智能体的能力，或者是说这个这个这个这个感感知环境。

或者说planning action这个能力之外，其实一个前提条件是，模型需要有相对来说非常长的context length对吧，就刚才所有的这些信息，如果按照这个流程走一遍的话。

实际上模型所process这个context length非常非常长，可那实际上在这个过程中，我们就呃呃其实也探索了很多路径吧，当然开源社区有很很多各种各样的探索。

如何把模型由四K8k exchange得到，比如32K呃，128k，甚至最近这个疫苗领，那我们实际上在探索的过程中，有几个核心的发现吧，或者主要的发现，第一个就是说呃。

我们做long context的这个这个事情的时候，让模型有这个处理更长context能力的时候，其实除了在预训练阶段，需要让这个模型呃不停的外推，有处理这个long context能力。

其实在对齐的阶段，尤其instruction阶段，我们发现其实这个对最终模型的效果也很重要，所以我们在这个时候就呃呃提出了这个la land，这个strategy，本质上就是说怎么让模型更好的。

在长数据上做对齐，那同时还要保证，大家可能知道说今天对大模型做领域呃，微调或者相关的一些任务的微调的时候，很重要的一个挑战，就是说，当你当我们尝试把某一项能力提升的时候。

在这里就是超文本这个能力提升的时候，其实很多时候可以赢，很多时候会negatively的影响，模型在其他尤其是通用任务上，它已有的任务上的一个一个性能对吧，那在这个过程中，我们实际上是需要保证。

模型在长短和短文身上的这个能力，能够同时提升的很高，或者说至少在成本提升的时候，能够保证短文本的能力不被降低诶，那第二点就是说很自然的，当我们比如说以这个instruction，或者对齐数据为例的话。

我们在做这个微调的时候，或者做instruction tuning的时候，实际上在需要很精细的模型呃，这个数据配比，把这个长文本，短文本的数据能够很好的这个这个结合，然后在这个结合的过程就自然产生了。

这个当这个这个这个这个这个在一个batch里，不同的这个instance它这个长度不不同的时候，其实在计算的过程中会容易产生这个ADOTIME，也就说这所谓这个气泡。

那实际上这里我们就需要采用呃packing和soft呃，呃sorted batting的技术，然后尝试让这个这个尽量减少气泡的时间，那又同时我们知道在训练的时候，这个短文本和长本。

如果正常的把它这个在求算loss时候，正常的算一起的时候，其实合并在一起的时候，其实它会导致这个这个这个这个对loss的，contribution实际上是一个不均衡的状态，只要在这个时候。

我们也需要对于长文本和短文本对loss的影响，产生呃做一个所谓的这个waiting，或者做一个balance诶，那呃通过采用相呃相关的这些呃策略的话，实际上我们最终可以让我们这个模型的。

在成本这个instruction阶段，比如说训练的时候，能够大约有两到三倍的一个，训练效率的一个提升，OK这是呃基于这个技术呃，Framework，我们最近呃几个月又呃。

进一步把这个模型的context length，有128K，64k128 k，其实上个周我们刚开源了一个9B的模型，把这个context length推到了这个E没有那token，就是说如果汉字的话。

按照那个那个那个那个我开播的那个那个那个，token nether那个情况的话，其实也接近，是这个200万的一个汉字的一个情况，可然后这是我们自己在benchmark上测的一个结果。

大家感兴趣也可以试一下，就是说呃比如说那个9B的one million，就是下面最上面那个那个高亮的GM4，9b chat one million，这个模型呃，目前是上个周是开源了K嗯。

然后这是模型有了long context能力，那有了long context能力，现在我们就要专注于说，如何让模型的这个智能体agent能力进一步提升，对吧，那我们刚才提到了。

我们去年暑假发现我们自己的模型，在智能体的任务上，其实相比这个这个其他这个尤其是open i的模型，安索尔pk模型有相当大的一个差距，那在这个过程中，我们就发现其实核心的一个难点还是数据。

就是说我们设计或者说收集智能体数据的时候，其实非常难，那大家知道，那你如果做简单的SFT，做简单的对话的，实际上一个一个问题，你给一个这个写一段答案，当然这个一般也不是很容易，当然至少它是一个一对Q呃。

这个这个这个所谓的q repair问答，对对吧，那对于agent来说，我们可以想象一下，我们让这个模型尝试解决一件事，如果我们要让它通过调外部工具，通过function call的方式。

实际上某种程度上，在整个这个模型解决这个问题，它这个trajectory当中有很多很多的分支，比如在某一步失败了，在第二步失败了，在下一步成功了之后又失败了等等。

实际上这个对数据的设计以及数据的这个收集，有很大的挑战，实际上我们在这个过程中是设呃，设计并开源了这个agent instruction，呃。

instruct这个智能体的一个trajectory的数据集，本质上我们是呃simulate的六个这个智能体的，或者说六个这个环境，然后让这个模型在里面探索自己，这个这个这个也不能叫随机游走吧。

这个模型在里面产生相关的一些数据，然后当然也有些人类的呃，这个这个标注的辅助，然后让收集到相对来说还比较有效的，这个智能体轨迹的数据，然后通过混合训练的方式，可以通过少样本让模型有呃。

这个很强的智能体泛航能力，实际上最终我们只需要1800多条智能体，这个轨迹数据，就可以让模型取得非常好的，这个这个处理智能体任务的能力，诶，那当然同样的我们是声明的是六个环境。

在60个环境里很很直很直接，我们的这个模型取得了一个不错的效果，但实际上在这个这个这个其他的智能体任务上，它没有过经过微调的任务上，我们也可发现中间这个图，也就是说所谓的在外分布上。

实际上它这个泛化性也非常强，然后用1000多条的数据，智能体的轨迹，数据，就可以让模型在其他的这个智能体任务上，取得一个不错的效果，当然呃对我们来说，可能更重要的一件事是。

我们需要确保模型在智能体能力提升的时候，它的通用能力，比如说MMLU代码，数学推理等等能力不能有所降低，这是最右边那个图所展示的，就是说我们确保了在智能体能力提升的时候。

我们最关心的基础通用能力不被呃损伤，OK那有了这个line online和agent tuning，实际上是某种程度上，让我们的模型有更长的context length。

然后在这个context length上可以处理呃，这个有更强的这个这个智能体的能力，然后能够取得呃，对我们来说还不错的一个呃效果诶，那这是我们去年呃，今年年初一月份发布的推出的GM4奥拓子，这个模型。

实际上大家感兴趣也可以在智谱清源尝试，就是说比如说我们让模型解决一些相对来说，对于next token prediction非常复杂的任务，当下对next token prediction非常复杂的。

比如说这个X3次方加AX方减五，X加九除以X加四，一商是X方加BX减一，然后余数是13，计算AB的值，实际上模型在处理这个任务的时候，他前期通过整理，把这个问题转化成中间那个等式。

然后它自己做了一个decision，这个时候我需要写一段代码，把这个任务完成，它实际上是写了这个代码，并通过Python解释器把这个代码运行，得到了A和B的值，最终通过这个语言的方式。

把这个相应的结果返回诶，那类似的还有比如说多工具的一个混合调用，比如说通过就是类似于刚才那个例子，比如说查一下呃，全球过去十多年GDP画出趋势图，如果哪年GDP下降，在趋势图用红色标出来。

就右边那个图实际上就是模型，在网上拿到了相关的数据之后，写了段Python代码，通过嗯matt plot lib把这个图画出来，而且还满足我们的要求，如果哪一年的这个增长率下呃，GDP下降的话。

用红色的点标出来诶，OK然后呃我们相关的模型实际上也刚才提到，上线了质朴青研，然后其实用户现在可以自己，基于我们这样的一个通用模型，可以创建各种各样的智能体，目前大约呃用户创建了30多个。

30万多个智能体，然后更重要的是，除了通过这种界面式的方式access这个智能体之外，实际上每个智能体也通过，也可以通过用户创建的智能体，也可以通过API的方式访问，然后处理哎，某种程度上。

我们在尝试实现通过零代码创建智能体，以及呃通过智能体AAPI的方式提供服务。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/be16388cc13d0d006d2fedb1f57b3480_1.png)

K呃这是我们这个在语言模型上做了一些尝试，当然呃在这个过程中，我们也逐渐意识到，实际上如果以我们人为例，我们每天大部分的时间，可能都花在这两个屏幕上，移动手机或者说这个电脑上对吧，然后我们就想模型。

某种程度上能不能像我们人一样，在处理相关的这个这个这个故意或者，图形界面的问题时候。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/be16388cc13d0d006d2fedb1f57b3480_3.png)

能够有智能体的能力，可那首先呃我们团队的呃，丁明同学实际上带着很多年轻的同学呃，开发了这个coo v l模型，实际上就是一个呃vision language model，然后这个模型其实核心的想法。

跟当时在当时提出这个模型时候，其实核心的一个想法，或者当时面临的一个问题，就是说如何将视觉或者image，这个这个这个这个这个空间能够跟language model，能够很合理的对齐在一起。

同时让这个训练被cost不要太大，可那一般的假设是说，我们希望这个语言模型经过很长期的预训练，甚至对齐之后，这个语言模型是fix住的，或者说尽量不要对这个原模型做大的，然后在这个时候。

如何让这个视觉的这个这个信号，或者视觉的space能够呃，跟这个原模型的这个space alan起来，那我们的同学实际上就提出了在这个语言模型，就是右边这个呃架构图上。

在这个标准的transformer这个架构上，实际上外接一个紫色的，也就是说这个视觉模块视觉的export，让这个视觉模块，然后处理新来的这个这个呃email的图像诶，呃email的数据。

那在此进一步的话，实际上基于这个模型，我们的同学呃团队又提出了这个cover agent，实际上就是尝试解决这个视觉语言模型，在处理这个呃，比如说agent能力，尤其是处理我刚才提到的这个手机或者电脑。

界面的时候，其实它那个那个里面的这个视觉的这个，比如说各种图标啊，各种像素啊，各种信息，有的时候非常非常小，如果这样，这个模型在计算量或者说这个训练量不很大，提有很大提升的情况下。

保证这个视觉模型可以呃很好的处理，这种呃这种这种呃，这种需要高清晰度表示的一些任务，比如说呃，在1000 1120×120，这样的一个像素级别下，如何让这个模型在训练量不提升的时候，同时取得这个呃。

我们期待这个模型取得的一个效果，实际上呃在这个模型当中，我们的同学就提出了这个cross attention的机制，通过一个cross attention的model，然后让这个模型在能够处理。

低这个分辨率图像的时候，同时也可以用较小的计算开销，能够对这个这个这个这个所谓的这个，高清的图片能够进行同步处理，诶，呃这个是基于我们这个模型最新做出的一个demo，当然大家可能上周或者上周看苹果和呃。

微软的发布会，可能呃见过类似的，但是我们这个完全是作为一个第三方，从模型的视角没有利用windows API，没有利用IPHONE安卓API的情况下做出了demo，完全是模型，像我们人一样看着这个屏幕。

无论是电脑还是手机屏幕，做出的相关的一些呃反应，感觉卡住了，好像，比如这个是让他在呃就是给模型的指令，就是删除PB中的个人信息，目前的整个操作过程都是模型自己在操作，可关于点什么怎么点。

点完了之后该干什么，可，咦感觉这个电脑有点卡住了是吗，还是，OK那我们先看下一个，Ok，那接下来呢，呃进一步在手机上能够处理网页相关的任务时，我们又提出这个呃。

这个诶我时间可能差不多auto web g m，然后通过create rome，learning DP o以及拒绝采样等等相关的技术，我们搭了这样的一个框架，让模型的处理这种agent ent的能力呃。

更强的一种呃呃方式，OK然后这是我们最新出的一个demo，是其实是那个下面团队刘潇同学，带着大家一起呃最近折腾的一个情况，比如说任务是为我筛选出价格在100~300原，同时包邮的女性钱包产品，接下来。

其实整个过程完全是模型在操纵这个手机，可就每一步他根据他看到的结果，然后一步步操作这个手机得到的呃，相关的一些情况，比如这个时候他知道他要筛选，点开这个界面，他知道他要填什么，选包邮。

在那个价格框里选上相应的额价格，OK但是呢即使我们今天做的其实相对来说，在具体的这个task上，这个任务上做到跟GBT4O或者4turbo，差不多的一个任务呃情况。

然后我们最新的那个版本g m o s web，这个system其实也可以做到接近50%，但是其实离人类performance78%，还有相对较大的一个差距，K呃，接下来三个例子，包括在微信里，在地图里。

在美团订单里，我我们就快速跳过。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/be16388cc13d0d006d2fedb1f57b3480_5.png)

呃然后最后的话，实际上在我们开发各种模型的时候，大家知道就是各种各样的benchmark，各种各样的evaluation，其实都大多时候都不太靠谱，实际上我们也在内部。

也开发了很多的相关的benchmark，其实更好的get得我们指导，我们在我们做各种开发训练决策的时候。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/be16388cc13d0d006d2fedb1f57b3480_7.png)

能够更好的呃做design o k，然后最后一页的话，我实际上是想说呃，刚才那个鹤迪老师也讨论过呃，简单提到刚才有观众也问到相关的一个问题，就是说呃左边这个图呢是google deep man的。

我一个截图，当然大家都有各种各样的类似的一个plot的，核心就是说transformer或者是神经网络，给了我们一个SKILLING的可能，然后目前来说，至少我们自己不知道spilling的尽头在哪里。

从算法从数据的角度对吧，那目前来看模型，随着模型的这个SCALLING，模型的参数或者计算量越来越大的情况下，我们并不知道这个这个拐点，或者是那个那个地面。

should return的那个那个turning point在哪，可那从另一方面，从算力的角度，大家知道大家可能经常会说摩尔定律放缓，然后但是从英伟达最近几年，两三年给我们的这个输出来看。

像这个英伟达单卡的性能在提升，英伟达的这个GPU，在这个从系统层面单卡提升之后，把多个卡连在一起组成一个系统，像它的这个这个计算，flops或者计算性能，也在不停的这个成倍数的增长，比如这里提到的说。

8年有1000倍的这个计算效率的一个提升，那在这两个词scaling的这个拐点，目前我们还没看到的时候，我们接下来做一个，无论是从呃呃一个团队的角度，还是大家对大模型感兴趣的一个角度，大家怎么能够一起。

能够让这个模型继续死scaling下去，以及SCALLING的更有效率，skill in的更好，取得更好的效果，当然在这过程中，很多时候其实不仅需要工程上的技术上的探索，还有需要可能理论上的一些突破。

其实都需要呃，我们大家一起来一起来讨论，一起来探索，那其实也是个开放性的问题，留给大家，然后那我今天的分享就到这里。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/be16388cc13d0d006d2fedb1f57b3480_9.png)

# 2024北京智源大会-大语言模型 - P4：大语言模型知识机理与编辑问题：张宁豫 - 智源社区 - BV1zE421N7UJ

我是来自浙大的张宁玉啊，然后呃我今天介绍的这个topic，其实前面两个老师都有这个关注过，就是提到过，就是啊我们现在都知道大运行语言模型啊，它给我们带来很大的冲击啊。

它的效果其实在很方面都很多方面都非常好，很多以前的自然语言任务啊，基本上它的效果都已经达到了，一个非常高的一个高度，但它背后的这个原理又是什么啊，其实我今天这个PPT题目应该加两个字啊。

应该叫加上假说啊，因为我们团队其实在这方面，其实做了一些的这个探索和思考啊，但其实背后呢呃很难讲清楚，这个到底是不是一个真正的一个原理，或者真理啊，其实我们最后讲的很多都是假说。

那我今天主要会分析一下这个大型语言模型，从知识的这个视角，它背后的这个机理啊，可能是什么啊，以及我们如何去操作它背后的知识，也就是去编辑它的背后的这个知识啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_1.png)

那我主要介绍两个问题呃，一个就是语言模型，它去存储以及表达啊，我们的这些这个啊像人类的一些很多的知识，那语言模型到底是如何去存储跟表达，这类知识呢，啊这个是第一个问题，那么在这个如果这个问题能够回答好。

或者是能够有一些初步理解的话，那我们进一步又如何去比较精准的高效的去啊，更新它里边的这个知识呢，这是我今天可能要啊介绍的第二个问题啊，其实第二个问题也能够促进我们去实现，更加可信可靠的一些这个啊应用。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_3.png)

那围绕这个方面啊，其实呃我们都知道，这个其实有很多实际的应用啊，比如说这个语言模型，它有些时候它会有一些知识是过时的啊，还有很多啊有偏见的，甚至是有一些有毒的信息，这些其实这些问题。

其实对于我们实际的大模型的应用，其实带来了很多的这个困扰，所以有很多很多的这个呃技术一直在探讨，这个如何去更新，或者是如何去啊，修正语言模型中的这个知识谬误，这些背后的一个本质的问题。

还是我们需要理解语言模型中的这个知识，它到底是如何的去存储跟表达的，其实在这个方面啊，其实像呃我们国外的很多的这个公司。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_5.png)

他们其实已经在做一些很初步的一些探讨了，比如说像ASSOPPIC，他们前段时间啊有一篇工作啊，就是从可解释的角度啊，分析了这个像啊cloudy的一些大型模型中，它这个在呃里边的一些区域。

到底是如何存储一些表征，一些相关的一些知识的信息的啊，他们甚至把这些相关的技术应用在一些啊，安全啊，安全的模型更加安全的一些领域，那么其实open i在前段时间也做了一篇啊，放出来一篇文章啊。

他们其实是啊，通过一些sps out to encoding的方式啊，提取扫描了其中的啊带海量的特征，其中很多特征其实都跟我们啊人类所熟知的一，些knowledge是非常相关的啊。

它从里边特征的角度去发现，里边有一些特征，可能表致了某某一部分的这个信息，那么从更深层次的角度啊，原模型到底是如何去表征这些复杂的。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_7.png)

这种知识呢，啊那么我们从这个分析一个事物的一个角度啊，其实有两个呃维度，一个是从底向上，也就是说从神经元底层开始去分析。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_9.png)

还有一个角度是从顶向下，那么从底向上的这种做法呢，其实是啊从哲学领域叫做还原论的这种思想，之前有很多工作都在思考，就是说啊我们其实可以去分析分析，这个神经元或者这一个组件到底是什么，围绕这个视角。

其实前期已经有很多学者提出了，一些非常优秀的一些假说，比如说像知识神经元的这种假说啊，比如说某一些神经元，或者是transformer中的MLP，某一些layer可能表征了某一个事实的这种知识。

那么其实还有这里边存在一个问题，就是我们想象一下，其实呃知识是非常复杂的，他们知识与知识之间，其实存在很多很多的这个关联啊，其实像左边这个图的这个有一篇去年的呃，前两年的一篇science s工作里。

他其实发现人类人脑在思考或者是做一些记忆，或者一些深度思考的时候啊，不同的区域之间是有一些linkage，有些关联的，那么语言模型，它的这个区域之间，是不是也存在一个明显的关联性，我们是不是可以啊。

从一个整体论的视角，从自顶向下来去分析，这个知识到底是如何去存储跟表征的啊，那围绕这个视角的话，其实我们团队最近做了一个啊，比较初步的一个思考啊，就是我们从这个整体论的视角来思考这个知识，是不是可以啊。

从整体的视角我们把它叫做这种知识的回路，那么这个回路其实啊啊是其实是一个很古老，很早就有的概念，在可解释领域，就是以前在解释这个原模型，包括很多深度学习框架里边，有一些很多学者他们提出了啊。

可以去造一个特定行为的一个子图，来去解释这个原模型这些行为。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_11.png)

那么我们其实做了一个视角，就是我们从这个知识的维度啊，来去提出了一个知识回路的一个这个假说啊，其实这个词其实老早就有啊，我记得好像去年啊张俊领导上提过这个词，其实啊在很多其他领域。

也有知识回路的这个说法，那么语言模型特别是大型语言模型，他的这个知识回路到底长的什么样子啊，那这张图其实就是有一个动图，就是可啊比较形象的把它展示出来，我们其实发现围绕一个事实知识。

可能中间有一些比较关键的MLP层，或者是attention层，或者是一些其他的一些组件，甚至是一些node等等，这些组件有一些组件表达了一个关系，有一些组件表达了某一个实体。

有一些组件可能表达了些其他的东西啊，甚至我们人类还不一定能理解这些东西，但他们共同一起来运作，然后最后来去实现了这一条知识的一个表达，也就是说可能啊这个通过这种模块化的组合，而不是单个神经元。

而是多个神经元之间共同的一个组合，去完成了一条知识的一个表达，那么具体的其实里边有很多，这是一个呃我们团队在这个GPT2啊，因为这个太大了，模型高效不太好去做，我们就围绕像GPT2。

甚至是tiny la等等模型去啊挖掘，去分析它的一些回路，那这个就是一个啊真实的一个在GBT2中的，一条事实知识的一个这个回路，然后右边这个图呢是这个回路的简化版本，我们可以发现啊。

其中啊有大量的MLP，也就这个就是那个FINN层，也刚好也印证了以前的这个知识神经元的假说，MLP层其实对于很多视知识是非常重要的，但其实里边有很多像其他层的，包括注意力等等。

这些其他的一些这种组件的信息，也就说明在表征这条知识的时候，其实有很多很多组件共同一起协作，来完成了这条知识的一个表达，那么这里边有很多关键的组件，比如说像这个move head啊。

它可能我们其实发现可能啊，它其实把这个投实体的信息，通过这个move head，把它转移到了这个下一个叫LETOKEN的等等信息，还有一些像relating head的。

我们其实发现了很多啊知识共享的reacing head，有一些head可能表征了很多很多共同的一些。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_13.png)

这种事实的这个知识啊，这也是比较有趣的一些这个发现啊，那我们其实围绕这个发现的这个啊这个回路，我们就去干脆做了一些实验，我们发现纯用这个发现的这个回路，其实就能够维持大约70%的这个模型的，这个性能。

甚至是我们拿这个回路去带一些其他的，就是跟它相相关的一些测试集上，甚至还有一定的提升，这也说明了，其实回路可能表征了已经表征了这个老知识，非常很多，很多组成部分就是靠这条回路来表征的。

甚至其他部分能还起到了一个副作用，这也是我们在猜想，为什么在测试集上还有提升的，一个可能的一个因素啊，那除了这个之外呢，我们进一步的去分析这个啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_15.png)

有一些呃我们都知道，众所周知的大模型的一些现象到底是怎么回事，我们其实探讨了几个问题，一个是幻觉问题，在幻觉情况下，这个回路到底是怎么回事啊，我们发现了一个有趣的现象，就是幻觉情况下。

这个回路可能是个错的，就比如说像左边这张图里边啊，在这个L15这层啊，出现了一条错误的一个流向信息，导致了这个啊某一个值急剧的下降，也就是说可能是因为这个这条知识，之所以有幻觉。

是因为L15H0这个节点，直接导致了整个模型就留下了一个错误信息，但是对于一些正常的事实来说，它是没有经过这个错误流向的，它是流向另外一条这个节点的啊，当然这只是个假说啊。

这是我们只是在实验中发现的一些这个现象，另外一个比较有趣的。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_17.png)

我个人觉得比较有趣的现象是在in contest learning的，这个时候，就我们都知道in contest learning，甚至现代的很多的这种red啊，我们加一些prompt的这个模型。

好像就一下子就会了这个答案了，就感觉很多新知识就会了，那它背后的原理到底是什么，那右边这张图呢，就是我们当时在做回路分析的时候，发现了一个有趣的现象，就说加了这些prompt以后，或者DEMC信以后。

这个突然之间冒出了一些特定的注意力头啊，这些注意力头关注到了这个demo session的信息，然后是让这个模型走向了正确的这个答案啊，这个也是一个有趣的一个发现啊，其实我印象中其实同期还有一篇工作啊。

把这个注意的可能称之为检索头啊，其实都是一些类似的现象，就说这个回路中是不是会有一些特定的信息，它会关注这个ICL的一些弹幕STRATION，然后让这个模型能够去啊。

相当于就临时就获得了这个新的这个知识等等，这都是一些些有趣的这个现象好。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_19.png)

那么啊有了这个现象以后啊，其实我们就可以有一个初步假设啊，原模型中间的这个知识，可能还是有一些这个规律的，那么这个规律可能能够帮助我们去解释它的，一些这个现象啊，那我如何去这个啊，在这些规律下。

如何让去更新，如何去更新，以及这个呃去精准的去操作这些中间的知识呢，那就是我今天要探讨的这个啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_21.png)

第二个问题就是五大模型的这个，知识的这个编辑啊，其实编辑这个问题很难啊，其实有很多同行都在跟我交流的时候，都考虑到一个问题，就说我们如果去改了这个模型中的一些问题，是不是这个模型就坏掉了。

这个模型可能就根本就不work了啊，但这里边其实有很多很多值得探讨的问题，假如说我们能够去理解它背后的，这个机理的话啊，其实我们可以在一个很小的待定代价，代价下去更新。

或者是擦除它中间的一些这种knowledge，来更好的去啊服务的这个应用，那我们团队最近其实做了一些这些思考，做了一个比较新的工作啊，就是我们考虑到一个情况，就是原模型。

其实啊我们在更新它的这个知识的时候，不可避免它肯定会影响，那么我们就在想这个怎么样去，更高效的去尽量避免这个模型在更新的时候，对它原有性能的一个这个影响，那我们就考虑去借鉴这个啊。

人在认知的时候的一个过程啊，人在认知的过程的时候，他的记忆其实是存在一个工作记忆，和一个这种长期记忆的，一个一个一个一个一个区分的啊，就比如说啊，其实啊今天各位来参加这个纸园大会对吧。

我们可能今天听了这个报告，可能大家还今天能够记得很清楚，那过段这个其实就是将来当天的一个呃working memory，那么可能有些信息呢，经过啊大量的这种这种消化吸收以后。

可能就固化在啊你的这个长期记忆里边，那就可能进行了一个长期的这个记忆，那么我们其实类比这个核心那个想法啊，我们其实在做编辑的时候，如果去直接去修改这个模型的核心参数，本身，它会影响到模型的长期记忆。

可能会对这个模型的performance，产生一个非常这个重大的一个影响，就有可能把模型搞崩掉了，那么我们就尝试想，是不是可以给大模型去做一个工作的，一个记忆啊，而去直接操作这个工作记忆。

来去实现这种模型的一个自我的一个编辑，和长期的一个更新啊，这样子也可以更好的去避免它的一，些这个副作用，那么我们最近就做了一个探索啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_23.png)

就提了一个工作叫做这个wise啊，这个工作其实思路非常简单，也是啊结合了刚才所提的知识机理的这个假说，中的这个MOP，可能代表了很多比较重要的知识，那我们对对这个MOP这层啊，从左往右看，这个MLP。

这个绿色就是它原有的这个原模型的，这个支持的这个记忆的一个核心的一个区域，那我们旁边给他造了一个旁支回路，这个回路其实就是我们把它假称称为工作，工作工作的一个记忆，它可能是一个临时的一个记忆啊。

这个新知识来了以后，我们把它给存储在这个MLP的旁支的，这个回路里边，那这个回路的原始的参数，是从这个绿色部分拷贝过来的，相当于它是啊基于已有的这个知识，然后我们去对它进行这个蓝色区域。

进行一个啊更新啊，那么这样的话我们再设计一个门控的机制，来，去决定它什么时候是使用以前的固有的，这个记忆来，什么时候使用这个长期的工作记忆，这样就可以保证模型在持续时间很长的一段，知识的编辑的过程中。

它的固有记忆是不会发生太大变化的，同时他也学会了一些新的一些这种知识。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_25.png)

那具体啊其实这里边有一些技术细节啊，就是我们如何去让他这个学习到新的知识呢，我们又把这个知识啊进行了若干个，这个随机的一个这种分区啊，这个经历形象起来非常简单，就比如说我们都知道呃，这个比如说前天昨天。

今天我各位大家都会发生不同的事情，经历不同的事情，那我们对每一个time step的情况下，都给他啊，copy1份这个相关的一个知识的一个分区啊，每个分区都是从原始的这个MFI，MMLOP那个层来的。

那么每个分区都可以去更新它当前状态的，这个知识啊，然后都会得到了若干个知识的一个分片，就像我们昨天发生什么事情，前天发生什么事情，就像这个左边这张图里展示的这样子，那么有了这个分区以后啊。

我们如何让这个模型根据这些记忆，去这个这个去完成这些任务呢，比如说我这个今天开了职员大会，大家听了这个报告，那这个报告里边有哪些信息呢，那模型该怎么知道这些新发生的这个信息呢。

我们这里提供了两个这个技术的一个思路，一个是直接对过去这个知识分区里边的，所有信息进行一个墨迹，进行一个合并操作，也就是说不管你昨天发生了什么，前天发生了什么模型，都不管372 11的把它给墨迹在一起。

然后共同的去作为一个外部的一个memory，然后这模型去啊得到这些信息啊，另外一个思路非常简单，另外一个思路就干脆直接检索，因为不同时间段发生的信息，可能是重要性是不一样的，所以我们也提供了一个知识。

继续检索的一个思路来去让这个模型去这个啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_27.png)

对这个知识进行一个这个区分好，那么呃，另外一个就是比较关键的就是门控机制了，这个门控机制其实就快，决定了这个模型，什么时候使用它固有的这个记忆，那什么时候又会使用它这个外面经过编辑好的。

这个相关的这个记忆，那这里边我们其实设计了一个非常简单的一个，优化目标，来让模型啊相当于去学习到这个，如果这个知识啊相当，如果假如这个知识可能是跟这个啊，前两天发生的信息有关的。

那么可能就倾向于这个一个啊，或者是今天相相关的，可能倾向于这个旁边这个回路，如果是跟这个模型本身它自己会的知识相关的，那就倾向于走上面这条烂路，就会直接走这个绿色的这个链路。

这样的话也是尽可能去避免这个模型，去影响到他的这个performance好。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_29.png)

那么它的效果怎么样呢，呃我们其实做了很多大量的这个实验啊，我们做了一个这个，相当于持续对进行大模型进行，编辑的一个实验啊，从编辑一条到编辑第二条，到一直到编辑到1000条。

相当于就从12341直编辑可以看到啊，其实啊编辑添千条以后，这个模型还没有崩掉，就是模型能够去啊，几乎保持很高的这个原有的这个performance，同时它的准确率也挺高的啊。

虽然说好像这个有些结果上没有，这个有一个baseline高，但是啊大部分情况下，它能够在这么经历过这么多次模型编辑以后，它还能够保持到一个相对更高的一个准确率，另外的话就是我们也去做了一些。

对幻觉数据上进行分析，就看下这个方法能不能去用来减轻这个幻觉啊，也是可以发现它能够去修改，比如说在接近600条的这个啊编辑以后，它还能够去保持一个比较低的一个困惑度，也就这个模型还没崩掉啊。

因为以前有很多工作，其实包括我们自己团队也做过啊，编辑久了以后，这个模型就崩掉了，就基本上不work了，这也是很大的一个问题，还能有一个问题，就是还能泛化到一些啊。

这个没有见过的一些自然语言的这个这个事例，也就是说它还有一定的这个泛化的这个情况，好啊，当然这个它也会带来一些这个代价啊，就是说会增加这个我们的这个计算成本，但相对还是在一个可控的一个范围内。

还会增加3%到四的一个计算。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_31.png)

跟这个推理的一个这个成本，而我们也其实也发现它有些可以改进的地方，比如说这个检索的这个思路啊，其实检索它有个天花板，就是目前呢其实检索的方法，其实可能还，这个。

我们使用的是比较NA业务的一些检索的方法啊，也就是说他可能没有找到一些啊，记忆中比较重要的一个一个一个一个一个区域，所以说可能就检索的事，还有很大的这个提升的好，那以上其实都是围绕这种啊。

我们给模型去新增一个知识的一个一个一个，编辑的一种情况，那么我们有没有可能去啊，把模型中的某一部分知识给它擦除掉，或者是说让模型让语言模型去忘掉一些知识，这个场景其实对于这个啊搞大模型安全。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_33.png)

其实非常有用的，因为我们都知道这个模型有些时候会吐出来，一些我们不想让它吐出来的话，包括一些这种安全的或者是隐私的一些信息，那我们也尝试了去如何用编辑技术来去做这种，大模型的这个去读来。

去让大模型变得更加这个安全的这个可信，那这个工作其实啊非常好理解啊，就是我们当时去探索这个语语言模型，假如是一个常规的语言模型啊，我们可以看到其实可以通过一些越狱的prompt，让它吐出来一些这种嗯。

有些时候会有一些这个非常敏感的一些内容啊，其实我们也试过像包括像DPO等等一些方法，甚至对齐的方法，其实对齐后的这个模型还是有可能会被这个啊，prompt给它攻击到的，就模型本身其实还是有这种情况的。

那么有没有可能有一个比较精准的方案，直接找到这个原模型中间的，跟这个有毒信息的这个区域，然后我们把这个区域的信息给它改掉，让它这个变得更加安全呢，那我们只是做了一个比较初步的一个探索呃。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_35.png)

这个工作，因为其实这个这个场景没有现成的数据集，所以我们首先干了一个事情，就是先构建了一个数据集，这个数据集叫做safe editor啊，我们当时收集了一些已有的公开的学术，数据集啊。

啊这个其实这个领域还是有很多公开的数据集，还有公开的一些BROM的，我们就收集了很多数据集，然后去自己构建了一个啊新的数据集，那然后接着我们就去尝试了一些已有的方法。

并且设计了一个非常简单的一个这个基线啊，这个机线啊其实思路非常简单，是个非常simple的机线，就是我们先做一个定位，我们根据这个安全的表征输出，和不安全的表征输出，我们假设啊。

但这个假设也不一定非常严谨啊，就假设它之间如果是差距非常大的，那么可能这个区域就表征了这些，非常有毒的这个信息，然后接着就是一个思路，就是我们直接去修改这个区域的这个参数，让它实现这个模型的一个剧读。

当然去读的时候，我们也为了保证它的通用能力，也会去设置一些通用能力的这个数据的，这个这些正则项，来保证它通用能力不会掉的特别厉害好，那效果上其实也是非常不错的，就是虽然说还是有一些副作用的。

可以看到我们当时测的，在三个这种公开的performance数据啊，去测了一下，结果发现还是会掉一些点的，但是相对还是可以去啊，保证一些这个副作用的副作用的，这个相对比较小的控制范围内。

同时它也可以在呃相对其他的一些机械来说，也是能够有一定的程度的这个提升的，那么这个思路它背后和一些传统的一些做法，它到底有一些什么有些本质的区别呢，啊我们又去做了一个比较深度的一个分析，就是发现。

其实像传统直接去T或者是做对齐的方法，就像这个啊下边的这样图例展示，可能这个读的信息还在里边，但是它可能被绕过去了，就是模型遇到这些输入的时候，它可能一些有毒的信息，仅仅是绕过了这个一些信息而没有啊。

像然后然后吐出来一些信息都是相对安全的，但是这个呃编辑的做法呢，他直接把那部分信息给改掉了，相当于是他因为做了一些梯度的一些操作，所以它被信息被改掉了，所以相对而言，整个毒性的这个权重就被降低了啊。

但是这个客观来讲啊，其实也没有被彻底擦除掉，因为这个呃为了保证这个模型的通用能力，不受太大影响，我们只是呃略微的让它这个信息，相当于略微的为它降低它的这个权重，但是事实上还是存在的啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_37.png)

但这个只是一个初步的一个探索，那这里是我们当时做这个编辑，做了一个比较简单的一个demo啊，这个在我们的这个呃这个代码也是开源的，如果呃有感兴趣的可以去尝试一下。

就是我们可以看到这里边就是对于给定的输入，跟这个输出的一个不安全的回复，和一个安全的回复，我们去首先做了一个这个相关的一个定位啊，可以看到这个它很快就可以定位到，这个这个层的这个这个区域啊。

大概是这个是在32层啊，然后后面的话就是进行一个这个，编辑的一个操作啊，因为时间有限，边际操作我就后面就不展示了，这个编辑，它可以成功的去让这个模型去突出些啊，相对啊这个这只是这个结果。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_39.png)

就相对于把一些原来的不安全的输出，变成一个安全的这个输出，好啊，我们把刚才所讲的这些工具跟方法，都集成在我们的一个团队的一个开源工具里，叫做这个easy editor啊。

它目前其实也支持我们很多的国产的这个模型，包括像这种百川通义啊，啊GLM下了GLM啊等等。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_41.png)

也包括一些国外的一些这种主流的一些，这种模型等等，好，那最后做一个简要的这个总结与展望啊，其实总结和展望主要介绍的信息，都是这个我们现有工作的一些，这种局限性跟limitation啊。

虽然看到其实刚才我所讲的这个编辑新增知识，擦除知识啊，看上去效果还行，但实际上它还是有很多问题的啊，就比如说啊，我们如果在1000条之后再继续进行编辑的话，这个模型其实还是有可能会崩掉，也就是说。

其实目前啊这个我们当时做了一个实验，就分析，假如说把一条知识啊，比如说以例子，比如说就以这个美国总统这个例子为例啊，假如说这个美国总统从这个A换成B，然后我们如果有一天这个这个这个B又变成A。

就相当总统又变成A了，那这个这个知识，这个模型还是不是原来那个模型呢，其实我们从这个左边这张图里比较，其实可以发现啊，参数化的这种知识的一个更新编辑，跟以前的像符号主义的这种知识图谱的啊。

知识的更新机理是完全不太一样的，就是很可能模型通过一些其他的机制，比如说下面红色的这个神经元，来实现了这个新知识的一个表达，但是这个蓝色神经元这个还在，就这里边说明一个很难的问题。

说明我们其实对这个知识的机理，了解的还是比较浅的啊。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_43.png)

哪怕用这个回路的思想来去解释，其实里边还有很多很多的这种问题啊，就背后带来了一个问题，就是现在目前其实还很难去实现，一种比较精准的终身的这个知识的编辑，但是呢其实这方面还是有很多。

我觉得比较有趣的一个方向的，比如说最近有一个工作叫做表征的这个编辑，或者表征工程啊，其实我们如果假设把这个参数化的知识，其实都用这种表征来去理解的话，其实我非常看好这个思路啊。

其实里边有很多很多有趣的现象可以发生，我们可以通过去编辑它的表征去控制它，让它这个变得更加安全啊，常常掌握一些新知识，让他尽量避免幻觉啊等等，这都是我觉得是一个非常有趣的一个这种视角。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_45.png)

但是整体而言啊，其实我们现在啊对这个方面的研究，有点像以前的这种物理学的研究一样，就是现在其实这个大黑盒，而且参数量很大，我没有办法去精确到每一个神经元，去分析它到底是什么样，很多的时候都是做一堆实验。

外部干预的实验，比如说我们就设计一些problem的，设计一些探针，或者设计一些啊机理分析的一些，这种可视化的一些角度等，去分析这个到底是什么，但这里边其实很难去非常完备的去理解，它到底背后是什么啊。

其实右边这张图是我最近看到一篇工作，他非常有趣啊，一篇ICMN工作，他把大模型的机理，跟人脑的机理来进行了一个类比，也就说明其实我们大模型很多分析现在有点像，跟人脑的分析越来越像了。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_47.png)

这背后有很多问题，其实都是有一些共性的这种问题的，那最后一页啊就是呃，当然这个其实也是这个一个一个一个，一个DISCANNER，就是我今天其实讲的东西呢，其实很多都是一些假说啊。

因为啊像刚才这个贺老师也提到，现在有很多新的架构，比如说MUA，它背后的这个机理是不是和transformer一样的，很难讲，不一定一样，也可能一样的啊，最近有一篇工作，提出了一个叫柏拉图的表征的假说。

他就说可能不同的架构啊，甚至不同的模态的模型，最后都是在去逼近一个可能是一个世界模型，但这个给我们带来一个很好的希望啊，就是可能假可能是一样的，但是未来还需要很多呃同行去探索啊。

如何去建立一个非常完备的知识存储，表达更新的一个理论体系。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/023b9ed505a39fe86fa1685eee1d0822_49.png)

好以上就是我的报告。

# 2024北京智源大会-大语言模型 - P5：小钢炮MiniCPM是如何炼成的？-曾国洋 - 智源社区 - BV1zE421N7UJ

大家好，我是曾国阳，然后非常高兴今天能跟大家一起分享一下，我们在训练啊，mini c p m系列模型中的一些技术发现，以及最后的一些经验啊，然后呃正好也开个场，就是前前几天呢。

其实发生了一个还比较大的事情，就是苹果在2024年的开发者大会上，推出了apple challenges，然后也是标志着成呃苹果也是正式的开始去啊，做自己的端测的AI啊，其实在苹果之前的话。

也有不少的国内外厂家就已经开始布局啊，端测的模型了，然后在这个方面的话，其实我们也是做的比较早，所以今天也正好能有机会跟大家分享一下，我们在探索端测模型中的一些发现，其实从我们的一些之前的结果来看。

端测模型的出现，基本上是大模型发展历史中一个，比较必然的事情，我们呃图上边有两张图，左边那张图的数据来源是papers code上呃，和MMU数据集的相关的水平啊，然后我们以GBT三一百七十五。

B就是最早20年那个版本的那个指标，作为一个参考的话啊，我们把那个图中红色的点，其实就是呃，水平大于等于GPA三一百七十五B的模型，然后浅色点就是小于的模型，然后画了这样一张图。

我们可以发现随着时间的推移，然后呃达到最原始的GPA3，175B的知识水平的模型，尺寸在逐渐的减小，并且非常巧妙的是，它满足了一个规律，就是我们发现他差不多每八个月时间嗯，模型的知识密度其实会提升一倍。

也能看出来啊，随着模型训练技术的发展，模型能够将越来越多的知识给保存在，越来越小的参数量上，如果我们把这个理解为模型的一个制程的话，其实也可以啊，看出来就是像计算机领域最开始出现的计算机。

像AI arc其实好几个房间那么大，但是随着制程的发展到现在，我们可以把呃这样一个计算机给拿在手上，像手机一样去使用它啊，这也是我们推测大模型啊，在这个发展历程上，端测模型未来一定也会这样出现。

然后同时除了在文本领域，我发现在多模态领域的话，其实也存在这样一个大的趋势啊，然后它和那个啊文本领域会比较像，然后这就不多讲了，在今年早些时候，然后我们其实发布了mini c p m系列的模型。

包括最早的mini c p m呃，1。0就是它的2B版本和1。2B版本，以及mini c p n杠V，还有mini c p m啊，杠V的2。5版本啊，然后今天主要就是介绍一下这些版本中。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/62555db713778a634900092ead2a45f9_1.png)

模型所使用的一些技术，以及它取得实际效果啊，今年最早的时候其实我们发布了mini CPU两币啊，其实发布这个模型，最开始我们没有想过要训练一个两币的模型，只是因为我们在实验过程中。

然后这个两币模型是我们产出了一个中间版本，然后这个中间版本呢它达到什么效果啊，相比于就是他之前的比较知名的模型，像MISTRO啊，甚至在他后边发布的google的GA啊。

它都能够呃取得和就是和他们相当的水平，同时啊在这样一个小的规模的参数量上啊，这样的模型它能达到这样的效果，在之前看来也是非常不容易的，在这里边的话，其实我们主要做了非常多方面，在训练方法上的一个探索。

比如呃在模型训练的时候，其实大家都会涉及到调整非常多的超参数啊，当我们训练更大规模模型的时候，要调整超参数，它的成本也会更高啊，而且呃就是对于不同规模的模型来说，其实它的自由超参数也是不一样的。

在一个之前的工作中，其实有相关的研究，应该叫就说在我们这里边，其实使用的mp这样一个框架啊，之前的工作一叫什么tensor programs，我有点忘了具体是啥名字了啊，然后在这个框架中。

然后他提出的方法能够对参数进行一些归一化，然后能够通过规划之后，然后就能够确保在不同规模上，模型能够共享一套最优的超参数，然后在我们的实验中，我们也对它进行了验证，其实除除了那个呃。

这个图是一个learning rate，其实除了learning rate之外的话，我们对其他的一些指标也做了一些测试啊，包括像啊模型的什么深度，还有模型的宽度之类的，还有一些其它的超参啊。

然后最终发现，其实在对模型最终效果影响比较明显的，其实就是这个learning rate，选择一个合适的learning rate，不仅能让模型训练的更更快。

同时当learning rate选择的不好的时候，它最终收敛到的位置也不会那么好，然后我们在复现了mu的工作之后，我们发现一个非常巧妙的值，就是learning rate使用0。01是非常的好啊。

所以这是我们在mini se分训练中，选择0。01作为learning rate的一个啊实际的原因，然后在确定了完learning rate之后呢，然后大家也会遇到，就是在实际训练过程中。

我们都会有learning rate schedule啊，这个schedule的话，其实也是一个非常重要的一个指标啊，从最开始训练BERT，大家用的是那个NO arm的那个方法，然后再到后边来。

大家普遍会使用cosine的一个啊调度器啊，但是我们对cos的调度器做了更深入的研究，其实在cos in调度器设置的时候，它最重要的是要设置一个最终截止的部署啊，然后我们对不同的截止步数的cos调度器。

都做了实验，上边那个N是指那个模型的参数量，20N是指训练20倍模型参数量的数据量啊，或者叫token量啊，然后通过设置不同的截止步数，我们可以发现，其实呃当一个cos inerrate。

它呃它取得在它曲线中啊，效果最好，loss最低的位置往往是它到达郭谷的那个位置，是他的那个呃，最终的那个那个那个那个值，就是应该叫最最终的LR最小的那个位置啊，同时的话我们发现就是呃。

我当我们能够给那个cos的learn rate给它切，就是当当它能让它重复足够多次次的时候，我们发现它其实在越往后的话，它其实最终也会达到一个差不多的水平，所以基于这个话，我们就进行了一些进一步的探索。

我们把这个learning rate上，learn rate schedule做了很多的不一样的实验，然后后来我们就试出了一个叫WSD的一个啊，Schedule，然后它非常简单。

就相比于传统的那个cos各种曲线来说，它就很粗暴，它就包含三个阶段，第一个阶段warm up，第二个阶段是stable，第三阶段decay，warm up的话，其实是现在所有scale的会自带的。

就是前期从最开始LR是零，然后通过训练持续增加到我们最终的初始LR，然后同时呃和COSN不一样的是，就是COSN的schedule，它会在那个训练过程中持续的下降，而对于我们WSD来说。

它会在中间保持相当长一段时间的，stable的一个啊学习率，我们发现通过一个更大的学习率，其实模型能够实现更快的学习啊，而为什么最后又会有个decay的阶段呢，啊是因为我们发现。

当我们一直保持比较大的LR的时候，模型确实会学的比较快，但是它最终到达的那个loss的水平，其实并没有那么高，但是当我们去降低R这个过程中，然后它loss会出现一个快速的下降，在这个过程中。

我们就是实验得到了右边那张图，我们可以发现呃，通过那个WSD的优化器，然后它在STL阶段，虽然它的那个loss会比cos更高啊，但是呢就是随着我们在不同阶段，使用decay的方法的话。

然后它就可以在decay阶段实现loss快速下降，甚至在后期是可以在那个decay阶段完成之后，他得到那个模型的loss是会比那个呃使用cos in，使用cos in的那个学习率。

在对应时间得到loss会更低啊，同时的话WSD的优化器也有个好处，是啥呢，就是当我们训练模型的时候，可能通常要呃就是其实数据训练的过程中，可能数据会发生各种各样的变化，甚至我一个模型训训完了之后。

还想再训一段时间，这都是很常见的问题，所以对于cosine学呃的schedule，它需要在训练之前呢，预先设置好一个他的那个呃截止时间啊，但是对WSD它是不需要的，当你随时要用的时候，你随时把它拿出来。

然后训一下它的decay阶段，就能得到一个非常好的模型，这个对于大模型的持续训练来说，也是非常有用的啊，然后右边是一个我们实际训练时候的那个lost，的一个情况，可以看出比较明显的一个变化。

就是它从从大概那个2万5000到3万中间，那个步数的时候，然后我们开始进入DK阶段，然后他的那个LR会呃，就是它的那个LR，在那个阶段会发生快速的下降，就对应的带来也是loss会发生快速的下降。

然后呃其实还有一些比较有意思的呃，结论就是其实在之前那个包括欧派的研究中，就是batch size的选择会和你最终的learning rate呃，会和你最终的loss收敛到的位置会相关啊。

但是在这里边理论上它应该在那个decay阶段，选择更大的lo呃，选择更大的batch size，但是我们做了一些实验，发现好像并没有什么效果啊，那反正也感觉挺奇怪的啊，然后嗯针对这样的模型的话。

我们也对它实际进行了一些评测，就说在之前的话，在模型训练阶段，其实有个叫CHAN区love optimal的一个说法，就是说呃当我们训练多少token的时候，能达到一个最最最有效的就是在在这个训练。

在这样一个呃运算量下，会最有最高效的一个模型的size，和它要训练的数据量，然后我们我们使用了相同的数据配方，然后去训练了那个change cha呃，根据群区up型模去训练一系列模型。

可以发现使用我们这样的方法啊，训练出了模型，最终能够超越呃，大概是我们mini c p u2B的一个模型，它最终loss是2。4，大概的水平，其实等于全区loft tm9B规模的模型。

这也是为什么mini c p m，可以在一个更小的规模上去，战胜更大规模模型的一个原因，然后这个是一个最终的效果，然后我们将mini CPU这个两臂模型，最终也只能跑在手机和啊各种的呃，就是PC上。

然后同时能够有一个比较高的一个速度啊，然后这个的话也是，而且这个速度其实当时我们最开始适配的时候，也还没有做任何的优化，就单纯利用手机的CPU，其实就能跑到一个比较快的效果啊，然后因为实验原因。

我就不放太多啊，嗯对然后有了mini c屏幕之后，我们又在mini c屏幕上面加入了多模态能力，就是我们的mini CPU杠V的2。0版本啊，相比于那个其他多模态模型，我发现在我们的实验过程中。

我们发现就是呃多对一个支持图文，多模态书的模型来说，文本模型文本的基座模型的水平其实会比较大，影响它在多模态最终的一个效果，所以在这里边的话，我们也是将mini c p这样一个比较强力的模型。

应用到了呃，应用到了这个多模态啊场景下边，然后可以发现通过一个更强的文本技术，我们能够超越数倍于我们规模的一个模型，然后这个是其实是一个比较旧的图了，就是当时发布的时候一个图，然后可以看出来就是啊。

mini c p m能够全方位的超越，甚至一些比自己大好几倍的模型，这也其实也是在我们实验中发现，是依赖于啊文本模型的一个强大的能力，然后在mini CPU杠V2。0中，我们能够做到对啊。

就是我们对那个我们能够做到，对于那个高清图片的各种的理解，同时还还能够把图像中那些比较小的字，都给识别出来啊，同时的话也能够识别，就是也能够做非常长的图片来理解，这个在文本领域。

其实有个常见的任务叫做长文本啊，就是我们给他一篇很长的文章，然后问一些问题，我们有意思的是，我们发现其实把这些文字转换成图片，然后通过图片这种多模态的形式输入进去，模型也能够做一些啊。

也能够做一些这种长文本的一些问答的问题啊，那么在这里边的话，其实我们主要应用到的技术就是呃一个呃U呃，就是lava u h d论文里提到，就是我们的那个多分辨率高清解码的一个技术，在这里边的话。

其实我在这个工作中，我们也是对多模态领域最最常见的一个问题，是对于不同输入尺寸的图片，然后它很难用统一的形式去编码，然后做出了一些相应的探索和研究，在图文多模态领域的话，其实比较知名的模型。

像GGPT4V啊这样一个模型的话，然后我们也对它做了比较细致的实验，左边是一个我们的实验，我们发现在GV4V，它可能应用了某种，就是将更到高清的图片切块的一个方法，同时它在块和块之间会有一些重叠啊。

然后来做的一个图像编码，然后这样的一个方案的话，我们也发现，就是他会经常在就是做一些数数的任务中，然后它会数错个数啊，左边是一个比较明显的示例，就是我们构造了一个九个小球的一个图片，然后我们发现。

以不同的尺寸将它放入到模型里边，然后GV4V它会数出不一样的数量啊，当那个它的那个当几个小球，它的大小是比较合适的时候，模型能够正确的数出是九个球啊，但是随着它的规模放大。

可以看出来它会逐渐从九变成12，再变成16啊，为什么变成16轮，其实我们会猜测它在这里边，它在那个实际处理过程中呢，它会包含一些就是呃就是切，就是把大的图像切片成小的图像。

然后在小图小的切片中会有重合的部分，所以导致有些呃，有些有些小球它会被重复的计数了啊，然后呃除了基弗四以外，我们也探寻了就是拉瓦1。5，它对于那个呃那个呃不不同，分辨率图像的一个编码方案。

然后发现它这样基于一个padding的方案，其实在一些比较极限的长宽比下的话，也会存在一些问题，所以在这个工作中的话，我们是综合的提出了，就是说我们要做一个动态分辨率的，一个编码方法。

然后具体的方法呢其实也比较简单啊，对于一个图像来说的话，它其实会存在多种切分方法，比如一个呃一一个一个就是啊，好非常高清的图片，我们可以直接竖着切，也可以直接横着切，也可以切2×3，也可以切3×2。

它有很多种切法，但是在这里的话我们经过实验发现呃，要达到最好的效果，其实是需要尽量去保证和原始训练的时候，每个就是原始训练时候那个v t encoder，它的一个呃，训练的一个长宽比最合适的一个情况下。

然后它能达到最好的效果，所以在这里的话，我们其实采用了一种比较精妙的方法，就是我们去通过给那个呃通通过计算，就是图像的一个高清图像的一个像素数量，是我们训练时候像素数量的多少倍了。

能确确定大概要分的块数就是那个N，然后根据N的话，我们能枚举出所有可能切块方法，然后在所有潜能可能的切块方法里边，再去找到一个，长宽比和训练时候最接近的一个方案，然后作为我们的切分方案。

基于这样的一个算法的话，我们最终能实现一个啊，就是能实现多，就是能实现多种不同分辨率下，这个图像的一个啊高高清图像的一个识别啊，同时包括传统比较难处理的长途，也是能比较好的解决，然后在这个的基础上。

然后后来因为拉玛三推出之后，然后我们又继续拉A3，然后将一样的技术移植了上去，然后发现确实跟基于一个更大更强的模型的话，在多模态的能力也会得到一个比较明显的提升，而在这个模型中的话。

我们在很就是在多种任务上，其实最终综合能力是达到了，GPT4V的一个水平，同时在OCR能力上，都会有一个比较强的一个啊体现，然后呃这个是一个例子，我们发现就是呃在这样一个模型中的话。

它能够比较好的去识别，就是包括中英文的一个识别，然后包含也能比较好的去识别，像图像中的票据的信息，同时也能做信息的抽取，比如让它按照JSON格式做输出对，然后像传统GPT4维有些大。

让大家觉得是比较难实现的能力，我发现当模型的就是特别是机动模型呃，能力起来之后的话，它都能够得到比较好的解决，比如像一个复杂流程图的理解，这个其实是对于啊，之前很多多模态模型来说是非常困难的。

但是随着模型能力的增强的话，这些也是可以解决的，还有就是一些表格信息的提取，对然后除了这个之外的话，我们还发现呃，在当模多模态模型，具有那个OCR能力之后的话，它能够有效的将文本空间和那个图像空间。

给更好的联系到一起，然后就能够利用语言模型的多种能力，然后能实现各种不一样的效果，比如啊在这里边的话，我们因为拥有OCR能力，然后我们还能就是我们就能和语言的跨语言，模型的。

跨跨语言的那个多语言能力给融合到一起，导致我们能够通过这样的方法去实现，对于各种不一样的主流语言的一个，多模态支持啊，最后这个发布的话，其实也在那个社区上受到了比较广泛的好评。

包括在hi face上的话也是啊受到非常多的关注，然后包括前段时间其实也出现那个呃，被被那个套壳的问题啊，然后同时的话除了呃mini c平衡系列，我们在开源社区的话，也是有很多其他相关的工作啊。

包括大家可能了解的比较多的就是开源模型，那些还有底层的训练框架，还有高更往上一层的就是agent的相关的框架，然后我们都是有啊涉及到，然后也非常啊，也非常希希望大家能够持续关注。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/62555db713778a634900092ead2a45f9_3.png)

我们一些啊更新的工作，然后最后呢就是端测模型下一步我们会做什么，对我们目前来说，我们还会继续去沿着我们最开始提出的那个，大模型的摩尔定律继续走下去啊，同时的话，我们也是想要让一个GPT3。5水平的模型。

能够真正的运行在端侧，能够运行在手机上，同时我们也会为我们的模型去，添加更多的模态啊，我们可以，我们能够感受到端测的AI是大势所趋啊，并且端测的AI能力，也会随着硬件的发展和普及变得越来越强。

对然后以上就是我今天说的内容。

# 2024北京智源大会-大语言模型 - P6：大语言模型预训练的效率优化-王炳宁 - 智源社区 - BV1zE421N7UJ

是来自百川智能的王笔，然后今天给大家分享一下，我们在那个大预言语言，大语言预训练的一个模型上的一个效率，优化上的一些一些探索，可能今天主要聊的是一些已经有的一些工作，包括我们的一些思考呃。

而且今天可能我这边主要给大家讲的都是一些，可能跟本质是预训练相关的一些东西，可能像类似于下游的一些对齐，有些agent的这个可能不会涉及到对，首先是先介绍一下background吧，就是因为我们刚才。

其实前面几位讲者也都介绍到了，其实现在我们的大模型，已经进入到大模型时代了，然后他的一个比较显著的特征就是它大，然后大模型的提升能力的一个非常关键的方法，其实就是scaling law。

就不断扩展它的一个呃模型的大小，不断扩展它其中训练的数据的大小对，但实际我们发现其实在真正训练中，其实本身我们除了说无脑，就是无限制的去扩展我们的参数，大小和数据的字，这个这个之外。

其实我们还有一个非常需要去做的事，就是我们怎么在单位时间内提升对我们的数据，比如我们的模型更好的一个一个压缩，就实现更好，就是单位时间内更高的一个智能，这可能是我们现在很多在做大语言模型。

不管是预训练还是这个反听令阶段，这种都在做的这样一个事情对，所以其实我们今天就主要给大家介绍一下，这些一切的一个方法，但可能有些局限啊，因为可能我们就讲了，只是一些理训练的一个方案，而且是主要关不呃。

当前的一些一些短暂的可能的一些结论，可能对对长期long term这些结论是不是有效，可能还是有些疑问了对，所以其实可能从几个方面来去做这个，来去进行一个分享对，首先是为什么要做这样一个优化。

其实语言模型我这里就简单介绍一下，它其实说白了就是语言模型，就是language model，就是对这个language进行建模，这样的一个方法，对它其实核心就是你根根据一个把一个句子的。

一个概率进行一个一个统计建模，然后由前面的一些句子，得到下面一个词单词的这样的一个概率，就是next token prediction，这是一个非常经典的这样的一个，一个一个预测的一个方案。

但其实我们知道现在大这有传统的，其实语言模型不是个新的事情，它传那方法有类似这种n gram，就靠之前前面几种几个单词，然后来预测下一个单词对，然后当然现在其实我们知道大模型来的时候，之后。

基本上现在都会都会落脚到这种所谓的auto，aggressive这种model里，也就是说我们如何根据前面呃，前面若干个单词直接去后预测后面这个单词，这样的一套范式也依靠神经网络啊。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/32573de54372409d7fc39c57e7555578_1.png)

确实是网络有点问题，那我就稍微讲的把一些重点讲讲的慢一些哈，然后可能这个现在能听清楚了吧，赵老师，哦好的好的，那我继续，然后可能现在的一个语言模型，发展的一个比较重要的特征就是它越来越大。

就是不管语言模型训练的数据，还是说本身的参数规模，Scalling，其实就是我们现在基本上取得所谓的，现在AGI通往AGI之路上，可能是最重要的一个突破的一个关键因素。

然后右边其实是左边是一个那个英伟达。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/32573de54372409d7fc39c57e7555578_3.png)

他们那个黄仁军，他在那个GDC2024上面，keynote可以看看到，最近几年，其实对AI发展其实最重要的一个一个变化，就是我们的一个模型的参数量，还有它训练的总共的一个flops，是非常非常夸张的。

在提升的，从之前很少的一个transformer g p T1，到现在可能GP4，它可能是一个万亿的这样一个MOE了，然后对于我们整个发展历程来看，我们可以看到，我们之前在很早一段时间。

在做这种各种各样的语言医疗，这种各种各样的feature engineering的模型，到后面可能是2010年之后，随着深度学习的发展，我们都在研究怎么把这些目这些不同的任务，用一个模型给做起来。

都是在研究一些模型，但其实现在特别是202022年之后，我们发现了scaling lash是一个非常重要的因素，现在大家都在做所谓的就是大，我们怎么把这个模型做大，然后把所有这些东西进行一个统一对。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/32573de54372409d7fc39c57e7555578_5.png)

所以其实这是一个我们认为是现大圆妈，现模型发展的最重要的一个原理，就是scaling law，其实scaling law，如果是我们把它形式化的表达一下的话，它可能就是一个非常简单的。

就是对loss的一个进行了一个预测，其实我们刚才讲的语言模型，其实就是对一个句子的的概率进行建模，然后呢，我们那个概率一个loss可以分为1reduce bloss，还有一个reduce bloss。

就是说诶我一个本身一个模型，对我们整个的数据进行一个建模，其实达到了，就是我要让在这些数据上得到，我最最小的一个预测的一个损失，然后当然了，我不管是模型有多大，还是我的数据有多少。

我最后肯定是有一个下界的，就是这个L的这样的一个无穷大的这样的一个，他其实就是说我有一个下界，就是我无无无论怎么去优化我的模型和数据，它其实会有一个夏季的一个损失。

但除了这个下界之外的是reduce blows，就是我最后需要去做的这样的，不管是我通过过大量的把参数扩大，还是把我的数据量训练的时间更长，都可以让这个loss变得更低，所以其实这就是skin law。

一个基本的一个简单的表示吧，当然其实对于scaling law，其实现在有很多不同的一种表达的方法，比如说有左边的最开始就是OpenAI，他们发的一个所谓的这种，基本上跟三个指标跟数据量。

跟我的训练资源，跟我的参数量相关的几个指标的，而且他他们通过训练不同的模型，可以把这个skin law给拟合出来，当然还有一个比较经典的就是CHENCHALT，他们的一个still in law。

他是把它当做也是一个所谓的power law，就是一个指数函数的一个拟合方式，E其实就刚才上面的ERISTENCE扫，就是不可去降低的，然后ABND其实都是一些超参数，我们可以进行去呃。

阿尔法贝塔都是可以去进行优化的，N和D就是我们的模型的参数量，和我们的数据量对，大概就是这样的一个情况，所以其实我们今天其其实在优化了很多，很多的动作，都是在，不管是我们模型结构的优化还是什么样优化。

其实都在去优化这样的一个scanning log，如何让我们的loss变得更低，所以其实你看现在我们很多情况下，不同的模型设计不同的训练方案，刚才其实那个呃曾老师其实也在介绍了。

就mini c ham他们在做了很多的这种优化，其实都是为了让我们这个string la去更好的去，你去做做优化，我们这个scaling law，让我们的这些参数去发生一些变化对，然后呢。

当然在提到我们scn law是我们今天要做报告，就是最根本的一个原理，或者其实就是大模型的一个最基本的原理，但是我们要首先要假设Scout是存在的，但对它的估计可能是非常脆弱和可能粗略的。

其实最近有一篇文章，就我们大家都知道，skin law肯定本身这个公式是对的，但对它的拟合，比如我真要把这个阿尔法贝塔A和B拟合出来，其实是个非常困难的事情，然后这篇工作大家回头可以去看一下。

其实他们就发现，其实拟合不管是现在请求大的，还是市面上基本上大部分的工作，对这个数据的拟合，对这个超参数的拟合其实是很弱的，你你需要可能非常非常多的这种参数样本。

才能把这个给这个skin lag给拟合出来，对所以这个是skin lag，可能是它本身是正确，但是要把它真正的拟合出来，可能是有一些困难和难点对，然后他但是呢如果我们拟合错了，就会发现。

其实很会对我们的结果和预估，会造成很大的影响，我举个简单的例子，对于这个scaling law这个本身来说，就是我们刚才讲的这个CHANGA，就是这个是就是不可去减小了这个loss。

然后后面两项一个是参数，这个D是数据量，然后这里去估计A和B阿尔法贝塔，然后我们其实对这个模型结构优化，其实可能就会把这个阿尔法进行优化，因为N就是参数嘛对吧，或者跟模型相关的。

然后我们假设能把这个从0。34，优化到0。35，就这个越大了，我们肯定是让这个loss可能变得更小，但其实你知道我们可以看到，如果你对这个估计估计差一点，其实对整个loss来说。

它是一个非常非常大的一个差距，所以说其实呃这个想讲的就是，skin lop本身一定是正确的，但对他的估计可能就是差之一点一点，人谬以千里，对可能是一个非常一个一个多的，所以其实我们今天现在很多的。

不管是我们的做法，其实还是说我们的很多的一个所谓的经验呃，其实就是在不断的增大模型的尺寸，提升我们的这个N就可以让我们模型变得更好，还有就是说像我们知道拉玛三，用了更多的是15T的数据去训练它。

就是用更多的这个data去来降低这个loss，但其实还有另外一个方面，除了这种比较原始吧，或者我们认为是可能是比较暴力的方法，其实我们还有就是我们上面标出来的，红色的部分，我们可以设计更好的模型结构。

比如像分词器啊，或者是类似各种各样的这种tension啊，优化结构去提升这个阿尔法或者降低A，然后可能是我们可以用更好的数据，比如说提升数据的质量配比，然后提升BB对，就提升去贝塔。

或者说降低被降低这个B，但也可以，最后就跟刚才那个WSD那种方法一样，就是我们用更好的训练技巧，然后同时去优化我的这个参数和这个D，所以所以它这其实是一个去，在这个固定的这个参数。

或者或在这我们固定的这个lo下，去优化这几个结构的这样的一个过程对，所以其实今天讲的主要就是这几块，一个是从数据，然后模型结构的设计，还有训练方法的优化，去来去对这几个进行一个统一的。

一个优化的一个过程，对首先是一个效率的优化，其实刚才第一个呃，这这赫迪老师其实也讲了，现在有很多这种效率优化的方法，包括包括linear attention，包括很多的，它其实核心就是想解决本身。

transformer里面最核心的这个框架attention，它里面的一个问题，比如说像最左边，就是我们标准的这样的一个attention，它的一个结构可以看到它是一个全连接的，就是说你有更长的话。

它就是下三角一个矩阵嘛，所以所以它其实计算的一个复杂度是N方的，那所以说这个N方当你的长度很长的时候，就会有很大的问题，所以后面有很多的工作都是对它进行一个降低，比如说把这个N方的复杂度降低到更小的。

比如说第一个常数项这样的一个工作，比如像sparse transformer这样，我们知道最近有很多的工作，包括five，但他也用了，包括刚刚才介绍到的block bus这种方法，但核心其实相相将于。

我们如何在这方面，把这个N方的这样的一个效率进行一个提升，对当然最近还有一些很多的这种去提升，不管是他的目标是长文本，还是说他就是提升这个本身transformer，建模能力的。

他其实就是去来提提升这个优化这个attention，它这个结构比如说像DTH，就是像streaming r m里面提升的，这提出了这个事，就是attention think，因为他也是发现。

现在的模型好像对第一列的这种attention，关注的非常多，也就是说不管你后面是什么样的词，它其实对第一个单词或头部几个单词，关注的非常多，所以由这发展出来一个，对这对attention进行一个改造。

提出了一个非常不错的一个效果，叫streaming2M，然后最后效果还是还是挺好的，当然除了这个我们讲了attention这个优化之外，就有很多的工作哈，还有一些其实就对本身只整个这个模模型结构。

进行一个优化的，比如说现在比较新的，可能大家也看到，前两天就是经常出来的叫MANA或者java，这个就是它其实本质上是一个，类似于这种循环的神经网络，其实我们知道循环神经网络。

就是在现在的大语言模型时代，它其实被忽略了，因为可能在前几年最开始，比如10年左右，其实大人家做了对于文本处理，都是用循环神经网络，因为它本身有这种递归的这种性质，你看文本也是从左到右一个词一个词的说。

其实循环神经网络也是这样，它可以一段不就是递归的进行建模，把之前的信息引入到后面的信息，所以本身以结构来看，它是一个非常好的，只不过可能transformer出来之后，他靠他的更好的性质。

然后得到了很好，但其实现在RN现在反而在这个大模型时代，被淡忘了，但最近大家发现了这种RN的这种效果，可能是嗯，可能它的一个效率上是会有更好的，相比于transformer，所以大家很多人包括MANA。

很多RWMKTV都在做这样的一个优化，首先先讲一下，为什么之前的很多模型结构没办法代替，Transformer，就是为什么像LSTM这种方法没办法替代，其实可能也不是说。

但它的嗯它的什么就是效果差或者什么样，它核心的一个缺陷是它的一个scaling property，就说如果我把我的这个模型，参数变得更大了之后，transformer是可以很好的进行一个扩展的。

但是像LSTM或者传统类似于这种convolution，这种方法，它也有在用文本上做CONOLUTION，他可能很难去做扩展，比如说两层三层，四层或者更多的，它其实可能效果就已经达到瓶颈了。

这可能就是LSTM，或者其他的这些很多宣传水平，它的一个非常大的一个一个痛点吧，就是他很难做scaling，这个当然是很早之前的一些工作了，就对研究，不管是ALBERT这种很多其他的工作的方法上。

对比这种呃他的SCALLING的性质，可以发现其实还是transformer是scale最好的，当然现在有一种新的结构RWKV，这也可能是在大模型时代出的一种，RN的一种形式。

大家就发现它其实还是可以做到很好的一个，spelling的性质的，但它本质其实也是一种RN的，这种这样的一个结构，对或它其实本质叫state state space model，就空间状态机嘛。

但核心还是RN的一种形式呃，但但他的一个做法其实也以，如果你以图的形式可以看的话，它其实就是把之前的一些信息引入到当前信息，并且有一个类似于这种time miss的一个方法，就可以引入了一个持续信息。

但它的一个建模是一个不会像R那个，就是像transformer这种平方向的一个增长，就是会把它固定在一个空间时态里面对，所以这个可能在现在里面如果做长文本处理，做时效性可就做实时。

就是效率优化是很好的一个结构对，然后他当然他也做了很多SCALLING的，这样的一个做法，可以看到，我们发现这RWMKV在大模型时代，也是会有一个不错的一个SCALLING的一个性质。

然后当然现在也有很新的吧，像曼巴呀什么，它都是基于这种SSMRN的依靠递归机制，将信息进行压缩在一个状态里面，然后不断的进行递归更新，它其实都是依靠这种，其实跟RN的思想是非常像。

就不要让它是平方向的增长这样的一个思路，其实第二种还有一种叫做memory based的，就是将信息依靠一个固定的婚比，不管是内部还是外部的一个memory，已经存储减少历史的信息。

然后防止它是一种N方的一个一个增长，这样其实就是一种相当于，我不管是你上下面有多长，我都把你固定到一个一个固定的一个空间里面，所以这个其实也是一种很多方法，都在做这样的一个优化。

但其实这个不管是结构优化还是attention优化，其实我们都会发现，现在的大语言模型都会存在一个问题，就是非常冗余，我们知道我们现在不管是transformer，还是一个LSTM还是各种各样的方法。

其实它都是一个一个语言模型，它都是一个深度网络嘛，神经网络，但其实我们这也是我们百川，前段时间刚发现的一个问题，就是现在的大语言模型可能非常非常容易，这个例子我们举左边的这个图。

就是它是一个就是拉马拉马尔的一个，7B的一个模型，当我们直接就是非常简单的，把模型最后面的一些层把它直接砍掉，然后让它输输出，意思就是你最后几层就不用了，直接让比如说他总共有30层的话，32层的话。

你直接可能把最后四层全部砍掉，它基本上在MMU或的效果，基本上没有什么影响，所以这个从这个角度来看嗯，现在就可以发现嗯，现在的模型其实非常冗余的，所以我们提了一个这样一个一个方法吧。

但是其实从这另外一个角度就是模拟模型冗余，它可能是现在大众优化的一个一个痛点，或者一个必然点，依靠，类似于之前有一个叫深度学习，里面有个叫做叫lottery ticket hypothesis。

就是叫彩票模型假说，就是只有模型够大之后，你才能找到一个比较好，小的空间来去作为一个本征的表示，但如果找到这个本征空间是需要很复杂的，所以其实如果后面的模型优化，我认为可能是需要去找到这个。

比较好的本质空间，然后来降低这样大模型的训练的一个代价，然后当然前前面提到了一个效率的结构，上面的方法，其实还有一个方法上的一个一个一个提升，这方面的工作就其实比较多了。

其实我们本身看本身就是这个大模型发展，或者本身这个原模型发展，它就开始，我们之前是没有预训练和强化，只有一个有限度微调，就是你有一个数据想一个model就可以了，但后面发展到像贝尔时代来临之后。

就有预训练这样的一个事情，你可以先预训练完之后再进行有限度微调，但其实现在就更多了，就是我们如果把它apply到真实的场景里面，我们可能还需要让他去跟这个environment，进行交互。

所以从范式来说，这个整个我们训练或者大大模型发展的，这个范式，就是在不断的进行一个效率提升的一个过程，开始这个可能是很低效，到后面他这几个有预训练之后，有这个人类反馈之后。

他可能是一个效率很高的一个事情，对然后提到这个效率，训练效率，当然我这里面有很多很多了，就是我们怎么去训练好，出来一个好模型，我们结构已经确定了，data已经确定了，怎么好。

其实第一个就要提到的是我们优化器，现在其实大家谈这个很少了哈，大家基本上默认的基本上就是ADAMM，或者加一个with it decay这样一个方法，但实际上对这个事情研究，几乎现在基已已经没有了吧。

但其实在传统里面其实对这个研究是非常多的，比如说像传统的里面，他们就认为可能在阿达姆，他对SGD它的一个优化，它对比它的有些认为ADAMM是比SGD要好的，但有些人认为ADAMM是没有SGD。

比如像我记得他们在图像里面，比如说你MEGNET，如果你要想调一个比较好的模型，你最后基本上都用SG来做最后的一个优化，但其实现在的模型我们知道，其实在语言模型里面啊，DM可能更好。

所以其实对优化器这个事情来说，其实没有一个定论，到底应该是什么，是一个比较好的这样的一个模型对，所以其实这个是，我们现在可能不是说有一个定定论，说阿达姆就已经完全是解决了这个问题。

然后但是alarm可以从另外一个一个视角来看，它为什么会比SDD，在现在大比原模型时代可能更好，原因就是因为它引入了一个所谓的二阶的这样，一个优化，我们知道其实我们如果对泰勒展开的话。

可能就是一个一个时刻，它的一个一阶加上一个二阶的信息，加上后面一些冗余项，可能SG它的问题就是他这个二阶，我们把它称为一个sharpness，它的一个问题就是它的二阶太sharp了。

就说他的那个抖动会特别大，然后ADAMM还一个好处，就是会他会把这个二阶的sharp变得更小，所以说这是一个它的一个优化的一个，一个一个方法，这也是为什么它可能在大圆模型去搜参的，这个过程中。

取得更好的优势的一个一个关键的一个因素吧，对所以其实现在很多的方法，不管是在记忆翻译还是真实在就是auto progressive，这种自回归的预测里面，都可以发现。

ADAMM确实是要比这个就是SGD要好，非常非常多的，然后其实这个里面ADDUM现在当然研究的少了，但但其实我们发现其实在大圆模型时代，应该也不能把它忘忘忘略掉，因为可能SGD这个。

咱们知道他之所以没有阿达姆表扬好，其实有很多工作发现，比如说这个黄色是长尾的，高频的，就哎就所谓低频吧，然后蓝色深色的就是高频的，这些，可以看到阿dam，可以把高频和低频都进行一个很好的优化。

越下降就是它的loss，但是SGD可能低频的东西，它就处理的非常差了，所以从这个角度来看，我们认为可能还是要因就阿达姆，他可能对低频的这种优势是非常非常大的测试，如果是我们大语言模型时代有很多。

比如说小数民族语言，或者说很低频的一些pattern，它可能有用RARM，可以很好的去对它进行一个学习，对，然后当然二阶的一个优化就优处优势，我们就不用讲了嘛，他肯定是比一阶的好，不管是从它的找了这个。

最后找到极小值点的一个速度来说的话，它都是会比纯一阶的这种啊SGD要好很多的，最近其实有一些在大语言模型时代，对这个优化器进行优化的一个方法，比如像索菲亚，它其实就是对这个优化器进行了一些。

比如二阶的一些近似，然后达到了非常不错的一个效果，然后可以看到他具其实就是一个效率源，就同等时，他能去取得比更快的一个速度的一个加速，对，然后当然其实除了这个之外，其实最后一个就是跟训练方法了。

就是超参数，刚才其实上面前前面一个就是面壁的这个，同一个一个一个一个一个同事，其实也已经介绍到了，其实很多超三是我们现在需要去调了，你看不同的模型有很多不同的超参数。

像gp three跟lama two，他们有很多很多参数，好像大家都是不太一样的，有长度啊，超learning rate，还有by size，所以其实有很多这种方法，像milk这种呃。

就是叫tensor gram，这个是也是呃，现在他们之前有很多去搜参的一种方法，就是我如何去初始化这样的一个模型，让他最后不管是什么学习方法，在这个模型上人都能去起作用。

所以其实他们就提了一个依靠小模型的初始化，通过比它其实核心就是说我那些MMP层，我的输入和输出应该以什么方法来进行初始化，然后最后可以发现通过这种初始化方法，它能达到一个非常好的一个极小值。

这样的一个效果对，当然跟这个也是他们最后实验中和最后理论中，都发现，确实依靠这种非常好的初始化和超参数的调节，就可以达到同等的时间内，可以达到最好的这样的一个loss的一个水平。

这样其实就在同样时间内去降低，就提升那个死亡了，当然除了这个之外，还有一些嗯，By side learn rate，这个当然也是面壁，刚才那个mini c p m他们团队的工作，刚才这个曾已已经介绍过。

就是我他如何去找到这样的一个better side，和这个learning rate的一个关系，让他最后的一个下游的表现是更好的，通过这样不断的做scn lag，然后去拟合出来这样的曲线。

找到这样的一个一个关系对，所以其实它这几里面，其实还是会有一些搜索的过程，但其实现在可能大家认为这个里面，可能它没有绝对的关系，可能反而是他这种策略，就是这种所谓的learn it it。

它可能在一个很大的区间内，都可以达到一个很好的一个优优势，他不是说我必须得到设到一个一个多，具体的值，可能是在一个空，一个一个范围内都可以达到不错的一个效果，对，然后当然刚才这个就是SCALLING了。

也就是他的一个schedule，就是我其实对比那些超参数来说，这些本身训练的方案不是cosine learn read，还是说我的一阶段，二阶段这样的训练可能是更重要的。

所以现在有很多方法都是把它分为几阶段，我有什么warm up，有stable，然后有最后decay这样的一个阶段，这个可能是一个比较新的，而且可能是在大模型时代非常有用的。

这样一个一个schedule吧，对然后就总结一下，其实就是效率提升外，有很多就优化器呀，科学数据啊，还有一些不就是科学的超参数设置，还有学习方案，但可能要去都可以提升，我们刚才讲的这些。

在同样的单位时间内，降低我们这个呃训练的一个一个代价，但可能有一个问题，就是可能我下面也是也是也是要讲的，就是说呃，就是所有的方案其实都在一个，可能都是在小尺寸，或者说一个一定规模下调试得到。

而当尺寸变大之后，这个是不是能完全scale上去，或者这些它我们不能把它叫trick吧，它可能是一些一些empirical的东西，是不是能起到预期的作用，其实现在其实我我现在看到很多。

不管业界还是学工业界，其实都没有一个完全的一个定论对，所以这可能是一个风险，最后其实还有一些精度上的优化，比如说用FP8的训练啊，这肯定都是可以提升优势的，这个当然是一个GPU跟硬件相关的一个方法。

对基英伟达这几年也在不断优化，最近他们TH200经发展到非常好了，最后就讲一下，简单讲一下数据工程吧，其实数据工程就是和，也是刚才那个我记得是一个观众在问的，就说除了你说你改模型结构训练参数。

你是不是数据上能做些优化，能让最后同时同样训练，同样时间，能让最后效果很达的很好，其实确实是，我们现在其实数据工程也是一个非常好的，一个一个一个一个作作用，当然现在数据其实对它优化无非就是筛选采样。

还有一些合成的方法，包括一些组织的方法。

![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/32573de54372409d7fc39c57e7555578_7.png)

对今天简单介绍一下采样这个方法，其实采样是一个很重要的，我们数据你看这不同的模型，有不同的这种采样的方法，但实际上其实没有一个科学的方法，大家可能都是拍脑瓜启发式的，但其实最近就有一篇工作。

其实就是说我如何去确定性的依靠scaling law，就是我把这些不断的用小的方法拟合出来，大的这种东西呢，它其实就是把这个不同的领域的配比，然后进行一个科学的一个一个调配，先去训一个小模型。

然后训一个大模，最后然后把它拟合到一个大模型上，最后他去发现哎，可能我用更少的这样的一个数据量，就可以达到更好的perplexity，这个比一个，就是我找了一个这样好的一个采样的一个方法。

当然还有一些工作，是我通过这种细粒度的数据的采样，就它不是这种大领域的采样，而说我的token，我一句话可能有些很重要，有些不重要，通过这些token上的采样对它进行一个优秀优化。

这个里面应该是介绍对它，它应该叫做real1，它这种方法其实就是一个优化的一个过程，对，然后当然这个方法，它里面做了一个一个一个一一个方法，其实发现已经可以在很短的时间内，就可以训练出来一个很好的模型。



![](https://gitee.com/OpenDocCN/dsai-notes-pt2-zh/raw/master/docs/baai24/img/32573de54372409d7fc39c57e7555578_9.png)

然后让他最后的下下游任务中，达到一个很理想的状态，得到了一个不错的结果，所以其实最近对这种采样的优化，其实大家发现也是非常非常重要，我们单位时间内提升很强的，这样的一个模型的效率对。

然后除了这个之外的话，最后就总结一下吧，因为时间关系，其实我们现在发现，其实我们所有的这种动作，不管是我们结构上的优化，还是我们数据上优化核心，就是我们要去优化这个scorning lots。

几里的这个几个参数，然后其实不管是数据的优化参数，它其实都在单位时间内，我们都想让这个东西降下来，但其实这个东西要涉及到最后一个，就因为这些所有的这引入了这种，不管是我们的trick还是技巧。

还是这些二阶三阶的很多东西，它可能本质都是人类所谓的叫inductive bias，就说我们人类想故意改变这种客观规律，而引入的，像让它加速的这种叫BIOS。

但其实可能是一个就richard so就sultan，他去在是他是一个是强化学习之父吧，他就想其实你纵观可能AI这些年的发展，它最重要一个原理就是你不要把人的鲜艳，那这个里面太多，最好是把它给排除掉。

这个就是所谓的一个better lesson，就是我们不要去把人引入更多人的BISS，就是让他以scale为第一性原理来做，所以可能未来的话，我可能我个人认为呃这些虽然重要，但可能最重要的事情。

还是把它无限制的去把它扩大，然后去做spelling up，这个可能涌现的出来的，是更更高级别的一个智能吧，对今天我的报告就到这。

