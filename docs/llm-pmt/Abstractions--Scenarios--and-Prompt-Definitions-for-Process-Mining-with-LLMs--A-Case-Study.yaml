- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:50:10'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs:
    A Case Study'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.02194](https://ar5iv.labs.arxiv.org/html/2307.02194)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '¹¹institutetext: Process and Data Science Chair, RWTH Aachen University, Aachen,
    Germany ¹¹email: {a.berti, schuster, wvdaalst}@pads.rwth-aachen.de ²²institutetext:
    Fraunhofer FIT, Sankt Augustin, GermanyAlessandro Berti 1122 [0000-0002-3279-4795](https://orcid.org/0000-0002-3279-4795
    "ORCID identifier")    Daniel Schuster 2211 [0000-0002-6512-9580](https://orcid.org/0000-0002-6512-9580
    "ORCID identifier")    Wil M. P. van der Aalst 1122 [0000-0002-0955-6940](https://orcid.org/0000-0002-0955-6940
    "ORCID identifier")'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) are capable of answering questions in natural language
    for various purposes. With recent advancements (such as GPT-4), LLMs perform at
    a level comparable to humans for many proficient tasks. The analysis of business
    processes could benefit from a natural process querying language and using the
    domain knowledge on which LLMs have been trained. However, it is impossible to
    provide a complete database or event log as an input prompt due to size constraints.
    In this paper, we apply LLMs in the context of process mining by i) abstracting
    the information of standard process mining artifacts and ii) describing the prompting
    strategies. We implement the proposed abstraction techniques into *pm4py*, an
    open-source process mining library. We present a case study using available event
    logs. Starting from different abstractions and analysis questions, we formulate
    prompts and evaluate the quality of the answers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Process Querying Prompting Engineering Large Language Models ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f4874bcc11f0d30396fc3997dfae442b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Summary of the approach proposed in the paper: mainstream process
    mining artifacts can be textually abstracted and provided inside prompts directed
    to a LLM, such as GPT-4\. Different prompting strategies can be considered.'
  prefs: []
  type: TYPE_NORMAL
- en: Process mining uses event data from information systems to enhance business
    processes, involving process discovery, conformance checking, model enhancement,
    and predictive analytics. This data science field provides insights for improving
    operational processes.
  prefs: []
  type: TYPE_NORMAL
- en: Transitioning from traditional process analysis, the emergence of Large Language
    Models (LLMs) like GPT-4 [[16](#bib.bib16)] adds a new perspective to data exploration.
    These advanced models, drawing on extensive training data, serve as versatile
    tools for general querying, enabling the extraction of valuable insights. They
    not only generate and retrieve information, but also hold potential to analyse
    and enhance business process outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we investigate the applications of LLMs in the context of process
    mining, which are essential for process querying (i.e., in the verification of
    properties against the event log or the preprocessing phase) and in embedding
    the domain knowledge (used to train the LLM) in the various process mining tasks.
    Despite their impressive performance, applying LLMs like GPT-4 to process mining
    presents challenges due to their ’context window’ limitation [[19](#bib.bib19),
    [6](#bib.bib6)], referring to the maximum sequence length these models can manage
    per interaction. This balancing act between information quantity and output quality
    can lead to significant data loss [[11](#bib.bib11)]. Strategies including text
    compression, context truncation, or improved prompts [[20](#bib.bib20), [8](#bib.bib8)]
    are required to effectively encapsulate process mining information. Therefore,
    we explore in this paper the usage of textual abstractions of standard process
    mining artifacts, e.g., event logs and process models, that can embed the essential
    information of such artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: 'This paper offers various prompting strategies to address the loss of information
    from proposed abstractions. A direct answer or a database query verified against
    the original object may be obtained, as summarized in Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Abstractions, Scenarios, and Prompt Definitions for Process
    Mining with LLMs: A Case Study"). This study further presents the integration
    of the pm4py process mining library¹¹1[https://pm4py.fit.fraunhofer.de](https://pm4py.fit.fraunhofer.de)
    with GPT-4 and provides a case study exploring these prompting strategies using
    public event logs. The case study examines responses under different abstractions
    and GPT-4’s domain knowledge for various processes (medical, travel expense reporting,
    and fines management), alongside additional process mining knowledge required
    for specific use cases.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The remainder of the paper is organized as follows. Section [2](#S2 "2 Related
    Work ‣ Abstractions, Scenarios, and Prompt Definitions for Process Mining with
    LLMs: A Case Study") covers related work. Section [3](#S3 "3 Approach ‣ Abstractions,
    Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study")
    describes the abstractions and the different prompting strategies for LLMs. Section
    [4](#S4 "4 Implementation ‣ Abstractions, Scenarios, and Prompt Definitions for
    Process Mining with LLMs: A Case Study") describes the implementation. Section
    [5](#S5 "5 Case Study ‣ Abstractions, Scenarios, and Prompt Definitions for Process
    Mining with LLMs: A Case Study") presents a case study demonstrating the usage
    of different abstractions and prompting strategies for process mining tasks. Finally,
    Section [6](#S6 "6 Conclusion ‣ Abstractions, Scenarios, and Prompt Definitions
    for Process Mining with LLMs: A Case Study") concludes this paper.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides a brief overview of process querying and the usage of
    domain knowledge in process mining.
  prefs: []
  type: TYPE_NORMAL
- en: Several process-mining-specific querying languages exist [[17](#bib.bib17)].
    In [[18](#bib.bib18)], a framework for devising process querying methods is proposed.
    SQL is widely used for process discovery [[21](#bib.bib21)], conformance checking
    [[2](#bib.bib2)], and data preprocessing [[15](#bib.bib15)]. Cypher, a graph-based
    querying language, has also been adopted for process mining [[10](#bib.bib10)].
    Also, Celonis PQL [[23](#bib.bib23)] is a proprietary high-performance process
    querying language integrated into the Celonis platform. The mentioned languages
    are expressive and permit a versatile set of process mining inquiries. However,
    they require considerable expertise in the syntax and semantics of the query language
    in question and specialist knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: The complexity of process querying can be reduced by translating natural language
    queries into database executable statements. As proposed in [[4](#bib.bib4)],
    a natural language querying interface aids in democratizing process mining, making
    it more accessible to non-technical users. The proposed reference architecture
    handles natural language questions and provides responses by integrating with
    process mining tools, using techniques such as entity recognition and semantic
    parsing. In [[13](#bib.bib13)], a natural language interface is proposed to assist
    the end-user in querying event data stored in a graph database. The natural language
    queries are translated into the Cypher language. Another study, [[1](#bib.bib1)],
    presents a conformance checking method based on NLP, which extracts business actions
    and objects from textual labels associated with events. Meanwhile, [[25](#bib.bib25)]
    focuses on identifying constraints for business process execution from natural
    language documents. In [[12](#bib.bib12)], chatbots are trained on customer service
    conversations to learn the underlying business process, showing the effectiveness
    of such an approach, though the generalization capabilities remain unclear.
  prefs: []
  type: TYPE_NORMAL
- en: Domain knowledge about a process can be expressed in natural language. For example,
    documents might contain the process execution rules if a formal model is not defined.
    Utilizing domain knowledge in process discovery has been investigated in [[22](#bib.bib22)].
    In [[9](#bib.bib9)], the domain knowledge of the process analyst is used to modify/improve
    a discovered process model. In [[3](#bib.bib3)], an event log is abstracted to
    a level needed by the analyst using domain knowledge extracted from the documentation
    of the process to match semi-automatically events and activities.
  prefs: []
  type: TYPE_NORMAL
- en: The role of LLMs in the business process management field has been initially
    investigated in [[7](#bib.bib7)], where prompt engineering techniques to embed
    the required information about the business processes are discussed as an alternative
    to training a company/process-specific LLM.
  prefs: []
  type: TYPE_NORMAL
- en: This paper proposes the usage of LLMs for process mining tasks. LLMs such as
    GPT-4 know the domain knowledge and execution constraints for the set of business
    processes covered by the training data. Therefore, LLMs are not process-specific
    and can interpret and execute queries in natural language. In our case study,
    we show that the queries can be either executed directly against an abstraction
    of a given process mining artifact or database (SQL) queries can be automatically
    generated by GPT-4 to verify hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When using LLMs for process mining, the original event logs or process model
    representations cannot be directly used due to size limitations. An abstraction
    of these artifacts must be obtained to execute specific queries, i.e., prompts,
    against an LLM. In the following subsections, we will explain textual abstractions
    (see Section [3.1](#S3.SS1 "3.1 Abstracting Process Mining Objects ‣ 3 Approach
    ‣ Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs:
    A Case Study")) and different prompt generation strategies (see Section [3.2](#S3.SS2
    "3.2 Prompt Generation ‣ 3 Approach ‣ Abstractions, Scenarios, and Prompt Definitions
    for Process Mining with LLMs: A Case Study")).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Abstracting Process Mining Objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section describes how textual abstractions of common process mining objects,
    i.e., event logs and process models, can be obtained. These abstractions are later
    used in the proposed case study.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Abstracting Event Logs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Traditional event logs link each event with a single case identifier, enabling
    the computation of the directly-follows graph and the identification of traces
    and process variants [[24](#bib.bib24)]. These concepts can be associated with
    frequency and performance metrics
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a directly-follows graph, frequency is quantified by the instances where
    a pair of activities are sequential, and performance is calculated as an aggregation,
    such as average or median, of recorded times between the two activities.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a process variant, frequency is determined by the count of cases following
    the given trace, while performance is an aggregation, such as average or median,
    of total throughput times for the cases.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This information can be textually represented to aid an LLM in responding to
    inquiries about event data. Section [5.2](#S5.SS2 "5.2 Hypothesis Formulation
    and Verification ‣ 5 Case Study ‣ Abstractions, Scenarios, and Prompt Definitions
    for Process Mining with LLMs: A Case Study") and Listing [1](#LST1 "Listing 1
    ‣ 3.1.1 Abstracting Event Logs ‣ 3.1 Abstracting Process Mining Objects ‣ 3 Approach
    ‣ Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs:
    A Case Study") demonstrate the textual representation of variants and the top
    5 relationships from a Directly-Follows Graph (DFG), respectively. When constructing
    the directly-follows graph, various notations may be employed such as $\rightarrow$
    or the phrase “is followed by”. Despite the differences in representation, Large
    Language Models (LLMs) like GPT-4 interpret these notations equivalently.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 1: Textual abstraction of a DFG.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create  Fine  ->  Send  Fine  (  frequency  =  103392  performance  =  7568635.65  )Send  Fine  ->  Insert  Fine  Notification  (  frequency  =  79757  performance  =  1501626.95  )Insert  Fine  Notification  ->  Add  penalty  (  frequency  =  72334  performance  =  5184000.0  )Add  penalty  ->  Send  for  Credit  Collection  (  frequency  =  57182  performance  =  45566346.44  )Create  Fine  ->  Payment  (  frequency  =  46952  performance  =  905663.45  )'
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of object-centric event logs, wherein an event may associate with
    various object types, additional process modeling notations exist that can undergo
    textual abstraction. Specifically, object-centric directly-follows graphs [[5](#bib.bib5)]
    represent an assembly of directly follows graphs corresponding to distinct object
    types.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Abstractions of Process Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Formal process models, e.g., Petri nets, BPMN, and declarative models, express
    constraints on the activities and the paths that are executable in a process.
    For example, the Petri net shown in Fig. [2](#S3.F2 "Figure 2 ‣ 3.1.2 Abstractions
    of Process Models ‣ 3.1 Abstracting Process Mining Objects ‣ 3 Approach ‣ Abstractions,
    Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study")
    can be abstracted as in Listing [2](#LST2 "Listing 2 ‣ 3.2 Prompt Generation ‣
    3 Approach ‣ Abstractions, Scenarios, and Prompt Definitions for Process Mining
    with LLMs: A Case Study"). The method used for textually abstracting a Petri net
    is not fixed and can be approached in multiple ways, provided that the naming
    for places and transitions is unique. The choice of abstraction strategy is arbitrary
    and can be tailored to specific use cases or data structures. Similar textual
    abstractions of many other model formalisms (e.g., process trees, prefix trees,
    transition systems, BPMN models) are possible, but we do not describe them here.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1f11cfb4333de418ff7f3e35d5c539c0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Example sequential Petri net. From the initial state (source), the
    transitions A and B could be used to reach the final state (sink).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Prompt Generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After obtaining the abstractions above, we can provide them to an LLM along
    with a query. These prompts could lead to two different types of answers, i.e.,
    directly answering the original questions or leading to the formulation of hypotheses
    that can be verified against the data by means of database queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 2: Textual abstraction of the Petri net represented in Fig. [2](#S3.F2
    "Figure 2 ‣ 3.1.2 Abstractions of Process Models ‣ 3.1 Abstracting Process Mining
    Objects ‣ 3 Approach ‣ Abstractions, Scenarios, and Prompt Definitions for Process
    Mining with LLMs: A Case Study").'
  prefs: []
  type: TYPE_NORMAL
- en: 'places:  [  p1,  sink,  source  ]transitions:  [  (A,  ’A’),  (B,  ’B’)  ]arcs:  [  (A,  ’A’)->p1,  (B,  ’B’)->sink,  p1->(B,  ’B’),  source->(A,  ’A’)  ]initial  marking:  [’source:1’]final  marking:  [’sink:1’]'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Direct Answering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An LLM prompt can be formulated using abstractions, such as ”Describe the meaning
    of the activity A,” which is particularly useful for descriptive or conformance
    checking purposes. It’s important that these prompts consider no more knowledge
    than the provided event log or process model abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the inherently probabilistic behavior of LLMs like GPT-4, the same question
    might yield varying responses across different sessions. This feature, rather
    than being an issue, is part of the model’s design to promote diverse outputs
    and creative problem solving. If initial responses do not adequately meet the
    user’s need, refining the question or asking more specific follow-up questions
    is possible to address any perceived gaps in the information provided.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Hypothesis Formulation and Verification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Certain process mining questions can be answered using the DFG/variants abstraction
    as they concern the order of activities. However, questions related to time and
    data perspectives of the event log, which require access to additional attributes
    or information, cannot be directly addressed by such abstractions. We may formulate
    hypotheses, such as impacts of specific activities on case duration, but these
    need further verification.
  prefs: []
  type: TYPE_NORMAL
- en: To verify a hypothesis, we can prompt an LLM, like GPT-4, with good SQL knowledge
    [[14](#bib.bib14)], to generate a database query that can be applied to the whole
    event log. The prompt uses the DFG/variants abstraction and an abstraction of
    event log attributes. Upon receiving the result of a query from the user, the
    LLM can then assess this information to confirm, refine, or dismiss the hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: It is also important to note that LLMs, provided with the top variants and attributes,
    can autonomously generate hypotheses on the data. Through provided abstractions,
    LLMs can make assertions and formulate database queries for hypothesis testing,
    demonstrating their flexibility and adaptability in process mining tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, LLMs offer flexibility in formulating queries for hypothesis testing
    based on provided abstractions.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we present the implementation of various abstractions (see
    Section [3.1](#S3.SS1 "3.1 Abstracting Process Mining Objects ‣ 3 Approach ‣ Abstractions,
    Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study"))
    into the open-source process mining library, pm4py (version 2.7.5 or later). The
    goal is to create textual abstractions of process mining artifacts, like traditional/object-centric
    event logs and process models (Petri nets), suitable for GPT-4’s input limit.
    From these abstractions, specific queries are formulated for GPT-4 execution.
    Listing [3](#LST3 "Listing 3 ‣ 4 Implementation ‣ Abstractions, Scenarios, and
    Prompt Definitions for Process Mining with LLMs: A Case Study") demonstrates this
    integration, where an event log is ingested for root cause analysis, and the inductive
    miner algorithm discovers a process model for optimization suggestions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 3: Example usage of the pm4py’s OpenAI/GPT-4 integration on traditional
    process mining objects'
  prefs: []
  type: TYPE_NORMAL
- en: 'import  pm4pylog  =  pm4py.read_xes(”tests/input_data/roadtraffic100traces.xes”)iq1  =  ”””\n␣What␣are␣the␣root␣causes␣of␣the␣performance␣issues␣in␣the␣process?Please␣provide␣only␣process␣and␣data␣specific␣considerations,no␣general␣considerations.”””print(pm4py.llm.abstract_variants(log)  +  iq1)net,  im,  fm  =  pm4py.discover_petri_net_inductive(log)iq2  =  ”””\n␣Can␣you␣provide␣suggestions␣to␣improve␣the␣process␣modelbased␣on␣your␣domain␣knowledge?”””print(pm4py.llm.abstract_petri_net(net,  im,  fm)  +  iq2)'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Case Study
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We present a case study using publicly available event logs and GPT-4 [[16](#bib.bib16)].
    We propose an assessment of prompts that can be directly answered by GPT-4. Further,
    we propose an example of hypothesis formulation and verification against the entire
    dataset (by means of a SQL query).
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Direct Answering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To assess prompts requiring direct answers from the LLM, we use publicly available
    event logs: (1) Road Traffic Fine Management process ²²2[https://data.4tu.nl/articles/_/12683249/1](https://data.4tu.nl/articles/_/12683249/1),
    which is related to the management of fines in an Italian municipality, (2) BPI
    Challenge 2020: Domestic Declarations ³³3[https://data.4tu.nl/collections/_/5065541/1](https://data.4tu.nl/collections/_/5065541/1),
    which is a travel expense approval process, (3) Sepsis Cases⁴⁴4[https://data.4tu.nl/articles/_/12707639/1](https://data.4tu.nl/articles/_/12707639/1),
    which is a medical process for sepsis treatment, and (4) Conformance Checking
    Challenge 2019⁵⁵5[https://data.4tu.nl/articles/_/12707639/1](https://data.4tu.nl/articles/_/12707639/1),
    which is a medical training process.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Experimental results for the provided prompts (each containing an
    abstraction and a question) on publicly available event logs.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Question | Abstraction | Road Traffic | BPIC 2020 | Sepsis | CCC 19 |'
  prefs: []
  type: TYPE_TB
- en: '| Descriptive Questions |'
  prefs: []
  type: TYPE_TB
- en: '| DQ1 | DFG |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DQ1 | Variants |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Conformance Questions |'
  prefs: []
  type: TYPE_TB
- en: '| CQ1 | DFG |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| CQ1 | Variants |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Process Improvement Questions |'
  prefs: []
  type: TYPE_TB
- en: '| IQ1 | DFG |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| IQ1 | Variants |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| IQ2 | Petri net |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: We have compiled a list of questions related to processes, sorted into various
    categories⁶⁶6A more extensive list of questions is available at [https://pm4py.fit.fraunhofer.de/static/assets/api/2.7.3/api.html#openai-integration-pm4py-openai](https://pm4py.fit.fraunhofer.de/static/assets/api/2.7.3/api.html#openai-integration-pm4py-openai)..
    Each question is accompanied by acceptance criteria to help determine if the response
    given by the LLM is satisfactory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Descriptive Questions:'
  prefs: []
  type: TYPE_NORMAL
- en: DQ1
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you describe the process contained in this data?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-4 should provide the name/category of the process underlying the data and
    the description of the main steps of the process).
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If GPT-4 does not correctly understand the context and identifies the wrong
    name or category for the process, the response is considered unsatisfactory.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Conformance Questions:'
  prefs: []
  type: TYPE_NORMAL
- en: CQ1
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you pinpoint the central anomalies of the process from this data? Please
    only process and data-specific considerations, not general considerations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Our expectation is that GPT-4, using its domain knowledge, is able to identify
    paths that are illogical, rework, or missing activities.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A response is deemed unsatisfactory if GPT-4 points to infrequent activities/paths,
    and to paths with high performance, without exploiting the domain knowledge about
    the process.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Process Improvement Questions:'
  prefs: []
  type: TYPE_NORMAL
- en: IQ1
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the root causes of performance issues specific to the process and related
    data? Please refrain from providing general considerations and focus on issues
    directly tied to the process and its data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Our expectation is that GPT-4 should identify activities, paths, or rework that
    lead to higher throughput times.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A response is deemed unsatisfactory when GPT-4 identifies just the infrequent
    activities or paths, or is able to detect different execution orders for the activities
    but asks the user to verify if there is something wrong.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: IQ2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please suggest improving the process model based on your domain knowledge. Also,
    please compare it against implementations of similar processes. Provide only process
    and data-specific considerations, not general ones.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We expect that GPT-4 can suggest additional activities to optimize the throughput
    time and reduce rework. Also, it should be able to detect when the activities
    are executed in a suboptimal order.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A response is deemed unsatisfactory if general considerations about merging
    activities or reducing invisible steps are provided.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Certain queries align closely with those presented in [[4](#bib.bib4)]. Specifically,
    IQ1 and IQ2 correspond to questions 104 and 71 respectively, as listed in the
    provided resource ([https://ic.unicamp.br/~luciana.barbieri/pmquestions.csv](https://ic.unicamp.br/~luciana.barbieri/pmquestions.csv)).
    Nevertheless, DQ1 and CQ1, which pertain to descriptive analytics and anomaly
    detection, exceed the capabilities offered by the Everflow tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the considered prompts have been created starting from the result of abstraction
    and including one question. The prompts have been executed against GPT-4 [[16](#bib.bib16)].
    We report on the quality of the answers in Table [1](#S5.T1 "Table 1 ‣ 5.1 Direct
    Answering ‣ 5 Case Study ‣ Abstractions, Scenarios, and Prompt Definitions for
    Process Mining with LLMs: A Case Study"). Each row reports the results on the
    considered logs for a given abstraction and question. Different colors have been
    used: green indicates a useful answer for the given question, orange indicates
    a partly useful response, and red indicates that GPT-4 did not provide a good
    answer to the given question.'
  prefs: []
  type: TYPE_NORMAL
- en: The response to descriptive questions has been satisfying for all event logs.
    GPT-4 for the considered questions and event logs is able to provide meaningful
    answers starting from both the directly-follows graph and variants. In particular,
    it is surprising that the DFG abstraction (which can be efficiently computed for
    large event logs) is sufficient not only to make local considerations (related
    to a path/activity of the process) but on the end-to-end execution of the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The conformance questions elicited satisfying responses for the ”Road Traffic”
    and ”BPI Challenge 2020” event logs (see Listing [4](#LST4 "Listing 4 ‣ 5.1 Direct
    Answering ‣ 5 Case Study ‣ Abstractions, Scenarios, and Prompt Definitions for
    Process Mining with LLMs: A Case Study")). Key issues like inconsistent activity
    order and multiple payment recordings were pinpointed for ”Road Traffic,” while
    the ”BPI Challenge 2020” rework in rejections/resubmissions were identified as
    problematic. Contrarily, responses for medical event logs ”Sepsis” and ”CCC19”
    were below expectations, possibly due to GPT-4’s limited domain knowledge of medical
    processes and difficulties handling their unstructured nature and high event count
    per case.'
  prefs: []
  type: TYPE_NORMAL
- en: Responses to process improvement questions met expectations for the ”Road Traffic”
    and ”BPI Challenge 2020” event logs, especially with the variants abstraction.
    The directly-follows graph abstraction had limited utility in root cause analysis,
    as rework was more discernible in variants abstraction. However, for IQ2 employing
    model-based abstraction, GPT-4 offered valuable process optimization insights
    expressed in natural text.
  prefs: []
  type: TYPE_NORMAL
- en: For the contexts where both the DFG and variants abstraction are useful, we
    found that different viewpoints are provided. Therefore, the tips obtained thanks
    to different abstractions can be combined. Across different executions, we obtained
    slightly different answers (with similar degrees of usefulness), which can lead
    to a broader set of insights.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 4: Response to CQ1 for the BPI Challenge 2020 event log.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From  the  given  data,  here  are  some  of  the  potential  anomalies  I  can  identify  in  this  process:Inefficient  Process  Variants:  There  are  several  process  variants  where  a  declaration  is  rejected  multiple  times  (by  either  ADMINISTRATION,  PRE_APPROVER,  SUPERVISOR,  or  BUDGET  OWNER)  before  it  is  finally  approved.  This  suggests  an  inefficiency  in  the  process  that  may  require  further  investigation.  It  is  possible  that  the  declaration  is  not  adequately  prepared  before  submission  or  the  criteria  for  approval  are  not  clearly  communicated.  These  inefficient  process  variants  not  only  increase  the  frequency  of  steps  in  the  process  but  also  increase  the  overall  performance  time.High  Performance  Time:  Some  process  variants  have  remarkably  high  performance  times.  For  instance,  the  process  variant  where  the  declaration  is  ”SUBMITTED␣by␣EMPLOYEE␣->␣Declaration␣REJECTED␣by␣ADMINISTRATION”  has  a  performance  time  of  13805149.2.  This  high  performance  time  could  indicate  a  delay  or  bottleneck  in  the  process  that  needs  to  be  addressed.Missing  Steps:  There  is  a  process  variant  where  a  declaration  is  directly  ”FINAL_APPROVED␣by␣SUPERVISOR”  without  going  through  ”APPROVED␣by␣ADMINISTRATION”  or  ”APPROVED␣by␣BUDGET␣OWNER”  or  ”APPROVED␣by␣PRE_APPROVER”.  This  could  indicate  a  deviation  from  the  standard  process,  which  might  either  suggest  an  alternative  process  route  or  a  process  violation.Unfinished  Process:  There  are  some  process  variants  that  do  not  end  with  ”Payment␣Handled”,  such  as  ”Declaration␣SUBMITTED␣by␣EMPLOYEE␣->␣Declaration␣REJECTED␣by␣ADMINISTRATION␣->␣Declaration␣REJECTED␣by␣EMPLOYEE”  and  ”Declaration␣SUBMITTED␣by␣EMPLOYEE␣->␣Declaration␣REJECTED␣by␣SUPERVISOR␣->␣Declaration␣REJECTED␣by␣EMPLOYEE”.  This  could  mean  that  these  processes  are  incomplete,  or  that  the  payment  handling  is  being  done  outside  of  the  tracked  process.Unexpected  REJECTION:  There  are  a  few  process  variants  where  after  being  ”FINAL_APPROVED␣by␣SUPERVISOR”,  the  declaration  is  ”REJECTED␣by␣MISSING”.  This  is  unexpected  as  the  declaration  should  ideally  not  be  rejected  after  final  approval.  This  anomaly  might  indicate  some  errors  or  issues  in  the  process  or  system.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Hypothesis Formulation and Verification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We provide an example of hypothesis formulation and verification on top of
    the Road Traffic Fine Management event log. For this, we formulate the prompt
    in Listing [5](#LST5 "Listing 5 ‣ 5.2 Hypothesis Formulation and Verification
    ‣ 5 Case Study ‣ Abstractions, Scenarios, and Prompt Definitions for Process Mining
    with LLMs: A Case Study"), containing the top variants of the event log, and a
    summary of the numerical attributes of the event log.'
  prefs: []
  type: TYPE_NORMAL
- en: In preliminary tests, GPT-4 required details about case identifier, activity,
    and timestamp attributes. It also attempted to access a non-existent variant attribute
    and needed guidance to compute the case’s duration. Yet, given the limited information,
    GPT-4 surprisingly formulated plausible and testable hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: 'GPT-4 generates various hypotheses for the given event log, including a supposed
    influence of the ’expense’ attribute on ’Payment’ activity occurrence. Testing
    this hypothesis using the SQL query in Listing [6](#LST6 "Listing 6 ‣ 5.2 Hypothesis
    Formulation and Verification ‣ 5 Case Study ‣ Abstractions, Scenarios, and Prompt
    Definitions for Process Mining with LLMs: A Case Study") shows it to be inaccurate,
    as the minor difference in average expenses between cases with and without payment
    isn’t statistically significant. Given these results, GPT-4 suggests examining
    the ’amount’ attribute’s influence on payment presence, recognizing its initial
    hypothesis as unsubstantiated.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 5: Prompt provided to GPT-4 for hypothesis formulation on the Road
    Traffic Fine Management event log.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If  I  have  a  process  with  the  following  process  variants:Create  Fine  ->  Send  Fine  ->  Insert  Fine  Notification  ->  Add  penalty  ->  Send  for  Credit  Collection  (  frequency  =  56482  performance  =  59591524.946000494  )Create  Fine  ->  Payment  (  frequency  =  46371  performance  =  889688.4000776347  )Create  Fine  ->  Send  Fine  (  frequency  =  20385  performance  =  8380516.026490066  )…and  the  log  of  the  process  contains  the  following  attributes:amount  empty:  331240  quantiles:  {0.0:  0.0,  0.25:  33.6,  0.5:  38.0,  0.75:  71.5,  1.0:  8000.0}article  empty:  411100  quantiles:  {0.0:  7.0,  0.25:  7.0,  0.5:  157.0,  0.75:  157.0,  1.0:  401.0}expense  empty:  457483  quantiles:  {0.0:  0.0,  0.25:  10.0,  0.5:  11.88,  0.75:  13.5,  1.0:  76.0}time:timestamp  empty:  0  quantiles:  {0.0:  Timestamp(’2000-01-01␣00:00:00+0000’,  tz=’UTC’),  0.25:  Timestamp(’2002-11-12␣00:00:00+0000’,  tz=’UTC’),  0.5:  Timestamp(’2006-02-28␣00:00:00+0000’,  tz=’UTC’),  0.75:  Timestamp(’2009-03-30␣00:00:00+0000’,  tz=’UTC’),  1.0:  Timestamp(’2013-06-18␣00:00:00+0000’,  tz=’UTC’)}…Can  you  provide  some  hypothesis  between  the  execution  of  the  process  and  its  attributes?  I  mean,  can  you  provide  me  a  DuckDB  SQL  query  that  I  can  execute,  and  return  the  results  to  you,  in  order  for  you  to  evaluate  such  hypothesis  about  the  process?  More  in  detail,  the  data  is  stored  in  a  Pandas  dataframe  where  each  row  is  an  event  having  the  provided  attributes  (so  there  are  no  separate  table  containing  the  variant).  Can  you  tell  me  in  advance  which  hypothesis  you  want  to  verify?  Please  consider  the  following  information:  the  case  identifier  is  called  ”case:concept:name”,  the  activity  is  stored  inside  the  attribute  ”concept:name”,  the  timestamp  is  stored  inside  the  attribute  ”time:timestamp”,  the  resource  is  stored  inside  the  attribute  ”org:resource”,  there  is  not  a  variant  column  but  that  can  be  obtained  as  concatenation  of  the  activities  of  a  case,  there  is  not  a  duration  column  but  that  can  be  obtained  as  difference  between  the  timestamp  of  the  first  and  the  last  event.  Also,  the  dataframe  is  called  ”dataframe”.  You  should  use  the  EPOCH  function  of  DuckDB  to  get  the  timestamp  from  the  date.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 6: SQL code provided by GPT-4 for the verification of an hypothesis
    on the entire dataset'
  prefs: []
  type: TYPE_NORMAL
- en: 'WITH  case_has_payment  AS  (SELECT  ”case:concept:name”,MAX(CASE  WHEN  ”concept:name”  =  ’Payment’  THEN  1  ELSE  0  END)as  has_paymentFROM  dataframeGROUP  BY  ”case:concept:name”)SELECT  has_payment,  AVG(expense)  as  avg_expenseFROM  dataframeJOIN  case_has_payment  ONdataframe.”case:concept:name”  =  case_has_payment.”case:concept:name”GROUP  BY  has_payment;'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Limitations, Open Challenges, and Opportunities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The results indicate that GPT-4’s proficiency in addressing advanced conformance
    and process improvement queries improves with mainstream and standardized processes.
    Generally, GPT-4 exhibits substantial process mining understanding, albeit with
    the need for simple instructions for computing variants and throughput time. Notably,
    it was intriguing that GPT-4 could decipher the entire process execution from
    the DFG abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, these insights warrant validation against a wider array of questions
    and event logs. Additionally, the assessment of the proposed questions was based
    on the stated acceptance criteria, which is somewhat subjective, and alternative
    criteria could be employed. Consequently, the presented case study should be regarded
    as a preliminary exploration of LLMs’ applicability in process mining.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The findings of this study provide promising indications for the application
    of Large Language Models (LLMs) in process mining, underscoring their potential
    in handling complex queries and process interpretations. LLMs, such as GPT-4,
    demonstrate impressive proficiency in understanding and analyzing process structures,
    highlighting the vast opportunities these models could bring to the field.
  prefs: []
  type: TYPE_NORMAL
- en: However, several challenges persist. One key concern is privacy - a considerable
    number of companies may be reticent to upload their core data to public LLMs like
    GPT-4 due to the sensitivity of the information involved. This brings to the fore
    the need for private LLMs, which can balance the utility of large-scale language
    models with the security needs of individual organizations.
  prefs: []
  type: TYPE_NORMAL
- en: To address privacy concerns, proprietary LLMs could be developed, trained on
    a mix of general and company-specific data. While current open-source models lag
    behind GPT-4, they’re improving, suggesting the feasibility of private, customized
    LLMs. These models could potentially enhance process mining’s efficiency and adaptability.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] van der Aa, H., Rebmann, A., Leopold, H.: Natural language-based detection
    of semantic execution anomalies in event logs. Inf. Syst. 102, 101824 (2021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Baader, G., Krcmar, H.: Reducing false positives in fraud detection: Combining
    the red flag approach with process mining. Int. J. Account. Inf. Syst. 31, 1–16
    (2018)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Baier, T., Mendling, J., Weske, M.: Bridging abstraction layers in process
    mining. Inf. Syst. 46, 123–139 (2014)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Barbieri, L., Madeira, E., Stroeh, K., van der Aalst, W.M.P.: A natural
    language querying interface for process mining. Journal of Intelligent Information
    Systems pp. 1–30 (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Berti, A., van der Aalst, W.M.P.: OC-PM: analyzing object-centric event
    logs and process models. Int. J. Softw. Tools Technol. Transf. 25(1), 1–17 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are
    few-shot learners. Advances in neural information processing systems 33, 1877–1901
    (2020)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Busch, K., Rochlitzer, A., Sola, D., Leopold, H.: Just tell me: Prompt
    engineering in business process management. In: van der Aa, H., Bork, D., Proper,
    H.A., Schmidt, R. (eds.) Enterprise, Business-Process and Information Systems
    Modeling - 24th International Conference, BPMDS 2023, and 28th International Conference,
    EMMSAD 2023, Zaragoza, Spain, June 12-13, 2023, Proceedings. Lecture Notes in
    Business Information Processing, vol. 479, pp. 3–11\. Springer (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of
    deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805
    (2018)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Dixit, P.M., Buijs, J.C.A.M., van der Aalst, W.M.P., Hompes, B., Buurman,
    H.: Enhancing process mining results using domain knowledge. In: Proceedings of
    the 5th International Symposium on Data-driven Process Discovery and Analysis
    (SIMPDA 2015). pp. 79–94\. CEUR-WS.org (2015)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Esser, S., Fahland, D.: Multi-dimensional event data in graph databases.
    J. Data Semant. 10(1-2), 109–141 (2021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Kaplan, J., McCandlish, S., Henighan, T., Brown, T.B., Chess, B., Child,
    R., Gray, S., Radford, A., Wu, J., Amodei, D.: Scaling laws for neural language
    models. arXiv preprint arXiv:2001.08361 (2020)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Kecht, C., Egger, A., Kratsch, W., Röglinger, M.: Quantifying chatbots’
    ability to learn business processes. Inf. Syst. 113, 102176 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Kobeissi, M., Assy, N., Gaaloul, W., Defude, B., Benatallah, B., Haidar,
    B.: Natural language querying of process execution data. Inf. Syst. 116, 102227
    (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Liu, A., Hu, X., Wen, L., Yu, P.S.: A comprehensive evaluation of chatgpt’s
    zero-shot text-to-sql capability. CoRR abs/2303.13547 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] de Murillas, E.G.L., Reijers, H.A., van der Aalst, W.M.P.: Connecting
    databases with process mining: a meta model and toolset. Softw. Syst. Model. 18(2),
    1209–1247 (2019)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] OpenAI: GPT-4 technical report. CoRR abs/2303.08774 (2023)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Polyvyanyy, A.: Process Querying Methods. Springer (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Polyvyanyy, A., Ouyang, C., Barros, A., van der Aalst, W.M.P.: Process
    querying: Enabling business intelligence through query-based process analytics.
    Decis. Support Syst. 100, 41–56 (2017)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.:
    Language models are unsupervised multitask learners. OpenAI blog 1(8),  9 (2019)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Reimers, N., Gurevych, I.: Sentence-bert: Sentence embeddings using siamese
    bert-networks. arXiv preprint arXiv:1908.10084 (2019)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Schönig, S., Rogge-Solti, A., Cabanillas, C., Jablonski, S., Mendling,
    J.: Efficient and customisable declarative process mining with SQL. In: Advanced
    Information Systems Engineering. LNCS, vol. 9694, pp. 290–305. Springer (2016)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Schuster, D., van Zelst, S.J., van der Aalst, W.M.P.: Utilizing domain
    knowledge in data-driven process discovery: A literature review. Comput. Ind.
    137 (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Vogelgesang, T., Ambrosy, J., Becher, D., Seilbeck, R., Geyer-Klingeberg,
    J., Klenk, M.: Celonis PQL: A query language for process mining. In: Process Querying
    Methods, pp. 377–408\. Springer (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Weerdt, J.D., Wynn, M.T.: Foundations of process event data. In: Process
    Mining Handbook, LNBIP, vol. 448, pp. 193–211\. Springer (2022)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Winter, K., Rinderle-Ma, S.: Detecting constraints and their relations
    from regulatory documents using NLP techniques. In: On the Move to Meaningful
    Internet Systems. OTM 2018 Conferences. LNCS, vol. 11229, pp. 261–278. Springer
    (2018)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
