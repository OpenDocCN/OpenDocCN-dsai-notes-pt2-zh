- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:50:58'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.12519](https://ar5iv.labs.arxiv.org/html/2305.12519)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Xiao Yu^(1†), Yuang Qi^(1†), Kejiang Chen¹  , Guoqiang Chen¹
  prefs: []
  type: TYPE_NORMAL
- en: Xi Yang¹, Pengyuan Zhu², Weiming Zhang¹, Nenghai Yu¹
  prefs: []
  type: TYPE_NORMAL
- en: ^†equal contribution
  prefs: []
  type: TYPE_NORMAL
- en: ¹University of Science and Technology of China
  prefs: []
  type: TYPE_NORMAL
- en: ²Hefei High-dimensional Data Technology
  prefs: []
  type: TYPE_NORMAL
- en: qya7ya@mail.ustc.edu.cn, {chenkj, zhangwm, ynh}@ustc.edu.cn
  prefs: []
  type: TYPE_NORMAL
- en: zhupengyuan@hddata.cn Corresponding author.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) can generate texts that carry the risk of various
    misuses, including plagiarism, planting fake reviews on e-commerce platforms,
    or creating fake social media postings that can sway election results. Detecting
    whether a text is machine-generated has thus become increasingly important. While
    machine-learning-based detection strategies exhibit superior performance, they
    often lack generalizability, limiting their practicality. In this work, we introduce
    GPT Paternity Test (GPT-Pat), which reliably detects machine-generated text across
    varied datasets. Given a text under scrutiny, we leverage ChatGPT to generate
    a corresponding question and provide a re-answer to the question. By comparing
    the similarity between the original text and the generated re-answered text, it
    can be determined whether the text is machine-generated. GPT-Pat consists of a
    Siamese network to compute the similarity between the original text and the generated
    re-answered text and a binary classifier. Our method achieved an average accuracy
    of 94.57% on four generalization test sets, surpassing the state-of-the-art RoBERTa-based
    method by 12.34%. The accuracy drop of our method is only about half of that of
    the RoBERTa-based method when it is attacked by re-translation and polishing.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large language models (LLMs) are neural networks that consist of hundreds of
    billions (or even more) of parameters. Prominent examples of LLMs include GPT-3
    [[4](#bib.bib4)], PaLM [[6](#bib.bib6)], ChatGPT ¹¹1Launched by OpenAI in November
    2022\. [https://chat.openai.com/chat](https://chat.openai.com/chat), and LLaMA
    [[31](#bib.bib31)]. These models are trained using extensive text data, allowing
    them to generate human-like responses and exhibit advanced language capabilities
    to understand natural language and solve complex tasks via text generation. LLMs
    such as ChatGPT can convincingly answer complex questions about science, mathematics,
    historical and current events, and social trends. ChatGPT has attracted the attention
    of millions of people, making it the fastest-growing app of all time [[15](#bib.bib15)].
    It has made significant advances in the field of natural language processing and
    can proficiently generate text for tasks such as writing emails, news reports,
    and academic papers.
  prefs: []
  type: TYPE_NORMAL
- en: However, if placed in wrong hands, ChatGPT can undoubtedly serve as a "weapon
    of mass deception" [[29](#bib.bib29)]. It is undeniable that this tool has the
    potential to become the most powerful means of spreading misinformation ever witnessed
    on the Internet. With ChatGPT, fabricating false narratives can be accomplished
    on a massive scale and with alarming frequency, akin to AI agents actively contributing
    to disinformation [[11](#bib.bib11)]. Extensive research in the field indicates
    that ChatGPT demonstrates a bias toward certain values [[18](#bib.bib18)], which
    must be taken into consideration. Additionally, the formidable writing capabilities
    of ChatGPT pose a significant threat to democracy, as they enable the creation
    of automated bots on online social networks that can manipulate people’s political
    choices during election campaigns [[30](#bib.bib30), [11](#bib.bib11)]. Furthermore,
    the adoption of ChatGPT by students in educational institutions has led to instances
    of academic dishonesty, with essays and assignments being generated through its
    use, as reported by various news sources [[19](#bib.bib19), [26](#bib.bib26)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Text produced by LLMs such as ChatGPT often bears a striking resemblance to
    text written by humans, exhibiting similarities in style, grammar, and coherence.
    As a result, humans only marginally outperform chance when attempting to classify
    machine-generated text versus human-written text. Consequently, researchers have
    developed more precise automated detection methods to address this challenge.
    Specifically, two categories of methods have been considered: metric-based methods
    [[10](#bib.bib10), [20](#bib.bib20), [30](#bib.bib30), [12](#bib.bib12)] and model-based
    methods [[30](#bib.bib30), [12](#bib.bib12)]. Metric-based methods rely on metrics
    such as perplexity and log probability, while model-based methods involve training
    a classification model using corpora consisting of both machine-generated and
    human-written text. In general, the latter category of methods demonstrates superior
    detection capabilities [[14](#bib.bib14)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ff62ce46c5996288b0255ed73fefee58.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: An illustration of GPT-Pat. We send the text to be detected to a
    large language model of ChatGPT, generate a question and feed it into the model
    to generate a corresponding re-answered text. Compare the similarity between the
    original text and the re-answered text for machine-generated text detection. If
    the similarity is high, the text to be detected is likely to be machine-generated
    text.'
  prefs: []
  type: TYPE_NORMAL
- en: Despite the achievements made by existing methods, detecting machine-generated
    text in more intricate scenarios remains a significant challenge. One such challenge
    arises from the complexity of text content in real-world detection scenarios.
    Existing methods necessitate the collection of extensive machine-generated and
    human-written text corpora for training purposes. However, machine-learning-based
    classifiers are susceptible to overfitting, thereby impacting their actual detection
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge lies in effectively addressing user perturbations. To evade
    detection, users are prone to employing various techniques, including multiple
    translations and artificial modifications on machine-generated text. It has been
    observed that existing detection methods struggle to perform well in the face
    of such attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address these challenges, this paper aims to propose a more comprehensive
    detection method. Due to LLMs lack the lived experiences and contextual knowledge
    that humans possess, and are limited to generating content based on the patterns
    found in their training data, we put forward a simple hypothesis: when similar
    questions are posed to a large language model, the model’s output will also be
    similar. We define this characteristic as the *genetic inheritance* of LLMs, signifying
    that everything the model generates is derived from its training data. We utilize
    the genetic inheritance of LLMs to develop a novel detection method, which we
    have aptly named the GPT Paternity Test (GPT-Pat). In this method, we employ ChatGPT
    itself to summarize the text under scrutiny, presenting it as an answer to a specific
    question. Subsequently, we instruct ChatGPT to generate an answer to this question.
    By comparing the similarity between the original text and the re-answered text,
    we can determine whether the text is machine-generated. We hypothesize that if
    the text to be detected is generated by ChatGPT, the re-answered text will exhibit
    higher similarity to the original text. Conversely, if the text under examination
    is human-written, the similarity score will be lower. Our proposed method involves
    leveraging a Siamese network model to assess the similarity between the original
    and generated text, facilitating the detection of machine-generated content. See
    Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ GPT Paternity Test: GPT Generated
    Text Detection with GPT Genetic Inheritance") for an overview of GPT-Pat.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our main contributions are: (1) We present a novel method to detect machine-generated
    text by introducing the concept of genetic inheritance. This concept leverages
    ChatGPT’s ability to detect itself in part by generating questions and re-answering;
    (2) We experiment in more realistic and complex environments. Our method achieves
    the state-of-the-art performance to date and improves the average accuracy by
    at least 12.34% over existing methods in detecting out-of-domain data; (3) We
    consider human-machine collaboration in real-world scenarios where users usually
    make secondary adjustments, our method also exhibits good robustness against attacks.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Several methods have been developed for detecting machine-generated text in
    the context of large language models (LLMs). In this paper, we focus on two metric-based
    detection methods, including Perplexity and DetectGPT, and a model-based detection
    methods that employ a fine-tuned RoBERTa model as a classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Metric-based Detection.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Perplexity (PPL) is a widely used metric for assessing the performance of large
    language models (LLMs) [[5](#bib.bib5)]. It is calculated as the exponential of
    the negative average log-likelihood of the text given the LLM. In general, machine-generated
    text produced by LLMs tends to have lower perplexity values than human-written
    text [[12](#bib.bib12)].
  prefs: []
  type: TYPE_NORMAL
- en: Mitchell et al. [[20](#bib.bib20)] introduced DetectGPT, a method that examines
    the fluctuations in the log probability function of a language model when minor
    perturbations are introduced to the original text. The fundamental idea behind
    this method posits that machine-generated text generated by LLMs often resides
    within a local optimum of the model’s log probability function.
  prefs: []
  type: TYPE_NORMAL
- en: Model-based Detection.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Model-based methods leverage statistical models to extract patterns and features
    from annotated data. A commonly employed approach involves training a binary classifier
    capable of distinguishing between generated and human-written text. Guo et al.
    [[12](#bib.bib12)] collected paired human-written text and ChatGPT-generated text,
    creating the HC3 dataset. They then fine-tuned a RoBERTa model using this dataset
    to construct a text detector. Additionally, they proposed a novel training strategy
    that incorporates question-answer text pairs to jointly fine-tune the RoBERTa
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Motivation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Traditional machine-generated text detection methods have primarily relied on
    data-driven binary classification, which involves training detectors using available
    data. However, this approach is susceptible to overfitting and relies heavily
    on the quality and availability of training data. Alternatively, optimization-based
    exploration methods require knowledge of intermediate model outputs or the use
    of fully controllable generative models, which are often impractical in real-world
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: To address these limitations, our research aims to investigate and analyze the
    underlying principles of machine-generated text generation. By uncovering the
    distinctions between machine-generated and human-written texts, we seek to uncover
    novel detection ideas that can enhance the effectiveness of detection methods.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 GPT Genetic Inheritance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After conducting a thorough examination of popular language models, we have
    observed remarkable advantages in fine-tuned large language models that employ
    carefully engineered text prompts. These models operate in accordance with the
    instruction fine-tuning approach, similar to InstructGPT[[24](#bib.bib24)], where
    they respond to user-provided instructions or prompts. In most cases, the user’s
    instruction can be seen as a question posed to the large language model (e.g.,
    ChatGPT), and the text generated by ChatGPT can be considered the model’s response
    or answer to that question. In the rest of this paper, we use GPT or ChatGPT to
    refer to all large language models with similar capabilities and no longer distinguish
    between the concepts of GPT-generated text, LLM-generated text, and machine-generated
    text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on our analysis of ChatGPT’s training process and user interactions,
    we propose a hypothesis: when ChatGPT consistently produces answers to similar
    questions, generated texts (i.e., ChatGPT’s responses to these questions) exhibit
    high similarity. In simpler terms, the language model’s output is a rearrangement
    of the content found in its training corpus. Therefore, when repeatedly answering
    a question, the language model’s response will be constrained by the information
    within its training corpus, resulting in limited deviations. We refer to this
    characteristic as the "genetic inheritance" of GPT-generated text. We present
    a more formal statement of our hypothesis in Hypothesis [3.1](#S3.Thmtheorem1
    "Hypothesis 3.1 (GPT Genetic Inheritance.) ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method
    ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance").'
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 3.1 (GPT Genetic Inheritance.)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let $\mathcal{T}=\{T_{1},T_{2},...\}$.
  prefs: []
  type: TYPE_NORMAL
- en: $A\to B$ in content and meaning. This hypothesis posits that the output of ChatGPT
    is predictable, implying that for questions that are highly similar, ChatGPT will
    produce correspondingly similar responses. Next, we aim to verify the presence
    of genetic inheritance in GPT-generated text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a piece of text $\mathcal{T}$, such that:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bar{\mathbf{q}}=\arg\max_{\mathbf{q}}{P(\mathbf{q}&#124;\mathbf{t})},$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $P(\mathbf{q}|\mathbf{t})$.
  prefs: []
  type: TYPE_NORMAL
- en: We notice that ChatGPT performs exceptionally well in the QG task. Specifically,
    we obtain human-written or ChatGPT-generated answers $\mathcal{T}^{H/C}$ in the
    dataset, we observed a significant level of similarity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: We use prompts to obtain questions and answers from ChatGPT. <TEXT>
    represents the text to be detected, and <QUESTION> is the summary of the text
    to be detected by ChatGPT, that is, the output of calling ChatGPT in the first
    step. $len$ is the length of the text to be detected. The prompts are adopted
    from [[1](#bib.bib1)]'
  prefs: []
  type: TYPE_NORMAL
- en: '| Task | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| QG | I want you to play the role of the questioner. I will type an answer
    in English, and you will ask me a question based on the answer in the same language.
    Don’t write any explanations or other text, just give me the question. <TEXT>
    |'
  prefs: []
  type: TYPE_TB
- en: '| Response | <QUESTION> Answer in $len$ words or less. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Examples that illustrate the similarity between the original text
    and the re-answered text. H stands for human and C stands for ChatGPT. It is evident
    that the machine text and its re-answer text share a greater degree of similarity.
    We have shaded identical portions of the text in a faint shade of red or green.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Question | Please explain what is "Spatial index"? |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Original text (H) | A \markoverwith \ULonspatial index is a general-purpose
    \markoverwith \ULondatabase (usually a relational database) that has been enhanced
    to include \markoverwith \ULonspatial data that represents objects defined in
    a geometric space, along with tools for querying … | Original text (C) | A \markoverwith \ULonspatial
    index is a \markoverwith \ULondata structure that is used to \markoverwith \ULonefficiently
    \markoverwith \ULonstore and \markoverwith \ULonquery data that \markoverwith \ULonrepresents
    \markoverwith \ULonobjects defined in a \markoverwith \ULongeometric \markoverwith \ULonspace.
    It is \markoverwith \ULondesigned to support \markoverwith \ULonspatial queries,
    which are queries … |'
  prefs: []
  type: TYPE_TB
- en: '| Generated question (H) | What is a spatial database and what types of objects
    can it represent? | Generated question (C) | What is a spatial index and how is
    it used to efficiently store and query data that represents objects defined in
    a geometric space? |'
  prefs: []
  type: TYPE_TB
- en: '| Re-answered text (H) | A \markoverwith \ULonspatial database is a \markoverwith \ULondatabase
    that is optimized to store and manage \markoverwith \ULonspatial data, which is
    data that has a geographic or spatial component. It is designed to handle \markoverwith \ULondata
    that is related to physical locations on the earth’s surface … | Re-answered text
    (C) | A \markoverwith \ULonspatial index is a \markoverwith \ULondata structure
    that is used to \markoverwith \ULonefficiently \markoverwith \ULonstore and \markoverwith \ULonquery
    data that \markoverwith \ULonrepresents \markoverwith \ULonobjects defined in
    a \markoverwith \ULongeometric \markoverwith \ULonspace. It is a type of index
    that is \markoverwith \ULondesigned to handle \markoverwith \ULonspatial data,
    … |'
  prefs: []
  type: TYPE_TB
- en: 'Next, we re-enter ChatGPT-generated questions $\mathcal{Q}^{\prime H/C}$ in
    Table [3.2](#S3.SS2 "3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance").'
  prefs: []
  type: TYPE_NORMAL
- en: Upon analysis, we observed that the re-answered text corresponding to machine-generated
    text exhibits a higher level of similarity to the original machine text in terms
    of structure and vocabulary, with more identical paragraphs. In contrast, the
    similarity between the re-answered text and the original human text is lower.
    This intuitive observation suggests that the re-answered text derived from the
    question generation-answering process demonstrates a relatively high similarity
    to the original machine-generated text, while the similarity to the original human
    text is comparatively low.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, Hypothesis [3.1](#S3.Thmtheorem1 "Hypothesis 3.1 (GPT Genetic Inheritance.)
    ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text
    Detection with GPT Genetic Inheritance") can be further expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis 3.2 (GPT Paternity Test)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let $\mathcal{T}=\{T_{1},T_{2},...\}$ tends to result in a lower similarity
    value.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 GPT Paternity Test
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Paternity testing involves utilizing DNA profiles to determine whether an individual
    is the biological parent of another individual. This process becomes particularly
    crucial when the rights and responsibilities of a parent are in question and there
    is uncertainty regarding the paternity of a child. In this paper, we propose the
    GPT Paternity Test (GPT-Pat), aiming to leverage the genetic inheritance of GPT
    as previously discussed to address the fundamental question: "Who is the author
    of a specific piece of text? Is it a human or a machine?" The GPT-Pat framework,
    outlined in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"), can be divided into
    three main components based on the learning pipeline: (1) data creation, (2) similarity
    measurement, and (3) classification.'
  prefs: []
  type: TYPE_NORMAL
- en: Data Creation.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Data creation aims to obtain the re-answered text corresponding to the text
    to be tested according to the process of summarizing and re-answering in Algorithm
    [1](#alg1 "Algorithm 1 ‣ Data Creation. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic
    Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with
    GPT Genetic Inheritance").'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 Data Creation
  prefs: []
  type: TYPE_NORMAL
- en: 0:  $text\ \mathcal{T}$
  prefs: []
  type: TYPE_NORMAL
- en: Similarity Measurement.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In our preliminary experiments, we observed that the re-answered text generated
    by ChatGPT was more similar to the original answer of the same question compared
    to the human-written answer. Here, we consider calculating the similarity at the
    high-dimensional feature level to better capture the similarity of sentences.
  prefs: []
  type: TYPE_NORMAL
- en: To address this, we employed a Siamese network structure to measure the similarity
    between texts. We selected a pre-trained language model as the backbone network
    to convert texts into semantic embeddings. A Siamese network is an artificial
    neural network that simultaneously processes two different input tensors using
    the same weights, producing comparable output tensors.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our Siamese network, the original text and the re-answered text are used
    as inputs for the two branches of the network. The output consists of two corresponding
    semantic embeddings. Based on these embeddings, we calculate the cosine similarity
    value, which can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{e}(\mathcal{T})$ obtained through the Siamese network.
  prefs: []
  type: TYPE_NORMAL
- en: Classification.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Both the embeddings and the cosine similarity value are fed into a classifier
    denoted as $\phi$ being machine-generated text can be computed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $pre(\mathcal{T})=\phi(\mathbf{e}(\mathcal{T}),\mathbf{e}(\mathcal{T}^{\prime}),\sigma(\mathcal{T},\mathcal{T^{\prime}})).$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: Please note that in addition to feeding the calculated similarity into the classifier,
    we have also included the semantic embeddings. This decision is based on the implication
    that the absolute value of similarity between a text and its corresponding re-answered
    text may vary across topics. By incorporating high-dimensional features represented
    by semantic embeddings, we can enhance the adaptability of the classifiers to
    handle a wide range of topics effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our loss function denoted as $\mathcal{L}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}=-y\log(pre)+(1-y)\log(1-pre).$ |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: With the well-trained Siamese network and the classifier, users can perform
    the paternity test on any piece of text to identify whether it is a machine-generated
    text.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we first introduce the datasets and evaluation metrics that
    we use in Sec. [4.1](#S4.SS1 "4.1 Datasets and Evaluation ‣ 4 Experiment ‣ Classification.
    ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity
    Test: GPT Generated Text Detection with GPT Genetic Inheritance") and details
    of our experiments in Sec. [4.2](#S4.SS2 "4.2 Implementation Details. ‣ 4 Experiment
    ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method
    ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance").
    Then we validate the effectiveness of our proposed GPT-Pat in Sec. [4.3](#S4.SS3
    "4.3 Performance ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2
    GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection
    with GPT Genetic Inheritance"), which is followed by an ablation study in Sec.
    [4.4](#S4.SS4 "4.4 Ablation Studies ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT
    Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"). Finally, in Sec.
    [4.5](#S4.SS5 "4.5 Adaptive Attacks ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT
    Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"), some attacks are
    conducted to evaluate the robustness of GPT-Pat.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Datasets and Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this paper, we leverage 5 datasets, one for training and testing, and the
    other four for evaluating the generalization ability of various methods.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HC3 [[12](#bib.bib12)]. The HC3 dataset consists of questions and their corresponding
    human/ChatGPT answers. Most of the human-written data come from the publicly available
    Question-Answering (QA) datasets, others are collected from Wikipedia²²2[https://www.wikipedia.org/](https://www.wikipedia.org/)
    as the human experts’ answers to questions such as "Please explain what is <concept>?"
    ChatGPT answers are collected by inputting the questions into ChatGPT.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wiki. We selected some entries from Wikipedia that do not overlap with the data
    in HC3 to evaluate the performance of different detection methods on data similar
    to the training dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CCNews [[13](#bib.bib13)]. We selected some data from CCNews dataset to construct
    human/ChatGPT news pairs. ChatGPT news is generated according to the prompt "Heading
    <title> and beginning with <desc>, follow up a press release", where <title> comes
    from the original dataset, and <desc> is intercepted from the first 20% of human
    text.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CovidCM [[21](#bib.bib21)]. We picked the community split from CovidQA dataset,
    which is a collection of COVID-19 Q&A pairs from 15 English news websites across
    4 continents. ChatGPT answers are obtained by inputting the questions into ChatGPT.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ACLAbs. We selected some Association for Computational Linguistics (ACL) scientific
    paper data from SUMMAC³³3[https://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html](https://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html).
    For the human-written data, we use the original ABSTRACT data. To generate ChatGPT
    responses, we use the following prompt: "Please write an abstract with the title
    <title> for the research paper," where <title> is obtained from the original dataset.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Both human answers and ChatGPT answers may contain some obvious indicating words
    that may influence the effectiveness of models [[12](#bib.bib12)]. Therefore,
    we conduct data cleaning on all data in the aforementioned datasets, removing
    indicating words corresponding to human-written and machine-generated text. Our
    evaluation metrics include accuracy, precision and F1-score. The machine-generated
    texts are used as positive samples, and the human-written texts are used as negative
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Implementation Details.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To be fairly comparable with other methods, we conduct the following training
    and testing settings. Unless otherwise noted, the settings are the same for all
    experiments. We implemented our proposed GPT-Pat using PyTorch [[25](#bib.bib25)].
    To access ChatGPT, we utilize the OpenAI API and specifically employed the gpt-3.5-turbo  [[23](#bib.bib23)]
    model for making requests, utilizing the prompts listed in Table [1](#S3.T1 "Table
    1 ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated
    Text Detection with GPT Genetic Inheritance") to generate questions and re-answered
    texts. We set the sampling temperature to 0.2, for lower temperature results in
    more focused and deterministic output, as suggested in the official documentation
    [[22](#bib.bib22)]. We create a new conversation with ChatGPT for each query to
    avoid being affected by the chat history. For measuring similarity, we use xlm-roberta-base  [[7](#bib.bib7)]
    as the initial weights for our Siamese network. We set batch size to 32 and employ
    the Adam [[16](#bib.bib16)] optimizer with an initial learning rate of 5e-5\.
    We trian the GPT-Pat model on HC3\. The ratio for splitting the training, validation,
    and test sets is 7:1.5:1.5\. The model was trained for 5000 steps on the training
    set, and the best model was selected based on its performance on the validation
    set.'
  prefs: []
  type: TYPE_NORMAL
- en: For PPL-based method [[12](#bib.bib12)], we use gpt2-medium  [[27](#bib.bib27)]
    model to compute the perplexity and burstiness of texts. We retrain a classification
    threshold for it on the training split of HC3\. DetectGPT is a zero-shot machine-generated
    text detection method based on the white-box assumption, which does not require
    training. To compare its performance, we follow the setting of MGTBench [[14](#bib.bib14)],
    utilizing gpt2-medium and t5-large  [[28](#bib.bib28)] as its base model and mask-filling
    model, respectively. For RoBERTa-based classifier, we use a pre-existing Hello-SimpleAI/chatgpt-detector-roberta  [[12](#bib.bib12)]
    weights that were well trained on the HC3 dataset.
  prefs: []
  type: TYPE_NORMAL
- en: All experiments are conducted on a workstation equipped with 4 NVIDIA A6000
    GPU cards.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 3: The accuracy, precision and F1-score performance of our detection
    method and others on various datasets. P, D, R, and G stand for PPL[[5](#bib.bib5)]
    classifier, DetectGPT [[20](#bib.bib20)], RoBERTa-based classifer [[12](#bib.bib12)],
    and GPT-Pat, respectively. The length of these five datasets are 8838, 5166, 650
    and 295, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset Accuracy Precision F1-score P D R G P D R G P D R G HC3 0.9344 0.8140
    0.9943 0.9989 0.9519 0.8036 0.9936 0.9984 0.9341 0.8171 0.9944 0.9989 Wiki 0.8547
    0.7155 0.8843 0.9532 0.8721 0.7181 0.8152 0.9348 0.8512 0.7138 0.8958 0.9541 CCNews
    0.7156 0.7650 0.7011 0.9337 0.6825 0.7477 0.6304 0.9670 0.7393 0.7729 0.7648 0.9313
    CovidCM 0.8353 0.7192 0.9676 0.9676 0.8758 0.7286 0.9634 0.9903 0.8260 0.7133
    0.9678 0.9669 ACLAbs 0.7050 0.8859 0.8745 0.8983 0.9692 0.9000 1.0000 1.0000 0.5915
    0.8839 0.8571 0.8872
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons on HC3.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We compare GPT-Pat with other methods on the test split of HC3 dataset and
    show the accuracy, precision and F1-score in Table [3](#S4.T3 "Table 3 ‣ 4.3 Performance
    ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance
    ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic
    Inheritance"). All methods except DetectGPT are trained on HC3, so these results
    can well reflect the detection performance of various detection methods on the
    same type of text. The best performer among the compared methods is the RoBERTa
    classifier, achieving a capability very close to that of our method. As the model-based
    method is trained on a corpus containing pairings of human-written and ChatGPT-generated
    texts, it should learn the subtle differences between human texts and ChatGPT
    texts, resulting in improved performance. It can be observed that our GPT-Pat
    outperforms the RoBERTa classifier in terms of detection performance across all
    three metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Comparisons on other datasets.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We present the accuracy, precision, and F1-score of the compared methods on
    additional generalization test datasets in Table [3](#S4.T3 "Table 3 ‣ 4.3 Performance
    ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance
    ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic
    Inheritance"). Our method demonstrates significantly superior performance compared
    to other methods in these experiments. For instance, GPT-Pat achieves F1-scores
    of 0.9541 and 0.9313 on the Wiki and CCNews datasets, respectively, whereas RoBERTa
    only achieves F1-scores of 0.8958 and 0.7648\. On all the data of these four general
    test data sets, the average accuracy of GPT-Pat is as high as 0.9457, which is
    12.34% higher than the average accuracy of 0.8223 of the second-ranked RoBERTa.
    These results indicate that GPT-Pat is more suitable for practical applications
    where the source of the text to be detected is unknown and the topics are diverse.'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, we observe that our method exhibits a more pronounced advantage
    when using precision as the evaluation metric. For example, GPT-Pat achieves precise
    detection with a precision rate of 0.9670 on the CCNews dataset, whereas other
    methods can only achieve precision rates of no more than 0.7477\. In other words,
    our method is less prone to misclassify human-written text as machine-generated
    text, a common issue in other methods. This is a significant advantage as misclassification
    can severely undermine the credibility of the detector in practical scenarios.
    If too many human-written texts are flagged as machine-generated texts, it can
    result in a decline in user trust towards machine-generated text detectors. Users
    may begin disregarding alerts, even if some of them are genuine, due to becoming
    accustomed to receiving false alerts.
  prefs: []
  type: TYPE_NORMAL
- en: This advantage can be attributed to the significant variations in writing styles
    among different human authors. It becomes challenging for human-written texts
    in other datasets to fully align with the features learned by the detector during
    training. GPT-Pat, on the other hand, learns the similarity between the text to
    be detected and its corresponding re-answered text. As long as the text does not
    exhibit the heritability of machine-generated text, it can be correctly classified
    as human-written text.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/efb0157556838e736d1fe439a47eb763.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Jaccard similarity between texts
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/133e4a44560501959102220ac463bd4a.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Cosine similarity between embeddings
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: Distributions of different similarity measurement on both human and
    ChatGPT text.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Ablation Studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We conduct ablation studies that investigate whether the Siamese network is
    effective and how to choose the backbone network.
  prefs: []
  type: TYPE_NORMAL
- en: Effect of Architecture.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We compared four structures for similarity calculation and classification in
    this study. Firstly, we use the Traditional method to compute the Jaccard Similarity
    between the text and its re-answered text and choose an optimal classification
    Threshold (TST). Secondly, we employ a Siamese network to generate embeddings
    for cosine Similarity calculation and Threshold classification (short for SST).
    Thirdly, we utilized a Fully Connected layer to classify the embeddings computed
    by the Siamese network (SFC). Lastly, we combined the Similarity measure and the
    embeddings and applied a Fully connected layer for classification (SSF). We present
    in Figure [2](#S4.F2 "Figure 2 ‣ Comparisons on other datasets. ‣ 4.3 Performance
    ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance
    ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic
    Inheritance") the distribution of Jaccard similarity computed by traditional method
    in TST and cosine similarity between the semantic embeddings of human-written
    or machine-generated texts and their corresponding re-answered texts, as computed
    by the trained Siamese network. It can be observed that there is a more significant
    difference in the cosine similarity distribution of embeddings than Jaccard similarity
    computed between texts, which allows for more clear distinction between the majority
    of human and machine texts. Moreover, considering the the high-dimensional semantic
    information of the text when measuring the similarity, the detection method can
    have a better adaptive ability. As shown in Table [4](#S4.T4 "Table 4 ‣ Effect
    of Architecture. ‣ 4.4 Ablation Studies ‣ 4 Experiment ‣ Classification. ‣ 3.3
    GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"), the structure that
    classifies both embeddings and similarity with a fully connected layer performed
    the best, which is what we selected as the structure for our GPT-Pat.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Accuracy of different classifier architectures on various datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Architecture |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| TST | SST | SFC | SSF |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| HC3 | 0.7977 | 0.9873 | 0.9987 | 0.9989 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Wiki | 0.7669 | 0.8697 | 0.9237 | 0.9532 |'
  prefs: []
  type: TYPE_TB
- en: '| CCNews | 0.6916 | 0.7880 | 0.9351 | 0.9337 |'
  prefs: []
  type: TYPE_TB
- en: '| CovidCM | 0.8000 | 0.9538 | 0.9584 | 0.9676 |'
  prefs: []
  type: TYPE_TB
- en: '| ACLAbs | 0.6542 | 0.9527 | 0.9322 | 0.8983 |'
  prefs: []
  type: TYPE_TB
- en: 4.5 Adaptive Attacks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To better understand of how GPT-Pat performs in real-world scenarios, we evaluate
    our detection method using two common text modification methods, namely Machine
    Re-translation and Partial Text Polishing (hybrid human-machine). Machine re-translation
    is a process where a piece of text is translated from one language to another
    and then back to the original language using machine translation. This process
    can sometimes introduce subtle changes and errors in the text, which can be challenging
    for a detection model to handle. In partial text polishing experiment, we use
    ChatGPT to partially polish the human-written texts, and for ChatGPT-generated
    text, we adopt a watermarking algorithm [[32](#bib.bib32)] which synonymously
    replaces words in sentences with a probability to simulate partial modification
    of human. This can be even more challenging for a detection model, as the text
    will be a mix of human-written and machine-generated content. We present the accuracy
    under these attacks of our GPT-Pat with other compared methods in Table [5](#S4.T5
    "Table 5 ‣ 4.5 Adaptive Attacks ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity
    Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated
    Text Detection with GPT Genetic Inheritance"). It can be seen that under these
    two attacks, the accuracy degradation of GPT-Pat is less than that of the RoBERTa
    classifier, indicating that our method is more robust in the actual environment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: The accuracy performance under adaptive attacks of GPT-Pat and RoBERTa-based
    classifier [[12](#bib.bib12)]. In Re-translation experiment, English texts are
    translated into Chinese and then translated back to English using Baidu Translation
    [[2](#bib.bib2)] and DeepL [[3](#bib.bib3)] API. In polishing experiments, only
    the first sentence of each text was modified.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Attack Method | Detection Method |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-Pat | RoBERTa |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Re-translation (Baidu) | before | 1.0 | 0.9962 |'
  prefs: []
  type: TYPE_TB
- en: '| after | 0.8520 | 0.6928 |'
  prefs: []
  type: TYPE_TB
- en: '| drop rate | 0.1480 | 0.3034 |'
  prefs: []
  type: TYPE_TB
- en: '| Re-translation (DeepL) | before | 1.0 | 0.9979 |'
  prefs: []
  type: TYPE_TB
- en: '| after | 0.8472 | 0.7320 |'
  prefs: []
  type: TYPE_TB
- en: '| drop rate | 0.1528 | 0.2659 |'
  prefs: []
  type: TYPE_TB
- en: '| Polishing | before | 0.9986 | 0.9959 |'
  prefs: []
  type: TYPE_TB
- en: '| after | 0.9879 | 0.9600 |'
  prefs: []
  type: TYPE_TB
- en: '| drop rate | 0.0107 | 0.0359 |'
  prefs: []
  type: TYPE_TB
- en: 5 Conclusion and Limitation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we propose a method for detecting machine-generated text using
    genetic inheritance of large language models (LLMs) such as GPT, which we refer
    to as GPT Paternity Test (GPT-Pat). GPT-Pat is based on a key hypothesis that
    LLMs tend to provide similar answers for similar questions. We designed a question
    generation and response process for ChatGPT, where the model generates a re-answered
    text corresponding to the input text. By comparing the similarity between the
    input text and the generated re-answered text, we can perform text detection,
    similar to the process of human paternity testing using DNA. Through evaluation
    on the HC3 and other generalized testing datasets, GPT-Pat demonstrates state-of-the-art
    detection performance and excels in robustness. One limitation of our method is
    that it requires querying ChatGPT during both training and testing, which results
    in perceptible time delays for users and incurs certain costs with each query.
    How to efficiently generate questions and re-answers corresponding to texts to
    be detected is to be studied in the future.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Awesome ChatGPT Prompts. [https://huggingface.co/datasets/fka/awesome-chatgpt-prompts](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Baidu Generic Text Translation API. [https://fanyi-api.baidu.com/](https://fanyi-api.baidu.com/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] DeepL API. [https://www.deepl.com/en/docs-api/](https://www.deepl.com/en/docs-api/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
    Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
    et al. Language models are few-shot learners. Advances in neural information processing
    systems, 33:1877–1901, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Stanley F Chen, Douglas Beeferman, and Roni Rosenfeld. Evaluation metrics
    for language models. 1998.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav
    Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian
    Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint
    arXiv:2204.02311, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
    Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin
    Stoyanov. Unsupervised cross-lingual representation learning at scale. CoRR, abs/1911.02116,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Xinya Du, Junru Shao, and Claire Cardie. Learning to ask: Neural question
    generation for reading comprehension. arXiv preprint arXiv:1705.00106, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Nan Duan, Duyu Tang, Peng Chen, and Ming Zhou. Question generation for
    question answering. In Proceedings of the 2017 conference on empirical methods
    in natural language processing, pages 866–874, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Sebastian Gehrmann, Hendrik Strobelt, and Alexander M Rush. Gltr: Statistical
    detection and visualization of generated text. In Annual Meeting of the Association
    for Computational Linguistics. Association for Computational Linguistics (ACL),
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Josh A Goldstein, Girish Sastry, Micah Musser, Renee DiResta, Matthew
    Gentzel, and Katerina Sedova. Generative language models and automated influence
    operations: Emerging threats and potential mitigations. arXiv preprint arXiv:2301.04246,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding,
    Jianwei Yue, and Yupeng Wu. How close is chatgpt to human experts? comparison
    corpus, evaluation, and detection. arXiv preprint arXiv:2301.07597, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Felix Hamborg, Norman Meuschke, Corinna Breitinger, and Bela Gipp. news-please:
    A generic news crawler and extractor. In Proceedings of the 15th International
    Symposium of Information Science, pages 218–223, March 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Xinlei He, Xinyue Shen, Zeyuan Chen, Michael Backes, and Yang Zhang. Mgtbench:
    Benchmarking machine-generated text detection. arXiv preprint arXiv:2303.14822,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Last Week in AI. Last week in ai #205: How ai is going modular, growing
    legal cases against generative ai, tools to detect ai-generated text, and more,
    2023. Retrieved from [https://lastweekin.ai/p/205](https://lastweekin.ai/p/205).
    Accessed on March 1, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization.
    arXiv preprint arXiv:1412.6980, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Ghader Kurdi, Jared Leo, Bijan Parsia, Uli Sattler, and Salam Al-Emari.
    A systematic review of automatic question generation for educational purposes.
    International Journal of Artificial Intelligence in Education, 30:121–204, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Gary Marcus. Inside the heart of chatgpt’s darkness., 2023. Retrieved
    from [https://garymarcus.substack.com/p/inside-the-heart-of-chatgpts-darkness](https://garymarcus.substack.com/p/inside-the-heart-of-chatgpts-darkness).
    Accessed on February 25, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Alex Mitchell. Professor catches student cheating with chatgptl: ’i feel
    abject terror’, 2022. Retrieved from [https://nypost.com/2022/12/26/students-using-chatgpt-to-cheat-professor-warns/](https://nypost.com/2022/12/26/students-using-chatgpt-to-cheat-professor-warns/).
    Accessed on February 17, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning,
    and Chelsea Finn. Detectgpt: Zero-shot machine-generated text detection using
    probability curvature. arXiv preprint arXiv:2301.11305, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Timo Möller, Anthony Reina, Raghavan Jayakumar, and Malte Pietsch. Covid-qa:
    A question answering dataset for covid-19. In Proceedings of the 1st Workshop
    on NLP for COVID-19 at ACL 2020, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] OpenAI. Document of api reference, 2023. Retrieved from [https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature).
    Accessed on April 1, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] OpenAI. Document of models, 2023. Retrieved from [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5).
    Accessed on April 1, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright,
    Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
    Training language models to follow instructions with human feedback. Advances
    in Neural Information Processing Systems, 35:27730–27744, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
    Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch:
    An imperative style, high-performance deep learning library. Advances in neural
    information processing systems, 32, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Mary Louise Kelly Patrick Wood. ’everybody is cheating’: Why this teacher
    has adopted an open chatgpt policy, 2023. Retrieved from [https://www.npr.org/2023/01/26/1151499213/chatgpt-ai-education-cheating-classroom-wharton-school](https://www.npr.org/2023/01/26/1151499213/chatgpt-ai-education-cheating-classroom-wharton-school).
    Accessed on January 26, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
    Sutskever, et al. Language models are unsupervised multitask learners. OpenAI
    blog, 1(8):9, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
    Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of
    transfer learning with a unified text-to-text transformer. Journal of Machine
    Learning Research, 21(140):1–67, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Alejo Jose G Sison, Marco Tulio Daza, Roberto Gozalo-Brizuela, and Eduardo C
    Garrido-Merchán. Chatgpt: More than a weapon of mass deception, ethical challenges
    and responses from the human-centered artificial intelligence (hcai) perspective.
    arXiv preprint arXiv:2304.11215, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss,
    Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, et al. Release
    strategies and the social impacts of language models. arXiv preprint arXiv:1908.09203,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
    Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
    Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint
    arXiv:2302.13971, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Xi Yang, Jie Zhang, Kejiang Chen, Weiming Zhang, Zehua Ma, Feng Wang,
    and Nenghai Yu. Tracing text provenance via context-aware lexical substitution.
    In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages
    11613–11621, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
