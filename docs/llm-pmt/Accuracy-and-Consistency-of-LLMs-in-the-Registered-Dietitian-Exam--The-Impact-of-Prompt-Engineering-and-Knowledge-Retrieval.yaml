- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:41:11'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact
    of Prompt Engineering and Knowledge Retrieval'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.02964](https://ar5iv.labs.arxiv.org/html/2408.02964)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Iman Azimi^(1,*), Mohan Qi¹, Li Wang², Amir M. Rahmani³, and Youlin Li¹
  prefs: []
  type: TYPE_NORMAL
- en: ¹Department of Engineering, iHealth Labs
  prefs: []
  type: TYPE_NORMAL
- en: ²Department of Clinical Research, iHealth Labs
  prefs: []
  type: TYPE_NORMAL
- en: ³School of Nursing and Department of Computer Science, University of California,
    Irvine
  prefs: []
  type: TYPE_NORMAL
- en: ^*Corresponding author, iman.azimi@ihealthlabs.com
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Large language models (LLMs) are fundamentally transforming human-facing applications
    in the health and well-being domains: boosting patient engagement, accelerating
    clinical decision-making, and facilitating medical education. Although state-of-the-art
    LLMs have shown superior performance in several conversational applications, evaluations
    within nutrition and diet applications are still insufficient. In this paper,
    we propose to employ the Registered Dietitian (RD) exam to conduct a standard
    and comprehensive evaluation of state-of-the-art LLMs, GPT-4o, Claude 3.5 Sonnet,
    and Gemini 1.5 Pro, assessing both accuracy and consistency in nutrition queries.
    Our evaluation includes 1050 RD exam questions encompassing several nutrition
    topics and proficiency levels. In addition, for the first time, we examine the
    impact of Zero-Shot (ZS), Chain of Thought (CoT), Chain of Thought with Self Consistency
    (CoT-SC), and Retrieval Augmented Prompting (RAP) on both accuracy and consistency
    of the responses. Our findings revealed that while these LLMs obtained acceptable
    overall performance, their results varied considerably with different prompts
    and question domains. GPT-4o with CoT-SC prompting outperformed the other approaches,
    whereas Gemini 1.5 Pro with ZS recorded the highest consistency. For GPT-4o and
    Claude 3.5, CoT improved the accuracy, and CoT-SC improved both accuracy and consistency.
    RAP was particularly effective for GPT-4o to answer Expert level questions. Consequently,
    choosing the appropriate LLM and prompting technique, tailored to the proficiency
    level and specific domain, can mitigate errors and potential risks in diet and
    nutrition chatbots.'
  prefs: []
  type: TYPE_NORMAL
- en: '^†^†journal:  \newcites'
  prefs: []
  type: TYPE_NORMAL
- en: a
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is growing interest in leveraging conversational models, commonly known
    as chatbots, in healthcare, particularly in the areas of diet and nutrition [[1](#bib.bib1),
    [2](#bib.bib2), [3](#bib.bib3)]. The rise of large language models (LLMs) is significantly
    transforming human-machine interactions in this context, creating new opportunities
    for nutrition management applications and lifestyle enhancement that involve natural
    language understanding and generation [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6)].
    These chatbots can serve as assistants to health providers (e.g., dietitian or
    nurses) or as ubiquitous companions for patients, providing preventive care, personalized
    meal planning, and chronic disease management [[7](#bib.bib7)].
  prefs: []
  type: TYPE_NORMAL
- en: Since the release of ChatGPT [[8](#bib.bib8)] in November 2022, numerous nutrition
    management studies have developed or employed LLM-based chatbots to target different
    health conditions, such as type 2 diabetes, obesity, liver diseases, kidney diseases,
    and cardiovascular diseases, to mention a few [[1](#bib.bib1), [9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11), [7](#bib.bib7), [12](#bib.bib12), [13](#bib.bib13),
    [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]. These studies highlight
    the potential of chatbots interventions to enhance diet and promote lifestyle
    behavior changes.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the life-critical nature of these applications, they must provide high
    quality attributes, such as accuracy, consistency, safety, and fairness, before
    being deployed in real-world settings for end-users [[17](#bib.bib17), [18](#bib.bib18),
    [19](#bib.bib19)]. Recent studies have evaluated the LLM-based chatbots within
    nutritional and dietary contexts. For example, Sun et al. [[20](#bib.bib20)] and
    Barlas et al. [[21](#bib.bib21)] assessed the performance of ChatGPT in providing
    nutritional management support for diabetic patients. Other investigations focused
    on chatbots’ reliability in delivering accurate calorie and macronutrient information
    [[22](#bib.bib22), [23](#bib.bib23)]. For non-communicable diseases, the accuracy
    of dietary advice generated by ChatGPT’s were assessed [[24](#bib.bib24), [10](#bib.bib10)].
    Other studies also examined ChatGPT’s ability to address common nutrition-related
    inquiries, highlighting its strength and weakness in offering personalized and
    accurate nutritional information [[25](#bib.bib25), [26](#bib.bib26)]. However,
    the existing evaluation studies on nutrition-related chatbots face three major
    challenges.
  prefs: []
  type: TYPE_NORMAL
- en: First, prior research on the LLMs application in nutrition has relied solely
    on ad-hoc or subjective evaluations. In these studies, domain experts designed
    a set of questions focused on specific diseases or nutrition topics. Subsequently,
    human evaluators were instructed to grade the responses in terms of accuracy,
    comprehensiveness, or attractiveness [[27](#bib.bib27), [21](#bib.bib21), [20](#bib.bib20)].
    Human-in-the-loop evaluation is widely recognized as a popular and well-established
    strategy for assessing chatbots in the literature [[18](#bib.bib18), [19](#bib.bib19)].
    However, these evaluations are not comprehensive regarding nutrition problems
    and are prone to human errors or biases, as they depend on the opinion of an individual
    expert, especially when no standard guidelines are followed in the evaluation
    process. Additionally, they are time-consuming and costly. This limitation can
    be observed in the current nutrition chatbots evaluation, as their assessments
    are restricted to a few hundred interactions (i.e., prompts) at most.
  prefs: []
  type: TYPE_NORMAL
- en: Second, most of the nutrition and diet studies have focused only on ChatGPT-3.5
    or ChatGPT-4\. The landscape of LLMs is rapidly evolving. New models and techniques
    are being released frequently, within weeks or months [[28](#bib.bib28)]. This
    rapid advancement requires the evaluation of a wide range of models to ensure
    the best possible solutions for diet and nutrition management applications. In
    addition, existing research on nutrition evaluation has ignored the impact of
    prompt engineering techniques. They have been limited to zero-shot prompting methods
    with either no instructions or fixed instructions. Prompt engineering is an important
    technique for enhancing the capabilities, adaptability, and applicability of LLMs
    [[29](#bib.bib29), [30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32)].
  prefs: []
  type: TYPE_NORMAL
- en: Third, previous work merely focused on the overall accuracy of LLMs responses.
    Their findings indicated that the models were generally accurate, but they still
    had errors [[10](#bib.bib10), [27](#bib.bib27), [21](#bib.bib21), [24](#bib.bib24)].
    These studies did not examine the errors, along with the strategies to enhance
    the LLMs’ responses. Wang et al. [[33](#bib.bib33)] highlights this issue in the
    context of clinical medicine. Moreover, the non-deterministic behavior of LLMs
    was ignored [[34](#bib.bib34)]. Within the healthcare and medical sectors, there
    is a strong demand for deterministic outcomes, ensuring that identical inputs
    generate identical outputs. The consistency and reliability of LLMs in answering
    nutrition-related questions must be evaluated to determine if their performance
    varies with identical or different prompts. In the nutrition context, to the best
    of our knowledge, only one study [[22](#bib.bib22)] has explored the consistency
    of ChatGPT-3.5 and ChatGPT-4 responses, using a zero-shot prompt for 222 food
    items across five repeated measurements.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/815ad9c69f7fded1e357e922df97e44a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Percentage Scores of the approaches on the RD exam. GPT-4o, Claude
    3.5 Sonnet, and Gemini 1.5 Pro are indicated with blue, orange, and green markers,
    respectively. The Zero Shot (ZS), Chain of Thought (CoT), Chain of Thought with
    Self Consistency (CoT-SC), and Retrieval Augmented Prompting (RAP) techniques
    are indicated with circle, square, triangle, and star markers, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this paper, we thoroughly evaluate the accuracy and consistency of GPT-4o
    [[35](#bib.bib35)], Claude 3.5 Sonnet [[36](#bib.bib36)], and Gemini 1.5 Pro [[37](#bib.bib37)]
    in addressing nutrition-related inquiries. To achieve this, we leverage the Registered
    Dietitian (RD) exam [[38](#bib.bib38)] for the first time, as a standard certification
    examination that serves to assess whether dietitians meet the qualifications required
    to practice in the dietetics and nutrition field. Our evaluation includes 1050
    multiple-choice questions with different proficiency levels, covering four nutrition
    domains: i.e., principles of dietetics, nutrition care, food service systems,
    and food and nutrition management. To investigate the impact of prompts, the questions
    are presented to the LLMs using four different prompting techniques: 1) Zero Shot
    prompting (ZS), 2) Chain of Thought (CoT), 3) Chain of Thought with Self Consistency
    (CoT-SC), and 4) Retrieval Augmented Prompting (RAP) enabled by external nutrition
    knowledge. We then compare the responses with the ground truth answers, enabling
    an objective assessment of the model’s performance. To examine the consistency
    of the responses, we perform repeated measurements by asking each model the same
    set of questions multiple times using each prompting technique. The responses
    for each technique and model are compared within and across groups.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: The percentage scores (mean and standard deviation) of the LLMs’ responses
    on the RD exam questions.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | Prompt | GPT-4o | Claude 3.5 S. | Gemini 1.5 P. |'
  prefs: []
  type: TYPE_TB
- en: '| RD Exam | Zero Shot | 91.92% (0.28) | 90.04% (0.10) | 90.78% (0.11) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Chain of Thought | 94.32% (0.18) | 92.32% (0.27) | 88.82% (0.63) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Chain of Thought w. Self Consistency | 94.48% (0.22) | 92.67% (0.16) |
    90.02% (0.39) |'
  prefs: []
  type: TYPE_TB
- en: '|  | Retrieval Augmented Prompting | 92.78% (0.27) | 89.22% (0.18) | 89.66%
    (0.11) |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: The performance of the LLMs on the MMLU [[39](#bib.bib39)], GPQA [[40](#bib.bib40)],
    and DROP [[41](#bib.bib41)] benchmarks, collected from [[36](#bib.bib36), [35](#bib.bib35),
    [42](#bib.bib42)].'
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | Prompt | GPT-4o | Claude 3.5 S. | Gemini 1.5 P. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU (Undergraduate Level Knowledge) | Zero Shot | 88.70% | 88.30% | - |'
  prefs: []
  type: TYPE_TB
- en: '|  | Five Shot | - | 88.70% | 85.90% |'
  prefs: []
  type: TYPE_TB
- en: '| GPQA (Graduate Level Reasoning) | Chain of Thought | 53.60% | 59.40% | 46.20%
    |'
  prefs: []
  type: TYPE_TB
- en: '| DROP (Reasoning) | Three Shot | 83.40% | 87.10% | 74.90% |'
  prefs: []
  type: TYPE_TB
- en: Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Overall Performance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The results show that all the approaches obtained a score of over 88% in selecting
    the correct option for the 1050 RD exam questions, as indicated in Figure [1](#Sx1.F1
    "Figure 1 ‣ Introduction ‣ Accuracy and Consistency of LLMs in the Registered
    Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval") and
    Table [1](#Sx1.F1 "Figure 1 ‣ Introduction ‣ Accuracy and Consistency of LLMs
    in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge
    Retrieval"). Overall, GPT-4o achieved the highest score (the blue markers in the
    figure) ranging between 91% and 95%, with the best score for CoT-SC. On the other
    hand, Gemini 1.5 Pro (the green markers) had the lowest scores.'
  prefs: []
  type: TYPE_NORMAL
- en: In both GPT-4o and Claude 3.5 Sonnet, the CoT and CoT-SC prompting techniques
    resulted in similar percentage scores, which were approximately 2.5 percent higher
    than the ZS prompting’s scores. However, the combination of Gemini with CoT or
    CoT-SC did not improve the accuracy but produced wider percentage scores across
    repeated measurements, with ranges of 1.9 and 1.2\. Moreover, RAP obtained better
    scores, compared to ZS, in GPT-4o but slightly decreased the performance of Claude
    and Gemini models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to our findings, an overview of the models’ performance on existing
    knowledge and reasoning benchmarks are indicated in Table [2](#Sx1.T2 "Table 2
    ‣ Introduction ‣ Accuracy and Consistency of LLMs in the Registered Dietitian
    Exam: The Impact of Prompt Engineering and Knowledge Retrieval"). The performance
    scores of these three benchmarks were collected from [[36](#bib.bib36), [35](#bib.bib35),
    [42](#bib.bib42)]. The GPQA benchmark [[40](#bib.bib40)] includes 448 multiple-choice
    questions on biology, physics, and chemistry. The MMLU benchmark [[39](#bib.bib39)]
    contains multiple-choice questions from 57 topics, such as elementary mathematics,
    US history, computer science, and law; and the DROP benchmark [[41](#bib.bib41)]
    consists of 96,567 questions focusing on discrete reasoning over the content of
    paragraphs, including addition, counting, and sorting. Claude 3.5 Sonnet outperformed
    the other LLMs in all scenarios, except for MMLU using the ZS prompting. These
    findings do not fully align with our findings presented in Table [1](#Sx1.T1 "Table
    1 ‣ Introduction ‣ Accuracy and Consistency of LLMs in the Registered Dietitian
    Exam: The Impact of Prompt Engineering and Knowledge Retrieval").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e00db67d15c00e135ce981282839bb51.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Average errors per approach by proficiency level. The exam includes 149
    Easy, 352 Moderate, 392 Difficult, and 157 Expert levels questions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a156849f674d58cac25c0035a2812e5b.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Average errors per approach by domain. The exam includes 237 principles
    of dietetics, 392 nutrition care for individuals and groups, 185 food service
    systems, and 236 management of food and nutrition programs and services questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: The LLMs’ inaccurate responses based on the RD exam questions’ proficiency
    levels and domains.'
  prefs: []
  type: TYPE_NORMAL
- en: Subgroup Error Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We categorize the RD exam questions into different subgroups, within which the
    LLMs’ inaccurate responses are assessed. To achieve this, we analyze the errors
    obtained in terms of proficiency levels and four nutrition domains (i.e., topics).
  prefs: []
  type: TYPE_NORMAL
- en: 'Proficiency Levels: The approaches are evaluated based on the questions’ proficiency
    levels, provided by the Academy of Nutrition and Dietetics, eatrightPREP for the
    RDN Exam [[43](#bib.bib43)]. The exam consists of 149 Easy, 352 Moderate, 392
    Difficult, and 149 Expert levels questions. Figure [2(a)](#Sx2.F2.sf1 "In Figure
    2 ‣ Overall Performance ‣ Accuracy ‣ Results ‣ Accuracy and Consistency of LLMs
    in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge
    Retrieval") shows the average errors for each approach.'
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4o obtained the lowest overall average error counts. The model with CoT-SC
    resulted in the fewest errors across the proficiency levels, with the average
    errors of 0.6, 10.6, 22.4, and 24.4 for Easy, Moderate, Difficult, and Expert
    levels questions, respectively. Compared to ZS prompting, CoT and CoT-SC improved
    the model’s performance at all levels, but RAP only enhanced the responses of
    the Difficult and Expert level questions.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the GPT-4o approaches, Claude 3.5 Sonnet performance was enhanced
    by CoT and CoT-SC. Claude 3.5 Sonnet with CoT and CoT-SC achieved similar average
    error rates. Conversely, using Claude 3.5 Sonnet, RAP recorded the highest error
    counts, particularly with 5 more errors (on average) for Expert questions, compared
    to the ZS prompting technique.
  prefs: []
  type: TYPE_NORMAL
- en: Gemini 1.5 Pro had the highest number of errors overall. The ZS prompting recorded
    the lowest average errors with Gemini. Compared to ZS, CoT and CoT-SC improved
    the responses of the Moderate questions but obtained higher average errors for
    the Difficult and Expert level questions. RAP obtained higher error rates for
    Moderate and Difficult questions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4a06ae3a6d46437f5b4b0b5003bb5b35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: The Cohen’s Kappa coefficients measured for each of the 12 pairwise
    comparisons using the RD exam. The dark blue indicates high levels of agreement,
    while the light blue represents lower agreement levels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Domains: The inaccurate responses collected by each approach is evaluated based
    on four domains: D1) Principles of Dietetics, D2) Nutrition Care for Individuals
    and Groups, D3) Food Service System, and D4) Management of Food and Nutrition
    Programs and Service. The exam consists of 237, 392, 185, and 236 questions for
    D1, D2, D3, and D4, respectively. As illustrated in Figure [2(b)](#Sx2.F2.sf2
    "In Figure 2 ‣ Overall Performance ‣ Accuracy ‣ Results ‣ Accuracy and Consistency
    of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and
    Knowledge Retrieval"), the impact of prompt engineering techniques varied across
    the domains for the three LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4o with CoT-SC reduced the average error counts in D3 from 27.4 to 12 and
    in D4 from 28.4 to 18.2, compared to GPT-4o with ZS. CoT and RAP also showed similar
    improvements in error rates although RAP recorded more errors for D2\. Using GPT-4o,
    different prompting techniques resulted in small changes in the error rates observed
    in D1.
  prefs: []
  type: TYPE_NORMAL
- en: Claude 3.5 Sonnet showed that transitioning from ZS prompting to CoT-SC or CoT
    reduced the average errors across the four domains. On the other hand, RAP slightly
    improved D1 and D2 but obtained more errors in D3 and D4.
  prefs: []
  type: TYPE_NORMAL
- en: With Gemini 1.5 Pro, different prompts led to small variations in error counts,
    with changes of fewer than 4 errors on average in D1, D3, and D4\. However, ZS
    prompting obtained the lowest error count in D2, with an average of 26.2 errors.
    Nevertheless, this outcome shows approximately 6 errors higher than the performance
    achieved by GPT-4o. In D2, Gemini and CoT obtained the highest error rates.
  prefs: []
  type: TYPE_NORMAL
- en: Consistency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Inter-rater Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The inter-rater reliability of the responses from the approaches was analyzed
    to investigate their agreement. To achieve this, Cohen’s Kappa coefficient was
    calculated for each pair of approaches to determine if they selected the same
    choices, whether accurate or inaccurate. Our study includes 12 distinct approaches
    (3 LLMs multiplied by 4 prompting techniques), so Cohen’s Kappa was measured for
    each of the 12 pairwise comparisons. Since each approach is repeated five times,
    one set of measurements per approach is randomly selected to assess the inter-rater
    reliability. Figure [3](#Sx2.F3 "Figure 3 ‣ Subgroup Error Analysis ‣ Accuracy
    ‣ Results ‣ Accuracy and Consistency of LLMs in the Registered Dietitian Exam:
    The Impact of Prompt Engineering and Knowledge Retrieval") presents the Cohen’s
    Kappa coefficients, where dark blue indicates high levels of agreement, and light
    blue represents lower agreement levels. Additionally, the detailed statistical
    data are presented in Supplementary Table S.1.'
  prefs: []
  type: TYPE_NORMAL
- en: The approaches based on GPT-4o showed a high degree of agreement, indicated
    by a Cohen’s Kappa coefficient of 0.98 between CoT and CoT-SC and a coefficient
    of 0.93 between RAP and the other three prompting techniques. This confirms that
    altering these prompting techniques did not result in a substantial change in
    the GPT-4o’s behavior. Similarly, Claude 3.5-based approaches indicated comparable
    levels of agreement. In contrast, the Gemini 1.5 Pro’s approaches recorded relatively
    lower Cohen’s Kappa coefficients, despite maintaining high overall agreement.
    The Cohen’s Kappa coefficients of the Gemini-based approaches were from 0.84 to
    0.93\. The agreement level between CoT and CoT-SC was 0.92, and the agreement
    between ZS and RAP was 0.93\. Interestingly, among the prompting techniques, the
    approaches (even with different LLMs) using CoT and CoT-SC obtained higher levels
    of agreement.
  prefs: []
  type: TYPE_NORMAL
- en: Intra-rater Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this study, each approach was repeated five times, resulting in five sets
    of responses. The intra-rater reliability of the responses was evaluated by measuring
    the repeatability of the approaches, determining how consistently they agreed
    with themselves when receiving the same questions. For this purpose, Fleiss Kappa
    was employed to assess the intra-rater agreements. Table [3](#Sx2.T3 "Table 3
    ‣ Intra-rater Analysis ‣ Consistency ‣ Results ‣ Accuracy and Consistency of LLMs
    in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge
    Retrieval") indicates the Fleiss Kappa coefficients, and Supplementary Table S.2
    includes the detailed statistical data.'
  prefs: []
  type: TYPE_NORMAL
- en: Gemini 1.5 Pro combined with the ZS prompting achieved the highest agreement
    among all combinations, whereas the Gemini with CoT produced the lowest agreement.
    The approaches based on Claude 3.5 Sonnet demonstrated the highest overall agreement.
    For the three LLMs, the ZS prompting technique consistently resulted in the highest
    agreement, as indicated by Fleiss’s Kappa coefficients of 0.996, 0.987, and 0.980
    for Gemini 1.5 Pro, Claude 3.5 Sonnet, and GPT-4o, respectively. Similarly, the
    coefficients of the LLMs with RAP were high. The CoT-SC recorded the third highest
    agreement, while the CoT obtained the lowest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: The Fleiss Kappa coefficients of the 12 approaches. Each approach
    was repeated 5 times.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | Fleiss’ Kappa | 95% CI |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-4o | ZS | 0.980 | 0.973 – 0.987 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.969 | 0.960 – 0.977 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT-SC | 0.977 | 0.970 – 0.985 |'
  prefs: []
  type: TYPE_TB
- en: '| RAP | 0.985 | 0.978 – 0.991 |'
  prefs: []
  type: TYPE_TB
- en: '| Claude 3.5 S. | ZS | 0.987 | 0.981 – 0.992 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.975 | 0.967 – 0.983 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT-SC | 0.982 | 0.975 – 0.988 |'
  prefs: []
  type: TYPE_TB
- en: '| RAP | 0.977 | 0.970 – 0.985 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemini 1.5 P. | ZS | 0.996 | 0.993 – 0.999 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.902 | 0.887 – 0.917 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT-SC | 0.938 | 0.926 – 0.951 |'
  prefs: []
  type: TYPE_TB
- en: '| RAP | 0.991 | 0.987 – 0.996 |'
  prefs: []
  type: TYPE_TB
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our findings indicated that all the approaches, combining three LLMs with four
    prompt engineering techniques, successfully passed the RD exam. However, the three
    leading LLMs had different performance levels in terms of the number of inaccurate
    responses and consistency. In addition, the prompting techniques had considerable
    impacts on the results. Such prompting impacts were also explored in other evaluation
    studies, for example, in clinical medicine [[33](#bib.bib33)], mental health [[44](#bib.bib44)]
    and radiology [[45](#bib.bib45)].
  prefs: []
  type: TYPE_NORMAL
- en: 'The combination of GPT-4o with CoT-SC prompting outperformed the other approaches
    in terms of accuracy, while Gemini 1.5 Pro with ZS prompting showed the highest
    consistency. On the other hand, the lowest average percentage score was 89.22%
    for Gemini 1.5 Pro with CoT, which also showed the lowest agreement in repeated
    measurements, with a coefficient of 0.902\. GPT-4o recorded the highest accuracy
    overall (see Table [1](#Sx1.T1 "Table 1 ‣ Introduction ‣ Accuracy and Consistency
    of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and
    Knowledge Retrieval")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This outcome contrasts with previous non-nutrition research, except in MMLU
    [[39](#bib.bib39)] with ZS prompting (see Table [2](#Sx1.T2 "Table 2 ‣ Introduction
    ‣ Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact
    of Prompt Engineering and Knowledge Retrieval")). Claude 3.5 with CoT obtained
    a 59.4% score on GPQA [[40](#bib.bib40)]. However, the three LLMs using CoT on
    the RD exam achieved scores above 90%. This difference might be due to the different
    difficulty levels of the exams. Particularly, 14.9% of the questions in the RD
    Exam are at the Expert level. However, as reported by Rein et al. [[40](#bib.bib40)],
    the GPQA questions are “extremely difficult,” from which PhD students achieved
    a 65% score while non-expert individuals achieved a 34% score. Moreover, DROP
    [[41](#bib.bib41)] demonstrated that Claude 3.5 with Three Shot prompting outperformed
    in reasoning over text. Conversely, our results indicated that GPT-4o performed
    better using the reasoning process of CoT prompting.'
  prefs: []
  type: TYPE_NORMAL
- en: Prior nutrition-focused research indicated that ChatGPT was accurate in most
    nutrition instances, but the chatbot also recorded errors that could potentially
    harm and negatively impact the end-users. Therefore, achieving general accuracy
    is insufficient for practical real-world applications. For example, Sun et al. [[20](#bib.bib20)]
    indicated that ChatGPT-3.5 and ChatGPT-4 passed the Chinese RD exam (included
    200 questions) and the food recommendations were acceptable despite the presence
    of mistakes for specific foods, such as root vegetables and dry beans. Mishra
    et al. [[46](#bib.bib46)] tested ChatGPT in eight medical nutritional therapy
    scenarios and discussed that ChatGPT should be avoided for complex scenarios.
    Similarly, other studies [[24](#bib.bib24), [10](#bib.bib10)] discussed that ChatGPT
    has great potentials for nutritional management focusing on non-communicable diseases,
    but the model might be potentially harmful by providing inaccurate responses,
    particularly in complex situations. Another study [[22](#bib.bib22)] leveraged
    ChatGPT-3.5 and ChatGPT-4 to provide nutritional information for eight menus.
    Their results indicated that responses had no significant differences compared
    to nutritionists’ recommendations in terms of energy, carbohydrate, and fat contents,
    but the difference was statistically significant for protein. The potential of
    ChatGPT to generate dietary advice for patients with allergic to food allergens
    were also investigated [[27](#bib.bib27)]. It was shown that although the model
    was generally accurate, it produced harmful diets. These studies highlight the
    need for further investigation into LLM responses within the context of food and
    nutrition.
  prefs: []
  type: TYPE_NORMAL
- en: Our results confirmed previous findings about the overall accuracy of ChatGPT
    and the instances of inaccurate responses. However, unlike the existing work,
    our study is not merely restricted to ChatGPT or the ZS prompting technique. We
    focused on examining errors across various subcategories and mitigate them by
    employing prompting techniques (reasoning and ensemble) and external knowledge
    retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: 'CoT guided LLMs to perform a reasoning process when answering a question. Our
    findings showed that CoT, compared to ZS prompting, enhanced the accuracy of GPT-4o
    and Claude 3.5 Sonnet but led to diminished consistency. The LLMs with CoT do
    not consistently generate the same reasoning paths, even with identical prompts
    (see Table [3](#Sx2.T3 "Table 3 ‣ Intra-rater Analysis ‣ Consistency ‣ Results
    ‣ Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact
    of Prompt Engineering and Knowledge Retrieval")). This variability indicates randomness
    in the selection of reasoning paths.'
  prefs: []
  type: TYPE_NORMAL
- en: We observed that the reasoning steps of CoT considerably reduced the LLMs’ mistakes
    for the questions with Easy, Moderate, and Difficult proficiency levels, but this
    improvement was less for Expert-level questions, where only a few errors were
    corrected. Additionally, CoT notably improved the questions about D3) food service
    systems, which involved calculations for food cost and portion estimation/forecasting.
    CoT also enhanced the accuracy of D4) food and nutrition management, which included
    theoretical and conceptual questions requiring an understanding of implicitly
    stated relationships. These improvements by CoT are consistent with existing literature,
    indicating CoT enhances LLMs’ performance in arithmetic and commonsense tasks
    by establishing logical connections [[47](#bib.bib47)]. Conversely, the combination
    of Gemini 1.5 Pro with CoT showed different patterns, where both accuracy and
    consistency decreased. Gemini with CoT was unable to select a choice from the
    given multiple-choice options for 20 out of 1050 questions (on average). Although
    the errors on Easy and Moderate levels questions slightly decreased, the errors
    on Difficult and Expert levels questions notably increased.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that while CoT reduced errors in questions requiring calculations,
    our observations indicate that CoT responses still include miscalculations and
    rounding errors. This issue may arise due to the inherent characteristics of Transformer
    models, designed to generate text based on tokens rather than numerical values.
    Potential solutions to address these issues include agentic approaches [[48](#bib.bib48),
    [49](#bib.bib49)], which integrate LLMs with calculator tools or symbolic computing
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'CoT-SC guided LLMs to perform multiple independent reasoning processes, then
    the responses were merged using a majority voting method. Our findings revealed
    that CoT-SC (compared to CoT) improved accuracy, particularly in Gemini 1.5 Pro.
    However, in GPT-4o and Claude 3.5, this improvement was small, as it only led
    to the correction of a few errors. This small difference can also be observed
    in their high inter-rater coefficient agreement, as illustrated in Figure [3](#Sx2.F3
    "Figure 3 ‣ Subgroup Error Analysis ‣ Accuracy ‣ Results ‣ Accuracy and Consistency
    of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and
    Knowledge Retrieval"). This finding does not support the literature suggesting
    that CoT-SC considerably enhances the accuracy of CoT [[50](#bib.bib50)].'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, CoT-SC achieved notably higher consistency (intra-rater agreement)
    compared to CoT. The ensemble process enabled by CoT-SC mitigates the randomness
    in the selection of reasoning paths. For GPT-4o and Claude 3.5 Sonnet, the Fleiss’
    Kappa agreements of CoT-SC were as robust as the agreements of ZS prompting. The
    Gemini’s inability to select a choice from the given multiple-choice options also
    improved, reducing them from 20 in CoT to 6 in CoT-SC. This highlights the importance
    of employing such ensemble techniques to enhance the consistency of LLM’s reasoning
    process by combining multiple reasoning paths rather than relying on a single
    path.
  prefs: []
  type: TYPE_NORMAL
- en: RAP integrated external relevant information from multiple references into the
    input prompts. However, our findings showed that RAP did not consistently improve
    accuracy across the three models. GPT-4o effectively leveraged the retrieved information
    to reduce error rates, particularly for Difficult and Expert questions that required
    more comprehensive understanding. Similar to CoT and CoT-SC, RAP improved D3)
    food service systems and D4) food and nutrition management questions. Although
    relevant information was provided in our knowledge base, RAP (compared to ZS)
    has recorded higher error rates for D2) nutrition care. D2 questions are mostly
    related to medical nutrition therapy, dietary guidelines, counseling skills, and
    nutrition care process. This higher error rates might arise from irrelevant retrieval,
    where the retrieval model fetches extraneous information [[51](#bib.bib51)]. Additionally,
    the complexity or ambiguity of the queries might contribute to this problem making
    it challenging for the retrieval model to find the most relevant chunks.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to GPT-4o, Gemini 1.5 Pro with RAP showed opposite behavior, as
    the accuracy for the Difficult and Expert questions reduced. We noticed that,
    in some cases, Gemini was prioritizing external information over its own internal
    knowledge, even when that external information was irrelevant to the question.
    This resulted in incorrect interpretations and answers. For example, for two questions,
    the model generated “The provided text does not contain the answer to the question
    as it pertains to dietary restrictions for patients on Linezolid.” and “The provided
    text focuses on Body Mass Index (BMI) but does not contain information about when
    weight and BMI peak.” This issue was particularly observed in D2, where error
    rates increased from 26.2 (ZS) to 35.6 (RAP).
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that the prompting techniques had less impact, whether positive
    or negative, on D1) Principles of Dietetics questions compared to the other domains.
    D1 questions primarily focus on general food science, nutrients, biochemistry,
    and related research (e.g. which fruit has the highest fructose?), compared to
    the other domains that are more specialized in dietetics or involve more domain
    knowledge. For D1, GPT-4o achieved the best accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: This study is limited to the leading proprietary LLM models. These models are
    user-friendly and highly powerful. Our results also confirm their significant
    potential in food and nutrition applications. Yet, growing concerns are being
    raised about their lack of openness and limited access. In contrast, open-source
    LLMs are emerging rapidly, offering benefits, such as improved data security and
    privacy, decreased reliance on vendors, and the ability to customize models. Examples
    of the state-of-the-art open-source LLMs are Llama 3 [[52](#bib.bib52)], Falcon
    2 [[53](#bib.bib53)], and Yi-34B [[54](#bib.bib54)]. Given their advantages, future
    research should evaluate the performance of open-source LLMs in the diet and nutrition
    field.
  prefs: []
  type: TYPE_NORMAL
- en: Our evaluation has primarily concentrated on the accuracy and consistency of
    the models. Given the sensitivity of health and nutrition applications, ensuring
    high accuracy and consistency is essential. However, it is important to assess
    LLMs from other perspectives, such as safety, bias, privacy, and emotional support,
    to mention a few [[18](#bib.bib18), [19](#bib.bib19), [55](#bib.bib55)]. Future
    work in this direction will involve evaluating LLMs according to these trustworthiness
    metrics by leveraging patient-centric questions, answers, and conversations.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we examined the impacts of prompt engineering methods on LLM answers
    to diet and nutrition questions. Various studies have explored the role of fine-tuning
    [[56](#bib.bib56), [57](#bib.bib57), [58](#bib.bib58)] and agentic methods [[23](#bib.bib23),
    [12](#bib.bib12), [59](#bib.bib59)]. Future research should evaluate their impact
    on nutrition management applications.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, this study assessed the accuracy and consistency of the GPT-4o,
    Claude 3.5 Sonnet, and Gemini 1.5 Pro in responding to diet and nutrition questions
    of the RD exam. In contrast to the previous LLM evaluation studies focusing on
    nutritional management, our experiments were not restricted to ChatGPT or ZS prompting.
    We evaluated the models using the RD exam and analyzed their errors across various
    questions complexities and nutrition domains. Our findings highlighted the strengths
    and weaknesses of the three LLMs, showing the influence of different prompting
    techniques on their responses to the RD exam questions. GPT-4o with CoT-SC prompting
    outperformed other approaches, while Gemini 1.5 Pro with ZS indicated the highest
    consistency. For GPT-4o and Claude 3.5, the application of CoT improved accuracy,
    while CoT-SC enhanced both accuracy and consistency. RAP particularly improved
    GPT-4o performance in addressing difficult- expert-level questions. Consequently,
    selecting the appropriate LLM and prompt engineering, tailored to the proficiency
    level and specific domain, can considerably reduce errors and mitigate potential
    risks in diet and nutrition chatbot applications.
  prefs: []
  type: TYPE_NORMAL
- en: Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b93dd94e8128a10ed5d1868c9b0eb035.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Zero Shot (ZS) prompting
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a65c18c01bcbc65fe3afae6657506dda.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Chain of Thought (CoT) prompting
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d05863bb3c796e7484343483cd5aaf3f.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Chain of Thought with Self Consistency (CoT-SC) prompting
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c5f3512e5c7db370df3243e3190d0686.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Retrieval Augmented Prompting (RAP)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: Schematic illustrations of the four prompting techniques used in
    the evaluation. The inputs include multiple-choice questions along with task description,
    and the generated output includes the selected choice.'
  prefs: []
  type: TYPE_NORMAL
- en: Registered Dietitian Exam
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Registration Examination for Dietitians is a required exam for individuals
    seeking to obtain the registered dietitian credential. To take the exam, candidates
    must successfully complete the eligibility requirements provided by the Commission
    on Dietetic Registration (CDR) [[60](#bib.bib60)]. The examination is computer-based
    and consists of 125 to 145 four-choice questions [[61](#bib.bib61)]. The exam
    includes multiple-choice questions from four major domains: D1) Principles of
    Dietetics (21%), D2) Nutrition Care for Individuals and Groups (45%), D3) Food
    Service Systems (13%), and D4) Management of Food and Nutrition Programs and Services
    (21%) [[61](#bib.bib61)]. The exam is scored from 1 to 50, and the minimum score
    to pass is 25\. The score is calculated based on the candidate’s performance as
    well as the difficulty levels of the questions [[61](#bib.bib61)].'
  prefs: []
  type: TYPE_NORMAL
- en: Within the four domains, D1 covers topics related to i) food, nutrition, and
    supporting sciences, ii) education, communication and technology, and iii) research
    applications. D2 consists of the topics related to i) screening and assessment,
    ii) diagnosis, iii) planning and intervention, and iv) monitoring and evaluation.
    D3 includes topics related to i) menu development, ii) procurement, production,
    distribution, and service, iii) sanitation and safety, and iv) equipment and facility
    planning. D4 includes topics related to i) functions of management, ii) human
    resource management, iii) financial management, iv) marketing and public relations;
    and v) quality management and regulatory compliance [[61](#bib.bib61)].
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, as the leading LLMs chatbots
    [[62](#bib.bib62), [63](#bib.bib63)], are employed in this study for evaluation.
    OpenAI released GPT-4o, their new flagship model, on May 13, 2024 [[35](#bib.bib35)],
    Claude 3.5 Sonnet was launched, by Anthropic, as their strongest vision model
    yet, on Jun 20, 2024 [[36](#bib.bib36)], and Google announced Gemini 1.5 Pro as
    their next-generation model on February 15, 2024 [[37](#bib.bib37)]. An overview
    of the models’ performance on other benchmarks are indicated in Table [2](#Sx1.T2
    "Table 2 ‣ Introduction ‣ Accuracy and Consistency of LLMs in the Registered Dietitian
    Exam: The Impact of Prompt Engineering and Knowledge Retrieval"). Find more details
    in [[36](#bib.bib36), [35](#bib.bib35), [42](#bib.bib42)].'
  prefs: []
  type: TYPE_NORMAL
- en: In this study, we set the temperature setting to 0 for all the models to better
    evaluate the LLMs’ knowledge and decision-making in nutrition and diet applications,
    minimizing the effect of external variables on consistency. The temperature parameter,
    ranging from 0 to 2, regulates the uncertainty or randomness in the output [[64](#bib.bib64)].
    With a temperature setting of 0, the model generates responses by selecting the
    next words with the highest probability, making the model “more deterministic.”
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Four prompting techniques are utilized in this study for the models evaluation.
    Schematic illustrations of the four techniques are shown in Figure [4](#Sx4.F4
    "Figure 4 ‣ Methods ‣ Accuracy and Consistency of LLMs in the Registered Dietitian
    Exam: The Impact of Prompt Engineering and Knowledge Retrieval"). Additionally,
    the instructions used for the prompting techniques are presented in Supplementary
    Table S.3.'
  prefs: []
  type: TYPE_NORMAL
- en: 1) Zero Shot (ZS) prompting generates the simplest type of prompt, including
    a question and a fixed task description. The model leverages its internal knowledge
    to generate responses [[29](#bib.bib29)]. To the best of our knowledge, existing
    evaluations of LLM chatbots focusing on nutrition and diet have utilized ZS prompting
    for their assessments. 2) Chain of Thought (CoT) prompting consists of a question
    and a description to the model to answer the question through intermediate reasoning
    steps [[47](#bib.bib47)]. CoT has been widely used in medical studies [[65](#bib.bib65),
    [33](#bib.bib33)]. 3) Chain of Thought with Self Consistency (CoT-SC) prompting
    creates several independent reasoning paths using CoT. Subsequently, the outcomes
    are aggregated [[50](#bib.bib50)]. In our experiments, we selected three independent
    reasoning paths and used a majority voting method for the aggregation. 4) Retrieval
    Augmented Prompting (RAP) fetches relevant information from a knowledge base in
    real-time and integrates it into the input prompt [[51](#bib.bib51), [66](#bib.bib66)].
    In contrast to the other prompting techniques, using RAP, the model generates
    responses by relying not only on its internal knowledge but also on external information.
    In our study, the knowledge base includes 125 documents (such as articles, books,
    and guidelines) recommended by the Academy of Nutrition and Dietetics [[43](#bib.bib43)],
    as references for the RD exam. The full list of the references used for RAP is
    provided in Supplementary Table S.4\. For the implementation, we leveraged a conventional
    Retrieval Augmented Generation (RAG) framework [[51](#bib.bib51)]. To achieve
    this, the references were divided into 512-token chunks, using the Amazon Titan
    Text Embeddings v2 model [[67](#bib.bib67)] for text embeddings. Then, the Cosine
    Similarity method [[68](#bib.bib68)] was utilized to identify the most similar
    chunks.
  prefs: []
  type: TYPE_NORMAL
- en: Data Collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The 1050 RD exam questions were delivered to the three models using the four
    prompting techniques. Each question was asked five times. Consequently, we collected
    60 (i.e., $3\times 4\times 5$) sets of 1050 responses. As previously mentioned,
    the questions include four choices. We observed that sometimes the LLMs were unable
    to select an option from the multiple choices and provided responses such as,
    “None of the above,” “Since no option is correct, we cannot provide a final answer
    within the requested tags,” or “Cannot be determined with the given information.”
    In summary, this issue occurred once for GPT-4o with CoT, once for GPT-4o with
    CoT-SC, 15 times for Claude 3.5 with RAP, 100 times for Gemini 1.5 with CoT, 30
    times for Gemini 1.5 with CoT-SC, and 63 times for Gemini 1.5 with RAP. For these
    responses, we added another option, labeled “Others.”
  prefs: []
  type: TYPE_NORMAL
- en: The collected responses were compared with the ground truth answers provided
    by the Academy of Nutrition and Dietetics, eatrightPREP [[43](#bib.bib43)]. It
    should be noted that we used a new chat session for each query to minimize bias
    in the evaluation caused by information leakage from other questions. The data
    collection was performed in Python using OpenAI [[69](#bib.bib69)], google-generativeai
    [[70](#bib.bib70)], Boto3 [[71](#bib.bib71)], and lxml.etree [[72](#bib.bib72)]
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The responses were evaluated in terms of accuracy and consistency. Accuracy
    measures how close a set of responses are to the ground truth answers. To this
    end, we calculate the percentage score, which is the ratio of correct responses
    to all responses multiplied by 100\. The percentage score indicates how well the
    LLMs can detect the correct option. As previously mentioned, each measurement
    is repeated five times. The five repeated measurements in each test are grouped,
    and the mean and standard deviation of the scores are calculated.
  prefs: []
  type: TYPE_NORMAL
- en: Consistency refers to the degree to which responses produce the same results.
    To assess consistency, we perform inter-rater and intra-rater analysis approaches.
    [[73](#bib.bib73)]. For the former, the agreement between the responses obtained
    from different models / prompting techniques are evaluated. To this end, Cohen’s
    Kappa [[74](#bib.bib74)] was utilized to measure the degree of agreement between
    two sets of responses. For example, the agreement between responses obtained from
    GPT-4o with ZS prompting and GPT-4o with CoT prompting are calculated. Furthermore,
    for the intra-rater analysis, Fleiss Kappa test [[75](#bib.bib75)] was used to
    indicate the degree of overall agreement between the repeated measurements under
    fixed conditions. For instance, we assess whether GPT-4o with ZS prompting provides
    the same choices in repeated measurements. It should be noted that the statistical
    analysis was conducted in R Programming using irr [[76](#bib.bib76)] and boot
    [[77](#bib.bib77)] libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Data Availability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The RD exam questions used in this study are not publicly available and can
    be accessed via [https://www.eatrightprep.org](https://www.eatrightprep.org).
  prefs: []
  type: TYPE_NORMAL
- en: Code Availability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The codes for data collection, API calls, and statistical analysis are available
    at [https://github.com/iHealthLab/DietitianExamEval](https://github.com/iHealthLab/DietitianExamEval).
  prefs: []
  type: TYPE_NORMAL
- en: Competing Interests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The authors declare no competing interests. Moreover, the funders of the study
    had no role in study design, data collection and analysis, or interpretation of
    results and preparation of the manuscript.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Singh, B. *et al.* Systematic review and meta-analysis of the effectiveness
    of chatbots on lifestyle behaviours. *npj Digital Medicine*  6, 118 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Webster, P. Six ways large language models are changing healthcare. *Nature
    Medicine*  29, 2969–2971 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Ma, P. *et al.* Large language models in food science: Innovations, applications,
    and future. *Trends in Food Science & Technology* 104488 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Clusmann, J. *et al.* The future landscape of large language models in
    medicine. *Communications medicine*  3, 141 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Meskó, B. The impact of multimodal large language models on health care’s
    future. *Journal of medical Internet research*  25, e52865 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Bond, A., Mccay, K. & Lal, S. Artificial intelligence & clinical nutrition:
    What the future might have in store. *Clinical nutrition ESPEN* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Dao, D., Teo, J. Y. C., Wang, W. & Nguyen, H. D. LLM-Powered Multimodal
    AI Conversations for Diabetes Prevention. In *Proceedings of the 1st ACM Workshop
    on AI-Powered Q&A Systems for Multimedia*, 1–6 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] OpenAI. Introducing ChatGPT. [https://openai.com/index/chatgpt/](https://openai.com/index/chatgpt/)
    (2022). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Liu, Y. *et al.* Exploring the usability of a chatbot-based conversational
    dietary assessment tool among cardiovascular patients. *European Journal of Preventive
    Cardiology*  30, zwad125–281 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Pugliese, N. *et al.* Accuracy, Reliability, and Comprehensibility of
    ChatGPT-generated Medical Responses for Patients with Nonalcoholic Fatty Liver
    Disease. *Clinical Gastroenterology and Hepatology*  22, 886–889 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Kim, D. W. *et al.* Qualitative evaluation of artificial intelligence-generated
    weight management diet plans. *Frontiers in Nutrition*  11, 1374834 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Abbasian, M. *et al.* Knowledge-Infused LLM-Powered Conversational Health
    Agent: A Case Study for Diabetes Patients. In *the 46th Annual International Conference
    of the IEEE Engineering in Medicine and Biology Society* (IEEE, 2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Haman, M., Školník, M. & Lošták, M. AI dietitian: Unveiling the accuracy
    of ChatGPT’s nutritional estimations. *Nutrition*  119, 112325 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Qarajeh, A. *et al.* AI-Powered Renal Diet Support: Performance of ChatGPT,
    Bard AI, and Bing Chat. *Clinics and Practice*  13, 1160–1172 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Tsai, C.-H. *et al.* Generating Personalized Pregnancy Nutrition Recommendations
    with GPT-Powered AI Chatbot. In *20th International Conference on Information
    Systems for Crisis Response and Management (ISCRAM)*, vol. 2023, 263 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Zhou, P. *et al.* FoodSky: A Food-oriented Large Language Model that Passes
    the Chef and Dietetic Examination. *arXiv preprint arXiv:2406.10261* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Thirunavukarasu, A. J. *et al.* Large language models in medicine. *Nature
    medicine*  29, 1930–1940 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Abbasian, M. *et al.* Foundation metrics for evaluating effectiveness
    of healthcare conversations powered by generative AI. *NPJ Digital Medicine*  7,
    82 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Liang, P. *et al.* Holistic evaluation of language models. *arXiv preprint
    arXiv:2211.09110* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Sun, H. *et al.* An AI dietitian for type 2 diabetes mellitus management
    based on large language and image recognition models: preclinical concept validation
    study. *Journal of Medical Internet Research*  25, e51300 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Barlas, T., Altinova, A. E., Akturk, M. & Toruner, F. B. Credibility of
    ChatGPT in the assessment of obesity in type 2 diabetes according to the guidelines.
    *International Journal of Obesity*  48, 271–275 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Hoang, Y. N. *et al.* Consistency and accuracy of artificial intelligence
    for providing nutritional information. *JAMA network open*  6, e2350367–e2350367
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Yang, Z. *et al.* ChatDiet: Empowering personalized nutrition-oriented
    food recommender chatbots through an LLM-augmented framework. *Smart Health*  32,
    100465 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Ponzo, V. *et al.* Is ChatGPT an Effective Tool for Providing Dietary
    Advice? *Nutrients*  16, 469 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Kirk, D., van Eijnatten, E. & Camps, G. Comparison of answers between
    ChatGPT and human dieticians to common nutrition questions. *Journal of Nutrition
    and Metabolism*  2023, 5548684 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Szymanski, A., Wimer, B. L., Anuyah, O., Eicher-Miller, H. A. & Metoyer,
    R. A. Integrating Expertise in LLMs: Crafting a Customized Nutrition Assistant
    with Refined Template Instructions. In *Proceedings of the CHI Conference on Human
    Factors in Computing Systems*, 1–22 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Niszczota, P. & Rybicka, I. The credibility of dietary advice formulated
    by ChatGPT: robo-diets for people with food allergies. *Nutrition*  112, 112076
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Minaee, S. *et al.* Large language models: A survey. *arXiv preprint arXiv:2402.06196*
    (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Sahoo, P. *et al.* A systematic survey of prompt engineering in large
    language models: Techniques and applications. *arXiv preprint arXiv:2402.07927*
    (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Chen, B., Zhang, Z., Langrené, N. & Zhu, S. Unleashing the potential of
    prompt engineering in large language models: a comprehensive review. *arXiv preprint
    arXiv:2310.14735* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Wang, J. *et al.* Prompt engineering for healthcare: Methodologies and
    applications. *arXiv preprint arXiv:2304.14670* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Maharjan, J. *et al.* OpenMedLM: prompt engineering can out-perform fine-tuning
    in medical question-answering with open-source large language models. *Scientific
    Reports*  14, 14156 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Wang, L. *et al.* Prompt engineering in consistency and reliability with
    the evidence-based guideline for LLMs. *npj Digital Medicine*  7, 41 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Ouyang, S., Zhang, J. M., Harman, M. & Wang, M. LLM is Like a Box of Chocolates:
    the Non-determinism of ChatGPT in Code Generation. *arXiv preprint arXiv:2308.02828*
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] OpenAI. Hello GPT-4o. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)
    (2024). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Anthropic. Introducing Claude 3.5 Sonnet. [https://www.anthropic.com/news/claude-3-5-sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)
    (2024). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Google. Introducing Gemini 1.5, Google’s next-generation AI model. [https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)
    (2024). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Commission on Dietetic Registration. Registered Dietitian Nutritionist.
    [https://www.cdrnet.org/RDN](https://www.cdrnet.org/RDN). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Hendrycks, D. *et al.* Measuring massive multitask language understanding.
    *arXiv preprint arXiv:2009.03300* (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] Rein, D. *et al.* GPQA: A Graduate-level Google-proof Q&A Benchmark. *arXiv
    preprint arXiv:2311.12022* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Dua, D. *et al.* DROP: A reading comprehension benchmark requiring discrete
    reasoning over paragraphs. *arXiv preprint arXiv:1903.00161* (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Reid, M. *et al.* Gemini 1.5: Unlocking multimodal understanding across
    millions of tokens of context. *arXiv preprint arXiv:2403.05530* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] Academy of Nutrition and Dietetics . [https://www.eatrightprep.org/](https://www.eatrightprep.org/).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Grabb, D. The impact of prompt engineering in large language model performance:
    a psychiatric example. *Journal of Medical Artificial Intelligence*  6 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Russe, M. F., Reisert, M., Bamberg, F. & Rau, A. Improving the use of
    LLMs in radiology through prompt engineering: from precision prompts to zero-shot
    learning. In *RöFo-Fortschritte auf dem Gebiet der Röntgenstrahlen und der bildgebenden
    Verfahren* (Georg Thieme Verlag KG, 2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Mishra, V., Jafri, F., Abdul Kareem, N., Aboobacker, R. & Noora, F. Evaluation
    of accuracy and potential harm of ChatGPT in medical nutrition therapy-a case-based
    approach. *F1000Research*  13, 137 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Wei, J. *et al.* Chain-of-Thought Prompting Elicits Reasoning in Large
    Language Models. *Advances in neural information processing systems*  35, 24824–24837
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] Gou, Z. *et al.* ToRA: A Tool-Integrated Reasoning Agent for Mathematical
    Problem Solving. *arXiv preprint arXiv:2309.17452* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Abbasian, M., Azimi, I., Rahmani, A. M. & Jain, R. Conversational health
    agents: A personalized LLM-powered agent framework. *arXiv preprint arXiv:2310.02374*
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Wang, X. *et al.* Self-Consistency Improves Chain of Thought Reasoning
    in Language Models. *arXiv preprint arXiv:2203.11171* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Gao, Y. *et al.* Retrieval-augmented generation for large language models:
    A survey. *arXiv preprint arXiv:2312.10997* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Meta AI. Introducing Meta Llama 3: The most capable openly available LLM
    to date. [https://ai.meta.com/blog/meta-llama-3/](https://ai.meta.com/blog/meta-llama-3/)
    (2024). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] Technology Innovation Institute. Falcon LLM. [https://falconllm.tii.ae/](https://falconllm.tii.ae/)
    (2024). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] 01.AI. Yi-34B. [https://huggingface.co/01-ai/Yi-34B](https://huggingface.co/01-ai/Yi-34B)
    (2024). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Sun, L. *et al.* TrustLLM: Trustworthiness in large language models. *arXiv
    preprint arXiv:2401.05561* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Xu, L., Xie, H., Qin, S.-Z. J., Tao, X. & Wang, F. L. Parameter-efficient
    fine-tuning methods for pretrained language models: A critical review and assessment.
    *arXiv preprint arXiv:2312.12148* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Singhal, K. *et al.* Large language models encode clinical knowledge.
    *Nature*  620, 172–180 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] Zhang, X. *et al.* Comparison of prompt engineering and fine-tuning strategies
    in large language models in the classification of clinical notes. *AMIA Summits
    on Translational Science Proceedings*  2024, 478 (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Li, Y. *et al.* Personal LLM agents: Insights and survey about the capability,
    efficiency and security. *arXiv preprint arXiv:2401.05459* (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Commission on Dietetic Registration, Registered Dietitian (Rd) Or Registered
    Dietitian Nutritionist (Rdn) Certification. [https://www.cdrnet.org/RDN](https://www.cdrnet.org/RDN).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Commission on Dietetic Registration. *Candidate Handbook, RD Exam* (Academy
    of Nutrition and Dietetics, 2024). URL [https://admin.cdrnet.org/vault/2459/web//RD%20Handbook%20for%20Candidates%20-%206-2024.pdf](https://admin.cdrnet.org/vault/2459/web//RD%20Handbook%20for%20Candidates%20-%206-2024.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] Chatbot Arena. Chat with Open Large Language Models. [https://chat.lmsys.org/?leaderboard](https://chat.lmsys.org/?leaderboard).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Artificial Analysis. Model & API Providers Analysis. [https://artificialanalysis.ai/](https://artificialanalysis.ai/).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] Peeperkorn, M., Kouwenhoven, T., Brown, D. & Jordanous, A. Is temperature
    the creativity parameter of large language models? *arXiv preprint arXiv:2405.00492*
    (2024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] Holmes, J. *et al.* Evaluating large language models on a highly-specialized
    topic, radiation oncology physics. *Frontiers in Oncology*  13, 1219326 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Li, Y. *et al.* ChatDoctor: A Medical Chat Model Fine-Tuned on a Large
    Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge. *Cureus*  15 (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Sebastien Stormacq. Amazon Titan Text Embeddings V2 now available in Amazon
    Bedrock, optimized for improving RAG. [https://aws.amazon.com/blogs/aws/amazon-titan-text-v2-now-available-in-amazon-bedrock-optimized-for-improving-rag/](https://aws.amazon.com/blogs/aws/amazon-titan-text-v2-now-available-in-amazon-bedrock-optimized-for-improving-rag/)
    (2024). Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Manning, C. D., Raghavan, P. & Schütze, H. Scoring, term weighting & the
    vector space model. In *Introduction to Information Retrieval* (Cambridge University
    Press, 2008).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] Libraries, OpenAI API. [https://platform.openai.com/docs/libraries/python-library](https://platform.openai.com/docs/libraries/python-library).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] google-generativeai, Gemini API. [https://pypi.org/project/google-generativeai/](https://pypi.org/project/google-generativeai/).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] AWS SDK for Python (Boto3) Documentation. [https://docs.aws.amazon.com/pythonsdk/](https://docs.aws.amazon.com/pythonsdk/).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] Stefan Behnel. The lxml.etree Tutorial. [https://lxml.de/tutorial.html](https://lxml.de/tutorial.html).
    Accessed: August 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] Hallgren, K. A. Computing inter-rater reliability for observational data:
    an overview and tutorial. *Tutorials in quantitative methods for psychology*  8,
    23 (2012).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] Cohen, J. A coefficient of agreement for nominal scales. *Educational
    and psychological measurement*  20, 37–46 (1960).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Fleiss, J. L. Measuring nominal scale agreement among many raters. *Psychological
    bulletin*  76, 378 (1971).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Gamer, M., Lemon, J. & Singh, I. F. P. *irr: Various Coefficients of Interrater
    Reliability and Agreement* (2019). URL [https://CRAN.R-project.org/package=irr](https://CRAN.R-project.org/package=irr).
    R package version 0.84.1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] Canty, A., Ripley, B. & Brazzale, A. R. *boot: Bootstrap Functions* (2024).
    URL [https://CRAN.R-project.org/package=boot](https://CRAN.R-project.org/package=boot).
    R package version 1.3-30.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See pages - of [supplementary.pdf](supplementary.pdf)
  prefs: []
  type: TYPE_NORMAL
