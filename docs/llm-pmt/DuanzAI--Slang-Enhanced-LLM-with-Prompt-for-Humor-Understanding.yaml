- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:43:32'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'DuanzAI: Slang-Enhanced LLM with Prompt for Humor Understanding'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.15818](https://ar5iv.labs.arxiv.org/html/2405.15818)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yesian Rohn¹
  prefs: []
  type: TYPE_NORMAL
- en: ¹School of Computer Science, Fudan University
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Language’s complexity is evident in the rich tapestry of slang expressions,
    often laden with humor and cultural nuances. This linguistic phenomenon has become
    increasingly prevalent, especially in digital communication. However, existing
    AI models, including ChatGPT-3.5, face challenges in comprehending these nuances,
    particularly in Chinese slang. In this study, we present DuanzAI, an innovative
    approach enhancing Large Language Models (LLMs) with deep Chinese slang comprehension.
    Leveraging curated datasets and advanced techniques, DuanzAI bridges the gap between
    human expression and AI comprehension, enabling contextually relevant responses.
    Our experiments contrast LLMs’ performance with a custom Punchline Entity Recognition
    (PER) system, integrating phonetic matching and pinyin2hanzi techniques. Applying
    these insights, we developed ChatDAI, an advanced chatbot and released our code
    at [https://github.com/YesianRohn/DuanzAI](https://github.com/YesianRohn/DuanzAI).
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '"I think the next best thing to solving a problem is finding some humor in
    it."'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- [Clark](#bib.bib3)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Language, as a dynamic and evolving entity, manifests itself in various forms
    within different social contexts. One of the fascinating linguistic phenomena
    that has emerged prominently in recent years is slang. Slang, defined as an informal
    language form primarily used within specific social groups, encompasses words
    or phrases that are metaphorical, pun-based, or even contrary to their literal
    meanings. It thrives on metaphor, wordplay, and implicit implications, adding
    depth and nuance to communication. Traditionally confined to oral interactions,
    the digital era has witnessed a surge in slang usage, especially on platforms
    like instant messaging applications and social media networks. This proliferation
    has sparked a pressing need for artificial intelligence systems to comprehend
    and respond effectively to these informal linguistic expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding slang is not merely a matter of linguistic curiosity; it holds
    substantial importance in the realm of natural language processing, particularly
    in the development of conversational AI. Humor, emotions, and subtle social cues
    often rely on slang usage, making it imperative for AI systems to grasp these
    nuances to facilitate more authentic and engaging interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite its prevalence, the study of slang in the context of natural language
    processing remains relatively unexplored. Existing research efforts have begun
    to delve into the applications of slang, but the field still lacks comprehensive
    attention. Slang’s inherent ambiguity, metaphorical nature, and irregularities
    pose significant challenges for artificial intelligence systems. Current conversational
    AI, including state-of-the-art models like GPT-3.5, often struggle to comprehend
    and respond appropriately to Chinese slang expressions, leading to a gap in humor
    understanding and cultural relevance (Figure  [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ DuanzAI: Slang-Enhanced LLM with Prompt for Humor Understanding")).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/43e734be9720b1f64d1c1e0a2c180857.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: ChatGPT-3.5 cannot understand Chinese homophonic pun jokes.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we create DuanzAI, an innovative approach aimed at enhancing LLMs
    with a deep understanding of Chinese slang. Leveraging a carefully curated dataset
    of Chinese slang expressions and optimizing existing pre-trained language models,
    DuanzAI seeks to bridge the gap between human expression and AI comprehension.
    By incorporating slang-specific prompts, DuanzAI aims to enable AI systems not
    only to recognize and interpret diverse slang expressions but also to respond
    contextually, thereby elevating the AI’s ability to understand humor, emotions,
    and social dynamics within conversations.
  prefs: []
  type: TYPE_NORMAL
- en: When we attempt to engage LLM in understanding humor, their cognitive process
    tends to revolve around identifying punchlines, highlighting the contrasts within
    these punchlines, and subsequently conducting analysis. In the first and third
    steps, they demonstrate relatively satisfactory performance on their own; however,
    errors in the second step can also impact the outcome of the third step. Moreover,
    if both the first and second steps are accurate, leveraging the extensive knowledge
    base of large models would generally ensure reliable analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, we initiated an experiment to assess the performance of LLMs,
    like ChatGLM-6BZeng et al. ([2022](#bib.bib19)) and ChatGPT3.5 in identifying
    punchlines. This was then contrasted with our self-constructed PER system. Following
    this, we proceeded with the second step by utilizing a combination of online phonetic
    matching API and the pinyin2hanziletiantian ([2015](#bib.bib12)) technique to
    locate the original words. Subsequently, we integrated PER and the aforementioned
    components into prompts to observe the enhanced performance of the large model.
    Based on the research on humor comprehension mentioned above, we constructed our
    ChatDAI: DuanzAI Chatbot using the SparkiFLYTEK ([2023](#bib.bib7)) large model
    API.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Datasets and Task Setups
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our research leverages a substantial dataset of Chinese homophonic puns and
    slang expressions obtained from the rich linguistic landscape of Sina Weibo, a
    prominent social media platform in China. This dataset comprises nearly 2500 meticulously
    curated instances, each meticulously annotated for both the punchline (the humorous
    element) and the original word or phrase. By focusing on these specific aspects,
    we aim to capture the essence of the humor embedded within slang expressions,
    enabling a detailed analysis of linguistic wit and creativity.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Task Setups
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our experimental design is meticulously crafted, encompassing three distinct
    phases to dissect the intricacies of humor recognition within Chinese slang expressions.
    These phases were structured as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Punchline Entity Recognition
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the initial phase, we focus on developing a robust PER system. This specialized
    system was engineered to identify and extract the precise entities constituting
    the punchlines within the Chinese slang expressions. Leveraging a combination
    of linguistic analysis and contextual understanding, PER aimed to capture the
    essence of humor by pinpointing the specific words or phrases that constituted
    the punchlines. Through meticulous annotation and validation, we curated a dataset
    that served as the gold standard for punchline identification, forming the basis
    for our subsequent evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 Punchline Original Word Retrieval
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Building upon the identified punchlines, the second phase of our experiment
    involved the intricate task of locating the original words or phrases corresponding
    to these punchlines. To achieve this, we employed a sophisticated combination
    of online phonetic matching APIs and the pinyin2hanzi technique. Phonetic matching
    was utilized to generate candidate words based on their pronunciation, which were
    then rigorously validated using pinyin2hanzi, a method converting phonetic representations
    (pinyin) back into accurate Chinese characters (hanzi). This meticulous process
    ensured the accurate retrieval of the original words associated with the identified
    punchlines, establishing a reliable ground truth for our evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.3 Comprehensive Humor Understanding
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the final phase of our experiment, we orchestrated a comprehensive evaluation
    of humor understanding within the context of Chinese slang expressions. This phase
    involved integrating the insights derived from the PER system and the precise
    original word retrieval into specially crafted prompts. These prompts were designed
    to challenge pre-trained language models, including ChatGLM-6B and ChatGPT3.5,
    to comprehend the nuanced layers of humor encapsulated within the slang expressions.
    By infusing the prompts with the knowledge garnered from PER and the phonetic
    matching techniques, our objective was to discern subtle distinctions in humor
    recognition between the pre-trained models and our specialized system.
  prefs: []
  type: TYPE_NORMAL
- en: Through these meticulously designed phases, we sought to unravel the subtle
    differentiations in punchline recognition between pre-trained models and our expertly
    crafted systems. This multifaceted approach provids a robust framework for evaluating
    the humor comprehension capabilities of both traditional language models and our
    specialized systems, shedding light on the complexities of humor recognition in
    the realm of Chinese slang expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Punchline Entity Recognition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the initial phase of our experiments, we aim to assess the punchline recognition
    abilities of LLMs. Additionally, we sought to address the challenge of punchline
    entity recognition through a direct and simple approach, utilizing BERT-LSTM-CRF
    (Bidirectional Encoder Representations from Transformers - Long Short-Term Memory
    - Conditional Random Fields). This methodology, derived from named entity recognition
    (NER) techniques Li et al. ([2022](#bib.bib13)), provided a robust framework for
    solving the punchline entity recognition problem. To evaluate the capabilities
    of ChatGPT and ChatGLM in recognizing punchlines within Chinese slang expressions,
    we employed a assessment with Exact Match Accuracy(EMA) and Similar Match Accuracy(SMA).
    Concurrently, we explored the performance of our specialized PER system based
    on BERT-LSTM-CRF. The evaluation metrics included precision, recall, and F1-score,
    offering a comprehensive understanding of each model’s accuracy in punchline recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results of our experiments, presented in Table  [1](#S3.T1 "Table 1 ‣ 3.1
    Punchline Entity Recognition ‣ 3 Experiments ‣ DuanzAI: Slang-Enhanced LLM with
    Prompt for Humor Understanding"), which is evident from the table that our PER
    system, utilizing the BERT-LSTM-CRF framework, outperforms both ChatGPT and ChatGLM
    in punchline entity recognition. The higher EMA achieved by our specialized system
    demonstrates its superior accuracy and robustness in capturing punchlines within
    Chinese slang expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | EMA | SMA |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `ChatGLM-6B (0-Shot)` | 0.57 | 0.73 |'
  prefs: []
  type: TYPE_TB
- en: '| `GPT3.5 (0-Shot)` | 0.87 | 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '| `GPT3.5 (5-Shot)` | 0.92 | 0.97 |'
  prefs: []
  type: TYPE_TB
- en: '| `GPT4 (5-Shot)` | 0.92 | 0.97 |'
  prefs: []
  type: TYPE_TB
- en: '| `Ours` | 0.97 | 0.98 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Results of Punchline Entity Recognition in All Models Experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Precision | Recall | F1-Score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `0.970` | `0.969` | `0.969` |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Results of BERT-LSTM-CRF Punchline Entity Recognition Experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Comprehensive Humor Understanding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the pursuit of enhancing humor comprehension within Chinese slang expressions,
    we adopted two distinct approaches: Clue Provided and 5-Shot. These methodologies
    were designed to augment the capabilities of our language models, specifically
    ChatGPT 3.5, in grasping the nuances of humor. To evaluate the effectiveness of
    these approaches, the output generated by our enhanced models was subjected to
    human evaluation. Participants were asked to assign scores based on the perceived
    humor understanding, with a maximum score of 100 indicating a perfect understanding
    of the humor embedded in the expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Clue Provided Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the Clue Provided scenario, the language model was furnished with additional
    context or clues related to the punchline. This approach aimed to simulate a scenario
    where subtle hints or off-site information was available, aiding the model in
    deciphering the humor within the slang expressions. The Clue Provided method resulted
    in an enhanced humor comprehension, as evidenced by the model’s improved score
    to 53.1 out of 100, compared to the baseline of 39.3 achieved by ChatGPT 3.5 in
    the 0-Shot setting.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 5-Shot Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the 5-Shot approach, the language model was provided with five iterations
    or examples of similar slang expressions to establish a pattern. This technique
    leveraged a small dataset to facilitate learning and improve the model’s grasp
    of the underlying humor structure. Despite the limited training data, the 5-Shot
    method yielded promising results, with ChatGPT 3.5 achieving a humor comprehension
    score of 51 out of 100.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3 Human Evaluation Results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The results of the human evaluation are summarized in Table  [3](#S3.T3 "Table
    3 ‣ 3.2.3 Human Evaluation Results ‣ 3.2 Comprehensive Humor Understanding ‣ 3
    Experiments ‣ DuanzAI: Slang-Enhanced LLM with Prompt for Humor Understanding").
    The scores obtained in the Clue Provided and 5-Shot approaches highlight the significant
    improvement in humor understanding compared to the 0-Shot scenario. These evaluations
    underscore the effectiveness of providing additional context or limited examples
    to enhance the language model’s ability to comprehend humor within Chinese slang
    expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Approach | Score (100) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `GPT3.5(0-Shot)` | 39.3 |'
  prefs: []
  type: TYPE_TB
- en: '| `GPT3.5(clue-provided)` | 53.1 |'
  prefs: []
  type: TYPE_TB
- en: '| `GPT3.5(5-Shot)` | 51.0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Human Evaluation Scores for Comprehensive Humor Understanding.'
  prefs: []
  type: TYPE_NORMAL
- en: These findings demonstrate the positive impact of contextual clues and limited
    training examples on the language model’s humor comprehension abilities. The Clue
    Provided and 5-Shot approaches offer valuable insights into how contextual information
    and minimal training data can substantially enhance the nuanced understanding
    of humor within the realm of Chinese slang expressions, paving the way for more
    culturally sensitive and engaging AI interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Slang detection involves the identification of informal language expressions
    within a given text, utilizing natural language processing techniques and machine
    learning algorithms to discern the differences between slang and formal expressions
    Pei et al. ([2019](#bib.bib17)). Simple and practical slang detection methods
    include emotion analysis techniques based on constructing dictionaries Dhuliawala
    et al. ([2016](#bib.bib4)); Wu et al. ([2018](#bib.bib18)) and modular multi-factor
    collection Pal and Saha ([2015](#bib.bib16)); Gupta et al. ([2019](#bib.bib5)).
    However, these approaches heavily rely on static information and structure of
    slang expressions, lacking the ability to comprehend the flexible semantics of
    slang and handle newly emerging expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'More sophisticated research in slang detection revolves around deep learning-based
    automatic slang detection and cognitive usage frameworks. Researchers have leveraged
    techniques such as multi-layer bidirectional LSTM perceptrons (MLP) Kulkarni and
    Wang ([2018](#bib.bib10)), conditional random fields (CRF) Lafferty et al. ([2001](#bib.bib11)),
    and Part-of-Speech (POS) taggers Korolainen ([2014](#bib.bib9)) to extract comprehensive
    linguistic features of slang. The field has seen continuous improvements, including:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sequence Models: Researchers have explored dialectal variations for feature
    extraction, leading to sequence models like the LID method, enabling recognition
    of diverse dialects Jurgens et al. ([2017](#bib.bib8)); Lourentzou et al. ([2019](#bib.bib14)).
    Dialectal varieties, being a significant source of slang, are well recognized
    by sequence models Kulkarni and Wang ([2018](#bib.bib10)).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Character-level Convolution: Unlike traditional methods based on word embeddings,
    character-level convolution is effective in capturing correlated words and morphological
    variations in text Zhang et al. ([2015](#bib.bib20)); Bu and Cho ([2018](#bib.bib2)).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pre-Training Models: In specific subtasks like humor detection, recent studies
    have incorporated pre-training models such as BERT, fine-tuning them on training
    data for tasks like joke scoring Mao and Liu ([2019](#bib.bib15)); Annamoradnejad
    and Zoghi ([2020](#bib.bib1)).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the current era of large-scale models, it appears that fine-tuning existing
    models with carefully crafted prompts can lead to more successful outcomes in
    achieving the ability to comprehend humor. The best paper presented at ACL 2023
    assessed the level of humor "understanding" in large models through meticulously
    designed prompts. This contribution showcases the effectiveness of prompt engineering
    in evaluating the humor comprehension capabilities of these models Hessel et al.
    ([2023](#bib.bib6)).
  prefs: []
  type: TYPE_NORMAL
- en: 5 Application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Building upon the insights gained from our research on humor comprehension,
    we embarked on the practical application of our findings. The culmination of our
    efforts led to the creation of ChatDAI: DuanzAI Chatbot, a sophisticated conversational
    agent designed to understand and engage in humorous interactions within the realm
    of Chinese slang expressions.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Development Process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our chatbot development process was informed by the research findings mentioned
    earlier. We began by contrasting the capabilities of ChatGPT and our PER system.
    Following this comparative analysis, we seamlessly integrated the PER system with
    a combination of online phonetic matching APIs and the pinyin2hanzi technique.
    This integration allowed us to accurately locate the original words corresponding
    to punchlines, providing a robust foundation for humor comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Integration of Components
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The culmination of our research efforts resulted in the integration of PER,
    phonetic matching, and pinyin2hanzi components into prompts used by our chatbot.
    By incorporating these elements, ChatDAI was equipped with an enhanced understanding
    of humor, allowing it to decipher the complexities of Chinese slang expressions.
    This integration significantly amplified the chatbot’s ability to engage users
    in witty and culturally relevant conversations.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 ChatDAI Implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Utilizing the Spark large model API, we brought our vision to life with the
    creation of ChatDAI. It serves as an embodiment of our research, showcasing the
    practical implications of our work. ChatDAI’s ability to comprehend humor within
    Chinese slang expressions is a testament to the advancements made in natural language
    processing, humor recognition, and conversational AI.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Limitations and Choice of Framework
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s noteworthy that we chose Spark as the baseline framework for ChatDAI, even
    though ChatGPT might offer superior performance. This decision was primarily influenced
    by OpenAI API limitations and regulatory constraints within the context of China.
    These restrictions necessitated the utilization of Spark as a viable and practical
    alternative, allowing us to implement our vision while adhering to local regulations.
  prefs: []
  type: TYPE_NORMAL
- en: 5.5 ChatDAI in Action
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can experience the capabilities of ChatDAI by visiting our live chatbot
    at www.duanzai.top. The chatbot’s interface provides users with an opportunity
    to engage in humorous conversations, exploring the richness of Chinese slang expressions
    in an interactive and engaging manner.
  prefs: []
  type: TYPE_NORMAL
- en: 5.6 Humor Comprehension Visualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figure  [2](#S5.F2 "Figure 2 ‣ 5.6 Humor Comprehension Visualization ‣ 5 Application
    ‣ DuanzAI: Slang-Enhanced LLM with Prompt for Humor Understanding") provides a
    visual representation of ChatDAI’s humor comprehension abilities. The graph showcases
    the chatbot’s proficiency in understanding and responding to various slang expressions,
    highlighting its capacity to navigate the intricacies of humor within the Chinese
    language.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b7f8aa2f45613370255a3148a7d516ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Chat with ChatDAI.'
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we pointed out that current large language models exhibit room
    for improvement in humor comprehension, addressed the understanding problem of
    Chinese humor and enhanced the humor comprehension abilities of large language
    models through the incorporation of carefully crafted prompt pipelines. The approach
    presented in this study establishes a solid baseline for future research endeavors
    aimed at refining and advancing the capabilities of language models in understanding
    humor, particularly in the context of Chinese linguistic expressions.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Annamoradnejad and Zoghi (2020) Iman Annamoradnejad and Ghazaleh Zoghi. 2020.
    Colbert: Using bert sentence embedding for humor detection. *arXiv preprint arXiv:2004.12765*,
    1(3).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bu and Cho (2018) Shi Jie Bu and Sang-Bum Cho. 2018. A hybrid deep learning
    system of cnn and lrcn to detect cyberbullying from sns comments. In *Hybrid Artificial
    Intelligent Systems*, pages 561–572\. Springer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (3) Frank A. Clark. I think the next best thing to solving a problem is finding
    some humor in it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dhuliawala et al. (2016) Shefali Dhuliawala, Debanjan Kanojia, and Pushpak
    Bhattacharyya. 2016. Slangnet: A wordnet like resource for english slang. In *Proceedings
    of the Tenth International Conference on Language Resources and Evaluation (LREC’16)*,
    pages 4329–4332.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gupta et al. (2019) Akshay Gupta, Sanya B Taneja, Gaurav Malik, Shruti Vij,
    Dinesh K Tayal, and Anjali Jain. 2019. Slangzy: A fuzzy logic-based algorithm
    for english slang meaning selection. *Progress in Artificial Intelligence*, 8:111–121.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hessel et al. (2023) Jack Hessel, Ana Marasovic, Jena D. Hwang, Lillian Lee,
    Jeff Da, Rowan Zellers, Robert Mankoff, and Yejin Choi. 2023. [Do androids laugh
    at electric sheep? humor “understanding” benchmarks from the new yorker caption
    contest](https://doi.org/10.18653/v1/2023.acl-long.41). In *Proceedings of the
    61st Annual Meeting of the Association for Computational Linguistics (Volume 1:
    Long Papers)*, pages 688–714, Toronto, Canada. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: iFLYTEK (2023) iFLYTEK. 2023. spark-ai-python. [https://github.com/iflytek/spark-ai-python](https://github.com/iflytek/spark-ai-python).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jurgens et al. (2017) David Jurgens, Yulia Tsvetkov, and Dan Jurafsky. 2017.
    Incorporating dialectal variability for socially equitable language identification.
    In *Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)*, pages 51–57.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Korolainen (2014) Ville Korolainen. 2014. Part-of-speech tagging in written
    slang. *Journal of Linguistics*, 50(2):343–371.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kulkarni and Wang (2018) Vivek Kulkarni and William Yang Wang. 2018. Simple
    models for word formation in slang. In *Proceedings of the 2018 Conference of
    the North American Chapter of the Association for Computational Linguistics: Human
    Language Technologies, Volume 1 (Long Papers)*, pages 1424–1434.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lafferty et al. (2001) John Lafferty, Andrew McCallum, and Fernando C Pereira.
    2001. Conditional random fields: Probabilistic models for segmenting and labeling
    sequence data. *Machine Learning*, 46(1-3):389–403.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: letiantian (2015) letiantian. 2015. Pinyin2hanzi. [https://github.com/letiantian/Pinyin2Hanzi](https://github.com/letiantian/Pinyin2Hanzi).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2022) Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li. 2022. [A
    survey on deep learning for named entity recognition](https://doi.org/10.1109/TKDE.2020.2981314).
    *IEEE Transactions on Knowledge and Data Engineering*, 34(1):50–70.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lourentzou et al. (2019) Ioannis Lourentzou, Kiran Manghnani, and ChengXiang
    Zhai. 2019. Adapting sequence to sequence models for text normalization in social
    media. In *Proceedings of the international AAAI conference on web and social
    media*, volume 13, pages 335–345.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mao and Liu (2019) Jie Mao and Wenbo Liu. 2019. A bert-based approach for automatic
    humor detection and scoring. In *IberLEF@SEPLN*, pages 197–202.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pal and Saha (2015) Anirban Roy Pal and Debajyoti Saha. 2015. Detection of slang
    words in e-data using semi-supervised learning. *arXiv preprint arXiv:1702.04241*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pei et al. (2019) Zhen Pei, Zhiyuan Sun, and Yang Xu. 2019. Slang detection
    and identification. *Proceedings of the 23rd Conference on Computational Natural
    Language Learning (CoNLL)*, pages 881–889.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2018) Lingfei Wu, Fred Morstatter, and Huan Liu. 2018. Slangsd:
    building, expanding and using a sentiment dictionary of slang words for short-text
    sentiment classification. *Language Resources and Evaluation*, 52:839–852.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeng et al. (2022) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b:
    An open bilingual pre-trained model. *arXiv preprint arXiv:2210.02414*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2015) Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level
    convolutional networks for text classification. *Advances in Neural Information
    Processing Systems*, 28:649–657.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
