# (超爽中英!) 2024吴恩达最好的【LangChain大模型应用开发】教程！附课件代码 DeepLearning.AI - P12：4——向量和嵌入 - 吴恩达大模型 - BV1iZ421M79T

![](img/351fb93d60a6130df964b235d2de5e90_0.png)

我们现在把文件分成了小的，语义有意义的块，是时候把这些块放入索引中了，在那里我们可以很容易地找回它们，当需要回答关于这个数据库的问题时，我们将利用嵌入和矢量存储，让我们看看这些是什么。

我们在上一节课中简要介绍过，但我们将重新审视它，原因有几个。

![](img/351fb93d60a6130df964b235d2de5e90_2.png)

第一批，这些对于在数据上构建聊天机器人非常重要。

![](img/351fb93d60a6130df964b235d2de5e90_4.png)

第二，我们要深入一点，我们将讨论边缘情况，这个通用方法实际上可能失败的地方。

![](img/351fb93d60a6130df964b235d2de5e90_6.png)

别担心，我们以后会解决的，但现在让我们讨论矢量存储和嵌入。

![](img/351fb93d60a6130df964b235d2de5e90_8.png)

这是在文本拆分之后出现的，当我们准备好以易于访问的格式存储文档时，什么是嵌入。

![](img/351fb93d60a6130df964b235d2de5e90_10.png)

他们拿了一条短信，他们创建了文本的数字表示。

![](img/351fb93d60a6130df964b235d2de5e90_12.png)

具有相似内容的文本将在此数字空间中具有相似的向量。

![](img/351fb93d60a6130df964b235d2de5e90_14.png)

意思就是，然后我们可以比较这些向量，找到相似的文本片段。

![](img/351fb93d60a6130df964b235d2de5e90_16.png)

所以在下面的例子中，我们可以看到这两个关于宠物的句子非常相似。

![](img/351fb93d60a6130df964b235d2de5e90_18.png)

而关于宠物的句子和关于汽车的句子不是很相似。

![](img/351fb93d60a6130df964b235d2de5e90_20.png)

作为完整端到端工作流的提醒，我们从文件开始。

![](img/351fb93d60a6130df964b235d2de5e90_22.png)

然后我们创建这些文档的较小拆分，然后我们创建这些文档的嵌入。

![](img/351fb93d60a6130df964b235d2de5e90_24.png)

然后我们把所有这些都存储在向量存储中，向量存储是一个数据库，您以后可以在其中轻松地查找类似的向量。

![](img/351fb93d60a6130df964b235d2de5e90_26.png)

当我们试图找到与手头问题相关的文档时，这将变得有用。

![](img/351fb93d60a6130df964b235d2de5e90_28.png)

然后我们就可以回答手头的问题了，创建嵌入，然后与向量存储中的所有不同向量进行比较。

![](img/351fb93d60a6130df964b235d2de5e90_30.png)

然后挑出最相似的末端，然后，我们把这些和大多数相似的块，把它们和问题一起传递给LLM，得到一个答案。

![](img/351fb93d60a6130df964b235d2de5e90_32.png)

我们稍后会讨论所有这些，现在是深入研究嵌入和矢量存储本身的时候了。

![](img/351fb93d60a6130df964b235d2de5e90_34.png)

开始，我们将再次设置适当的环境变量。

![](img/351fb93d60a6130df964b235d2de5e90_36.png)

从现在开始我们要处理同一套文件，这些是CS二十九节课，我们要装载，这里有几个，请注意，我们实际上要复制，第一讲，这是为了模拟一些脏数据。



![](img/351fb93d60a6130df964b235d2de5e90_38.png)

加载文档后，然后，我们可以使用递归字符文本拆分器来创建块。

![](img/351fb93d60a6130df964b235d2de5e90_40.png)

我们可以看到我们现在已经创造了200多个不同的块，是时候进入下一个部分并为所有这些创建嵌入了。

![](img/351fb93d60a6130df964b235d2de5e90_42.png)

在跳入真实世界的示例之前，我们将使用openai来创建这些嵌入。

![](img/351fb93d60a6130df964b235d2de5e90_44.png)

让我们用几个玩具测试用例来尝试一下。

![](img/351fb93d60a6130df964b235d2de5e90_46.png)

只是为了了解引擎盖下发生了什么，我们有几个例句，其中前两个非常相似。

![](img/351fb93d60a6130df964b235d2de5e90_48.png)

第三个是没有关系的。

![](img/351fb93d60a6130df964b235d2de5e90_50.png)

然后，我们可以使用嵌入类为每个句子创建嵌入。

![](img/351fb93d60a6130df964b235d2de5e90_52.png)

然后我们可以使用Numpy来比较它们，看看哪些是最相似的。

![](img/351fb93d60a6130df964b235d2de5e90_54.png)

我们期望前两句应该非常相似，然后第一个和第二个与第三个相比不应该几乎相似。

![](img/351fb93d60a6130df964b235d2de5e90_56.png)

我们将使用点积来比较两个嵌入。

![](img/351fb93d60a6130df964b235d2de5e90_58.png)

如果你不知道什么是点积，那很好，重要的是要知道越高越好。

![](img/351fb93d60a6130df964b235d2de5e90_60.png)

这里，我们可以看到前两个嵌入有一个相当高的分数点9。6。

![](img/351fb93d60a6130df964b235d2de5e90_62.png)

如果我们将第一个嵌入与第三个嵌入进行比较。

![](img/351fb93d60a6130df964b235d2de5e90_64.png)

我们可以看到它在点七明显较低，如果我们把第二个和第三个比较。

![](img/351fb93d60a6130df964b235d2de5e90_66.png)

我们可以看到它是正确的大约在点七六。

![](img/351fb93d60a6130df964b235d2de5e90_68.png)

现在是停顿一下，尝试一下你自己的句子的好时机，看看点积是什么。

![](img/351fb93d60a6130df964b235d2de5e90_70.png)

现在让我们回到现实世界的例子，现在是为PDF的所有块创建嵌入的时候了。

![](img/351fb93d60a6130df964b235d2de5e90_72.png)

然后把它们储存在一个矢量中，存储我们将在本课中使用的向量存储是色度，所以让我们导入莱恩链，它与30多个不同的矢量商店集成在一起。



![](img/351fb93d60a6130df964b235d2de5e90_74.png)

我们选择色度是因为它在内存中是轻量级的。

![](img/351fb93d60a6130df964b235d2de5e90_76.png)

这使得它很容易站起来开始。

![](img/351fb93d60a6130df964b235d2de5e90_78.png)

还有其他Vector商店提供托管解决方案，当您试图持久保存大量数据时，这可能很有用，或持久存在于云存储中。



![](img/351fb93d60a6130df964b235d2de5e90_80.png)

我们要把这个矢量存储保存在某个地方，这样我们就可以在以后的课程中使用它。

![](img/351fb93d60a6130df964b235d2de5e90_82.png)

因此，让我们创建一个名为持久化目录的变量，我们将在稍后的《色度博士》中使用。

![](img/351fb93d60a6130df964b235d2de5e90_84.png)

我们也要确保那里什么都没有。

![](img/351fb93d60a6130df964b235d2de5e90_86.png)

如果那里已经有东西了，它可以把东西扔掉，我们不希望这种情况发生。

![](img/351fb93d60a6130df964b235d2de5e90_88.png)

所以让我们rm破折号rf文档色度，只是为了确保那里什么都没有。

![](img/351fb93d60a6130df964b235d2de5e90_90.png)

现在让我们创建向量存储，所以我们从以分裂方式传递的文档中调用色度，这些是我们之前创建的分裂传递和嵌入。



![](img/351fb93d60a6130df964b235d2de5e90_92.png)

这是开放的AI嵌入模型，然后传入持久化目录，它是一个特定于色度的关键字参数，允许我们将目录保存到磁盘。



![](img/351fb93d60a6130df964b235d2de5e90_94.png)

![](img/351fb93d60a6130df964b235d2de5e90_95.png)

如果我们看看收集数，做完这个之后，我们可以看到它是二百零九，这和我们之前的分裂次数一样。

![](img/351fb93d60a6130df964b235d2de5e90_97.png)

让我们现在开始使用它，让我们想一个问题，我们可以问这个数据，我们知道这是关于一个课堂讲座。

![](img/351fb93d60a6130df964b235d2de5e90_99.png)

所以让我们问问是否有任何电子邮件可以寻求帮助，如果我们在课程或材料或类似的事情上需要任何帮助。

![](img/351fb93d60a6130df964b235d2de5e90_101.png)

我们将使用相似搜索法，我们将通过这个问题，然后我们也通过k等于三，这指定了我们要返回的文档数。

![](img/351fb93d60a6130df964b235d2de5e90_103.png)

所以如果我们运行它，我们看看文档的长度，所以我们可以看到它是我们指定的三个。

![](img/351fb93d60a6130df964b235d2de5e90_105.png)

如果我们看看第一份文件的内容。

![](img/351fb93d60a6130df964b235d2de5e90_107.png)

我们可以看到它实际上是关于一个电子邮件地址，CS二二九破折号QA CS，斯坦福，Edu，这是我们可以发送问题的电子邮件，所有的助教都读了，这样做之后，让我们确保保持向量数据库。

以便我们可以在以后的课程中使用它，通过运行向量db点持久化。

![](img/351fb93d60a6130df964b235d2de5e90_109.png)

这涵盖了语义搜索的基础知识，并向我们展示了我们可以仅仅基于嵌入就得到相当好的结果。

![](img/351fb93d60a6130df964b235d2de5e90_111.png)

但它并不完美，在这里，我们将讨论一些边缘案例，并展示它可能失败的地方。

![](img/351fb93d60a6130df964b235d2de5e90_113.png)

让我们尝试一个新问题，他们怎么说matlab，让我们运行这个指定k等于五的程序，并得到一些结果。

![](img/351fb93d60a6130df964b235d2de5e90_115.png)

如果我们看看前两个结果，我们可以看到它们实际上是相同的，这是因为当我们加载PDF时，如果你还记得我们故意指定，重复条目，这很糟糕，因为我们在两个不同的块中得到了相同的信息。

我们将把这两个块传递给语言模型，第二条信息没有真正的价值，如果有一个不同的，语言模型可以从中学习的不同块，我们下节课要讲的一件事，如何同时检索相关和不同的块，这是另一种类型的故障模式，也可能发生。



![](img/351fb93d60a6130df964b235d2de5e90_117.png)

让我们来看看这个问题，他们在第三堂课上对回归说了什么。

![](img/351fb93d60a6130df964b235d2de5e90_119.png)

当我们拿到文件的时候，直觉上，我们希望他们都是第三讲的一部分。

![](img/351fb93d60a6130df964b235d2de5e90_121.png)

我们可以检查这一点，因为我们在元数据中有关于它们来自哪些讲座的信息。

![](img/351fb93d60a6130df964b235d2de5e90_123.png)

因此，让我们循环所有文档并打印出元数据。

![](img/351fb93d60a6130df964b235d2de5e90_125.png)

我们可以看到实际上有一个结果的组合。

![](img/351fb93d60a6130df964b235d2de5e90_127.png)

第三讲的一些，有些是第二节课的，有些是第一节课的，关于为什么这是失败的直觉是，第三讲。

![](img/351fb93d60a6130df964b235d2de5e90_129.png)

事实上，我们只需要第三堂课的文档，这是一个结构化的信息。

![](img/351fb93d60a6130df964b235d2de5e90_131.png)

但我们只是在做一个基于嵌入的语义查找。

![](img/351fb93d60a6130df964b235d2de5e90_133.png)

它为整个句子创建了一个嵌入。

![](img/351fb93d60a6130df964b235d2de5e90_135.png)

它可能更专注于回归，因此，我们得到的结果可能与回归非常相关。

![](img/351fb93d60a6130df964b235d2de5e90_137.png)

所以如果我们看看第五个，做第一堂课的那个，我们可以看到它确实，事实上，提及回归，所以它开始注意到这一点，但它没有意识到这样一个事实，它只应该查询第三堂课的文件，因为再一次，这是一个结构化的信息。

并没有真正完美地捕捉到，我们创建的语义嵌入，现在是暂停并尝试更多查询的好时机，你还能注意到出现了哪些边缘情况，你也可以玩改变K，检索的文档数，正如你可能已经注意到的，在本课中，我们先用了三个。

然后用了五个，你可以试着把它调整成你想要的任何东西，你可能会注意到，当你把它做大的时候，您将检索更多的文档，但结尾的文件可能不如开头的文件相关，现在我们已经介绍了语义搜索的基础知识，以及一些失效模式。

让我们继续下一节课。