# LangChain_微调ChatGPT提示词_RAG模型应用_agent_生成式AI - P36：4——向量和嵌入 - 吴恩达大模型 - BV1gLeueWE5N

![](img/0a1504e4d52443086f49c2f919757e43_0.png)

我们现在已经将文档分成了小的，语义上有意义的片段，现在是将这些片段放入索引的时候，这样我们就可以轻松地检索它们，当需要回答关于这个数据集的问题时，我们将利用嵌入和向量存储。

让我们看看那些是什么我们之前在之前的课程中简要覆盖了，但我们将再次回顾它，有几个原因。

![](img/0a1504e4d52443086f49c2f919757e43_2.png)

首先，这些对于在你的数据上构建聊天机器人来说至关重要。

![](img/0a1504e4d52443086f49c2f919757e43_4.png)

其次，我们将深入探讨，并谈论边缘情况，以及这个通用方法实际上可以失败的地方。

![](img/0a1504e4d52443086f49c2f919757e43_6.png)

不要担心，我们将在后来修复这些问题，但现在让我们谈谈向量存储和嵌入。

![](img/0a1504e4d52443086f49c2f919757e43_8.png)

这发生在文本分割之后，当我们准备好以易于访问的格式存储文档时，什么是嵌入。

![](img/0a1504e4d52443086f49c2f919757e43_10.png)

它们将一段文本，并创建该文本的数值表示。

![](img/0a1504e4d52443086f49c2f919757e43_12.png)

与内容相似的文本将在这个数值空间中有相似的向量。

![](img/0a1504e4d52443086f49c2f919757e43_14.png)

这意味着，我们可以然后比较那些向量并找到相似的文本部分。

![](img/0a1504e4d52443086f49c2f919757e43_16.png)

例如，在下面的例子中，我们可以看到关于宠物的两句话非常相似。

![](img/0a1504e4d52443086f49c2f919757e43_18.png)

而在关于汽车的句子中提到宠物的句子并不相似。

![](img/0a1504e4d52443086f49c2f919757e43_20.png)

作为对完整工作流程的全面回顾，我们开始与文档。

![](img/0a1504e4d52443086f49c2f919757e43_22.png)

然后创建这些文档的较小分割，然后创建这些文档的嵌入。

![](img/0a1504e4d52443086f49c2f919757e43_24.png)

并将所有这些都存储在向量存储中，向量存储是一种数据库，您可以在其中后来轻松地查找相似的向量。

![](img/0a1504e4d52443086f49c2f919757e43_26.png)

这将在尝试找到与手头问题相关的文档时非常有用。

![](img/0a1504e4d52443086f49c2f919757e43_28.png)

我们可以然后处理手头的问题，创建一个嵌入，然后与向量存储中的所有不同向量进行比较。

![](img/0a1504e4d52443086f49c2f919757e43_30.png)

然后选择最相似的一个，我们然后取这些和最相似的片段，并将它们与问题一起传递给llm，并得到答案。

![](img/0a1504e4d52443086f49c2f919757e43_32.png)

我们将稍后覆盖所有这些，现在，是我们深入探讨嵌入和向量存储本身的时候。

![](img/0a1504e4d52443086f49c2f919757e43_34.png)

首先，我们将再次设置适当的环境变量。

![](img/0a1504e4d52443086f49c2f919757e43_36.png)

从这里开始，我们将与相同的一组文档工作，这些是cs two twenty九的讲座，我们将加载，其中一些在这里，注意，我们将实际上复制，第一堂课，这是为了模拟一些脏数据。



![](img/0a1504e4d52443086f49c2f919757e43_38.png)

文档加载后，我们可以然后使用递归字符文本分割器创建块。

![](img/0a1504e4d52443086f49c2f919757e43_40.png)

我们可以看到，我们已经创建了超过二百个不同的分块，是时候转向下一个部分并为它们创建嵌入式向量了。

![](img/0a1504e4d52443086f49c2f919757e43_42.png)

我们将使用openai来创建这些嵌入式向量，然后在实际世界中跳入。

![](img/0a1504e4d52443086f49c2f919757e43_44.png)

让我们尝试使用几个玩具测试案例。

![](img/0a1504e4d52443086f49c2f919757e43_46.png)

只是为了了解引擎内部的情况，我们有一些示例句子，其中前两句非常相似。

![](img/0a1504e4d52443086f49c2f919757e43_48.png)

而第三句与前两句无关。

![](img/0a1504e4d52443086f49c2f919757e43_50.png)

然后，我们可以使用嵌入类为每个句子创建嵌入式向量。

![](img/0a1504e4d52443086f49c2f919757e43_52.png)

然后，我们可以使用numpy来比较它们并看到哪些最相似。

![](img/0a1504e4d52443086f49c2f919757e43_54.png)

我们预期前两句应该非常相似，然后，第一和第二与第三相比不应该那么相似。

![](img/0a1504e4d52443086f49c2f919757e43_56.png)

我们将使用点积来比较两个嵌入式向量。

![](img/0a1504e4d52443086f49c2f919757e43_58.png)

如果你不知道点积是什么，没关系，重要的是要知道，更高的分数越好。

![](img/0a1504e4d52443086f49c2f919757e43_60.png)

在这里，我们可以看到，第一个和第二个嵌入式向量有一个相当高的得分为9。6。

![](img/0a1504e4d52443086f49c2f919757e43_62.png)

如果我们比较第一个嵌入式向量与第三个嵌入式向量。

![](img/0a1504e4d52443086f49c2f919757e43_64.png)

我们可以看到，它显著低于7。7，如果比较第二个与第三个。

![](img/0a1504e4d52443086f49c2f919757e43_66.png)

我们可以看到，它大约相同于7。6。

![](img/0a1504e4d52443086f49c2f919757e43_68.png)

现在是一个暂停并尝试自己几句的好时机，并看看点积是什么。

![](img/0a1504e4d52443086f49c2f919757e43_70.png)

现在让我们回到实际世界的例子，是时候为pdf块的所有部分创建嵌入式向量了。

![](img/0a1504e4d52443086f49c2f919757e43_72.png)

然后存储它们为向量，我们将用于本课程的向量存储是chroma，所以让我们导入它lane chain与超过三十个向量存储有集成。



![](img/0a1504e4d52443086f49c2f919757e43_74.png)

我们选择chroma因为它在内存中轻量级。

![](img/0a1504e4d52443086f49c2f919757e43_76.png)

这使得它非常容易开始使用。

![](img/0a1504e4d52443086f49c2f919757e43_78.png)

还有其他向量存储提供托管解决方案，这可能在您试图持久大量数据时非常有用，或持久在云存储中。

![](img/0a1504e4d52443086f49c2f919757e43_80.png)

我们将想在某个地方保存这个向量存储，以便我们在未来课程中使用它。

![](img/0a1504e4d52443086f49c2f919757e43_82.png)

所以让我们创建一个变量叫做持久目录，我们将在后续的doc chroma中使用它。

![](img/0a1504e4d52443086f49c2f919757e43_84.png)

让我们也确保那里什么都没有。

![](img/0a1504e4d52443086f49c2f919757e43_86.png)

如果有东西在那里，可能会引起问题，我们不想要那样。

![](img/0a1504e4d52443086f49c2f919757e43_88.png)

所以让我们rm dash rf docs chroma，只是为了确保那里什么都没有。

![](img/0a1504e4d52443086f49c2f919757e43_90.png)

现在让我们创建向量存储，所以我们从文档中调用chroma，传递分裂，这些是我们 earlier 创造的分裂，传递嵌入。



![](img/0a1504e4d52443086f49c2f919757e43_92.png)

这是开放AI嵌入模型，然后，我们将传入持久目录，这是一个chroma特定的关键字参数，允许我们将目录保存到磁盘。



![](img/0a1504e4d52443086f49c2f919757e43_94.png)

![](img/0a1504e4d52443086f49c2f919757e43_95.png)

如果我们看一下集合计数，做完这个之后，我们可以看到它是209，这与我们从前的分裂数相同。

![](img/0a1504e4d52443086f49c2f919757e43_97.png)

现在让我们开始使用它，让我们思考一个问题，我们可以问这个数据，我们知道这是关于一堂课的。

![](img/0a1504e4d52443086f49c2f919757e43_99.png)

所以让我们问是否有我们可以寻求帮助的电子邮件，如果我们需要关于课程或材料的任何帮助。

![](img/0a1504e4d52443086f49c2f919757e43_101.png)

我们将使用相似性搜索方法，我们将传递问题，然后，我们还将传递k等于3，这指定我们要返回的文档数量。

![](img/0a1504e4d52443086f49c2f919757e43_103.png)

如果我们运行那个，然后我们看文档的长度，我们可以看到它是3，因为我们指定的。

![](img/0a1504e4d52443086f49c2f919757e43_105.png)

如果我们看第一个文档的内容。

![](img/0a1504e4d52443086f49c2f919757e43_107.png)

我们可以看到它实际上关于电子邮件地址，cs2-299-dash-qa-cs，斯坦福，edu，这是我们可以发送问题的电子邮件地址，并且由所有tas阅读，做完之后，让我们确保持久向量数据库。

以便我们可以在未来的课程中使用它，通过运行向量db。dot。persist。

![](img/0a1504e4d52443086f49c2f919757e43_109.png)

这覆盖了语义搜索的基本知识，并展示了我们可以仅基于嵌入物就得到很好的结果。

![](img/0a1504e4d52443086f49c2f919757e43_111.png)

但它不是完美的，在这里，我们将讨论几个边缘情况并显示在哪里这可能会失败。

![](img/0a1504e4d52443086f49c2f919757e43_113.png)

让我们尝试一个新问题，他们对matlab说了什么，让我们运行这个，指定k等于5，并获取一些结果。

![](img/0a1504e4d52443086f49c2f919757e43_115.png)

如果我们看第一个两个结果，我们可以看到它们实际上是相同的，这是因为当我们加载pdfs时，如果你记得我们特意指定，一个重复项，这是很糟糕的，因为我们在同一个部分中有相同的信息。

我们将这两个部分都传递给语言模型往下游，第二个部分的信息并没有真正的价值，而且如果存在一个不同，独特的部分，语言模型可以从中学习，在下一节课中，我们将覆盖如何同时获取相关和独特的部分。

这是另一种可能会发生的失败模式，让我们看看这个问题。

![](img/0a1504e4d52443086f49c2f919757e43_117.png)

他们在第三堂课中说了什么关于回归的内容。

![](img/0a1504e4d52443086f49c2f919757e43_119.png)

当我们得到这些文档时，直觉上，我们预期它们应该都是第三堂课的一部分。

![](img/0a1504e4d52443086f49c2f919757e43_121.png)

我们可以检查这个，因为元数据中包含了它们来自哪些讲座的信息。

![](img/0a1504e4d52443086f49c2f919757e43_123.png)

所以让我们遍历所有文档并打印出元数据。

![](img/0a1504e4d52443086f49c2f919757e43_125.png)

我们可以看到实际上有一组结果。

![](img/0a1504e4d52443086f49c2f919757e43_127.png)

一些来自第三堂课，一些来自第二堂课，还有一些来自第一堂课，关于为什么这失败直觉的原因是第三堂课。

![](img/0a1504e4d52443086f49c2f919757e43_129.png)

以及我们想要只从第三堂课获取文档的事实是一段结构化信息。

![](img/0a1504e4d52443086f49c2f919757e43_131.png)

但我们只是在基于嵌入的语义查找上做。

![](img/0a1504e4d52443086f49c2f919757e43_133.png)

它为整个句子创建了一个嵌入。

![](img/0a1504e4d52443086f49c2f919757e43_135.png)

而且它可能更专注于回归，因此我们得到的结果可能对回归非常相关。

![](img/0a1504e4d52443086f49c2f919757e43_137.png)

所以如果我们看第五个，查看来自第一堂课的那个，我们可以看到它确实，实际上，提到了回归，所以它捕捉到了这个，但它没有捕捉到事实，它只应该查询来自第三堂课的文档，因为再次，这是一段结构化信息。

并不是我们创建的语义嵌入完全捕捉的，现在是个好时机暂停并尝试一些更多的查询，你还能注意到哪些边缘情况出现，你也可以尝试改变k，你检索的文档数量，正如你在这堂课中注意到的，我们使用了前三个，然后五个。

你可以尝试调整它成为你想要的任何数字，你可能注意到当你使它更大时，你将检索更多的文档，但是那个尾端的文档可能不如开始的那些相关，现在，我们覆盖了语义搜索的基本知识，以及一些失败模式，让我们继续下一堂课。

我们将讨论如何解决这些失败模式并增强我们的检索，让我们转到下一堂课。