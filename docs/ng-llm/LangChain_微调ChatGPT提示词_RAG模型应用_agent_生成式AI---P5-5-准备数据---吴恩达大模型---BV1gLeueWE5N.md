# LangChain_微调ChatGPT提示词_RAG模型应用_agent_生成式AI - P5：5-准备数据 - 吴恩达大模型 - BV1gLeueWE5N

![](img/04be87adea703493c4bb301f9c54bbfa_0.png)

探索数据后，将学习如何准备数据训练，让我们开始，接下来，需要准备哪种数据，有一些好的最佳实践，其一，需要高质量数据，这是微调所需的第一要素，而非低质量数据，我指的是，即，如果你给定，垃圾输入。

它会尝试模仿并给出垃圾输出，因此，提供高质量数据很重要，其次是多样性，拥有多样化的数据，覆盖用例的许多方面是有帮助的，如果所有输入和输出都相同，模型可能会开始记忆它们，如果这不是你想要的。

模型将开始只重复相同的东西，因此，数据多样性非常重要，真实或生成，我知道有很多方法可以创建生成数据，你已经看到了一种使用LLM的方式，但实际上拥有真实数据非常，非常有效和有帮助，特别是对于写作任务。

因为生成数据已经具有某些模式，你可能听说过一些服务试图检测，某物是否为生成，实际上是因为生成数据中有他们试图检测的模式，因此，如果你训练更多的相同模式，它不一定能学习新的模式或新的表达方式。

最后我把它放在最后，因为在大多数机器学习应用中，拥有更多数据比拥有更少数据更重要，但正如你刚才看到的，预训练处理了大部分这个问题，预训练从大量数据中学习，来自互联网的所有数据。

所以它已经有一个很好的基础理解，它不是从零开始的，因此，更多数据对模型有帮助，但不如前三项重要。

![](img/04be87adea703493c4bb301f9c54bbfa_2.png)

肯定不如质量重要，首先，让我们回顾一下收集数据的步骤，你已经看到了一些指令响应对，第一步是收集它们，下一步是将这些对连接起来，或添加提示模板，你已见过，下一步是分词数据，添加填充，或截断数据。

确保模型输入正确大小，实验室中会展示如何分词，准备数据步骤：一是收集指令响应对，可能是问答对，然后拼接这些对，或添加如前的提示模板，最后一步是分割数据为训练和测试。



![](img/04be87adea703493c4bb301f9c54bbfa_4.png)

分词什么？那真正意味着什么？嗯，分词你的数据是将文本数据，实际转换为代表每个文本片段的数字，不一定是按单词，基于常见字符出现频率，在这种情况下，我最喜欢的是img标记，这在分词器中很常见。

因为那发生在每个中，在这里你可以看到微调，我g，所以每个你知道的动词在jd中，你知道微调或分词都有img，这映射到标记278，当你用相同的分词器解码时，它会变回相同的文本，现在有很多不同的分词器。

分词器实际上与特定模型相关，因为它是在其上训练的，如果你给模型错误的分词器，它会非常困惑，因为它会期望不同的数字代表不同的字母集和单词，确保使用正确的分词器，实验室中会很容易展示如何做到这一点，酷。



![](img/04be87adea703493c4bb301f9c54bbfa_6.png)

让我们转到笔记本，好的，首先我们将导入几个不同的库，实际上最重要的是这里看到的auto tokenizer类，来自transformers库。



![](img/04be87adea703493c4bb301f9c54bbfa_8.png)

由hugging face，它做得很棒，并且当您仅指定模型时，它会自动找到正确的分词器，你所要做的就是输入模型名称，这是之前看到的相同模型名称，是一个7000万基于Python的模型。

所以也许你有段文字，你知道 嗨，你怎么样 现在，让我们分词那段文字，所以放那 砰，所以让我们看看编码文本是什么 好吧，所以那是不同的数字代表文本这里，分词器输出一个字典 包含输入ID 代表标记。

所以我只是打印那这里，然后让我们实际解码那回到文本。

![](img/04be87adea703493c4bb301f9c54bbfa_10.png)

看看它是否实际转回 嗨，你怎么样 酷。

![](img/04be87adea703493c4bb301f9c54bbfa_12.png)

棒极了，它转回 嗨，你怎么样，所以，那太棒了，好吧，所以在分词时 你大概在放入批量的输入。

![](img/04be87adea703493c4bb301f9c54bbfa_14.png)

所以让我们就看看几个不同的输入一起。

![](img/04be87adea703493c4bb301f9c54bbfa_16.png)

所以有 嗨，你怎么样，我很好，还有 是，所以把列表的文本通过，你可以就这样放入一个批 到分词器，你得到一些不同东西这里，所以这里是 嗨，你怎么样 再次，我很好 更小，还有 是，它只是一个标记。

所以你可以看到这些长度在变化，实际上 对模型来说 真正重要的是，批中的所有东西是相同长度，因为你操作的是固定大小的张量，所以文本需要是相同的，所以我们会做的一件事 叫做填充。

填充是一种策略 来处理这些可变长度的编码文本，对于填充标记 你必须指定，你知道 你想，什么数字你想代表 对于填充，并且具体我们使用零，实际上也是句末标记，所以当我们运行 填充等于真 通过分词器。

你可以看到 是 字符串有很多零填充那里 在右边，只是为了匹配 这个 嗨，你怎么样 u 字符串，你的模型也会有最大长度 它可以处理和接收，所以它不能只是适应所有东西，你以前玩过提示。

你可能注意到提示长度有限，这也是同样的事，截断是一种处理方法，使编码文本更短，实际上适合模型。

![](img/04be87adea703493c4bb301f9c54bbfa_18.png)

所以这是一种缩短方法，如你所见，我只是人为地将最大长度改为3，将截断设为真。

![](img/04be87adea703493c4bb301f9c54bbfa_20.png)

现在对hi来说它短多了，你好吗，从右边截断，所以右边全删了，实际上很常见的是，你知道你在写，也许你的指示在某处，有很多重要的东西，可能在另一边，在右边。



![](img/04be87adea703493c4bb301f9c54bbfa_22.png)

那被截断了，所以你知道，指定截断侧向左实际上可以反方向截断。

![](img/04be87adea703493c4bb301f9c54bbfa_24.png)

这确实取决于你的任务，和，实际上对于填充和截断。

![](img/04be87adea703493c4bb301f9c54bbfa_26.png)

你想使用螺栓，所以让我们实际上设置两者，所以截断为真，填充为真。

![](img/04be87adea703493c4bb301f9c54bbfa_28.png)

并打印出来，所以你可以看到这里的零，但也截断到三个伟大，那真是个玩具例子，现在粘贴你在上次实验中做的代码。



![](img/04be87adea703493c4bb301f9c54bbfa_30.png)

所以这里加载了包含问题和答案的数据集文件。

![](img/04be87adea703493c4bb301f9c54bbfa_32.png)

放入提示，给这些提示补水。

![](img/04be87adea703493c4bb301f9c54bbfa_34.png)

一次全部完成，所以现在你可以看到一个数据点的问答。

![](img/04be87adea703493c4bb301f9c54bbfa_36.png)

所以现在你可以运行这个分词器在一个数据点上，所以首先将那个问题和答案连接起来，然后通过分词器运行，这里仅将张量作为numpy数组返回。



![](img/04be87adea703493c4bb301f9c54bbfa_38.png)

为了简单起见，仅使用填充运行，那是因为我不知道这些令牌实际上会有多长，重要的是。

![](img/04be87adea703493c4bb301f9c54bbfa_40.png)

然后我确定你知道的最小值是最大长度和标记化输入之间。

![](img/04be87adea703493c4bb301f9c54bbfa_42.png)

当然，你总是可以填充到最长，你总是可以填充到最大长度，所以这就是这里的原因，嗯，然后我再用截断方式处理到那个最大长度，让我打印出来。



![](img/04be87adea703493c4bb301f9c54bbfa_44.png)

![](img/04be87adea703493c4bb301f9c54bbfa_45.png)

只需从字典指定，很酷，这就是令牌的样子，对吧，现在让我们实际将其包装成一个完整的函数。

![](img/04be87adea703493c4bb301f9c54bbfa_47.png)

这样您就可以将其运行通过整个数据集，这又是，这里正在发生与您已经查看的相同的事情，获取最大长度。

![](img/04be87adea703493c4bb301f9c54bbfa_49.png)

设置截断侧，这是一个用于标记数据集的功能，现在您可以做的是。

![](img/04be87adea703493c4bb301f9c54bbfa_51.png)

您可以加载该数据集，这里有一个很棒的地图函数，因此，您可以映射标记化函数到该数据集上，您将看到这里，我在做非常简单的操作，因此，我将批量大小设置为1，非常简单，它将按批次处理并丢弃最后一个批次为真。



![](img/04be87adea703493c4bb301f9c54bbfa_53.png)

这通常是您知道我们为处理混合大小输入而做的事情，因此，最后一个批次可能具有不同的不同大小。

![](img/04be87adea703493c4bb301f9c54bbfa_55.png)

很好，然后下一步是分割数据集。

![](img/04be87adea703493c4bb301f9c54bbfa_57.png)

因此，首先我必须添加这个标签列，以便hugging face可以处理它，然后我将运行此train_test_split函数，并将测试大小指定为数据集的10％，当然，您可以更改此值，取决于您的数据集大小。

shuffles为真，因此，我在随机化这个数据集顺序，我只是在这里打印出来。

![](img/04be87adea703493c4bb301f9c54bbfa_59.png)

因此，您现在可以看到数据集已跨，训练和测试集在一百四十个测试集中，当然，这已经在hugging face中加载，就像您之前看到的那样，因此，您可以前往那里并下载它，看看它是相同的。



![](img/04be87adea703493c4bb301f9c54bbfa_61.png)

因此，虽然这是一个专业数据集，它是关于一家公司，也许这与您的公司有关，例如，您可以将其适应于您的公司，我们认为这可能会有点无聊，它不必如此，因此，我们包含了一些其他有趣的数据集，您也可以与之合作。

并随时自定义和训练您的模型以适应这些，而不是，一个是关于泰勒·斯威夫特，一个是关于流行乐队BTS，另一个是关于实际上开源的大型语言模型，您可以玩并查看。



![](img/04be87adea703493c4bb301f9c54bbfa_63.png)

您知道，来自泰·泰数据集的一个数据点。

![](img/04be87adea703493c4bb301f9c54bbfa_65.png)

让我们看看好吧，千禧一代中最受欢迎的泰勒·斯威夫特歌曲是什么，一首歌如何与千禧一代相关，好的，好的，你可以自己看看这个，是的，这些数据集可通过Hugging Face获取，接下来在下一个实验中。

现在你已准备好所有数据并进行了分词。