# LangChain_微调ChatGPT提示词_RAG模型应用_agent_生成式AI - P38：6——问答聊天机器人 - 吴恩达大模型 - BV1gLeueWE5N

![](img/8fdba8c04f845e8d78897dbf4b174b32_0.png)

已讲解如何检索相关文档，下一步是处理这些文档，取原始问题，连同文档一起给语言模型，让它回答问题，本课将讲解及几种方法，让我们开始这节课。



![](img/8fdba8c04f845e8d78897dbf4b174b32_2.png)

将讲解如何用已检索文档，回答问题，在完成存储和导入后，获取相关切分后，需传入语言模型得答案。

![](img/8fdba8c04f845e8d78897dbf4b174b32_4.png)

流程大致如下，问题输入。

![](img/8fdba8c04f845e8d78897dbf4b174b32_6.png)

查找相关文档，然后传入这些切分，连同系统提示和问题。

![](img/8fdba8c04f845e8d78897dbf4b174b32_8.png)

语言模型给出答案，默认情况下，所有块放入同一上下文，进入语言模型的呼唤。

![](img/8fdba8c04f845e8d78897dbf4b174b32_10.png)

但有几种不同方法，各有优缺点。

![](img/8fdba8c04f845e8d78897dbf4b174b32_12.png)

大部分优点来自有时会有很多文档，你无法将它们全部放入同一上下文中。

![](img/8fdba8c04f845e8d78897dbf4b174b32_14.png)

Mapreduce，精炼。

![](img/8fdba8c04f845e8d78897dbf4b174b32_16.png)

今天课程中我们将涵盖其中一些，开始编码。

![](img/8fdba8c04f845e8d78897dbf4b174b32_18.png)

首先，我们将加载环境变量。

![](img/8fdba8c04f845e8d78897dbf4b174b32_20.png)

然后加载之前持久化的向量数据库，我将检查其正确性。

![](img/8fdba8c04f845e8d78897dbf4b174b32_22.png)

可见与之前相同，有209个文档。

![](img/8fdba8c04f845e8d78897dbf4b174b32_24.png)

快速检查相似性搜索，确保为第一个问题工作：本课程的主要主题是什么。

![](img/8fdba8c04f845e8d78897dbf4b174b32_26.png)

现在初始化将用于回答问题的语言模型。

![](img/8fdba8c04f845e8d78897dbf4b174b32_28.png)

我们将使用Chat Open AI模型gpt 3。5。

![](img/8fdba8c04f845e8d78897dbf4b174b32_30.png)

并将温度设置为0，当我们需要事实答案时，这非常好。

![](img/8fdba8c04f845e8d78897dbf4b174b32_32.png)

因其变化性低，通常提供最高保真度，最可靠答案。

![](img/8fdba8c04f845e8d78897dbf4b174b32_34.png)

然后导入检索QA链，这是基于检索的问题解答，由检索步骤支持。

![](img/8fdba8c04f845e8d78897dbf4b174b32_36.png)

可通过传入语言模型创建。

![](img/8fdba8c04f845e8d78897dbf4b174b32_38.png)

然后向量数据库作为检索器。

![](img/8fdba8c04f845e8d78897dbf4b174b32_40.png)

然后可调用它，查询等于要问的问题。

![](img/8fdba8c04f845e8d78897dbf4b174b32_42.png)

查看结果，我们得到一个答案，本课主要话题是机器学习，此外，讨论部分可能会复习统计和代数。

![](img/8fdba8c04f845e8d78897dbf4b174b32_44.png)

本季度晚些时候，讨论部分还将涵盖主要讲座材料的外延。

![](img/8fdba8c04f845e8d78897dbf4b174b32_46.png)

让我们试着更好地理解，底层发生了什么，并揭示一些主要部分的调整旋钮，重要的是我们使用的提示，这是接受文档和问题并将其传递给语言模型的提示。



![](img/8fdba8c04f845e8d78897dbf4b174b32_48.png)

关于提示的复习。

![](img/8fdba8c04f845e8d78897dbf4b174b32_50.png)

可以查看我与安德鲁的第一堂课，这里我们定义了一个提示模板。

![](img/8fdba8c04f845e8d78897dbf4b174b32_52.png)

有一些关于如何使用以下上下文片段的说明，然后它有一个上下文变量的占位符，这是文档将放置的地方，还有一个问题变量的占位符。



![](img/8fdba8c04f845e8d78897dbf4b174b32_54.png)

我们现在可以创建一个新的检索，Qn，我们将使用与之前相同的语言模型，与之前相同的向量数据库，但我们将传递一些新的参数，所以我们有返回源文档，所以我们将此设置为真，这将使我们能够轻松检查检索到的文档。



![](img/8fdba8c04f845e8d78897dbf4b174b32_56.png)

然后我们还将传递一个提示。

![](img/8fdba8c04f845e8d78897dbf4b174b32_58.png)

等于qa链，上面定义的提示，让我们尝试一个新问题是概率，一个课程主题。

![](img/8fdba8c04f845e8d78897dbf4b174b32_60.png)

我们得到一个结果，如果我们检查里面的内容，我们可以看到是的，概率被认为是课程的前提。

![](img/8fdba8c04f845e8d78897dbf4b174b32_62.png)

讲师假设对基本概率统计熟悉，我们将在讨论部分复习一些先决条件，作为复习课程，谢谢提问回答我们也很高兴，为了更好地理解它从哪里获取数据。



![](img/8fdba8c04f845e8d78897dbf4b174b32_64.png)

我们可以看一下返回的源文档。

![](img/8fdba8c04f845e8d78897dbf4b174b32_66.png)

如果你浏览它们，你应该看到所有被回答的信息都在这些源文档之一中，现在是一个暂停并尝试一些不同问题的好时机，或者你自己的不同提示模板，看看结果如何变化。



![](img/8fdba8c04f845e8d78897dbf4b174b32_68.png)

我们一直在使用stuff技术，我们默认使用的技术，基本上只是把所有文档都塞入最终提示中，这真的很好因为它只涉及一次对语言模型的调用，然而，这也有一个限制，如果有太多的文档。



![](img/8fdba8c04f845e8d78897dbf4b174b32_70.png)

它们可能无法全部放入上下文窗口，我们可以使用的不同技术，文档问答中的mapreduce技术，每个文档先单独送至语言模型。



![](img/8fdba8c04f845e8d78897dbf4b174b32_72.png)

然后这些答案组合成最终答案。

![](img/8fdba8c04f845e8d78897dbf4b174b32_74.png)

这涉及更多语言模型的调用，但它可以处理任意多文档。

![](img/8fdba8c04f845e8d78897dbf4b174b32_76.png)

运行前一个问题，可看到此方法的另一个限制，实际上可以看到两个，它要慢得多，二，结果实际上更糟，这个问题没有明确答案，根据文档的部分内容，这可能是因为它基于每个文档单独回答。



![](img/8fdba8c04f845e8d78897dbf4b174b32_78.png)

因此，如果信息分散在两个文档中，它没有在同一上下文中拥有所有信息。

![](img/8fdba8c04f845e8d78897dbf4b174b32_80.png)

这是一个使用车道链平台获得更好理解的机会，关于这些链条内部正在发生的事情。

![](img/8fdba8c04f845e8d78897dbf4b174b32_82.png)

我们将在此处演示，如果你想自己使用。

![](img/8fdba8c04f845e8d78897dbf4b174b32_84.png)

课程材料中有说明，如何获取API密钥，设置这些环境变量后，我们可以重新运行映射，减少链，然后我们可以切换到UI查看。



![](img/8fdba8c04f845e8d78897dbf4b174b32_86.png)

内部，从这里可以找到刚运行的运行。

![](img/8fdba8c04f845e8d78897dbf4b174b32_88.png)

我们可以点击查看输入和输出，然后可看到孩子跑分析，内部，首先，有MapReduce文档链，实际涉及4次语言模型调用。



![](img/8fdba8c04f845e8d78897dbf4b174b32_90.png)

若点击其中一个调用，可看到每个文档的输入和输出。

![](img/8fdba8c04f845e8d78897dbf4b174b32_92.png)

若返回，然后可看到遍历每个文档后，最终合并为链，将所有回复填入最终调用的填充文档链，点击进入。

![](img/8fdba8c04f845e8d78897dbf4b174b32_94.png)

我们看到系统消息，来自先前文档的4个摘要，然后使用你的问题，然后有答案在那里，我们可以做类似的事情，将链类型设置为细化。



![](img/8fdba8c04f845e8d78897dbf4b174b32_96.png)

这是一种新的链类型，让我们看看内部是什么样子，我们看到它在调用精炼文档链，涉及对llm链的四个连续调用，让我们看看这个链中的第一个调用，看看这里发生了什么，在发送给语言模型之前，我们有提示。

我们可以看到一个由几部分组成的系统消息，此上下文信息在下面的部分，是系统消息的一部分，它是我们提前定义的提示模板的一部分，接下来的这部分，所有这些文本，这是我们检索到的其中一个文档，下面是用户问题。

然后这里是答案，如果我们回到前面，我们可以看看对语言模型的下一个调用，发送给语言模型的最终提示，是一个将先前响应与新数据组合的序列，然后请求改进的响应，所以我们可以看到，我们有了原始用户问题。

然后我们有了答案，这跟之前的一样，然后我们说我们有机会仅用下面的更多上下文改进现有答案，如果需要的话，这是提示模板的一部分，一部分指令，其余部分是我们在列表中检索到的第二个文档，然后我们可以看到。

在新的上下文中，我们有一些额外的指令，改进原始答案以更好地回答问题，然后在下面我们得到了最终答案，但这是第二个最终答案，这个过程运行四次，在所有文档之前运行，然后到达最终答案，最终的答案就在这里。

课程假设熟悉基本概率和统计，但我们将有复习部分来刷新先决条件，你会发现这比MapReduce链更好，因为使用精炼链确实允许你组合信息，尽管是顺序的，它实际上比MapReduce链更鼓励信息的传递。

这是一个暂停的好机会，尝试一些问题，尝试不同的链，尝试不同的提示模板，看看它在UI中看起来像什么，这里有很多可以玩的东西，聊天机器人的一大优点，也是它们越来越受欢迎的原因之一是你可以问后续问题。



![](img/8fdba8c04f845e8d78897dbf4b174b32_98.png)

你可以要求对之前的答案进行澄清，所以让我们在这里这样做，创建问答链，使用默认内容。

![](img/8fdba8c04f845e8d78897dbf4b174b32_100.png)

问它，问题概率，课程主题。

![](img/8fdba8c04f845e8d78897dbf4b174b32_102.png)

然后问后续问题，提到概率是前提，然后问，为何需要前提，得到答案，课程前提是计算机基础，和之前无关的计算机技能，我们问概率，怎么回事，我们用的链无状态概念，不记得先前问题或答案，需引入记忆。



![](img/8fdba8c04f845e8d78897dbf4b174b32_104.png)