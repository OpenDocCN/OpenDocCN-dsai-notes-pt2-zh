# LangChain_微调ChatGPT提示词_RAG模型应用_agent_生成式AI - P2：2-为什么要微调 - 吴恩达大模型 - BV1gLeueWE5N

本课将学习为何要微调，微调究竟为何，与提示工程比较，并通过一个实验，比较微调与未微调模型，酷，让我们开始吧，为何要微调LLMs？



![](img/5f94026aeaa256766103d6bad461c9a7_1.png)

为何，先谈谈微调是什么。

![](img/5f94026aeaa256766103d6bad461c9a7_3.png)

这些通用模型如何微调，如GPT-3，专化为类似ChatGPT。

![](img/5f94026aeaa256766103d6bad461c9a7_5.png)

特定聊天用途，使其聊天流畅，或使用GPT-4，将其转换为。

![](img/5f94026aeaa256766103d6bad461c9a7_7.png)

GitHub Copilot专用案例以自动完成代码，我喜欢做的类比是PCP，初级保健医生就像你的通用模型，你每年去看你的PCP进行全面检查，但微调或专业模型就像心脏病专家或皮肤科医生。



![](img/5f94026aeaa256766103d6bad461c9a7_9.png)

一位具有特定专业并能真正照顾你的心脏问题或皮肤问题的医生。

![](img/5f94026aeaa256766103d6bad461c9a7_11.png)

深入得多，精细调整对模型有何作用。

![](img/5f94026aeaa256766103d6bad461c9a7_13.png)

就是让它能够处理更多数据。

![](img/5f94026aeaa256766103d6bad461c9a7_15.png)

超出提示框的内容，这样模型就能从这些数据中学习。

![](img/5f94026aeaa256766103d6bad461c9a7_17.png)

而不仅仅是访问它们，从学习过程中，它能够从pcp升级为更专业的。

![](img/5f94026aeaa256766103d6bad461c9a7_19.png)

如皮肤科医生，如图所示，你可能输入了一些症状，如皮肤刺激。

![](img/5f94026aeaa256766103d6bad461c9a7_21.png)

红肿，瘙痒，基础模型，即通用模型，可能只说是痤疮，经过皮肤科数据微调的模型。

![](img/5f94026aeaa256766103d6bad461c9a7_23.png)

然而，可能输入相同症状给出更清晰结果。

![](img/5f94026aeaa256766103d6bad461c9a7_25.png)

更具体诊断，除了学习新信息，微调也能帮助模型更稳定输出或行为。

![](img/5f94026aeaa256766103d6bad461c9a7_27.png)

例如，你在这里可以看到基础模型，你叫什么名字，它可能会回答你姓什么，因为它看到了很多不同的调查数据。

![](img/5f94026aeaa256766103d6bad461c9a7_29.png)

所以它甚至不知道它应该回答那个问题，但微调模型，相比之下，当你问它，你的名字会清晰回答。

![](img/5f94026aeaa256766103d6bad461c9a7_31.png)

我的名字是莎伦，这个机器人可能训练于我，除了引导模型更一致输出。

![](img/5f94026aeaa256766103d6bad461c9a7_33.png)

微调可帮助模型减少幻觉，这是一个常见问题，模型编造内容。

![](img/5f94026aeaa256766103d6bad461c9a7_35.png)

可能它说我的名字是鲍勃，但训练于我的数据。

![](img/5f94026aeaa256766103d6bad461c9a7_37.png)

我的名字肯定不是鲍勃，微调使你定制模型特定用例。

![](img/5f94026aeaa256766103d6bad461c9a7_39.png)

在微调过程中，稍后会有更多细节，实际上与模型早期训练类似。

![](img/5f94026aeaa256766103d6bad461c9a7_41.png)

现在与你可能更熟悉的比较。

![](img/5f94026aeaa256766103d6bad461c9a7_43.png)

即提示工程，这是你一直在做的一件事，甚至在过去十年与谷歌，即输入查询并编辑查询改变结果，提示有很多优点，你不需要任何数据开始，你可以开始与模型聊天，前期成本较小，不需要考虑成本，嗯。



![](img/5f94026aeaa256766103d6bad461c9a7_45.png)

因为每次你查询模型，并不贵，你不需要技术知识开始，你只需知道如何发送短信。

![](img/5f94026aeaa256766103d6bad461c9a7_47.png)

酷的是现在有方法可用，如检索，增强生成，或RAG连接更多数据，选择哪种数据进入提示，当然，如果你有超过一点数据，可能无法放入提示，因此不能使用那么多数据，通常当你尝试放入大量数据。

不幸的是它会忘记很多数据，有幻觉问题，即模型编造内容，很难纠正它已学的错误信息。

![](img/5f94026aeaa256766103d6bad461c9a7_49.png)

虽然使用检索增强生成连接数据很棒。

![](img/5f94026aeaa256766103d6bad461c9a7_51.png)

它也会经常错过正确数据，嗯，得到错误数据并导致模型输出错误，微调与提示相反，实际上可以放入几乎无限数据，很好，因为模型可学习新数据，因此，可纠正之前学到的错误信息，甚至可输入之前未学过的近期信息。

后期成本较低，若对小型模型进行微调，这尤其重要，若预期频繁使用模型，因此需要大量吞吐量，或预期其处理更大负载，此处也可使用检索增强生成。



![](img/5f94026aeaa256766103d6bad461c9a7_53.png)

人们有时认为它是独立事物，实际上两者皆可用，实际上可连接更多数据。

![](img/5f94026aeaa256766103d6bad461c9a7_55.png)

即使已学习所有信息，有缺点，然而，需要更多数据，且数据需高质量起步。

![](img/5f94026aeaa256766103d6bad461c9a7_57.png)

前期计算成本也存在，并非免费，非仅几美元起步，现在当然有免费工具开始，但实现此功能涉及计算，远不止提示。



![](img/5f94026aeaa256766103d6bad461c9a7_59.png)

有时你需要技术知识将数据放对位置，嗯，而且特别是你知道，围绕这段数据。

![](img/5f94026aeaa256766103d6bad461c9a7_61.png)

现在工具越来越多，这使事情容易多了，但你仍需理解那些数据。

![](img/5f94026aeaa256766103d6bad461c9a7_63.png)

而你不会，无需仅是发短信的人。

![](img/5f94026aeaa256766103d6bad461c9a7_65.png)

必然，所以最终意味着对于提示。

![](img/5f94026aeaa256766103d6bad461c9a7_67.png)

你知道这对通用案例很好，对不同侧项目和原型很好。

![](img/5f94026aeaa256766103d6bad461c9a7_69.png)

只是开始很好，非常快，同时微调对企业或特定领域案例很好。

![](img/5f94026aeaa256766103d6bad461c9a7_71.png)

对生产使用。

![](img/5f94026aeaa256766103d6bad461c9a7_73.png)

我们还将讨论下节中它对隐私的用处，微调自有LLM有何益。

![](img/5f94026aeaa256766103d6bad461c9a7_75.png)

若你有微调的自有LLM，一益处是性能提升，可阻止LLM胡编乱造，特别是针对你的领域，该领域专业知识更丰富，一致性也更高，有时这些模型会产出，今天很棒的内容，但明天可能就失效，不再一致了。

输出不再那么出色，这能使它更稳定可靠，也能更好地进行审核，如果你玩过很多Chi BT，你可能见过Chi BG，比如，抱歉，无法回答，实际上可以让它说同样或不同的话，这与您的公司或用例相关。



![](img/5f94026aeaa256766103d6bad461c9a7_77.png)

保持正轨，再说一次，现在我想谈谈隐私，当您微调自己的LLM时。

![](img/5f94026aeaa256766103d6bad461c9a7_79.png)

这可以在您的VPC中发生，或在本地，嗯，这防止了现成的第三方解决方案可能发生的。

![](img/5f94026aeaa256766103d6bad461c9a7_81.png)

数据泄露和数据泄露。

![](img/5f94026aeaa256766103d6bad461c9a7_83.png)

这是一种保持数据安全的方式，你收集了一段时间的，可能是最后几天，也可能是最后几十年，另一个你想微调自己的，LLM是关于成本的，一个是成本透明度，也许你有很多人在使用你的模型。



![](img/5f94026aeaa256766103d6bad461c9a7_85.png)

实际上你想降低每个请求的成本，然后微调一个较小的LLM可以帮助你做到这一点。

![](img/5f94026aeaa256766103d6bad461c9a7_87.png)

总体上你对成本有更大的控制。

![](img/5f94026aeaa256766103d6bad461c9a7_89.png)

还有其他一些因素，包括运行时间和延迟，对于自动完成功能等应用，可大幅降低延迟，您可能需要低于200毫秒的延迟，这样自动完成功能就不会被用户察觉，您可能不希望自动完成功能在30秒内发生。

目前运行gpt四有时就是这种情况，最后，适度，我们在这里已经稍微谈过。

![](img/5f94026aeaa256766103d6bad461c9a7_91.png)

但基本上，如果您希望模型对某些事情说抱歉。

![](img/5f94026aeaa256766103d6bad461c9a7_93.png)

或说不确定某些事，甚至定制回复，这是为模型设置护栏的一种方式，真正酷的是，实际上可以在笔记本中看到示例。



![](img/5f94026aeaa256766103d6bad461c9a7_95.png)

在所有这些实验中，将使用许多不同技术进行微调。

![](img/5f94026aeaa256766103d6bad461c9a7_97.png)

共有3个Python库，一个是Meta开发的PyTorch。

![](img/5f94026aeaa256766103d6bad461c9a7_99.png)

这是您将看到的最低级别接口，然后有一个由拥抱脸在PyTorch上构建的伟大图书馆，以及许多已经完成的工作。



![](img/5f94026aeaa256766103d6bad461c9a7_101.png)

这是一个更高层次的接口，你可以很容易地导入数据集和训练模型，最后，你将看到llama i库，我和我的团队一直在开发，我们称之为llama库，献给所有伟大的llamas。



![](img/5f94026aeaa256766103d6bad461c9a7_103.png)

这是一个更高层次的接口，你可以只用三行代码训练模型，好吧。

![](img/5f94026aeaa256766103d6bad461c9a7_105.png)

所以让我们转到笔记本，看看一些微调模型的实际应用。

![](img/5f94026aeaa256766103d6bad461c9a7_107.png)

好的，我们将比较一个微调模型和一个未微调模型。

![](img/5f94026aeaa256766103d6bad461c9a7_109.png)

所以首先我们从llama库导入。

![](img/5f94026aeaa256766103d6bad461c9a7_111.png)

这是来自llama i，基本模型运行器，这个类所做的就是。

![](img/5f94026aeaa256766103d6bad461c9a7_113.png)

它帮助我们运行开源模型，所以这些是托管在GPU上的开源模型以运行。

![](img/5f94026aeaa256766103d6bad461c9a7_115.png)

高效运行它们，你可以在这里运行的第一个模型是llama 2模型，现在非常流行。

![](img/5f94026aeaa256766103d6bad461c9a7_117.png)

这个模型没有经过微调。

![](img/5f94026aeaa256766103d6bad461c9a7_119.png)

所以我们将基于这个实例化它，基于这是它的拥抱脸名称，告诉我如何训练我的狗坐下，所以它是，你知道，非常非常简单，进入未微调模型，我们将得到输出，让我们打印未调优输出和coof。



![](img/5f94026aeaa256766103d6bad461c9a7_121.png)

好的，我们问它告诉我如何训练我的狗坐下，它说句号，然后告诉我如何训练我的狗说。

![](img/5f94026aeaa256766103d6bad461c9a7_123.png)

告诉我如何教我的狗来，告诉我如何让我的狗愈合，显然。

![](img/5f94026aeaa256766103d6bad461c9a7_125.png)

这与你的名字是什么，你的姓是什么答案非常相似，这个模型没有被告诉或训练来实际响应那个命令，所以可能有点灾难。



![](img/5f94026aeaa256766103d6bad461c9a7_127.png)

但让我们继续看，所以也许我们可以问它，你对火星有什么看法，所以现在你知道。

![](img/5f94026aeaa256766103d6bad461c9a7_129.png)

至少它在回应问题，但它的回答并不好。

![](img/5f94026aeaa256766103d6bad461c9a7_131.png)

我认为它是一个伟大的行星，我认为它是一个好行星，我认为它将成为一颗伟大的行星，所以它一直在非常哲学地思考。



![](img/5f94026aeaa256766103d6bad461c9a7_133.png)

甚至可能存在主义，如果你继续阅读。

![](img/5f94026aeaa256766103d6bad461c9a7_135.png)

那么像谷歌搜索查询之类的东西呢，等等。

![](img/5f94026aeaa256766103d6bad461c9a7_137.png)

像泰勒·斯威夫特的好友，看看那到底说了什么好吧，嗯，呃，它并没有完全理解泰勒的好友，但是，它确实说它是泰勒·斯威夫特的忠实粉丝，嗯，好吧，让我们继续探索，也许有些对话看看。



![](img/5f94026aeaa256766103d6bad461c9a7_139.png)

如果它能像查奇·BT一样在对话中转弯，这是一个亚马逊送货订单的代理，好的，所以，至少它在做不同的客户代理，但它并没有真正得到任何东西，这不是任何一种，像假转弯或帮助制作自动代理的东西好吧。



![](img/5f94026aeaa256766103d6bad461c9a7_141.png)

你已经看够了那个，让我们实际上比较一下llama two。

![](img/5f94026aeaa256766103d6bad461c9a7_143.png)

那已经被微调来真正聊天，所以我要实例化这个微调过的模型，注意这个名字，唯一不同的是，这里的聊天，然后我要让这个微调过的模型做同样的事情，告诉我如何训练我的狗坐下，我会打印那个。



![](img/5f94026aeaa256766103d6bad461c9a7_145.png)

好的，非常有趣，所以你可以立即看出区别，告诉我如何向医生展示它仍在尝试自动完成，告诉我如何训练我的狗坐下听从命令，但它实际上几乎一步一步，指南告诉我该怎么做，训练我的狗坐下酷，所以那好多了。

实际上摆脱这个额外自动完成的方法，实际上是告诉模型你想要指示，所以我实际上在这里放了这些指示标签，这用于llama too，当你微调你自己的模型时，你可以使用不同的东西，但这有助于告诉模型，嘿。

这是我的指示和这些是边界，我完成了给这个指示停止，停止，继续给我一个指示。

![](img/5f94026aeaa256766103d6bad461c9a7_147.png)

所以这里你可以看到它不会自动完成，命令那事，仅比较公平，用非微调模型看实际说啥，嗯 很好，只是重复同样的话，嗯 同样或非常相似，不太对，酷，继续向下，火星模型你觉得如何。



![](img/5f94026aeaa256766103d6bad461c9a7_149.png)

哦，迷人的星球 吸引人类数世纪，好的，酷，更好的输出，嗯，输出在这，泰勒·斯威夫特最好朋友，看这表现如何，好的，这个挺可爱，有几个候选，嗯，泰勒·斯威夫特最好朋友，实际是，看亚马逊快递员回复，好的。

说 看到，能提供订单号吗，这好太多了，有趣 因为下面也总结。

![](img/5f94026aeaa256766103d6bad461c9a7_151.png)

可能不想要，可微调去除。

![](img/5f94026aeaa256766103d6bad461c9a7_153.png)

现在好奇，ChatGPT会怎么说，教我如何训练狗坐下。

![](img/5f94026aeaa256766103d6bad461c9a7_155.png)

好的，给出不同步骤，很好，好，行，随意用Chachi或其他模型看结果，但很明显 微调过的更好，包括Chachi BT和这llama llm，明显优于未微调，下节课，看微调在训练中的位置，将看到如何到这。

微调模型第一步。