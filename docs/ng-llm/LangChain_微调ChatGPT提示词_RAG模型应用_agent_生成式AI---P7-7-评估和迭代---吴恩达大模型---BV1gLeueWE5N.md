# LangChain_微调ChatGPT提示词_RAG模型应用_agent_生成式AI - P7：7-评估和迭代 - 吴恩达大模型 - BV1gLeueWE5N

![](img/0a1b414c4dd12262cbdec0f0301f27c1_0.png)

现在你完成模型训练，下一步是评估它，看看表现如何，这是非常重要的一步，因为AI就是迭代，这有助于随时间改进模型，好的，让我们开始吧，评估生成模型非常难，非常困难，指标不明确，嗯。

这些模型的性能随时间不断提高，指标实际上难以跟上，因此，人类评估通常是可靠的方法，实际上是让领域专家评估输出，好的测试数据集，对充分利用这个人时间非常重要，意味着这是一个高质量的数据集，准确无误。

所以你检查过以确保准确，是通用的，实际上覆盖了你想确保模型覆盖的许多不同测试案例，当然不能在训练数据中看到，另一种新兴的方式是elo比较，所以这几乎就像是在多个模型之间进行a/b测试或锦标赛。

elo排名专门用于国际象棋，这也是一种了解哪些模型表现良好或不佳的方式，因此，一个非常常见的开放llm基准是一套不同的评估方法。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_2.png)

实际上采用多种评估方法，并将它们平均以排名模型，此为luther ai开发，如前所述，结合不同基准，一个是ARC，是一套小学问题，Hella Swag是常识测试，MLU涵盖许多小学科目。

以及真实QA衡量，模型复制常见虚假信息的能力，这些是由研究人员随时间开发的基准，现已被用于通用评估套件，你可以看到这，这是最新排名，截至录音时，但我确信这总在变化，Llama two表现良好。

实际上这不一定按平均排序，Llama two表现良好，最近有个免费Willy模型不错，在Llama模型上微调，我使用称为鲸鱼方法，这就是为什么叫自由威利，不会深入太多，这里有很多动物在进行。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_4.png)

但请随意自己查看，好的，另一个分析评估模型框架称为错误与分析，这是对错误进行分类，这样你了解，你知道常见错误类型，首先处理常见和灾难性错误，这真的很酷，因为我们的分析通常需要你先训练模型。

但当然对于微调，你已经有一个预训练的基模型，所以你可以先进行错误分析，甚至在微调模型之前，这有助于你理解和描述基模型的表现。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_6.png)

这样你知道哪种数据会给它最大的提升以进行微调，所以有很多不同类别，我将介绍一些常见的供你查看，一个是拼写错误，这非常直接，非常简单，所以这里说，去检查你的肝脏或杠杆。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_8.png)

它拼错了，所以只需在数据集中修复该示例即可正确拼写。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_10.png)

长度是一个我经常听到的常见问题，你知道，聊天，Gpt或生成模型总体上，它们非常冗长，所以一个例子就是确保你的数据集不那么冗长，这样它实际上就能简洁地回答问题，你在。训练笔记本中已经看到了这一点。

模型不那么冗长和重复，说到重复，嗯，你知道，这些模型确实非常重复，所以一种方法是使用停止标记更明确地修复它，你看到的那些提示模板，但，当然也要确保你的数据集包含没有那么多重复的例子，并且具有多样性酷。

所以现在进入一个实验室，你可以在测试数据集上运行模型，然后能够运行一些不同的指标，但主要是手动检查，也在运行那些llm基准测试。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_12.png)

好的，实际上只需一行代码，运行模型于整个测试集，分批处理，对GPU非常高效，所以我想在这里分享，加载模型，实例化，让它运行整个测试集列表，自动在GPU上快速分批。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_14.png)

现在我们主要运行在CPU上，所以在这个实验中你将真正。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_16.png)

仅运行一些测试数据点，当然你可以自己运行更多，很好，首先加载我们一直在工作的测试集，然后让我们看看其中一个数据点的样子，就打印问题答案对。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_18.png)

好的。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_20.png)

这是我们一直在看的，嗯，然后我们要加载模型来运行整个数据集。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_22.png)

和之前一样，我将从Hugging Face提取实际微调模型。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_24.png)

好的，现在加载了模型，我将加载一个非常基本的评估指标，只是为了让你感受这个生成任务。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_26.png)

它是否是两个字符串的精确匹配，当然，去掉一些空格，但只是感受是否能精确匹配，这对写作任务真的很困难，因为它在生成内容，实际上有很多不同的正确答案，所以对于，你知道，阅读引号任务。

这个评估指标可能不太有效，那些阅读任务你可能在提取主题，你可能在提取一些信息，所以在那些更接近分类的案例中，这可能更有意义，但我只是想运行这个，你也可以运行不同的评估指标。

当你运行模型评估模式时重要的是做model eval。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_28.png)

以确保像dropout这样的东西被禁用。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_30.png)

然后就像之前的实验一样。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_32.png)

你可以运行这个推断函数来能够，呃，生成输出。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_34.png)

再次运行第一个测试问题，查看输出和实际答案，与它比较相似，但并不完全一样，当然，当你运行精确匹配时，并不完美，并不是说，没有其他方法衡量这些模型。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_36.png)

这是一个非常简单的方法，有时人们也会，将这些输出放入另一个，LLM中询问并评分，看看它有多好，你知道它实际上有多接近，你也可以使用嵌入。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_38.png)

因此，您可以嵌入实际答案，并实际嵌入生成的答案，看看它们在距离上有多接近，所以有很多不同的方法可以采取，酷，所以现在要在整个数据集上运行，这可能是这样的，所以让我们实际上运行十个。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_40.png)

因为它需要相当长的时间，你遍历那个数据集。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_42.png)

提取问题和答案，我也试图获取预测的答案。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_44.png)

并将其与其他答案附加，这样您就可以稍后手动检查。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_46.png)

嗯，然后查看精确匹配的数量，它正在评估，精确匹配的数量为零，这并不完全令人惊讶，因为这是一项非常生成性的任务，并且通常对于这些任务，你知道，再次有很多不同的评估方法，但到最后。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_48.png)

通过大量边际显著性发现，使用手动检查在一个非常精选的测试集上。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_50.png)

这就是那个数据框的样子，所以现在你可以去检查并看到，对于每个预测的答案，目标是什么，它实际上有多接近，好吧酷。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_52.png)

所以这只是在数据的一个子集上，我们还评估了所有数据。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_54.png)

你可以从Hugging Face加载并能够，你知道，基本上查看和手动评估所有数据。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_56.png)

最后。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_58.png)

但并非最不重要的是，嗯，你将看到运行弧线，这是一个基准，所以如果你好奇，你知道学术基准，这是你在不同LLM基准测试套件中探索的一个，作为提醒，这个弧线基准是，路德AI提出的四个之一，这些来自学术论文。

对于这个，检查数据集，会发现你懂的科学问题，可能与任务无关。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_60.png)

这些评估指标，特别是这里，非常适合学术竞赛或理解，你知道，一般模型能力，有时围绕这些，在这种情况下，基本的小学问题，但我真的推荐，你知道。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_62.png)

即使运行这些，也不要过于关注这些基准的性能。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_64.png)

尽管现在人们是这样排名模型的，这是因为它们与你的用例无关，它们并不一定与公司关心的事情相关，你真正关心的，对于你的最终，用例，对于那个微调模型。



![](img/0a1b414c4dd12262cbdec0f0301f27c1_66.png)

正如你可能看到的，微调模型基本上能够适应大量不同的任务，需要多种评估方式。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_68.png)

好的，弧形基准测试刚完成，分数在这里，0。31，实际上低于论文中基线模型的分数，0。36，太疯狂了，因为你在上面看到了它的巨大改进，但它是因为在这个公司数据集上改进巨大，与这家公司相关的数据集。

关于问题，回答它，不是小学科学，所以弧度真正测量的是，当然，如果你对一般任务微调模型，所以如果你对羊驼微调，例如，你应该看到特定基准性能的一点提升，如果你使用更大的模型，你也会看到可能的增长。

因为它学得更多，就这样，所以如你所见，这个弧形基准可能只重要，如果你在查看通用模型并比较通用模型，也许那是为你找到基础模型，但不是你实际的微调任务，它不太有用，除非你正在微调模型来做小学科学问题。

这就是上节课笔记本的结束，你将学习一些微调的实际技巧。

![](img/0a1b414c4dd12262cbdec0f0301f27c1_70.png)