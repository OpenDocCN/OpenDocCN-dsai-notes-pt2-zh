#  【LangChain大模型应用开发】DeepLearning.AI - P3：3——记忆 - 吴恩达大模型 - BV1iZ421M79T

![](img/6611f57afa341027c62f44f8188df02e_0.png)

![](img/6611f57afa341027c62f44f8188df02e_1.png)

与这些模型互动时，与这些模型互动时，它们自然不记得你之前说过什么或之前的对话，它们自然不记得你之前说过什么或之前的对话，这是一个问题，这是一个问题，当你构建如聊天机器人等应用时，你想与他们交谈。

当你构建如聊天机器人等应用时，你想与他们交谈，因此，在这一节中我们将涵盖记忆，因此，在这一节中我们将涵盖记忆，基本上是如何记住对话的前一部分并将其输入语言模型。

基本上是如何记住对话的前一部分并将其输入语言模型，这样，当你与他们互动时，它们可以有这种对话流程，这样，当你与他们互动时，它们可以有这种对话流程，是的，是的，lang提供了多种高级选项来管理这些记忆。

lang提供了多种高级选项来管理这些记忆，让我们深入了解一下，让我们深入了解一下，首先导入API密钥，首先导入API密钥。



![](img/6611f57afa341027c62f44f8188df02e_3.png)

然后导入所需工具，然后导入所需工具。

![](img/6611f57afa341027c62f44f8188df02e_5.png)

以记忆为例，以记忆为例。

![](img/6611f57afa341027c62f44f8188df02e_7.png)

使用lag链管理聊天或聊天机器人对话，使用lag链管理聊天或聊天机器人对话。

![](img/6611f57afa341027c62f44f8188df02e_9.png)

为此，为此，我将设置lm为OpenAI的聊天界面，我将设置lm为OpenAI的聊天界面。

![](img/6611f57afa341027c62f44f8188df02e_11.png)

温度为0，温度为0，并将内存用作对话缓冲内存，并将内存用作对话缓冲内存。

![](img/6611f57afa341027c62f44f8188df02e_13.png)

稍后您将看到这意味着什么，稍后您将看到这意味着什么，嗯，嗯，稍后我将重建对话链，稍后我将重建对话链。

![](img/6611f57afa341027c62f44f8188df02e_15.png)

在这门短课中，在这门短课中，哈里森将更深入探讨链的本质和土地链，哈里森将更深入探讨链的本质和土地链，现在不必太担心语法的细节，现在不必太担心语法的细节，但这构建了一个LLM，但这构建了一个LLM。

如果我开始对话，如果我开始对话，对话点预测，对话点预测，给定输入嗨，给定输入嗨。

![](img/6611f57afa341027c62f44f8188df02e_17.png)

我叫安德鲁，我叫安德鲁，看看它说什么 你好，看看它说什么 你好，很高兴见到你等，很高兴见到你等，然后假设我问它，然后假设我问它，一加一等于几，一加一等于几，嗯，一加一等于二，嗯，一加一等于二。

然后再次问它，然后再次问它，你知道我的名字吗，你知道我的名字吗，你的名字是安德鲁，你的名字是安德鲁，如你之前所说，如你之前所说。



![](img/6611f57afa341027c62f44f8188df02e_19.png)

那里有一点讽刺，那里有一点讽刺，不确定，不确定，所以如果你想，所以如果你想，可将此变量设为真查看实际操作，可将此变量设为真查看实际操作。



![](img/6611f57afa341027c62f44f8188df02e_21.png)

运行predict high时，运行predict high时，我叫安德鲁，我叫安德鲁，这是lang chain生成的提示，这是lang chain生成的提示。



![](img/6611f57afa341027c62f44f8188df02e_23.png)

它说以下是人类与AI的对话，它说以下是人类与AI的对话。

![](img/6611f57afa341027c62f44f8188df02e_25.png)

健谈等，健谈等，这是lang chain生成的提示，这是lang chain生成的提示，让系统有希望和友好对话，让系统有希望和友好对话，并保存对话，并保存对话，这里是回应，这里是回应，当你执行这个时。

当你执行这个时。

![](img/6611f57afa341027c62f44f8188df02e_27.png)

嗯，嗯，因果的第二三部分，因果的第二三部分，它保持提示如下，它保持提示如下，注意当我念出我的名字时，注意当我念出我的名字时，这是第三个术语，这是第三个术语。



![](img/6611f57afa341027c62f44f8188df02e_29.png)

这是我的第三个输入，这是我的第三个输入，它已将当前对话存储如下，它已将当前对话存储如下。

![](img/6611f57afa341027c62f44f8188df02e_31.png)

你好，我叫安德鲁，你好，我叫安德鲁，1加1等，1加1等，因此，对话的历史越来越长，因此，对话的历史越来越长。



![](img/6611f57afa341027c62f44f8188df02e_33.png)

实际上在顶部，实际上在顶部，我用内存变量存储了记忆，我用内存变量存储了记忆。

![](img/6611f57afa341027c62f44f8188df02e_35.png)

所以如果我打印内存缓冲，所以如果我打印内存缓冲，它已存储到目前为止的对话，它已存储到目前为止的对话。

![](img/6611f57afa341027c62f44f8188df02e_37.png)

你也可以打印这个，你也可以打印这个。

![](img/6611f57afa341027c62f44f8188df02e_39.png)

内存加载内存变量，内存加载内存变量，嗯，嗯，这里的花括号实际上是一个空字典，这里的花括号实际上是一个空字典。



![](img/6611f57afa341027c62f44f8188df02e_41.png)

有一些更高级的功能你可以使用，有一些更高级的功能你可以使用。

![](img/6611f57afa341027c62f44f8188df02e_43.png)

但在这门短课程中我们不会讨论它们，但在这门短课程中我们不会讨论它们，所以不用担心，所以不用担心。

![](img/6611f57afa341027c62f44f8188df02e_45.png)

为什么这里有一个空的花括号，为什么这里有一个空的花括号，但这是lang chain记住的，但这是lang chain记住的。



![](img/6611f57afa341027c62f44f8188df02e_47.png)

到目前为止对话的记忆，到目前为止对话的记忆，它只是AI或人类所说的一切，它只是AI或人类所说的一切，我鼓励你暂停视频并运行代码，我鼓励你暂停视频并运行代码。



![](img/6611f57afa341027c62f44f8188df02e_49.png)

lang chain存储对话的方式是使用这个对话缓冲内存，lang chain存储对话的方式是使用这个对话缓冲内存。



![](img/6611f57afa341027c62f44f8188df02e_51.png)

如果我使用组合，如果我使用组合。

![](img/6611f57afa341027c62f44f8188df02e_53.png)

缓冲内存指定几个输入和输出，缓冲内存指定几个输入和输出，这就是你如何向记忆中添加新东西，这就是你如何向记忆中添加新东西。



![](img/6611f57afa341027c62f44f8188df02e_55.png)

如果你想明确地这样做，记忆，如果你想明确地这样做，记忆，保存上下文说你好，保存上下文说你好。

![](img/6611f57afa341027c62f44f8188df02e_57.png)

怎么了，怎么了，我知道这不是最令人兴奋的对话，我知道这不是最令人兴奋的对话。

![](img/6611f57afa341027c62f44f8188df02e_59.png)

但我想让它有一个简短的例子，但我想让它有一个简短的例子，有了这个，这就是记忆的状态，有了这个，这就是记忆的状态。



![](img/6611f57afa341027c62f44f8188df02e_61.png)

再次让我实际上显示，再次让我实际上显示，嗯，嗯，内存变量现在，内存变量现在，如果你想添加额外的，如果你想添加额外的。



![](img/6611f57afa341027c62f44f8188df02e_63.png)

嗯数据到内存，嗯数据到内存，你可以继续保存更多上下文，你可以继续保存更多上下文，因果继续不多，因果继续不多。



![](img/6611f57afa341027c62f44f8188df02e_65.png)

只是冷静地挂着，只是冷静地挂着，如果你打印出内存，如果你打印出内存。

![](img/6611f57afa341027c62f44f8188df02e_67.png)

你知道现在有更多的内容，你知道现在有更多的内容，所以当你使用大型语言模型进行聊天对话时，所以当你使用大型语言模型进行聊天对话时。



![](img/6611f57afa341027c62f44f8188df02e_69.png)

嗯大型语言模型本身实际上是无状态的，嗯大型语言模型本身实际上是无状态的。

![](img/6611f57afa341027c62f44f8188df02e_71.png)

语言模型本身不记对话，语言模型本身不记对话，每笔交易，每笔交易，每次API调用独立，每次API调用独立。



![](img/6611f57afa341027c62f44f8188df02e_73.png)

聊天机器人，聊天机器人，仅因为通常有代码提供，仅因为通常有代码提供，迄今为止的完整对话作为上下文，迄今为止的完整对话作为上下文。



![](img/6611f57afa341027c62f44f8188df02e_75.png)

因此内存可以明确存储，因此内存可以明确存储。

![](img/6611f57afa341027c62f44f8188df02e_77.png)

嗨，嗨，我叫安德鲁，我叫安德鲁，很高兴见到你等，很高兴见到你等，这种内存存储用作输入或附加上下文，这种内存存储用作输入或附加上下文。



![](img/6611f57afa341027c62f44f8188df02e_79.png)

以便它们可以生成输出，以便它们可以生成输出，就像只有下一个对话回合，就像只有下一个对话回合。

![](img/6611f57afa341027c62f44f8188df02e_81.png)

知道之前说了什么，知道之前说了什么。

![](img/6611f57afa341027c62f44f8188df02e_83.png)

随着对话变长，随着对话变长，所需内存量变得非常长，所需内存量变得非常长，发送大量令牌到LM的成本也会增加，发送大量令牌到LM的成本也会增加。



![](img/6611f57afa341027c62f44f8188df02e_85.png)

通常按需要处理的令牌数收费，通常按需要处理的令牌数收费。

![](img/6611f57afa341027c62f44f8188df02e_87.png)

因此链提供了几种方便的内存类型，因此链提供了几种方便的内存类型。

![](img/6611f57afa341027c62f44f8188df02e_89.png)

以存储和累积对话，以存储和累积对话。

![](img/6611f57afa341027c62f44f8188df02e_91.png)

我们一直在看对话缓冲内存，我们一直在看对话缓冲内存，让我们看看另一种类型的内存，让我们看看另一种类型的内存。



![](img/6611f57afa341027c62f44f8188df02e_93.png)

我将导入对话缓冲窗口AR，我将导入对话缓冲窗口AR。

![](img/6611f57afa341027c62f44f8188df02e_95.png)

它只保留一段内存，它只保留一段内存，我设置内存为缓冲窗口内存，k等于一，我设置内存为缓冲窗口内存，k等于一。



![](img/6611f57afa341027c62f44f8188df02e_97.png)

变量k等于一，变量k等于一，指定我只想记住一次对话交换，指定我只想记住一次对话交换。

![](img/6611f57afa341027c62f44f8188df02e_99.png)

即一次我的回合，即一次我的回合，和一次聊天机器人的发言，和一次聊天机器人的发言。

![](img/6611f57afa341027c62f44f8188df02e_101.png)

所以现在如果我让它保存上下文嗨，所以现在如果我让它保存上下文嗨，怎么了，怎么了，不只是挂着，不只是挂着。



![](img/6611f57afa341027c62f44f8188df02e_103.png)

如果我查看内存加载变量，如果我查看内存加载变量。

![](img/6611f57afa341027c62f44f8188df02e_105.png)

它只记得最近的发言，它只记得最近的发言，注意'嗨'被丢弃，注意'嗨'被丢弃。

![](img/6611f57afa341027c62f44f8188df02e_107.png)

怎么了，怎么了，它只说人类说不多，它只说人类说不多，只是挂着，只是挂着，AI说酷，AI说酷。

![](img/6611f57afa341027c62f44f8188df02e_109.png)

因为k等于一，因为k等于一，这是一个很好的功能，这是一个很好的功能。

![](img/6611f57afa341027c62f44f8188df02e_111.png)

因为它让你跟踪最近的几次对话，因为它让你跟踪最近的几次对话。

![](img/6611f57afa341027c62f44f8188df02e_113.png)

实践中你可能不会用k等于一，实践中你可能不会用k等于一，你会用k设置为较大的数字，你会用k设置为较大的数字。



![](img/6611f57afa341027c62f44f8188df02e_115.png)

嗯，但这防止了内存无限制增长，嗯，但这防止了内存无限制增长。

![](img/6611f57afa341027c62f44f8188df02e_117.png)

![](img/6611f57afa341027c62f44f8188df02e_118.png)

随着对话变长，随着对话变长，如果我们重新运行刚才的对话，如果我们重新运行刚才的对话，我们说嗨，我们说嗨，我叫安德鲁，我叫安德鲁。



![](img/6611f57afa341027c62f44f8188df02e_120.png)

1加1等于几，1加1等于几，我叫什么名字。

![](img/6611f57afa341027c62f44f8188df02e_122.png)

因为k等于一，它只记得最后交流。

![](img/6611f57afa341027c62f44f8188df02e_124.png)

哪个是一加一，答案是1，加等于2，然后它忘记了，这个早期交流。

![](img/6611f57afa341027c62f44f8188df02e_126.png)

现在说抱歉，我没有访问这些信息。

![](img/6611f57afa341027c62f44f8188df02e_128.png)

我希望你会暂停视频，在左边的代码中改为true，并重新运行此对话，verbose等于true。

![](img/6611f57afa341027c62f44f8188df02e_130.png)

然后你会看到实际使用的提示。

![](img/6611f57afa341027c62f44f8188df02e_132.png)

当你调用lm时，希望你能看到记忆。

![](img/6611f57afa341027c62f44f8188df02e_134.png)

我叫什么名字，记忆已经丢失这个交流，我学到，我叫什么名字，这就是为什么现在说不知道，我叫什么名字。

![](img/6611f57afa341027c62f44f8188df02e_136.png)

使用对话令牌缓冲记忆，记忆将限制保存的令牌数。

![](img/6611f57afa341027c62f44f8188df02e_138.png)

因为许多lm定价基于令牌，这更直接地映射到lm调用的成本。

![](img/6611f57afa341027c62f44f8188df02e_140.png)

如果我设定最大令牌限制等于五十，实际上让我插入一些注释。

![](img/6611f57afa341027c62f44f8188df02e_142.png)

比如对话是人工智能是什么惊人的反向传播，美丽的教堂是什么迷人的，我用abc作为所有这些国家术语的第一个字母，我们可以跟踪何时说了什么。



![](img/6611f57afa341027c62f44f8188df02e_144.png)

如果我以高令牌限制运行，它几乎有整个对话，如果我增加令牌限制到一百，现在它有整个对话，人工智能的标志是什么，如果我减少它，那么你知道它切掉了对话的早期部分，以保留对应最近交流的令牌数。

但受限于不超过令牌限制，如果你想知道为什么我们需要指定，因为不同的lm使用不同的计数令牌方式，所以这告诉它使用聊天openai lm使用的计数令牌方式。



![](img/6611f57afa341027c62f44f8188df02e_146.png)

我鼓励你暂停视频并运行代码，并尝试修改提示以查看是否可以得到不同的输出，最后，这里有一种我想说明的最后一种记忆，即对话摘要缓冲记忆。



![](img/6611f57afa341027c62f44f8188df02e_148.png)

想法不是限制记忆到固定数量的令牌。

![](img/6611f57afa341027c62f44f8188df02e_150.png)

基于最近的陈述，而是基于最相关的陈述，或固定对话次数。

![](img/6611f57afa341027c62f44f8188df02e_152.png)

用语言模型写对话摘要。

![](img/6611f57afa341027c62f44f8188df02e_154.png)

让那成为记忆，示例如下。

![](img/6611f57afa341027c62f44f8188df02e_156.png)

我将创建某人日程长字符串，与产品团队会议，需PPT等，长字符串说。

![](img/6611f57afa341027c62f44f8188df02e_158.png)

你的日程如何，你知道，中午在意大利餐厅结束如何，与客户一起，带上笔记本电脑，展示最新电影演示，因此让我使用对话摘要。



![](img/6611f57afa341027c62f44f8188df02e_160.png)

缓冲，内存，嗯，最大标记限制为400。

![](img/6611f57afa341027c62f44f8188df02e_162.png)

在这种情况下，很高的标记限制，我将要。

![](img/6611f57afa341027c62f44f8188df02e_164.png)

我们以'你好'开始的一些对话术语，怎么了，没，就挂着，嗯，酷。

![](img/6611f57afa341027c62f44f8188df02e_166.png)

今天日程上有什么，回答是。

![](img/6611f57afa341027c62f44f8188df02e_168.png)

你知道那长长的日程，现在这段记忆包含了很多文本。

![](img/6611f57afa341027c62f44f8188df02e_170.png)

实际上让我们看看记忆变量，包含全部文本，400个标记足够存储，但若减少最大标记数，比如100个标记，记住存储全部对话历史，若减少标记数至100，实际上使用了OpenAI的lm端点，因为我们说过。

让lm生成对话摘要，所以摘要是人类和AI闲聊，通知人类早会，blah blah blah，嗯，与对AI感兴趣的客户午餐会议，因此，如果我们进行对话，使用此LM，让我创建对话链，与之前相同，嗯。

假设我们要问。

![](img/6611f57afa341027c62f44f8188df02e_172.png)

你知道输入，展示什么好呢？我说详细为真，所以这是提示，Dlm认为对话已讨论这些，因为那是对话总结，还有注意点，若熟悉openai聊天API，有特定系统消息，例如中，这不是使用官方OpenAI系统消息。

只是将其作为提示的一部分，但它仍然工作得很好，考虑到这个提示，你知道，输出基本上很有趣，发展正在展示我们最新的NLP能力，好的，那很酷，好吧，你知道，给酷演示提建议，让你思考，如果见客户，我会说，伙计。

若开源框架可用，助我建酷NLP应用，好东西，比如，有趣的是，看内存发生了什么，注意，这里整合了最新AI系统输出，我询问的演示不会好，已集成到系统消息中，嗯，你知道到目前为止的对话概要，缓冲内存。

它试图做的是保持消息的显式存储，直到我们指定的标记数为止，所以你知道这部分显式存储，或尝试限制在一百个标记，因为这是我们要求的，然后任何超出部分它将使用lm生成摘要，这就是上面所见的。

尽管我已用聊天示例，说明了这些不同记忆，这些记忆对其他应用也有用，在那里你可能不断收到文本片段，或不断接收新信息，例如，若系统反复在线搜索事实，但你想保持总记忆量，不要让列表任意增长，我建议你暂停。

视频并运行代码，你看到几种内存。

![](img/6611f57afa341027c62f44f8188df02e_174.png)

嗯，包括基于交换次数或标记数的缓冲内存，或可总结超过一定限制标记的内存。

![](img/6611f57afa341027c62f44f8188df02e_176.png)

实际上，该链还支持其他类型的内存，最强大的是向量数据内存。

![](img/6611f57afa341027c62f44f8188df02e_178.png)

如果你熟悉词嵌入和文本嵌入。

![](img/6611f57afa341027c62f44f8188df02e_180.png)

向量数据库实际上存储这样的嵌入（如不知道，别担心）。

![](img/6611f57afa341027c62f44f8188df02e_182.png)

别担心，哈里森稍后会解释，然后检索最相关文本块，使用这种向量数据库存储记忆。

![](img/6611f57afa341027c62f44f8188df02e_184.png)

Lankan也支持实体记忆，适用于你想记住特定人或特定实体的细节时。

![](img/6611f57afa341027c62f44f8188df02e_186.png)

比如谈论特定朋友，可以让Lang Chain记住关于那个朋友的事实，这应该以明确实体方式。

![](img/6611f57afa341027c62f44f8188df02e_188.png)

在用Lang Chain实现应用时，也可以使用多种类型记忆。

![](img/6611f57afa341027c62f44f8188df02e_190.png)

如使用视频中看到的对话记忆类型之一，另外，还有实体记忆以回忆个人。

![](img/6611f57afa341027c62f44f8188df02e_192.png)

这样你可以记住对话的概要，以及关于对话中重要人物的重要事实的明确存储方式。

![](img/6611f57afa341027c62f44f8188df02e_194.png)

当然，除了使用这些记忆类型，开发人员将整个对话存储在传统数据库中也不罕见，某种键值存储或SQL数据库。



![](img/6611f57afa341027c62f44f8188df02e_196.png)

![](img/6611f57afa341027c62f44f8188df02e_197.png)

![](img/6611f57afa341027c62f44f8188df02e_198.png)

![](img/6611f57afa341027c62f44f8188df02e_199.png)