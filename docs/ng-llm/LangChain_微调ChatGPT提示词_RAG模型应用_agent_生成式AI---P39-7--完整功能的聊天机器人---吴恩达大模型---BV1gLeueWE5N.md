# LangChain_微调ChatGPT提示词_RAG模型应用_agent_生成式AI - P39：7——完整功能的聊天机器人 - 吴恩达大模型 - BV1gLeueWE5N

![](img/92ccfc59e7465ca7b35eec7bf4601f06_0.png)

我们离拥有一个功能齐全的聊天机器人只差一步，我们首先开始加载文档，然后我们进行了分割，然后我们创建了一个向量存储，我们讨论了不同类型的检索，我们已经展示了我们可以回答问题，但我们无法处理后续问题。

我们不能与它进行真正的对话，好消息是，我们将修复这个问题，在这堂课中，让我们找出如何做，我们现在将通过创建一个问题来结束，回答调情，这将做两件事，首先，它看起来将与以前相似。

但我们将添加一个聊天历史的概念，这是指您与链交换的任何先前对话或消息，这将允许它做什么，是允许它将聊天历史放入上下文中，当它试图回答问题时，因此，如果您问后续问题，它将知道您在谈论什么。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_2.png)

一个重要的事情要注意的是，这里是我们之前讨论的所有酷类型的检索，如自我查询或压缩，或任何类似的，您可以绝对在这里使用它们，我们所讨论的所有组件都非常模块化，可以相互配合，我们只是添加了聊天历史的概念。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_4.png)

让我们先看看它看起来什么样子，如往常一样，我们将加载我们的环境变量。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_6.png)

如果您已经设置平台，它也可能很好打开，从一开始，将有许多令人兴奋的事情想要查看，正在发生什么内部。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_8.png)

我们将加载包含所有嵌入式的向量存储，对于所有课程材料。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_10.png)

我们可以在向量存储上进行基本的相似性搜索。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_12.png)

我们可以初始化我们将用作聊天机器人的语言模型。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_14.png)

并且这是从以前，这就是我为什么快速浏览它，我们可以初始化提示模板，创建检索QA链，然后输入一个问题并获取结果。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_16.png)

但现在让我们做更多，让我们给它一些记忆，所以我们将工作与对话缓冲器记忆，这做什么，它只是简单地保持一个列表，历史记录缓冲区，并且它将将这些信息与问题一起传递给聊天机器人，每次我们指定记忆键时，聊天历史。

这将仅与提示中的输入变量对齐，然后，我们指定返回消息等于true，这将返回聊天历史作为消息列表的形式，与单个字符串不同，这是最简单的记忆类型，用于更深入地查看记忆，回到与安德鲁一起教过的第一个班级。

我们详细覆盖了这个主题。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_18.png)

然后，现在让我们创建一个新的链类型，对话检索链，我们传递语言模型，我们传递检索器和记忆，对话检索链在检索上添加了一个新的部分，QA链，不仅仅是记忆，具体来说，它添加的是，它添加了一个步骤。

该步骤将历史和新问题合并为一个独立的问题，以便传递给向量存储，以查找相关文档，我们将在ui中查看此，在我们运行它并看到其效果后，但目前让我们试试看。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_20.png)

我们可以问一个问题，这是在没有历史的情况下，并看看我们得到的结果。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_22.png)

然后我们可以问跟进问题以回答那个答案，这是同样的，所以我们在问概率，一个课程主题，我们得到一些答案，教师假设学生对概率和统计有基本的理解，然后我们问，为什么需要这些前提，我们得到结果并让我们看看它。

我们得到答案。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_24.png)

现在我们可以看到答案指的是基本的概率和统计作为前提，并进一步解释不要与计算机科学混淆，就像以前。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_26.png)

让我们看看ui下的工作原理。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_28.png)

所以这里我们已经可以看到有更多的复杂性，我们可以看到，链的输入现在不仅包括问题。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_30.png)

还包括聊天历史，聊天历史来自记忆，并且这在被调用和记录在日志系统之前被应用了，这就是在ui下正在发生的事情，如果我们查看轨迹，我们可以看到有两个不同的事情在进行，首先有一个对项目的调用。

然后有一个对填充文档链的调用，让我们来看看第一个调用。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_32.png)

我们可以在这里看到一个带有一些指示的提示，给定以下对话，一个后续问题，将后续问题重新表述为一个独立的问题。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_34.png)

这里我们有之前的历史，所以我们首先问的问题是主题分类的概率，然后我们有辅助答案，然后外面我们有一个独立的问题，要求基本概率和统计作为课程预修的原因是什么。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_36.png)

结果是独立答案然后传递给检索器，我们检索四个文档或三个文档，或任何数量，我们指定，然后我们将那些文档传递给填充文档链并尝试回答原始问题。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_38.png)

如果我们看进去，我们可以看到系统答案，使用以下上下文来回答用户的问题。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_40.png)

我们有大量的上下文。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_42.png)

然后我们有下面的独立问题，然后我们得到答案，这里是与当前问题相关的答案。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_44.png)

这是关于概率和统计作为预修要求的，现在是一个暂停并尝试为这个链不同选项的好时机，你可以传递不同的提示模板，不仅用于回答问题，而且也用于将这个问题重新表述为一个独立的问题。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_46.png)

你可以尝试不同类型的记忆，这里有许多不同的选择可以从这里提取。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_48.png)

接下来我们将所有这些都整合到一个漂亮的ui中，创建这个ui需要很多代码，但这是这里最重要的部分。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_50.png)

具体来说，这是一个关于，基本上这个整个课程的全面指南，我们将加载数据库和检索器链，我们将传递一个文件，我们将用它的pdf加载器加载它，他们将它加载到文档中，我们将那些文档分割。

我们将创建一些嵌入并将它们放入向量存储中，我们将那个向量存储转换为检索器。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_52.png)

我们将在这里使用相似性，使用一些搜索词k。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_54.png)

我们将其设置为我们可以传递的参数，然后我们将创建对话检索链。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_56.png)

需要注意的是，我们不是在传递内存，我们将外部管理内存，为了方便下面的GUI，这意味着聊天历史必须在链外管理，然后我们在这里有很多代码，我们不会花费太多时间在它们上。

但指出在这里我们正在将聊天历史传递给链。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_58.png)

再次，这是因为它没有附着在内存中。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_60.png)

然后，我们在这里扩展聊天历史，结果，我们可以然后将它们全部放在一起，并运行此以获取通过哪个我们可以与我们的聊天机器人交互的漂亮UI，并且，让我们问你一个问题，TAS是谁。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_62.png)

TAS是保罗，Bustarch。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_64.png)

Katie Chang，在这里，你会注意到有几个标签，我们也可以点击它们来查看其他东西。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_66.png)

如果我们点击数据库，我们可以看到上次我们向数据库提出的问题。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_68.png)

以及我们从那里查找回来的来源，所以这些是文档。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_70.png)

这些是在分裂后的结果，这些是我们检索的每个部分，我们可以看到包含输入和输出的聊天历史。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_72.png)

然后，还有一个地方可以进行配置，您可以上传文件。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_74.png)

我们还可以问后续问题，所以让我们问他们的专业是什么。

![](img/92ccfc59e7465ca7b35eec7bf4601f06_76.png)

我们得到关于之前提到的TAS的答案，所以我们可以看到保罗正在学习机器学习和计算机视觉，而凯蒂实际上是一名神经科学家。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_78.png)

这基本上就是课程的结束，所以现在是暂停的好时机，问更多的问题，在这里上传您自己的文档，并享受这个端到端的问题解答机器人，配有令人惊叹的笔记本UI，这结束了我们使用链链聊天与您数据的课程，在这门课程中。

我们覆盖了如何使用Link Chain从各种文档源加载数据，使用Link Chains，超过八十种不同的文档加载器，从那里我们分割文档成块，并讨论了在执行此操作时出现的许多微妙之处，然后，我们将这些块。

为他们创建嵌入式，并将它们放入向量存储，展示了如何轻松地使用语义搜索，但我们也谈论了一些语义搜索的缺点，并指出了它在可能出现的特定边缘情况中可能会失败的地方，我们覆盖的是关于检索的内容。

这可能是我最喜欢的课程部分，我们在这里讨论了许多新的、先进的和非常有趣的检索算法，以克服那些边缘情况，在下一次课程中，我们将那个与llms结合，我们将那些检索的文档，我们将用户问题。

我们将其传递给llm并生成对原始问题的答案，但是还缺少一件事，那就是其中的对话方面，这就是我们在课程结束时完成的地方，通过创建基于您数据的完全功能端到端聊天机器人，我真的享受教这门课。

我希望你们 guys 享受学习它，我想感谢开源社区的所有人，他们为使这门课程可能贡献了很多，如所有的提示和您在 lang chain 中看到的许多功能，当你们使用 lang chain 建立时。

并发现新的方法、技巧和技巧，我希望你们分享你们在推特上学到的东西，甚至向 link chain 提交 PR，这是一个快速发展的领域，现在是一个令人兴奋的时期来构建。



![](img/92ccfc59e7465ca7b35eec7bf4601f06_80.png)