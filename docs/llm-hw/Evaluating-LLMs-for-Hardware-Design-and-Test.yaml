- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:51:44'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating LLMs for Hardware Design and Test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.02326](https://ar5iv.labs.arxiv.org/html/2405.02326)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \lst@Key
  prefs: []
  type: TYPE_NORMAL
- en: 'numbersnone\lstKV@SwitchCases#1none:'
  prefs: []
  type: TYPE_NORMAL
- en: 'left:'
  prefs: []
  type: TYPE_NORMAL
- en: 'right:'
  prefs: []
  type: TYPE_NORMAL
- en: Jason Blocklove New York University New York, NY USA
  prefs: []
  type: TYPE_NORMAL
- en: jason.blocklove@nyu.edu    Siddharth Garg New York University New York, NY USA
  prefs: []
  type: TYPE_NORMAL
- en: siddharth.garg@nyu.edu    Ramesh Karri New York University New York, NY USA
  prefs: []
  type: TYPE_NORMAL
- en: rkarri@nyu.edu    Hammond Pearce University of New South Wales
  prefs: []
  type: TYPE_NORMAL
- en: Sydney, Australia
  prefs: []
  type: TYPE_NORMAL
- en: hammond.pearce@unsw.edu.au
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have demonstrated capabilities for producing code
    in Hardware Description Languages (HDLs). However, most of the focus remains on
    their abilities to write functional code, not test code. The hardware design process
    consists of both design and test, and so eschewing validation and verification
    leaves considerable potential benefit unexplored, given that a design and test
    framework may allow for progress towards full automation of the digital design
    pipeline. In this work, we perform one of the first studies exploring how a LLM
    can both design and test hardware modules from provided specifications. Using
    a suite of 8 representative benchmarks, we examined the capabilities and limitations
    of the state-of-the-art conversational LLMs when producing Verilog for functional
    and verification purposes. We taped out the benchmarks on a Skywater 130nm shuttle
    and received the functional chip.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hardware Design and Verification, CAD, LLM
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Digital hardware design has traditionally relied on a relatively niche skill
    set, requiring specifically trained engineers to both architect and implement
    new semiconductor hardware designs, and then to validate and verify those designs
    before they are taped out into integrated circuits. This testing process is time-consuming
    and difficult, requiring the development of appropriately comprehensive tests
    to ensure that every possible eventuality is accurately accounted for. Indeed,
    according to [[1](#bib.bib1)], 51% of development effort (cost) in both ASIC and
    FPGA-based systems are spent on verification. Any missed bugs will have increasingly
    expensive consequences, depending on how late in the product’s development and
    deployment lifecycle they are eventually discovered. In a push to simplify design
    and test, tools have been developed to support processes like high-level synthesis
    (HLS) [[2](#bib.bib2)], which make it easier for those with preexisting software
    development experience to create functioning hardware—though in order for an engineer
    to take full advantages of the domain, they will still often require a good level
    of hardware development knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Other techniques have leveraged machine learning (ML) to enhance tooling for
    design and test. For design-focused examples [[3](#bib.bib3)] discusses ML adoption
    in logic synthesis, design space reduction, exploration, placement, and routing.
    These techniques focus on simplifying electronic design automation (EDA) algorithms
    rather than simplifying the tasks. Advances in natural language processing—in
    particular, Large Language Models (LLM)—have presented new avenues for hardware
    design. Prior work shows that LLMs can write code, including in verilog hardware
    description language (HDL)  [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]. However, while this demonstrated how LLMs can aid design, research
    exploring LLMs for test are lacking.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this work we evaluate how LLMs may be used for both design and test together
    by starting from a plain language specification, instructing for Verilog implementation,
    and then creating the associated testbenches. To this end we leverage design and
    test tools in a feedback loop with a LLM such that minimal user debugging assistance
    is required. To this end, we provide a set of conversational LLMs with simple
    prompts to create the functional and verification HDL, which we then successfully
    taped out through Tiny Tapeout 3 [[9](#bib.bib9)]. Our contributions are: (i)
    Developing simple benchmarks to evaluate the capabilities of LLMs for functional
    hardware development and verification. (ii) Providing post-silicon results from
    a taped-out device. Open-source: Benchmarks, toolchain scripts, Verilog and LLM
    conversation logs are on Zenodo [[10](#bib.bib10)].'
  prefs: []
  type: TYPE_NORMAL
- en: II Background and Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: II-A Large Language Models (LLMs)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs such as GPT-3 [[11](#bib.bib11)] and Codex [[12](#bib.bib12)] are a class
    of ML model which use a Transformer architecture [[13](#bib.bib13)] and are trained
    on a large corpus of plain-language data to generate a predicted output. LLMs
    receive an text-based input prompt, then produce the “most-likely” continuation
    of that prompt. By training over appropriate data this means LLMs can complete
    lexical sequences, including code. Further, LLMs have recently been made “conversational”
    using instruction-tuning. Rather than guessing the next most likely token in an
    “autocomplete” fashion, they ingest whole prompts and formulate complete responses
    to those prompts. Examples include ChatGPT [[14](#bib.bib14)] versions 3.5 and
    4, Google’s Bard [[15](#bib.bib15)], and HuggingFace’s HuggingChat [[16](#bib.bib16)].
  prefs: []
  type: TYPE_NORMAL
- en: II-B LLM Aided Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Several LLMs have been created with the intention of generating Verilog for
    hardware design, e.g. Pearce et al. [[4](#bib.bib4)] fine-tuned a GPT-2 model
    aimed at generating Verilog; and VeriGen [[5](#bib.bib5)] is a fine-tuned CodeGen
    model; another work just used GPT-4 directly to co-author a microprocessor [[7](#bib.bib7)]
    sent for tapeout. Commercial models also exist, such as RapidGPT [[17](#bib.bib17)],
    ChipNeMo [[18](#bib.bib18)], JedAI [[19](#bib.bib19)], and Synopsys.ai [[20](#bib.bib20)].
    Test-focused work is typically aimed at evaluating the models, e.g. VerilogEval [[8](#bib.bib8)]
    offers a set of standard benchmarks derived from HDLBits [[21](#bib.bib21)] for
    LLMs writing Verilog. LLM work focusing on design test is more nascent. [[22](#bib.bib22)]
    explored generating SystemVerilog assertions with some success, and [[23](#bib.bib23)]
    examined bug-finding in isolation without considering tool feedback.
  prefs: []
  type: TYPE_NORMAL
- en: III Prompting LLMs for Design and Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: III-A Methodology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Figure 1](#S3.F1 "In III-A Methodology ‣ III Prompting LLMs for Design and
    Test ‣ Evaluating LLMs for Hardware Design and Test") illustrates the main experimental
    structure for our design and test focused investigation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b9e272c7303e74afa785b90e679c8a7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Simplified LLM conversation flowchart'
  prefs: []
  type: TYPE_NORMAL
- en: The prompts in [Figure 2](#S3.F2 "In III-A Methodology ‣ III Prompting LLMs
    for Design and Test ‣ Evaluating LLMs for Hardware Design and Test") (lines 2-8
    updated for each design) and [Figure 3](#S3.F3 "In III-A Methodology ‣ III Prompting
    LLMs for Design and Test ‣ Evaluating LLMs for Hardware Design and Test") (always
    constant) are given to the LLM. Then, the output is inspected to determine if
    it meets the I/O design specification. If not, it is regenerated with the same
    prompt up to five times, and is deemed failing if it cannot meet specifications.
  prefs: []
  type: TYPE_NORMAL
- en: Once the design and testbench have been written, they are compiled with Icarus
    Verilog (iverilog) [[24](#bib.bib24)] and, if the compilation succeeds, simulated—closing
    the loop between design and test. If no errors are reported then the design passes
    with no feedback necessary (NFN). If instead either of those actions report errors
    they are fed back into the LLM and it is asked to “Please provide fixes.”, referred
    to as tool feedback (TF). However, LLMs cannot always complete designs. If we
    observe the same error or type of error appearing three times, then simple human
    feedback (SHF) is given by the user, usually by stating what type of problem in
    Verilog would cause this error (e.g. syntax error in declaring a signal). If the
    error continues, moderate human feedback (MHF) is given with more directed information
    being given to the tool to identify the specific error, and if the error persists
    then advanced human feedback (AHF) is given which relies on pointing out precisely
    where the error is and the method of fixing it. Once the design compiles and simulates
    with no failing test cases, it is considered a success. If advanced feedback does
    not fix the error or should the user need to write any Verilog to address the
    error, the test is considered a failure. The test is also considered a failure
    if the conversation exceeds 25 messages. Sometimes, an LLM’s response would be
    cut off due to excessive length. In those cases the model would be prompted with
    “Please continue”. The final code following this sequence would then usually need
    human editing for re-assembly, but no HDL was ever added during this process.
    On other occasions, responses included comments for the user to add their own
    code.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,SSBhbSB0cnlpbmcgdG8gY3JlYXRlIGEgVmVyaWxvZyBtb2RlbCBmb3IgYSBzaGlmdCByZWdpc3Rlci4gSXQgbXVzdCBtZWV0IHRoZSBmb2xsb3dpbmcgc3BlY2lmaWNhdGlvbnM6Ci0gSW5wdXRzOgoJLSBDbG9jawoJLSBBY3RpdmUtbG93IHJlc2V0CgktIERhdGEgKDEgYml0KQoJLSBTaGlmdCBlbmFibGUKLSBPdXRwdXRzOgoJLSBEYXRhICg4IGJpdHMpCkhvdyB3b3VsZCBJIHdyaXRlIGEgZGVzaWduIHRoYXQgbWVldHMgdGhlc2Ugc3BlY2lmaWNhdGlvbnM/)1I  am  trying  to  create  a  Verilog  model  for  a  shift  register.  It  must  meet  the  following  specifications:2-  Inputs:3  -  Clock4  -  Active-low  reset5  -  Data  (1  bit)6  -  Shift  enable7-  Outputs:8  -  Data  (8  bits)9How  would  I  write  a  design  that  meets  these  specifications?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: Design prompt with 8-bit shift register example. Lines 2-8 would
    be updated depending upon the desired spec.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Q2FuIHlvdSBjcmVhdGUgYSBWZXJpbG9nIHRlc3RiZW5jaCBmb3IgdGhpcyBkZXNpZ24/IEl0IHNob3VsZCBiZSBzZWxmLWNoZWNraW5nIGFuZCBtYWRlIHRvIHdvcmsgd2l0aCBpdmVyaWxvZyBmb3Igc2ltdWxhdGlvbiBhbmQgdmFsaWRhdGlvbi4gSWYgdGVzdCBjYXNlcyBzaG91bGQgZmFpbCwgdGhlIHRlc3RiZW5jaCBzaG91bGQgcHJvdmlkZSBlbm91Z2ggaW5mb3JtYXRpb24gdGhhdCB0aGUgZXJyb3IgY2FuIGJlIGZvdW5kIGFuZCByZXNvbHZlZC4=)1Can  you  create  a  Verilog  testbench  for  this  design?  It  should  be  self-checking  and  made  to  work  with  iverilog  for  simulation  and  validation.  If  test  cases  should  fail,  the  testbench  should  provide  enough  information  that  the  error  can  be  found  and  resolved.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Testbench prompt. This prompt remains constant.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B Real-world design constraints on benchmark design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Real-world hardware design has synthesis, budgetary, and tape-out constraints.
    We targeted the real-world platform Tiny Tapeout 3 [[9](#bib.bib9)], which sells
    small areas (1000 standard cells) of a Skywater 130nm shuttle. This adds constraints
    to the design: a limit on IO – each design was allowed 8 bits of input and 8 bits
    of output. We reserved 3 bits of input for a multiplexer to choose a benchmark,
    so we could have $2^{3}=8$ benchmarks. Each benchmark could only have 5 input
    bits, including clock and reset. The Tiny Tapeout toolflow relies on OpenLane [[25](#bib.bib25)]:
    we were restricted to Verilog-2001. Some benchmarks had requirements beyond the
    initial design, to examine how LLMs handled different constraints. The sequence
    generator and detector were given patterns to generate or detect respectively,
    ABRO was asked to use one-hot state encoding, and LFSR had an initial state and
    tap locations.'
  prefs: []
  type: TYPE_NORMAL
- en: III-C Challenge benchmarks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The benchmarks given in [Table I](#S3.T1 "In III-C Challenge benchmarks ‣ III
    Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware Design and Test")
    were designed to give insight in to hardware that the different LLMs could write.
    The functions are implemented in hardware, and taught at the level of an undergraduate
    digital logic curriculum.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: Benchmark Descriptions'
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 8-bit Shift Register | Shift register with enable |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence Generator | Generates a specific sequence of eight 8-bit values
    |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence Detector | Detects if the correct 8 3-bit inputs were given consecutively
    |'
  prefs: []
  type: TYPE_TB
- en: '| ABRO FSM | One-hot state machine for detecting inputs A and B to emit O |'
  prefs: []
  type: TYPE_TB
- en: '| Binary to BCD | Converts a 5-bit binary input into an 8-bit BCD output |'
  prefs: []
  type: TYPE_TB
- en: '| LFSR | 8-bit Linear Feedback Shift Register |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Light FSM | Cycle between 3 states based on a number of clock cycles
    |'
  prefs: []
  type: TYPE_TB
- en: '| Dice Roller | Simulated rolling either a 4, 6, 8, or 20-sided die |'
  prefs: []
  type: TYPE_TB
- en: 'III-D Model evaluation: Metrics'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE II: Evaluated Conversational LLMs'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Release Date | Company | Open Access | Open Source |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT-4 [[26](#bib.bib26)] | 14 Mar. 2023 | OpenAI | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT-3.5 [[27](#bib.bib27)] | 30 Nov. 2022 | OpenAI | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| Bard [[15](#bib.bib15)] | 21 Mar. 2023 | Google | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| HuggingChat [[16](#bib.bib16)] | April 2023 | HuggingFace | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: 'The four conversational LLMs in [Table II](#S3.T2 "In III-D Model evaluation:
    Metrics ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware
    Design and Test") were evaluated in this work. As an initial qualifier, each model
    was prompted with the 8-bit shift register benchmark prompt with the intention
    of proceeding through the conversational flow in [Section III-A](#S3.SS1 "III-A
    Methodology ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware
    Design and Test"). The response from ChatGPT-4 is given in [Figure 4](#S3.F4 "In
    III-D Model evaluation: Metrics ‣ III Prompting LLMs for Design and Test ‣ Evaluating
    LLMs for Hardware Design and Test"), with the ChatGPT-3.5, Bard, and HuggingChat
    responses given in the Appendix. While ChatGPT models were able to meet the specifications
    and begin moving through the design flow, Bard and HuggingChat failed to meet
    the initial criteria of the specifications even when the initial prompts were
    regenerated five times. Bard failed to meet design specifications (Figure [2](#A0.F2
    "Figure 2 ‣ Evaluating LLMs for Hardware Design and Test")) and HuggingChat’s
    Verilog grew nonsensical past the module definition (Figure [3](#A0.F3 "Figure
    3 ‣ Evaluating LLMs for Hardware Design and Test")). Given the poor performance
    of Bard and HuggingChat on the qualifier benchmark prompt, we did the full set
    of tests only for ChatGPT models, both of which were able to continue with the
    conversational flow. For all benchmarks, we ran the conversations three times,
    as the LLMs are non-deterministic and respond differently to the same prompts.
    The repetition measures how consistently they can create benchmarks and testbenches,
    and how different runs with the same prompt differ in their implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,bW9kdWxlIHNoaWZ0X3JlZ2lzdGVyICgKICAgIGlucHV0IHdpcmUgY2xrLAogICAgaW5wdXQgd2lyZSByZXNldF9uLAogICAgaW5wdXQgd2lyZSBkYXRhX2luLAogICAgaW5wdXQgd2lyZSBzaGlmdF9lbmFibGUsCiAgICBvdXRwdXQgcmVnIFs3OjBdIGRhdGFfb3V0Cik7CgphbHdheXMgQChwb3NlZGdlIGNsayBvciBuZWdlZGdlIHJlc2V0X24pIGJlZ2luCiAgICBpZiAoIXJlc2V0X24pIGJlZ2luCiAgICAgICAgZGF0YV9vdXQgPD0gOCdiMDsgLy8gQWN0aXZlLWxvdyByZXNldDogQ2xlYXIgdGhlIHJlZ2lzdGVyIHdoZW4gcmVzZXRfbiBpcyBsb3cKICAgIGVuZCBlbHNlIGlmIChzaGlmdF9lbmFibGUpIGJlZ2luCiAgICAgICAgZGF0YV9vdXQgPD0ge2RhdGFfb3V0WzY6MF0sIGRhdGFfaW59OyAvLyBTaGlmdCB0aGUgcmVnaXN0ZXIgYW5kIGluc2VydCB0aGUgbmV3IGRhdGEgYml0CiAgICBlbmQKZW5kCgplbmRtb2R1bGU=)1module  shift_register  (2  input  wire  clk,3  input  wire  reset_n,4  input  wire  data_in,5  input  wire  shift_enable,6  output  reg  [7:0]  data_out7);89always  @(posedge  clk  or  negedge  reset_n)  begin10  if  (!reset_n)  begin11  data_out  <=  8’b0;  //  Active-low  reset:  Clear  the  register  when  reset_n  is  low12  end  else  if  (shift_enable)  begin13  data_out  <=  {data_out[6:0],  data_in};  //  Shift  the  register  and  insert  the  new  data  bit14  end15end1617endmodule'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: 8-bit shift register attempt from ChatGPT-4.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compliant vs. Non-compliant designs: Since the LLMs created both the functional
    code and testbenches, even if a design ‘passes’ the testbench it may still be
    ‘non-compliant’ with the original specification (e.g. an empty testbench which
    just returns ‘success!’). We therefore manually mark each passing result as ‘compliant’
    or ‘non-compliant’.'
  prefs: []
  type: TYPE_NORMAL
- en: III-E Example conversation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Figure 5](#S3.F5 "In III-E Example conversation ‣ III Prompting LLMs for Design
    and Test ‣ Evaluating LLMs for Hardware Design and Test") provides the examples
    of the remainder of the conversation with ChatGPT-4 for the shift register T1—for
    succinctness, we remove the portions of the response that are irrelevant. This
    conversation flow follows the initial design prompt in [Figure 2](#S3.F2 "In III-A
    Methodology ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware
    Design and Test")), the design returned in [Figure 4](#S3.F4 "In III-D Model evaluation:
    Metrics ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware
    Design and Test"), and the testbench prompt in [Figure 3](#S3.F3 "In III-A Methodology
    ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware Design
    and Test")). Unfortunately, the testbench has erroneous traces (relevant portion
    presented in [Figure 5(a)](#S3.F5.sf1 "In Figure 5 ‣ III-E Example conversation
    ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware Design
    and Test")). When simulated, this will print error messages. These are returned
    to ChatGPT-4 using the message in [Figure 5(b)](#S3.F5.sf2 "In Figure 5 ‣ III-E
    Example conversation ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs
    for Hardware Design and Test"). This prompts ChatGPT-4 to repair the testbench,
    giving the code in [Figure 5(c)](#S3.F5.sf3 "In Figure 5 ‣ III-E Example conversation
    ‣ III Prompting LLMs for Design and Test ‣ Evaluating LLMs for Hardware Design
    and Test"). The errors are resolved, and the design and testbench now compile
    and show passing simulation, meaning that the conversational design flow criteria
    is met.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Ly8gVGVzdCBjYXNlIDE6IFNpbXBsZSBzaGlmdApkYXRhX2luID0gMSdiMTsKc2hpZnRfZW5hYmxlID0gMSdiMTsKcmVwZWF0ICg4KSBAKHBvc2VkZ2UgY2xrKTsKaWYgKGRhdGFfb3V0ICE9PSA4J2IxMDAwMDAwMCkgJGRpc3BsYXkoIkVycm9yOiBUZXN0IGNhc2UgMSBmYWlsZWQuIEV4cGVjdGVkOiAxMDAwMDAwMCwgUmVjZWl2ZWQ6ICViIiwgZGF0YV9vdXQpOwoKLy8gVGVzdCBjYXNlIDI6IFNoaWZ0IHdpdGggYWx0ZXJuYXRpbmcgYml0cwovLyAuLi4gU1RJTVVMVVMgVFJVTkNBVEVEIEZPUiBTUEFDRQppZiAoZGF0YV9vdXQgIT09IDgnYjEwMTAxMDEwKSAkZGlzcGxheSgiRXJyb3I6IFRlc3QgY2FzZSAyIGZhaWxlZC4gRXhwZWN0ZWQ6IDEwMTAxMDEwLCBSZWNlaXZlZDogJWIiLCBkYXRhX291dCk7CgovLyBUZXN0IGNhc2UgMzogU2hpZnQgd2l0aG91dCBzaGlmdF9lbmFibGUKZGF0YV9pbiA9IDEnYjA7CnNoaWZ0X2VuYWJsZSA9IDEnYjA7CkAocG9zZWRnZSBjbGspOwppZiAoZGF0YV9vdXQgIT09IDgnYjEwMTAxMDEwKSAkZGlzcGxheSgiRXJyb3I6IFRlc3QgY2FzZSAzIGZhaWxlZC4gRXhwZWN0ZWQ6IDEwMTAxMDEwLCBSZWNlaXZlZDogJWIiLCBkYXRhX291dCk7CgouLi4KCi8vIERpc3BsYXkgc3VjY2VzcyBtZXNzYWdlIGFuZCBlbmQgc2ltdWxhdGlvbgokZGlzcGxheSgiQWxsIHRlc3QgY2FzZXMgcGFzc2VkISIpOwokZmluaXNoOw==)1//  Test  case  1:  Simple  shift2data_in  =  1’b1;3shift_enable  =  1’b1;4repeat  (8)  @(posedge  clk);5if  (data_out  !==  8’b10000000)  $display("Error:  Test  case  1  failed.  Expected:  10000000,  Received:  %b",  data_out);67//  Test  case  2:  Shift  with  alternating  bits8//  ...  STIMULUS  TRUNCATED  FOR  SPACE9if  (data_out  !==  8’b10101010)  $display("Error:  Test  case  2  failed.  Expected:  10101010,  Received:  %b",  data_out);1011//  Test  case  3:  Shift  without  shift_enable12data_in  =  1’b0;13shift_enable  =  1’b0;14@(posedge  clk);15if  (data_out  !==  8’b10101010)  $display("Error:  Test  case  3  failed.  Expected:  10101010,  Received:  %b",  data_out);1617...1819//  Display  success  message  and  end  simulation20$display("All  test  cases  passed!");21$finish;'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Portion of 8-bit shift register testbench with errors
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,V2hlbiBydW5uaW5nIHRoZSBzaW11bGF0aW9uIGl0IGdpdmVzIHRoZSBmb2xsb3dpbmcgb3V0cHV0LiBQbGVhc2UgcHJvdmlkZSBmaXhlZCBjb2RlLgoKRXJyb3I6IFRlc3QgY2FzZSAxIGZhaWxlZC4gRXhwZWN0ZWQ6IDEwMDAwMDAwLCBSZWNlaXZlZDogMDExMTExMTEKRXJyb3I6IFRlc3QgY2FzZSAyIGZhaWxlZC4gRXhwZWN0ZWQ6IDEwMTAxMDEwLCBSZWNlaXZlZDogMDEwMTAxMDEKRXJyb3I6IFRlc3QgY2FzZSAzIGZhaWxlZC4gRXhwZWN0ZWQ6IDEwMTAxMDEwLCBSZWNlaXZlZDogMDEwMTAxMDEKQWxsIHRlc3QgY2FzZXMgcGFzc2VkIQ==)1When  running  the  simulation  it  gives  the  following  output.  Please  provide  fixed  code.23Error:  Test  case  1  failed.  Expected:  10000000,  Received:  011111114Error:  Test  case  2  failed.  Expected:  10101010,  Received:  010101015Error:  Test  case  3  failed.  Expected:  10101010,  Received:  010101016All  test  cases  passed!'
  prefs: []
  type: TYPE_NORMAL
- en: (b) Tool feedback prompt for 8-bit shift register
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Ly8gVGVzdCBjYXNlIDE6IFNpbXBsZSBzaGlmdApkYXRhX2luID0gMSdiMTsKc2hpZnRfZW5hYmxlID0gMSdiMTsKcmVwZWF0ICg4KSBAKHBvc2VkZ2UgY2xrKTsKaWYgKGRhdGFfb3V0ICE9PSBbXHRleHRiZntcdGV4dHR0e1xobHs4J2IwMTExMTExMX19fV0pICRkaXNwbGF5KCJFcnJvcjogVGVzdCBjYXNlIDEgZmFpbGVkLiBFeHBlY3RlZDogW1x0ZXh0YmZ7XHRleHR0dHtcaGx7MDExMTExMTF9fX1dLCBSZWNlaXZlZDogJWIiLCBkYXRhX291dCk7CgovLyBUZXN0IGNhc2UgMjogU2hpZnQgd2l0aCBhbHRlcm5hdGluZyBiaXRzCi8vIC4uLiBTVElNVUxVUyBUUlVOQ0FURUQgRk9SIFNQQUNFCmlmIChkYXRhX291dCAhPT0gW1x0ZXh0YmZ7XHRleHR0dHtcaGx7OCdiMDEwMTAxMDF9fX1dKSAkZGlzcGxheSgiRXJyb3I6IFRlc3QgY2FzZSAyIGZhaWxlZC4gRXhwZWN0ZWQ6IFtcdGV4dGJme1x0ZXh0dHR7XGhsezAxMDEwMTAxfX19XSwgUmVjZWl2ZWQ6ICViIiwgZGF0YV9vdXQpOwoKLy8gVGVzdCBjYXNlIDM6IFNoaWZ0IHdpdGhvdXQgc2hpZnRfZW5hYmxlCmRhdGFfaW4gPSAxJ2IwOwpzaGlmdF9lbmFibGUgPSAxJ2IwOwpAKHBvc2VkZ2UgY2xrKTsKaWYgKGRhdGFfb3V0ICE9PSBbXHRleHRiZntcdGV4dHR0e1xobHs4J2IwMTAxMDEwMX19fV0pICRkaXNwbGF5KCJFcnJvcjogVGVzdCBjYXNlIDMgZmFpbGVkLiBFeHBlY3RlZDogW1x0ZXh0YmZ7XHRleHR0dHtcaGx7MDEwMTAxMDF9fX1dLCBSZWNlaXZlZDogJWIiLCBkYXRhX291dCk7CgouLi4KCi8vIERpc3BsYXkgc3VjY2VzcyBtZXNzYWdlIGFuZCBlbmQgc2ltdWxhdGlvbgokZGlzcGxheSgiQWxsIHRlc3QgY2FzZXMgcGFzc2VkISIpOwokZmluaXNoOwo=)1//  Test  case  1:  Simple  shift2data_in  =  1’b1;3shift_enable  =  1’b1;4repeat  (8)  @(posedge  clk);5if  (data_out  !==  8’b01111111)  $display("Error:  Test  case  1  failed.  Expected:  01111111,  Received:  %b",  data_out);67//  Test  case  2:  Shift  with  alternating  bits8//  ...  STIMULUS  TRUNCATED  FOR  SPACE9if  (data_out  !==  8’b01010101)  $display("Error:  Test  case  2  failed.  Expected:  01010101,  Received:  %b",  data_out);1011//  Test  case  3:  Shift  without  shift_enable12data_in  =  1’b0;13shift_enable  =  1’b0;14@(posedge  clk);15if  (data_out  !==  8’b01010101)  $display("Error:  Test  case  3  failed.  Expected:  01010101,  Received:  %b",  data_out);1617...1819//  Display  success  message  and  end  simulation20$display("All  test  cases  passed!");21$finish;'
  prefs: []
  type: TYPE_NORMAL
- en: (c) Corrected portion of testbench code. Replaced values bold / highlighted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5: Remaining portions of the successful shift register T1 conversation
    with ChatGPT-4\. The design is compliant.'
  prefs: []
  type: TYPE_NORMAL
- en: IV Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TABLE III: Benchmark challenge results'
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | Test Set | ChatGPT-4 | ChatGPT-3.5 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Outcome | Compliant | # Messages | Outcome | Compliant | # Messages |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Shift Register | T1 | TF | ✓ | 3 | SHF | ✓ | 13 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | TF | ✓ | 9 | FAIL | - | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | AHF | ✓ | 15 | FAIL | - | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence Gen. | T1 | AHF | ✓ | 14 | FAIL | - | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | TF | ✓ | 4 | FAIL | - | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | AHF | ✓ | 20 | FAIL | - | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence Det. | T1 | FAIL | - | 24 | FAIL | - | 21 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | SHF | ✓ | 9 | SHF | ✗ | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | TF | ✓ | 13 | SHF | ✗ | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| ABRO | T1 | FAIL | - | 16 | FAIL | - | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | AHF | ✓ | 20 | MHF | ✓ | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | TF | ✓ | 12 | NFN | ✗ | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| LFSR | T1 | TF | ✓ | 12 | FAIL | - | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | SHF | ✓ | 7 | TF | ✓ | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | SHF | ✓ | 9 | FAIL | - | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Binary to BCD | T1 | TF | ✓ | 4 | SHF | ✗ | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | NFN | ✓ | 2 | FAIL | - | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | SHF | ✓ | 9 | TF | ✗ | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Light | T1 | TF | ✓ | 4 | FAIL | - | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | SHF | ✓ | 12 | FAIL | - | 13 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | TF | ✓ | 5 | FAIL | - | 18 |'
  prefs: []
  type: TYPE_TB
- en: '| Dice Roller | T1 | SHF | ✗ | 8 | MHF | ✗ | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| T2 | SHF | ✓ | 9 | FAIL | - | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| T3 | SHF | ✗ | 18 | NFN | ✗ | 3 |'
  prefs: []
  type: TYPE_TB
- en: 'All chat logs are in [[10](#bib.bib10)]. [Table III](#S4.T3 "In IV Results
    ‣ Evaluating LLMs for Hardware Design and Test") shows the results of the three
    test-sets of benchmarks with ChatGPT-4 and -3.5. Experiment dates: The ChatGPT
    LLMs evolve over time. Our study was performed between 06 Apr and 12 May, 2023.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-A Simulation Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ChatGPT-4 performed well. The majority of benchmarks passed, most of which required
    only tool feedback. ChatGPT-4 most frequently needed human feedback in testbench
    design. Several failure modes were consistent, with a common error being the addition
    of SystemVerilog-specific syntax in the design or testbench (not supported in
    iverilog). Testbenches produced by ChatGPT-4 were not comprehensive. Still, a
    majority of the designs that passed accompanying testbenches were deemed compliant.
    The two non-compliant ‘passes’ were Dice Rollers which did not produce pseudo-random
    outputs. The Dice Roller from test set T1 would output a 2 for one roll and then
    only 1 for all subsequent rolls, regardless of the die selected. Meanwhile, Dice
    Roller T3 would change values, but between a small set (depending on the chosen
    die) which is repeated. We synthesized test set T1 from ChatGPT-4 conversations
    for Tiny Tapeout 3, adding a wrapper module designed by ChatGPT-4\. The design
    took 85 combinational units, 4 diodes, 44 flip flops, 39 buffers, 300 taps.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S4.F6.pic1" class="ltx_picture ltx_centering" height="448" overflow="visible"
    version="1.1" width="538"><g transform="translate(0,448) matrix(1 0 0 -1 0 0)
    translate(-0.28,0) translate(0,-0.28)"><g stroke-width="0.4pt" fill="#000000"
    stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject
    width="538" height="448" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer
    to caption](img/2a607ec60e08c0e0902acb3f9b49e058.png)</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Tiny Tapeout 3 carrier board, with the chip in the green box. The
    board has and headers to interact with the chip to test the projects on it.'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT-3.5 performed worse than ChatGPT-4, with most conversations yielding
    a failed benchmark, and a majority of those that passed their testbenches being
    non-compliant. Modes of failure were less consistent with ChatGPT-3.5 than they
    were for ChatGPT-4, with many issues introduced between each conversation and
    benchmark. It required corrections to design and testbenches more often than ChatGPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Silicon Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Upon receiving the Tiny Tapeout 3 chip and carrier board, shown in [Figure 6](#S4.F6
    "In IV-A Simulation Results ‣ IV Results ‣ Evaluating LLMs for Hardware Design
    and Test"), the benchmarks were tested to ensure they matched the simulations.
    Each benchmark behaved in hardware as expected from the simulations ([Figure 4](#A0.F4
    "In Evaluating LLMs for Hardware Design and Test")), verifying that our design
    and verification can yield functional chips.
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ability to generate and test Verilog designs depends on the LLM. ChatGPT-4
    performed adequately, though it required human feedback for 12 of the 24 conversations
    to be successful and compliant with the specifications. When fixing errors, ChatGPT-4
    required several messages—even with minor errors, as it struggled to understand
    specific lines that caused error messages in iverilog. The errors it added tended
    to repeat between conversations. ChatGPT-4 struggled much more to create functioning
    testbenches than designs. The majority of benchmarks required little to no modification
    of the design, necessitating testbench repair. This is particularly true of FSMs,
    as the model seemed unable to create a testbench which properly checks the output
    without significant feedback regarding the state transitions and corresponding
    expected outputs. ChatGPT-3.5, on the other hand, struggled with both functional
    designs and testbenches. HuggingFace’s HuggingChat was the worst-performer, struggling
    at times to even write coherent Verilog. Google’s Bard was better at this, but
    was unable to follow instructions with enough detail that it could be evaluated.
    A major limitation with the performance of all models was in authorship of testbenches.
    We believe this reflects (non-) availability of open-source training data. The
    LLMs tested are non-deterministic, so the generated output was not consistent
    across tests, even for same input prompt. We performed a limited repeatability
    study by repeating experiments 3 times, but this does not reach statistical significance.
  prefs: []
  type: TYPE_NORMAL
- en: V Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While current state of the art LLMs can be used for design tasks, they are still
    underperforming when it comes to test. Our investigation shows that ChatGPT-3.5
    and ChatGPT-4, the two premier models in this space, do not consistently understand
    or fix errors that they encounter during code authorship, nor can they reliably
    produce comprehensive testbenches in isolation. However, when an experienced hardware
    engineer is able to provide improved feedback, the most capable models were able
    to create simple and functioning designs with no direct Verilog written by the
    user. We believe that improvements in the LLM space, whether that be from new
    models or fine-tuning, could result in tools capable of simplifying hardware design
    and increasing designer productivity, especially considering common or simple
    hardware structures.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] H. Foster, “Wilson Research Group Functional Verification Study 2020,”
    Nov. 2020, section: News. [Online]. Available: [https://blogs.sw.siemens.com/verificationhorizons/2020/11/05/part-1-the-2020-wilson-research-group-functional-verification-study/](https://blogs.sw.siemens.com/verificationhorizons/2020/11/05/part-1-the-2020-wilson-research-group-functional-verification-study/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] P. Coussy and A. Morawiec, *High-level synthesis*.   Springer, 2010, vol. 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] V. Hamolia and V. Melnyk, “A Survey of Machine Learning Methods and Applications
    in Electronic Design Automation,” in *2021 11th International Conference on Advanced
    Computer Information Technologies (ACIT)*, Sep. 2021, pp. 757–760\. [Online].
    Available: [https://ieeexplore.ieee.org/abstract/document/9548117](https://ieeexplore.ieee.org/abstract/document/9548117)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] H. Pearce, B. Tan, and R. Karri, “DAVE: Deriving Automatically Verilog
    from English,” in *2020 ACM/IEEE 2nd Workshop on Machine Learning for CAD (MLCAD)*,
    Nov. 2020, pp. 27–32.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-Gavitt,
    and S. Garg, “Benchmarking Large Language Models for Automated Verilog RTL Code
    Generation,” in *2023 Design, Automation & Test in Europe Conference & Exhibition
    (DATE)*, Apr. 2023, pp. 1–6, iSSN: 1558-1101\. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10137086](https://ieeexplore.ieee.org/abstract/document/10137086)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] S. Thakur, B. Ahmad, H. Pearce, B. Tan, B. Dolan-Gavitt, R. Karri, and
    S. Garg, “VeriGen: A Large Language Model for Verilog Code Generation,” *ACM Transactions
    on Design Automation of Electronic Systems*, Feb. 2024, just Accepted. [Online].
    Available: [https://dl.acm.org/doi/10.1145/3643681](https://dl.acm.org/doi/10.1145/3643681)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] J. Blocklove, S. Garg, R. Karri, and H. Pearce, “Chip-Chat: Challenges
    and Opportunities in Conversational Hardware Design,” in *2023 ACM/IEEE 5th Workshop
    on Machine Learning for CAD (MLCAD)*, Sep. 2023, pp. 1–6\. [Online]. Available:
    [https://ieeexplore.ieee.org/document/10299874](https://ieeexplore.ieee.org/document/10299874)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] M. Liu, N. Pinckney, B. Khailany, and H. Ren, “VerilogEval: Evaluating
    Large Language Models for Verilog Code Generation,” Sep. 2023, arXiv:2309.07544
    [cs]. [Online]. Available: [http://arxiv.org/abs/2309.07544](http://arxiv.org/abs/2309.07544)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] “Tiny Tapeout,” May 2023\. [Online]. Available: [https://tinytapeout.com/](https://tinytapeout.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] A. f. b. review, “Repository for ”Evaluating LLMs for Hardware Design
    and Test”,” Apr. 2024\. [Online]. Available: [https://zenodo.org/records/10947127](https://zenodo.org/records/10947127)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan,
    R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler,
    M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford,
    I. Sutskever, and D. Amodei, “Language Models are Few-Shot Learners,” in *Advances
    in Neural Information Processing Systems*, H. Larochelle, M. Ranzato, R. Hadsell,
    M. F. Balcan, and H. Lin, Eds., vol. 33.   Curran Associates, Inc., 2020, pp.
    1877–1901\. [Online]. Available: [https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards,
    Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf,
    G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser,
    M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis,
    E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang,
    I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike,
    J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati,
    K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and
    W. Zaremba, “Evaluating Large Language Models Trained on Code,” Jul. 2021, arXiv:2107.03374
    [cs]. [Online]. Available: [http://arxiv.org/abs/2107.03374](http://arxiv.org/abs/2107.03374)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is All you Need,” in *Advances in Neural
    Information Processing Systems*, vol. 30.   Curran Associates, Inc., 2017\. [Online].
    Available: [https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] OpenAI, “ChatGPT: Optimizing Language Models for Dialogue,” Nov. 2022\.
    [Online]. Available: [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] S. Pichai, “An important next step on our AI journey,” Feb. 2023\. [Online].
    Available: [https://blog.google/technology/ai/bard-google-ai-search-updates/](https://blog.google/technology/ai/bard-google-ai-search-updates/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] HuggingFace, “HuggingChat,” May 2023\. [Online]. Available: [https://huggingface.co/chat](https://huggingface.co/chat)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] “Welcome to RapidGPT | PrimisAI.” [Online]. Available: [https://primis.ai/docs](https://primis.ai/docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] M. Liu, T.-D. Ene, R. Kirby, C. Cheng, N. Pinckney, R. Liang, J. Alben,
    H. Anand, S. Banerjee, I. Bayraktaroglu, B. Bhaskaran, B. Catanzaro, A. Chaudhuri,
    S. Clay, B. Dally, L. Dang, P. Deshpande, S. Dhodhi, S. Halepete, E. Hill, J. Hu,
    S. Jain, B. Khailany, K. Kunal, X. Li, H. Liu, S. Oberman, S. Omar, S. Pratty,
    J. Raiman, A. Sarkar, Z. Shao, H. Sun, P. P. Suthar, V. Tej, K. Xu, and H. Ren,
    “ChipNeMo: Domain-Adapted LLMs for Chip Design,” Nov. 2023, arXiv:2311.00176 [cs].
    [Online]. Available: [http://arxiv.org/abs/2311.00176](http://arxiv.org/abs/2311.00176)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] “Cadence JedAI Generative AI Solution for Chip, System, and Product Design.”
    [Online]. Available: [https://www.cadence.com/en_US/home/solutions/joint-enterprise-data-ai-platform.html](https://www.cadence.com/en_US/home/solutions/joint-enterprise-data-ai-platform.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] “Redefining Chip Design with AI-Powered EDA Tools | Synopsys.ai | Synopsys
    Blog.” [Online]. Available: [https://www.synopsys.com/blogs/chip-design/synopsys-ai-eda-tools.html](https://www.synopsys.com/blogs/chip-design/synopsys-ai-eda-tools.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] “Problem sets - HDLBits.” [Online]. Available: [https://hdlbits.01xz.net/wiki/Problem_sets](https://hdlbits.01xz.net/wiki/Problem_sets)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] R. Kande, H. Pearce, B. Tan, B. Dolan-Gavitt, S. Thakur, R. Karri, and
    J. Rajendran, “(Security) Assertions by Large Language Models,” *IEEE Transactions
    on Information Forensics and Security*, pp. 1–1, 2024, conference Name: IEEE Transactions
    on Information Forensics and Security. [Online]. Available: [https://ieeexplore.ieee.org/abstract/document/10458667](https://ieeexplore.ieee.org/abstract/document/10458667)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] B. Ahmad, B. Tan, R. Karri, and H. Pearce, “FLAG: Finding Line Anomalies
    (in code) with Generative AI,” Jun. 2023, arXiv:2306.12643 [cs]. [Online]. Available:
    [http://arxiv.org/abs/2306.12643](http://arxiv.org/abs/2306.12643)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] “Icarus Verilog.” [Online]. Available: [http://iverilog.icarus.com/home](http://iverilog.icarus.com/home)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] “OpenLane,” May 2023, original-date: 2020-07-20T19:35:02Z. [Online]. Available:
    [https://github.com/The-OpenROAD-Project/OpenLane](https://github.com/The-OpenROAD-Project/OpenLane)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] OpenAI, “GPT-4,” Mar. 2023\. [Online]. Available: [https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] ——, “Introducing ChatGPT,” Nov. 2022\. [Online]. Available: [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figures A1, A2, and A3 give additional examples of LLMs responding to the initial
    prompt for an 8-bit shift register. Figure A2 highlights a repeated error made
    by Bard in generating a proper module definition.
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,bW9kdWxlIHNoaWZ0X3JlZ2lzdGVyKAogICAgaW5wdXQgY2xrLAogICAgaW5wdXQgcmVzZXRfbiwKICAgIGlucHV0IGRhdGEsCiAgICBpbnB1dCBzaGlmdF9lbmFibGUsCiAgICBvdXRwdXQgcmVnIFs3OjBdIHEKKTsKCmFsd2F5cyBAKHBvc2VkZ2UgY2xrLCBuZWdlZGdlIHJlc2V0X24pIGJlZ2luCiAgICBpZiAoIXJlc2V0X24pIGJlZ2luCiAgICAgICAgcSA8PSA4J2IwOwogICAgZW5kIGVsc2UgaWYgKHNoaWZ0X2VuYWJsZSkgYmVnaW4KICAgICAgICBxIDw9IHtxWzY6MF0sIGRhdGF9OwogICAgZW5kCmVuZAoKZW5kbW9kdWxlCg==)1module  shift_register(2  input  clk,3  input  reset_n,4  input  data,5  input  shift_enable,6  output  reg  [7:0]  q7);89always  @(posedge  clk,  negedge  reset_n)  begin10  if  (!reset_n)  begin11  q  <=  8’b0;12  end  else  if  (shift_enable)  begin13  q  <=  {q[6:0],  data};14  end15end1617endmodule'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: 8-bit shift register attempt from ChatGPT-3.5.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,bW9kdWxlIHNoaWZ0X3JlZ2lzdGVyICgKICBpbnB1dCBjbGssCiAgaW5wdXQgcnN0LAogIGlucHV0IFs3OjBdIGRhdGEsCiAgaW5wdXQgc2hpZnRfZW5hYmxlLAogIG91dHB1dCByZWcgWzc6MF0gZGF0YV9vdXQKKTsKCiAgYWx3YXlzIEAocG9zZWRnZSBjbGsgb3IgcG9zZWRnZSByc3QpIGJlZ2luCiAgICBpZiAocnN0KSBiZWdpbgogICAgICBkYXRhX291dCA8PSA4J2IwOwogICAgZW5kIGVsc2UgYmVnaW4KICAgICAgaWYgKHNoaWZ0X2VuYWJsZSkgYmVnaW4KICAgICAgICBkYXRhX291dCA8PSB7ZGF0YV9vdXRbNjowXSwgZGF0YX07CiAgICAgIGVuZAogICAgZW5kCiAgZW5kCgplbmRtb2R1bGU=)1module  shift_register  (2  input  clk,3  input  rst,4  input  [7:0]  data,5  input  shift_enable,6  output  reg  [7:0]  data_out7);89  always  @(posedge  clk  or  posedge  rst)  begin10  if  (rst)  begin11  data_out  <=  8’b0;12  end  else  begin13  if  (shift_enable)  begin14  data_out  <=  {data_out[6:0],  data};15  end16  end17  end1819endmodule'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: 8-bit shift register attempt by Bard. Input on line 4 is too wide.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,bW9kdWxlIFNoaWZ0UmVnaXN0ZXIoaW5wdXQgY2xrLCBpbnB1dCByc3RfbiwgaW5wdXQgZGF0YV9pbiwgaW5wdXQgc2hmdF9lbiwgb3V0cHV0IHJlZyBbNzowXSBxKTsKCi4uLiAvL2l0IGdlbmVyYXRlcyBhIG51bWJlciBvZiBwYXJhbWV0ZXJzIGhlcmUgd2hpY2ggYXJlIG5vdCByZWZlcnJlZCB0bwoKYXNzaWduIGRhdGFfb3V0ID0gfmRhdGFfaW4gJiBzaGZ0X2VuICYgcnN0X24gPyAxJ2IwIDogKHFbNzoxXSA8PCAxKSB8IHsxJ2IwLCBkYXRhX2lufTsKYWx3YXlzIEAoKikgYmVnaW4KICMgLyogeCdGRiAgKi8gQ0xLX1JRU1REQ0xLICo7CiAjIC9yZXNldF9uIFIwIFIwWyhpbnQqKSYoX0NUTC0tKV0gPD0gMzInaDgwMDBfMDAwMDsKIGlmIChyc3RfbiAmJiAhc2hmdF9lbikgYmVnaW4KICAkc2V0dXBob2xkIChwb3NlZGdlIHJlc2V0X24gLCBuZWdlZGdlIGFjdGl2ZSApIDsKICAkZGlzcGxheSgiKioqIFJFU0VUICoqKlxuIik7CiAgYCNhZGRyIGBhZGRyOmBhZGRyWyhpbnQqKSAmUE9TXWBwb3MgPyhpbnQpICggKChgYWRkcmA6YWRkcltfQUREUl0rICRfSU5UUlRWQUxVKS8yKToxJ2IxO2BhZGRyOihhZGRyPD5gYWRkcilgcG9zICwiRnVsbCBzY2FuIGRvbmUuIikpO2Bjb3V0IT0iRGl2aXNpb24gYnkgemVybyEiICYgJ0AoICFfTFVUKSAmJiAoYGdyYW5kcGEnKT8oc3ByaW50Zihgc25pcGAsc3RybGVuKCZfVEkpLCgkaGFsZipgY291dD4mMSknaGFzaCAoKSk6IHNucHJpbnRmKCFyZXNlcnZlMigoY29uc3QgY2hhciopKHR5cGUoKmBgY291dClzdHJsZW5gYnVmKystPl9HQklUXSkpKSkgb2U9dG1wMiAmJiB0bXAzID8gKF9fZmxhc2gpKCh2b2lkKilyZWFsbG9jKCQoaW50KikoaWR4PSgqKHUqYHB0cmApfCh+KGFkZHJlc3M+CiAgcmVtb3ZlY29tbWVudHMgVHIxRVNyYW4gZGlmZiBncmVkJFxlbGxlb2Zvcm1hdGZsb2F0IGZvcm1hdC0tLS0tLS0tLS0tLS0tLS0tLS0tLS1gY2hhclRtcExpbX0gTGVuIHJvbGxvdmVyIExlbmcgbGVuIExlbiBOb24gUm9sbG92ciBPcHRpbWl6YXRpb25DZW50ZXJ9XG4gcmVzaWRlbnQgQXN5bXB0b3RpY0FzcGVjdH1cbnAgUmVzZXRPcHQgXEFsbCAlcGFyIElEID09IFBDSTAgU1BDIFJlY29uZmlndXJhdGlvbkZlYXR1cmUgc3VwcG9ydGVkIH0gSUYgUFJPUFJJRVRBUlkgQVNQRUNUPWBwb3J0IVxQbHVnCiAgLi4uYGBg)1module  ShiftRegister(input  clk,  input  rst_n,  input  data_in,  input  shft_en,  output  reg  [7:0]  q);23...  //it  generates  a  number  of  parameters  here  which  are  not  referred  to45assign  data_out  =  ~data_in  &  shft_en  &  rst_n  ?  1’b0  :  (q[7:1]  <<  1)  |  {1’b0,  data_in};6always  @(*)  begin7  #  /*  x’FF  */  CLK_RQSTDCLK  *;8  #  /reset_n  R0  R0[(int*)&(_CTL--)]  <=  32’h8000_0000;9  if  (rst_n  &&  !shft_en)  begin10  $setuphold  (posedge  reset_n  ,  negedge  active  )  ;11  $display("***  RESET  ***\n");12  ‘#addr  ‘addr:‘addr[(int*)  &POS]‘pos  ?(int)  (  ((‘addr‘:addr[_ADDR]+  $_INTRTVALU)/2):1’b1;‘addr:(addr<>‘addr)‘pos  ,"Full  scan  done."));‘cout!="Division  by  zero!"  &  ’@(  !_LUT)  &&  (‘grandpa’)?(sprintf(‘snip‘,strlen(&_TI),($half*‘cout>&1)’hash  ()):  snprintf(!reserve2((const  char*)(type(*‘‘cout)strlen‘buf++->_GBIT]))))  oe=tmp2  &&  tmp3  ?  (__flash)((void*)realloc($(int*)(idx=(*(u*‘ptr‘)|(~(address>13  removecomments  Tr1ESran  diff  gred$\elleoformatfloat  format----------------------‘charTmpLim}  Len  rollover  Leng  len  Len  Non  Rollovr  OptimizationCenter}\n  resident  AsymptoticAspect}\np  ResetOpt  \All  %par  ID  ==  PCI0  SPC  ReconfigurationFeature  supported  }  IF  PROPRIETARY  ASPECT=‘port!\Plug14  ...‘‘‘'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: 8-bit ‘shift register’ by HuggingChat (truncated, formatted).'
  prefs: []
  type: TYPE_NORMAL
- en: Figure A4 shows the output of the sequence generator benchmark running on the
    Tiny Tapeout 3 board. This was captured using a DreamSourceLabs USB Logic Analyzer
    in the DSView software. The hexadecimal decoding at the top of the capture shows
    the correct generation of the first five elements of the output sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fc79d8691d80f51f57ef6be46c49b2a0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The output of the sequence generator benchmark running on the Tiny
    Tapeout 3 board. This was captured using a DreamSourceLabs USB Logic Analyzer
    in the DSView software. The hexadecimal decoding at the top of the capture shows
    the correct generation of the first five elements of the output sequence.'
  prefs: []
  type: TYPE_NORMAL
