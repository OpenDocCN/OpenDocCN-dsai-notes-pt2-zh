- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:51:47'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.08806](https://ar5iv.labs.arxiv.org/html/2404.08806)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \lst@NormedDef\languageNormedDefd@verilog
  prefs: []
  type: TYPE_NORMAL
- en: Verilog \lst@SaveOutputDef‘’\quotesngl@verilog\lst@SaveOutputDef“\backtick@verilog\lst@SaveOutputDef‘$\dollar@verilog
    \lst@Keyvlogconstantstyle \lst@Keyvlogdefinestyle \lst@Keyvlogsystemstyle
  prefs: []
  type: TYPE_NORMAL
- en: Matthew DeLorenzo, Vasudev Gohil, Jeyavijayan Rajendran
  prefs: []
  type: TYPE_NORMAL
- en: Texas A&M University, USA
  prefs: []
  type: TYPE_NORMAL
- en: '{matthewdelorenzo, gohil.vasudev, jv.rajendran}@tamu.edu'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have proved effective and efficient in generating
    code, leading to their utilization within the hardware design process. Prior works
    evaluating LLMs’ abilities for register transfer level code generation solely
    focus on functional correctness. However, the creativity associated with these
    LLMs, or the ability to generate novel and unique solutions, is a metric not as
    well understood, in part due to the challenge of quantifying this quality.
  prefs: []
  type: TYPE_NORMAL
- en: To address this research gap, we present CreativEval, a framework for evaluating
    the creativity of LLMs within the context of generating hardware designs. We quantify
    four creative sub-components, fluency, flexibility, originality, and elaboration,
    through various prompting and post-processing techniques. We then evaluate multiple
    popular LLMs (including GPT models, CodeLlama, and VeriGen) upon this creativity
    metric, with results indicating GPT-3.5 as the most creative model in generating
    hardware designs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hardware Design, LLM, Creativity
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recent advancements within artificial intelligence, machine learning, and computing
    performance have resulted in the development of LLMs, which have quickly proven
    to be a widely applicable and successful solution when applied to a variety of
    text-based tasks [[1](#bib.bib1)]. After extensive training on large quantities
    of text data, these transformer-based models [[2](#bib.bib2)] have demonstrated
    the ability to not only successfully interpret the contextual nuances of a provided
    text (or prompt), but also generate effective responses to a near human-like degree [[3](#bib.bib3)].
    This can take the form of summarizing a document, answering and elaborating upon
    questions, and even generating code. The effectiveness and versatility of LLMs
    regarding textual understanding have resulted in their adoption within various
    applications, such as language translation [[4](#bib.bib4)], customer service
    chat-bots [[5](#bib.bib5)], and programming assistants [[1](#bib.bib1)].
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the potential of LLM code generation has recently been explored
    within the integrated circuit (IC) design process [[6](#bib.bib6)], such as within
    the logic design stage. With chip designs continually growing in scale and complexity,
    efforts to increase the automation of this task through LLMs have been explored.
    This includes the evaluation of LLMs’ ability to generate hardware design codes
    from English prompts, leading to promising initial results within various frameworks [[7](#bib.bib7),
    [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)].
  prefs: []
  type: TYPE_NORMAL
- en: With the goal of further optimizing these LLMs to the level of an experienced
    hardware designer, many research efforts have focused on improving performance
    within the metric of code functionality. This includes testing various LLM fine-tuning
    strategies and prompting methods for domain-optimized performance, such as register
    transfer level (RTL) code generation.
  prefs: []
  type: TYPE_NORMAL
- en: However, another dimension to consider when evaluating the ability of a designer,
    absent from previous evaluations, is creativity. This term refers to the capacity
    to think innovatively—the ability to formulate new solutions or connections that
    are effective and unconventional [[11](#bib.bib11)]. When applied to hardware
    code generation, this can take the form of writing programs that are not only
    correct, but also novel, surprising, or valuable when compared to typical design
    approaches. This quality is essential to understanding the greater potential of
    LLMs as a tool for deriving new approaches to hardware design challenges, rather
    than simply a method to accelerate existing design practices. With a quantitative
    method of measuring this concept of creativity within LLM hardware generation,
    valuable insights could be derived, such as how performance could be further improved,
    or how LLMs can be best utilized within the hardware design process.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this absence within the analysis of LLM-based RTL code generation,
    we propose a comparative evaluation framework in which the creativity of LLMs
    can be effectively measured. This assessment is composed of four cognitive subcategories
    of creativity (fluency, flexibility, originality, and elaboration), which are
    quantified and evaluated within the context of generating functional Verilog modules.
    Furthermore, this approach utilizes various prompting structures, generation strategies,
    and post-processing methods, from which the quality and variations of responses
    are utilized to generate a metric for creativity. This work presents the following
    contributions:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To the best of our knowledge, we propose the first framework from which a metric
    for creativity is defined for LLMs within the context of hardware design and code
    generation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We provide a comparative evaluation between state-of-the-art LLMs upon our creativity
    metric and its components, with GPT-3.5 achieving the highest result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To enable future research, we will open-source our framework codebase and datasets
    here: [https://github.com/matthewdelorenzo/CreativEval/](https://github.com/matthewdelorenzo/CreativEval/)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: II Background and Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: II-A LLMs for Code Generation and Hardware Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/806f0d1f98ef70deb68440ea27801ded.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Experimental Framework - calculating creativity of LLMs in Verilog
    code generation.'
  prefs: []
  type: TYPE_NORMAL
- en: Many state-of-the-art LLMs have demonstrated remarkable success in generating
    code when provided only with a natural language description, such as GPT-3.5/4
    [[12](#bib.bib12)], BERT [[13](#bib.bib13)], and Claude [[14](#bib.bib14)], revolutionizing
    the software development process. These models demonstrate promising performance
    in code functionality, such as GPT-4 generating correct code for 67% of programming
    tasks in the HumanEval benchmark in a single response (pass@1) [[15](#bib.bib15),
    [16](#bib.bib16), [17](#bib.bib17)].
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the applications of LLMs within hardware design through RTL code
    generation are explored within various studies, such as DAVE [[18](#bib.bib18)]
    which utilized GPT-2 for this task. VeriGen [[7](#bib.bib7)] then demonstrated
    that fine-tuning smaller models (CodeGen) upon a curated RTL dataset can outperform
    larger models in RTL tests. VerilogEval [[19](#bib.bib19)] presents enhanced LLM
    hardware generation through supervised fine-tuning, and provides an RTL benchmark
    for evaluating functionality in RTL generation. ChipNeMo [[9](#bib.bib9)] applied
    fine-tuning upon open-source models (Llama2 7B/13B) for various hardware design
    tasks. RTLCoder [[20](#bib.bib20)] presents an automated method for expanding
    the RTL dataset used for fine-tuning, resulting in a 7B-parameter model that outperforms
    GPT-3.5 on RTL benchmarks. Other works, including RTLLM [[21](#bib.bib21)] and
    Chip-Chat [[8](#bib.bib8)], explore prompt engineering strategies to enhance the
    quality and scale of LLM-generated designs. Although there is a plethora of work
    on LLM-based RTL generation, none of these prior works assess the creative component
    of LLMs in the hardware design process. We address this shortcoming in this work.
  prefs: []
  type: TYPE_NORMAL
- en: II-B Evaluating Creativity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prior cognitive science studies [[22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24),
    [25](#bib.bib25)] have explored methods in which creative thinking can be effectively
    measured. A widely accepted creativity model [[24](#bib.bib24)] defines four primary
    cognitive dimensions from which divergent thinking, or the ability to generate
    creative ideas through exploring multiple possible solutions [[26](#bib.bib26)],
    can be measured—fluency, flexibility, originality, and elaboration.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fluency. The quantity of relevant and separate ideas able to be derived in response
    to a single given question.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flexibility. The ability to formulate alternative solutions to a given problem
    or example across a variety of categories.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Originality. A measure of how unique or novel a given idea is, differing from
    typical responses or solutions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elaboration. The ability to expand upon or refine a given idea. This can include
    the ability to construct complex solutions utilizing provided, basic concepts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: These subcategories have been widely in evaluating human creativity within educational
    research, including various studies of students [[27](#bib.bib27), [28](#bib.bib28),
    [29](#bib.bib29)] as a metric for effective learning. Furthermore, recent works
    explore the intersection between cognitive science and LLMs [[30](#bib.bib30),
    [31](#bib.bib31), [32](#bib.bib32)], in which the creativity of LLMs are evaluated
    within the context of natural language, demonstrating near-human like performance
    in many cases [[31](#bib.bib31)]. In particular, [[33](#bib.bib33)] utilizes the
    four creative subcategories to evaluate LLMs across multiple language-based cognitive
    tasks. However, this framework has not been adapted to LLMs within the context
    of generating hardware code. To this end, we devise our creativity evaluation
    framework for LLM-based hardware code generation.
  prefs: []
  type: TYPE_NORMAL
- en: III CreativEval Framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Given a target LLM, our CreativEval framework, as shown in Fig. [1](#S2.F1
    "Figure 1 ‣ II-A LLMs for Code Generation and Hardware Design ‣ II Background
    and Related Work ‣ CreativEval: Evaluating Creativity of LLM-Based Hardware Code
    Generation"), seeks to evaluate the creativity associated with LLMs in hardware
    code generation. CreativEval evaluates the previously defined subcategories of
    creativity—fluency, flexibility, originality, and elaboration. To this end, we
    query the target LLM with different Verilog-based prompts, and analyze the responses
    through various methods of post-processing to calculate the desired metrics, as
    explained below.'
  prefs: []
  type: TYPE_NORMAL
- en: III-A Fluency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To capture the quantity of relevant and separate ideas in our context, we define
    fluency as the average number of unique Verilog solutions generated by the target
    LLM in response to a given prompt. Our prompts contain a brief English description
    of the module and the module’s declaration, as shown in Listing [1](#LST1 "Listing
    1 ‣ III-A Fluency ‣ III CreativEval Framework ‣ CreativEval: Evaluating Creativity
    of LLM-Based Hardware Code Generation"). Each prompt is provided as input to the
    LLM, with the response intended to be the completed implementation of the module.
    As the inference process of LLMs contain variations in the generated responses,
    we generate $t$ responses for each prompt to estimate the average performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Ly9DcmVhdGUgYSBmdWxsIGFkZGVyLiAKLy9BIGZ1bGwgYWRkZXIgYWRkcyB0aHJlZSBiaXRzIChpbmNsdWRpbmcgY2FycnktaW4pIGFuZCBwcm9kdWNlcyBhIHN1bSBhbmQgY2Fycnktb3V0LgoKbW9kdWxlIHRvcF9tb2R1bGUgKCAKICAgIGlucHV0IGEsIGIsIGNpbiwKICAgIG91dHB1dCBjb3V0LCBzdW0gcmlnaHRicmFja2V0Ow==)1//Create  a  full  adder.2//A  full  adder  adds  three  bits  (including  carry-in)  and  produces  a  sum  and  carry-out.34module  top_module  (5  input  a,  b,  cin,6  output  cout,  sum  );'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 1: Fluency/Originality prompt example'
  prefs: []
  type: TYPE_NORMAL
- en: Upon generating all responses, each response is then tested for functionality
    against the module’s associated testbench. If all test cases pass, the module
    is considered functional. Then, for each prompt, the functional responses (if
    any) are collected and compared to identify if they are unique implementations.
  prefs: []
  type: TYPE_NORMAL
- en: This is done through GNN4IP [[34](#bib.bib34)], a tool utilized to assess the
    similarities between circuits. By representing two Verilog modules as a data-flow
    graph (DFG), GNN4IP generates a similarity score within [-1,1], with larger values
    indicating a higher similarity. Each correct generated solution from the LLM is
    input into GNN4IP, and compared to its ideal solution, or “golden response”. Upon
    the generation of each similarity value for a given prompt, these results are
    then compared to determine how many unique values are in the response set, indicating
    the number of distinct solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that there are a set of $p$ prompts, there is a sub-total of the $t$,
    are defined as the set $R=\{{r_{1n},...,r_{mn}}\}$ responses. This process is
    repeated for all $n$ below:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $F=\frac{1}{n}\sum_{i=1}^{n}\left(\frac{&#124;S(R_{i})&#124;}{t}\right)$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: III-B Flexibility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Flexibility is quantified as the ability of the LLM to generate an alternative
    implementation of a Verilog module when provided with a solution. The prompts
    for this metric are constructed for a set of Verilog modules in which a correct
    solution (the golden response) is included (Listing [2](#LST2 "Listing 2 ‣ III-B
    Flexibility ‣ III CreativEval Framework ‣ CreativEval: Evaluating Creativity of
    LLM-Based Hardware Code Generation")). The LLM then rewrites the Verilog module,
    ideally resulting in a functional and unique implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Ly8gWW91IGFyZSBhIHByb2Zlc3Npb25hbCBoYXJkd2FyZSBkZXNpZ25lciB0aGF0IHdyaXRlcyBjb3JyZWN0LCBmdWxseSBmdW5jdGlvbmFsIFZlcmlsb2cgbW9kdWxlcy4KLy8gR2l2ZW4gdGhlIGZ1bGx5IGltcGxlbWVudGVkIGV4YW1wbGUgb2YgdGhlIFZlcmlsb2cgbW9kdWxlIGJlbG93OgoKbW9kdWxlIHRydWVfbW9kdWxlKCAKICAgIGlucHV0IGEsIGIsIGNpbiwKICAgIG91dHB1dCBjb3V0LCBzdW0gcmlnaHRicmFja2V0OwogICAgYXNzaWduIHN1bSA9ICBhIF4gYiBeIGNpbjsKICAgIGFzc2lnbiBjb3V0ID0gYSAmIGIgfCBhICYgY2luIHwgYiAmIGNpbjsKZW5kbW9kdWxlCgovLyBGaW5pc2ggd3JpdGluZyBhIGRpZmZlcmVudCBhbmQgdW5pcXVlIGltcGxlbWVudGF0aW9uIG9mIHRoZSBwcm92aWRlZCB0cnVlX21vZHVsZSBpbiB0aGUgbW9kdWxlIGJlbG93LCB0b3BfbW9kdWxlLgptb2R1bGUgdG9wX21vZHVsZSAoIAogICAgaW5wdXQgYSwgYiwgY2luLAogICAgb3V0cHV0IGNvdXQsIHN1bSByaWdodGJyYWNrZXQ7)1//  You  are  a  professional  hardware  designer  that  writes  correct,  fully  functional  Verilog  modules.2//  Given  the  fully  implemented  example  of  the  Verilog  module  below:34module  true_module(5  input  a,  b,  cin,6  output  cout,  sum  );7  assign  sum  =
    a  ^  b  ^  cin;8  assign  cout  = a  &  b  | a  &  cin  | b  &  cin;9endmodule1011//  Finish  writing  a  different  and  unique  implementation  of  the  provided  true_module  in  the  module  below,  top_module.12module  top_module  (13  input  a,  b,  cin,14  output  cout,  sum  );'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 2: Flexibility prompt example'
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, $t$ functional responses. These functional responses are compared
    directly with the golden response (through GNN4IP) to identify their similarity
    value. If the similarity value $s$ is then defined below:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $T(s)=\begin{cases}1&amp;\text{if }s<0\\ 0&amp;\text{if }s\geq 0\end{cases}$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $X=\frac{1}{n}\sum_{i=1}^{n}\left(T[\min S(R_{i})]\right)$ |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: III-C Originality
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The originality metric is defined as the variance (uniqueness) of an LLM-generated
    Verilog module in comparison to a typical, fully functional implementation. This
    metric is derived from the similarity value (generated through GNN4IP) between
    successful generations and their golden response.
  prefs: []
  type: TYPE_NORMAL
- en: 'The originality experiment follows the same prompt structure and procedure
    as described in [III-A](#S3.SS1 "III-A Fluency ‣ III CreativEval Framework ‣ CreativEval:
    Evaluating Creativity of LLM-Based Hardware Code Generation"). For each prompt,
    the response with the minimum similarity value is found. Then, the similarity
    values [-1, 1] are re-normalized to be on scale of [0, 1] with 1 indicating the
    least similarity (i.e. most original). These results are averaged over all $n$
    is described below:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $O=\frac{1}{n}\sum_{i=1}^{n}\frac{\left(-\min S(R_{i})+1\right)}{2}$ |  |
    (4) |'
  prefs: []
  type: TYPE_TB
- en: III-D Elaboration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To measure an LLM’s capacity for elaboration, the LLM is provided with multiple
    smaller Verilog modules in a prompt, and tasked with utilizing them to implement
    a larger, more complex module. As this metric requires multi-modular designs,
    a separate set of Verilog modules is utilized in constructing the prompts, as
    shown in Listing [3](#LST3 "Listing 3 ‣ III-D Elaboration ‣ III CreativEval Framework
    ‣ CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation").'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,Ly8gWW91IGFyZSBnaXZlbiBhIG1vZHVsZSBhZGQxNiB0aGF0IHBlcmZvcm1zIGEgMTYtYml0IGFkZGl0aW9uLiAKLy9JbnN0YW50aWF0ZSB0d28gb2YgdGhlbSB0byBjcmVhdGUgYSAzMi1iaXQgYWRkZXIuIAoKbW9kdWxlIGFkZDE2ICggaW5wdXRbMTU6MF0gYSwgaW5wdXRbMTU6MF0gYiwgaW5wdXQgY2luLCBvdXRwdXRbMTU6MF0gc3VtLCBvdXRwdXQgY291dCByaWdodGJyYWNrZXQ7Cgptb2R1bGUgdG9wX21vZHVsZSAoCiAgICBpbnB1dCBbMzE6MF0gYSwKICAgIGlucHV0IFszMTowXSBiLAogICAgb3V0cHV0IFszMTowXSBzdW0KcmlnaHRicmFja2V0Ow==)1//  You  are  given  a  module  add16  that  performs  a  16-bit  addition.2//Instantiate  two  of  them  to  create  a  32-bit  adder.34module  add16  (  input[15:0]  a,  input[15:0]  b,  input  cin,  output[15:0]  sum,  output  cout  );56module  top_module  (7  input  [31:0]  a,8  input  [31:0]  b,9  output  [31:0]  sum'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 3: Elaboration prompt example'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: Comparison of different LLMs in terms of creativity and its subcategories'
  prefs: []
  type: TYPE_NORMAL
- en: '| LLM | Functionality | Fluency | Flexibility | Originality | Elaboration |
    Creativity |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CodeLlama-7B [[35](#bib.bib35)] | 0.2417 | 0.1483 | 0.0000 | 0.2926 | 0.2222
    | 0.1658 |'
  prefs: []
  type: TYPE_TB
- en: '| CodeLlama-13B [[36](#bib.bib36)] | 0.3167 | 0.1611 | 0.0260 | 0.3021 | 0.3333
    | 0.2056 |'
  prefs: []
  type: TYPE_TB
- en: '| VeriGen-6B [[37](#bib.bib37)] | 0.3667 | 0.1244 | 0.1000 | 0.2527 | 0.3333
    | 0.2026 |'
  prefs: []
  type: TYPE_TB
- en: '| VeriGen-16B [[38](#bib.bib38)] | 0.3250 | 0.1189 | 0.0556 | 0.2771 | 0.3333
    | 0.1962 |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-3.5 [[39](#bib.bib39)] | 0.3083 | 0.1343 | 0.1600 | 0.2526 | 0.3333 |
    0.2201 |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-4 [[40](#bib.bib40)] | 0.3750 | 0.1644 | 0.0795 | 0.2657 | 0.3333 | 0.2107
    |'
  prefs: []
  type: TYPE_TB
- en: 'Multiple LLM responses are generated for each module, which are all then checked
    for functionality. For all given functional solutions, the responses are checked
    to see if the solution utilizes the smaller modules (as opposed to a single modular
    solution). If any of the responses for a given prompt are both functional and
    utilize the smaller modules, it is considered a positive instance of elaboration.
    Given $p$ have at least one response that demonstrates elaboration, the metric
    is specified as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $E=\left(\frac{n}{p}\right)$ |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: 'III-E Creativity: Putting It All Together'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given each of the subcategories associated with creativity defined above, the
    metrics are then combined to define the overall creativity of a given LLM in Verilog
    hardware design.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $C=(0.25)F+(0.25)X+(0.25)O+(0.25)E$ |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: IV Experimental Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IV-A Experimental Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We evaluate multiple LLMs using the CreativEval framework, including CodeLlama
    7B [[35](#bib.bib35)] and 13B [[36](#bib.bib36)] parameter models, VeriGen 6B
    [[37](#bib.bib37)] and 16B [[38](#bib.bib38)] (16B model loaded in 8-bit quantization
    due to memory constraints), GPT-3.5 [[39](#bib.bib39)], and GPT-4 [[40](#bib.bib40)].
    The inference process of the VeriGen and CodeLlama models was performed locally
    on an NVIDIA A100 GPU with 80 GB RAM, while GPT-3.5/4 were queried through the
    OpenAI Python API. All scripts are written in Python 3.10, with Icarus Verilog
    10.3 as the simulator for evaluating functionality checks. The open-source GNN4IP
    repository was adapted to this framework to generate the similarity scores. The
    prompt dataset utilized for functionality, fluency, and originality consists of
    111 single-module HDLBits [[41](#bib.bib41)] prompts sourced through AutoChip [[42](#bib.bib42)],
    each containing a correctly implemented solution and testbench. The smaller prompt
    set used for elaboration contains 9 separate multi-module prompts from the same
    source. The base functionality metric (pass@10) is measured on all 120 prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 'When generating LLM responses in all experiments, the LLMs were all set to
    the following inference hyperparameters: temperature=0.3; max_tokens=1024; top_k=10;
    top_p=0.95\. All responses were trimmed to the first generated instance of “endmodule”
    for effective functionality evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [I](#S3.T1 "TABLE I ‣ III-D Elaboration ‣ III CreativEval Framework ‣
    CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation") summarizes
    the results for all LLMs for all subcategories of creativity. In evaluating fluency,
    GPT-4 had the highest quantity of separate and correct Verilog solutions to a
    module (with respect to the modules that have at least one correct solution),
    with CodeLlama-13B achieving similar results. The VeriGen models comparatively
    struggled in this metric, partly due to repeated generations of similar implementations
    instead of different implementations.'
  prefs: []
  type: TYPE_NORMAL
- en: Regarding flexibility, GPT-3.5 had the highest rate of generating alternative
    solutions to provided modules across most models. The models that struggled (e.g.,
    CodeLlama) produced results that were often direct copies of the provided module,
    indicating the ability to understand the prompt’s natural language description
    as an important factor that determined flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: As for originality, the GPT models had slightly worse performance than the others,
    with CodeLlama performing best. This means that the successful solutions provided
    with the GPT models were, on average, closer to the ideal solution. This could
    be due to its large size and training dataset, resulting in a more direct retrieval
    of existing solutions or coding practices.
  prefs: []
  type: TYPE_NORMAL
- en: Elaboration was largely similar for all modules, as the HDLBits dataset for
    this metric is comparatively small (9 modules). The models primarily excelled
    in correctly connecting the input and output parameters between separate modules,
    while struggling to generate the larger module solution.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the GPT models were the most creative, with GPT-3.5 as the best, and
    CodeLlama-7B was the least creative. Creativity is shown to slightly drop for
    the larger model sizes of GPT and VeriGen.
  prefs: []
  type: TYPE_NORMAL
- en: V Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recent studies on LLMs regarding their applications to hardware design have
    effectively demonstrated their potential, applying many optimization strategies
    to increase the performance in terms of functional correctness. However, these
    studies do not investigate the creativity associated with LLMs in their ability
    to generate solutions, largely due to the lack of an effective metric. Within
    this work, we propose CreativEval, a framework to evaluate the creativity of LLMs
    in generating hardware code. By evaluating multiple popular LLMs within this framework,
    we perform a comparative analysis, concluding that GPT-3.5 had the greatest creativity.
    Future research in this direction can further evaluate more LLMs and on larger
    prompt sets.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The authors acknowledge the support from the Purdue Center for Secure Microelectronics
    Ecosystem – CSME#210205\. This work was also partially supported by the National
    Science Foundation (NSF CNS–1822848 and NSF DGE–2039610).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Tim Keary, “12 Practical Large Language Model (LLM) Applications,” [https://www.techopedia.com/12-practical-large-language-model-llm-applications](https://www.techopedia.com/12-practical-large-language-model-llm-applications),
    2023, [Online; last accessed 21-Nov-2023].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. Kaiser, and I. Polosukhin, “Attention is all you need,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Z. G. Cai, X. Duan, D. A. Haslett, S. Wang, and M. J. Pickering, “Do large
    language models resemble humans in language use?” 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] T. Kocmi and C. Federmann, “Large language models are state-of-the-art
    evaluators of translation quality,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] K. Pandya and M. Holia, “Automating customer service using langchain: Building
    custom open-source gpt chatbot for organizations,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] R. Zhong, X. Du, S. Kai, Z. Tang, S. Xu, H.-L. Zhen, J. Hao, Q. Xu, M. Yuan,
    and J. Yan, “Llm4eda: Emerging progress in large language models for electronic
    design automation,” *arXiv preprint arXiv:2401.12224*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] S. Thakur, B. Ahmad, H. Pearce, B. Tan, B. Dolan-Gavitt, R. Karri, and
    S. Garg, “Verigen: A large language model for verilog code generation,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] J. Blocklove, S. Garg, R. Karri, and H. Pearce, “Chip-chat: Challenges
    and opportunities in conversational hardware design,” in *2023 ACM/IEEE 5th Workshop
    on Machine Learning for CAD (MLCAD)*.   IEEE, Sep. 2023\. [Online]. Available:
    [http://dx.doi.org/10.1109/MLCAD58807.2023.10299874](http://dx.doi.org/10.1109/MLCAD58807.2023.10299874)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] M. Liu, T.-D. Ene, R. Kirby, C. Cheng, N. Pinckney, R. Liang *et al.*,
    “Chipnemo: Domain-adapted llms for chip design,” 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] M. DeLorenzo, A. B. Chowdhury, V. Gohil, S. Thakur, R. Karri, S. Garg,
    and J. Rajendran, “Make every move count: Llm-based high-quality rtl code generation
    using mcts,” 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] M. Runco and G. Jaeger, “The standard definition of creativity,” *Creativity
    Research Journal - CREATIVITY RES J*, vol. 24, pp. 92–96, 01 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] OpenAI, J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman
    *et al.*, “Gpt-4 technical report,” 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training
    of Deep Bidirectional Transformers for Language Understanding,” in *Proceedings
    of the 2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*.   Minneapolis,
    Minnesota: Association for Computational Linguistics, Jun. 2019, pp. 4171–4186\.
    [Online]. Available: [https://aclanthology.org/N19-1423](https://aclanthology.org/N19-1423)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] [Online]. Available: [https://www.anthropic.com/news/claude-3-haiku](https://www.anthropic.com/news/claude-3-haiku)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Z. Luo, C. Xu, P. Zhao, Q. Sun, X. Geng, W. Hu, C. Tao, J. Ma, Q. Lin,
    and D. Jiang, “Wizardcoder: Empowering code large language models with evol-instruct,”
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto, J. Kaplan
    *et al.*, “Evaluating large language models trained on code,” 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Y. Wang, H. Le, A. D. Gotmare, N. D. Q. Bui, J. Li, and S. C. H. Hoi,
    “Codet5+: Open code large language models for code understanding and generation,”
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] H. Pearce, B. Tan, and R. Karri, “Dave: Deriving automatically verilog
    from english,” in *Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning
    for CAD*, ser. MLCAD ’20.   New York, NY, USA: Association for Computing Machinery,
    2020, p. 27–32\. [Online]. Available: [https://doi.org/10.1145/3380446.3430634](https://doi.org/10.1145/3380446.3430634)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] M. Liu, N. Pinckney, B. Khailany, and H. Ren, “Verilogeval: Evaluating
    large language models for verilog code generation,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] S. Liu, W. Fang, Y. Lu, Q. Zhang, H. Zhang, and Z. Xie, “Rtlcoder: Outperforming
    gpt-3.5 in design rtl generation with our open-source dataset and lightweight
    solution,” 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Y. Lu, S. Liu, Q. Zhang, and Z. Xie, “Rtllm: An open-source benchmark
    for design rtl generation with large language model,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] L. S. Almeida, L. P. Prieto, M. Ferrando, E. Oliveira, and C. Ferrándiz,
    “Torrance test of creative thinking: The question of its construct validity,”
    *Thinking Skills and Creativity*, vol. 3, no. 1, pp. 53–58, 2008\. [Online]. Available:
    [https://www.sciencedirect.com/science/article/pii/S1871187108000072](https://www.sciencedirect.com/science/article/pii/S1871187108000072)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] S. L. Doerr, “Conjugate lateral eye movement, cerebral dominance, and
    the figural creativity factors of fluency, flexibility, originality, and elaboration,”
    *Studies in Art Education*, vol. 21, no. 3, pp. 5–11, 1980\. [Online]. Available:
    [http://www.jstor.org/stable/1319788](http://www.jstor.org/stable/1319788)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] J. P. Guilford, *The nature of human intelligence*.   McGraw-Hill, 1971.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] E. P. Torrance, “Torrance tests of creative thinking,” *Educational and
    psychological measurement*, 1966.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] M. Arefi, “Comparation of creativity dimensions (fluency, flexibility,
    elaboration, originality) between bilingual elementary students (azari language-kurdish
    language) in urmia city iran - the iafor research archive,” Dec 2018\. [Online].
    Available: [https://papers.iafor.org/submission22045/](https://papers.iafor.org/submission22045/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] S. A. Handayani, Y. S. Rahayu, and R. Agustini, “Students’ creative thinking
    skills in biology learning: fluency, flexibility, originality, and elaboration,”
    *Journal of Physics: Conference Series*, vol. 1747, no. 1, p. 012040, feb 2021\.
    [Online]. Available: [https://dx.doi.org/10.1088/1742-6596/1747/1/012040](https://dx.doi.org/10.1088/1742-6596/1747/1/012040)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] F. Alacapinar, “Grade level and creativity,” *Eurasian Journal of Educational
    Research (EJER)*, vol. 13, pp. 247–266, 01 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] M. Arefi and N. Jalali, “Comparation of creativity dimensions (fluency,
    flexibility, elaboration, originality) between bilingual elementary students (azari
    language-kurdish language) in urmia city–iran,” in *The IAFOR International Conference
    on Language Learning*, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] R. Shiffrin and M. Mitchell, Mar 2023\. [Online]. Available: [https://www.pnas.org/doi/abs/10.1073/pnas.2300963120](https://www.pnas.org/doi/abs/10.1073/pnas.2300963120)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] C. Stevenson, I. Smal, M. Baas, R. Grasman, and H. van der Maas, “Putting
    gpt-3’s creativity to the (alternative uses) test,” 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] M. Binz and E. Schulz, “Using cognitive psychology to understand gpt-3,”
    *Proceedings of the National Academy of Sciences*, vol. 120, no. 6, Feb. 2023\.
    [Online]. Available: [http://dx.doi.org/10.1073/pnas.2218523120](http://dx.doi.org/10.1073/pnas.2218523120)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Y. Zhao, R. Zhang, W. Li, D. Huang, J. Guo, S. Peng, Y. Hao, Y. Wen, X. Hu,
    Z. Du, Q. Guo, L. Li, and Y. Chen, “Assessing and understanding creativity in
    large language models,” 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] R. Yasaei, S.-Y. Yu, E. K. Naeini, and M. A. A. Faruque, “Gnn4ip: Graph
    neural network for hardware intellectual property piracy detection,” 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] “Hugging face.” [Online]. Available: [https://huggingface.co/codellama/CodeLlama-7b-hf](https://huggingface.co/codellama/CodeLlama-7b-hf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] “Hugging face.” [Online]. Available: [https://huggingface.co/codellama/CodeLlama-13b-hf](https://huggingface.co/codellama/CodeLlama-13b-hf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] “Hugging face.” [Online]. Available: [https://huggingface.co/shailja/fine-tuned-codegen-6B-Verilog](https://huggingface.co/shailja/fine-tuned-codegen-6B-Verilog)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] “Hugging face.” [Online]. Available: [https://huggingface.co/shailja/fine-tuned-codegen-16B-Verilog](https://huggingface.co/shailja/fine-tuned-codegen-16B-Verilog)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] “fine-tuning and api updates.” [Online]. Available: [https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] “fine-tuning and api updates.” [Online]. Available: [https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] [Online]. Available: [https://hdlbits.01xz.net/wiki/Main_Page](https://hdlbits.01xz.net/wiki/Main_Page)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] S. Thakur, J. Blocklove, H. Pearce, B. Tan, S. Garg, and R. Karri, “Autochip:
    Automating hdl generation using llm feedback,” 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
