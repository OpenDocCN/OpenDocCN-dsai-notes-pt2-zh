- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:51:38'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.12347](https://ar5iv.labs.arxiv.org/html/2405.12347)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Mohammad Akyash Dept. of Electrical and Comp. Eng. (ECE)
  prefs: []
  type: TYPE_NORMAL
- en: University of Central Florida Orlando, US 32816
  prefs: []
  type: TYPE_NORMAL
- en: mohammad.akyash@ucf.edu    Hadi Mardani Kamali Dept. of Electrical and Comp.
    Eng. (ECE)
  prefs: []
  type: TYPE_NORMAL
- en: University of Central Florida Orlando, US 32816
  prefs: []
  type: TYPE_NORMAL
- en: hadi.mardanikamali@ucf.edu
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The rise of instruction-tuned Large Language Models (LLMs) marks a significant
    advancement in artificial intelligence (AI) (tailored to respond to specific prompts).
    Despite their popularity, applying such models to debug security vulnerabilities
    in hardware designs, i.e., register transfer language (RTL) modules, particularly
    at system-on-chip (SoC) level, presents considerable challenges. One of the main
    issues lies in the need for precisely designed instructions for pinpointing and
    mitigating the vulnerabilities, which requires substantial time and expertise
    from human experts. In response to this challenge, this paper proposes Self-HWDebug,
    an innovative framework that leverages LLMs to automatically create required debugging
    instructions. In Self-HWDebug, a set of already identified bugs from the most
    critical hardware common weakness enumeration (CWE) listings, along with mitigation
    resolutions, is provided to the framework, followed by prompting the LLMs to generate
    targeted instructions for such mitigation. The LLM-generated instructions are
    subsequently used as references to address vulnerabilities within the same CWE
    category but in totally different designs, effectively demonstrating the framework’s
    ability to extend solutions across related security issues. Self-HWDebug significantly
    reduces human intervention by using the model’s own output to guide debugging.
    Through comprehensive testing, Self-HWDebug proves not only to reduce experts’
    effort/time but also to even improve the quality of the debugging process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: LLM, Hardware Security, Validation, CWE.
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given the widespread use of SoCs within today’s digital systems, coupled with
    the escalating size and complexity of their associated hardware, the emergence
    of unknown vulnerabilities (especially security vulnerabilities) stemming from
    their hardware has become an inevitable and challenging aspect of the integrated
    circuit (IC) supply chain process [[1](#bib.bib1)]. To minimize re-spins due to
    post-silicon verification issues, addressing these vulnerabilities must be done
    at the highest level of abstraction, i.e., RTL [[2](#bib.bib2), [3](#bib.bib3)].
    This process is time-consuming and demands extensive hardware engineering expertise.
    Numerous methodologies have been investigated over the years for such challenges,
    from formal methods [[4](#bib.bib4)] to advanced testing techniques, e.g., fuzzing
    [[5](#bib.bib5), [6](#bib.bib6)].
  prefs: []
  type: TYPE_NORMAL
- en: More recently, significant advancements in seedling AI use, particularly through
    LLMs, have greatly enhanced the resolution of verification issues, particularly
    w.r.t. the automating the verification process, reducing required experts’ knowledge
    and time [[7](#bib.bib7)]. Prompt engineering, which is the process of crafting
    inputs that guide LLMs’ responses, has been widely used for hardware security
    verification purposes [[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)]. For
    example, [[8](#bib.bib8)] has explored employing expert-crafted prompts to steer
    model behavior in specific debugging scenarios. However, this method suffers from
    scalability and prompts’ efficacy issues [[7](#bib.bib7)]. As hardware designs
    grow in complexity and the number of IP cores increases, the task of manually
    creating prompts that address every potential security vulnerability becomes impractical.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main shortcomings of manual prompt engineering for hardware security
    verification resides in the reliance upon prompts created by experts possessing
    deep expertise in a specific design or scenario. This approach often fails to
    consistently yield effective instructions tailored to address vulnerabilities.
    As a result, an instruction deemed effective for mitigating a given vulnerability
    within one design may fail when applied to the same vulnerability in a different
    design. This inherent limitation adversely affects engineered prompts’ scalability
    across diverse design contexts [[11](#bib.bib11)]. While effective for specific
    scenarios, one main reason of LLM solutions for hardware security shifting from
    prompt engineering to fine-tuning (hardware-oriented training) is to better understand
    and respond the nuances of hardware security queries [[12](#bib.bib12), [13](#bib.bib13)].
    However, as fine-tuning typically requires substantial amounts of relevant data
    to train the model effectively, fine-tuning on hardware, especially due to limited
    datasets, may present challenges for achieving optimal effectiveness [[7](#bib.bib7)].
  prefs: []
  type: TYPE_NORMAL
- en: 'To Address these challenges, this paper introduces Self-HWDebug, a framework
    that leverages the self-instructional capabilities of LLMs to produce debugging
    instructions autonomously. In Self-HWDebug, we utilize LLMs to automatically generate
    debugging instructions by prompting the LLM with pairs of already-crafted vulnerable
    and secure RTL snippet. These generated instructions are then applied to debug
    unseen RTL snippets, testing their effectiveness in resolving errors in new and
    varied hardware configurations but in a same vulnerability categoty. To mention
    the core benefits of our approach, we outline the following contributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '(1) Automatic Self-Instructing by LLM: Self-HWDebug exploits the inherent knowledge
    embedded within the models, and the automated generation of prompts for better
    effectiveness, providing instructions with higher specificity/relevance to the
    tasks compared to expert-crafted instructions.'
  prefs: []
  type: TYPE_NORMAL
- en: '(2) Exploration of References for Self-Instructing: We examine varying quantities
    of references used for self-improvement in LLM self-instructing, revealing that
    the observation of more number of vulnerabilities correlates with an increased
    success rate in self-instruction for security verification.'
  prefs: []
  type: TYPE_NORMAL
- en: '(3) Scalability and Adaptation: We evaluate the effectiveness of Self-HWDebug
    showing the enhanced scalability of the process and allows for rapid adaptation
    to new vulnerabilities, while circumventing the labor-intensive process of verification.'
  prefs: []
  type: TYPE_NORMAL
- en: II Background and Related Works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with most other research directions, particularly software design and testing,
    the integration of LLMs is poised to streamline hardware design processes, particularly
    for electronic design automation (EDA). LLMs, when deployed at higher levels of
    abstraction, e.g., RTL, offer multifaceted advantages from design to verification:
    (1) alleviating the burden of manual intervention in implementation tasks [[14](#bib.bib14),
    [15](#bib.bib15)], (2) acting as a substitute for conventional hardware generators,
    e.g., high-level synthesis (HLS) [[16](#bib.bib16)], (3) addressing the persistent
    issue of inadequate HDL codebase availability [[14](#bib.bib14)], (4) facilitating
    the acceleration of time-to-market (TTM) in the competitive landscape of IC design
    [[17](#bib.bib17)], and (5) minimizing the occurrence of human-induced errors
    [[7](#bib.bib7)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in Fig. [1](#S2.F1 "Figure 1 ‣ II Background and Related Works ‣ Self-HWDebug:
    Automation of LLM Self-Instructing for Hardware Security Verification"), Within
    the domain of hardware, current mechanisms centered around LLMs can be divided
    into three main groups: (1) Development of automated AI agents tailored to streamline
    EDA workflows in the IC supply chain, (2) the derivation of software code generation
    to facilitate RTL implementation, and (3) the use of its semantic parsing for
    testing and verification. While the first group assists with a range of tasks,
    e.g., script generation, architecture specification, and interpretation of compilation
    reports, the second and third group acts as a design and testing assistant to
    expedite the design and verification process. As shown, a sub-category of the
    second and third group is centered around the use of LLMs for creating secure
    RTLs or debugging RTLs with existing vulnerabilities (security-oriented verification).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/36f68411dc28017aabc1427467494657.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The Use of LLMs for SW/HW Coding (Design) and Test (Verification).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8de2a4a6a08678da25d648276e7f83eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The Overview of Self-Instructing for HW Security Debugging (Based
    on One-Shot Learning - One Reference for Self-Instructing).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6b527c0beb845a7f53bde8fa1190587e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Top View of Task Descriptions at Three Levels (I[1]-basic, I[2]-intermediate,
    I[3]-advanced) for Instructions’ Generation in Self-HWDebug (Sample CWE 1191 for
    One-shot Learning).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3672ea1b6b6c23129ef7c0b965ab77bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Top View of Generated Instructions (I[1]-basic, I[2]-intermediate,
    I[3]-advanced) by Llama3 for Sample CWE 1191 based on One-shot Learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In security-oriented solutions, existing studies aim to propel designs towards
    a state devoid of vulnerabilities, functional or security-related. Analogous to
    the LLM-based RTL design paradigm, these methodologies fall into two primary streams:
    (1) prompt engineering, where the refinement of design prompts steers towards
    generating secure code by LLM [[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)],
    and (2) RTL-driven tuning, which involves modifying the framework of LLMs themselves
    based on RTL codebase to yield vulnerability-free outputs [[12](#bib.bib12), [13](#bib.bib13)].'
  prefs: []
  type: TYPE_NORMAL
- en: Although LLMs in hardware security exhibit promising potential, they encounter
    formidable obstacles in hardware design, testing, and verification. These challenges
    arise from factors such as prompt engineering and fine-tuning, highlighting the
    paramount importance of acquiring and effectively utilizing high-quality codebases
    [[18](#bib.bib18)]. Moreover, the creation of specialized LLMs, e.g., large circuit
    models (LCMs), or the adaptation of existing models necessitate deep expertise
    to achieve optimal outcomes in RTL-oriented tasks encompassing generation, detection,
    and mitigation [[19](#bib.bib19), [20](#bib.bib20)]. In light of these challenges,
    the endeavor demands rigorous and concerted efforts across diverse domains.
  prefs: []
  type: TYPE_NORMAL
- en: 'III Proposed Scheme: Self-HWDebug'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Self-HWDebug, as shown in Fig. [2](#S2.F2 "Figure 2 ‣ II Background and
    Related Works ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware
    Security Verification"), generating and testing instructions operates through
    a two-stage process: First, for a specific vulnerability, e.g., *CWE*[x], we generate
    instructions based on a predefined pair of vulnerable (*V*[x1]) and secure code
    (*S*[x1]) snippets, known as the reference sample. Using this pair, LLM will be
    invoked to generate an instruction (*I*[x1,i]), acting as security rule checks,
    that can be used for debugging the vulnerable snippet. Next, we provide these
    instructions (*I*[x1,i]) along with a different vulnerable code snippet (*V*<math
    id="S3.p1.6.m6.1" class="ltx_Math" alttext="{}_{xi~{}|~{}i></math>). Using this
    approach, the design and verification team can enhance the self-improvement of
    the LLM and bypass the challenging and time-consuming task of manually crafting
    instructions by human experts. We utilize one pair (one-shot shown in Fig. [2](#S2.F2
    "Figure 2 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification")) and multiple pairs (case
    study of two-shot shown in Fig. [5](#S4.F5 "Figure 5 ‣ IV-A Bugs Descriptions
    ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification")) from each vulnerability as reference to
    produce instructions, while a set of different circuits induced with the same
    vulnerabilities are used to test the effectiveness of the generated instructions
    for debugging RTL codes.'
  prefs: []
  type: TYPE_NORMAL
- en: III-A Instruction Generation at Multiple Levels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our objective is to develop a set of debugging instructions *I*[x1,i] for each
    CWE category, customized to varying levels of detail. These instructions are designed
    to effectively enable the language model to suggest repairs when paired with instances
    of vulnerabilities. To do so, for each CWE category (*CWE*[x] in Fig. [2](#S2.F2
    "Figure 2 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification")), we prepare a task description
    (*T*[x,i]) along with both vulnerable (*V*[x1]) and secure (*S*[x1]) code snippets.
    Consider $M$ represents the level of detail required from the language model as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '(1) Basic: It mostly focuses on a high-level description of the CWE and how
    it can be basically mitigated.'
  prefs: []
  type: TYPE_NORMAL
- en: '(2) Intermediate: It covers a high-level of the CWE and how it can be basically
    mitigated (basic). It also offers a more detailed step-by-step debugging instructions,
    which resembles a detailed security rule checklist for the targeted vulnerability.'
  prefs: []
  type: TYPE_NORMAL
- en: '(3) Advanced: It covers a high-level of the CWE and how it can be basically
    mitigated (basic), alongside with a more detailed step-by-step debugging instructions
    (intermediate), while it also provides a second example pair of vulnerable and
    secure code snippet using a different design.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a more clear picture of how these levels are generated, and how LLMs
    are initially invoked for instruction generation at different levels, Fig. [3](#S2.F3
    "Figure 3 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification") demonstrates a sample showcase
    on how these levels are defined for task description specialized for CWE-1191\.
    Despite many recent hardware verification techniques centered on LLMs, which demand
    deep expert knowledge for generation and testing, Self-HWDebug only requires these
    high-level and generic descriptions, where designers, without needing in-depth
    security examination and expertise, can generate these descriptions with minimal
    effort, drawing almost automatically from sources such as CWE databases, design/architecture
    specification sheets, etc.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B Mitigating Vulnerabilities with Generated Instructions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Given the descriptions mentioned above followed by calling the LLM, the required
    instructions will be generated per vulnerability at the desired levels. Fig. [4](#S2.F4
    "Figure 4 ‣ II Background and Related Works ‣ Self-HWDebug: Automation of LLM
    Self-Instructing for Hardware Security Verification") depicts the generated instructions
    for different levels of detail²²2Due to spacing, less critical instruction snippets
    have been omitted.. As shown in Fig. [4](#S2.F4 "Figure 4 ‣ II Background and
    Related Works ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware
    Security Verification"), the more advanced instructions provide increased detail
    regarding the bug and mitigation strategies. These more advanced instructions
    contribute to a higher success rate in achieving secure design. To see the efficiency
    of Self-HWDebug, following the generation of these instructions, they are utilized
    to test unseen vulnerable code snippets within the same vulnerability category,
    aiming to mitigate the vulnerability across various designs. Assume we possess
    code ($V_{xi}$ is a general task description that we ask LLM to mitigate the vulnerability
    according to the given instruction.'
  prefs: []
  type: TYPE_NORMAL
- en: III-C Using multiple references for higher accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When employing a single reference (one-shot) to generate instructions (e.g.,
    *V*[x1] and *S*[x1] for *CWE*[x]), our experimental results show acceptable success
    rate. However, depending on the type of the vulnerability, difficulties to mitigate,
    vulnerability and task/instruction representation, etc., different vulnerabilities
    within the same CWE category can require distinct mitigation techniques, and one
    technique (one reference) may not sufficiently address the same vulnerability
    in a different design. Recognizing this limitation in the one-shot method (Fig.
    [2](#S2.F2 "Figure 2 ‣ II Background and Related Works ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification")), where the instruction
    might not include multiple techniques, we explore the possibility of using multiple
    references (showcasing two-shot), targeting a higher success rate (better coverage
    of the same vulnerability while the LLM targets the same CWE across a wider array
    of unseen designs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable the use of multiple references (e.g., two-shot), as shown in Fig.
    [5](#S4.F5 "Figure 5 ‣ IV-A Bugs Descriptions ‣ IV Experiments and Results ‣ Self-HWDebug:
    Automation of LLM Self-Instructing for Hardware Security Verification"), we prompt
    the LLM to generate instructions using two distinct pairs of references that address
    the same vulnerability through varied techniques/designs (*CWE*[x] in both {*V*[x1],
    *S*[x1]} and {*V*[x2], *S*[x2]}). To obtain the two-shot instruction (*I*[xt]
    as the combination of *I*[x1] and *I*[x2]), we prompt the LLM with a task description
    (see Fig. [6](#S4.F6 "Figure 6 ‣ IV-A Bugs Descriptions ‣ IV Experiments and Results
    ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification"))
    formulated as $I_{xt}=M(T_{xt}\oplus V_{x1}\oplus S_{x1}\oplus V_{x2}\oplus S_{x2})$,
    where (*V*[x1], *S*[x1]) and (*V*[x2], *S*[x2]) are our reference samples (two
    pairs of vulnerable and secure snippet codes). By contrasting the task descriptions
    from the one-shot (Fig. [3](#S2.F3 "Figure 3 ‣ II Background and Related Works
    ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification"))
    and two-shot approaches (Fig. [6](#S4.F6 "Figure 6 ‣ IV-A Bugs Descriptions ‣
    IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification")), the two-shot method prompts the LLM to
    generate a combined instruction that considers both references (to build a more
    comprehensive set of instructions, i.e., *I*[xt,i=1,2,3]. In our experimental
    results, by analyzing The instructions generated using in two-shot approach, we
    demonstrate that using multiple reference (here is 2), the mitigation operates
    more comprehensive and contain more detail and strategies compared to their one-shot
    counterpart. It is noteworthy that an increasing number of references could potentially
    enhance comprehensiveness. However, in future studies, we demonstrate that there
    is a threshold for the number of references beyond which the model may be misled.'
  prefs: []
  type: TYPE_NORMAL
- en: IV Experiments and Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To assess the effectiveness of Self-HWDebug, we conduct experiments that involve
    generating and testing instructions in both one-shot and two-shot formats over
    a set of CWEs. Furthermore, we explore various levels of instruction complexity
    to gauge the impact of more advanced directives. Additionally, we experiment with
    integrating guidance from an expert LLM to determine whether their advanced knowledge
    can improve the mitigation efforts of an open-source model.
  prefs: []
  type: TYPE_NORMAL
- en: IV-A Bugs Descriptions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/03c125c8370e4cbfce040e985a423aa7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The Overview of Self-Instructing for HW Security Debugging (Based
    on Two-Shot Learning - Two References for Self-Instructing).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f00059aa42267876fa719d7ffdbff181.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Generating Instruction for Two-shot Learning (Sample CWE 1191).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our experimental setup, we focused on a subset (five) of most important
    hardware CWEs [[21](#bib.bib21)]. For each category, a database of seven distinct
    samples (snippet code with vulnerabilities) based on the respective CWE descriptions
    (from different sources, e.g., MITRE [[21](#bib.bib21)], hackathons [[22](#bib.bib22)],
    Trust-hub [[23](#bib.bib23)], etc.). We designated one/two of these samples as
    the reference (shot) for generating instructions, while we used five (different
    designs) to test the efficacy of the generated instructions in addressing and
    rectifying the issues. Table [I](#S4.T1 "TABLE I ‣ IV-C Instruction Generation
    in One- and Two-Shot Approaches ‣ IV Experiments and Results ‣ Self-HWDebug: Automation
    of LLM Self-Instructing for Hardware Security Verification") demonstrates the
    utilized CWE categories and their description. For two-shot approach, we used
    and extra pair of vulnerable and secure code as the reference.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Experimental Settings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In all our experiments we utilized recently-introduced Llama3-70B [[24](#bib.bib24)].
    This is an open-source high-capacity language model from Meta, designed for text
    and code generation. For implementing LLM, we employ the Groq API [[25](#bib.bib25)].
    This API uses Groq’s cutting-edge LPU technology, which provides extremely fast
    AI inference capabilities, and make it highly suitable for tasks that require
    real-time performance. As of May 2024, Groq provides a free plan, though it comes
    with some limitations. To ensure consistency in our analysis of the experiments,
    we set the temperature and top-p parameters to constant values of 0.6 and 1, respectively.
    This approach allows us to examine the effects of other variables without the
    influence of the probabilistic nature of LLM outputs.
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Instruction Generation in One- and Two-Shot Approaches
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the one-shot approach, we prompt the LLM with a single reference to generate
    general debugging instructions at varying levels of detail³³3To enhance the accuracy
    of these instructions, a hardware designer can add general annotation to the reference
    code with comments.. Our observations indicate that the LLM-produced instructions
    are comprehensive, capturing both the essence of the vulnerability and the necessary
    debugging steps for mitigating the vulnerability. These instructions are then
    validated: the LLM is prompted with an unseen snippet to provide a repair solution,
    and we use an assertion-based validation on the the repaired code to verify its
    validity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: Description of the utilized CWE categories.'
  prefs: []
  type: TYPE_NORMAL
- en: '| CWE category | Bug description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1191 | Pertains to vulnerabilities in on-chip debug and test interfaces
    that lack proper access controls, potentially allowing unauthorized access or
    manipulation of the chip’s functions. |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1231 | Refers to vulnerabilities arising from the improper prevention
    of modifications to lock bits, which can lead to unauthorized changes in the device’s
    functionality or security settings. |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1244 | Involves vulnerabilities where internal assets are exposed due
    to being set at an unsafe debug access level or state, potentially compromising
    the security and integrity of the system. |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1245 | Refers to vulnerabilities due to improperly designed Finite State
    Machines (FSMs) in hardware logic, which can lead to unpredictable behavior or
    security risks in the hardware’s operation. |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1300 | Relates to vulnerabilities from inadequate safeguards against
    physical side channels, which can inadvertently reveal critical information through
    the hardware’s electromagnetic signals, acoustic outputs, or power consumption
    patterns. |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/cfc58bd7aaaab1ae1922209baa73bce5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: One example of a vulnerable code snippet (CWE 1231) alongside its
    repairs, each generated with different levels of instruction detail.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-D Instruction Generation by More Advanced Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apart from the instruction and testing generation all done by LLama3, we also
    incorporated knowledge from more advanced and capable models, e.g., GPT-4, to
    determine if it can further improve mitigation success rate. For this part of
    the experiment, we utilized GPT-4 to generate detailed instructions based on a
    reference pair and then apply these instructions to Llama3 for generating the
    repairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our findings, as shown in Table [II](#S4.T2 "TABLE II ‣ IV-F Takeaways for
    Self Instructing in Hardware Verification ‣ IV Experiments and Results ‣ Self-HWDebug:
    Automation of LLM Self-Instructing for Hardware Security Verification"), demonstrate
    that GPT-4’s comprehensive instructions greatly aid Llama3 in performing more
    effective code repairs. This approach allows us to leverage the advanced capabilities
    of a limited-access, closed-source model (i.e., GPT-4) to augment an open-source
    model (i.e., Llama3) and achieve comparable performance at a lower cost. The integration
    of GPT-4 involves a process similar to knowledge distillation, where GPT-4, serving
    as a sophisticated *’teacher’*, transfers complex debugging strategies and subtle
    details to Llama3, the *’student’*. This method infuses Llama3 with enhanced capabilities
    to handle complex debugging tasks that were previously out of reach and demonstrate
    a practical application of knowledge distillation in bridging the gap between
    proprietary and open-source LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-E Comparison of Different Levels of Instruction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [II](#S4.T2 "TABLE II ‣ IV-F Takeaways for Self Instructing in Hardware
    Verification ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification") depicts the mitigation results for the targeted
    CWE categories and different instructions’ levels. As demonstrated, the model
    exhibits improvement from basic to advanced task descriptions in one-shot self-instructing.
    However, this improvement is not always consistent, as the quality of the model’s
    responses can vary due to inherent randomness and certain limitations. Nonetheless,
    by transitioning to a more advanced model, such as GPT-4, and employing a two-shot
    model approach (moving towards optimum -multiple- number of references), even
    at an intermediate level of task description, the success rate remains consistently
    high.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To draw a top picture of how this self-instructing performs for a specific
    scenario, Fig. [7](#S4.F7 "Figure 7 ‣ IV-C Instruction Generation in One- and
    Two-Shot Approaches ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of
    LLM Self-Instructing for Hardware Security Verification") shows a snippet code
    of CWE 1231 and its mitigation approaches with different level of details (based
    on the instructions generated from Figs. [3](#S2.F3 "Figure 3 ‣ II Background
    and Related Works ‣ Self-HWDebug: Automation of LLM Self-Instructing for Hardware
    Security Verification") and Fig. [6](#S4.F6 "Figure 6 ‣ IV-A Bugs Descriptions
    ‣ IV Experiments and Results ‣ Self-HWDebug: Automation of LLM Self-Instructing
    for Hardware Security Verification")). In the vulnerable snippet code the logic
    mistakenly sets the config_lock to 1’b0 (unlocked) when the state is not in maintenance_mode,
    which is counter-intuitive as it should remain locked to protect the system configuration.
    This leaves the system vulnerable to unauthorized changes almost at normal (functional)
    mode (vs. during the test mode).'
  prefs: []
  type: TYPE_NORMAL
- en: In the advanced level mitigation, LLM simplifies the control logic by removing
    the maintenance mode check, resulting in a configuration that is always unlocked
    except during the reset. This approach is less secure than even the flawed original,
    as it does not attempt to verify the context or condition under which unlocking
    is permissible. With instructions generated by GPT-4, the LLM tries to mitigate
    the bug by unlocking during both system resets and maintenance mode which enables
    a more flexible and accessible system management. With the two-shot approach,
    the LLM (all based on Llama3) introduces a multi-condition lock control mechanism,
    leveraging both a global reset and a specific JTAG unlock condition, which can
    be tied to authenticated sessions or cryptographic checks.
  prefs: []
  type: TYPE_NORMAL
- en: IV-F Takeaways for Self Instructing in Hardware Verification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE II: Efficacy Ratio of Self-HWDebug in Self-Instructing for Security Verification
    (Debugging using One/Two-Shot Learning).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Vulnerability | Basic | Intermediate | Advanced | GPT-4^(∗1) | Two-shot^(∗1)
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1191 | 2 out of 5 | 5 out of 5 | 3 out of 5 | 4 out of 5 | 5 out of 5
    |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1231 | 0 out of 5 | 0 out of 5 | 1 out of 5 | 2 out of 5 | 5 out of 5
    |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1244 | 5 out of 5 | 4 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5
    |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1245 | 5 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5
    |'
  prefs: []
  type: TYPE_TB
- en: '| CWE-1300 | 2 out of 5 | 4 out of 5 | 5 out of 5 | 5 out of 5 | 5 out of 5
    |'
  prefs: []
  type: TYPE_TB
- en: '| Average | 56% | 72% | 76% | 84% | 100% |'
  prefs: []
  type: TYPE_TB
- en: ^(∗1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For both GPT-4 and two-shot experiments, we used an intermediate level of detail
    when prompting the LLM.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Dependence of Mitigation on the Accuracy of the Reference Sample: Instructions
    and subsequent mitigation become most effective when the reference examples accurately
    represent the issue across various scenarios. Therefore, using multiple reference
    pairs, each employing different approaches for mitigation, leads to more comprehensive
    and general instructions and thus, more effective self-instruction-based mitigation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Detailed Instructions Lead to More Sophisticated Repairs: As the complexity
    and detail in the instructions or descriptions increase, particularly while coupled
    with another example within the instruction, the potential for innovative and
    sophisticated repairs also rises. This comprehensive understanding allows LLM
    to devise more complex and effective solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Variability in Mitigation Difficulty Based on the Vulnerability: The difficulty
    of mitigating a vulnerability can vary significantly depending on the nature of
    the vulnerability itself. Some vulnerabilities might be straightforward , while
    others might be inherently complex to mitigate. Depending on their nature, multiple/advanced
    instructions are required to guarantee a high success rate in Self-HWDebug.'
  prefs: []
  type: TYPE_NORMAL
- en: V Conclusion and future work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we introduce a new framework designed to enhance the scalability
    and efficiency of LLMs in mitigating security vulnerabilities in hardware designs
    in a more automated manner. Prior research has shown that LLMs can effectively
    manage vulnerability mitigation. However, generating detailed, hand-written instructions
    has remained a significant challenge. This is primarily because the creation of
    these instructions demands significant time and effort from experts and typically
    only reflects the knowledge scope of a hardware engineer. To address these limitations,
    our proposed solution, Self-HWDebug, leverages the LLM’s ability to autonomously
    generate instructions. This approach not only addresses scalability issues but
    also produces instructions that are comprehensive and informed by an expanded
    knowledge base. In Self-HWDebug, the LLM acts as its own teacher and facilitates
    self-improvement. Through an initial testing, our experiments shows the efficacy
    of Self-HWDebug over a sub-set of CWE vulnerabilities with high success rate.
  prefs: []
  type: TYPE_NORMAL
- en: We view Self-HWDebug as a significant advancement in automating the mitigation
    of security vulnerabilities using LLMs, though require further study. Firstly,
    we plan to evaluate it over a wide (complete) range of CWEs and expand our dataset
    to advance the LLM’s capabilities towards more comprehensiveness. Also, we are
    considering the possibility of using the LLM both as a detector and mitigator
    of bugs. We believe this approach is feasible and would allow the application
    of LLMs to large-scale SoC designs, rather than being limited to snippets of already-detected
    vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] S. Ray *et al.*, “System-on-chip platform security assurance: Architecture
    and validation,” *Proceedings of the IEEE*, vol. 106, no. 1, pp. 21–37, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] A. Ferraiuolo *et al.*, “Verification of a practical hardware security
    architecture through static information flow analysis,” in *Int’l Conference on
    Architectural Support for Programming Languages and Operating Systems (ASPLOS)*,
    2017, pp. 555–568.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] W. Hu *et al.*, “An overview of hardware security and trust: Threats, countermeasures,
    and design tools,” *IEEE Transactions on Computer-Aided Design of Integrated Circuits
    and Systems*, vol. 40, no. 6, pp. 1010–1038, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] T. Grimm *et al.*, “A survey on formal verification techniques for safety-critical
    systems-on-chip,” *Electronics*, vol. 7, no. 6, p. 81, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] K. Z. Azar *et al.*, “Fuzz, penetration, and ai testing for soc security
    verification: Challenges and solutions,” *Cryptology ePrint Archive*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] M. M. Hossain *et al.*, “Socfuzzer: Soc vulnerability detection using cost
    function enabled fuzz testing,” in *Design, Automation & Test in Europe Conference
    & Exhibition (DATE)*, 2023, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] M. Akyash *et al.*, “Evolutionary large language models for hardware security:
    A comparative survey,” in *Great Lakes Symposium on VLSI (GLSVLSI)*, 2024, pp.
    1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] B. Ahmad *et al.*, “On hardware security bug code fixes by prompting large
    language models,” *IEEE Transactions on Information Forensics and Security*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] M. Nair *et al.*, “Generating secure hardware using chatgpt resistant to
    cwes,” *Cryptology ePrint Archive*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] M. Orenes-Vera *et al.*, “Using llms to facilitate formal verification
    of rtl,” *arXiv e-prints*, pp. arXiv–2309, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] W. Fang *et al.*, “Assertllm: Generating and evaluating hardware verification
    assertions from design specifications via multi-llms,” *arXiv preprint arXiv:2402.00386*,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] W. Fu *et al.*, “Llm4sechw: Leveraging domain-specific large language
    model for hardware debugging,” in *Asian Hardware Oriented Security and Trust
    Symposium (AsianHOST)*, 2023, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] X. Meng *et al.*, “Unlocking hardware security assurance: The potential
    of llms,” *arXiv preprint arXiv:2308.11042*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Y. Lu *et al.*, “Rtllm: An open-source benchmark for design rtl generation
    with large language model,” in *Asia and South Pacific Design Automation Conference
    (ASP-DAC)*, 2024, pp. 722–727.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] M. DeLorenzo *et al.*, “Make every move count: Llm-based high-quality
    rtl code generation using mcts,” *arXiv preprint arXiv:2402.03289*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] J. Liu *et al.*, “Is your code generated by chatgpt really correct? rigorous
    evaluation of large language models for code generation,” *Advances in Neural
    Information Processing Systems*, vol. 36, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] S. Liu *et al.*, “Rtlcoder: Outperforming gpt-3.5 in design rtl generation
    with our open-source dataset and lightweight solution,” *arXiv preprint arXiv:2312.08617*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] S. Gunasekar *et al.*, “Textbooks are all you need,” *arXiv preprint arXiv:2306.11644*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] X. Li *et al.*, “Prefix-tuning: Optimizing continuous prompts for generation,”
    *arXiv preprint arXiv:2101.00190*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] L. Chen *et al.*, “The dawn of ai-native eda: Promises and challenges
    of large circuit models,” *arXiv preprint arXiv:2403.07257*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] MITRE, “2021 cwe most important hardware weaknesses,” 2021\. [Online].
    Available: https://cwe.mitre.org/data/definitions/1343.html'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] A. R. Sadeghi *et al.*, “Organizing the world’s largest hardware security
    competition: challenges, opportunities, and lessons learned,” in *Proceedings
    of the 2021 on Great Lakes Symposium on VLSI*, 2021, pp. 95–100.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Trust-Hub, “Trust-hub benchmarks,” 2024\. [Online]. Available: https://trust-hub.org/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Meta AI, “Llama3,” 2024\. [Online]. Available: https://llama.meta.com/llama3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Groq, “Groq api,” 2024\. [Online]. Available: https://wow.groq.com/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
