- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:52:02'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlocking Hardware Security Assurance: The Potential of LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2308.11042](https://ar5iv.labs.arxiv.org/html/2308.11042)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Xingyu Meng1, Amisha Srivastava1, Ayush Arunachalam1, Avik Ray2,
  prefs: []
  type: TYPE_NORMAL
- en: 'Pedro Henrique Silva3, Rafail Psiakis3, Yiorgos Makris1 and Kanad Basu1 This
    research is supported by Technology Innovation Institute, Abu Dhabi, United Arab
    Emirates. (Corresponding Author:Xingyu Meng, Email: xxm150930@utdallas.edu). 1University
    of Texas at Dallas, 2Amazon Alexa, 3Technology Innovation Institute'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: System-on-Chips (SoCs) form the crux of modern computing systems. SoCs enable
    high-level integration through the utilization of multiple Intellectual Property
    (IP) cores. However, the integration of multiple IP cores also presents unique
    challenges owing to their inherent vulnerabilities, thereby compromising the security
    of the entire system. Hence, it is imperative to perform hardware security validation
    to address these concerns. The efficiency of this validation procedure is contingent
    on the quality of the SoC security properties provided. However, generating security
    properties with traditional approaches often requires expert intervention and
    is limited to a few IPs, thereby resulting in a time-consuming and non-robust
    process. To address this issue, we, for the first time, propose a novel and automated
    Natural Language Processing (NLP)-based Security Property Generator (NSPG). Specifically,
    our approach utilizes hardware documentation in order to propose the first hardware
    security-specific language model, HS-BERT, for extracting security properties
    dedicated to hardware design. To evaluate our proposed technique, we trained the
    HS-BERT model using sentences from RISC-V, OpenRISC, MIPS, OpenSPARC, and OpenTitan
    SoC documentation. When assessed on five untrained OpenTitan hardware IP documents,
    NSPG was able to extract 326 security properties from 1723 sentences. This, in
    turn, aided in identifying eight security bugs in the OpenTitan SoC design presented
    in the hardware hacking competition, Hack@DAC 2022.
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Modern computing systems are built on System-on-Chips (SoCs), as they offer
    a high level of integration through the use of multiple Intellectual Property
    (IP) cores [[24](#bib.bib24)]. However, this also presents new security challenges,
    since vulnerabilities in one IP core may affect the security of the entire system [[21](#bib.bib21)].
    While software and firmware patches can address many hardware security vulnerabilities,
    some cannot be fixed and require extensive security assurance during the design
    process. Hence, hardware security validation is imperative to ensure the security
    and trustworthiness of the design. MITRE’s Common Weakness Enumeration (CWE) for
    hardware categorizes commonly encountered security weaknesses in hardware designs,
    including issues with security flow, privilege and access control, reset control,
    memory and storage, peripherals and on-chip fabric, and debugging and test [[1](#bib.bib1)].
    Commercial verification tools, such as JasperGold Security Path Verification,
    Mentor Questa Secure Check, and Tortuga Logic Radix, have been proposed for SoC
    security verification [[20](#bib.bib20), [8](#bib.bib8), [10](#bib.bib10)]. However,
    the effectiveness of these tools depends on the quality of the security properties.
    Therefore, these properties are critical components that provide resources for
    detecting vulnerabilities during SoC development.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/989a26ee78d8e563454cac07b560f53d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Security property generation from documents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generating appropriate security properties for each specific design can be
    a challenge. Traditional approaches, which often require the experience of developers,
    are time-intensive and non-robust [[21](#bib.bib21)]. Hence, a technique that
    is capable of systematically generating security properties for SoCs is needed
    to address this issue. On the other hand, major organizations such as RISC-V,
    MSP, and Arduino usually provide documentation describing processor functionalities
    and operation behaviors with explicit details [[7](#bib.bib7), [9](#bib.bib9)].
    Therefore, as shown in Figure [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs"), we reason that it is possible
    to generate numerous security properties by analyzing operation details from these
    documents, which can be converted into security constraints at the Register-Transfer
    Level (RTL). We aim to achieve this by creating a language-based machine learning
    framework to extract essential information from the documentation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Existing research in the biomedical field, such as BioBERT, has shown that
    text and documents can provide essential information in specialized domains to
    fine-tune the general Bidirectional Encoder Representations from Transformers
    (BERT) language model for text generation and phrase classification [[15](#bib.bib15),
    [35](#bib.bib35)]. Similarly, security property-related sentences in hardware
    documentation also furnish domain-specific terminology. Hence, we intend to apply
    this concept to the hardware security domain and develop an automatic security
    property extraction framework built on the BERT model, which is fine-tuned with
    domain-specific data, as shown in Figure [2](#S1.F2 "Figure 2 ‣ I Introduction
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs"). Our aim is to
    utilize this framework to extract each sentence in the documentation that can
    be potentially converted into security properties. To this end, we developed a
    fully automatic hardware security property generator called NLP-based Security
    Property Generator (NSPG). NSPG applies data augmentation and masked language
    model to enhance the dataset and improve the learning process. We compared the
    output of NSPG with the expected information flow policies of these designs and
    found that the generated specifications were accurate and comprehensive, and if
    followed, would protect the designs from known and potential future attacks. To
    the best of our knowledge, NSPG is the first property generation technique utilizing
    the NLP model and SoC documentation to generate security properties for hardware
    designs. Our contributions are summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We propose an NLP-based security property generation framework, NSPG, to automatically
    mine security property-related sentences from the SoC documents, assisting in
    the detection of security vulnerabilities in RTL.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We present a complete end-to-end framework with hardware domain-specific knowledge
    and data modification techniques to improve the performance of the proposed HS-BERT
    model by analyzing hardware documentation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NSPG is evaluated on five unseen OpenTitan design documents and all generated
    security properties are validated. Furthermore, we apply these properties to search
    for security violations in the OpenTitan design used in Hack@DAC 2022 and identify
    eight bugs [[3](#bib.bib3)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When compared with ChatGPT, NSPG shows 15% improvement on identifying security
    properties in OpenTitan SoC documentation [[4](#bib.bib4)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/49beafa09f2d8e3218c4893d40ee84c2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Domain-specific BERT model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of this paper is organized as follows. Section [II](#S2 "II Background
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs") introduces the
    background of hardware security, and techniques in the NLP domain. Section [III](#S3
    "III Can Leveraging Large Language Models Foster Hardware Security Assurance?
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs") includes the
    proposed technique. Section [IV](#S4 "IV OpenTitan SoC and Threat Model ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs") introduces the SoC architecture,
    threat model, and security objectives used in this work. Section [V](#S5 "V Experiments
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs") demonstrates
    the evaluation of the proposed technique. Section [VI](#S6 "VI Discussion ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs") discusses the capabilities
    of the proposed technique. Section [VII](#S7 "VII Related Work ‣ Unlocking Hardware
    Security Assurance: The Potential of LLMs") presents the related works on security
    property generation. Finally, Section [VIII](#S8 "VIII Conclusion ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs") concludes our paper.'
  prefs: []
  type: TYPE_NORMAL
- en: II Background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will provide some background on hardware security verification,
    NLP, and the SoC designs used for developing the proposed NSPG framework.
  prefs: []
  type: TYPE_NORMAL
- en: II-A Hardware Security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: II-A1 Hardware Security Verification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A plethora of techniques have been developed to ensure the security of software
    applications, either through source code or binary operations [[21](#bib.bib21)].
    However, the availability of commercial Electronic Design Automation (EDA) tools,
    which are specifically crafted for hardware security, is rare. Hence, recently,
    researchers have focused on developing tools and methodologies to ensure hardware
    security. Nevertheless, all existing security verification techniques need robust
    security properties to validate the trustworthiness and robustness of the RTL [[21](#bib.bib21)].
    More details on hardware security verification approaches will be presented in
    Section [VII-A](#S7.SS1 "VII-A Hardware Security Verification Approaches ‣ VII
    Related Work ‣ Unlocking Hardware Security Assurance: The Potential of LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/35100ddac7b77c60aab5744e2ff6fc27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Proposed NSPG framework.'
  prefs: []
  type: TYPE_NORMAL
- en: II-A2 Hardware Design Documentation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In order to enhance the comprehensibility of the SoCs, it is imperative to have
    access to thorough SoC documentation, considering their complexity and dependence
    on reusable components. However, documentation is generally considered to provide
    limited value for any scientific analysis, and, thus overlooked by researchers.
    In reality, technical documentation is an important part of the overall product
    and should be prioritized along with the design and implementation stages. In
    more than one instance, insufficient documentation has been regarded as the major
    reason for design failure [[16](#bib.bib16)]. Additionally, various tools have
    been introduced to generate system documentation more efficiently. For instance,
    “Javadoc” and “CppDoc” generate API documentation in HTML from the comments in
    the source code [[5](#bib.bib5), [2](#bib.bib2)].
  prefs: []
  type: TYPE_NORMAL
- en: II-A3 Hardware Security Property
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The specification of security properties usually varies from the method of security
    analysis, producing specifications that are unique to the selected verification
    tools or models [[38](#bib.bib38)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 1: Security Property and SystemVerilog Assertion'
  prefs: []
  type: TYPE_NORMAL
- en: 'Security  Property  Description:If  the  AES  unit  wants  to  finish  encryption/decryptionof  a  data  block  but  the  previous  output  data  has  notyet  been  read  by  the  processor,  AES  unit  is  stalled.SystemVerilog  Assertion:assert  property  ( (posedge
    clk) disable iff (rst)// Security Property aes.done |-> aes.out==\$past(aes.key)
    ) else // Error Message \$error("\%m  previous  key  has  not  been  read");'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing [1](#LST1 "Listing 1 ‣ II-A3 Hardware Security Property ‣ II-A Hardware
    Security ‣ II Background ‣ Unlocking Hardware Security Assurance: The Potential
    of LLMs") presents an example of SystemVerilog assertion based on the description
    of the security property. It shows that in order to generate an appropriate term
    for a verification mechanism, the descriptions of security properties must contain
    strong reasoning and details of the operation. Listing [2](#LST2 "Listing 2 ‣
    II-A3 Hardware Security Property ‣ II-A Hardware Security ‣ II Background ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs") shows a paragraph from the
    OpenTitan AES document [[4](#bib.bib4)]. The sentences marked in blue are security
    related.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 2: A example paragraph in AES Document'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also,  there  is  a  back-pressure  mechanism  for  theoutput  data.
    If  the  AES  unit  wants  to  finish  theencryption/decryption  of  a  data  block  but  the  previousoutput  data  has  not  yet  been  read  by  the  processor,the  AES  unit  is  stalled.  It  hangs  and  does  not  dropdata.  The  order  in  which  the  output  registers  are  readdoes  not  matter.  Every  output  register  must  be  readat  least  once  for  the  AES  unit  to  continue.
    This  isthe  default  behavior.  It  can  be  disabled  by  settingthe  MANUAL_OPERATION  bit  in  CTRL_SHADOWED  to  1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is obvious that the security properties have more distinguished contexts,
    such as the usage of relation conjunctions and domain-specific terms, compared
    to other sentences in the paragraph. Therefore, it is possible to distinguish
    the security property-related sentences, which present precise definitions of
    the schematic, keywords of the processes, or relations between several entities.
    Hence, we can emphasize these aspects when fine-tuning the language model by enhancing
    and identifying the security property-related context in each sentence. Further
    details about the security property extraction techniques utilized in our framework
    will be presented in Section [I](#S3.T1 "TABLE I ‣ III Can Leveraging Large Language
    Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance:
    The Potential of LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: II-B Natural Language Processing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: NLP is a field of study that focuses on applying computational techniques to
    understand, learn, and generate human language content. NLP plays a crucial role
    in various industries and has a wide range of applications, ranging from real-time
    translation and social media search engines to sentiment analysis [[26](#bib.bib26)].
    In this section, we will discuss the NLP facets that are integrated into NSPG.
  prefs: []
  type: TYPE_NORMAL
- en: II-B1 BERT Model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most state-of-the-art natural language models are built on transformer architectures,
    such as Bidirectional Encoder Representations from Transformers (BERT), which
    are effective at modeling long-range dependencies in text [[27](#bib.bib27)].
    These models utilize a multi-layer, multi-head self-attention mechanism, and contextual
    embeddings which allow for efficient parallel computation on GPUs [[23](#bib.bib23)].
    We utilize the BERT masked language model to comprehend the hardware documentation
    and BERT sequence classification model to extract the security property-related
    sentences.
  prefs: []
  type: TYPE_NORMAL
- en: II-B2 Data Augmentation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Data augmentation (DA) is a method of enhancing the diversity of training data
    without collecting more data. It involves adding modified copies of existing data
    or creating synthetic data to act as a regularizer and reducing overfitting during
    the training of machine learning models [[26](#bib.bib26)]. Since this is the
    first work that utilizes design documentation for hardware security, our data
    samples are limited to open-source documentation. Thus, we will apply DA approaches,
    as discussed in Section [III](#S3 "III Can Leveraging Large Language Models Foster
    Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance: The Potential
    of LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: II-B3 Masked Language Modeling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Masked Language Modeling (MLM) is a self-supervised learning method used in
    state-of-the-art BERT models, such as SciBERT or RoBERTa [[15](#bib.bib15), [23](#bib.bib23)].
    MLM is used to improve the ability to comprehend the context and relationships
    between each word in a sequence, such as the security property demonstrated in
    Listing [1](#LST1 "Listing 1 ‣ II-A3 Hardware Security Property ‣ II-A Hardware
    Security ‣ II Background ‣ Unlocking Hardware Security Assurance: The Potential
    of LLMs"). We will utilize MLM to modify the sequences from the document and provide
    additional data for fine-tuning.'
  prefs: []
  type: TYPE_NORMAL
- en: II-B4 Sequence Classification Modeling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Sequence Classification Modeling (SCM) divides sequences into predefined sentiment
    categories [[23](#bib.bib23)]. Our proposed framework, NSPG, will apply this model
    to categorize each sequence of sentences and identify if they belong to security
    property or non-property descriptions in the documents.
  prefs: []
  type: TYPE_NORMAL
- en: III Can Leveraging Large Language Models Foster Hardware Security Assurance?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TABLE I: Data Augmentation for sentence in documents. The first row shows the
    original sentence in the document, the rest shows an example sentence after the
    random swap, random deletion, synonym replacement, and random insertion.'
  prefs: []
  type: TYPE_NORMAL
- en: Sentence Original If some hang condition were to occur when in this mode, the
    main state machine debug register should be read. Original with RS If some hang
    condition were to occur, the main state machine debug register should be read
    when in this mode. Original with RD If [some] hang condition were to occur when
    in this mode, the main state machine debug register should be read. Original with
    SR If some hang condition were to happen when in this mode, the main state machine
    debug register should be read. Original with RI If some hang condition were to
    occur when in this mode, the main state machine debug register should be read
    [immediately].
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will demonstrate the details of each process flow in the
    proposed NSPG framework, as shown in Figure [3](#S2.F3 "Figure 3 ‣ II-A1 Hardware
    Security Verification ‣ II-A Hardware Security ‣ II Background ‣ Unlocking Hardware
    Security Assurance: The Potential of LLMs"). The first step involves comprehending
    the context of the hardware domain from the hardware design documentation of OpenTitan
    and RISC-V, and generating the hardware security-specific BERT model. Next, we
    alter them using data augmentation and hardware domain-specific modification to
    create an enhanced dataset for fine-tuning the pre-trained BERT model. We compare
    the performance of various modified datasets used to fine-tune the classification
    model and select the best one for security property extraction. The details of
    the data augmentation and pre-training hardware-domain BERT will be discussed
    in detail in Section [III-B](#S3.SS2 "III-B Comprehending the Hardware Domain
    ‣ III Can Leveraging Large Language Models Foster Hardware Security Assurance?
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs"). The domain-specific
    data modification process and security property classification will be described
    in detail in Section [III-C](#S3.SS3 "III-C Security Property Classification ‣
    III Can Leveraging Large Language Models Foster Hardware Security Assurance? ‣
    Unlocking Hardware Security Assurance: The Potential of LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: III-A Hardware Documentation Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The sentences used for training and fine-tuning are extracted from various
    documentation and paragraphs similar to the example shown in Listing [2](#LST2
    "Listing 2 ‣ II-A3 Hardware Security Property ‣ II-A Hardware Security ‣ II Background
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs"). We create three
    datasets, as follows: (1) 15583 sentences from OpenTitan, RISC-V, OpenRISC, MIPS,
    and OpenSPARC documentation are used for pre-training the BERT model with MLM.
    This dataset will be called ${\mathcal{}{D}}_{pre}$.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B Comprehending the Hardware Domain
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, the language model needs to recognize the context differences between
    security properties and regular sentences. General BERT model has been applied
    in various industries and has a wide range of applications, ranging from real-time
    translation and social media search engines to sentiment analysis [[26](#bib.bib26)].
    Training the BERT model with its corresponding MLM could augment the performance
    of the language model by introducing contextual embeddings of the specific domain.
    As shown in Figure [4](#S3.F4 "Figure 4 ‣ III-B Comprehending the Hardware Domain
    ‣ III Can Leveraging Large Language Models Foster Hardware Security Assurance?
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs"), during training,
    a certain percentage of tokens are randomly selected and replaced with a special
    token ([MASK] in Masked sentence). After training, the fine-tuned MLM will predict
    the original tokens based on the context provided by the remaining unmasked tokens,
    thus completing the in-domain sentence with appropriate phrases. The primary objective
    is to minimize the cross-entropy loss between the predicted tokens and their original
    counterparts. For instance, in SciBERT and RoBERTa, by default, 15% of the input
    tokens are chosen for masking, with 80% probability of being replaced by [MASK],
    10% left unchanged and 10% randomly replaced by another token from the vocabulary [[15](#bib.bib15),
    [23](#bib.bib23)]. Therefore, pre-training BERT model with hardware domain documentation
    will help it learn to represent the in-domain words based on the context of the
    other words in the sentence. However, since we have limited data samples for hardware
    domain-specific documentation (compared to 1.14M papers from Semantic Scholar
    to train Sci-Bert), data augmentation is needed to improve the dataset[[15](#bib.bib15)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f810cc6cc575732d4b85351fdf42274d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Masked language model.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B1 Data Augmentation for Hardware Documentation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many DA techniques have been proposed for NLP, including rule-based manipulations
    and generative approaches. Ideal DA techniques should be implemented seamlessly
    in order to further improve model performance. Techniques that use trained models
    are more expensive to implement. However, they introduce more variance in data,
    thereby resulting in enhanced model performance. Although model-based techniques
    are designed to boost performance in downstream tasks, they are difficult to develop
    and use. This may result in overfitting or performance degradation when trained
    on out-of-domain examples. DA is a key component for enhancing the quantity of
    in-domain data samples, which involves generating two correlated views of a data
    point in order to increase the amount and diversity of training data. Although
    it is important to ensure the diversity of the generated data, the structure,
    and synonym of the original sentence should not be modified.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the security properties involve the behaviors of two or more entities
    in the design. Therefore, the context of operational relations and hardware terminology
    needs to be preserved in fine-tuning MLM. We need to avoid the essential information
    of the operating entities and only apply DA to swap or replace the rest of the
    tokens in the sentence. We analyze four DA techniques: random swap, random deletion,
    synonym replacement, and random insertion. These are the most common data augmentation
    technique available for NLP model [[26](#bib.bib26)]. The closest sentiment texts
    are provided by Wordnet, a large lexical database of English, where synonyms are
    interconnected by means of conceptual-semantic, to generate the augmented data [[40](#bib.bib40)].
    The tokens in the texts are modified in the following ways to generate the augmented
    data. Table [I](#S3.T1 "TABLE I ‣ III Can Leveraging Large Language Models Foster
    Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance: The Potential
    of LLMs") presents examples of the techniques applied to a sentence from the DA
    task, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Random Swap (RS): We exchange the positions of two randomly selected phrases
    such as nouns and conjunctions, while maintaining the operation behavior and the
    content of the original sentence. For example, as evident from Table [I](#S3.T1
    "TABLE I ‣ III Can Leveraging Large Language Models Foster Hardware Security Assurance?
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs"), RS takes parts
    of the sentence conjunction “when in this mode” and places them into a random
    spot, which is either before or at end of a conjunction in the original sentence.
    In case the sentence does not have multiple conjunctions, no augmented sentence
    will be generated.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Random Deletion (RD): To keep the essential context, we only delete one of
    the adjectives, determiners, or adverbs available in the sentence, which does
    not impact the operation descriptions. For example, RD removes the definition
    term “some” from the sentence in Table [I](#S3.T1 "TABLE I ‣ III Can Leveraging
    Large Language Models Foster Hardware Security Assurance? ‣ Unlocking Hardware
    Security Assurance: The Potential of LLMs"). When these terms are not found in
    the sentence, RD will not be applied.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Synonym Replacement (SR): In order to preserve the hardware components described
    in the sentence, we only replace verbs in the sentence with their closest synonyms
    obtained from the WordNet database. It utilizes the database to find the closest
    semantic words for the sentence and replace the verb with the new ones. For example,
    in Table [I](#S3.T1 "TABLE I ‣ III Can Leveraging Large Language Models Foster
    Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance: The Potential
    of LLMs"), “occur” is replaced with its synonym “happen”, and the sentence still
    presents the same operation. When the sentence only contains verbs such as “is”
    or “are”, no augmented sentence will be generated.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Random Insertion (RI): For this operation, we first summarize all the adverbs
    that are used in the documentation, and randomly select one to insert into the
    sentence near verbs. To avoid altering the context, we randomly choose the most
    common adverb used in the documents. For instance, insert the adverb ’immediately’
    before or after a randomly selected verb in the sentence, as shown in Table [I](#S3.T1
    "TABLE I ‣ III Can Leveraging Large Language Models Foster Hardware Security Assurance?
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: Each method tends to introduce diversity in the original sentence and increase
    possible word usage, thereby reducing data overfitting and boosting the generalization
    ability of the model. We train four BERT models using different augmented data
    (in combination with the original data) and evaluate their performance to determine
    the best model.
  prefs: []
  type: TYPE_NORMAL
- en: III-B2 Pre-training BERT with MLM
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'TABLE II: The performances of HS-BERT models with the original sentence from
    ${\mathcal{}{D}}_{pre}$ and after the random swap, random deletion, synonym replacement,
    and random insertion.'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset Training Samples Runtime Perplexity Original Documents 12472 57 mins
    6.018 Original & RS 24065 109 mins 5.018 Original & RD 24946 114 mins 5.046 Original
    & SR 24208 110 mins 5.029 Original & RI 24931 113 mins 4.795
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of MLM is to understand the detail of each sentence demonstrated
    in the document and predict the masked content. Hence, we will select the model
    having the lowest perplexity, where a lower score indicates that the model has
    a better comprehension of the hardware domain and prediction of the masked word
    in the in-domain sentences [[41](#bib.bib41)]. We split the samples from ${\mathcal{}{D}}_{pre}$
    into training and validation datasets with a ratio of 80% and 20%. Each model
    is trained with samples from the OpenTitan, RISC-V, OpenRISC, MIPS, and OpenSPARC
    documentation, which consist of 12473 sentences and additional data from the DA
    task. Table [II](#S3.T2 "TABLE II ‣ III-B2 Pre-training BERT with MLM ‣ III-B
    Comprehending the Hardware Domain ‣ III Can Leveraging Large Language Models Foster
    Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance: The Potential
    of LLMs") shows the runtime, and perplexity for each DA approach, as described
    in Section [III-B1](#S3.SS2.SSS1 "III-B1 Data Augmentation for Hardware Documentation
    ‣ III-B Comprehending the Hardware Domain ‣ III Can Leveraging Large Language
    Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance:
    The Potential of LLMs"). Note that the runtime differences are caused by different
    numbers of augmented data samples since the operation details of original sentences
    need to be preserved. We evaluate each pre-trained BERT model with the validation
    dataset consisting of 3112 sentences. As shown in Table [II](#S3.T2 "TABLE II
    ‣ III-B2 Pre-training BERT with MLM ‣ III-B Comprehending the Hardware Domain
    ‣ III Can Leveraging Large Language Models Foster Hardware Security Assurance?
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs"), the DA task
    significantly improves the performance of the BERT model comprehension (lower
    perplexity) with scalable runtime increase. Random insertion operation performs
    the best among all four approaches with a perplexity score of 5. Therefore, we
    use the BERT model pre-trained with data from RI for further processes. This BERT
    model will be called Hardware Security-specific BERT (HS-BERT).'
  prefs: []
  type: TYPE_NORMAL
- en: III-C Security Property Classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE III: Sentence pre-processing methods and examples.'
  prefs: []
  type: TYPE_NORMAL
- en: Sentence Original If KEYMGR is at the conclusion of the operation, KEYMGR.CTRL.STATUS
    stays in the same state, begins again. Verb Swapping If KEYMGR is at the conclusion
    of the operation, KEYMGR.CTRL.STATUS [remain] in the same state, [starts] again.
    Noun Swapping If [condition] is at the conclusion of the operation, [register]
    stays in the same state, begins again. Fragment Removal If KEYMGR is at the conclusion
    of the operation, KEYMGR.CTRL.STATUS stays in the same state. [ begins again.]
    Fragment Addition If KEYMGR is at the conclusion of the operation, KEYMGR.CTRL.STATUS
    stays in the same state, [system sampling] begins again.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will explain the process of security property classification
    from the design documentation utilizing the Sequence Classification Model (SCM),
    as mentioned in Section [II-B4](#S2.SS2.SSS4 "II-B4 Sequence Classification Modeling
    ‣ II-B Natural Language Processing ‣ II Background ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs"). Figure [5](#S3.F5 "Figure 5 ‣ III-C Security
    Property Classification ‣ III Can Leveraging Large Language Models Foster Hardware
    Security Assurance? ‣ Unlocking Hardware Security Assurance: The Potential of
    LLMs") illustrates the training procedure of NSPG framework, which consists of
    three stages. In the first stage, we obtain the HS-BERT model with sentences from
    hardware design documentation. In the second stage, we will modify the labeled
    ${\mathcal{}{D}}_{cls}$ and utilize the best-performing one to generate security
    properties from the documents.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8f94eb8b6276f7e432b3a2dc8ff9cee9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: HS-BERT model training process.'
  prefs: []
  type: TYPE_NORMAL
- en: ${\mathcal{}{D}}_{cls}$ as unseen in-domain documentation, and evaluate the
    performances of the fine-tuned SCM model for security property generation. Each
    BERT sequence classification model is trained with different combinations of the
    original and modified training datasets to evaluate the classification performance
    based on accuracy, recall, precision, and F1-score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since our priority is to maximize the generation of security properties, we
    can tolerate the presence of a few non-property-related sentences (*i.e.*, False
    Positives), which can be removed with further analysis. Therefore, accuracy and
    recall are the key metrics to determine the performance of sentence modification
    and SCM in NSPG. Higher values of accuracy and recall indicate better performance
    of the modification method and SCM model. The details will be discussed in Section [III-C4](#S3.SS3.SSS4
    "III-C4 Fine-tuning SCM model ‣ III-C Security Property Classification ‣ III Can
    Leveraging Large Language Models Foster Hardware Security Assurance? ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs"). In this work, we employ
    the SciBERT and general BERT model (“bert-base-uncased”), and compare their performances
    against HS-BERT in Section [III-C3](#S3.SS3.SSS3 "III-C3 General BERT vs SciBERT
    vs HS-BERT ‣ III-C Security Property Classification ‣ III Can Leveraging Large
    Language Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b2cff89d3a05d4ecab34061f4d38a21b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Sentence modification in documents. The first row represents the
    original sentence in the document. The second row shows each fragment of the original
    sentence. The third row adds [Mask] token into the fragment for missing components.
    The fourth row demonstrates the process of reconstructing the missing components
    of each fragment, and the last row shows the sentence after constructing the missing
    components.'
  prefs: []
  type: TYPE_NORMAL
- en: III-C1 Data Modification for Property Classification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'TABLE IV: Performance comparison between general BERT, SciBERT and HS-BERT
    with data modifications from ${\mathcal{}{D}}_{cls}$.'
  prefs: []
  type: TYPE_NORMAL
- en: General BERT SciBERT HS-BERT Accuracy Recall Precision F1-Score Accuracy Recall
    Precision F1-Score Accuracy Recall Precision F1-Score Baseline 83.1% 81% 49.4%
    65.1% 83.2% 98% 46% 61.7% 84% 97% 45% 63% MT 83.2% 93.5% 51.8% 65.8% 82.2% 96%
    49% 65% 85.1% 97.3% 48.7% 64.7% MOT 86% 96.4% 46.7% 63% 88.1% 98% 45% 62% 90.1%
    98.3% 49% 65% MTT 81.2% 83.4% 50.4% 61.2% 87.1% 95% 44% 60% 88.1% 97.5% 48% 64%
    MOTMT 83.2% 70.6% 35.5% 71% 87.5% 97% 44% 59% 88.5% 98.1% 48% 64%
  prefs: []
  type: TYPE_NORMAL
- en: Data pre-processing and data cleansing are utilized to generate unbiased data,
    which in turn is critical to furnish reliable machine learning algorithms [[25](#bib.bib25)].
    Studies have shown that biased learning can result from training on imbalanced
    or noisy data [[46](#bib.bib46), [34](#bib.bib34)]. Therefore, significant consideration
    should be provided to the data cleansing process and detailing the methods used
    in our studies. BERT model tokenizer is used to tokenize the sentences by its
    data pre-processing technique [[23](#bib.bib23)]. In order to improve the performance
    of sequence classification, we propose a hardware domain-specific modification
    to further differentiate the features of each sentence in the documents, which
    enforces the BERT model to recognize more contextual dependencies. For instance,
    sentences including hardware operations and behavior are considered in-domain,
    while common descriptions are regarded as out-of-domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although a plethora of data pre-processing approaches have been proposed to
    improve the performances of machine learning techniques in text mining and image
    classification [[28](#bib.bib28), [32](#bib.bib32)], most language models are
    pre-trained with a wide range of documentation in a different domain. In this
    work, we consider some data modification methods with hardware security-domain
    context and validate their impact on model performances. As shown in Table [III](#S3.T3
    "TABLE III ‣ III-C Security Property Classification ‣ III Can Leveraging Large
    Language Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs"), we apply several alternative methods, including
    verb swapping, noun swapping, fragment deletion, and fragment insertion, to preprocess
    all sentences in the dataset, described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Verb Swapping: This approach substitutes the verbs in the sentence with semantic
    pre-defined hardware domain-related verbs. For example, in Table [III](#S3.T3
    "TABLE III ‣ III-C Security Property Classification ‣ III Can Leveraging Large
    Language Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs"), “stay” and “begins” in each sentence are replaced
    with “remain” and “starts” to formalize the usage of verbs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Noun Swapping: This method intends to remove the arbitrary term used in each
    sentence, such as “KEYMGR” and “KEYMGR.CTRL.STATUS” in Table [III](#S3.T3 "TABLE
    III ‣ III-C Security Property Classification ‣ III Can Leveraging Large Language
    Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance:
    The Potential of LLMs"), and replace them with more generalized terminology in
    the hardware domain such as “condition” and “register”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fragment Deletion: Some fragments of the sentence are not directly related
    to operation details. In this case, we intend to break the sentence into multiple
    conjunctions and remove the small fragments such as “begin again” in Table [III](#S3.T3
    "TABLE III ‣ III-C Security Property Classification ‣ III Can Leveraging Large
    Language Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs"), while retaining the more essential content
    of hardware operations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fragment Insertion: This approach adds information to the incomplete sentence.
    Typically, we consider a complete sentence consists of two (noun, verb) or three
    components (noun, verb, and noun). For each incomplete fragment in the sentence,
    we will construct them with a similar structure.'
  prefs: []
  type: TYPE_NORMAL
- en: III-C2 Fragment Insertion Modification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Through our initial analysis, the other data modification approaches furnished
    sub-par classification performance of up to 55% accuracy, we have included and
    described the results pertaining to the fragment insertion technique. Therefore,
    we determine that only fragment insertion improves the performance of the classification
    model. While noun swapping and verb swapping do not significantly affect performance,
    fragment removal degrades performance. The primary reason is that fragment insertion
    adds more in-domain context to the original sentence, which helps the SCM identify
    the operation context. Therefore, we can infer that instead of simplifying the
    data, the NLP model tends to require more information and complete structure in
    each sentence to learn the subjects more accurately. Intuitively, the prevailing
    assumption is that using more in-domain text in the training datasets should help
    with domain-specific classification. Although each sentence in the document is
    constructed differently, we will explore this concept by adding domain-specific
    portions for each sentence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [6](#S3.F6 "Figure 6 ‣ III-C Security Property Classification ‣ III
    Can Leveraging Large Language Models Foster Hardware Security Assurance? ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs") shows an example of modifying
    a sentence in the document with fragment insertion. First, we break the sentence
    “When resetting, if 0, allow requests to pass through the host-side FIFO with
    no clock delay.” into fragments by identifying each conjunction “When”, “if”,
    and “to” in the sentence, and separating the sentence into fragments as: “When
    resetting”, “if 0”, “allow requests”, and “to pass through the host-side FIFO
    with no clock delay”. In these fragments, “When resetting”, and “allow requests”
    are missing nouns, “if 0” is missing noun and verb, and “to pass through the host-side
    FIFO with no clock delay” is complete. We will add these missing components into
    the fragments by adding a [Mask] token into the fragment and applying the pre-trained
    HS-BERT to place appropriate in-domain terms for each [Mask] token. Hence, “When
    resetting”, “if 0”, and “allow requests” will be transformed into “When system
    is resetting”, “if value is set 0”, and “module allows requests”. Since the other
    data modification approaches furnished sub-par classification performance of up
    to 55% accuracy, we have included and described the results pertaining to the
    fragment insertion technique.'
  prefs: []
  type: TYPE_NORMAL
- en: III-C3 General BERT vs SciBERT vs HS-BERT
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we will discuss the available pre-trained BERT models and
    motivate our choice of the proposed HS-BERT, as shown in Section [III-B2](#S3.SS2.SSS2
    "III-B2 Pre-training BERT with MLM ‣ III-B Comprehending the Hardware Domain ‣
    III Can Leveraging Large Language Models Foster Hardware Security Assurance? ‣
    Unlocking Hardware Security Assurance: The Potential of LLMs"), for its inclusion
    in NSPG. General BERT utilizes WordPiece [[49](#bib.bib49)] for unsupervised tokenization
    of input sequences, building its vocabulary with the most frequently used words
    or sub-word units. SciBERT, on the other hand, is constructed with a new WordPiece
    vocabulary on a scientific corpus using the SentencePiece1 library [[45](#bib.bib45)].
    The token overlap between BERT and SciBERT vocabulary is 42%, indicating a substantial
    difference in the frequently used words between scientific and general domain
    texts. SciBERT was trained on a dataset comprising 1.14M papers from Semantic
    Scholar, where 82% of the papers belong to the biomedical domain, while the remaining
    18% pertain to computer science [[12](#bib.bib12)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [IV](#S3.T4 "TABLE IV ‣ III-C1 Data Modification for Property Classification
    ‣ III-C Security Property Classification ‣ III Can Leveraging Large Language Models
    Foster Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance: The
    Potential of LLMs") shows the comparison between the general BERT model, SciBERT,
    and the proposed HS-BERT, training the same data modification method and the same
    3927 samples from ${\mathcal{}{D}}_{cls}$ are used for validation. Modifications
    are applied to both in-domain and out-of-domain sentences. The baseline refers
    to no modification on both training and testing data. We have considered the following
    cases for modification: MT refers to only modifying training data. MTT refers
    to modifying training and testing data. Note that the modification only changes
    the content of testing sentences and does not increase the size of test samples.
    MOT refers to both modified and original training data. MOTMT refers to the original
    training data, its modified counterpart, and modified testing data. The results
    indicate that all three BERT models demonstrate improved performance in comparison
    to their baseline models, with an average increase of 0.6% accuracy with General
    BERT, 3.1% accuracy with SciBERT, and 3.95% accuracy with HS-BERT. For each data
    modification method, the largest effects of fine-tuning were observed in the MOT
    (+6.1% accuracy with HS-BERT, +4.9% accuracy with SciBERT, and +2.9% accuracy
    with General BERT) and MOTOT (+4.9% accuracy with SciBERT and +0.1% accuracy with
    General BERT). While little effect was seen on recall, precision, and F1-score
    for HS-BERT and SciBERT, General BERT gains a significant improvement in recall
    when applying MOT (+15.4%). However, HS-BERT, with fine-tuning, outperforms the
    state of art General BERT and SciBERT model on accuracy and recall, while performing
    similarly on precision and F1-score. Based on these observations, we determine
    that HS-BERT is more suitable for extracting potential security properties, which
    we have subsequently incorporated in NSPG.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE V: Sequence Classification for ${\mathcal{}{D}}_{val}$. Each row represents
    the accuracy, recall, and F1-score for different HS-BERT models and different
    modified labeled datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: OpenTitan RISCV Openrisc Accuracy Recall Accuracy Recall Accuracy Recall Base-HS-BERT
    70.6% 72.8% 71.9% 71.2% 80.3% 80.2% MT-HS-BERT 74.5% 80.4% 75.8% 79.2% 83.6% 82.6%
    MOT-HS-BERT 81.5% 93% 79.1% 90.1% 88.3% 87% MTT-HS-BERT 75% 85% 74.3% 83.5% 86.3%
    82.6% MOTMT-HS-BERT 76% 84.1% 73.3% 80.5% 87% 84.7%
  prefs: []
  type: TYPE_NORMAL
- en: III-C4 Fine-tuning SCM model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this stage, NSPG will apply fine-tuned HS-BERT SCM to identify the security
    properties in the SoC documentation. In order to emulate this scenario in which
    the SCM is applied on an unseen document to determine whether the sentence is
    a security property or not, we will test each trained sequence classification
    model on ${\mathcal{}{D}}_{val}$. Table [V](#S3.T5 "TABLE V ‣ III-C3 General BERT
    vs SciBERT vs HS-BERT ‣ III-C Security Property Classification ‣ III Can Leveraging
    Large Language Models Foster Hardware Security Assurance? ‣ Unlocking Hardware
    Security Assurance: The Potential of LLMs") shows the results for HS-BERT performance
    with no modification and the data modification approach, as described in Section [III-C3](#S3.SS3.SSS3
    "III-C3 General BERT vs SciBERT vs HS-BERT ‣ III-C Security Property Classification
    ‣ III Can Leveraging Large Language Models Foster Hardware Security Assurance?
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs"). Base-HS-BERT
    refers to the SCM performance fine-tuned with no data modification. The HS-BERT
    model trained with the MOT modification performs the best with an average of 82%
    accuracy, and 90% recall score. Since this method consists of both the original
    and the modified sentences, it improves the diversity of the training dataset,
    which helps the model to learn more features and context of a property-related
    sentence. Therefore, we will use MOT modification as our final data modification
    approach for the SCM model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Input: Document Files, Labeled Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: 'Output: Property, Non-Property'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 Sentence Formalization
  prefs: []
  type: TYPE_NORMAL
- en: 1:MLM.train(Document Files)2:Initialize Enhanced Labeled Dataset3:for each Sentence
    in Labeled Dataset do4:     Split(Sentence) $\rightarrow$Sentence12:end for13:SCM.train(Enhanced
    Labeled Dataset)14:for each Sentence in Document do15:     if SC.predict(Sentence)
    <math id="alg1.l15.m1.1" class="ltx_Math" alttext="></math> Non-Property19:end for
  prefs: []
  type: TYPE_NORMAL
- en: III-C5 NSPG Framework Summary
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'After validating each procedure in training, we will construct the pipeline
    of our proposed framework NSPG. It comprises data augmentation, data modification,
    fine-tuning masked language model, and sequence classification model. The fine-tuned
    sequence classification model is used to analyze the unseen documents, and extract
    the security properties which contain essential information about operation behaviors,
    and register interactions. Algorithm [1](#alg1 "Algorithm 1 ‣ III-C4 Fine-tuning
    SCM model ‣ III-C Security Property Classification ‣ III Can Leveraging Large
    Language Models Foster Hardware Security Assurance? ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs") demonstrates the details of each stage for
    the training and security property generation process. These extracted security
    properties can be further utilized by commercial hardware verification approaches,
    such as Cadence Jaspergold, and detect potential vulnerabilities in the design.
    The generated security properties as well as their application in detecting SoC
    vulnerabilities will be evaluated in Section [V](#S5 "V Experiments ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: IV OpenTitan SoC and Threat Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IV-A OpenTitan SoC
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we do not have access to commercial designs, our framework has been developed
    using open-source SoCs, such as OpenSPARC, MIPS, OpenRISC, RISC-V and OpenTitan.
    In this work, while the OpenTitan design documentation is utilized for both training
    and validation, the other documents are only used for training. The OpenTitan
    document considered in our study corresponds to a buggy design, which was used
    in the Hack@DAC 2022 hardware hacking competition [[3](#bib.bib3)].
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Threat Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our threat model is similar to the one used in Hack@DAC 2022\. The attack scenarios
    considered are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An unprivileged software adversary that can access the core in user mode, with
    control over user-space interfaces and the ability to issue unprivileged system
    instructions and request feedback.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A privileged software adversary that can execute malicious code with supervisor
    privilege but may target higher privilege levels or bypass security countermeasures.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An authorized debug adversary which is capable of unlocking and debugging production
    devices.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The aim of the adversary is to exploit any potential vulnerabilities in the
    SoC in order to bypass any security objective.
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Security Objectives and Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The security objectives of OpenTitan are as follows [[3](#bib.bib3)]:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SO1: Preventing privilege level compromise due to unprivileged code running
    in the core.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SO2: Protecting system debug interface from malicious or unauthorized debugger.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SO3: Protecting device integrity and preventing exploits from a software adversary.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Various security features have been developed for the OpenTitan SoC to support
    the aforementioned security objectives, including privileged access control to
    peripherals, write and read locks on registers to protect the privilege integrity
    from unprivileged instruction, and reset to flush sensitive information in cryptographic
    processors.
  prefs: []
  type: TYPE_NORMAL
- en: V Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will demonstrate the evaluation of our framework NSPG with
    five OpenTitan IP documents, and discuss its performance on security property
    extraction. Furthermore, these extracted properties will be utilized with verification
    methods to detect vulnerabilities in the design.
  prefs: []
  type: TYPE_NORMAL
- en: V-A Experimental Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE VI: Number of processed sentences, security properties generated, and
    properties covered and not covered by design verification (DV) documentation.'
  prefs: []
  type: TYPE_NORMAL
- en: Hardware IP Sentences Extracted Properties Covered by DV Not covered by DV Key
    Manager 241 51 47 40 7 LC Controller 375 79 76 65 11 HMAC 170 28 27 19 8 KMAC
    367 84 74 60 14 OTP Controller 570 105 102 84 18 Total 1723 347 326 268 58
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE VII: Examples of security properties generated from the framework.'
  prefs: []
  type: TYPE_NORMAL
- en: Module Constructed Security Properties HW CWE Category Key Manager Upon Disabled
    entry, the internal key is updated with KMAC computed random values; however,
    previously generated sideload key slots and software key slots are preserved.
    Improper Zeroization of Hardware Register - (1239) Invalid state is entered whenever
    key manager is deactivated through the life cycle connection or when an operation
    encounters a fault . Improper Finite State Machines (FSMs) in Hardware Logic -
    (1245) When an illegal operation is supplied, the err_code is updated and the
    operation is flagged as done with error. Improper Protection for Outbound Error
    Messages and Alert Signals - (1320) When the life cycle controller deactivates
    the key manager, the key manager transitions to the Invalid state. Improper Finite
    State Machines (FSMs) in Hardware Logic - (1245) LC Controller fatal_bus_integ_error_q
    is triggered when a fatal TL-UL bus integrity fault is detected. Improper Protection
    for Outbound Error Messages and Alert Signals - (1320) fatal_bus_integ_error_q
    is set to 1 if a fatal bus integrity fault is detected. Improper Protection for
    Outbound Error Messages and Alert Signals - (1320) HMAC If SW wants to convert
    the message byte order, SW should set CFG.endian_swap to 1. Expected Behavior
    Violation - (440) When the SHA engine is disabled the digest is cleared. Sensitive
    Information in Resource Not Removed Before Reuse - (226) If CPU writes value into
    the register, the value is used to randomize internal variables such as secret
    key, internal state machine, or hash value. Sensitive Information in Resource
    Not Removed Before Reuse - (226) KMAC If the EnMasking parameter is not set, the
    second share is always zero. Improper Zeroization of Hardware Register - (1239)
    If EnMasking is not defined, the KMAC merges the shared key to the unmasked form
    before uses the key. Sensitive Information in Resource Not Removed Before Reuse
    - (226) If the EnMasking parameter is set and CFG_SHADOWED.msg_mask is enabled,
    the message is masked upon loading into the Keccak core using the internal entropy
    generator. Security Primitives and Cryptography Issues - (1205) OTP Controller
    The otp_lc_data_o.secrets_valid signal is a multibit valid signal that is set
    to lc_ctrl_pkg::On if the SECRET2 partition containing the root keys has been
    locked with a digest. Improper Prevention of Lock Bit Modification - (1231) Read
    transactions through the CSR window will error out if they are out of bounds,
    or if read access is locked. Improper Access Control for Register Interface -
    (1262)
  prefs: []
  type: TYPE_NORMAL
- en: 'All of our experiments are run on a server consisting of 40 CPUs of 64-bit
    Intel(R) Xeon(R) E5-2698 v4 @ 2.20GHz. Our NSPG framework is implemented in Python.
    We intend to release our framework in GitHub soon, for use by other researchers.
    The entire SoC documentation comprises of 33 IP design specifications, with 10865
    sentences. Each IP design documentation demonstrates information on register descriptions,
    functionalities, and operation processes, including the security features for
    various modules, that will be used for evaluating NSPG [[7](#bib.bib7)]. Among
    these, the contents of the operational processes or behaviors can be transformed
    into security properties, while the others are treated as non-properties. In the
    following subsections, we will evaluate each extracted sentence from five unseen
    IP documents and identify whether they can be transformed into security properties.
    Moreover, we will utilize these security properties to search for potential violations
    in relevant hardware IPs. Since the list of registers in SoC design is available
    to us, we craft the detailed security properties from the IP security specification
    and checklist of the OpenTitan SoC registers. The verification of SoC is based
    on the threat model and security objectives, as described in Section [IV-B](#S4.SS2
    "IV-B Threat Model ‣ IV OpenTitan SoC and Threat Model ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs") and [IV-C](#S4.SS3 "IV-C Security Objectives
    and Features ‣ IV OpenTitan SoC and Threat Model ‣ Unlocking Hardware Security
    Assurance: The Potential of LLMs"), respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: V-B NSPG Framework Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, NSPG processes each text file consisting of sentences in the design
    documentation. It filters out any sentence having less than 10 words, since they
    usually do not contain enough information about operation behaviors. The rest
    of the sentences will be parsed through the trained HS-BERT sequence classification
    model discussed in Section [III](#S3 "III Can Leveraging Large Language Models
    Foster Hardware Security Assurance? ‣ Unlocking Hardware Security Assurance: The
    Potential of LLMs"), and the extracted sentences from each IP document will be
    listed in property text files. As shown in Table [VI](#S5.T6 "TABLE VI ‣ V-A Experimental
    Setup ‣ V Experiments ‣ Unlocking Hardware Security Assurance: The Potential of
    LLMs"), 1723 sentences are processed, and 344 sentences are extracted as potential
    security properties. Overall, 326 sentences (94% of the 347 extracted sentences)
    can be utilized to generate security properties for design validation. We compare
    the generated security properties with the test cases listed in the Design Verification
    (DV) documentation, which describes all the test cases and IP operations needed
    to be checked by the SoC designer. While 268 of our generated security properties
    are covered in DV, 58 properties are not covered in the test cases, which clearly
    demonstrate that NSPG is adept at accounting for specifications that are not covered
    in DV. This shows that our proposed framework, NSPG, is able to efficiently identify
    security properties in the documents. Next, we use these newly generated security
    properties to verify the bugs.'
  prefs: []
  type: TYPE_NORMAL
- en: V-C Effectiveness in Discovering Violations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TABLE VIII: Eight bugs found in Key Manager, LC controller, HMAC, KMAC, and
    OTP memory controller, the violated security objectives, CWE, CVSS, and security
    impacts.'
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability No. Module Sec Obj Violated CWE Category CVSS [[6](#bib.bib6)]
    Security Impact Bug 1 - Secret key is not wiped under a invalid state. Key Manager
    Device Integrity Sensitive Information in Resource Not Removed Before Reuse -
    (226) 3.3 Information Leakage Bug 2 - Secret key is not wiped during the operation
    state. Key Manager Device Integrity Sensitive Information Not Removed Before Reuse
    - (226) 4.4 Information Leakage Bug 3 - JTAG does not support bus integrity checks.
    LC Controller Device Integrity Improper Protection for Outbound Error Messages
    and Alert Signals - (1320) 4 Unexpected Behavior Bug 4 - The message byte order
    conversion is not operational. HMAC Device Integrity Expected Behavior Violation
    - (440) 3.1 Unexpected Behavior Bug 5 - Digest is not cleared when SHA is disabled.
    HMAC Device Integrity Sensitive Information in Resource Not Removed Before Reuse
    - (226) 4.8 Information Leakage Bug 6 - Key is not written with randomly generated
    value. HMAC Exploits from Software Sensitive Information in Resource Not Removed
    Before Reuse - (226) 2.8 Unprivileged Access Bug 7 - Software does not provide
    the key in masked form. KMAC Exploits from Software Security Primitives and Cryptography
    Issues - (1205) 4.2 Information Leakage Bug 8 - Lock control signal is bypassed
    with fault instruction. OTP Controller Unprivileged Code Improper Access Control
    for Register Interface - (1262) 5.8 Unprivileged Access
  prefs: []
  type: TYPE_NORMAL
- en: 'The extracted security properties provide us with essential information to
    construct various constraints when generating test cases for vulnerable IP designs.
    We choose to transfer the properties into SystemVerilog assertion format. Figure [7](#S5.F7
    "Figure 7 ‣ V-C Effectiveness in Discovering Violations ‣ V Experiments ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs") shows an example of the process,
    transforming an extracted property into an assertion that can be applied for verification.
    It breaks the conjunctions of the sentence to identify the fragments of the operation
    relation. The nouns are transformed into RTL-level registers based on the IP register
    listing, and the verbs are converted into operators. Finally, the fragments rejoin
    to present a constraint for operation behavior, which can be asserted into the
    original RTL. Table [VII](#S5.T7 "TABLE VII ‣ V-A Experimental Setup ‣ V Experiments
    ‣ Unlocking Hardware Security Assurance: The Potential of LLMs") outlines a few
    security properties generated by our framework and their corresponding CWE categories,
    from which we discover some vulnerabilities in the design. By creating constraints
    based on the acquired security properties and generating test cases on the design,
    we are able to detect eight vulnerabilities in the buggy IP designs. Table [VIII](#S5.T8
    "TABLE VIII ‣ V-C Effectiveness in Discovering Violations ‣ V Experiments ‣ Unlocking
    Hardware Security Assurance: The Potential of LLMs") demonstrates the details
    of eight bugs we identified from the extracted security properties. It presents
    the security objectives violated, CVSS score [[6](#bib.bib6)] (ranges from 0 to
    10, a higher score refers to more severe vulnerabilities), CWE categories, and
    the potential security impacts on the system. We will discuss these vulnerabilities
    and their impacts on the system as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ad1ec0a18cfe7d4b1ffc4daa0680760b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Process of transforming a security property into an assertion. The
    first row breaks the sentences into relation conjunctions. The second row identifies
    the design components and the operations. The third row converts the texts into
    registers and operators. The forth row reconstructs them into the constraint for
    verification.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A. Key Manager: The key manager implements the root key operation for the system
    and allows it to protect critical assets from malicious software. Two vulnerabilities
    are found in this IP: (1) The security property requires the key manager to wipe
    internal storage when it is in an invalid state. However, the implementation reverses
    the operation and wipes the key under a valid state. (2) It is required to continuously
    wipe the secret key with entropy during the operation state. However, the implementation
    does not replace the key registers, leaving sensitive information vulnerable.
    These vulnerabilities could potentially impact the confidentiality of the secret
    key, allowing the attacker to reveal the key information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'B. LC Controller: The life cycle (LC) controller controls the peripheral interactions
    on the chip interconnect bus. The security property requires the signal fatal_bus_integ_error_q
    to be set to one, when any bus integrity fault is detected. However, the boundary-scan
    test controller (JTAG) Test Access Port (TAP) does not provide a bus integrity
    check signal, which might cause integrity check failure in the life cycle controller
    and unexpected behavior in the system.'
  prefs: []
  type: TYPE_NORMAL
- en: 'C. HMAC: The HMAC module implements a SHA-256 hash-based authentication module
    to ensure the integrity of any incoming message and its encryption code from the
    secret key. Three security bugs are found in this IP: (1) The first bug occurs
    when the software wants to convert the message byte order. It is required to set
    CFG.endian_swap register to one. However, the implementation reverses the operation,
    making the IP convert the message, when CFG.endian_swap is zero. This will cause
    unexpected operations due to incorrect instructions for converting messages. (2)
    The second bug occurs when the SHA engine is disabled. Although it is required
    to clear the digest in HMAC, no implementation is built to satisfy this property.
    (3) The third bug involves key randomization when the CPU writes values to the
    secret key. The key is required to be wiped with randomly generated value; however,
    no implementation is addressed for this property.'
  prefs: []
  type: TYPE_NORMAL
- en: 'D. KMAC: The KMAC module is a Keccak-based message authentication code generator
    used to verify the incoming messages. It utilizes masked permutations to prevent
    side-channel attacks. The security property requires the software to provide the
    key in masked form when the EnMasking parameter is not set and the SwKeyMasked
    parameter is set. However, this mechanism is not correctly implemented, leaving
    the software with an unmasked key. This could cause key leakage through an unprivileged
    software adversary.'
  prefs: []
  type: TYPE_NORMAL
- en: 'E. OTP Memory Controller: The OTP memory controller is a module that provides
    a device with a one-time programming functionality. The security property only
    allows the IP to respond and write into the readout register when the lock control
    is not active. However, the IP is implemented with a mechanism that allows it
    to bypass the read-and-write lock control signal every four clock cycles. This
    will cause unpredictable behavior of the controller and allow the software adversary
    to attack the integrity of the module.'
  prefs: []
  type: TYPE_NORMAL
- en: In summary, we have discovered eight vulnerabilities in five hardware IP designs
    from the 326 security properties we generated using NSPG. These vulnerabilities
    may cause information leakage, unexpected behavior, and unprivileged accesses
    in these IPs. It proves that these extracted security properties can provide valuable
    information to generate constraints for the hardware verification process.
  prefs: []
  type: TYPE_NORMAL
- en: VI Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A. False Positives and False Negatives: We will show some examples of the false
    positives and false negatives that were encountered, represented as FP and FN,
    respectively. A few of the FPs are short sentences that furnish equations or incomplete
    register interactions such as “How often FSM wakes up from ADC PD mode to take
    a sample, measured in always on clock cycles.” Although the framework is able
    to identify the operations, there is not enough information in the sentence to
    construct a complete security property. In contrast, FNs usually involve the structure
    of the sentences such as “To this end, the processor has to set the SIDELOAD bit
    in CTRL_SHADOWED to 1”. Despite including two registers, the operation does not
    describe their behaviors separately, making it difficult for NSPG to classify
    them. Overall, the FP rate is 4%, and FN rate is 15% for the five IP documents.
    It should be mentioned that NSPG is the first work that utilizes NLP for hardware
    security property generation, and there are potentials for further improving its
    performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'B. Compared to text classification models: We also explore standard text classification
    models such as TF-IDF and Bag-of-Words trained with ${\mathcal{}{D}}_{cls}$. Among
    them, TF-IDF achieved 70% accuracy for OpenTitan, and 61% accuracy for RISC-V,
    Bag-of-Words achieved 51% accuracy for OpenTitan, and 53.12% for RISC-V. Hence,
    we can conclude that HS-BERT is significantly more effective than standard text
    classifiers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'C. Compared to ChatGPT: In this section, we compare NSPG against ChatGPT [[4](#bib.bib4)],
    a popular chatbot based on the OpenAI Generative Pre-trained Transformer (GPT)-3.5
    language model that is adept at generating human-like text responses to any input
    in a conversational context [[44](#bib.bib44)]. We investigated if such a state-of-the-art
    off-the-shelf general LLM can outperform a small domain-specific BERT model in
    solving the security property identification task. We evaluated their performances
    on a reduced dataset of 50 sentences, which contained 25 property-related and
    25 non-property-related sentences (the dataset size was necessitated by resource
    limitations, since GPT-3.5 is not publicly available as an open-source model).
    ChatGPT’s evaluation resulted in numerous false positives and false negatives,
    with only 35 sentences correctly classified, many of which were unsuitable for
    SoC security verification. For example, sentences like “The ADC is continually
    powered on” and “In addition, they could potentially also be extracted when being
    transferred over the TL-UL bus interface” were incorrectly classified as properties.
    Conversely, sentences such as “For encryption or if the mode is set to CFB, OFB,
    or CTR, there is no such initial delay upon changing the key” and “The AES unit
    cannot recover from such an error and needs to be reset” were labeled as non-properties.
    The accuracy, recall and F1-score obtained by the ChatGPT model were 68%, 88%
    and 73%, respectively. On the contrary, NSPG outperforms ChatGPT by identifying
    all 25 property-related sentences, thereby furnishing an accuracy, recall, and
    F-1 score of 100%, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: VII Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section presents prior related work proposed for hardware security property
    generation and verification.
  prefs: []
  type: TYPE_NORMAL
- en: VII-A Hardware Security Verification Approaches
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Information Flow Tracking (IFT) improves hardware security by identifying malicious
    input interfaces, regulating the use of counterfeit information, and verifying
    hardware operation flows [[47](#bib.bib47), [48](#bib.bib48), [42](#bib.bib42),
    [13](#bib.bib13), [43](#bib.bib43), [14](#bib.bib14)]. This approach has been
    demonstrated to effectively detect malicious attacks with security property-generated
    constraints. Theorem proving utilizes a language, VeriCoq, to automate the transformation
    of RTL into Coq theorem. This approach validates the converted language through
    the Proof-Carrying Hardware Intellectual Property (PCHIP) framework and ensures
    the robustness of a third-party IP with formal proofs of security properties [[36](#bib.bib36),
    [18](#bib.bib18)]. Assertion-based security verification employs formal and simulation-based
    methods to detect violations against assertions included in RTL designs [[19](#bib.bib19),
    [30](#bib.bib30)]. Property-specific information flow utilizes property specifications
    to generate information flow models that are catered to the pre-defined security
    properties. The models are verified by conducting a property-specific search and
    identifying security-critical paths [[31](#bib.bib31)]. Directed test generation
    has been developed to address state space explosion. Existing research, such as [[11](#bib.bib11),
    [37](#bib.bib37)], utilize control flow graphs on RTL models to ensure functional
    correctness. Symbolic techniques incorporating security properties and concolic
    testing can detect violations in RTL and conclusively verify designs [[39](#bib.bib39),
    [50](#bib.bib50)].
  prefs: []
  type: TYPE_NORMAL
- en: VII-B Property Generation Techniques
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A recent approach, Isadora, creates information flow specifications of core
    designs and combines IFT and security specifications [[22](#bib.bib22)]. It requires
    conclusive testbenches and simulation traces for property generation. Therefore,
    it might be not scalable when applied to more complex SoCs. PCHIP introduces the
    concept of theorem generation functions, which enables the generation of security
    theorems independent from the information flow traces, thereby assisting in the
    development of data secrecy properties [[33](#bib.bib33), [17](#bib.bib17)]. However,
    PCHIP is only limited to cryptographic circuits. SCIFinder is a recent approach
    that generates Security-Critical Invariants (SCI) for design verification [[51](#bib.bib51)].
    This approach only studies a limited size of security properties and is not scalable
    when applied to property generation on more complex processors. Comments-based
    property generation is an NLP-based translation technique was developed, which
    automatically generates Computation Tree Logic (CTL) verification properties from
    Hardware Description Language (HDL) code comments [[29](#bib.bib29)]. In comparison,
    NSPG uses a BERT model to automatically identify and generate new security property-related
    sentences from the documentation. Furthermore, [[29](#bib.bib29)] has been evaluated
    only on small *well-commented* benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: VIII Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper presents NSPG, the first NLP-based automated hardware security property
    generation method, that utilizes SoC documentation to extract security properties.
    NSPG includes a novel hardware security-specific language model (HS-BERT) and
    a data modification technique to improve automated security property generation.
    Our framework is evaluated on OpenTitan SoC documentation, resulting in 326 correctly
    extracted security properties from 1723 sentences for five hardware IPs. Furthermore,
    these security properties help discover eight vulnerabilities in a buggy design,
    which proves the effectiveness of the generated security properties. Additionally,
    our evaluations prove that NSPG furnishes better performance than ChatGPT, a popular
    chatbot system, for SoC security property generation. With the advent of LLMs,
    we envision that NSPG will lay the foundation for utilizing NLP approaches in
    SoC design and verification.
  prefs: []
  type: TYPE_NORMAL
- en: IX Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This research is partially supported by Technology Innovation Institute, Abu
    Dhabi, United Arab Emirates.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] “Cwe - cwe-1194: Hardware design (4.0),” [https://cwe.mitre.org/data/definitions/1194.html](https://cwe.mitre.org/data/definitions/1194.html),
    (Accessed on 05/15/2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] “Github - shal/cppdoc: Powerful documentation generation tool for c++,”
    [https://github.com/shal/cppdoc](https://github.com/shal/cppdoc), (Accessed on
    01/12/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] “Hack@dac22 – hack@event hw ctf,” [https://hackatevent.org/hackdac22/](https://hackatevent.org/hackdac22/),
    (Accessed on 01/26/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] “Introducing chatgpt,” [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt),
    (Accessed on 04/12/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] “Javadoc tool home page,” [https://www.oracle.com/java/technologies/javase/javadoc-tool.html](https://www.oracle.com/java/technologies/javase/javadoc-tool.html),
    (Accessed on 01/12/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] “NVD - CVSS v3 calculator,” [https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator](https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator),
    (Accessed on 02/05/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] “Opentitan — opentitan documentation,” [https://docs.opentitan.org/](https://docs.opentitan.org/),
    (Accessed on 01/26/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] “Questa Secure Check - Exhaustive Verification of Secure Paths — Siemens
    Software,” [https://eda.sw.siemens.com/en-US/ic/questa/formal-verification/secure-check/](https://eda.sw.siemens.com/en-US/ic/questa/formal-verification/secure-check/),
    (Accessed on 02/05/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] “Risc-v instruction set specifications — riscv-isa-pages documentation,”
    [https://msyksphinz-self.github.io/riscv-isadoc/html/index.html](https://msyksphinz-self.github.io/riscv-isadoc/html/index.html),
    (Accessed on 01/27/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] “Tortuga Logic — Synopsys,” [https://www.synopsys.com/dw/ipdir.php?ds=arc-access-member-tortuga-logic](https://www.synopsys.com/dw/ipdir.php?ds=arc-access-member-tortuga-logic),
    (Accessed on 02/05/2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] A. Ahmed, F. Farahmandi, and P. Mishra, “Directed test generation using
    concolic testing on rtl models,” in *2018 Design, Automation & Test in Europe
    Conference & Exhibition (DATE)*.   IEEE, 2018, pp. 1538–1543.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] W. Ammar, D. Groeneveld, C. Bhagavatula, I. Beltagy, M. Crawford, D. Downey,
    J. Dunkelberger, A. Elgohary, S. Feldman, V. Ha *et al.*, “Construction of the
    literature graph in semantic scholar,” *arXiv preprint arXiv:1805.02262*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] A. Ardeshiricham, W. Hu, J. Marxen, and R. Kastner, “Register transfer
    level information flow tracking for provably secure hardware design,” in *Design,
    Automation & Test in Europe Conference & Exhibition (DATE), 2017*.   IEEE, 2017,
    pp. 1691–1696.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] A. Ardeshiricham, Y. Takashima, S. Gao, and R. Kastner, “Verisketch: Synthesizing
    secure hardware designs with timing-sensitive information flow properties,” in
    *Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications
    Security*, 2019, pp. 1623–1638.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] I. Beltagy, K. Lo, and A. Cohan, “Scibert: A pretrained language model
    for scientific text,” *arXiv preprint arXiv:1903.10676*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] B. Bentley, “Validating the intel pentium 4 microprocessor,” in *Proceedings
    of the 38th annual Design Automation Conference*, 2001, pp. 244–248.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] M.-M. Bidmeshki, X. Guo, R. G. Dutta, Y. Jin, and Y. Makris, “Data secrecy
    protection through information flow tracking in proof-carrying hardware ip—part
    ii: Framework automation,” *IEEE Transactions on Information Forensics and Security*,
    vol. 12, no. 10, pp. 2430–2443, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] M.-M. Bidmeshki and Y. Makris, “Vericoq: A verilog-to-coq converter for
    proof-carrying hardware automation,” in *ISCAS*.   IEEE, 2015, pp. 29–32.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] M. Bilzor, T. Huffmire, C. Irvine, and T. Levin, “Evaluating security
    requirements in a general-purpose processor by combining assertion checkers with
    code coverage,” in *2012 IEEE International Symposium on Hardware-Oriented Security
    and Trust*.   IEEE, 2012, pp. 49–54.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Cadence, “Jaspergold formal verification platform (apps),” [https://www.cadence.com/en_US/home/tools/system-design-and-verification/formal-and-static-verification/jasper-gold-verification-platform.html](https://www.cadence.com/en_US/home/tools/system-design-and-verification/formal-and-static-verification/jasper-gold-verification-platform.html),
    (Accessed on 05/15/2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] G. Dessouky, D. Gens, P. Haney, G. Persyn, A. Kanuparthi, H. Khattri,
    J. M. Fung, A.-R. Sadeghi, and J. Rajendran, “$\{$ hardware bugs,” in *28th USENIX
    Security Symposium (USENIX Security 19)*, 2019, pp. 213–230.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] C. Deutschbein, A. Meza, F. Restuccia, R. Kastner, and C. Sturton, “Isadora:
    Automated information flow property generation for hardware designs,” in *Proceedings
    of the 5th Workshop on Attacks and Solutions in Hardware Security*, 2021, pp.
    5–15.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
    of deep bidirectional transformers for language understanding,” *arXiv preprint
    arXiv:1810.04805*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] N. Farzana, F. Rahman, M. Tehranipoor, and F. Farahmandi, “Soc security
    verification using property checking,” in *2019 IEEE International Test Conference
    (ITC)*.   IEEE, 2019, pp. 1–10.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] E. A. Felix and S. P. Lee, “Systematic literature review of preprocessing
    techniques for imbalanced data,” *IET Software*, vol. 13, no. 6, pp. 479–496,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] S. Y. Feng, V. Gangal, J. Wei, S. Chandar, S. Vosoughi, T. Mitamura, and
    E. Hovy, “A survey of data augmentation approaches for nlp,” *arXiv preprint arXiv:2105.03075*,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] A. Gillioz, J. Casas, E. Mugellini, and O. Abou Khaled, “Overview of the
    transformer-based models for nlp tasks,” in *2020 15th Conference on Computer
    Science and Information Systems (FedCSIS)*.   IEEE, 2020, pp. 179–183.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] S. Gupta and A. Gupta, “A set of measures designed to identify overlapped
    instances in software defect prediction,” *Computing*, vol. 99, no. 9, pp. 889–914,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] C. B. Harris and I. G. Harris, “Generating formal hardware verification
    properties from natural language documentation,” in *Proceedings of the 2015 IEEE
    9th International Conference on Semantic Computing (IEEE ICSC 2015)*.   IEEE,
    2015, pp. 49–56.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] M. Hicks, C. Sturton, S. T. King, and J. M. Smith, “Specs: A lightweight
    runtime mechanism for protecting software from security-critical processor bugs,”
    in *Proceedings of the Twentieth International Conference on Architectural Support
    for Programming Languages and Operating Systems*, 2015, pp. 517–529.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] W. Hu, A. Ardeshiricham, M. S. Gobulukoglu, X. Wang, and R. Kastner, “Property
    specific information flow analysis for hardware security verification,” in *2018
    IEEE/ACM International Conference on Computer-Aided Design (ICCAD)*.   IEEE, 2018,
    pp. 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] T. Iliou, C.-N. Anagnostopoulos, M. Nerantzaki, and G. Anastassopoulos,
    “A novel machine learning data preprocessing method for enhancing classification
    algorithms performance,” in *Proceedings of the 16th International Conference
    on Engineering Applications of Neural Networks (INNS)*, 2015, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Y. Jin, X. Guo, R. G. Dutta, M.-M. Bidmeshki, and Y. Makris, “Data secrecy
    protection through information flow tracking in proof-carrying hardware ip—part
    i: Framework fundamentals,” *IEEE Transactions on Information Forensics and Security*,
    vol. 12, no. 10, pp. 2416–2429, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] B. Krawczyk, M. Woźniak, and G. Schaefer, “Cost-sensitive decision tree
    ensembles for effective imbalanced classification,” *Applied Soft Computing*,
    vol. 14, pp. 554–562, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] J. Lee, W. Yoon, S. Kim, D. Kim, S. Kim, C. H. So, and J. Kang, “Biobert:
    a pre-trained biomedical language representation model for biomedical text mining,”
    *Bioinformatics*, vol. 36, no. 4, pp. 1234–1240, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] E. Love, Y. Jin, and Y. Makris, “Proof-carrying hardware intellectual
    property: A pathway to trusted module acquisition,” *IEEE Transactions on Information
    Forensics and Security*, vol. 7, no. 1, pp. 25–40, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Y. Lyu and P. Mishra, “Automated test generation for activation of assertions
    in rtl models,” in *ASP-DAC*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] A. Maña and G. Pujol, “Towards formal specification of abstract security
    properties,” in *2008 Third International Conference on Availability, Reliability
    and Security*.   IEEE, 2008, pp. 80–87.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] X. Meng, S. Kundu, A. K. Kanuparthi, and K. Basu, “Rtl-contest: Concolic
    testing on rtl for detecting security vulnerabilities,” *IEEE Transactions on
    Computer-Aided Design of Integrated Circuits and Systems*, vol. 41, no. 3, pp.
    466–477, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] G. A. Miller, “Wordnet: a lexical database for english,” *Communications
    of the ACM*, vol. 38, no. 11, pp. 39–41, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] R. C. Moore and W. Lewis, “Intelligent selection of language model training
    data,” in *Proceedings of the ACL 2010 conference short papers*, 2010, pp. 220–224.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] J. Oberg, W. Hu, A. Irturk, M. Tiwari, T. Sherwood, and R. Kastner, “Theoretical
    analysis of gate level information flow tracking,” in *Proceedings of the 47th
    Design Automation Conference*, 2010, pp. 244–247.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] M. Qin, X. Wang, B. Mao, D. Mu, and W. Hu, “A formal model for proving
    hardware timing properties and identifying timing channels,” *Integration*, vol. 72,
    pp. 123–133, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] J. Schulman, B. Zoph, C. Kim, J. Hilton, J. Menick, J. Weng, J. F. C.
    Uribe, L. Fedus, L. Metz, M. Pokorny *et al.*, “Chatgpt: Optimizing language models
    for dialogue,” *OpenAI blog*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] R. Sennrich, B. Haddow, and A. Birch, “Neural machine translation of rare
    words with subword units,” in *Proceedings of the 54th Annual Meeting of the Association
    for Computational Linguistics (Volume 1: Long Papers)*.   Berlin, Germany: Association
    for Computational Linguistics, Aug. 2016, pp. 1715–1725\. [Online]. Available:
    [https://aclanthology.org/P16-1162](https://aclanthology.org/P16-1162)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] J. Stefanowski, “Dealing with data difficulty factors while learning from
    imbalanced data,” in *Challenges in computational statistics and data mining*.   Springer,
    2016, pp. 333–363.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas, “Secure program execution
    via dynamic information flow tracking,” *ACM Sigplan Notices*, vol. 39, no. 11,
    pp. 85–96, 2004.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] M. Tiwari, H. M. Wassel, B. Mazloom, S. Mysore, F. T. Chong, and T. Sherwood,
    “Complete information flow tracking from the gates up,” in *Proceedings of the
    14th international conference on Architectural support for programming languages
    and operating systems*, 2009, pp. 109–120.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey, M. Krikun,
    Y. Cao, Q. Gao, K. Macherey *et al.*, “Google’s neural machine translation system:
    Bridging the gap between human and machine translation,” *arXiv preprint arXiv:1609.08144*,
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] R. Zhang, C. Deutschbein, P. Huang, and C. Sturton, “End-to-end automated
    exploit generation for validating the security of processor designs,” in *2018
    51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)*.   IEEE,
    2018, pp. 815–827.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] R. Zhang, N. Stanley, C. Griggs, A. Chi, and C. Sturton, “Identifying
    security critical properties for the dynamic verification of a processor,” *ACM
    SIGARCH Computer Architecture News*, vol. 45, no. 1, pp. 541–554, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
