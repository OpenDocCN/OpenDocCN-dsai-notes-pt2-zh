# 【Andrej Karpathy：从零开始构建 GPT 系列】 - P6：p6 Building makemore Part 5： Building a WaveNet - 加加zero - BV11yHXeuE9d

大家好，今天我们将继续我们的实现，让我们的最喜欢的角色级别语言模型更加完善。

![](img/c9be2506944533fbac16b5c8db99ea71_1.png)

你现在会发现我身后的背景有所不同，那是因为我正在京都，非常棒，所以我在这里的酒店房间里，在过去的几堂课中，我们构建到了这种架构，那就是多层感知器，角色级别语言模型，所以我们看到它接收三个之前的字符。

并试图预测序列中的第四个字符，使用一个非常简单的多层感知器，使用包含十个新连接的隐藏层神经元，我们现在想在这堂课中做，我想复杂化这个架构，特别是我们想要处理序列中更多的字符，作为输入，不仅仅是三个。

此外，我们不仅想要全部输入到一个隐藏层，因为那样会压缩信息太快，相反，我们希望建立一个更深的模型，逐步融合这些信息，以便对它们下一个字符的猜测，因此，当我们使这个架构更复杂时。

我们实际上将到达看起来非常像波形网的东西。

![](img/c9be2506944533fbac16b5c8db99ea71_3.png)

所以这篇论文是由2016年拒绝发表的。

![](img/c9be2506944533fbac16b5c8db99ea71_5.png)

它也是一个语言模型。

![](img/c9be2506944533fbac16b5c8db99ea71_7.png)

基本上，但它试图预测音频序列，而不是角色级别序列或词级别序列。

![](img/c9be2506944533fbac16b5c8db99ea71_9.png)

但本质上，建模设置是相同的。

![](img/c9be2506944533fbac16b5c8db99ea71_11.png)

它是自回归模型，并试图预测序列中的下一个字符，而且架构实际上采取了这种有趣的层次化，一种方法来预测序列中的下一个字符，嗯，用这种树状结构，这就是架构。



![](img/c9be2506944533fbac16b5c8db99ea71_13.png)

我们将在视频中实现它，所以让我们开始。

![](img/c9be2506944533fbac16b5c8db99ea71_15.png)

所以第五部分的代码库与第三部分结束时的代码库非常相似，记得第三部分是手动后向传播的练习，这是一种 aside。



![](img/c9be2506944533fbac16b5c8db99ea71_17.png)

所以我们回到第三部分，复制粘贴其中的部分，这就是我们第五部分的起始代码，我基本上没有做太多的更改，所以很多这部分应该对你来说很熟悉，如果你已经完成了第三部分。



![](img/c9be2506944533fbac16b5c8db99ea71_19.png)

所以特别是，我们简要地导入，我们读取我们的单词数据集。

![](img/c9be2506944533fbac16b5c8db99ea71_21.png)

并将单词集处理为单独的示例。

![](img/c9be2506944533fbac16b5c8db99ea71_23.png)

而且这个数据生成代码没有改变，基本上我们有大量的例子，特别是，我们有十八万两千个例子，是三个字符试图预测第四个字符的，我们已将所有这些单词分解为，给定三个字符预测第四个字符，所以这是我们的数据集。



![](img/c9be2506944533fbac16b5c8db99ea71_25.png)

这就是我们现在想让神经网络做的事情，在第三部分，我们开始围绕这些层模块开发我们的代码，一，那些是，例如，一个线性类，我们正在做这个，因为我们想要考虑这些模块作为构建块，就像乐高积木块。

我们可以将这些砖块堆叠起来，就像堆叠神经网络一样，我们可以在这些层之间输入数据，并将它们堆叠起来，形成某种图，我们还开发了这些层，以便它们具有API和签名。



![](img/c9be2506944533fbac16b5c8db99ea71_27.png)

与PyTorch中找到的相似，所以我们有torch。nn，而且它具有所有必要的层构建块，你在实践中会使用它们，我们正在开发所有这些，以模仿这些的api，例如，我们有线性。

所以还会有一个torch和n点线性。

![](img/c9be2506944533fbac16b5c8db99ea71_29.png)

它的签名将与我们的签名非常相似，至于功能，我知道它们将非常相似。

![](img/c9be2506944533fbac16b5c8db99ea71_31.png)

所以我们有带有浴室的线性层，一个d层和一个我们之前开发的10h层。

![](img/c9be2506944533fbac16b5c8db99ea71_33.png)

嗯。

![](img/c9be2506944533fbac16b5c8db99ea71_35.png)

线性仅在模块的前向传递中进行矩阵乘法，批归一化。

![](img/c9be2506944533fbac16b5c8db99ea71_37.png)

当然，这是我们在前一节课中开发的疯狂层，它疯狂的地方在于，有很多，首先，它具有在外面的反向传播之外训练的运行均值和方差，它们使用指数移动平均在这个层内进行训练。



![](img/c9be2506944533fbac16b5c8db99ea71_39.png)

当我们调用前向传播时，此外，还有训练标志，因为巴斯特罗姆的行为在训练时间和评估时间有所不同，因此突然我们必须非常小心，确保批归一化处于正确的状态，它是处于评估状态还是训练状态。

所以这是现在需要跟踪的一些东西，有时它会引入错误，因为你忘记把它放入正确的模式，最后我们看到批归一化耦合了统计数据，或批中例子的激活，所以我们通常认为批只是效率的事情，嗯。

但是现在我们正在将计算跨批元素耦合，这是为了控制激活统计数据的目的。

![](img/c9be2506944533fbac16b5c8db99ea71_41.png)

正如我们在前一个视频中看到的，所以这是一个非常奇怪的层。

![](img/c9be2506944533fbac16b5c8db99ea71_43.png)

至少对于许多错误来说，部分地，例如，因为你需要在训练和评估阶段等处调节。

![](img/c9be2506944533fbac16b5c8db99ea71_45.png)

嗯在，此外，例如，你需要等待，嗯，均值和方差稳定下来，并实际上达到稳定状态。

![](img/c9be2506944533fbac16b5c8db99ea71_47.png)

所以嗯，你需要确保基本上这个层中有状态。

![](img/c9be2506944533fbac16b5c8db99ea71_49.png)

状态是有害的，嗯，现在，我引出了生成器对象。

![](img/c9be2506944533fbac16b5c8db99ea71_51.png)

以前，我们 had 生成器等于 g 等等。

![](img/c9be2506944533fbac16b5c8db99ea71_53.png)

在这些层中，我放弃了这个，更喜欢在这里外初始化 torch rng。

![](img/c9be2506944533fbac16b5c8db99ea71_55.png)

只在全球使用一次，只是为了简单。

![](img/c9be2506944533fbac16b5c8db99ea71_57.png)

然后，我们在这里开始构建一些神经网络元素，这应该看起来很熟悉，我们有我们的嵌入表 c，然后，我们有一个层的列表，它是线性馈送到批归一化馈送到 10 h，然后有一个线性输出层，并且其权重被缩放。

所以我们不确信是错误的，在初始化时。

![](img/c9be2506944533fbac16b5c8db99ea71_59.png)

我们看到这大约有十二万个参数，我们告诉 PyTorch 我们的参数梯度。

![](img/c9be2506944533fbac16b5c8db99ea71_61.png)

优化据我所知是相同的。

![](img/c9be2506944533fbac16b5c8db99ea71_63.png)

并且应该看起来很熟悉，这里什么都没改变，嗯，损失函数看起来非常疯狂。

![](img/c9be2506944533fbac16b5c8db99ea71_65.png)

我们可能需要修复这个，这是因为两个批元素太少，所以你可以非常幸运，幸运或不幸在任何一个批元素中。

![](img/c9be2506944533fbac16b5c8db99ea71_67.png)

并且它创建了一个非常厚的损失函数，所以我们要修复它。

![](img/c9be2506944533fbac16b5c8db99ea71_69.png)

很快就要了，当我们想要评估训练的神经网络时，我们需要记住，因为浴室层，需要设置。

![](img/c9be2506944533fbac16b5c8db99ea71_71.png)

所有层训练等于 false，这目前只对浴室层重要。

![](img/c9be2506944533fbac16b5c8db99ea71_73.png)

然后我们评估，我们看到目前我们的验证损失为2。1。0，这相当好，但是嗯。

![](img/c9be2506944533fbac16b5c8db99ea71_75.png)

还有很长的路要走，即使达到2。1。0，我们看到当我们从模型中采样时，我们实际上得到相对命名的结果，这些结果不存在于训练集中，例如，伊文娜横跨一条拉雅。



![](img/c9be2506944533fbac16b5c8db99ea71_77.png)

等等，当然不可能，嗯，并非不合理。

![](img/c9be2506944533fbac16b5c8db99ea71_79.png)

我会说但不会令人惊叹，而且我们还可以将验证损失推得更低，并获取甚至更接近名称的样本。

![](img/c9be2506944533fbac16b5c8db99ea71_81.png)

所以让我们现在改进这个模型。

![](img/c9be2506944533fbac16b5c8db99ea71_83.png)

好的，首先，让我们修复这个图，因为它刺痛我的眼睛，而且我无法再忍受了。

![](img/c9be2506944533fbac16b5c8db99ea71_85.png)

所以最后我记得是Python，Python的浮点数列表。

![](img/c9be2506944533fbac16b5c8db99ea71_87.png)

所以例如，前十个元素看起来像这样，我们现在想做的，基本上，我们需要平均起来，嗯，一些这些值来获得一个更代表的，在路上有一个值，这样做的一种方法是在pytorch中如下所示，如果我创建，例如。

一个包含前十个数字的张量，那么这目前是一个一维数组，但请记住，我可以将这个数组视为二维，所以例如，我可以将其视为一个2x5的数组，这是一个2D张量，现在2x5，你看pytorch做了什么。

那是这个张量的第一行是第一五个元素吗，而第二行是第二个五个元素，我也可以将其视为一个五乘二的例子，然后记住，我也可以使用-1代替这些数字中的一个，然后PyTorch将计算这个数字必须是什么。

以便使元素的数量工作出来，所以这可以像这样或那样，嗯，两者都会工作，当然这不会工作，好的，所以这允许它将一些连续的值分散到行中，所以这非常有帮助，因为现在我们可以做的是第一个。

我们将从浮点数列表创建一个torch tensor，然后我们将其视为它是什么，但我们将把它拉伸成一千个连续元素的行，所以这现在的形状变成了二百乘以一千，每一行都是列表中的一千个连续元素。

所以这非常有帮助，因为现在我们可以沿着行计算平均值，这形状只有二百，所以我们基本上在每个行上计算了平均值，所以plt dot plot的那个应该更好看很多。



![](img/c9be2506944533fbac16b5c8db99ea71_89.png)

所以我们基本上已经取得了很大的进步，然后这里是学习率衰减，在这里我们看到学习率衰减，从系统中减去了大量的能量，并允许我们 settle 在某种优化的本地最小值。



![](img/c9be2506944533fbac16b5c8db99ea71_91.png)

所以这是一张更好的图表。

![](img/c9be2506944533fbac16b5c8db99ea71_93.png)

让我来删除怪兽，我们将使用这个。

![](img/c9be2506944533fbac16b5c8db99ea71_95.png)

从现在开始，接下来，我担心的是，你看，我们的前向传播有点复杂，占用了太多的代码行，特别是在我们组织一些层在layers列表中时，但不是所有的。



![](img/c9be2506944533fbac16b5c8db99ea71_97.png)

嗯，没有理由，特别是在我们还有嵌入表，特别地放置在层之外，此外，这里的查看操作也不在我们的层之外，所以让我们为这些创建层，然后我们可以将这些层添加到我们的列表。

特别是我们需要的两个东西在这里我们有这个嵌入表，我们正在索引在批处理xp中的整数，在内部一个tensor xb中，所以这是嵌入表查找，仅通过索引完成，然后这里我们看到我们有这个查看操作。

如果你记得之前的视频，简单地重新排列字符嵌入并拉伸它们成一行，实际上，那是连接操作，基本上，除了它是免费的。



![](img/c9be2506944533fbac16b5c8db99ea71_99.png)

因为查看在PyTorch中非常便宜，没有复制任何记忆，我们只是重新代表我们如何做那个tensor，所以让我们创建，嗯，嗯，嗯，模块对于这两个操作。



![](img/c9be2506944533fbac16b5c8db99ea71_101.png)

嵌入操作和扁平化操作，所以我实际上只是为了节省时间才写了代码。

![](img/c9be2506944533fbac16b5c8db99ea71_103.png)

所以我们有一个模块嵌入和一个模块展开，并且两者只是在前向传递中简单地执行索引操作，在这里的展开操作，并且这个c现在只会成为一个嵌入模块的自我权重，我正在特别调用这些层，因为它们被称为嵌入和展开。

因为事实证明，它们都实际上存在于PyTorch中。

![](img/c9be2506944533fbac16b5c8db99ea71_105.png)

所以在PyTorch中，我们有n n点嵌入。

![](img/c9be2506944533fbac16b5c8db99ea71_107.png)

它也需要嵌入的数量和嵌入的维度，就像我们这里一样。

![](img/c9be2506944533fbac16b5c8db99ea71_109.png)

但是除此之外，Pytorch还接受许多其他关键字参数，但我们没有使用，对于我们的目的来说，还没有。

![](img/c9be2506944533fbac16b5c8db99ea71_111.png)

并且对于flatten，它也存在于Pytorch中，它还接受其他关键字参数，但我们没有使用，所以我们有一个非常简单的flatten，但是两者都存在于Pytorch中，它们只是稍微更简单，现在。

我们有这些。

![](img/c9be2506944533fbac16b5c8db99ea71_113.png)

我们可以简单地取出，嗯，一些特殊的情况。

![](img/c9be2506944533fbac16b5c8db99ea71_115.png)

嗯，谢谢，所以我们不再使用c，我们只有有一个嵌入，查看大小和n嵌入，然后，嵌入后我们将其展开，所以让我们构建那些模块。



![](img/c9be2506944533fbac16b5c8db99ea71_117.png)

现在我可以删除这个费用，因为我不再需要特殊处理了，因为现在c是嵌入的权重，它位于层中。

![](img/c9be2506944533fbac16b5c8db99ea71_119.png)

所以这应该就能工作了，然后这里我们的前向传播大大简化。

![](img/c9be2506944533fbac16b5c8db99ea71_121.png)

因为我们不需要做这些，现在，在这些层之外，而且他们现在明确地在内部层中，所以我们可以删除那些，但现在要嗯，来启动事情，我们想要这个小x，在开始就是xp，指定输入中这些字符身份的整数张量。

因此这些字符不能直接输入到第一层。

![](img/c9be2506944533fbac16b5c8db99ea71_123.png)

这就应该可以工作，所以让我来这里插入一个断点。

![](img/c9be2506944533fbac16b5c8db99ea71_125.png)

因为我只是想确保这个循环的第一次运行，并且没有错误，所以运行正确。

![](img/c9be2506944533fbac16b5c8db99ea71_127.png)

基本上我们在这里极大地简化了前向传播，好的。

![](img/c9be2506944533fbac16b5c8db99ea71_129.png)

我很抱歉，我改变了我的麦克风，所以希望音频稍微好一点，为了将代码pi torify，我还想做一件事，更进一步的是，我们现在正在裸列表维护所有模块。



![](img/c9be2506944533fbac16b5c8db99ea71_131.png)

我们也可以简化这个，嗯。

![](img/c9be2506944533fbac16b5c8db99ea71_133.png)

因为我们可以引入pi torch容器的概念，所以在torch nn，我们基本上从零开始重建，这里，有容器的概念，这些容器基本上是一种组织层的方式，将它们放入列表或字典中，等等。



![](img/c9be2506944533fbac16b5c8db99ea71_135.png)

特别是序列，维护一个层的列表，它是pytorch中的一个模块类。

![](img/c9be2506944533fbac16b5c8db99ea71_137.png)

它基本上只是将给定的输入传递给所有层。

![](img/c9be2506944533fbac16b5c8db99ea71_139.png)

顺序地，正是我们做的这里，让我们编写我们自己的序列。

![](img/c9be2506944533fbac16b5c8db99ea71_141.png)

我已经在这里写了代码，和序列的代码相当直接，我们传递一个层列表，我们将其保存在这里，然后在前向传递中，给定任何输入，我们只是依次调用所有层并返回结果以参数形式。



![](img/c9be2506944533fbac16b5c8db99ea71_143.png)

它只是所有子模块的参数，我们可以运行这个，我们可以再次大大简化这个。

![](img/c9be2506944533fbac16b5c8db99ea71_145.png)

因为我们不再维护这个裸层的列表，我们现在有一个模型概念，它是一个模块，特别是在所有这些层的序列中。

![](img/c9be2506944533fbac16b5c8db99ea71_147.png)

现在参数只是模型点参数，所以列表推导式现在住在这里。

![](img/c9be2506944533fbac16b5c8db99ea71_149.png)

然后这里我们点击这里。

![](img/c9be2506944533fbac16b5c8db99ea71_151.png)

我们现在在这里做我们以前在这里做的事情，代码再次大大简化，因为我们不再在这里做前向传递，相反，我们只是调用模型在输入数据上，并输入数据，在这里是xb中的整数，我们可以简单地做逻辑，这是我们模型的输出。

只是模型在xb上的调用，然后交叉熵在这里取逻辑和目标，这大大简化了，然后这看起来不错。

![](img/c9be2506944533fbac16b5c8db99ea71_153.png)

所以让我们确保这运行看起来好，现在，实际上我们还在这里有一些工作要做，但我稍后会回来，目前没有更多层，有一个包含层的模型，但是直接访问这些类的属性是不道德的。



![](img/c9be2506944533fbac16b5c8db99ea71_155.png)

所以我们会回来稍后修复这个问题，然后当然，这里也会大大简化，因为逻辑是x所调用的模式。

![](img/c9be2506944533fbac16b5c8db99ea71_157.png)

然后这些喷嘴来到这里，所以我们可以评估训练验证损失。

![](img/c9be2506944533fbac16b5c8db99ea71_159.png)

目前它非常糟糕，因为嗯，我们只是初始化了一个神经网络，然后我们也可以从模型中采样，这也大大简化了，因为我们只是想在上下文中调用模型的输出逻辑，然后这些逻辑进入softmax并得到概率等。



![](img/c9be2506944533fbac16b5c8db99ea71_161.png)

所以我们可以从这个模型中采样。

![](img/c9be2506944533fbac16b5c8db99ea71_163.png)

嗯，我犯了什么错误。

![](img/c9be2506944533fbac16b5c8db99ea71_165.png)

好的，所以我修复了问题，我们现在得到了我们期待的结果，嗯，这是无意义的，因为模型没有训练，因为我们从零重新初始化了它。



![](img/c9be2506944533fbac16b5c8db99ea71_167.png)

问题在于当我将此细胞修改为模型出层的层而不是层时，我没有实际上运行此细胞。

![](img/c9be2506944533fbac16b5c8db99ea71_169.png)

因此我们的神经网络处于训练模式，在这里出现问题的原因是浴室层。

![](img/c9be2506944533fbac16b5c8db99ea71_171.png)

因为浴室层经常喜欢这样做，因为批归一化处于训练模式，在这里我们正在传递输入，这是一个由上下文组成的批，只有一个示例，如果你试图将单个示例传递给批归一化。



![](img/c9be2506944533fbac16b5c8db99ea71_173.png)

它处于训练模式，你将使用输入来估计方差。

![](img/c9be2506944533fbac16b5c8db99ea71_175.png)

单个数字的方差不是数字，因为它是散布的度量。

![](img/c9be2506944533fbac16b5c8db99ea71_177.png)

例如，单一数字5的方差不是数字。

![](img/c9be2506944533fbac16b5c8db99ea71_179.png)

所以基本上浴室层在这里造成了问题，然后它污染了所有进一步的处理。

![](img/c9be2506944533fbac16b5c8db99ea71_181.png)

我们所需要做的就是确保这个运行。

![](img/c9be2506944533fbac16b5c8db99ea71_183.png)

嗯，我们基本上又犯了同样的问题。

![](img/c9be2506944533fbac16b5c8db99ea71_185.png)

我们没有看到损失的问题，我们可以评估损失，但我们得到了错误的结果，因为批归一化处于训练模式。

![](img/c9be2506944533fbac16b5c8db99ea71_187.png)

所以我们仍然得到结果，只是错误的结果，因为它使用批的样本统计。

![](img/c9be2506944533fbac16b5c8db99ea71_189.png)

因此，我们再次看到一个在代码行中引入错误的例子。

![](img/c9be2506944533fbac16b5c8db99ea71_191.png)

嗯，因为我们没有正确维护训练或未训练的状态。

![](img/c9be2506944533fbac16b5c8db99ea71_193.png)

好的，所以我重新运行了一切，这就是我们现在的情况，作为提醒，我们现在的训练损失为2。5，验证损失为2。1。0，因为这些损失非常相似于彼此，我们有一种感觉我们没有过度拟合这个任务太多。

并且我们可以在我们的性能上做出进一步的进步，通过扩大神经网络的规模，使一切都更大更深。

![](img/c9be2506944533fbac16b5c8db99ea71_195.png)

目前，我们正在使用这种架构，其中我们输入一些字符，进入一个隐藏层，然后预测下一个字符，问题在于，我们没有一种直接的方法可以以生产性的方式使这个更大。



![](img/c9be2506944533fbac16b5c8db99ea71_197.png)

我们可能，当然，使用我们的层，就像构建块和材料一样，在这里引入额外的层，并使网络更深，但是，仍然的情况是我们把所有的字符都压入到一个层中，从一开始，即使我们使这个层更大并添加神经元。

它还是像愚蠢一样把所有的信息都压得这么快，在一个步骤中，所以我们想要。

![](img/c9be2506944533fbac16b5c8db99ea71_199.png)

相反，我们希望我们的网络在Wavenet的情况下看起来像这样，所以你看到在，当我们试图预测序列中的下一个字符时，它是前一个字符输入的函数，但不是所有这些不同的字符都被压入到一个层中，然后有一个三明治。

它们被压得慢慢地，嗯，特别是我们取两个字符并将它们融合成类似于大写字母的表示形式，我们这样做于所有这些字符连续，然后，我们取大写字母并融合它们成四个字符级别的块，然后我们再次融合。

所以我们这样做在这个像树一样的层次化方式中，所以我们将之前的上下文信息慢慢地融合到网络中，随着它变深，所以现在我们要实现的架构是，在Wanets的情况下，这是堆叠的稀释因果卷积层的可视化。

这听起来很可怕，但实际上，想法非常简单，而且，它是稀释因果卷积层的事实，实际上是实现细节，使得一切都更快，我们将看到后来的，但是现在让我们只保留这个基本概念，这就是渐进性融合，所以我们想要使网络更深。

在每个级别上，我们只想融合两个连续的元素，两个字符，然后两个大词组，然后两个四词组等等，所以让我们开始吧，所以首先，让我来滚动到我们构建数据集的地方，让我们将块大小从3更改为8。

所以我们将使用8个字符的上下文来预测第9个字符。

![](img/c9be2506944533fbac16b5c8db99ea71_201.png)

所以现在的数据集看起来像这样，我们有更多的上下文输入来预测序列中的任何下一个字符，并且这8个字符现在将被处理为这种树状结构。



![](img/c9be2506944533fbac16b5c8db99ea71_203.png)

如果我们滚动到这里，这里的一切都应该能够工作，所以我们应该能够重新定义网络，你看，参数的数量已经增加了10，000，这是因为块大小增长了。



![](img/c9be2506944533fbac16b5c8db99ea71_205.png)

所以这个第一个线性层非常大，我们的线性层现在将8个字符输入到这个中间层。

![](img/c9be2506944533fbac16b5c8db99ea71_207.png)

所以那里有很多参数，但这应该可以运行，嗯，让我在第一个迭代后立即中断，所以你看到，这运行得非常好。

![](img/c9be2506944533fbac16b5c8db99ea71_209.png)

只是这网络并不太有意义，我们正在太快地压缩太多信息。

![](img/c9be2506944533fbac16b5c8db99ea71_211.png)

所以现在我们来看看如何尝试实现层次化方案。

![](img/c9be2506944533fbac16b5c8db99ea71_213.png)

现在，在深入探讨这里的早期实现之前，我只是好奇要运行它。

![](img/c9be2506944533fbac16b5c8db99ea71_215.png)

并看看我们在基准性能方面的进展，只是懒散地增加上下文长度。

![](img/c9be2506944533fbac16b5c8db99ea71_217.png)

所以我让它运行，我们得到了一个漂亮的损失曲线，然后评估损失。

![](img/c9be2506944533fbac16b5c8db99ea71_219.png)

实际上，仅仅通过增加上下文长度，我们实际上看到了很大的改进，我开始在这里记录一些性能数据，之前我们处于哪里，我们得到了2。1。0的验证损失，现在，只是简单地将上下文长度从3增加到8，给我们带来了2。0。

2的性能，在这里有了很大的改进。

![](img/c9be2506944533fbac16b5c8db99ea71_221.png)

而且当你从模型中采样时，你看，名字确实在质量上也有所提高。

![](img/c9be2506944533fbac16b5c8db99ea71_223.png)

我们可能，当然可以花很多时间在这里调整，调整并使它更大，进一步扩展网络，即使这里的设置非常简单，但我们继续并实现这里，将此视为一个粗略的基础性能模型，但还有许多像未充分利用的优化。

在您现在可能对一些超参数有所了解的方面。

![](img/c9be2506944533fbac16b5c8db99ea71_225.png)

好的，所以现在让我们滚动到顶部并回来，我在这里做的。

![](img/c9be2506944533fbac16b5c8db99ea71_227.png)

我为我们创建了一个小小的草图空间，以便，查看神经网络的前向传播，并检查形状的张量在途中，随着神经网络的前进，所以这里，我只是暂时为了调试，创建了一个批，就说四个例子，所以四个随机整数。

然后我从训练集中挑选出那些行，然后我将其传递给模型，输入xp，现在xp的形状在这里，因为我们只有四个例子是四乘以八，并且这个八现在是当前块大小，检查xp。



![](img/c9be2506944533fbac16b5c8db99ea71_229.png)

我们只是看到有四个例子，每个例子都是xp的行，并且这里有八个字符，这个整数张量只包含那些字符的身份。

![](img/c9be2506944533fbac16b5c8db99ea71_231.png)

嗯，所以我们神经网络的第一个层是嵌入层。

![](img/c9be2506944533fbac16b5c8db99ea71_233.png)

所以传递xp，这个整数张量通过嵌入层。

![](img/c9be2506944533fbac16b5c8db99ea71_235.png)

创建了一个输出是四乘以八乘以十，所以我们的嵌入表对于每个字符都有一个十维向量，我们在尝试学习，所以嵌入层在这里做什么，是它提取每个这些整数的嵌入向量，并将它们组织成一个四乘以八乘以十的张量现在。

所有这些整数都被翻译成十维向量。

![](img/c9be2506944533fbac16b5c8db99ea71_237.png)

现在存在于这个三维张量中现在通过扁平层。

![](img/c9be2506944533fbac16b5c8db99ea71_239.png)

正如您记得的，这做什么，它视为这个张量只是一个四乘以八的张量，那实际上做什么，所有这些十维的嵌入对于所有这些八个字符，最终都被拉伸成一行，看起来有点像连接操作，基本上通过改变张量的视图。

我们现在有一个四乘以八十，在里面是所有的十维，嗯向量只是连续地拼接在一起，然后线性层，当然，通过矩阵乘法，只需要八十个输入就可以创建两百个通道。



![](img/c9be2506944533fbac16b5c8db99ea71_241.png)

到目前为止一切都很好，我想展示一些令人惊讶的东西，让我们看看线性层的内部。

![](img/c9be2506944533fbac16b5c8db99ea71_243.png)

并提醒我们自己它如何工作，在这里的前向传递中，线性层接受输入，X乘以权重，然后可选择添加偏置，这里的权重是二维的，如定义在这里。



![](img/c9be2506944533fbac16b5c8db99ea71_245.png)

偏置是一维的，所以实际上。

![](img/c9be2506944533fbac16b5c8db99ea71_247.png)

从形状的角度来看，线性层内部的情况现在看起来像这样。

![](img/c9be2506944533fbac16b5c8db99ea71_249.png)

我在这里使用随机数字，但我只是在演示形状和发生了什么，基本上，一个四乘以八十的输入进入线性层，被这个八十乘以两百的权重矩阵内部乘以，然后加上两百的偏置，从线性层输出的整个形状是四乘以两百，如我们所见。

顺便说一句，这里会创建一个四乘以两百的张量，然后加上两百，在这里发生了广播，大约有四乘以两百的广播与两百，所以这里一切都正常，所以现在我想展示给你一个令人惊讶的事情，你可能不期待的是，这个被乘法的输入。

实际上不需要是二维的，PyTorch中的矩阵乘法操作非常强大，实际上，你可以实际上传递更高维的数组，张量和一切都正常，例如，这可能是四乘以五乘以八十，在这种情况下，结果将变为四乘以五乘以两百。

你可以在这里添加任何必要的维度，所以实际上，矩阵乘法只作用于最后一个维度，输入张量的其他维度被保留不变，这就是说，嗯，基本上这些，嗯，这些维度在这里都被视为批处理维度，嗯，所以我们可以有多个批处理维度。

然后在所有这些维度上并行地对最后一个维度进行矩阵乘法，这非常方便。

![](img/c9be2506944533fbac16b5c8db99ea71_251.png)

因为我们可以在网络中使用它了，因为记住我们有这八个字符的输入，我们现在不想，嗯，将所有都展平成一个大的一维向量，因为我们不想进行矩阵乘法，想把a立即与权重矩阵相乘，所以我们想要像这样分组。

所以每个连续的两个元素，一、二、三、四、五、六、七、八，所有这些都应该现在，嗯，基本上被展平并乘以权重矩阵，但是所有这些四个组在这里，我们喜欢并行处理，所以，这就有点像我们可以引入的批处理维度，然后。

我们可以并行，基本上，我们可以在单个示例的四个批处理维度中处理所有这些大词组，而且，也可以在实际的批处理维度上，你知道，在我们的例子中，有四个例子。



![](img/c9be2506944533fbac16b5c8db99ea71_253.png)

所以，让我们看看这如何有效地工作，我们现在想要，我们从一个四乘以八十的矩阵中乘以一个由二乘以二百二的向量组成的线性层，这就是发生的，但是我们想要的并不是，我们不想要八十个字符或八十个数字进来。

我们只希望在第一层输入两个字符，并且这两个字符应该融合，换句话说，我们只是想要二十进来对吧，嗯，二十数字会进来，在这里我们不想要一个四乘八十输入到线性层，我们实际上想要这些两组两个数字输入，所以。

而不是四乘以八十，我们要这个变成四乘以四乘以二十，所以，这些都是四个两组，并且每组都是十个维向量，所以，我们现在需要的是改变展平层，所以，它不会上升到四乘以八十，但它会输出四乘以四乘以二十，基本上。

这些嗯，每两个连续的字符都被打包在最后一维上，然后，这个四是第一批维的维度，然后，这个四是第一组的维度，并且这个四就是第二批的维度，指的是这些例子中的每一个内部组，然后这就会像这样相乘。

这就是我们想要达到的目的，所以我们必须改变线性层的输入数量，它不应该期待它不应该期待八十，它应该只期待二十个数字，我们必须改变我们的扁平层，所以它不是完全展开，这个整个例子，它需要创建一个四乘四乘二十。

而不是四乘八十。

![](img/c9be2506944533fbac16b5c8db99ea71_255.png)

那么让我们看看这可以如何实现，基本上现在。

![](img/c9be2506944533fbac16b5c8db99ea71_257.png)

我们有一个输入，它是一个四乘八乘十，输入到展平层，并且目前展平层只是拉伸它。

![](img/c9be2506944533fbac16b5c8db99ea71_259.png)

如果你记得展平的实现。

![](img/c9be2506944533fbac16b5c8db99ea71_261.png)

它取我们的x，并将其视为批处理维度的任何值。

![](img/c9be2506944533fbac16b5c8db99ea71_263.png)

然后负一，所以实际上，它现在所做的是，E点视图的四负一和形状的这个。

![](img/c9be2506944533fbac16b5c8db99ea71_265.png)

当然这是四乘八十，所以这就是目前发生的情况，而我们想要这个变成四乘四乘二十，在这些连续的十维向量中连接，所以你知道在Python中你可以取一个范围的列表，所以我们有数字从零到九。

我们可以像这样索引来获取所有偶部分，我们也可以像这样索引，从一开始，步长为二来获取所有奇部分，所以这是一种实现方式，"这将是这样的"。



![](img/c9be2506944533fbac16b5c8db99ea71_267.png)

"我们可以获取e，并对其进行所有批次元素的索引"，"然后，甚至在这个维度中的基本元素"，"所以，在位置零和二处"，四和八，"然后，从这最后一个维度的所有部分这里"，"而且，这就给了我们偶数字符"。

"然后这里就给我们所有奇奇怪怪的字符"，"基本上我们想要干的事情是，我们制造"，"我们想要确保这些在PyTorch中被连接起来"，"然后，我们要连接"，嗯，"这两个张量沿着第二个维度"，"所以。

这个和它的形状将是四乘四的"，一百二十，这肯定是我们想要的结果，我们明确地抓取了偶数部分和奇数部分，"我们正在安排这四个四乘十的模块紧挨在一起。"，"并斩断指甲"，所以这行得通，但是，结果发现。

什么也起作用的是。

![](img/c9be2506944533fbac16b5c8db99ea71_269.png)

你可以简单地再次使用视图，并且只请求正确的形状，而且正好是，在这种情况下，那些向量又会以我们想要的方式排列。



![](img/c9be2506944533fbac16b5c8db99ea71_271.png)

所以，特别是如果我们取e，并将其视为一个4x4x20的矩阵，这就是我们想要的，我们可以检查这正好等于什么，让我叫这个，这是明确的连接，我想嗯，所以明确的点形状是四乘四乘二十。

如果你仅仅把它视为四乘四乘二十，你可以检查一下，当你与明确的相比，你得到一个大，这是元素级别的操作，所以确保所有都是真值到真值，所以基本上长话短说，我们不需要显式调用拼接等操作。

我们可以直接将输入张量视为扁平的，我们可以以任何方式查看它，特别是在你不想用负一来拉伸东西的情况下，我们实际上想要创建一个三维数组，并且取决于连续的向量有多少个，我们想要像那样融合，例如两个。

然后我们可以简单地要求这个，网格为二十，然后嗯，在这里使用负数，然后PyTorch会找出需要打包到额外批次维度的组数，所以它需要将这个额外的批次维度打包成。



![](img/c9be2506944533fbac16b5c8db99ea71_273.png)

所以让我们现在进入flatten并实现这个，好的，所以我在这里滚动到flatten，我们想做的是，我们现在想要改变它，所以让我为其创建一个构造函数并接受连续元素的数量，我们现在想要拼接。

在输出结果的最后一维，所以这里我们只是记住解决数据n等于n。

![](img/c9be2506944533fbac16b5c8db99ea71_275.png)

然后我在这里要小心，因为PyTorch实际上有一个torch。flatten。

![](img/c9be2506944533fbac16b5c8db99ea71_277.png)

并且它的关键字参数是不同的，它们像函数一样工作，所以我们的flatten开始偏离PyTorch flatten，所以让我称它为flat flatten consecutive或类似的东西。

只是为了确保我们的API大致相等，所以这基本上只将一些连续的n个元素扁平化，并将它们放入最后一个维度，现在x的形状是，嗯，B由t由c组成，让我把它们弹出来存储在变量中，并记住在我们的例子中，下面b是4。

t是8，c是10，而不是做x的那个b由-1的视图，这是我们之前有的，我们想要这个成为b由-1由。基本上这里我们想要c乘以n，那就是我们想要连续的元素数量，在这里，而不是负一，我不太喜欢使用负一。

因为我喜欢非常明确，这样你就可以得到错误消息，当事情不符合你的期望时，所以我们在这里期待什么，我们期待这个变成除以并使用整除在这里，这就是我期待的结果，在这里，我还想做一件事，那就是记住从一开始的所有。

N是三，嗯，基本上我们在那里连接所有存在的三个字符，所以我们基本上连接了一切，所以有时我可以在这里创建一个虚假的维度为一，如果x点shape在1处是1，那么它就像是一个虚假的维度。

所以我们不想在这里返回一个包含1的3维张量，我们只是想返回一个与以前相同的2维张量，在这种情况下，基本上我们会说x等于x点squeeze，那是PyTorch的一个函数。



![](img/c9be2506944533fbac16b5c8db99ea71_279.png)

嗯，和squeeze取一个维度，它要么挤压出张量的所有维度为1，或者你可以指定你想要挤压的精确维度，再次。



![](img/c9be2506944533fbac16b5c8db99ea71_281.png)

我喜欢尽可能明确，总是所以我预期只会挤压这个张量的第一个维度，这个3维张量，如果这里的维度是1，我只想返回b由c乘以n，所以self点out将是x，然后我们返回self点out，这就是候选实现。



![](img/c9be2506944533fbac16b5c8db99ea71_283.png)

当然这应该是self，而不是只是in。

![](img/c9be2506944533fbac16b5c8db99ea71_285.png)

所以让我们运行并来这里现在，让它旋转一下。

![](img/c9be2506944533fbac16b5c8db99ea71_287.png)

所以flatten，连续的，在开始让我们只是使用8。

![](img/c9be2506944533fbac16b5c8db99ea71_289.png)

这应该恢复之前的行为，所以flatten连续的8。

![](img/c9be2506944533fbac16b5c8db99ea71_291.png)

嗯，这是当前块的大小。

![](img/c9be2506944533fbac16b5c8db99ea71_293.png)

我们可以这样做，这应该恢复之前的行为，所以我们应该能够运行模型。

![](img/c9be2506944533fbac16b5c8db99ea71_295.png)

在这里我们可以检查，我有一个小代码片段在这里，我遍历所有层，我打印这个层的名称，嗯，类和形状，因此，我们看到了形状，像我们预期的那样，在每个输出层的后面。



![](img/c9be2506944533fbac16b5c8db99ea71_297.png)

所以现在让我们尝试重新结构化它，使用我们的扁平连续并按层次进行操作。

![](img/c9be2506944533fbac16b5c8db99ea71_299.png)

因此，特别是我们想要扁平连续，不仅仅是块大小，只是两，然后，我们要用这个线性处理它，然后，这个线性的输入数量不将是嵌入乘以块大小，它将现在只是被嵌入乘以二十，这通过第一个层，现在。

我们可以原则上只是复制粘贴这个，现在，下一个线性层应该期待，和隐藏乘以二，嗯，最后的一部分应该期待和隐藏乘以你再次。



![](img/c9be2506944533fbac16b5c8db99ea71_301.png)

这有点像它的原始版本，嗯。

![](img/c9be2506944533fbac16b5c8db99ea71_303.png)

所以运行这个，我们现在有一个大大大的模式，我们应该能够基本上只是 uh 向前传递模型。

![](img/c9be2506944533fbac16b5c8db99ea71_305.png)

现在，我们可以检查。

![](img/c9be2506944533fbac16b5c8db99ea71_307.png)

嗯，中间的数字，所以四字节乘以二十被扁平化，连续百万到四字节乘以四乘以二十，这被投影到四字节乘以四乘以二百，然后批量归一化，嗯，直接从盒子中工作出来，我们必须验证批量归一化是否做了正确的事情。

尽管它接受三个维的输入而不是两个维的输入，然后我们有十个h，它是元素wise的，然后它又被压扁了，所以如果我们连续扁平化并最终得到了一个四字节乘以二乘以四百，现在，然后线性把它带回到二百。

Bathroom ten h和最后我们得到一个四字节乘以四百，我们看到，对于这个最后的扁平化，连续扁平化，它挤出了那个维度的一，所以我们最终只留下了四字节乘以四百，然后线性，批量归一化。

ten h和 uh。

![](img/c9be2506944533fbac16b5c8db99ea71_309.png)

最后一个线性层来获取我们的logits，所以最终只结束在他们之前相同的形状，但现在我们实际上有一个漂亮的三层神经网络，它基本上对应于谁ops，抱歉，它基本上对应于这个网络现在，除了只有这里这一部分。

因为我们只有三层，而在这个例子中，我们有，四层，总感受野大小为十六字符，而不是只有八个字符，所以这里的块大小是十六，所以这一部分在这里基本实现了。



![](img/c9be2506944533fbac16b5c8db99ea71_311.png)

嗯，我们现在只需要在这里找出一些好的信道号来使用。

![](img/c9be2506944533fbac16b5c8db99ea71_313.png)

现在，特别是在这个架构中，我改变了隐藏单元的数量为六十八，因为我使用六十八，参数数量出来为二十二千，所以这就是我们之前有的，我们在这个神经网络中以参数的数量来说，具有相同的容量。

但是问题在于我们是否在更有效的架构中利用这些参数。

![](img/c9be2506944533fbac16b5c8db99ea71_315.png)

所以我做了，然后，我删除了很多这里的调试细胞。

![](img/c9be2506944533fbac16b5c8db99ea71_317.png)

然后我重新运行优化并滚动到结果，我们看到我们得到了相同的性能，大约，所以，我们的验证损失现在是2。029，之前它是2。027，所以，控制着参数从平坦到层次结构变化的数量。



![](img/c9be2506944533fbac16b5c8db99ea71_319.png)

并没有给我们带来什么，但是，尽管如此，有两件事需要指出，嗯。

![](img/c9be2506944533fbac16b5c8db99ea71_321.png)

首先，第一点，我们在这里并没有真正折磨架构，这只是我的第一次猜测，而且，我们可以通过大量的超参数搜索来做到，以确定我们如何分配参数预算到哪些层。



![](img/c9be2506944533fbac16b5c8db99ea71_323.png)

数字二，我们可能仍然在批归一化一维层中有一个bug。

![](img/c9be2506944533fbac16b5c8db99ea71_325.png)

所以让我们来看看，嗯。

![](img/c9be2506944533fbac16b5c8db99ea71_327.png)

这是因为它运行，或者它做对了事情。

![](img/c9be2506944533fbac16b5c8db99ea71_329.png)

所以我拉起了层检查器，大致就是我们这里有的，并在途中打印出了形状，目前看起来，批归一化正在接收一个输入，那就是三二由四由六十八，正确，就在这里，右边，我现在有我们目前正在使用的批归一化的当前实现。

我们在编写时假设的批归一化方式，当x是二维时，所以它是n由d，其中n是批大小，这就是为什么我们只减少了零维上的均值和方差，但现在x基本上将成为三维，所以现在批层内部正在发生什么，并且它为什么能正常工作。

而没有任何错误，那个原因主要是因为一切都广播得恰到好处，但是批量归一化并没有我们做我们需要做的，我们做想要达到的效果。



![](img/c9be2506944533fbac16b5c8db99ea71_331.png)

特别是，让我们基本上思考一下批处理归一化内部发生了什么，嗯，看看发生了什么。

![](img/c9be2506944533fbac16b5c8db99ea71_333.png)

让我们在这里看看发生了什么，我有代码在这里，所以我们接收到一个32x4x68的输入，然后我们在这里做，这里我们乘以均值，我有e而不是x，实际上这给了我们一个一比四的结果，由六十八得出。

所以我们只在第一个维度上计算平均值，这给了我们一个平均值和一个方差，它们仍然保持这个维度，所以这些平均值只在第一个维度的三个数字上计算，当我们执行这个时，一切都正确地广播，但基本上发生了什么，平均值。

它的形状，所以我正在查看三层叠加的模型，这是第一层浴室，和它的形状，而不是，嗯，你知道，就是尺寸的大小，因为我们有68个通道，我们预期要维护六十八个均值和方差，但实际上我们有一个四行六十八列的数组。

所以基本上这告诉我们，是这批归一化只是目前在并行处理于，四次，嗯，六十八个通道而不是仅仅六十八个通道，所以基本上我们正在为每个这些四个位置独立地维护统计数据，而我们想要干的是。

我们希望将这个视为批处理维度，就像零维一样，所以对于批归一化来说，它不想平均，两个数字，我们现在想要，对于每个单个，有两个四次的数字，这些六十八个通道中的一个，嗯，那么现在让我们删除这个。



![](img/c9be2506944533fbac16b5c8db99ea71_335.png)

结果发现，当您查看torch dot的文档时，平均值。

![](img/c9be2506944533fbac16b5c8db99ea71_337.png)

嗯，所以让我们去折磨，我的意思是。

![](img/c9be2506944533fbac16b5c8db99ea71_339.png)

嗯，在它的签名中的一个中。

![](img/c9be2506944533fbac16b5c8db99ea71_341.png)

当我们指定维度时，我们看到这里的维度不是，它可以是int，或者它也可以是一个元组的int，所以我们可以同时减少多个整数。



![](img/c9be2506944533fbac16b5c8db99ea71_343.png)

同时减少多个维度，所以不像只是减少零，我们可以传递一个元组，零一和这里零一也，然后发生了什么，当然，输出将是相同的，但现在会发生什么，因为我们减少了零和一，如果我们看那个形状。

我们看到我们现在已经减少了，我们取零和第一个维度的平均值，所以我们只能得到六十八个数字和一些多余的维度在这里。



![](img/c9be2506944533fbac16b5c8db99ea71_345.png)

所以现在它变成了一由一由六十八，类似地，也将变成一由一由六十八，即使有额外的维度，当前的，正确的事情将在那里发生，因为我们只维护六十四个的平均值和方差，抱歉，六十八个通道。

我们不计算平均值方差跨三次二乘四维度，这就是我们要的，让我们改变批归一化的实现，我们有一个d1，以便它可以接受二维或三维输入并相应地执行。



![](img/c9be2506944533fbac16b5c8db99ea71_347.png)

最终，修复相对简单，基本上我们想要减少的维度是零或元组，零和一，取决于x的维数x，如果x。dot和m是2，所以它是一个二维张量，那么我们想要减少的维度只是整数零，Lofx。dot和m是3。

所以它是一个三维张量，那么我们假设要减少的维度是零和一，嗯，然后我们只是传递dim，如果x的维数是其他任何值，我们现在将得到错误，哪个是好的，所以那应该是修复方法，现在我想指出一件事。

我们在这里稍微偏离了PyTorch API的pi。

![](img/c9be2506944533fbac16b5c8db99ea71_349.png)

因为当你来到批处理或1D在PyTorch的pi时，你可以向下滚动，你可以看到，这个层的输入可以要么是n由c，其中n是批处理大小，并且c是特征或通道的数量，或者它实际上接受三维输入，但是。

它期望它是n乘以c乘以l的，在哪里说，比如序列长度或者类似的东西，所以嗯，这是一个问题，因为你看c在这里被嵌套在中间，所以当它接收到三维输入时，这个浴室层将减少为零和二，而不是零和一。

所以基本上PyTorch批归一化，一层d假设c将始终是第一维，而我们在这里假设c是最后一维，并且有一些批处理维度预先存在，嗯所以它期望，通过c或m由c由l我们期望，通过c或由l由c所以它是一个偏差。

嗯我认为这是可以的。

![](img/c9be2506944533fbac16b5c8db99ea71_351.png)

我更喜欢这种方式，说实话，所以这就是我们将为我们的目的保持的方式。

![](img/c9be2506944533fbac16b5c8db99ea71_353.png)

所以我重新定义了层，重新初始化神经网络，并做了一次带有刹车的前向传递。

![](img/c9be2506944533fbac16b5c8db99ea71_355.png)

只是为了一步，在路上看着形状，它们是。

![](img/c9be2506944533fbac16b5c8db99ea71_357.png)

当然相同，所有的形状都是一样的，顺便我们看到事情实际上按照我们希望它们工作的方式工作，现在是当我们看批归一化层时，运行均值形状现在是一乘一乘六十八，所以我们只维护每个通道的六十八个均值。

所以我们将零维和壹维都视为批处理维度，这正是我们想要的，所以让我来重新训练神经网络。

![](img/c9be2506944533fbac16b5c8db99ea71_359.png)

好的，所以我用bug fix重新训练了神经网络，我们得到了一条漂亮的曲线，当我们看验证性能时。

![](img/c9be2506944533fbac16b5c8db99ea71_361.png)

我们实际上看到了一些改进，所以我们从2。0提升到了9。0，提升到了2。0到2。0，所以基本上浴室里的bug就像一点点地阻碍着我们，看起来，嗯，我们现在正在得到一点改进，但是否这具有统计学意义还不清楚。

嗯，我们稍微期待改进的原因，是因为我们不再维护那么多只被估计的不同平均值和方差，而是有效地使用三个两个数字，我们现在使用三个两乘以四个数字来估计它们，所以你在任一均值和方差估计中只有更多的数字。

并且它允许事情稍微更稳定，不那么波动，在这些统计数据的估计中。

![](img/c9be2506944533fbac16b5c8db99ea71_363.png)

嗯，所以相当不错，有了这种更一般的架构，我们现在已经准备好通过增加网络的大小来进一步提高性能，例如，我将嵌入的数量增加到了两个，而不是十个，而且还增加了隐藏单元的数量。



![](img/c9be2506944533fbac16b5c8db99ea71_365.png)

但使用了相同的架构，我们现在有七十六万个参数，而且训练时间大大延长。

![](img/c9be2506944533fbac16b5c8db99ea71_367.png)

但我们确实得到了一条漂亮的曲线，然后当你实际评估性能时。

![](img/c9be2506944533fbac16b5c8db99ea71_369.png)

我们现在得到了验证性能的1。993，所以我们跨越了2。0种地区的界限。

![](img/c9be2506944533fbac16b5c8db99ea71_371.png)

我们现在大约在1。99，但我们开始不得不等待很长时间。

![](img/c9be2506944533fbac16b5c8db99ea71_373.png)

我们稍微有些困惑，关于在这里正确设置超参数的问题。

![](img/c9be2506944533fbac16b5c8db99ea71_375.png)

以及学习率等，因为实验开始需要更长的时间来训练，所以我们错过了，就像是一个实验的框架，在上面我们可以运行多个实验，真正地调优这个架构。



![](img/c9be2506944533fbac16b5c8db99ea71_377.png)

所以我现在要总结一下几点，我们基本上从开始的2。1提升到了1。9。

![](img/c9be2506944533fbac16b5c8db99ea71_379.png)

但我不想这个成为焦点，因为说实话，我们对此有些困惑，我们没有实验性的束缚。

![](img/c9be2506944533fbac16b5c8db99ea71_381.png)

我们只是在猜测和检查，而且整个事情都很糟糕，我们只是在看训练损失，通常，你想要同时看训练和验证损失，整个事情看起来都不同。



![](img/c9be2506944533fbac16b5c8db99ea71_383.png)

如果你实际上是在试图挤出数字，尽管如此，我们从wavenet论文中实现了这个架构。

![](img/c9be2506944533fbac16b5c8db99ea71_385.png)

但是我们没有实现这个特定的前向被动适应性，在你有一个更复杂的地方，一种线性层的排序，那就是这种有门控的线性层类型的，并且有与残差连接和跳跃连接等类似的东西。



![](img/c9be2506944533fbac16b5c8db99ea71_387.png)

所以我们没有实现那个，我们只实现了这个结构，我想简要，提示或预览如何，我们这里所做的事情与卷积神经网络有关。



![](img/c9be2506944533fbac16b5c8db99ea71_389.png)

在wavenet论文中使用的，基本上，卷积的使用纯粹是为了效率。

![](img/c9be2506944533fbac16b5c8db99ea71_391.png)

它实际上并没有改变我们实现的模型，所以这里，例如，让我看一个特定的名称来处理一个例子，所以在我们的训练集中有一个名称，它是deandre，它有七个字母，那就是，嗯，在我们的模型中有八个独立的例子。

所以所有这些行在这里都是安卓的独立示例，你现在可以向前，当然，任何一行都可以独立地前进，所以我可以拿我的模式并叫它在任何单个索引上，顺便说一句这里，我正在玩一点小花招。

这样做的原因是额外的形状7只是一个一维数组中的8，所以你实际上不能叫模式在它上，你会得到一个错误，因为没有批处理维度，所以当你有额外的列表7时，那么这个形状就变成了1x8。

所以我得到一个额外的批处理维度为1。

![](img/c9be2506944533fbac16b5c8db99ea71_393.png)

然后我们可以向前传递模式，这向前传递一个示例，你可能想象你实际上可能会同时向前传递所有这些8个，预先分配一些内存，然后在for循环中，H次，并向前传递所有这些8个，这将给我们所有这些不同情况下的逻辑。

对于我们的模型。

![](img/c9be2506944533fbac16b5c8db99ea71_395.png)

像我们现在这样实现的，这是对模型的8个独立调用，但卷积允许你做的是，它允许你基本上滑过输入序列的这个模型高效地，所以这个for循环可以在Python的外部不做，但在CUDA的核中可以做。

所以这个for循环被隐藏在卷积中，所以卷积，基本上你可以把它想成它是一个for循环，你可以把它想成它是一个for循环，在输入序列的空间上应用一个小的线性滤波器，在我们的情况下，感兴趣的空间是一维的。

我们感兴趣的是在这些滤波器滑过输入数据，所以，这个图表实际上也相当好，基本上我们做的就是这里，他们用黑色高亮显示一个和一种计算树的单一种，所以，在这里计算一个单一的输出示例，所以。

这就是我们在这里实现的基本情况，我们实现了一个单一的，这个黑色结构，我们实现了那个，并计算一个单一的输出，如单一示例，但卷积允许你做的是，它允许你取这个黑色结构，并像滑过输入序列这里一样移动它。

并同时计算所有这些橙色输出或这里，这相当于计算所有这些输出的，嗯，在所有安德烈的位置同时计算，这个之所以更有效是因为第一，如我所说，for循环在cuda内核中的滑动内部，所以这使得它高效。

但请注意这里的变量重用，例如，如果我们看看这个圆，这个节点这里，这个节点这里是这个节点的右子节点，但也是这里节点的左子节点，所以基本上这个节点和它的值被使用两次，所以现在以这种 naive 的方式。

我们将不得不重新计算它，但在这里我们允许重复使用，所以在卷积神经网络中，你考虑我们上面有的这些线性层作为滤波器，我们取这些滤波器和他们的线性滤波器，并将它们滑过输入序列，我们计算第一个层，然后第二个层。

然后第三个层，然后三明治层的输出层，所有这些都使用这些卷积非常高效地完成。

![](img/c9be2506944533fbac16b5c8db99ea71_397.png)

所以我们将在未来的视频中覆盖这个问题，我希望你从这个视频中学到的第二件事是。

![](img/c9be2506944533fbac16b5c8db99ea71_399.png)

你看我基本上实现了所有这些层乐高积木或模块构建块。

![](img/c9be2506944533fbac16b5c8db99ea71_401.png)

我在这里实施它们。

![](img/c9be2506944533fbac16b5c8db99ea71_403.png)

我们已经实现了许多层一起，我们还实现了这些这些容器。

![](img/c9be2506944533fbac16b5c8db99ea71_405.png)

我们现在的代码已经被PyTorch扭曲了很多。

![](img/c9be2506944533fbac16b5c8db99ea71_407.png)

基本上我们做的就是，我们重新实现了torch。nn，这是神经网络，嗯，一个在torch tensor之上的库。



![](img/c9be2506944533fbac16b5c8db99ea71_409.png)

它看起来像这样，除非因为它更好，因为。

![](img/c9be2506944533fbac16b5c8db99ea71_411.png)

因为它是pytorch的，而不是在jupyter笔记本中折腾。

![](img/c9be2506944533fbac16b5c8db99ea71_413.png)

所以我认为将来，我可能会把它视为已经解锁的，嗯，torch nn，我们大致理解里面是什么，这些模块是如何工作的，它们如何嵌套。



![](img/c9be2506944533fbac16b5c8db99ea71_415.png)

以及它们在torch tensor上的做什么，所以希望我们只是，我们会切换过来，继续并开始使用torch和n直接。



![](img/c9be2506944533fbac16b5c8db99ea71_417.png)

我希望你稍微有了一点感觉的，是构建深度神经网络开发过程的样子，我认为在某种程度上还是比较代表性的。

![](img/c9be2506944533fbac16b5c8db99ea71_419.png)

所以第一点，我们在pi torch的文档页面上花费了大量的时间，并正在阅读所有的层，查看文档，输入的形状是什么，他们可能是什么，这一层做什么，嗯，等等，很遗憾我必须说PyTorch的文档并不好。

他们花费了大量的时间在各种分布式基本原理等硬核工程上，但我可以告诉你，没有人在维护文档，它会写给你，它会错误，它会不完整，将会不清楚，所以很不幸这就是事实，而你只能尽力做好你能做的。



![](img/c9be2506944533fbac16b5c8db99ea71_421.png)

嗯，他们给了我们，嗯，数字二。

![](img/c9be2506944533fbac16b5c8db99ea71_423.png)

我希望你能感受到的另一件事，是尝试让形状工作有很多，在这些多维数组周围有很多体操，它们是二维的吗，三维，四维，它包含哪些层，它的形状是什么，Ncl或nlc，你在打乱和查看，它可能会变得相当混乱。

因此我带来了我要讨论的第三个问题。

![](img/c9be2506944533fbac16b5c8db99ea71_425.png)

我经常在jupyter notebooks中原型这些层和实现。

![](img/c9be2506944533fbac16b5c8db99ea71_427.png)

并确保所有形状都能正常工作，我正在花费大量的时间，基本上来说，我在看护形状，确保一切都正确，然后一旦我对Jupyter Notebook的功能感到满意，我会将代码复制并粘贴到我的仓库中。

实际上是我正在训练的代码，所以我在VS Code的另一边工作，所以我通常有Jupyter Notebook和VS Code，我开发了一个Jupyter Notebook，我将其粘贴到VS Code中。

然后我从仓库中启动实验。

![](img/c9be2506944533fbac16b5c8db99ea71_429.png)

当然，从代码仓库中，这是关于与神经网络一起工作开发过程的大致笔记。

![](img/c9be2506944533fbac16b5c8db99ea71_431.png)

最后，我认为这门课程解锁了许多未来课程的潜力，因为第一点，我们必须将我的神经网络转换为，实际上使用这些扩展的因果卷积层，所以实现战斗第二点。



![](img/c9be2506944533fbac16b5c8db99ea71_433.png)

有可能开始理解这是什么意思，残差连接和跳跃连接。

![](img/c9be2506944533fbac16b5c8db99ea71_435.png)

以及它们为什么有用，第三点，嗯，我们，如我所说。

![](img/c9be2506944533fbac16b5c8db99ea71_437.png)

我们没有任何实验装置，所以现在我只是猜测检查一切，这不代表典型的深度学习工作流程。

![](img/c9be2506944533fbac16b5c8db99ea71_439.png)

你需要设置你的评价装置，你可以启动实验，你的脚本可以接受许多参数，你，你正在启动大量的实验，你看到许多训练和验证损失的图表，你在看什么工作，什么不工作，你在这个层面上工作，你在进行所有这些超参数搜索。

所以我们到目前为止还没有做任何那个，所以如何设置它，如何使它好。

![](img/c9be2506944533fbac16b5c8db99ea71_441.png)

我认为这是一个完全不同的主题，第三点，我们可能应该覆盖循环神经网络。

![](img/c9be2506944533fbac16b5c8db99ea71_443.png)

Rnn lstm groove和，当然，变压器，有许多地方可以去，我们将在未来覆盖这些内容，再见。

![](img/c9be2506944533fbac16b5c8db99ea71_445.png)

抱歉，我忘了说，如果你感兴趣，我认为尝试打败这个1。993有点兴趣。

![](img/c9be2506944533fbac16b5c8db99ea71_447.png)

因为我在这里并没有尝试太多的实验。

![](img/c9be2506944533fbac16b5c8db99ea71_449.png)

我对此有很大的渴望，有可能进一步推动这个，所以我还没有尝试在其他方式中分配这些通道在这个神经网络中。

![](img/c9be2506944533fbac16b5c8db99ea71_451.png)

也许嵌入的维度数量都错了。

![](img/c9be2506944533fbac16b5c8db99ea71_453.png)

也许只使用一层隐藏层的原始网络是可能的。

![](img/c9be2506944533fbac16b5c8db99ea71_455.png)

并使它足够大，实际上击败我的复杂层次网络。

![](img/c9be2506944533fbac16b5c8db99ea71_457.png)

显然，如果这不能做得更好，可能会有点尴尬。

![](img/c9be2506944533fbac16b5c8db99ea71_459.png)

即使你稍微折磨它一下，也许你可以阅读wavenet论文，并尝试理解一些这些层的工作方式并自己实现它们。



![](img/c9be2506944533fbac16b5c8db99ea71_461.png)

使用我们所有的东西，当然，你可以总是调整一些初始化或优化。

![](img/c9be2506944533fbac16b5c8db99ea71_463.png)

并看看你是否能用这种方式改进它。

![](img/c9be2506944533fbac16b5c8db99ea71_465.png)

所以我对是否有人能想出一些方法来打败这个感到好奇，是的，这就是现在。

![](img/c9be2506944533fbac16b5c8db99ea71_467.png)