- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:35:30'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Achieving Tool Calling Functionality in LLMs Using Only Prompt Engineering
    Without Fine-Tuning ††thanks: Citation: Authors. Title. Pages…. DOI:000000/11111.'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.04997](https://ar5iv.labs.arxiv.org/html/2407.04997)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Shengtao He
  prefs: []
  type: TYPE_NORMAL
- en: Hunan University
  prefs: []
  type: TYPE_NORMAL
- en: Changsha, Hunan
  prefs: []
  type: TYPE_NORMAL
- en: '[hst97@qq.com](mailto:hst97@qq.com)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Currently, the vast majority of locally deployed open-source large language
    models (LLMs) and some commercial model interfaces do not support stable tool
    calling functionality. The existing solution involves fine-tuning LLMs, which
    results in significant time and computational resource consumption. This paper
    proposes a method that enables LLMs to achieve stable tool calling capabilities
    using only prompt engineering and some ingenious code design. We conducted experiments
    on multiple LLMs that lack tool calling capabilities across various tool calling
    tasks, achieving a success rate of 100%.
  prefs: []
  type: TYPE_NORMAL
- en: '*K*eywords Large Language Models  $\cdot$ Tool Calling  $\cdot$ Prompt Engineering
     $\cdot$ Deep Learning'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Currently, the primary method for enabling large language models (LLMs) to achieve
    tool calling capabilities is through fine-tuning. For example, ToolLLM is a general
    framework for tool usage. Y. Qin et al. proposed a fine-tuning technique to enable
    tool calling capabilities in LLMs, providing a comprehensive API dataset [[1](#bib.bib1)].
    After extensive training on a large number of real API datasets, the ToolLlama
    model achieved stable tool calling capabilities. I. Abdelaziz et al. enabled function
    calling capabilities (i.e., tool calling) in LLMs through fine-grained multi-task
    learning [[2](#bib.bib2)]. Fine-tuning LLMs requires significant time and computational
    resources, and may even result in an LLM with lower intelligence levels than before
    fine-tuning. This leads to high trial-and-error costs. When a different type or
    more complex API structure needs to be called, the fine-tuned LLM requires additional
    time and computational resources for further fine-tuning to meet new demands.
    This is clearly detrimental to the practical application of LLMs in industry.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering can enable LLMs to achieve tool calling capabilities with
    almost no cost and high efficiency. By dynamically adjusting prompts for different
    application scenarios, LLMs can adapt to new tool libraries. However, the drawback
    of using prompt engineering is its instability. This paper proposes a method to
    achieve stable tool calling capabilities in LLMs using only prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Principle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The prompt engineering method used in this paper consists of two main parts:
    prompt injection and tool result feedback. Prompt injection is used to add tool
    information and prompts for using the tool into the system prompt. Tool result
    feedback involves parsing the output of the tool calling and embedding the content
    returned by the tool back into the LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'During the prompt injection phase, the prompts used are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)if  tools  is  not  None:tools_dis  =  json.loads(tools)for  tool_dis  in  tools_dis:tools_list.append(tool_dis["function"])tools_instructions  =  ""tools_instruction_list  =  []for  tool  in  tools_list:tools_instruction_list.append(tool["name"])tools_instructions  +=  (str(tool["name"])+  ":"+  "Call  this  tool  to  interact  with  the  "+  str(tool["name"])+  "  API.  What  is  the  "+  str(tool["name"])+  "  API  useful  for?  "+  str(tool["description"])+  ".  Parameters:"+  str(tool["parameters"])+  "Required  parameters:"+  str(tool["parameters"]["required"])+  "\n")TOOL_EAXMPLE  =  "You  will  receive  a  JSON  string  containing  a  list  of  callable  tools.  Please  parse  this  JSON  string  and  return  a  JSON  object  containing  the  tool  name  and  tool  parameters.  Here  is  an  example  of  the  tool  list:\n\n{\"tools\":  [{\"name\":  \"plus_one\",  \"description\":  \"Add  one  to  a  number\",  \"parameters\":  {\"type\":  \"object\",\"properties\":  {\"number\":  {\"type\":  \"string\",\"description\":  \"The  number  that  needs  to  be  changed,  for  example:  1\",\"default\":  \"1\",}},\"required\":  [\"number\"]}},{\"name\":  \"minus_one\",  \"description\":  \"Minus  one  to  a  number\",  \"parameters\":  {\"type\":  \"object\",\"properties\":  {\"number\":  {\"type\":  \"string\",\"description\":  \"The  number  that  needs  to  be  changed,  for  example:  1\",\"default\":  \"1\",}},\"required\":  [\"number\"]}}]}\n\nBased  on  this  tool  list,  generate  a  JSON  object  to  call  a  tool.  For  example,  if  you  need  to  add  one  to  number  77,  return:\n\n{\"tool\":  \"plus_one\",  \"parameters\":  {\"number\":  \"77\"}}\n\nPlease  note  that  the  above  is  just  an  example  and  does  not  mean  that  the  plus_one  and  minus_one  tools  are  currently  available."REUTRN_FORMAT="{\"tool\":  \"tool  name\",  \"parameters\":  {\"parameter  name\":  \"parameter  value\"}}"INSTRUCTION  =  f"""{TOOL_EAXMPLE}Answer  the  following  questions  as  best  you  can.  You  have  access  to  the  following  APIs:{tools_instructions}Use  the  following  format:‘‘‘tool_json{REUTRN_FORMAT}‘‘‘Please  choose  the  appropriate  tool  according  to  the  user’s  question.  If  you  don’t  need  to  call  it,  please  reply  directly  to  the  user’s  question.  When  the  user  communicates  with  you  in  a  language  other  than  English,  you  need  to  communicate  with  the  user  in  the  same  language.When  you  have  enough  information  from  the  tool  results,  respond  directly  to  the  user  with  a  text  message  without  having  to  call  the  tool  again."""system_prompt=INSTRUCTION'
  prefs: []
  type: TYPE_NORMAL
- en: 'INSTRUCTION is the final string injected into the system prompt, which includes
    three parts: TOOL EXAMPLE, tools instructions, and RETURN FORMAT. TOOL EXAMPLE
    is used to guide the LLMs on how to understand and use the tool. When writing
    TOOL EXAMPLE, it is important to use trivial tools as examples, such as the tools
    used in this paper for incrementing and decrementing numbers, to avoid confusing
    the LLMs with actual usable tools. tools instructions is a list of currently available
    tools converted into a format readable by the LLMs. When using the LLMs in practice,
    tools instructions can be dynamically adjusted by inputting different tools, allowing
    the LLMs to know which tools are available and how to use them. RETURN FORMAT
    defines the format for calling the API.'
  prefs: []
  type: TYPE_NORMAL
- en: 'During the tool result feedback phase, regular expressions are used to extract
    the “tool” and “parameters” from the output. For the interpreter tool, another
    regular expression is used to extract the code output by the LLMs, increasing
    the success rate of the LLMs using the interpreter tool. The code used in this
    paper is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,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)history.append({"role":  "user","content":  user_prompt.strip()})response=  model.create_chat_completion(messages  =  history,max_tokens=max_length,temperature=temperature,)response_content=response[’choices’][0][’message’][’content’]pattern  =  r’\{\s*"tool":\s*"(.*?)",\s*"parameters":\s*\{(.*?)\}\s*\}’while  re.search(pattern,  response_content,  re.DOTALL)!=None:match=re.search(pattern,  response_content,  re.DOTALL)tool  =  match.group(1)parameters  =  match.group(2)json_str  =  ’{"tool":  "’  +  tool  +  ’",  "parameters":  {’  +  parameters  +  ’}}’parameters  =  json.loads(’{’  +parameters+  ’}’)results  =  dispatch_tool(tool,  parameters)print(results)history.append({"role":"assistant",  "content":  json_str})history.append({"role":  "observation",  "content":  results})response=  model.create_chat_completion(messages  =  history,max_tokens=max_length,temperature=temperature,)response_content  =  response.choices[0].message.contentpattern  =  r"‘‘‘python\n(.*?)\n‘‘‘"while  re.search(pattern,  response,  re.DOTALL)  !=None:matches  =  re.search(pattern,  response,  re.DOTALL)code  =  matches.group(1)results  =  interpreter(code)print(results)json_str  =  ’{"tool":  "interpreter",  "parameters":  ’+code+’}’history.append({"role":"assistant",  "content":  json_str})history.append({"role":  "observation",  "content":  results})response=  model.create_chat_completion(messages  =  history,max_tokens=max_length,temperature=temperature,)response_content  =  response.choices[0].message.content'
  prefs: []
  type: TYPE_NORMAL
- en: 'By identifying the dictionary of tools called by the LLM and extracting the
    corresponding values, these values are then passed into the appropriate tool functions.
    Finally, the results returned by the tools are sent back to the LLM in the role
    of “observation.” For some LLM interfaces that do not accept the roles of “observation,”
    “tool,” or “function,” the results can be returned to the “user” role instead.
    For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[⬇](data:text/plain;base64,aGlzdG9yeS5hcHBlbmQoeyJyb2xlIjogInVzZXIiLCAiY29udGVudCI6ICJDYWxsIiArIHRvb2wgKyAiVGhlIHJlc3VsdCByZXR1cm5lZCBieSB0aGUgdG9vbCBpczoiICsgcmVzdWx0cyArICIuIFBsZWFzZSBjb250aW51ZSB0byBhbnN3ZXIgbXkgcHJldmlvdXMgcXVlc3Rpb24gYmFzZWQgb24gdGhlIHJlc3VsdCByZXR1cm5lZCBieSB0aGUgdG9vbC4ifSk=)history.append({"role":  "user",  "content":  "Call"  +  tool  +  "The  result  returned  by  the  tool  is:"  +  results  +  ".  Please  continue  to  answer  my  previous  question  based  on  the  result  returned  by  the  tool."})'
  prefs: []
  type: TYPE_NORMAL
- en: By using the above prompt engineering method, it is possible to avoid fine-tuning
    and enable LLMs that originally lack tool calling capabilities to achieve stable
    tool calling functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Experimental Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this study, we used the quantized versions of the current mainstream small
    open-source models llama3-8b, gemma2-9b, qwen2-7b, and mistral-7b from Ollama
    as test models [[3](#bib.bib3)]. The following tool calling tasks were tested,
    each with 10 different queries:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Querying real-time time in different time zones.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Querying real-time weather in different locations.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Answering recent events after performing a Google search.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Solving mathematical problems using a Python interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Searching local file information to answer questions.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Querying relevant papers on arXiv.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Searching local knowledge graphs to answer questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tests were conducted on an NVIDIA GeForce RTX 4080, using a platform developed
    by the author: the open-source project ComfyUI LLM Party [[4](#bib.bib4)]. This
    project is available on GitHub. To quickly reproduce the results of this paper,
    you can download the project for testing. Table 1 shows the number of successful
    tool calls for multiple models across various tool calling tasks using the prompt
    engineering method proposed in this paper. For models that do not use the prompt
    injection method, tool information is passed to these models via the tool interface.
    However, since these models do not support tool calling functionality, they cannot
    call these tools.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Number of Successful Tool Calls Using Prompt Engineering'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Time Zone Query | Weather Query | Google Search | Python Interpreter
    | Local File Search | ArXiv Query | Knowledge Graph Search |'
  prefs: []
  type: TYPE_TB
- en: '| llama3-8b | 10 | 10 | 10 | 1 | 10 | 10 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| gemma2-9b | 10 | 10 | 10 | 10 | 10 | 10 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| qwen2-7b | 10 | 10 | 10 | 10 | 10 | 10 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| mistral-7b | 10 | 10 | 10 | 2 | 10 | 10 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'Table [1](#S3.T1 "Table 1 ‣ 3 Experimental Results ‣ Achieving Tool Calling
    Functionality in LLMs Using Only Prompt Engineering Without Fine-Tuning Citation:
    Authors. Title. Pages…. DOI:000000/11111.") shows that all models successfully
    executed the tool calling step and correctly output dictionaries that could be
    captured by regular expressions. However, due to limitations in code generation
    capabilities, the Ollama-quantized versions of the llama3-8b and mistral-7b models
    did not consistently output correct code in the Python interpreter task, resulting
    in unstable completion of computational tasks. In the knowledge graph search task,
    all models successfully returned relevant knowledge using the tools. However,
    due to limitations in logical understanding capabilities, the Ollama-quantized
    versions of the qwen2-7b and mistral-7b models could not consistently understand
    the logical relationships between multiple edges in the knowledge graph.'
  prefs: []
  type: TYPE_NORMAL
- en: These experimental results demonstrate that prompt engineering can enable LLMs
    that originally lack tool calling capabilities to achieve tool calling functionality.
    However, the ability to effectively utilize the information returned by the tools
    to solve user problems is still limited by the LLM’s own intelligence level. Larger
    models, such as gemma2-9b, show significantly more stable capabilities in utilizing
    the results returned by the tools.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6260e02269e7f43d72b7ec9a4a37e316.png)'
  prefs: []
  type: TYPE_IMG
- en: (a)
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/34888cf0dfdfc8b7b4466ec282b6c072.png)'
  prefs: []
  type: TYPE_IMG
- en: (b)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: (a) Output of gemma2-9b without using prompt engineering; (b) Output
    of gemma2-9b using prompt engineering'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Figure [1](#S3.F1 "Figure 1 ‣ 3 Experimental Results ‣ Achieving Tool Calling
    Functionality in LLMs Using Only Prompt Engineering Without Fine-Tuning Citation:
    Authors. Title. Pages…. DOI:000000/11111.") shows the output of the gemma2-9b
    model when calling the weather tool. When prompt engineering is not used, the
    ‘is tools in sys prompt’ attribute is set to disable, and the gemma2-9b model
    believes it cannot obtain real-time information, thus rejecting the user’s request.
    When prompt engineering is used, the ‘is tools in sys prompt’ attribute is set
    to enable, and the gemma2-9b model provides the correct real-time weather information.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This study demonstrates that prompt engineering alone can enable LLMs to achieve
    tool calling capabilities, significantly saving time and computational resources
    required for fine-tuning. All models in the experiment successfully output the
    correct format for regular expression recognition. However, due to the intelligence
    level limitations of small LLMs, some models lacked the programming or logical
    capabilities to produce correct results for certain complex tasks. Due to the
    limitations of the author’s equipment, the effects of prompt engineering were
    not tested on larger LLMs. Researchers who have doubts about the experimental
    results can use the author’s open-source project on GitHub, ComfyUI LLM Party
    [[4](#bib.bib4)], to reproduce the work presented in this paper.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Y. Qin et al. Toolllm: Facilitating large language models to master 16000+
    real-world apis. arXiv preprint arXiv:2307.16789, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] I. Abdelaziz et al. Granite-function calling model: Introducing function
    calling abilities via multi-task learning of granular tasks. arXiv preprint arXiv:2407.00121,
    2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Ollama. Quantized versions of llama3-8b, gemma2-9b, qwen2-7b, and mistral-7b,
    2024. Ollama Documentation, [https://ollama.com/library](https://ollama.com/library).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] S. He. Comfyui llm party: An open-source project for llm tool calling,
    2024. GitHub Repository, [https://github.com/heshengtao/comfyui_LLM_party](https://github.com/heshengtao/comfyui_LLM_party).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
