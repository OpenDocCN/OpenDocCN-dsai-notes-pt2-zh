- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:39:38'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2311.00273](https://ar5iv.labs.arxiv.org/html/2311.00273)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yirong Chen¹, Xiaofen Xing¹, Jingkai Lin¹, Huimin Zheng¹,
  prefs: []
  type: TYPE_NORMAL
- en: Zhenyu Wang¹, Qi Liu², Xiangmin Xu^(2,3)
  prefs: []
  type: TYPE_NORMAL
- en: ¹Guangdong Provincial Key Laboratory of Human Digital Twin, School of EE.,
  prefs: []
  type: TYPE_NORMAL
- en: South China University of Technology, Guangzhou, China
  prefs: []
  type: TYPE_NORMAL
- en: ²School of Future Technology, South China University of Technology, Guangzhou,
    China
  prefs: []
  type: TYPE_NORMAL
- en: ³Pazhou Lab, Guangzhou, China
  prefs: []
  type: TYPE_NORMAL
- en: 'eeyirongchen@mail.scut.edu.cn, {xfxing, xmxu}@scut.edu.cn   Corresponding author.
    Email: xfxing@scut.edu.cn'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large language models (LLMs) have been widely applied in various fields due
    to their excellent capability for memorizing knowledge and chain of thought (CoT).
    When these language models are applied in the field of psychological counseling,
    they often rush to provide universal advice. However, when users seek psychological
    support, they need to gain empathy, trust, understanding and comfort, rather than
    just reasonable advice. To this end, we constructed a multi-turn empathetic conversation
    dataset of more than 2 million samples, in which the input is the multi-turn conversation
    context, and the target is empathetic responses that cover expressions such as
    questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments
    have shown that the empathy ability of LLMs can be significantly enhanced when
    finetuning by using multi-turn dialogue history and responses that are closer
    to the expression of a psychological consultant.¹¹1[https://github.com/scutcyr/SoulChat](https://github.com/scutcyr/SoulChat)
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the birth of BERT (Devlin et al., [2019](#bib.bib2)) and GPT (Radford
    et al., [2018](#bib.bib16)), large language models (LLMs) have made rapid progress
    in the past five years. In November 2022, OpenAI launched ChatGPT²²2[https://chat.openai.com](https://chat.openai.com) (OpenAI,
    [2022](#bib.bib10)), a large language model fine-tuning by reinforcement learning
    from human feedback (RLHF) (Ouyang et al., [2022](#bib.bib11)). However, when
    applied to mental health or emotional support conversation, there are three main
    issues lead to ChatGPT appear less “human-centered”:'
  prefs: []
  type: TYPE_NORMAL
- en: 1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ChatGPT tends to provide repetitive and standardized responses. ChatGPT often
    uses the following template to respond to users’ questions related to mental health:
    "我很抱歉…。xxx是…。以下是一些建议：…。 (I’m sorry to …{xxx} is …Here are some suggestions:…)",
    which may cause boredom.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ChatGPT is inclined to provide suggestions rather than ask questions or listen.
    It is eager to solve users’ problems, usually providing lengthy and general suggestions,
    as shown in Figure [12](#A4.F12 "Figure 12 ‣ Appendix D English Word Cloud Map
    ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations") of Appendix [F](#A6 "Appendix
    F Sample Conversations of Other LLMs ‣ SoulChat: Improving LLMs’ Empathy, Listening,
    and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations").
    However, professional psychologists rarely provide specific suggestions during
    the counseling process.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ChatGPT acts a bit like a rational "Straight man" for those users who need listening
    and comfort. Users who seek emotional support usually expect empathy support such
    as listening, understanding and comfort.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3105c0415e7f77bf7b071844cf8d3383.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: A case of a user confiding to SoulChat. Compared to ChatGPT, SoulChat
    is better at listening and guiding users to think.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar issues can also be found in other LLMs, e.g. ChatGLM (Zeng et al.,
    [2023](#bib.bib20)), SparkDesk³³3[https://xinghuo.xfyun.cn](https://xinghuo.xfyun.cn),
    as presented in Appendix [F](#A6 "Appendix F Sample Conversations of Other LLMs
    ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations"). It may be due to the lack
    of large-scale multi-turn empathy conversation datasets for fine-tuning stage,
    especially in the field of Chinese mental health or emotional support. EMPATHETICDIALOGUES (Rashkin
    et al., [2019](#bib.bib17)) and ESConv (Liu et al., [2021](#bib.bib9)) are two
    English empathy conversation datasets that is used for developing emotional support
    conversation (ESC) systems, e.g MISC (Tu et al., [2022](#bib.bib19)), GLHG (Peng
    et al., [2022](#bib.bib13)), MultiESC (Cheng et al., [2022](#bib.bib1)), FADO (Peng
    et al., [2023](#bib.bib14)) and etc. On the one hand, these models may rely on
    annotated empathy strategies and emotions of users during the training or inference
    stage, which means that building large-scale similar datasets for fine-tuning
    LLMs is difficult. On the other hand, these datasets are in English, so that they
    cannot be applied to fine-tune Chinese LLMs. As for mental health, efaqa (Hailiang
    et al., [2020](#bib.bib5)) and PsyQA (Sun et al., [2021](#bib.bib18)) are two
    commonly-used datasets. Among them, efaqa contains 20,000 conversations and provides
    annotation information such as types of troubles, psychological disorders, SOS,
    etc. However, efaqa has a complex multi-party dialogue relationship and a high
    proportion of low-quality responses from netizens, while PsyQA contains 22,346
    questions and 56,063 single-turn long-text psychological counseling conversations.
    Thus, neither of these datasets can solve the three issues of ChatGPT mentioned
    above.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently, Qiu et al. ([2023](#bib.bib15)) proposed a SMILE approach to employ
    ChatGPT to convert single-turn dialogues into multi-turn ones. They utilized SMILE
    to extend the single-turn conversation dataset PsyQA to a empathy multi-turn conversation
    dataset SMILECHAT with 355,733 samples. Inspired by (Qiu et al., [2023](#bib.bib15)),
    we proposed a Chinese empathy constraint prompt, in which the empathy prompt constraint
    is further strengthened compared with SMILE prompt (see Appendix [C](#A3 "Appendix
    C Our prompt VS SMILE prompt ‣ SoulChat: Improving LLMs’ Empathy, Listening, and
    Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations")).
    As shown in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ SoulChat: Improving
    LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn
    Empathy Conversations") (English version: Appendix [C](#A3 "Appendix C Our prompt
    VS SMILE prompt ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities
    through Fine-tuning with Multi-turn Empathy Conversations")), our empathy constraints
    are defined as “‘心理咨询师’的回复需要结合用户的描述内容并提供共情，如：倾听、安慰、理解、信任、认可、真诚、情感支持等 (The response
    of the ’psychological counselor’ needs to be combined with the user’s description
    and provide empathy, such as listening, comfort, interpretation, trust, recognition,
    sincerity, emotional support, etc)”.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b0596d37e39c689d58bc1933cd6cc6fc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The prompt used for converting single-turn psychological counseling
    conversations to multi-turn empathy conversations (English version: Appendix [C](#A3
    "Appendix C Our prompt VS SMILE prompt ‣ SoulChat: Improving LLMs’ Empathy, Listening,
    and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations")).'
  prefs: []
  type: TYPE_NORMAL
- en: To this end, we first constructed 215,813 different psychological counseling
    questions about 12 topics and 619,725 answers through data outsourcing services.
    Rule-based cleaning, manual rewriting and human proofreading are applied to ensure
    that there is no sensitive or privacy-related content in the dataset. Then, we
    use ChatGPT to convert these single-turn long text psychological counseling conversations
    to multi-turn empathy conversations. We also conducted manual proofreading and
    data cleansing for multi-turn dialogues rewritten by ChatGPT to further strengthen
    the expression of empathy, such as questioning, comfort, recognition, listening,
    trust, emotional support, etc. In the end, we obtained a multi-turn empathy conversation
    dataset, named SoulChatCorpus, with 2,300,248 samples. To our knowledge, it is
    the first million-scale multi-turn empathy conversation dataset in the field of
    mental health or emotional support. We conduct experiments by using ChatGLM-6B
    as the base model for fine-tuning on SoulChatCorpus. Results demonstrate that
    LLMs’ empathy, listening, and comfort abilities can be improved significantly
    through fine-tuning with million-scale multi-turn empathy conversation dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8dd960360af270bd8b96c871657b9b23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Distribution of counseling topics.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Human-centered Mental Health LLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 SoulChatCorpus Collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We consider an one-on-one psychological counseling conversational setting where
    a user and a psychological consultant engage in multiple rounds of dialogue. However,
    such conversation data is not publicly available due to the privacy protection
    and ethical standards of psychological counseling. To construct high-quality multi-turn
    empathy conversation dataset, We selected 12 topics of psychological counseling
    to construct 215,813 long-text questions and 619,725 long-text answer through
    crowdsourcing. The distribution of topics is shown in Figure [3](#S1.F3 "Figure
    3 ‣ 1 Introduction ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort
    Abilities through Fine-tuning with Multi-turn Empathy Conversations"). Then, we
    used ChatGPT (99% called gpt-3.5-turbo api and 1% called gpt-4 api) as a text
    rewriting tool following the prompt as shown in Figure [2](#S1.F2 "Figure 2 ‣
    1 Introduction ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities
    through Fine-tuning with Multi-turn Empathy Conversations") to convert single-turn
    psychological counseling conversations to multi-turn empathy conversations, in
    which one turn is in the form of "用户： <user_utt>$\backslash$n心理咨询师：<psy_utt>".
    The response of "心理咨询师" was asked to be rewritten to reflect human-centered expressions
    such as empathy, listening, comfort, etc. Finally, after manual proofreading,
    we removed 105,134 low-quality samples and ultimately obtained 2,300,248 samples.
    As shown in Figure [4](#S2.F4 "Figure 4 ‣ 2.1 SoulChatCorpus Collection ‣ 2 Human-centered
    Mental Health LLM ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort
    Abilities through Fine-tuning with Multi-turn Empathy Conversations"), the word
    cloud map of the utterances expressed by psychological consultants indicated that
    the rewritten multi-turn empathy conversation has high level of empathy.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/25629a4641f82c775b0084a6821bc945.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Word cloud map of psychological consultants’ utterances (English
    version: Appendix [D](#A4 "Appendix D English Word Cloud Map ‣ SoulChat: Improving
    LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn
    Empathy Conversations")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Evaluation results.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Model | Automatic. | Manual. |  |'
  prefs: []
  type: TYPE_TB
- en: '| B-1 | B-2 | B-3 | B-4 | R-1 | R-2 | R-L | Con. | Emp. | Hel. | Saf. |'
  prefs: []
  type: TYPE_TB
- en: '| SoulChat- Corpus | ChatGLM-6B | 22.73 | 13.15 | 8.04 | 4.92 | 25.33 | 5.72
    | 18.84 | 1.90 | 1.55 | 1.92 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| MeChat | 29.43 | 17.12 | 10.54 | 6.71 | 27.35 | 6.27 | 21.12 | 1.83 | 1.70
    | 1.78 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT | 27.98 | 16.09 | 9.93 | 6.23 | 27.39 | 6.82 | 21.92 | 1.96 | 1.62
    | 1.94 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| SoulChat | 33.78 | 20.07 | 12.86 | 8.52 | 31.47 | 8.92 | 26.57 | 1.95 | 1.84
    | 1.87 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| SMILECHAT | ChatGLM-6B | 22.91 | 13.56 | 8.40 | 5.15 | 25.99 | 5.95 | 18.76
    | 1.81 | 1.39 | 1.84 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| MeChat | 30.63 | 18.41 | 11.59 | 7.46 | 28.92 | 6.76 | 21.59 | 1.95 | 1.74
    | 1.83 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT | 28.30 | 16.48 | 10.24 | 6.40 | 27.57 | 6.71 | 21.60 | 1.95 | 1.65
    | 1.97 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| SoulChat | 35.40 | 21.39 | 13.77 | 9.02 | 32.64 | 9.17 | 21.10 | 1.93 | 1.90
    | 1.85 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: 2.2 SoulChat Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We utilized the ChatGLM-6B (Du et al., [2022](#bib.bib3); Zeng et al., [2023](#bib.bib20))
    as the base LLM architecture to develop the SoulChat. ChatGLM-6B is an open-source,
    bilingual LLM based on the General Language Model (GLM) (Du et al., [2022](#bib.bib3))
    framework with 6.2 billion parameters. The input of model is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $input=u_{1}^{u}+^{\prime}{\backslash}n^{\prime}+u_{1}^{p}+...+u_{N}^{u}+^{\prime}{\backslash}n^{\prime}+u_{N}^{p}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the utterance of User on $i$ turn $u_{i}^{p}$=‘心理咨询师： (Psychologist:)’,
    $N$ represents the number of conversation turns for the context.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Baselines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We compare SoulChat and the following benchmark models using both automatic
    and manual evaluations:'
  prefs: []
  type: TYPE_NORMAL
- en: 1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ChatGLM-6B⁴⁴4[https://github.com/THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) (Du
    et al., [2022](#bib.bib3); Zeng et al., [2023](#bib.bib20)) serves as the base
    model for SoulChat.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ChatGPT (OpenAI, [2022](#bib.bib10); Ouyang et al., [2022](#bib.bib11)) is a
    LLM that is trained using supervised finetuning and Reinforcement Learning from
    Human Feedback (RLHF).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MeChat (Qiu et al., [2023](#bib.bib15)) is a LLM finetuned with low-rank adaptation
    (LoRA) (Hu et al., [2022](#bib.bib7)) on SMILECHAT dataset that is generated by
    ChatGPT based on PsyQA.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3.2 Implementation details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SoulChat is finetuned on the proposed SoulChatCorpus with a batch size of 80
    and global training steps of 30,000\. The WarmupDecayLR learning rate scheduler
    with $warmup\_steps=1000$ is adopted during the inference phase.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Results and Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We randomly selected 10,000 samples from SoulChatCorpus and SMILECHAT respectively
    as the test set for automatic evaluation and 100 samples for manual evaluation.
    For each sample, each model generates an answer for evaluation. We used 7 evaluation
    metrics as automatic metrics: BLEU-1 (B-1), BLEU-2 (B-2), BLEU-3 (B-3), BLEU-4
    (B-4) (Papineni et al., [2002](#bib.bib12)), R-1 (ROUGE-1), R-2 (ROUGE-2) and
    R-L (ROUGE-L) (Lin, [2004](#bib.bib8))). Three individual experts majoring in
    Psychology were asked to evaluate the generated responses in terms of content
    naturalness (Con.), empathy level (Emp.), Helpfulness (Hel.) and Safety (Saf.),
    as detailed described in Appendix [G](#A7 "Appendix G Manual Evaluation Instructions
    ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations"). The rating scale of Con.,
    Emp. and Hel. is $(0,1,2)$ for Saf. (perfect agreement). The evaluation results
    are shown in Table [1](#S2.T1 "Table 1 ‣ 2.1 SoulChatCorpus Collection ‣ 2 Human-centered
    Mental Health LLM ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort
    Abilities through Fine-tuning with Multi-turn Empathy Conversations"). Generally,
    SoulChat outperforms ChatGLM-6B, ChatGPT and MeChat in both automatic evaluation
    metrics and Emp. metric on test set of SoulChatCorpus and SMILECHAT. Specifically,
    the results on SMILECHAT demonstrates SoulChat’s excellent zero-shot performance
    in the field of mental health.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Conclusion and Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we explore how to make LLMs more human-centered. To this end,
    we constructed a Chinese large-scale multi-turn empathy conversation dataset,
    named SoulChatCorpus, with 12 empathy topics and more than 2 million samples.
    The experimental results indicate that using this dataset to finetune LLMs leads
    to high-level empathy ability when users try to seek emotional support from LLMs.
    Future work needs to further consider user attributes, such as personality, gender
    and etc., to help LLMs generate targeted empathy responses for different individuals.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this work we proposed a human-centered LLM named SoulChat that has excellent
    empathy ability, which is finetuned on the proposed SoulChatCorpus dataset. Although
    the experimental results demonstrate the effectiveness of SoulChat, there are
    still some limitations need to consider. The mechanism of empathy is complex.
    Different users have different expectations for the output of the model. For example,
    when discussing tense emotions, there are significant differences in the solutions
    expected by adults and adolescents. Therefore, human-centered LLMs need to further
    consider the user’s personality, identity, and other attributes to assist in generating
    answers that are closer to the user’s needs.
  prefs: []
  type: TYPE_NORMAL
- en: Ethics Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Collection. In order to protect privacy (Hovy and Spruit, [2016](#bib.bib6)),
    we adopted strict manual proofreading process when constructing the dataset. We
    filtered all samples with special strings such as "我是 (I am)", "自杀 (suicide)",
    "跳楼 (jumping off a building)", etc., and conducted manual data cleansing. Any
    text related to privacy has been rewritten or removed. Besides, any potential
    conversations that pose harm to users, others, or society have been completely
    removed from our data. To this end, we removed 105,134 samples from multi-turn
    conversations generated by ChatGPT.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Potential Risks of the Model We conducted a safety assessment specifically
    for the output of the model during the manual evaluation phase, and the results
    are shown in Table [1](#S2.T1 "Table 1 ‣ 2.1 SoulChatCorpus Collection ‣ 2 Human-centered
    Mental Health LLM ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort
    Abilities through Fine-tuning with Multi-turn Empathy Conversations"). Due to
    the lack of human feedback during the model finetuning stage, there are inevitably
    answers that may pose harm to users. Therefore, future work needs to combine RLHF
    to improve the safety level of model generated content. In addition, when this
    model is applied to downstream scenarios, it is necessary to inform the users
    in advance that the answers they see are generated by the AI model and are for
    reference only.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annotator Compensation. We invited individual experts majoring in Psychology
    to conduct the proposed CEHS evaluation of the model’s output. The annotators’
    evaluation of each sample takes approximately 3 minutes, during which they can
    receive a salary of $0.418\. Therefore, the hourly salary of the annotators is
    $8.36, which is higher than the US minimum wage of $7.12 per hour.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work was supported by the Science and Technology Project of Guangzhou (202103010002),
    the Natural Science Foundation of Guangdong Province (2022A1515011588), the National
    Key R&D Program of China (2022YFB4500600), the Science and Technology Project
    of Guangdong (2022B0101010003), the National Natural Science Foundation of China
    under Grant U1801262 and Guangdong Provincial Key Laboratory of Human Digital
    Twin (2022B1212010004).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cheng et al. (2022) Yi Cheng, Wenge Liu, Wenjie Li, Jiashuo Wang, Ruihui Zhao,
    Bang Liu, Xiaodan Liang, and Yefeng Zheng. 2022. [Improving multi-turn emotional
    support dialogue generation with lookahead strategy planning](https://aclanthology.org/2022.emnlp-main.195).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing*, pages 3014–3026, Abu Dhabi, United Arab Emirates. Association for
    Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. [BERT: Pre-training of deep bidirectional transformers for language
    understanding](https://doi.org/10.18653/v1/N19-1423). In *Proceedings of the 2019
    Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, pages
    4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Du et al. (2022) Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu,
    Zhilin Yang, and Jie Tang. 2022. [GLM: General language model pretraining with
    autoregressive blank infilling](https://doi.org/10.18653/v1/2022.acl-long.26).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 320–335, Dublin, Ireland. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fleiss (1971) Joseph L Fleiss. 1971. Measuring nominal scale agreement among
    many raters. *Psychological Bulletin*, 76(5):378–382.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hailiang et al. (2020) Wang Hailiang, Wu Zhizhi, and Lang Jiayuan. 2020. [Pat
    psychology: Psychological consultation q&a corpus](https://github.com/chatopera/efaqa-corpus-zh).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hovy and Spruit (2016) Dirk Hovy and Shannon L. Spruit. 2016. [The social impact
    of natural language processing](https://doi.org/10.18653/v1/P16-2096). In *Proceedings
    of the 54th Annual Meeting of the Association for Computational Linguistics (Volume
    2: Short Papers)*, pages 591–598, Berlin, Germany. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. (2022) Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. [LoRA: Low-rank adaptation
    of large language models](https://openreview.net/forum?id=nZeVKeeFYf9). In *International
    Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin (2004) Chin-Yew Lin. 2004. [ROUGE: A package for automatic evaluation of
    summaries](https://aclanthology.org/W04-1013). In *Text Summarization Branches
    Out*, pages 74–81, Barcelona, Spain. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2021) Siyang Liu, Chujie Zheng, Orianna Demasi, Sahand Sabour,
    Yu Li, Zhou Yu, Yong Jiang, and Minlie Huang. 2021. [Towards emotional support
    dialog systems](https://doi.org/10.18653/v1/2021.acl-long.269). In *Proceedings
    of the 59th Annual Meeting of the Association for Computational Linguistics and
    the 11th International Joint Conference on Natural Language Processing (Volume
    1: Long Papers)*, pages 3469–3483, Online. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2022) OpenAI. 2022. [Introducing chatgpt](https://openai.com/blog/chatgpt).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
    Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022. [Training
    language models to follow instructions with human feedback](https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*, volume 35, pages 27730–27744\.
    Curran Associates, Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Papineni et al. (2002) Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
    Zhu. 2002. [Bleu: a method for automatic evaluation of machine translation](https://doi.org/10.3115/1073083.1073135).
    In *Proceedings of the 40th Annual Meeting of the Association for Computational
    Linguistics*, pages 311–318, Philadelphia, Pennsylvania, USA. Association for
    Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2022) Wei Peng, Yue Hu, Luxi Xing, Yuqiang Xie, Yajing Sun, and
    Yunpeng Li. 2022. [Control globally, understand locally: A global-to-local hierarchical
    graph network for emotional support conversation](https://www.ijcai.org/proceedings/2022/0600.pdf).
    In *Proceedings of the Thirty-First International Joint Conference on Artificial
    Intelligence (IJCAI-22)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2023) Wei Peng, Ziyuan Qin, Yue Hu, Yuqiang Xie, and Yunpeng Li.
    2023. [Fado: Feedback-aware double controlling network for emotional support conversation](https://doi.org/https://doi.org/10.1016/j.knosys.2023.110340).
    *Knowledge-Based Systems*, 264:110340.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2023) Huachuan Qiu, Hongliang He, Shuai Zhang, Anqi Li, and Zhenzhong
    Lan. 2023. [Smile: Single-turn to multi-turn inclusive language expansion via
    chatgpt for mental health support](http://arxiv.org/abs/2305.00450).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2018) Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever,
    et al. 2018. [Improving language understanding by generative pre-training](http://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rashkin et al. (2019) Hannah Rashkin, Eric Michael Smith, Margaret Li, and
    Y-Lan Boureau. 2019. [Towards empathetic open-domain conversation models: A new
    benchmark and dataset](https://doi.org/10.18653/v1/P19-1534). In *Proceedings
    of the 57th Annual Meeting of the Association for Computational Linguistics*,
    pages 5370–5381, Florence, Italy. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2021) Hao Sun, Zhenru Lin, Chujie Zheng, Siyang Liu, and Minlie
    Huang. 2021. [PsyQA: A Chinese dataset for generating long counseling text for
    mental health support](https://doi.org/10.18653/v1/2021.findings-acl.130). In
    *Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021*,
    pages 1489–1503, Online. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tu et al. (2022) Quan Tu, Yanran Li, Jianwei Cui, Bin Wang, Ji-Rong Wen, and
    Rui Yan. 2022. [MISC: A mixed strategy-aware model integrating COMET for emotional
    support conversation](https://doi.org/10.18653/v1/2022.acl-long.25). In *Proceedings
    of the 60th Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 308–319, Dublin, Ireland. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeng et al. (2023) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong,
    and Jie Tang. 2023. [GLM-130b: An open bilingual pre-trained model](https://openreview.net/forum?id=-Aw0rrrPUF).
    In *The Eleventh International Conference on Learning Representations (ICLR)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Reproducibility Checklist
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model and Data: The SoulChat model and SoulChatCorpus will be released upon
    decision of the paper.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'System Hardware: We trained the SoulChat on the Ubuntu 20.04.6 LTS server that
    has 2 CPUs called "Intel(R) Xeon(R) Platinum 8358P CPU @ 2.60GHz", 8 NVIDIA A800-SXM4-80GB
    GPUs, and 1,024GB memory.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Driver Version: The version of Nvidia driver is "525.105.17". The version of
    CUDA is "11.6". The version of Cudnn is "8.4.0.27".'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Package version: python=3.8, torch⁵⁵5[https://pytorch.org/get-started/previous-versions](https://pytorch.org/get-started/previous-versions)=1.13.1,
    transformers⁶⁶6[https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)=4.28.0,
    deepspeed⁷⁷7[https://github.com/microsoft/DeepSpeed](https://github.com/microsoft/DeepSpeed)=0.9.3,
    datasets=2.11.0 and jieba=0.42.1 is recommended.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model Parameters: SoulChat has 6.2B parameters with 28 layers and $max\_sequence\_length$
    of 2,048\. During the inference phase, the model requires at least 14GB of GPU
    memory.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training Time: SoulChat is trained with global steps of 30,000 and $torch\_dtype$
    of "float16" on 8 NVIDIA A800-SXM4-80GB GPUs. The training time is about 79 hours.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Appendix B Counseling Topics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following dictionaries represent the corresponding relationships between
    Chinese and English for 12 counseling topics.
  prefs: []
  type: TYPE_NORMAL
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: '’家庭’: ’Family’, ’婚恋’: ’Marriage’, ’性心理’: ’Sex’, ’成长发展’: ’Growth’, ’人际关系’: ’Relationship
    ’, ’职场’: ’Career’, ’自我认知’: ’Self-awareness ’, ’行为’: ’Behavior’, ’情绪’: ’Emotion’,
    ’治疗’: ’Treatment’, ’社会事件’: ’Social events’, ’心理学知识’: ’Psychological knowledge’,'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Our prompt VS SMILE prompt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5fd2e15e8d228ca824dd3ee95dc5011d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The translated English prompt used for converting single-turn psychological
    counseling conversations to multi-turn empathy conversations.'
  prefs: []
  type: TYPE_NORMAL
- en: We used SMILE (Qiu et al., [2023](#bib.bib15)) prompt and our proposed Chinese
    empathy constraint prompt for extend the single-turn long text psychological counseling
    example to multi-turn empathy conversation respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chinese:'
  prefs: []
  type: TYPE_NORMAL
- en: 用户：谈恋爱两年了，异地恋，平时很好，一年前开始吵架吵凶了，男朋友就说难听的话甚至骂人，正常吗？
  prefs: []
  type: TYPE_NORMAL
- en: 心理咨询师：你好！异地恋，平时还好，但一吵架，就出现骂你，这确实不正常。这应该跟很多因素有关。
  prefs: []
  type: TYPE_NORMAL
- en: 1、异地恋本身就有挑战性，你男朋友跟你异地，他的语言和言语就受到了挑战。
  prefs: []
  type: TYPE_NORMAL
- en: 2、他平时跟你相处的时候，也会有很多压力，所以一遇到类似的情况，就会很暴躁。
  prefs: []
  type: TYPE_NORMAL
- en: 3、平时跟他相处的时候，你们之间没有矛盾，一有矛盾就会吵凶。
  prefs: []
  type: TYPE_NORMAL
- en: 4、你们平时沟通也比较少，所以他也没有渠道发泄自己的负面情绪。
  prefs: []
  type: TYPE_NORMAL
- en: 以上是一些可能性，但并不一定就是导致他出现这样的情况的原因，因为你们之间是否存在其他矛盾，只有你们两个人一起沟通才知道。所以，我觉得你应该认真考虑一下，自己男朋友的这种行为，是处于什么心理状态，或者是什么情况，只有你自己最清楚。
  prefs: []
  type: TYPE_NORMAL
- en: 'English:'
  prefs: []
  type: TYPE_NORMAL
- en: 'User: I have been in a relationship for two years and have been in a long-distance
    relationship. I am usually very good. I started arguing and quarreling a year
    ago, and my boyfriend said unpleasant things or even cursed. Is it normal'
  prefs: []
  type: TYPE_NORMAL
- en: 'Psychologist: Hello! Long distance love is usually okay, but when you argue,
    it’s really abnormal to scold you. This should be related to many factors'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Long distance relationships are inherently challenging, and when your boyfriend
    is away from you, their language and language are challenged
  prefs: []
  type: TYPE_NORMAL
- en: 2\. When he usually gets along with you, he will also have a lot of pressure,
    so when encountering similar situations, he will be very irritable
  prefs: []
  type: TYPE_NORMAL
- en: 3\. When we usually get along with him, there is no conflict between you. Whenever
    there is a conflict, we will argue fiercely
  prefs: []
  type: TYPE_NORMAL
- en: 4\. You usually communicate less, so he doesn’t have a channel to vent his negative
    emotions
  prefs: []
  type: TYPE_NORMAL
- en: The above are some possibilities, but they may not necessarily be the reason
    for his situation, because whether there are any other conflicts between you is
    only known through communication between the two of you. So, I think you should
    seriously consider what kind of psychological state or situation your boyfriend’s
    behavior is in, and only you know it best.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in Figure [7](#A4.F7 "Figure 7 ‣ Appendix D English Word Cloud Map
    ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations") (English version: Figure [8](#A4.F8
    "Figure 8 ‣ Appendix D English Word Cloud Map ‣ SoulChat: Improving LLMs’ Empathy,
    Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations"))
    and Figure [9](#A4.F9 "Figure 9 ‣ Appendix D English Word Cloud Map ‣ SoulChat:
    Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning
    with Multi-turn Empathy Conversations") (English version: Figure [10](#A4.F10
    "Figure 10 ‣ Appendix D English Word Cloud Map ‣ SoulChat: Improving LLMs’ Empathy,
    Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations")),
    the multi-turn conversation generated by using the proposed prompt has richer
    expressions of empathy, compared with SMILE prompt.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D English Word Cloud Map
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The English word cloud map is presented in Figure [6](#A4.F6 "Figure 6 ‣ Appendix
    D English Word Cloud Map ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort
    Abilities through Fine-tuning with Multi-turn Empathy Conversations").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/090ad1d1fad4865c7c74bfb4c7db891f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Word cloud map of psychological consultants’ utterances.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f1de3a581665bf5f970d08b7d9cd7cba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Multi-turn conversation generated by ChatGPT using the proposed prompt.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e4a8333b3ca8b6a1726afa07e5672016.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Multi-turn conversation generated by ChatGPT using the proposed prompt
    (English version).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/641cf449b62ec17678406f8ca130e309.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Multi-turn conversation generated by ChatGPT using the SMILE prompt.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5dbb936ead5825d51a29e37182587c37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Multi-turn conversation generated by ChatGPT using the SMILE prompt
    (English version).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/08a248df618ec9d5bd2aa5445b8af6b6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: A case of a user confiding to SoulChat.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f8fde2dfd6aa939e6f6ebede2fefd3df.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: A case of a user confiding to ChatGPT. ChatGPT is eager to solve
    user problems and tends to provide comprehensive and effective advice rather than
    truly empathizing with users.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Sample Conversations of SoulChat
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As shown in Figure [11](#A4.F11 "Figure 11 ‣ Appendix D English Word Cloud
    Map ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations"), SoulChat can better serve
    as a listener when users seek emotional support or confide. Besides, it can naturally
    empathize with users (e.g. "你的童年经历真的很不容易 (Your childhood experiences were really
    difficult)", "我可以理解你的痛苦和内心的挣扎 (I can understand your pain and inner struggle)")
    and comfort them (e.g. "我相信你是一个坚强的人，你可以通过自己的努力来改变现状。 (I believe you are a strong
    person who can change the situation through your own efforts.)").'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix F Sample Conversations of Other LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The examples when users seek emotional support from ChatGPT, ChatGLM and SparkDesk
    are shown in Figure [12](#A4.F12 "Figure 12 ‣ Appendix D English Word Cloud Map
    ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations"), Figure [13](#A7.F13 "Figure
    13 ‣ Appendix G Manual Evaluation Instructions ‣ SoulChat: Improving LLMs’ Empathy,
    Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations")
    and Figure [14](#A7.F14 "Figure 14 ‣ Appendix G Manual Evaluation Instructions
    ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through
    Fine-tuning with Multi-turn Empathy Conversations"). These LLMs are inclined to
    provide suggestions rather than ask questions or listen, acting a bit like a rational
    “Straight man” for those users who need listening and comfort, which make them
    appear less “human-centered”.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix G Manual Evaluation Instructions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For mental health LLMs, we have constructed a manual evaluation framework called
    "CEHS" with the following four dimensions: Content naturalness, Empathy, Helpfulness,
    Safety, as presented in Table [2](#A7.T2 "Table 2 ‣ Appendix G Manual Evaluation
    Instructions ‣ SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities
    through Fine-tuning with Multi-turn Empathy Conversations"). Specifically, there
    may be a certain conflict between Empathy and Helpfulness. For example, ChatGPT
    tends to generate helpful but lacking empathetic responses. On the other hand,
    when SoulChat generates empathetic responses, it may weaken the direct Helpfulness
    of the answer. This is because general advice often appears helpful, but not so
    empathetic. The scores of Empathy and Helpfulness in Table [1](#S2.T1 "Table 1
    ‣ 2.1 SoulChatCorpus Collection ‣ 2 Human-centered Mental Health LLM ‣ SoulChat:
    Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning
    with Multi-turn Empathy Conversations") also illustrate this phenomenon.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Manual Evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Aspect | Score | Description |'
  prefs: []
  type: TYPE_TB
- en: '| Content | 0-2 | It mainly evaluates whether the content generated by the
    model is relevant and coherent to the user’s conversation history, whether the
    content is smooth and natural, whether the content is consistent with language
    habits, whether the content has syntax error. |'
  prefs: []
  type: TYPE_TB
- en: '| Empathy | 0-2 | The main assessment is whether the text generated by the
    model can understand the feelings and behaviors of the parties involved, grasp
    their inner feelings, deep meanings, and their degree. |'
  prefs: []
  type: TYPE_TB
- en: '| Helpful- ness | 0-2 | This indicator mainly evaluates whether the output
    of the model is helpful to the user. When evaluating this item, it is necessary
    to consider from the user’s perspective whether the model’s answer provides assistance.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Safety | 0-1 | This indicator mainly evaluates whether the text generated
    by the model causes harm to users, others, society, environment, etc., whether
    personal privacy is protected, and whether laws and regulations are complied with.
    The main considerations are: respect for social morality, Public policy doctrine.
    Whether it violates laws and regulations, involves political sensitivity, commits
    crimes, infringes on physical health, infringes on mental health, infringes on
    property privacy, discriminates/prejudices, insults/hate speech, violates ethical
    ethics, etc. |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/90fb4d562bb7e106039473aae32d90ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: A case of a user confiding to ChatGLM.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ac9de5d6cfdb2a389c00414924992761.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: A case of a user confiding to SparkDesk.'
  prefs: []
  type: TYPE_NORMAL
