- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:38:00'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in
    Translation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.01940](https://ar5iv.labs.arxiv.org/html/2404.01940)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Veronica Valeros Department of Computer Science
  prefs: []
  type: TYPE_NORMAL
- en: Czech Technical University Prague, Czech Republic
  prefs: []
  type: TYPE_NORMAL
- en: valerver@fel.cvut.cz    Anna Širokova Rapid7
  prefs: []
  type: TYPE_NORMAL
- en: Prague, Czech Republic
  prefs: []
  type: TYPE_NORMAL
- en: anna_sirokova@rapid7.com    Carlos Catania School of Engineering
  prefs: []
  type: TYPE_NORMAL
- en: National University of Cuyo (UNCuyo) Prague, Czech Republic
  prefs: []
  type: TYPE_NORMAL
- en: harpo@ingenieria.uncuyo.edu.ar    Sebastian Garcia Department of Computer Science
  prefs: []
  type: TYPE_NORMAL
- en: Czech Technical University Prague, Czech Republic
  prefs: []
  type: TYPE_NORMAL
- en: sebastian.garcia@agents.fel.cvut.cz
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Understanding cybercrime communications is paramount for cybersecurity defence.
    This often involves translating communications into English for processing, interpreting,
    and generating timely intelligence. The problem is that translation is hard. Human
    translation is slow, expensive, and scarce. Machine translation is inaccurate
    and biased. We propose using fine-tuned Large Language Models (LLM) to generate
    translations that can accurately capture the nuances of cybercrime language. We
    apply our technique to public chats from the NoName057(16) Russian-speaking hacktivist
    group. Our results show that our fine-tuned LLM model is better, faster, more
    accurate, and able to capture nuances of the language. Our method shows it is
    possible to achieve high-fidelity translations and significantly reduce costs
    by a factor ranging from 430 to 23,000 compared to a human translator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: cybercrime, hacktivism, LLM, machine translation, model fine-tuning
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The escalation of the Russia-Ukraine war in 2022 has brought with it a large
    number of cyber-attacks [[6](#bib.bibx6), [8](#bib.bibx8)]. The war fuelled and
    instigated cyber-hacktivist groups to join in, which in turn influenced and sustained
    more cyber operations. Many cyber-hacktivist groups quickly pledged allegiance
    to one side or the other [[11](#bib.bibx11)], generating a massive increase in
    cyber attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Given the participation of cyber-hacktivists in the war, it has become paramount
    to interpret their online campaigns in a time-efficient manner in order to better
    understand their tactics, motivations, and alliances. A better understanding of
    this evolving landscape contributes to the implementation of effective countermeasures [[15](#bib.bibx15),
    [11](#bib.bibx11)].
  prefs: []
  type: TYPE_NORMAL
- en: The main problem that this research addresses is that manually translating and
    analysing online chats in Russian-language groups is hard, costly [[34](#bib.bibx34)],
    slow, not scalable, biased, inaccurate, and exposes human analysts to toxic and
    disturbing content [[3](#bib.bibx3)]. Additionally, analysts who can accurately
    produce translations are scarce, and analysts do not know all languages with sufficient
    proficiency [[29](#bib.bibx29)].
  prefs: []
  type: TYPE_NORMAL
- en: Translating is difficult because of the complexity given by cultural differences,
    jargon, Internet slang, and inner terminology. It is costly because human translators
    are scarce, their time is very valuable, and often, many are needed even to understand
    one individual group, thus limiting the possible number of translations. Translating
    is slow, averaging 2,000 words per day per translator [[23](#bib.bibx23)], making
    it not scalable for the hundreds of thousands of chats online, given that a single
    group can produce more than 1,000 words in one day. Also, there is the issue of
    uncontrolled human bias, given translators will vary in their experiences, expertise,
    tiredness and availability. Translating has inaccuracies, as human translators
    also need to learn and understand the language nuances and the context of the
    translations.
  prefs: []
  type: TYPE_NORMAL
- en: Human translators also face an additional challenge regarding the type of content.
    They are susceptible to hate speech and inflammatory material, which is one of
    the reasons that it is unhealthy to have any one translator exposed to this type
    of content for an extended period, thus increasing the time and cost [[3](#bib.bibx3)].
  prefs: []
  type: TYPE_NORMAL
- en: Another important challenge lies in the ability to process and study thousands
    of these messages in a time-efficient manner. At the time of writing, state-of-the-art
    shows that real-time processing of these messages using machine translation is
    not possible [[17](#bib.bibx17)]. Solutions like Google Translate [[10](#bib.bibx10)]
    or DeepL [[7](#bib.bibx7)] introduce important mistakes, such as translating a
    URL, which forces the need to have human analysts validate and correct the translations.
  prefs: []
  type: TYPE_NORMAL
- en: Several methods have been proposed to address different parts of the previously
    mentioned problems. Human translation is possibly the most common method, with
    the translators trying to obtain some knowledge of the subject, albeit with the
    previously discussed limitations [[28](#bib.bibx28)]. Machine translation was
    used for cybercrime Twitter translation [[29](#bib.bibx29)]. However, it was a
    hybrid approach, with humans verifying the translation and categories by hand.
    Machine translation has its own limitations, such as biases and inaccuracies [[20](#bib.bibx20)].
    In addition, machine translation alone may be insufficient, given the translation
    does not only include content typically present in conversations. Common problems
    include mistranslating punctuation, URLs, slang, emojis, humour, and a lack of
    consistency in naming conventions.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome most of these limitations, we propose to study and eventually fine-tune
    a cloud-based Large Language Model (LLM) with curated translations of cyber-hacktivism
    chat messages. Cloud-based LLMs were trained with a large amount of data, documents,
    and expertise in many languages. By default, vanilla LLMs may not be sufficient
    to translate the messages accurately [[31](#bib.bibx31)]. Therefore, we propose
    to fine-tune models to learn the specifics of the hacktivist groups’ messages
    to generate better, faster, cheaper, and more accurate translations.
  prefs: []
  type: TYPE_NORMAL
- en: Our methodology consists of downloading a large number of Russian-language chats
    from the public online Telegram channel of the cyber-hacktivist group NoName057(16) [[22](#bib.bibx22)],
    and a combination of several vanilla cloud-based LLM models, local-based LLM models,
    and human translators to fine-tune a cloud-based LLM. The dataset was split into
    training and testing sets to evaluate the performance of the system in unseen
    messages. The models were evaluated and compared by a test group of native Russian
    speakers with cybersecurity knowledge who did not participate in the original
    translation.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the fine-tuned LLM model with the not fine-tuned model and measuring
    differences with human translators shows that our fine-tuned model based on GPT-3.5-turbo
    obtained the best performance. These models performance was also measured with
    BLUE (0.347), METEOR (0.711), and TER (47.792) metrics. In a blind test, human
    translators choose the fine-tuned model as the best translation in 64.08% of the
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: Such an accurate model for Russian-based cybercrime chats allows the research
    community to have a cheaper, faster, and more accurate cybercrime-oriented translation
    of Russian text to English. We hope this will allow for more timely and accurate
    translations and to better understanding of cyber-hacktivism activities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contributions of this paper are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publication of a manually translated and curated dataset of a selection of NoName057(16)
    chat messages.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A thorough comparison of various LLM-based translation methods with human translators.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methodology on how to generate a fine-tuned model from cybercrime chats.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two public tools for collection and translation of text from Russian to English.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The reviewed literature focuses on three main areas. First, we review studies
    on translations from cyber-hacktivism chats or alike, specifically Russian-English
    translations that include jargon. Second, we review previous efforts on machine
    translation in the context of cybersecurity and its limitations. Third, we review
    existing work on the use of Large Language Models (LLMs) for translation in the
    context of cybersecurity. While most approaches to produce advances in this area
    have been focused on underground forums, there are no specific evaluations of
    hacktivist public broadcasting channels that are so prevalent today and are the
    focus of this work.
  prefs: []
  type: TYPE_NORMAL
- en: The task of translating content from the cybercrime world is challenging, as
    it is filled with jargon, internet slang, emojis, and other content that current
    machine translation (MT) methods fail to capture and translate correctly [[18](#bib.bibx18),
    [30](#bib.bibx30)]. Manatova et al. [[18](#bib.bibx18)] argue that current machine
    translation is not capable of capturing dark humour, jokes, and other aspects
    of how underground actors communicate. Specifically, the authors mention that
    correctly understanding these nuances of the language can help better understand
    attackers’ motivations, strategies, and other social dynamics that are key in
    cyber threat research. Seyler et al. [[30](#bib.bibx30)] further emphasise the
    challenges of understanding the dark jargon in underground forums where mistranslated
    or misinterpreted words can lead to the wrong classification of content.
  prefs: []
  type: TYPE_NORMAL
- en: The limitations of machine translation in the context of cybersecurity have
    already been discussed thoroughly in [[18](#bib.bibx18)], where authors highlight
    how state-of-the-art MT in content from underground forums and other jargon-loaded
    content leads to semantic loss and directly affects the efficacy of cyber threat
    identification. Ebrahimi et al.  [[9](#bib.bibx9)] remark that the three key drawbacks
    of MT are that they omit language-specific semantics, miss hacker-specific jargon,
    and rely on separate monolingual models for each language. This results in mistranslations
    or incomplete ones. Moreover, Michel and Neubig [[20](#bib.bibx20)] observed that
    a large portion of research in the MT field relies on synthetically generated
    datasets for model evaluation. They noted that these datasets lack noise, such
    as emojis, internet slang, profanities, and other linguistic complexities, which
    cybercrime forums and chats are known to have. This further emphasises the inadequacy
    of MT and its tendency to produce inaccurate translations in such environments.
  prefs: []
  type: TYPE_NORMAL
- en: The use of LLMs for translation is an emerging topic that promises to resolve
    some machine translation shortcomings. Nikolich and Puchkova [[21](#bib.bibx21)]
    fine-tuned a GPT-3 model using a Russian dataset to produce an English translation,
    producing promising results. Nevertheless, the approach still presented limitations,
    especially when respecting essential elements of the text, such as names, surnames,
    places, and dates.
  prefs: []
  type: TYPE_NORMAL
- en: Both Zhu et al. [[35](#bib.bibx35)] and Jiao et al. [[14](#bib.bibx14)] evaluated
    ChatGPT with GPT-3.5 and GPT-4 in translation tasks and compared it to other translation
    methods. Their work shows the promises of GPT-4, noting challenges in languages
    that may be more distant from English, such as Chinese. In both cases, the ChatGPT
    platform is used and not the OpenAI-specific models, which makes it harder to
    know precisely which version of the models was used. Manakhimova et al. [[17](#bib.bibx17)]
    conducted a systematic translation comparison primarily from English to other
    two languages with 37 translation systems. While GPT-4 performance was good, it
    was outperformed by other techniques and approaches. Among the main challenges
    listed by the authors are the linguistic nuances, which are significant in our
    focus area.
  prefs: []
  type: TYPE_NORMAL
- en: In [[28](#bib.bibx28)], authors show how fine-tuning and prompt engineering
    can be used in LLMs for augmented MT. While the evaluation shows that the human
    translation is overall better, the combination of fine-tuning and prompt engineering
    can produce better results and help reduce the human input to the most needed
    tasks, like post-editing. Similarly, Siu [[31](#bib.bibx31)] showed how LLM models
    can help in various translation tasks such as error detection and grammar checking,
    further helping use the costly and expensive human input in more critical tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Peng et al. [[27](#bib.bibx27)] proposed to improve MT using Chat-GPT and Domain-Specific-Prompts
    (DSP) through the prompts. They concluded that this method indeed improves the
    translation. However, they also pointed out that their prompts were not designed
    to test ChatGPT abilities fully.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The raw data used for this study contains 5,455 text messages extracted from
    the Telegram public channel of the hacktivist group NoName057(16) [[22](#bib.bibx22)],
    spanning from the creation of the channel on March 11, 2022, to December 26, 2023\.
    The Telegram channel, shown in Figure [1](#S3.F1 "Figure 1 ‣ 3 Methodology ‣ Towards
    Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation"),
    is an open public channel that anyone can read anonymously. The data was collected
    by developing a custom Python tool.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/016302efad34d2f64eb135e097522ac9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Public Telegram channel of the NoName057(16) hacktivist group, in
    Russian, where they showcase and publicise their activity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The methodology is composed of (i) creating a dataset from the Telegram chats;
    (ii) using eight different LLM models to translate the messages (both cloud and
    local); (iii) a translator selecting the best translation (train translator);
    (iv) training a fine-tuned model; (v) comparing all models and evaluating with
    a new group of translators (test translators); (vi) evaluating the results with
    analytical metrics. Figure [2](#S3.F2 "Figure 2 ‣ 3 Methodology ‣ Towards Better
    Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation") shows
    the detailed steps.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e39e74c2516b78ade9c2ec25c29ccb0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The hacktivist group messages were processed first to compare existing
    translation methods and select the best one, using the output and the expert input
    to produce ground truth and fine-tune the selected LLM model, and finally, generating
    the data needed for the human and automatic evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Creation of the dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The chat messages of the Telegram channel of the group NoName057(16) between
    March 11, 2022, and December 26, 2023, were downloaded with our open-source tool
    called Spylegram [[2](#bib.bibx2)], that accesses the Telegram API using the Telethon
    library [[16](#bib.bibx16)] and stores them in a SQLite database.
  prefs: []
  type: TYPE_NORMAL
- en: The first 130 messages were selected (chronologically) for the training, evaluation,
    and testing. A hundred messages were used for training and validation, while 30
    were reserved only for testing and never used in the creation of the models.
  prefs: []
  type: TYPE_NORMAL
- en: The native Russian expert was asked to manually translate all 130 messages from
    Russian to English and generate the ground truth translation. The complete dataset
    had 130 rows with the original message in Russian and the ground truth translation
    in English.
  prefs: []
  type: TYPE_NORMAL
- en: This dataset of 130 messages was split into 100 messages for training/validation
    and 30 for testing ¹¹1The link to the dataset has been omitted for anonymization
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Later, during fine-tuning, the 100 messages of training/validation were augmented
    with 25 messages of vocabulary to complete the 125 messages of the dataset for
    fine-tuning, as shown in Figure [2](#S3.F2 "Figure 2 ‣ 3 Methodology ‣ Towards
    Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation").'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Using current LLMs as a Translation Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first 100 messages in the dataset were translated with the following eight
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Translate (Deep Neural Nets, cloud) [[10](#bib.bibx10)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepL (Deep Neural Nets, cloud) [[7](#bib.bibx7)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-3.5-turbo-0125 (LLM, cloud) [[25](#bib.bibx25)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mistral (LLM, local) [[13](#bib.bibx13)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural chat (LLM, local) [[12](#bib.bibx12)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zephyr (LLM, local) [[33](#bib.bibx33)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-4 prompt 1 (LLM, cloud) [[24](#bib.bibx24)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-4 prompt 2 (LLM, cloud) [[24](#bib.bibx24)]
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In total, 800 translations were produced. The same native Russian expert who
    generated the ground truth evaluated the translations for each of the 100 messages.
    For each message, the expert selected which method generated the best translation.
    The top selected method was then chosen for the next stage.
  prefs: []
  type: TYPE_NORMAL
- en: The LLM translations were orchestrated with our own tool, called HermeneisGPT [[1](#bib.bibx1)].
    The tool is able to translate messages using a given prompt using OpenAI API and
    storing the translation along with the translation parameters on an SQLite DB.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 LLM Fine-tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Russian expert selected an LLM model as the best model in the training dataset.
    We decided to fine-tune it to adapt it to the nuances of the Russian language
    cybercriminal world. Fine-tuning consists of improving the LLM model by giving
    as input a new dataset with the correct expected outputs. In our case, the correct
    expected outputs were the corrections of the native Russian expert over the translated
    messages of the best model on training data. The native Russian expert also provided
    new vocabulary and its correct translation based on the errors made by the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset used for fine-tuning has three parts: (i) a prompt with instructions,
    (ii) the original message in Russian, and (iii) the correct translation. In some
    cases, the correct translation is the improvement of the Russian expert upon the
    output of the best model during training; in others, it is the correct translation
    of a word. In total, there are 130 Russian texts along with their correct English
    translation.'
  prefs: []
  type: TYPE_NORMAL
- en: The prompt for fine-tuning used sentences with clear directives and incorporated
    feedback from the language expert. It emphasised respecting URLs, names, links,
    dates, and other important information. The full prompt is shown in Appendix I.
  prefs: []
  type: TYPE_NORMAL
- en: The original ground-truth 100 messages for training/validation were augmented
    with 25 vocabulary corrections, to sum up to 125 messages in the fine-tuning dataset.
    This fine-tuning dataset was split using an 80/20 separation into fine-tuning
    training (100 messages) and fine-tuning validation (25 messages). The split was
    done so that the specialised vocabulary generated by the Russian expert was present
    only in the training, with the rest of the messages randomised. The validation
    data was composed only of hacktivist messages.
  prefs: []
  type: TYPE_NORMAL
- en: The fine-tuning was done through the OpenAI web platform, using the base model
    gpt-3.5-turbo-0125 with training data up to September 2021, which was the best
    model chosen by the language expert.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset used for fine-tuning is in JSONL format, the standard from OpenAI.
    Each JSONL in the dataset contains a message with three key roles: the system
    role contains the prompt, the user role contains the message in Russian, and the
    assistant role contains the English translation’s ground truth. The template for
    each entry in the dataset used for fine-tuning is shown in Figure [3](#S3.F3 "Figure
    3 ‣ 3.3 LLM Fine-tuning ‣ 3 Methodology ‣ Towards Better Understanding of Cybercrime:
    The Role of Fine-Tuned LLMs in Translation").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/19a49927d04f1f37abbf88a9d9f1537c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: The dataset used for fine-tuning has a JSONL format, where each line
    contains a message with three keys. Each key represents a role: system, user,
    and assistant.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Human Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our first evaluation of whether our fine-tuned LLM model is better than the
    non-fine-tuned LLM model was done using a new test group of human translators.
    Human evaluation is arguably the most important and precise type of comparison,
    given humans are much better than any tool at evaluating the quality of translations [[5](#bib.bibx5)].
  prefs: []
  type: TYPE_NORMAL
- en: The evaluation methodology consisted of asking native Russian speakers with
    technical background if, given the original Russian text, they preferred the translation
    of the original LLM model or the fine-tuned LLM model. The interaction was done
    using an online form where the experiment was explained in full, the privacy disclosure
    was done, and the voting was performed for 30 questions.
  prefs: []
  type: TYPE_NORMAL
- en: For each question, respondents were presented with an original hacktivist message
    in Russian, the translation by the base LLM model, and the translation by the
    fine-tuned LLM model. The survey was configured in a way that the respondents
    did not know which translation belonged to which model. The position of the model
    translations was randomised from question to question, making it harder for respondents
    to guess which model was which.
  prefs: []
  type: TYPE_NORMAL
- en: 'The survey included two questions regarding the respondents’ knowledge. The
    first question asked them to self-assess their English proficiency at European
    standard language levels. The three options were A1/A2, B1/B2, and C1/C2\. The
    second question asked them to self-assess their cybersecurity knowledge. The four
    options were: 1\. Beginner, I have a basic understanding of cybersecurity concepts;
    2\. Intermediate, I have moderate experience, and I’m familiar with routine cybersecurity
    concepts; 3\. Advanced, I have extensive experience, and I am knowledgeable in
    complex cybersecurity concepts; 4\. Expert, I am highly knowledgeable and recognised
    as an authority in the field of cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Quantitative Evaluation with Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The methodology for the automatic evaluation consisted of using three well-known
    automatic machine translation methods BLEU, METEOR, TER. These methods take as
    input and compare the ground truth translation and the candidate translation.
  prefs: []
  type: TYPE_NORMAL
- en: BLEU, BiLingual Evaluation Understudy [[26](#bib.bibx26)], assigns a score ranging
    from zero to one, indicating how closely the machine translation aligns with the
    reference translation (1 is better). METEOR, Evaluation of Translation with Explicit
    Ordering [[4](#bib.bibx4)], calculates a score using unigram precision, unigram
    recall, and their combined harmonic F1 score. It puts particular emphasis on accuracy,
    fluency, and word order and scores the similarity ranging from 0 to 1 (1 is better).
    TER, Translation Edit Rate [[32](#bib.bibx32)], estimates the level of editing
    required by a human to align a system output with a reference translation (0 is
    better).
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Ethical Considerations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The human evaluation part of this study involved human participants. As such,
    we received approval from our university’s institutional review board (IRB) to
    ensure compliance with ethical guidelines and regulations.
  prefs: []
  type: TYPE_NORMAL
- en: The survey was conducted using the SurveyMonkey platform. No personally identifiable
    information was collected from the participants. The participants were warned
    beforehand that the messages could contain hate speech, propaganda and other inflammatory
    material and that the participation was entirely voluntary. Participants were
    offered the option to exit the survey at any time.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experiments and Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The human evaluation included 7 respondents, which produced a total of 103 answers.
    When asked about their level of English proficiency, 100% of the respondents reported
    an advanced level of English (C1/C2). When asked about their level of cybersecurity
    knowledge, 14% reported a basic level, 57% reported an intermediate level, 0%
    reported an advanced level, and 29% reported an expert level.
  prefs: []
  type: TYPE_NORMAL
- en: The results from the survey indicate that participant translators prefer the
    fine-tuned LLM model in 64.08% of the cases. In contrast, the base LLM model without
    fine-tuning was chosen in 35.92% of cases.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Statistical Analysis of Survey Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We employed a Generalized Linear Mixed Model (GLMM) [[19](#bib.bibx19)] to examine
    the effect of different modeling approaches on participants’ preferences. We considered
    LLM model as a fixed effect and both question and participant as random effects.
    We use a logit link function to model the odds of preference as a function of
    the fixed effect (LLM model) and random intercepts for question and participant.
    This setup allows us to account for within-participant and within-paragraph variations
    in preferences, acknowledging that responses might be clustered by these factors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we applied an ANOVA test using Type III Wald Chi-square Tests to analyse
    the significant differences in the results. The final results are presented in
    Table [I](#S4.T1 "Table I ‣ 4.1 Statistical Analysis of Survey Results ‣ 4 Experiments
    and Results ‣ Towards Better Understanding of Cybercrime: The Role of Fine-Tuned
    LLMs in Translation")'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table I: Analysis of Deviance Table (Type III Wald Chi-square Tests)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Term | $\chi^{2}$) |'
  prefs: []
  type: TYPE_TB
- en: '| (Intercept) | 7.9409 | 0.004833 |'
  prefs: []
  type: TYPE_TB
- en: '| model | 15.8819 | 6.742e-05 |'
  prefs: []
  type: TYPE_TB
- en: The intercept, representing the log odds of preference being 1 when all predictors
    variables are at their reference levels, is significantly different from zero
    (p-value = 0.004833), suggesting a baseline preference that is distinct from a
    neutral standpoint. Furthermore, the analysis reveals that the effect of the model
    when comparing the reference base LLM to the fine-tuned LLM model —is highly significant
    (p-value = 6.742e-05), demonstrating a strong influence of the translator type
    on the preference outcome. This level of significance underscores the substantial
    impact that different models have on shaping preferences, affirming the importance
    of the model variable in the analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Quantitative Analysis of Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Following the methodology presented in Section [3](#S3 "3 Methodology ‣ Towards
    Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation"),
    we also used algorithms to measure the similarity of the LLM-based translations
    with the ground truth. Table [II](#S4.T2 "Table II ‣ 4.2 Quantitative Analysis
    of Results ‣ 4 Experiments and Results ‣ Towards Better Understanding of Cybercrime:
    The Role of Fine-Tuned LLMs in Translation") shows the scores achieved by the
    gpt-3.5-turbo-0125 (base model) and ft:gpt-3.5-turbo-0125 (fine-tuned) translations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table II: Main Metrics Comparison between the base LLM model gpt-3.5-turbo-0125
    and fine-tuned LLM model ft:gpt-3.5-turbo-0125'
  prefs: []
  type: TYPE_NORMAL
- en: '| Metric | Base LLM model | Fine-tuned LLM model |'
  prefs: []
  type: TYPE_TB
- en: '| gpt-3.5-turbo-0125 | ft:gpt-3.5-turbo-0125 |'
  prefs: []
  type: TYPE_TB
- en: '| BLEU | 0.3523 ± 0.0912 | 0.3477 ± 0.0968 |'
  prefs: []
  type: TYPE_TB
- en: '| METEOR | 0.6914 ± 0.0583 | 0.7119 ± 0.0833 |'
  prefs: []
  type: TYPE_TB
- en: '| TER | 46.6983 ± 9.5051 | 47.7292 ± 10.0451 |'
  prefs: []
  type: TYPE_TB
- en: 5 Analysis of Both Evaluations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regarding the analysis of results from the humans and algorithms, results suggest
    that the fine-tuned model may produce, in general, better translations than the
    base model. However, these evaluations do not explain the translations’ difficulties,
    subtleties, and intricacies.
  prefs: []
  type: TYPE_NORMAL
- en: When analysing the human evaluation, we found that it was not an easy task for
    them. For example, feedback from respondents was that the two translation options
    were very similar, and it was hard to spot the differences. Respondents also mentioned
    they were “irritated” and “triggered” by the messages they were asked to review,
    that they had to “take breaks”, and that they “would not imagine spending more
    time doing this work”. This is corroborated by the fact that only 42% of the respondents
    were able to complete the survey in its totality. At the same time, the other
    58% spent an average of 30 minutes before exiting the survey. This further highlights
    the importance of having automated tools that are not affected by such emotions,
    take no sides, and do not get tired.
  prefs: []
  type: TYPE_NORMAL
- en: 'The quantitative metrics used to measure the distance between the translations
    produced by the fine-tuned model and the base model, when compared to the ground
    truth translation, slightly favour the base model. METEOR was the only metric
    found to prefer the fine-tuned model. A case-by-case analysis of these results
    shows that these metrics are not representative of the quality of the translations
    and can be misleading. In Figure [4](#S5.F4 "Figure 4 ‣ 5 Analysis of Both Evaluations
    ‣ Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation"),
    we present a case where the three metrics chose the base model translation over
    the fine-tuned model translation. The message ground truth, composed of two paragraphs,
    is shown alongside their translations generated by both the base model and the
    fine-tuned model. A human can clearly see how the base model translation is incorrect
    by using the word attached, and the fine-tuned model is able to understand better
    the context and understand the message is referring to something being attacked.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a0989820e29c9a144804cbf69dad1011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: A hacktivist message ground truth (black, top), alongside the translations
    by the base LLM model (green, middle) and fine-tuned model (blue, bottom). The
    three metrics chose the base-model translation when, as can be seen, the best
    translation is generated by the fine-tuned model.'
  prefs: []
  type: TYPE_NORMAL
- en: Traditional MT, such as DeepL and Google Translate, have a tendency to translate
    the given text literally, word for word. In contrast, LLMs are able to interpret
    the context and extrapolate missing words to generate a better translation.
  prefs: []
  type: TYPE_NORMAL
- en: Ranade et al. [[29](#bib.bibx29)] used LSTM-based neural machine translation
    to translate text extracted from social media matching specific cybersecurity
    terminology from Russian to English. Their method achieved a BLEU score of 28.4\.
    The authors compare the system to Google Translate, but BLEU score metrics are
    not provided. Our method shows a higher score.
  prefs: []
  type: TYPE_NORMAL
- en: Our cost analysis shows that the proposed method is 430 to 23000 times cheaper
    than a human translator, depending on the cost of the translation service. Translations
    made by a native Russian cybersecurity analyst are estimated to cost 0.21$ per
    message, in contrast to specialised services, which may cost up to 0.21$ per word
    but produce very high fidelity and accurate translations.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Qualitative Analysis of Translation Errors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The evaluation of messages is a very difficult task. Often, translations may
    contain tiny differences that can have a significant impact on the overall meaning.
    A wrong character in a URL can render it unusable and hamper intelligence collection.
    The use of LLMs in translation can help correct small mistakes, although at a
    high cost. In this subsection, we analyse some common errors where the use of
    LLMs shows improved performance over traditional MT methods.
  prefs: []
  type: TYPE_NORMAL
- en: Wrong Handling of URLs. A critical error when using MT is the modification of
    URLs, where the edition of a single character can render the URL useless. This
    error is common when using Google Translate, which often changes the URLs. For
    example, We-are-not-alone.ru translated to We-Ra-not-alone.ru, strana.today to
    Strana.tude, and espreso.tv to Espresso.TV. The base LLM model and the fine-tuned
    model were both able to respect the instructions and did not modify the URLs.
  prefs: []
  type: TYPE_NORMAL
- en: Wrong Handling of Emoji. Another error when using MT is the difficulty in handling
    special characters, in particular emojis. The use of emoji is prevalent in hacktivist
    messages. Google Translate tends to remove the emoji completely from the message.
    Open-source LLM models often replace the emoji with text interpretations, with
    different emoji, or with a combination of emojis. DeepL performed well, sometimes
    duplicating emojis. The base LLM model and the fine-tuned model were both able
    to respect the instructions and did not modify them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Missed puns, humour, and play of words. Another limitation of MT is their inability
    to understand humour, puns, jokes and plays on words. One salient example is a
    pun the hacktivist group did on an attack on the news site “Segodnya”. In Russian,
    “Segodnya” means “today”. The original pun used was “Каламбур: сегодня у «Сегодня»
    не задалось.”, which correctly interpreted means “A pun: Today did not go well
    for “Segodnya” [today]”. Google Translate fails to capture the meaning with its
    translation “Kalamble: Today, ”today” did not set.”. Open-source LLM models and
    DeepL failed to capture the pun as well. The base LLM model and the fine-tuned
    model were both able to capture the pun correctly.'
  prefs: []
  type: TYPE_NORMAL
- en: Poor translation of jargon. The correct translation of jargon is a known issue
    of MT methods. Google Translate performs poorly in this area. For example, “Толстосумы”
    is translated as “heaps of dough”, but it should be “Moneybags”; “DDOS-атаки”
    is translated to “DDOS adjectives”, but it should be “DDoS-attacks”; and “айтишник”
    is translated to “ITISHNIK” but it should be “person who works in IT”. Open-source
    LLM models, DeepL, and the base model all fail to capture these to some degree.
    The fine-tuned model performs better when taught, which is one of the clear advantages
    in this context.
  prefs: []
  type: TYPE_NORMAL
- en: Wrong translations of words. Other errors of mistranslation of words or expressions
    are also common. Google Translate fails to translate some common expressions,
    often translating word-for-word and losing context. For example, “Недо-хакеры”
    is translated as “non-chairs”, but it should be “wannabe hackers”; “А нас за шо?”
    is translated to “And we are for sho?”, but it should be “Why us?”, and “Ахи-вздохи”
    is translated as “Ahi-sizdokhs”, but it should be “signs and moans”. Open-source
    models perform better depending on the context. The fine-tuned model performs
    slightly better as it seems to contextualise the words better.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our research shows that with small ground truth data, it is possible to fine-tune
    an LLM model that will produce better translations of cyber-hacktivist groups
    than those of traditional machine translation methods. Translations are faster,
    more accurate, and are not susceptible to toxic or inflammable content. With proper
    training, LLM models can be taught the nuances of the language and jargon much
    more accurately than other MT methods. Furthermore, we showed how fine-tuned LLM
    models can help produce translations significantly cheaper than human translators,
    making translation scalability primarily dependent on money. Biases are still
    present, mainly when working with close source models.
  prefs: []
  type: TYPE_NORMAL
- en: The use of a fine-tuned LLM model shows clear benefits, including respect for
    the punctuation, the emojis, the URLs, using appropriate formality levels in the
    language that is closer to the original, and understanding word plays and humour
    from the original text. This creates the opportunity for a more rich and in-depth
    analysis of chats and messages.
  prefs: []
  type: TYPE_NORMAL
- en: Using closed platforms such as OpenAI has its challenges. On more than one occasion,
    the translation of messages or fine-tuning tasks were automatically cancelled
    due to violations of the terms and conditions. We discovered the messages were
    flagged by OpenAI as containing hate speech. The inability to do research should
    not be constrained by restrictions from third-party private companies. This is
    why one of the main areas we aim to move forward is reproducing these results
    using open models. Furthermore, fine-tuned models through OpenAI cannot be publicly
    shared, restricting researchers from sharing models and furthering the discussion
    and collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: Our future work includes expanding this work to fine-tune open models to match
    current performance levels, cut costs, and share fine-tuned models openly with
    the community. Future work also includes the use of this output in a pipeline
    of intelligence analysis. If messages can be accurately translated, they can be
    further studied in real time to produce timely intelligence and analysis that
    can be used for defence.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Acknowledgements are anonymized for blind review.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Anonymized Repository “hermeneisGPT” URL: [https://anonymous.4open.science/r/hermeneisGPT-8EDA/README.md](https://anonymous.4open.science/r/hermeneisGPT-8EDA/README.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Anonymized Repository “Spylegram” URL: [https://anonymous.4open.science/r/Spylegram-47B4/README.md](https://anonymous.4open.science/r/Spylegram-47B4/README.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Arnav Arora et al. “Detecting Harmful Content on Online Platforms: What
    Platforms Need vs. Where Research Efforts Go” In *ACM Computing Surveys* 56.3,
    2024, pp. 1–17 DOI: [10.1145/3603399](https://dx.doi.org/10.1145/3603399)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Satanjeev Banerjee and Alon Lavie “METEOR: An Automatic Metric for MT Evaluation
    with Improved Correlation with Human Judgments” In *Proceedings of the ACL Workshop
    on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or
    Summarization* Ann Arbor, Michigan: Association for Computational Linguistics,
    2005, pp. 65–72 URL: [https://aclanthology.org/W05-0909](https://aclanthology.org/W05-0909)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Shihua Brazill “ANALYSIS OF HUMAN VERSUS MACHINE TRANSLATION ACCURACY”
    Number: 1-4 December In *Intermountain Journal of Sciences* 21.1-4 December, 2015,
    pp. 106–107 URL: [https://arc.lib.montana.edu/ojs/index.php/IJS/article/view/993](https://arc.lib.montana.edu/ojs/index.php/IJS/article/view/993)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] CyberPeace Institute “Timeline of Cyberattacks and Operations — CyberPeace
    Institute” In *Timeline of Cyberattacks and Operations*, 2024 URL: [https://cyberconflicts.cyberpeaceinstitute.org/threats/timeline](https://cyberconflicts.cyberpeaceinstitute.org/threats/timeline)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] DeepL SE “DeepL Translate: The world’s most accurate translator” DeepL
    SE, 2024 URL: [https://www.deepl.com/translator](https://www.deepl.com/translator)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Stéphane Duguin and Pavlina Pavlova “The role of cyber in the Russian war
    against Ukraine: Its impact and the consequences for the future of armed conflict”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Mohammadreza Ebrahimi, Sagar Samtani, Yidong Chai and Hsinchun Chen “Detecting
    Cyber Threats in Non-English Hacker Forums: An Adversarial Cross-Lingual Knowledge
    Transfer Approach” In *2020 IEEE Security and Privacy Workshops (SPW)*, 2020,
    pp. 20–26 DOI: [10.1109/SPW50608.2020.00021](https://dx.doi.org/10.1109/SPW50608.2020.00021)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Google LLC “Google Translate” Google LLC, 2024 URL: [https://translate.google.com/](https://translate.google.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Insikt Group® “Dark Covenant 2.0: Cybercrime, the Russian State, and War
    in Ukraine — Recored Future” In *Dark Covenant 2.0: Cybercrime, the Russian State,
    and the War in Ukraine*, 2023 URL: [https://www.recordedfuture.com/dark-covenant-2-cybercrime-russian-state-war-ukraine](https://www.recordedfuture.com/dark-covenant-2-cybercrime-russian-state-war-ukraine)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Intel(R) Neural Compressor “Supervised Fine-Tuning and Direct Preference
    Optimization on Intel Gaudi2” In *Intel Analytics Software*, 2023 URL: [https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3](https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Albert Q. Jiang et al. “Mistral 7B” arXiv:2310.06825 [cs] arXiv, 2023
    DOI: [10.48550/arXiv.2310.06825](https://dx.doi.org/10.48550/arXiv.2310.06825)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Wenxiang Jiao, Wenxuan Wang, Jen-Tse Huang and Xing Wang “Is ChatGPT A
    Good Translator? A Preliminary Study”, 2023 URL: [https://www.researchgate.net/publication/367359399_Is_ChatGPT_A_Good_Translator_A_Preliminary_Study](https://www.researchgate.net/publication/367359399_Is_ChatGPT_A_Good_Translator_A_Preliminary_Study)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] KELA Cybercrime Intelligence Center “Beyond Donations: How Hacktivist
    Groups Fund Their Operations”, pp. 37 URL: [https://www.kelacyber.com/wp-content/uploads/2023/08/Research-by-KELA_How-Hacktivist-Groups-Fund-Their-Operations.pdf](https://www.kelacyber.com/wp-content/uploads/2023/08/Research-by-KELA_How-Hacktivist-Groups-Fund-Their-Operations.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] LonamiWebs “Telethon” In *GitHub*, 2023 URL: [https://github.com/LonamiWebs/Telethon](https://github.com/LonamiWebs/Telethon)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Shushen Manakhimova et al. “Linguistically Motivated Evaluation of the
    2023 State-of-the-art Machine Translation: Can ChatGPT Outperform NMT?” In *Proceedings
    of the Eighth Conference on Machine Translation* Singapore: Association for Computational
    Linguistics, 2023, pp. 224–245 DOI: [10.18653/v1/2023.wmt-1.23](https://dx.doi.org/10.18653/v1/2023.wmt-1.23)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Dalyapraz Manatova et al. “An Argument for Linguistic Expertise in Cyberthreat
    Analysis: LOLSec in Russian Language eCrime Landscape” In *2023 IEEE European
    Symposium on Security and Privacy Workshops (EuroS&PW)* Delft, Netherlands: IEEE,
    2023, pp. 170–176 DOI: [10.1109/EuroSPW59978.2023.00024](https://dx.doi.org/10.1109/EuroSPW59978.2023.00024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Charles E. Mcculloch and John M. Neuhaus “Generalized Linear Mixed Models”
    In *Wiley StatsRef: Statistics Reference Online* John Wiley & Sons, Ltd, 2014
    URL: [https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat07540](https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat07540)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Paul Michel and Graham Neubig “MTNT: A Testbed for Machine Translation
    of Noisy Text” arXiv:1809.00388 [cs] arXiv, 2018 URL: [http://arxiv.org/abs/1809.00388](http://arxiv.org/abs/1809.00388)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Alexandr Nikolich and Arina Puchkova “Fine-tuning GPT-3 for Russian Text
    Summarization” In *ArXiv*, 2021 URL: [https://www.semanticscholar.org/paper/eb18be41441260c40cdee36f17fc7ad48f426c5f](https://www.semanticscholar.org/paper/eb18be41441260c40cdee36f17fc7ad48f426c5f)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] NoName057(16) “NoName057(16) Telegram Channel” In *Telegram*, 2024 URL:
    [https://t.me/s/noname05716](https://t.me/s/noname05716)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Ofer Tirosh “What is the average translation speed?” In *Tomedes*, 2016
    URL: [https://www.tomedes.com/translator-hub/what-average-translation-speed.php](https://www.tomedes.com/translator-hub/what-average-translation-speed.php)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Open AI “ChatGPT [GPT-4]” URL: [https://chat.openai.com](https://chat.openai.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] “OpenAI GPT-3 API [gpt-3.5-turbo-0125]”, 2024 URL: [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu “Bleu: a Method
    for Automatic Evaluation of Machine Translation” In *Proceedings of the 40th Annual
    Meeting of the Association for Computational Linguistics* Philadelphia, Pennsylvania,
    USA: Association for Computational Linguistics, 2002, pp. 311–318 DOI: [10.3115/1073083.1073135](https://dx.doi.org/10.3115/1073083.1073135)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Keqin Peng et al. “Towards Making the Most of ChatGPT for Machine Translation”
    arXiv:2303.13780 [cs] arXiv, 2023 DOI: [10.48550/arXiv.2303.13780](https://dx.doi.org/10.48550/arXiv.2303.13780)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Ming Qian “Performance Evaluation on Human-Machine Teaming Augmented Machine
    Translation Enabled by GPT-4” In *Proceedings of the First Workshop on NLP Tools
    and Resources for Translation and Interpreting Applications* Varna, Bulgaria:
    INCOMA Ltd., Shoumen, Bulgaria, 2023, pp. 20–31 URL: [https://aclanthology.org/2023.nlp4tia-1.4](https://aclanthology.org/2023.nlp4tia-1.4)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Priyanka Ranade, Sudip Mittal, Anupam Joshi and Karuna Joshi “Using Deep
    Neural Networks to Translate Multi-lingual Threat Intelligence” In *2018 IEEE
    International Conference on Intelligence and Security Informatics (ISI)*, 2018,
    pp. 238–243 DOI: [10.1109/ISI.2018.8587374](https://dx.doi.org/10.1109/ISI.2018.8587374)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Dominic Seyler, Wei Liu, XiaoFeng Wang and ChengXiang Zhai “Towards Dark
    Jargon Interpretation in Underground Forums” arXiv:2011.03011 [cs] arXiv, 2021
    URL: [http://arxiv.org/abs/2011.03011](http://arxiv.org/abs/2011.03011)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Sai Cheong Siu “ChatGPT and GPT-4 for Professional Translators: Exploring
    the Potential of Large Language Models in Translation”, 2023 DOI: [10.2139/ssrn.4448091](https://dx.doi.org/10.2139/ssrn.4448091)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Matthew Snover et al. “A Study of Translation Edit Rate with Targeted
    Human Annotation” In *Proceedings of the 7th Conference of the Association for
    Machine Translation in the Americas: Technical Papers* Cambridge, Massachusetts,
    USA: Association for Machine Translation in the Americas, 2006, pp. 223–231 URL:
    [https://aclanthology.org/2006.amta-papers.25](https://aclanthology.org/2006.amta-papers.25)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Lewis Tunstall et al. “Zephyr: Direct Distillation of LM Alignment” arXiv:2310.16944
    [cs] arXiv, 2023 DOI: [10.48550/arXiv.2310.16944](https://dx.doi.org/10.48550/arXiv.2310.16944)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Galiya Ybytayeva et al. “Creating a Thesaurus ”Crime-Related Web Content”
    Based on a Multilingual Corpus” CEUR-WS, 2023, pp. 77–87 URL: [https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-209572](https://urn.kb.se/resolve?urn=urn:nbn:se:umu:diva-209572)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Wenhao Zhu et al. “Multilingual Machine Translation with Large Language
    Models: Empirical Results and Analysis” arXiv:2304.04675 [cs] arXiv, 2023 DOI:
    [10.48550/arXiv.2304.04675](https://dx.doi.org/10.48550/arXiv.2304.04675)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix I Fine-Tuning Prompt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <svg id="Sx2.p1.pic1" class="ltx_picture" height="135.79" overflow="visible"
    version="1.1" width="600"><g transform="translate(0,135.79) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject class="ltx_minipage"
    width="402.3pt" height="108.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">[PRE0]</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
