- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:37:43'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.13033](https://ar5iv.labs.arxiv.org/html/2404.13033)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Biyang Guo^(1†), He Wang^(1†), Wenyilin Xiao^(1†)
  prefs: []
  type: TYPE_NORMAL
- en: Hong Chen^(2†), Zhuxin Lee³, Songqiao Han^(1∗), Hailiang Huang^(1,4∗)
  prefs: []
  type: TYPE_NORMAL
- en: ¹AI Lab, SIME, Shanghai University of Finance and Economics
  prefs: []
  type: TYPE_NORMAL
- en: ²Ant Group, ³Guangdong Yunxi Technology
  prefs: []
  type: TYPE_NORMAL
- en: ⁴Key Laboratory of Interdisciplinary Research of Computation and Economics,
  prefs: []
  type: TYPE_NORMAL
- en: Ministry of Education, China
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the burgeoning field of Large Language Models (LLMs) like ChatGPT and LLaMA,
    Prompt Engineering (PE) is renowned for boosting zero-shot or in-context learning
    (ICL) through prompt modifications. Yet, the realm of the sample design for downstream
    fine-tuning, crucial for task-specific LLM adaptation, is largely unexplored.
    This paper introduces Sample Design Engineering (SDE), a methodical approach to
    enhancing LLMs’ post-tuning performance by refining input, output, and reasoning
    designs. We conduct a series of in-domain (ID) and out-of-domain (OOD) experiments
    to assess the impact of various design options on LLMs’ downstream performance,
    revealing several intriguing patterns that hold consistently across different
    LLMs. Based on these insights, we propose an integrated SDE strategy, combining
    the most effective options, and validate its consistent superiority over heuristic
    sample designs in complex downstream tasks like multi-aspect sentiment analysis,
    event extraction, and nested entity recognition. Additionally, analyses of LLMs’
    inherent prompt/output perplexity, zero-shot, and ICL abilities illustrate that
    good PE strategies may not always translate to good SDE strategies. Code available
    at [https://github.com/beyondguo/LLM-Tuning](https://github.com/beyondguo/LLM-Tuning).
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs'
  prefs: []
  type: TYPE_NORMAL
- en: Biyang Guo^(1†), He Wang^(1†), Wenyilin Xiao^(1†) Hong Chen^(2†), Zhuxin Lee³,
    Songqiao Han^(1∗), Hailiang Huang^(1,4∗) ¹AI Lab, SIME, Shanghai University of
    Finance and Economics ²Ant Group, ³Guangdong Yunxi Technology ⁴Key Laboratory
    of Interdisciplinary Research of Computation and Economics, Ministry of Education,
    China
  prefs: []
  type: TYPE_NORMAL
- en: '^(${\dagger}$)^(${\dagger}$)footnotetext: Equal Contribution^($*$)^($*$)footnotetext:
    Corresponding authors, emails:^†^†footnotetext: han.songqiao@shufe.edu.cn, hlhuang@shufe.edu.cn'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The emergence of Large Language Models (LLMs) such as GPT-3 Brown et al. ([2020](#bib.bib4)),
    PaLM Chowdhery et al. ([2023](#bib.bib6)), LLaMA Touvron et al. ([2023a](#bib.bib32))
    and GPT-4 Achiam et al. ([2023](#bib.bib1)) revolutionized natural language processing
    (NLP), enabling complex tasks to be tackled with a single model. This shift has
    profoundly broadened the range of tasks manageable by NLP models, while simultaneously
    consolidating the methodologies for various tasks under the unified framework
    of text generation. In this background, Prompt Engineering (PE) has emerged as
    a key area in leveraging cutting-edge LLMs, leading to advances in applying LLMs
    to new tasks Brown et al. ([2020](#bib.bib4)), enhancing logical reasoning Wei
    et al. ([2022](#bib.bib39)), and increasing task-specific accuracy Wang et al.
    ([2023a](#bib.bib34)); Wei et al. ([2023](#bib.bib40)), without updating model
    weights.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7533e8b9579d7af98aebef16e378ce86.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: A simplified comparison between PE and our proposed SDE.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While numerous PE techniques have been developed for LLMs’ zero-shot and in-context
    learning (ICL), the challenge of designing effective training samples for fine-tuning
    LLMs—termed Sample Design Engineering (SDE) in this paper—remains underexplored.
    SDE is crucial for tailoring smaller open-source LLMs to specific requirements,
    especially given the complexity of training samples for downstream tasks. Figure
    [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs") is a simplified
    demonstration of PE and SDE.'
  prefs: []
  type: TYPE_NORMAL
- en: To address this gap, this paper undertakes a detailed and comprehensive exploration
    of SDE for LLMs’ downstream fine-tuning. Our study is based on the hypothesis
    that the structure or elements of training samples may have a big impact on the
    fine-tuned LLMs. Different sample designs may make it easier or harder for the
    LLMs to learn, especially in scenarios where data is scarce.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by identifying a range of typical SDE options and categorizing them
    into three groups: input, output , and reasoning design options (shown in Figure
    [2](#S2.F2 "Figure 2 ‣ 2.2 Fine-tuning LLMs ‣ 2 Background and Related Work ‣
    Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning
    Samples for LLMs")). To reveal the impact of each SDE option, we conduct experiments
    on a typical downstream scenario – multi-aspect sentiment analysis (MASA), with
    2 in-domain (ID) tasks and 2 out-of-domain (OOD) tasks. Different from instruction-tuning
    datasets like FLAN Longpre et al. ([2023](#bib.bib25)), the MASA task involves
    more complicated input and output elements, making it suitable for in-depth investigation
    of different sample designs. Comprehensive experiments on these 4 tasks with 6
    popular open-source LLMs are undertaken to reveal how different SDE options affect
    downstream performances. Some interesting and thought-provoking conclusions are
    revealed through our experiments. For example, simply switching the position of
    the task instruction can make a difference; adding placeholders to unmentioned
    targets brings a notable performance gain, etc.'
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging these findings, we combine the empirically well-performing SDE options
    and propose an integrated SDE strategy ES-SDE. Extensive experiments on 3 complex
    downstream tasks (Nested-NER, Event Detection, and MASA) on 2 additional LLMs
    demonstrate that ES-SDE notably surpasses weaker SDE combination, as well as heuristic
    design from other studies. ES-SDE’s robustness on different training sizes, decoding
    randomness or instruction variation further underscores its stable effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: In an exploratory analysis, we investigate the link between effective prompt
    and sample designs, via perplexity, zero-shot, and ICL analysis. Our findings
    suggest that a well-crafted PE strategy may not necessarily translate to a successful
    SDE strategy. This observation encourages further research into SDE’s mechanisms,
    promising for enhancing LLMs’ downstream applications.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Background and Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 Prompt Engineering (PE)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The effectiveness of PE methods is largely built upon the strong inherent capabilities
    of LLMs, with most research focusing on very large models such as GPT-3, GPT-4,
    PaLM, etc. (refer to Sahoo et al. ([2024](#bib.bib28))). These models are pre-trained
    on extremely vast corpora, acquiring a wealth of knowledge and patterns, which
    enables them to directly perform complex tasks through careful prompt design.
    For instance, Brown et al. ([2020](#bib.bib4)) use carefully crafted prompts and
    in-context-learning (ICL) techniques to guide GPT-3 on novel tasks without training;
    Wei et al. ([2022](#bib.bib39)) propose the Chain-of-Thought (CoT) technique that
    can boost the logic reasoning performance; RAG Lewis et al. ([2020](#bib.bib21))
    and CoVe Dhuliawala et al. ([2023](#bib.bib10)) methods are used to reduce hallucination
    during generation; Li et al. ([2023](#bib.bib22)) introduce EmotionPrompt to improve
    LLMs’ emotional intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: However, these most advanced and effective LLMs are either black-box models
    that are only accessible via APIs, or extremely large models that are unaffordable
    for most companies to serve in production. Consequently, many practitioners turn
    to smaller but open-source LLMs, especially 10B around models. In this situation,
    solely relying on PE for zero-shot or ICL inference is unable to handle many real-world
    complex NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Fine-tuning LLMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'According to the different purposes, we can divide LLMs’ fine-tuning into two
    types: instruction-tuning (IT) and downstream-tuning (DT)¹¹1It is also known as
    task tuning (TT) in some literature, like Weber et al. ([2023](#bib.bib37))..'
  prefs: []
  type: TYPE_NORMAL
- en: IT trains LLMs to comprehend and execute instructions across a range of NLP
    tasks, enabling predictions for new tasks Wei et al. ([2021](#bib.bib38)); Mishra
    et al. ([2022](#bib.bib26)) with datasets like FLAN Longpre et al. ([2023](#bib.bib25)),
    Self-instruct Wang et al. ([2023b](#bib.bib36)), Alpaca Taori et al. ([2023](#bib.bib30))
    and HC3 Guo et al. ([2023](#bib.bib15)), covering tasks like such as classification,
    QA and translation. This is mainly applied to base models to enable them to follow
    general human instructions. DT focuses on customizing LLMs for specific, often
    complex, tasks in industrial applications, demanding high output stability for
    easier parsing and application in downstream products. An example is multi-aspect
    sentiment analysis, which requires detailed task instructions and outputs. Our
    study centers on SDE in DT scenarios, highlighting sample design challenges, but
    the insights may also benefit IT sample design, a topic for future exploration.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f279587ad781adc45802d3aa911bd979.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Typical SDE options to be considered when designing downstream-tuning
    samples, taking the MASA task as an example. $Ai$ means its sentiment label, [P]
    refers to placeholder tokens.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c0128683df24b4bd639fbd8ec626ca19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: An example for the MASA task.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Parameter-efficient fine-tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The expansion of language models has made traditional full-parameter fine-tuning
    (FFT) less viable due to its high computational and storage demands. Parameter-efficient
    fine-tuning (PEFT) methods, such as prefix-tuningLi and Liang ([2021](#bib.bib23)),
    prompt-tuningLester et al. ([2021](#bib.bib19)), p-tuningLiu et al. ([2023](#bib.bib24)),
    and LoRAHu et al. ([2021](#bib.bib17)) provide cost-effective alternatives that
    retain FFT’s effectiveness, gaining popularity in industrial applications. These
    techniques are adaptable to both IT and DT scenarios. In this research, we use
    the widely-used LoRA as the default fine-tuning technique. However, we believe
    results from our study are also applicable to other PEFT methods.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Sample Design Engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Typical SDE Options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We categorize sample design options into three aspects: input, output, and
    reasoning. We take the Multi-Aspect Sentiment Analysis (MASA), a typical downstream
    task, as an example to clarify each design option for fine-tuning samples. As
    illustrated in Figure [3](#S2.F3 "Figure 3 ‣ 2.2 Fine-tuning LLMs ‣ 2 Background
    and Related Work ‣ Sample Design Engineering: An Empirical Study of What Makes
    Good Downstream Fine-Tuning Samples for LLMs"), MASA requires analyzing review
    texts to assign sentiments to predefined aspects, while some aspects may be unmentioned.
    Figure [2](#S2.F2 "Figure 2 ‣ 2.2 Fine-tuning LLMs ‣ 2 Background and Related
    Work ‣ Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs") is an overview of different SDE options, which
    should be considered to design proper DT samples.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Input Design Options
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '$a.$ Instruction Placement: We explore the effect of instruction positioning
    relative to task text (for MASA, the review text), examining Inst-first (before
    the task text), Inst-last (after the task text). We also compare with the No-inst
    (no instruction) option to evaluate the effectiveness of explicit instructions,
    as used in many previous conditional text generation tasks Lewis et al. ([2019](#bib.bib20));
    Guo et al. ([2022](#bib.bib14)); Zhang et al. ([2023](#bib.bib43)).'
  prefs: []
  type: TYPE_NORMAL
- en: '$b.$ Input Modeling: Considering the distinction between unified sequence modeling
    in LLM pre-training and the explicit input/output segmentation in fine-tuning,
    we compare No-MI that excluding input from loss calculation, akin to LLaMA2’s
    SFT process Touvron et al. ([2023b](#bib.bib33))) against MI (modeling input in
    backpropagation).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Output Design Options
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '$a.$ Multiple Predictions Formatting: For tasks necessitating several predictions,
    we evaluate output formatting from less to more structured: Natural (free-form
    text), Lines (each aspect on a new line), and JSON (JSON-lines for precision and
    explicitness).'
  prefs: []
  type: TYPE_NORMAL
- en: '$b.$ Handling Unmentioned Targets: We consider whether to omit the unmentioned
    (OU) targets in the output, or place placeholders (PU) for those targets. The
    placeholder tokens can be strings like "Unmentioned", "None", or "[]" according
    to tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '$c.$ Textual or numerical labels: By default, we use the TxtLabel option for
    textual output labels. However, in some cases, using numbers to represent outcomes
    (NumLabel) may enhance prediction robustness.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Reasoning Design Options
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many tasks require reasoning, where the Chain-of-Thought (CoT) Wei et al. ([2022](#bib.bib39))
    has shown promise in improving LLM’s reasoning in zero-shot and ICL, as well as
    IT scenarios Kim et al. ([2023](#bib.bib18)). Yet, its impact on DT remains less
    studied.
  prefs: []
  type: TYPE_NORMAL
- en: We introduce the CoT option for training models to "think before they predict".
    We use JSON as the default output format to make the representation clearer and
    add a new description field before the sentiment field. Conversely, the R-CoT
    (Reverse-CoT) reverses these fields, enabling a "predict then explain" approach
    to explore CoT’s mechanics further. Note that Implementing CoT-like samples incurs
    additional annotation costs due to the description fields, making the reasoning
    design options task-dependent.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Integrated SDE Strategy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A final sample design is a combination of the above design options, which we
    call an integrated SDE strategy. This paper initially explores the impact of each
    individual option through extensive experimentation, leading to the proposal of
    an evidence-based integrated SDE strategy.
  prefs: []
  type: TYPE_NORMAL
- en: '4 Experiments I: Evaluating The Impact of Each SDE Option'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Settings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Tasks and Datasets. We experiment with in-domain (ID) evaluations and out-of-domain
    (OOD) evaluations, for the Chinese online review MASA scenario. The data is provided
    and annotated by our collaborating company, which encounters a real-world business
    need for the analysis of extensive customer online reviews. The data annotations
    come from two domains of aspects: D1 about food, beverage, price, hygiene, staff
    attitude, and parking convenience and D2 about traffic convenience, queuing, serving
    speed, decoration, and noise. The model needs to give a sentiment label from {positive,
    neutral, negative} for each aspect, while some aspects may not occur in the review.
    Based on the two domains, we construct the following 4 tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$D2 are two ID evaluation tasks, where train and test sets come from
    the same domains;
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$D1 are two OOD generalization tasks, where the model trains on one
    domain but tests on an unseen domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the high cost of annotation in industries and the fact that fine-tuning
    LLMs requires less annotated data Zhou et al. ([2024](#bib.bib44)), we train the
    model with $500$ samples to make results more stable and convincing. Dataset details
    see Appendix [A.2](#A1.SS2 "A.2 Datasets and Training Settings ‣ Appendix A Appendix
    ‣ Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/69f35fbe0100d223b71a97493f04feb3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Sentiment analysis performances ($\kappa$) of different SDE options.
    Results of ID are the average of D1->D1 and D2->D2, same for OOD. The bars depict
    each method’s relative improvement or degradation compared to the baseline, with
    each method differing from the baseline in only one option (colored in red). Detailed
    results for each task see Table [3](#A1.T3 "Table 3 ‣ A.4 Detailed Evaluations
    of Each SDE Option ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs")-[8](#A1.T8
    "Table 8 ‣ A.4 Detailed Evaluations of Each SDE Option ‣ Appendix A Appendix ‣
    Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning
    Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Models. We utilize the following widely used open-source LLMs of 7B size of
    both the base and chat versions: 1) chinese-llama-2-7b (note as c-llama2-base)
    and the instruction-tuned version chinese-alpaca-2-7b (c-llama2-chat) from the
    Chinese-LLaMA2 series Cui et al. ([2023](#bib.bib9)), which is the vocabulary-expanded
    version of LLaMA2 Touvron et al. ([2023b](#bib.bib33)) with secondary pre-training
    and fine-tuning on Chinese corpus; 2) internlm-7b-base (intern-base) and internlm-7b-chat
    (intern-chat) from the InternLM series Team ([2023](#bib.bib31)), which are pretrained
    on trillions of high-quality tokens, performs well in Chinese and English tasks;
    3) baichuan2-7b-base (bc2-base) and baichuan2-7b-chat (bc2-chat) from the Baichuan2
    series Yang et al. ([2023](#bib.bib41)), one of the SOTA LLMs at the time of release.
    We use LoRA as the default efficient fine-tuning technique. Hyperparameters and
    other training details can be found in Appendix [A.2](#A1.SS2 "A.2 Datasets and
    Training Settings ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation Metrics. We evaluate the MASA’s performance from two perspectives:
    1) Sentiment analysis performance. We use the weighted Kappa score $\kappa$, Kappa
    weight matrix, and format-parsing rules can be seen in Appendix [A.1](#A1.SS1
    "A.1 Metrics for MASA ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Experimental Results on Each Option
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We report and analyze the results from two perspectives—sentiment analysis performances,
    and format adherence abilities.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Sentiment Analysis Performance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We first assess the sentiment analysis performances of LLMs using different
    sample design options. The comparative results of ID and OOD tasks on 3 Chat-LLMs
    and 3 Base-LLMs are plotted in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Settings ‣ 4
    Experiments I: Evaluating The Impact of Each SDE Option ‣ Sample Design Engineering:
    An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs")
    (full results see Table [3](#A1.T3 "Table 3 ‣ A.4 Detailed Evaluations of Each
    SDE Option ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study
    of What Makes Good Downstream Fine-Tuning Samples for LLMs") to Table [8](#A1.T8
    "Table 8 ‣ A.4 Detailed Evaluations of Each SDE Option ‣ Appendix A Appendix ‣
    Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning
    Samples for LLMs") in Appendix [A.4](#A1.SS4 "A.4 Detailed Evaluations of Each
    SDE Option ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study
    of What Makes Good Downstream Fine-Tuning Samples for LLMs")). Some shared and
    intriguing patterns are revealed from the results.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusions for Input Options: 1) Instructions enhance DT performances: The
    No-Inst option leads to poorer performance in ID tasks and a lack of OOD generalization
    ability compared to Inst-first or Inst-last methods that incorporate instructions.
    This underlines the critical role of including instructions for improving both
    understanding and generalizability of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '2) Better to place instruction first: The Inst-first method outperforms Inst-last
    across both ID and OOD tasks for different LLMs. This demonstrates the significance
    of instruction placement for LLMs’ tuning process. We hypothesize that this may
    partly be explained by the attention mechanism, see Appendix [A.6](#A1.SS6 "A.6
    Additional Analysis on Inst-last and Inst-first ‣ Appendix A Appendix ‣ Sample
    Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning
    Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '3) Modeling input detracts from performance: Employing the MI approach results
    in worse outcomes compared to the No-MI baselines across various models and tasks.
    This indicates that modeling the input part during fine-tuning may hinder the
    LLM’s effectiveness, suggesting a cautious approach to what aspects of the task
    are modeled.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4fc540bdc0b6078e7f7e7be5113a2956.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Format adherence performance, measured by parsing error rates (%).
    ’*’ means same option as above.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusions for Output Options: 1) Lines is a reliable output format for multiple
    predictions: The Lines format, positioned between the Natural and JSON formats,
    demonstrates stable and high performance in sentiment analysis across various
    models and tasks. Its effectiveness lies in offering structured information while
    retaining natural language readability, making it versatile for different LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: '2) Base-LLMs exhibit similar patterns while Chat-LLMs diverse: Base models
    respond similarly to output formats, indicating consistency in their responses.
    In contrast, Chat models, such as bc2-chat and cllama2-chat, exhibit varied performances,
    suggesting differences in their SFT or RLHF data’s structure. For instance, bc2-chat
    and cllama2-chat perform well with JSON format, unlike intern-chat, implying a
    variance in the amount of structured data used in training.'
  prefs: []
  type: TYPE_NORMAL
- en: '3) Base-LLMs favor more natural formats while Chat-LLMs can fit or bear more
    sophisticated formats: Base models prefer Natural and Lines over JSON. Conversely,
    Chat models lean towards structured formats, with Lines and JSON. This divergence
    hints at the different training backgrounds, with Chat models being more accommodating
    to sophisticated data formats. One more piece of evidence is that the NumLabel
    option brings much more damage to the Base models than to the Chat models, which
    is less natural than TxtLabel.'
  prefs: []
  type: TYPE_NORMAL
- en: '4) Textual over numeric labels: Switching from textual to numeric labels worsens
    performance, likely because numeric labels lack the descriptive depth and context
    clues that textual labels provide, crucial for LLMs trained on natural language
    text.'
  prefs: []
  type: TYPE_NORMAL
- en: '5) Omitting the unmentioned targets may not be a good choice: While the OU
    option, which excludes unmentioned aspects, might seem to simplify outputs, it
    also introduces format inconsistency. This lack of uniformity forces the model
    to adapt to varied aspect mentions per sample, increasing task complexity with
    dynamic adjustment of the output format. Instead, the PU option keeps a consistent
    output format by adding placeholders, perhaps making LLMs easier to learn. Additional
    analysis shows that the aspects with a higher degree of unmentioning suffer greater
    underperformance with OU compared to PU, see Appendix [A.7](#A1.SS7 "A.7 Additional
    Analysis on OU and PU ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusions for Reasoning Options: 1) Subtle impact of CoT on ID, while significant
    on OOD tasks: CoT design marginally affects ID tasks but markedly improves OOD
    performance. This contrast highlights CoT’s role in enhancing model reasoning
    and adaptability in unfamiliar contexts, underpinning its value for generalization.'
  prefs: []
  type: TYPE_NORMAL
- en: '2) "Think before predict" beats "predict then explain": When the reasoning
    step is placed after predicting, like the R-CoT method, the performance does not
    match that of the standard CoT approach. However, R-CoT can still outperform No-CoT
    in many cases, suggesting that a single reasoning component is also beneficial.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Format Adherence Performance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5035105ff2c5e9052e56f1a954a04b4c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Comparison of different sample design strategies.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [5](#S4.F5 "Figure 5 ‣ 4.2.1 Sentiment Analysis Performance ‣ 4.2 Experimental
    Results on Each Option ‣ 4 Experiments I: Evaluating The Impact of Each SDE Option
    ‣ Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs") presents the results of the format adherence performances
    for Chat-LLMs, from which we find that: 1) While the Inst-first method improves
    sentiment analysis, it shows less stability in format adherence, especially in
    OOD scenarios, indicating that leading with instructions might increase format
    errors with unfamiliar content; 2) Structured design options lead to better format
    adherence abilities: A noticeable trend is that structured outputs, especially
    in the order JSON > Lines > Natural, have lower format error rates. JSON format,
    in particular, demonstrates strong adherence to the correct structure, highlighting
    a balance between output complexity and precision; 3) MI, NumLabel and CoT options
    can be quite unstable for certain LLMs, while other options are generally consistent
    across different models. In applications where stability is vital, these unstable
    options should be taken seriously; 4) Though improving the understanding or reasoning
    performances, CoT design puts LLMs at a higher risk of parsing failure for customized
    downstream tasks, underlining a trade-off for this option.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering LLMs’ format adherence alongside the understanding abilities is
    crucial for specialized downstream applications, suggesting a need for a balanced
    approach in industrial scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: '5 Experiments II: An Robust Integrated SDE Strategy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Based on the experimental evidence from the previous section, we propose an
    empirically strong SDE strategy (termed as ES-SDE) using the well-performing options:
    a combination of Inst-first, No-MI input designs and Lines, PU, TxtLabel output
    designs. We don’t use the CoT design because of its high annotation cost and relatively
    unstable output. In this section, we conduct comprehensive experiments to validate
    its effectiveness across different downstream tasks, as well as the robustness
    against perturbations in instructions or generation.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Settings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Tasks and datasets. To evaluate the effectiveness of ES-SDE, we conduct experiments
    on three challenging downstream tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$ GENIA Ohta et al. ([2002](#bib.bib27)). A nested named entity recognition
    (Nested-NER) dataset in the molecular biology domain, where ChatGPT (GPT-3.5)
    only achieves an F1 score of 50.89%, using 5-shot CoT reasoning Han et al. ([2023](#bib.bib16)).
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$ MAVEN Wang et al. ([2020](#bib.bib35)). A general domain event detection
    (ED) dataset. Han et al. ([2023](#bib.bib16)) demonstrate that the performance
    of ChatGPT in ED tasks falls below expectations. We use the top-10 event types
    in our experiments.
  prefs: []
  type: TYPE_NORMAL
- en: '$\bullet$ Review11. This is our self-collected Chinese MASA dataset that involves
    11 aspects, more complicated than the MASA tasks in Section [4](#S4 "4 Experiments
    I: Evaluating The Impact of Each SDE Option ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Baselines. As a comparison to ES-SDE, we also propose an empirically weak SDE
    strategy (EW-SDE), combining Inst-last, Natural, and OU, while keeping other options
    the same. We naturally hypothesize that EW-SDE should be weaker than ES-SDE. Note
    that ES-SDE and EW-SDE are both evidence-based strategies according to the previous
    empirical results, therefore, we also set up a heuristic-based baseline, referring
    to the prompt designs from the study of Han et al. ([2023](#bib.bib16)), which
    are similar to a combination of Inst-first and OU options, with a "lines-of-list"
    output format. Examples of these strategies see Appendix [11](#A1.F11 "Figure
    11 ‣ A.8.2 Perplexity Analysis ‣ A.8 Can PE Guide SDE? Detailed Results ‣ Appendix
    A Appendix ‣ Sample Design Engineering: An Empirical Study of What Makes Good
    Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Models. For a more generalized evaluation, we utilize two new LLMs, instead
    of those used in Section [4](#S4 "4 Experiments I: Evaluating The Impact of Each
    SDE Option ‣ Sample Design Engineering: An Empirical Study of What Makes Good
    Downstream Fine-Tuning Samples for LLMs"). Considering the task language, the
    llama2-7b-chat Touvron et al. ([2023b](#bib.bib33)) is used for GENIA and MAVEN
    and qwen1.5-4b-chat Bai et al. ([2023](#bib.bib2)), a very latest LLM, is used
    for Review11\. The training details are the same as Section [4](#S4 "4 Experiments
    I: Evaluating The Impact of Each SDE Option ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figure [6](#S4.F6 "Figure 6 ‣ 4.2.2 Format Adherence Performance ‣ 4.2 Experimental
    Results on Each Option ‣ 4 Experiments I: Evaluating The Impact of Each SDE Option
    ‣ Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs") reports the comparison between different sample
    design strategies, from different perspectives. Soft-match F1 scores Han et al.
    ([2023](#bib.bib16)) are reported for GENIA and MAVEN, and $\kappa$ reported for
    Review 11\. More detailed results see Appendix [A.5](#A1.SS5 "A.5 Detailed Results
    on GENIA, MAVEN and Review11 ‣ Appendix A Appendix ‣ Sample Design Engineering:
    An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").
    Several key conclusions can be observed:'
  prefs: []
  type: TYPE_NORMAL
- en: '1) ES-SDE maintains advantages across tasks and training sizes. Figure [6](#S4.F6
    "Figure 6 ‣ 4.2.2 Format Adherence Performance ‣ 4.2 Experimental Results on Each
    Option ‣ 4 Experiments I: Evaluating The Impact of Each SDE Option ‣ Sample Design
    Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples
    for LLMs")-(a) demonstrates a consistent trend that ES-SDE keeps its advantage
    as the training size increases from $500$ EW-SDE and heuristic samples in GENIA
    and Review11 tasks, indicating the high quality of ES-SDE samples. 2) Stable on
    decoding randomness. By default, the model employs a greedy decoding strategy
    (no sampling). Figure [6](#S4.F6 "Figure 6 ‣ 4.2.2 Format Adherence Performance
    ‣ 4.2 Experimental Results on Each Option ‣ 4 Experiments I: Evaluating The Impact
    of Each SDE Option ‣ Sample Design Engineering: An Empirical Study of What Makes
    Good Downstream Fine-Tuning Samples for LLMs")-(b) shows the results when activating
    decoding sampling with varying random seeds. ES-SDE maintains exceptional stability
    across different seeds on three tasks. The adoption of decoding sampling tends
    to diminish the performances of both SW-SDE and heuristic strategies for GENIA
    and MAVEN, while ES-SDE gives stable performances. 3) Robust to instruction variation.
    For instructions about a specific task, we have various ways of expressing the
    same idea. Therefore, we validate the sensitivity of different strategies to different
    formulations of the instruction, by changing the common content to other formulations
    (examples in Appendix [12](#A1.F12 "Figure 12 ‣ A.8.2 Perplexity Analysis ‣ A.8
    Can PE Guide SDE? Detailed Results ‣ Appendix A Appendix ‣ Sample Design Engineering:
    An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs")).
    As shown in Figure [6](#S4.F6 "Figure 6 ‣ 4.2.2 Format Adherence Performance ‣
    4.2 Experimental Results on Each Option ‣ 4 Experiments I: Evaluating The Impact
    of Each SDE Option ‣ Sample Design Engineering: An Empirical Study of What Makes
    Good Downstream Fine-Tuning Samples for LLMs")-(c), ES-SDE keeps its edge in different
    variations, showing its robustness to instruction content.'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, ES-SDE represents a reliable and potent approach for the DT of LLMs,
    illustrating that—through a careful SDE process, LLMs can achieve much higher
    performances in downstream tasks. Note that ES-SDE may not be the best strategy
    for all tasks. A detailed investigation into SDE across a broader spectrum of
    tasks and models could yield even more effective strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Can PE guide SDE? An Additional Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prompts are the key to understand models’ innate qualities and capabilities.
    A good PE method often indicates some patterns that a LLM is more familiar with
    or excels in. A natural question is: can PE guide SDE? To answer this question,
    we craft zero-shot and ICL prompts according to different SDE options to evaluate
    their PE performances. Figure [7](#S6.F7 "Figure 7 ‣ 6 Can PE guide SDE? An Additional
    Analysis ‣ Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs") reports the average rankings of SDE options and
    their corresponding prompts in the MASA ID tasks. Detailed results for each task
    see Appendix [A.8](#A1.SS8 "A.8 Can PE Guide SDE? Detailed Results ‣ Appendix
    A Appendix ‣ Sample Design Engineering: An Empirical Study of What Makes Good
    Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our analysis revealed some consistent patterns: Inst-first is an effective
    choice for both PE and SDE; CoT improves performances for both PE and SDE evaluations.
    However, there are also many counter-intuitive findings. For example, the OU option
    consistently harms DT performances according to our previous experiments, however,
    its corresponding prompts results in notably better zero-shot or ICL results for
    certain LLMs; Similarly, while the Natural option outperforms the Lines approach
    for base models in SDE, the reverse is true in zero-shot or ICL evaluations for
    models like c-llama2-base and intern-base. Gonen et al. ([2023](#bib.bib12)) showed
    through a wide range of tasks that the lower that lower perplexity (PPL) generally
    leads to better prompt designs. Inspired by this, we also conduct PPL analysis
    on the ICL prompts/predictions corresponding to each SDE options. Interestingly,
    OU-like prompt gives the highest averaged PPL scores across all options, which
    seems to be contradictory that OU brings better zero-shot or ICL results. The
    JSON format surprisingly achieves rather low PPL scores, however its SDE performances
    are worse than Lines.'
  prefs: []
  type: TYPE_NORMAL
- en: These findings highlight a complex landscape where prompt design patterns do
    not always align with SDE effectiveness, underscoring the nuanced relationship
    between PE and SDE.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b2fa0cb1b2f734a38501b9da7ce84828.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Average rankings of the DT performances of SDE options and zero-shot/ICL/PPL
    rankings of their corresponding prompts. Results based on the MASA ID tasks across
    6 LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: 7 Conclusion & Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this study, we introduce SDE as an effective method to enhance the downstream-tuning
    performances of LLMs. Through comprehensive ID and OOD experiments involving six
    LLMs, we demonstrate the effects of various sample design strategies, uncovering
    some interesting patterns that are consistent across different LLMs. Building
    on these findings, we develop the ES-SDE approach, which integrates the most effective
    options. Our experiments on three new tasks with two additional LLMs consistently
    show ES-SDE’s superiority over baseline methods. Further analysis of the relationship
    between PE and SDE suggests that effective prompt designs do not necessarily translate
    to successful sample designs. This observation opens up avenues for more detailed
    investigations into the mechanisms of SDE in future research.
  prefs: []
  type: TYPE_NORMAL
- en: 8 Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This research follows a two-step experimental approach. In the first step,
    we investigate the impact of each SDE option, the results are then used as evidence
    for the second step—proposing an empirically strong SDE combination strategy.
    As an empirical study, this research is subject to certain limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we demonstrate that the experimental findings from the first phase are
    extendable to different downstream tasks, the applicability to other untested
    scenarios remains uncertain. For instance, although the Lines output design outperforms
    the JSON format in our current experiments, it is unclear if this advantage persists
    in more complex tasks with intricate structures. Future research will address
    these more challenging contexts;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the rapid pace of advancements in LLMs, new and more sophisticated models
    are being introduced frequently. The models we used in our study were among the
    best open-source options available at the start of our research but have since
    been surpassed by newer releases. Although we assessed a total of 8 LLMs, including
    both base and chat variants, there remains a possibility that our findings may
    not be universally applicable to other models;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3\.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Combining different SDE options poses significant challenges, particularly
    without prior validation experiments such as those described in Section [4](#S4
    "4 Experiments I: Evaluating The Impact of Each SDE Option ‣ Sample Design Engineering:
    An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").
    The challenges are twofold. Firstly, unlike typical hyperparameters like learning
    rate or network layers, choosing different SDE options alters the training data
    itself, rendering traditional hyperparameter-tuning techniques such as Bayesian
    Optimization Snoek et al. ([2012](#bib.bib29)) less practical. Secondly, evaluating
    LLMs on downstream tasks is both resource-intensive and costly, due to the need
    for customized task metrics, parsing rules, and high model inference costs. Therefore,
    developing a more efficient framework for SDE studies is a critical objective
    for future research.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. 2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bai et al. (2023) Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong
    Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang
    Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui
    Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang,
    Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian
    Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang,
    Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan
    Zhou, and Tianhang Zhu. 2023. Qwen technical report. *arXiv preprint arXiv:2309.16609*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ben-David (2008) Arie Ben-David. 2008. Comparison of classification accuracy
    using cohen’s weighted kappa. *Expert Systems with Applications*, 34(2):825–832.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (1998) Stanley F Chen, Douglas Beeferman, and Roni Rosenfeld. 1998.
    Evaluation metrics for language models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chowdhery et al. (2023) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, et al. 2023. Palm: Scaling language modeling with pathways.
    *Journal of Machine Learning Research*, 24(240):1–113.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cohen (1968) J Cohen. 1968. Weighted kappa: nominal scale agreement with provision
    for scaled disagreement or partial credit. *Psychological bulletin*, 70(4):213–220.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cohen (1960) Jacob Cohen. 1960. A coefficient of agreement for nominal scales.
    *Educational and psychological measurement*, 20(1):37–46.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cui et al. (2023) Yiming Cui, Ziqing Yang, and Xin Yao. 2023. Efficient and
    effective text encoding for chinese llama and alpaca. *arXiv preprint arXiv:2304.08177*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dhuliawala et al. (2023) Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta
    Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023. Chain-of-verification
    reduces hallucination in large language models. *arXiv preprint arXiv:2309.11495*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Galar et al. (2011) Mikel Galar, Alberto Fernández, Edurne Barrenechea, Humberto
    Bustince, and Francisco Herrera. 2011. An overview of ensemble methods for binary
    classifiers in multi-class problems: Experimental study on one-vs-one and one-vs-all
    schemes. *Pattern Recognition*, 44(8):1761–1776.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gonen et al. (2023) Hila Gonen, Srini Iyer, Terra Blevins, Noah A Smith, and
    Luke Zettlemoyer. 2023. Demystifying prompts in language models via perplexity
    estimation. In *Findings of the Association for Computational Linguistics: EMNLP
    2023*, pages 10136–10148.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Grandini et al. (2020) Margherita Grandini, Enrico Bagli, and Giorgio Visani.
    2020. Metrics for multi-class classification: an overview. *arXiv preprint arXiv:2008.05756*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. (2022) Biyang Guo, Yeyun Gong, Yelong Shen, Songqiao Han, Hailiang
    Huang, Nan Duan, and Weizhu Chen. 2022. Genius: Sketch-based language model pre-training
    via extreme and selective masking for text generation and augmentation. *arXiv
    preprint arXiv:2211.10330*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2023) Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie,
    Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023. How close is chatgpt to human experts?
    comparison corpus, evaluation, and detection. *arXiv preprint arXiv:2301.07597*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Han et al. (2023) Ridong Han, Tao Peng, Chaohao Yang, Benyou Wang, Lu Liu, and
    Xiang Wan. 2023. Is information extraction solved by chatgpt? an analysis of performance,
    evaluation criteria, robustness and errors. *arXiv preprint arXiv:2305.14450*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. (2021) Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li,
    Shean Wang, Lu Wang, Weizhu Chen, et al. 2021. Lora: Low-rank adaptation of large
    language models. In *International Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2023) Seungone Kim, Se Joo, Doyoung Kim, Joel Jang, Seonghyeon
    Ye, Jamin Shin, and Minjoon Seo. 2023. The cot collection: Improving zero-shot
    and few-shot learning of language models via chain-of-thought fine-tuning. In
    *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*,
    pages 12685–12708.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lester et al. (2021) Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The
    power of scale for parameter-efficient prompt tuning. In *Proceedings of the 2021
    Conference on Empirical Methods in Natural Language Processing*, pages 3045–3059.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lewis et al. (2019) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart:
    Denoising sequence-to-sequence pre-training for natural language generation, translation,
    and comprehension. *arXiv preprint arXiv:1910.13461*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive
    nlp tasks. *Advances in Neural Information Processing Systems*, 33:9459–9474.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2023) Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou,
    Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie. 2023. Large language models
    understand and can be enhanced by emotional stimuli. *arXiv preprint arXiv:2307.11760*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Liang (2021) Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing
    continuous prompts for generation. In *Proceedings of the 59th Annual Meeting
    of the Association for Computational Linguistics and the 11th International Joint
    Conference on Natural Language Processing (Volume 1: Long Papers)*, pages 4582–4597.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2023) Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian,
    Zhilin Yang, and Jie Tang. 2023. Gpt understands, too. *AI Open*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Longpre et al. (2023) Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won
    Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. 2023. The
    flan collection: Designing data and methods for effective instruction tuning.
    In *International Conference on Machine Learning*, pages 22631–22648\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mishra et al. (2022) Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh
    Hajishirzi. 2022. Cross-task generalization via natural language crowdsourcing
    instructions. In *Proceedings of the 60th Annual Meeting of the Association for
    Computational Linguistics (Volume 1: Long Papers)*, pages 3470–3487.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ohta et al. (2002) Tomoko Ohta, Yuka Tateisi, Jin-Dong Kim, Hideki Mima, and
    Junichi Tsujii. 2002. The genia corpus: An annotated research abstract corpus
    in molecular biology domain. In *Proceedings of the human language technology
    conference*, pages 73–77\. Citeseer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sahoo et al. (2024) Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija
    Jain, Samrat Mondal, and Aman Chadha. 2024. A systematic survey of prompt engineering
    in large language models: Techniques and applications. *arXiv preprint arXiv:2402.07927*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snoek et al. (2012) Jasper Snoek, Hugo Larochelle, and Ryan P Adams. 2012. Practical
    bayesian optimization of machine learning algorithms. *Advances in neural information
    processing systems*, 25.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Taori et al. (2023) Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois,
    Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023. Stanford
    alpaca: An instruction-following llama model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Team (2023) InternLM Team. 2023. Internlm: A multilingual language model with
    progressively enhanced capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation
    language models. *arXiv preprint arXiv:2302.13971*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023a) Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong Ma, Haixing
    Dai, Qiushi Yang, Yanqing Kang, Jinru Wu, Huawen Hu, Chenxi Yue, Haiyang Zhang,
    Yi-Hsueh Liu, Xiang Li, Bao Ge, Dajiang Zhu, Yixuan Yuan, Dinggang Shen, Tianming
    Liu, and Shu Zhang. 2023a. Prompt engineering for healthcare: Methodologies and
    applications. *ArXiv*, abs/2304.14670.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020) Xiaozhi Wang, Ziqi Wang, Xu Han, Wangyi Jiang, Rong Han,
    Zhiyuan Liu, Juanzi Li, Peng Li, Yankai Lin, and Jie Zhou. 2020. Maven: A massive
    general domain event detection dataset. In *Proceedings of the 2020 Conference
    on Empirical Methods in Natural Language Processing (EMNLP)*, pages 1652–1671.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023b) Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu,
    Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b. Self-instruct:
    Aligning language models with self-generated instructions. In *The 61st Annual
    Meeting Of The Association For Computational Linguistics*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weber et al. (2023) Lucas Weber, Elsa M. Bruni Bruni, and Dieuwke Hupkes. 2023.
    Mind the instructions: a holistic evaluation of consistency and interactions in
    prompt-based learning. In *Proceedings of the 27th Conference on Computational
    Natural Language Learning (CoNLL)*, pages 294–313.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2021) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language
    models are zero-shot learners. In *International Conference on Learning Representations*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2023) Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang,
    Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, et al. 2023. Zero-shot
    information extraction via chatting with chatgpt. *arXiv preprint arXiv:2302.10205*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023) Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian,
    Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, et al. 2023. Baichuan 2: Open
    large-scale language models. *arXiv preprint arXiv:2309.10305*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yilmaz and Demirhan (2023) Ayfer Ezgi Yilmaz and Haydar Demirhan. 2023. Weighted
    kappa measures for ordinal multi-class classification performance. *Applied Soft
    Computing*, 134:110020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023) Hanqing Zhang, Haolin Song, Shaoyu Li, Ming Zhou, and Dawei
    Song. 2023. A survey of controllable text generation using transformer-based pre-trained
    language models. *ACM Computing Surveys*, 56(3):1–37.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2024) Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao
    Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2024. Lima: Less
    is more for alignment. *Advances in Neural Information Processing Systems*, 36.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A.1 Metrics for MASA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Weighted Kappa. Considering the imbalance of different aspects and the ordinal
    nature of labels, weighted agreement measures are proved to be more effective
    than traditional metrics Ben-David ([2008](#bib.bib3)); Galar et al. ([2011](#bib.bib11));
    Grandini et al. ([2020](#bib.bib13)). Thus we adopt Weighted Kappa (Cohen, [1968](#bib.bib7);
    Yilmaz and Demirhan, [2023](#bib.bib42)) as the measure of classification effect,
    which is an extension of Cohen’s Kappa (Cohen, [1960](#bib.bib8)). Weighted Kappa
    $\kappa$. The probabilities $p_{ij},p_{i.},p_{.j}$, enables a nuanced assessment
    of different error degrees. For example, classifying "positive" as "negative"
    is more detrimental than classifying "positive" as "neutral," hence a higher penalty
    should be imposed on the former. Based on the feedback from enterprises in practical
    applications, we define the weight matrix without loss of generality as Table
    [1](#A1.T1 "Table 1 ‣ A.1 Metrics for MASA ‣ Appendix A Appendix ‣ Sample Design
    Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples
    for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Pre-Pos | Pre-Neu | Pre-Neg | Pre-Unm |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Label-Pos | 1 | 1/2 | 0 | 1/2 |'
  prefs: []
  type: TYPE_TB
- en: '| Label-Neu | 2/3 | 1 | 2/3 | 2/3 |'
  prefs: []
  type: TYPE_TB
- en: '| Label-Neg | 0 | 1/2 | 1 | 1/2 |'
  prefs: []
  type: TYPE_TB
- en: '| Label-Unm | 1/2 | 2/3 | 1/2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Weight matrix for calculating weighted Kappa.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | TrainSet (size=500) | TrainSet (size=1000) | TestSet |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Pos | Neu | Neg | Unm | Pos | Neu | Neg | Unm | Pos | Neu | Neg | Unm
    |'
  prefs: []
  type: TYPE_TB
- en: '| D1 | F | 65.20 | 15.00 | 18.80 | 1.00 | 66.60 | 13.70 | 18.30 | 1.40 | 66.01
    | 12.23 | 20.12 | 1.64 |'
  prefs: []
  type: TYPE_TB
- en: '| B | 22.20 | 4.20 | 8.20 | 65.40 | 23.50 | 3.60 | 7.20 | 65.70 | 21.50 | 3.15
    | 6.29 | 69.07 |'
  prefs: []
  type: TYPE_TB
- en: '| P | 33.40 | 13.00 | 15.60 | 38.00 | 35.60 | 10.70 | 15.80 | 37.90 | 36.64
    | 10.24 | 13.97 | 39.15 |'
  prefs: []
  type: TYPE_TB
- en: '| H | 14.80 | 1.20 | 6.00 | 78.00 | 17.10 | 1.00 | 5.50 | 76.40 | 16.12 | 0.82
    | 5.58 | 77.48 |'
  prefs: []
  type: TYPE_TB
- en: '| SA | 48.80 | 3.60 | 14.00 | 33.60 | 47.90 | 4.10 | 13.60 | 34.40 | 42.73
    | 3.46 | 13.87 | 39.94 |'
  prefs: []
  type: TYPE_TB
- en: '| PC | 4.40 | 0.60 | 1.40 | 93.60 | 4.80 | 0.30 | 1.90 | 93.00 | 3.93 | 0.34
    | 1.56 | 94.18 |'
  prefs: []
  type: TYPE_TB
- en: '| D2 | TC | 52.40 | 13.20 | 7.60 | 26.80 | 53.10 | 13.20 | 8.10 | 25.60 | 48.56
    | 12.84 | 7.03 | 31.57 |'
  prefs: []
  type: TYPE_TB
- en: '| Q | 18.80 | 8.20 | 11.20 | 61.80 | 17.90 | 10.10 | 11.00 | 61.00 | 14.67
    | 10.00 | 10.44 | 64.89 |'
  prefs: []
  type: TYPE_TB
- en: '| SS | 16.80 | 3.60 | 8.20 | 71.40 | 15.70 | 3.80 | 8.90 | 71.60 | 14.86 |
    3.15 | 8.58 | 73.41 |'
  prefs: []
  type: TYPE_TB
- en: '| D | 46.00 | 8.20 | 4.20 | 41.60 | 48.50 | 8.10 | 4.30 | 39.10 | 43.10 | 7.68
    | 5.28 | 43.93 |'
  prefs: []
  type: TYPE_TB
- en: '| N | 1.00 | 1.40 | 2.80 | 94.80 | 1.40 | 1.30 | 3.40 | 93.90 | 2.10 | 1.08
    | 3.36 | 93.46 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Label distribution(%) in various aspects of train set and test set.
    D1 contains annotations for 6 aspects—food (F), beverage (B), price (P), hygiene
    (H), staff attitude (SA), and parking convenience (PC); D2 contains annotations
    for 5 different aspects—traffic convenience (TC), queuing (Q), serving speed (SS),
    decoration (D), and noise (N). We use ’Pos’, ‘Neu’, ’Neg’, ‘Unm’ to represent
    Positive, Neutral, Negative and Unmentioned labels, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Format adherence. Format adherence not only ensures that outputs from the model
    can be reliably parsed and utilized in practical applications, but also reflects
    the model’s ability to understand the context and the nuances of different instructions.
    We set up parsers according to the prescribed formats of different designs, then
    we calculate the ratio of predictions that cannot be successfully parsed with
    our output parser. Considering the inherently uncertainty nature of generative
    language models, we relaxed the format such as the expression of aspects and sentiments.
    Meanwhile, in order to compare the content correctness between designs more fairly,
    for some cases such as common punctuation errors, we will correct it into the
    required format when calculating the Kappa. Figure [10](#A1.F10 "Figure 10 ‣ A.8.2
    Perplexity Analysis ‣ A.8 Can PE Guide SDE? Detailed Results ‣ Appendix A Appendix
    ‣ Sample Design Engineering: An Empirical Study of What Makes Good Downstream
    Fine-Tuning Samples for LLMs") shows a variety of representative format error
    types and how they are processed by the parsers we design.'
  prefs: []
  type: TYPE_NORMAL
- en: A.2 Datasets and Training Settings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [2](#A1.T2 "Table 2 ‣ A.1 Metrics for MASA ‣ Appendix A Appendix ‣ Sample
    Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning
    Samples for LLMs") shows the label distribution of each aspect for two domains
    D1 and D2, where we can see the distributions are highly unbalanced.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The training setup was as follows: learning rate set to 1e-4, batch size of
    4, LoRA rank of 8 LoRA alpha of 32, LoRA dropout of 0.1.'
  prefs: []
  type: TYPE_NORMAL
- en: A.3 Sample Design Examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figure [9](#A1.F9 "Figure 9 ‣ A.6 Additional Analysis on Inst-last and Inst-first
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs") shows a detailed example
    of our sample designs on MASA tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: A.4 Detailed Evaluations of Each SDE Option
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The detailed results of in-domain (ID) and out-of-domain (OOD) evaluations
    on the MASA task of different SDE options across six LLMs are shown in Table [3](#A1.T3
    "Table 3 ‣ A.4 Detailed Evaluations of Each SDE Option ‣ Appendix A Appendix ‣
    Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning
    Samples for LLMs") to Table [8](#A1.T8 "Table 8 ‣ A.4 Detailed Evaluations of
    Each SDE Option ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs"), including
    both the sentiment analysis performances ($\kappa$) and the format adherence performances
    (format error rate). An averaged results of training size 500 and 1000 of ID and
    OOD scenarios are visualized in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Settings ‣ 4
    Experiments I: Evaluating The Impact of Each SDE Option ‣ Sample Design Engineering:
    An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '| model: c-llama2-chat | Weighted Kappa $\kappa$ | # Wrong format (7969 test
    samples in total) |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=500 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | .8091 | .6882 | .5243 | .7217 | 0 | 0 | 2 | 2
    |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | .8136 | .7079 | .5124 | .7223 | 0 | 0 | 9 | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | .7757 | .6626 | \ | \ | 20 | 1 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | .6187 | .6187 | .4806 | .2756 | 1 | 0 | 0 | 1079 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | .8091 | .6882 | .5243 | .7217 | 0 | 0 |
    2 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | .8083 | .6969 | .5068 | .7447 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | .8086 | .6952 | .4905 | .7354 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | .7697 | .6373 | .4221 | .6723 | 3 | 1 | 0 | 1260 |'
  prefs: []
  type: TYPE_TB
- en: '|  | _, _, OU | .7934 | .6005 | .5282 | .6203 | 0 | 0 | 87 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | .7934 | .6005 | .5282 | .6203 | 0 | 0 | 87 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | .7928 | .6873 | .5249 | .7085 | 56 | 65 | 36 | 282 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | .8074 | .6752 | .4726 | .7297 | 93 | 65 | 141 | 263 |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=1000 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8256 | 0.7110 | 0.5518 | 0.7312 | 0 | 0 | 0
    | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8236 | 0.7090 | 0.5483 | 0.7264 | 0 | 0 | 5 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.8003 | 0.6920 | \ | \ | 6 | 4 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.8113 | 0.6700 | 0.5095 | 0.5182 | 0 | 0 | 0 | 728 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.7916 | 0.7253 | 0.5303 | 0.7356 | 0 |
    0 | 0 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.8259 | 0.7118 | 0.5560 | 0.7452 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8249 | 0.7094 | 0.5488 | 0.7432 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.7624 | 0.6604 | 0.4210 | 0.6840 | 2 | 2 | 0 | 765 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.8172 | 0.7125 | 0.5511 | 0.6746 | 0 | 0 | 493 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.8018 | 0.7175 | 0.5332 | 0.7323 | 0 | 0 | 493 | 1
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.8111 | 0.7111 | 0.5354 | 0.7311 | 59 | 24 | 30 | 253 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.8214 | 0.7137 | 0.5085 | 0.7532 | 51 | 25 | 75 | 115 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: MASA evaluations of each SDE option for model c-llama2-chat. The first
    method in each group is the group baseline. "_" means keeping the same option
    with the group baseline.'
  prefs: []
  type: TYPE_NORMAL
- en: '| model: c-llama2-base | Weighted Kappa $\kappa$ | # Wrong format (7969 test
    samples in total) |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=500 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8067 | 0.6801 | 0.5246 | 0.7000 | 0 | 0 | 6
    | 98 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8092 | 0.6921 | 0.5575 | 0.6794 | 0 | 0 | 34 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.7762 | 0.6511 | \ | \ | 0 | 1 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7778 | 0.5024 | 0.4946 | 0.4184 | 2 | 0 | 118 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.8067 | 0.6801 | 0.5246 | 0.7000 | 0 |
    0 | 6 | 98 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.8066 | 0.6410 | 0.5128 | 0.6622 | 0 | 0 | 19 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8010 | 0.6242 | 0.5170 | 0.6287 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.7728 | 0.5949 | 0.5155 | 0.6296 | 14 | 1 | 26 | 356 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.7746 | 0.5012 | 0.4199 | 0.5711 | 0 | 3 | 300 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.8010 | 0.6242 | 0.5170 | 0.6287 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7789 | 0.6652 | 0.4649 | 0.6974 | 83 | 82 | 33 | 226 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.8019 | 0.6428 | 0.4657 | 0.4199 | 88 | 11 | 87 | 1823 |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=1000 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8237 | 0.7011 | 0.6010 | 0.7197 | 0 | 0 | 3
    | 177 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8231 | 0.7068 | 0.6069 | 0.6956 | 0 | 2 | 16 | 28 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.7957 | 0.6882 | \ | \ | 2 | 2 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.8048 | 0.6174 | 0.5306 | 0.6390 | 0 | 3 | 139 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.8237 | 0.7011 | 0.6010 | 0.7197 | 0 |
    0 | 3 | 177 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.8205 | 0.6947 | 0.5900 | 0.6963 | 0 | 0 | 10 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8212 | 0.6857 | 0.5649 | 0.6875 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.7619 | 0.6536 | 0.4804 | 0.6709 | 1 | 2 | 0 | 584 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.8179 | 0.6774 | 0.5034 | 0.6277 | 0 | 5 | 64 | 29 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.8212 | 0.6857 | 0.5649 | 0.6875 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.8026 | 0.6979 | 0.5519 | 0.7159 | 70 | 31 | 16 | 125 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.8195 | 0.7034 | 0.5368 | 0.6454 | 46 | 14 | 24 | 666 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: MASA evaluations of each SDE option for model c-llama2-base. Definition
    of "_" see Table [3](#A1.T3 "Table 3 ‣ A.4 Detailed Evaluations of Each SDE Option
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '| model: intern-chat | Weighted Kappa $\kappa$ | # Wrong format (7969 test
    samples in total) |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=500 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.7774 | 0.6278 | 0.3947 | 0.6707 | 0 | 0 | 0
    | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8035 | 0.6609 | 0.3949 | 0.7090 | 4 | 2 | 13 | 304 |'
  prefs: []
  type: TYPE_TB
- en: '| T2L | 0.7862 | 0.5963 | \ | \ | 10 | 7 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7463 | 0.5178 | 0.3153 | 0.5363 | 0 | 0 | 0 | 395 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.7774 | 0.6278 | 0.3947 | 0.6707 | 0 |
    0 | 0 | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.7827 | 0.6261 | 0.4032 | 0.6799 | 0 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.7713 | 0.5966 | 0.3965 | 0.6129 | 0 | 0 | 0 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.7765 | 0.6261 | 0.4165 | 0.6926 | 0 | 0 | 3 | 23 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.7520 | 0.4888 | 0.4029 | 0.6221 | 0 | 1 | 16 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.7713 | 0.5966 | 0.3965 | 0.6129 | 0 | 0 | 0 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7666 | 0.6401 | 0.4843 | 0.6797 | 43 | 19 | 30 | 121 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.7764 | 0.6124 | 0.3892 | 0.6648 | 44 | 23 | 23 | 72 |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=1000 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8049 | 0.6793 | 0.4330 | 0.6982 | 0 | 0 | 0
    | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8173 | 0.7125 | 0.4640 | 0.7343 | 0 | 1 | 6 | 259 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.8139 | 0.6811 | \ | \ | 8 | 5 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7819 | 0.6256 | 0.3332 | 0.6520 | 1 | 0 | 8 | 29 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.8049 | 0.6793 | 0.4330 | 0.6982 | 0 |
    0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.8060 | 0.6797 | 0.4498 | 0.7038 | 0 | 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8021 | 0.6649 | 0.4661 | 0.6647 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.8081 | 0.6764 | 0.4393 | 0.7286 | 0 | 0 | 3 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.8008 | 0.6369 | 0.4374 | 0.6694 | 0 | 0 | 33 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.8021 | 0.6649 | 0.4661 | 0.6647 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7981 | 0.6966 | 0.5190 | 0.7098 | 36 | 7 | 10 | 132 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.8043 | 0.6709 | 0.3994 | 0.7195 | 50 | 4 | 19 | 42 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: MASA evaluations of each SDE option for model intern-chat. Definition
    of "_" see Table [3](#A1.T3 "Table 3 ‣ A.4 Detailed Evaluations of Each SDE Option
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '| model: intern-base | Weighted Kappa $\kappa$ | # Wrong format (7969 test
    samples in total) |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=500 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.7849 | 0.6465 | 0.4898 | 0.6129 | 0 | 1 | 1
    | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.7955 | 0.6472 | 0.4947 | 0.7006 | 3 | 8 | 18 | 221 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.7936 | 0.6119 | \ | \ | 11 | 6 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7562 | 0.5029 | 0.3305 | 0.4672 | 0 | 1 | 232 | 447 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.7849 | 0.6465 | 0.4898 | 0.6129 | 0 |
    1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.7873 | 0.6455 | 0.4939 | 0.6365 | 0 | 2 | 4 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.7859 | 0.6250 | 0.4727 | 0.6127 | 0 | 0 | 3 | 82 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.7605 | 0.6003 | 0.3861 | 0.6412 | 14 | 3 | 10 | 102 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.7275 | 0.5185 | 0.3943 | 0.4935 | 0 | 4 | 48 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.7859 | 0.6250 | 0.4727 | 0.6127 | 0 | 0 | 3 | 82 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7621 | 0.6489 | 0.4581 | 0.6388 | 77 | 12 | 2347 | 50 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.7734 | 0.6342 | 0.3752 | 0.6816 | 141 | 49 | 1496 | 206 |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=1000 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8112 | 0.6874 | 0.5216 | 0.7065 | 1 | 0 | 0
    | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8167 | 0.6965 | 0.5195 | 0.7544 | 0 | 0 | 5 | 46 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.8191 | 0.6963 | \ | \ | 5 | 8 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7937 | 0.6238 | 0.2780 | 0.6492 | 0 | 2 | 383 | 45 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.8112 | 0.6874 | 0.5216 | 0.7065 | 1 |
    0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.8113 | 0.6919 | 0.5060 | 0.7126 | 0 | 0 | 3 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8076 | 0.6781 | 0.5195 | 0.6817 | 0 | 0 | 3 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.8084 | 0.6776 | 0.4426 | 0.7139 | 3 | 1 | 31 | 20 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.8006 | 0.6330 | 0.4587 | 0.6098 | 0 | 1 | 30 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.8076 | 0.6781 | 0.5195 | 0.6817 | 0 | 0 | 3 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7956 | 0.6874 | 0.5196 | 0.6903 | 34 | 12 | 405 | 56 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.8069 | 0.6725 | 0.4890 | 0.7185 | 46 | 11 | 220 | 125 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: MASA evaluations of each SDE option for model intern-base. Definition
    of "_" see Table [3](#A1.T3 "Table 3 ‣ A.4 Detailed Evaluations of Each SDE Option
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '| model: bc2-chat | Weighted Kappa $\kappa$ | # Wrong format (7969 test samples
    in total) |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=500 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.7904 | 0.6544 | 0.4067 | 0.6170 | 8 | 0 | 21
    | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.7958 | 0.6660 | 0.3858 | 0.6739 | 19 | 36 | 12 | 385 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.7176 | 0.4776 | \ | \ | 23 | 13 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7645 | 0.5636 | 0.3713 | 0.5490 | 0 | 0 | 5 | 16 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.7904 | 0.6544 | 0.4067 | 0.6170 | 8 |
    0 | 21 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.7869 | 0.6653 | 0.4091 | 0.6344 | 0 | 0 | 9 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.7927 | 0.6489 | 0.4714 | 0.6196 | 0 | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.7839 | 0.6401 | 0.3671 | 0.6506 | 5 | 4 | 12 | 17 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.7016 | 0.5670 | 0.3599 | 0.3285 | 2 | 81 | 50 | 19 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.7927 | 0.6489 | 0.4714 | 0.6196 | 0 | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7722 | 0.6400 | 0.5006 | 0.6776 | 3641 | 757 | 739 | 3323 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.7922 | 0.6535 | 0.4534 | 0.6579 | 107 | 126 | 280 | 563 |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=1000 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8113 | 0.7060 | 0.4709 | 0.6365 | 0 | 4 | 13
    | 18 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8142 | 0.7095 | 0.4733 | 0.6787 | 31 | 12 | 21 | 136 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.7466 | 0.6172 | \ | \ | 6 | 6 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7935 | 0.6514 | 0.3951 | 0.5885 | 0 | 0 | 7 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.8113 | 0.7060 | 0.4709 | 0.6365 | 0 |
    4 | 13 | 18 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.8103 | 0.7057 | 0.4691 | 0.6387 | 0 | 0 | 3 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8118 | 0.7064 | 0.5237 | 0.6323 | 0 | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.8121 | 0.6962 | 0.4042 | 0.6697 | 10 | 17 | 4 | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.8061 | 0.6467 | 0.4843 | 0.5155 | 1 | 25 | 44 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.8118 | 0.7064 | 0.5237 | 0.6323 | 0 | 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7995 | 0.7026 | 0.4992 | 0.6975 | 2273 | 193 | 560 | 2043 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.8087 | 0.6961 | 0.5022 | 0.6772 | 57 | 48 | 85 | 167 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7: MASA evaluations of each SDE option for model bc2-chat. Definition
    of "_" see Table [3](#A1.T3 "Table 3 ‣ A.4 Detailed Evaluations of Each SDE Option
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '| model: bc2-base | Weighted Kappa $\kappa$ | # Wrong format (7969 test samples
    in total) |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=500 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8017 | 0.6412 | 0.4441 | 0.6146 | 0 | 0 | 75
    | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8016 | 0.6649 | 0.4488 | 0.6657 | 0 | 6 | 27 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.7533 | 0.6020 | \ | \ | 2 | 3 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.7660 | 0.4999 | 0.3220 | 0.1978 | 0 | 0 | 1 | 164 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.8017 | 0.6412 | 0.4441 | 0.6146 | 0 |
    0 | 75 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.7996 | 0.6317 | 0.4583 | 0.6191 | 0 | 0 | 2 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8008 | 0.6476 | 0.4316 | 0.6104 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.7969 | 0.5794 | 0.4312 | 0.5206 | 7 | 45 | 469 | 47 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.7595 | 0.5202 | 0.4240 | 0.4944 | 0 | 0 | 116 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.7595 | 0.5202 | 0.4240 | 0.4944 | 0 | 0 | 116 | 2
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.7865 | 0.6814 | 0.3854 | 0.6745 | 63 | 17 | 43 | 483 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.7980 | 0.6548 | 0.4240 | 0.6349 | 32 | 44 | 39 | 32 |'
  prefs: []
  type: TYPE_TB
- en: '| train_size=1000 | D1→D1 | D2→D2 | D1→D2 | D2→D1 | D1→D1 | D2→D2 | D1→D2 |
    D2→D1 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 0.8143 | 0.6981 | 0.4747 | 0.6767 | 0 | 0 | 26
    | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 0.8155 | 0.7157 | 0.5061 | 0.6974 | 0 | 3 | 26 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| No-inst, _ | 0.7543 | 0.6391 | \ | \ | 0 | 3 | \ | \ |'
  prefs: []
  type: TYPE_TB
- en: '| _, MI | 0.8010 | 0.6489 | 0.4164 | 0.5250 | 0 | 0 | 1 | 431 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.8143 | 0.6981 | 0.4747 | 0.6767 | 0 |
    0 | 26 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.8103 | 0.7003 | 0.4732 | 0.6713 | 0 | 0 | 6 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.8120 | 0.7039 | 0.4785 | 0.6819 | 0 | 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.8119 | 0.6812 | 0.4575 | 0.6467 | 1 | 5 | 292 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.7894 | 0.6484 | 0.4031 | 0.6235 | 0 | 1 | 31 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.7894 | 0.6484 | 0.4031 | 0.6235 | 0 | 1 | 31 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.8045 | 0.7063 | 0.5319 | 0.6965 | 21 | 12 | 25 | 494 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.8160 | 0.7021 | 0.4604 | 0.6949 | 15 | 14 | 24 | 115 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 8: MASA evaluations of each SDE option for model bc2-base. Definition
    of "_" see Table [3](#A1.T3 "Table 3 ‣ A.4 Detailed Evaluations of Each SDE Option
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: A.5 Detailed Results on GENIA, MAVEN and Review11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [9](#A1.T9 "Table 9 ‣ A.5 Detailed Results on GENIA, MAVEN and Review11
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs") shows the comparison of different
    sample design strategies on three downstream tasks—GENIA (Nested NER), MAVEN (Event
    Detection), and Review11 (MASA). Hard and soft-matching F1 scores are reported
    for GENIA and MAVEN, while kappa $\kappa$ and accuracy are reported for Review11.
    From the results, we can see that ES-SDE maintains its advantage over other methods,
    across different tasks and training sizes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [10](#A1.T10 "Table 10 ‣ A.5 Detailed Results on GENIA, MAVEN and Review11
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs") illustrates the performances
    of different sample design strategies on three downstream tasks across different
    instruction variations.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | GENIA (Nested-NER) | MAVEN (ED) | Review11 (MASA) |'
  prefs: []
  type: TYPE_TB
- en: '| training size | Strategies | F1-hard | F1-soft | F1-hard | F1-soft | $\kappa$
    | Acc |'
  prefs: []
  type: TYPE_TB
- en: '| $500$ | heuristic | 0.51232 | 0.57465 | 0.5197 | 0.5356 | 0.588 | 0.7586
    |'
  prefs: []
  type: TYPE_TB
- en: '| EW-SDE | 0.48328 | 0.54318 | 0.4922 | 0.5364 | 0.7235 | 0.8327 |'
  prefs: []
  type: TYPE_TB
- en: '| ES-SDE | 0.54068 | 0.61412 | 0.5846 | 0.6331 | 0.7691 | 0.8626 |'
  prefs: []
  type: TYPE_TB
- en: '| $1,000$ | heuristic | 0.56537 | 0.62275 | 0.6237 | 0.6354 | 0.7058 | 0.8262
    |'
  prefs: []
  type: TYPE_TB
- en: '| EW-SDE | 0.48785 | 0.55166 | 0.6109 | 0.6275 | 0.7565 | 0.8502 |'
  prefs: []
  type: TYPE_TB
- en: '| ES-SDE | 0.61593 | 0.68951 | 0.6432 | 0.6726 | 0.7892 | 0.8716 |'
  prefs: []
  type: TYPE_TB
- en: '| $2,000$ | heuristic | 0.64759 | 0.69905 | 0.6722 | 0.6813 | 0.7479 | 0.8483
    |'
  prefs: []
  type: TYPE_TB
- en: '| EW-SDE | 0.54351 | 0.6025 | 0.6966 | 0.7106 | 0.7805 | 0.8649 |'
  prefs: []
  type: TYPE_TB
- en: '| ES-SDE | 0.68069 | 0.7393 | 0.7033 | 0.7172 | 0.8023 | 0.8785 |'
  prefs: []
  type: TYPE_TB
- en: '| $4,000$ | heuristic | 0.68726 | 0.73825 | 0.7118 | 0.7176 | 0.7751 | 0.8644
    |'
  prefs: []
  type: TYPE_TB
- en: '| EW-SDE | 0.71109 | 0.77093 | 0.7265 | 0.7338 | 0.7917 | 0.8715 |'
  prefs: []
  type: TYPE_TB
- en: '| ES-SDE | 0.72726 | 0.78487 | 0.7295 | 0.7466 | 0.805 | 0.8814 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 9: Comparison of different sample design strategies on three downstream
    tasks. ES-SDE maintains its advantage over other methods, across different tasks
    and training sizes.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | GENIA (Nested-NER) | MAVEN (ED) | Review11 (MASA) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Instruction Variation | Strategies | F1-hard | F1-soft | F1-hard | F1-soft
    | $\kappa$ | Acc |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| inst-1 | heuristic | 0.5123 | 0.5747 | 0.5197 | 0.5356 | 0.588 | 0.7586 |'
  prefs: []
  type: TYPE_TB
- en: '| EW-SDE | 0.4833 | 0.5432 | 0.4922 | 0.5364 | 0.7235 | 0.8327 |'
  prefs: []
  type: TYPE_TB
- en: '| ES-SDE | 0.5407 | 0.6141 | 0.5846 | 0.6331 | 0.7691 | 0.8626 |'
  prefs: []
  type: TYPE_TB
- en: '| inst-2 | heuristic | 0.49813 | 0.56095 | 0.5134 | 0.5334 | 0.6009 | 0.7685
    |'
  prefs: []
  type: TYPE_TB
- en: '| EW-SDE | 0.48593 | 0.54999 | 0.4956 | 0.5339 | 0.7208 | 0.8344 |'
  prefs: []
  type: TYPE_TB
- en: '| ES-SDE | 0.53479 | 0.60767 | 0.5636 | 0.6167 | 0.7659 | 0.8615 |'
  prefs: []
  type: TYPE_TB
- en: '| inst-3 | heuristic | 0.48733 | 0.55491 | 0.4940 | 0.5060 | 0.5793 | 0.7533
    |'
  prefs: []
  type: TYPE_TB
- en: '| EW-SDE | 0.47638 | 0.53685 | 0.4925 | 0.5399 | 0.721 | 0.8365 |'
  prefs: []
  type: TYPE_TB
- en: '| ES-SDE | 0.53525 | 0.60902 | 0.5530 | 0.6087 | 0.7624 | 0.8601 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 10: Performances of different sample design strategies on three downstream
    tasks across different instruction variations.'
  prefs: []
  type: TYPE_NORMAL
- en: A.6 Additional Analysis on Inst-last and Inst-first
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The experimental results showing that Inst-first consistently outperforms Inst-last
    across various tasks and models are thought-provoking, leading us to conduct a
    more in-depth analysis. We extract the attention weights related to some task-related
    fields in the instruction, and sum up these task-related attention weights for
    each token. Figure [8](#A1.F8 "Figure 8 ‣ A.6 Additional Analysis on Inst-last
    and Inst-first ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs") shows the comparison
    of the attention weights for a certain customer review. As we can see, tokens
    that are closer to the instruction usually get higher task-related attention weights.
    Intuitively, when people write reviews, they generally present their core opinions
    at the beginning. This leads to the possibility that if the instructions are placed
    at the front, those core parts may receive greater task-related attention weights.
    This may partly explain why Inst-first usually leads to a higher sentiment analysis
    performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d2b6106d39a97a922fd38183d9da802d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Comparison of task-related attention scores using Inst-last and Inst-first.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b4852be1e85384d6aa871b4667cdb817.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Examples of different sample designs on the MASA task.'
  prefs: []
  type: TYPE_NORMAL
- en: A.7 Additional Analysis on OU and PU
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In previous experiments, we found that OU performs much worse than PU. This
    intriguing result motivates us to a further analysis. Specifically, we calculate
    and compare the kappa scores of OU and PU for each aspect, to analyze the relationship
    between label distributions and the effect of OU.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the result in Table [11](#A1.T11 "Table 11 ‣ A.7 Additional Analysis on
    OU and PU ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study
    of What Makes Good Downstream Fine-Tuning Samples for LLMs"), we can observe that
    when training the model with 500 samples, for aspects with a higher number of
    unmentioned, the OU method showed a significant gap compared to the PU format.
    When the training set increased to 1000 samples, this gap noticeably narrowed.
    This suggests that for the OU method, aspects with more unmentioned, implying
    less frequent occurrence in answers, are harder for the model to learn, so requiring
    more data. From another perspective, it also indicates that even if a certain
    aspect is not covered in the text, mentioning this aspect in the answers can enhance
    the model’s understanding of it.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Aspect | Trainsize=500 | Trainsize=1000 |'
  prefs: []
  type: TYPE_TB
- en: '| (%)Num_ | $\Delta$ |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Unmen | Avg_Chat | Avg_Base | Unmen | Avg_Chat | Avg_Base |'
  prefs: []
  type: TYPE_TB
- en: '| D1 | F | 1.00 | -.0004 | .0007 | 1.40 | -.0026 | -.0011 |'
  prefs: []
  type: TYPE_TB
- en: '|  | SA | 33.60 | -.0687 | -.0555 | 34.40 | -.0062 | -.0212 |'
  prefs: []
  type: TYPE_TB
- en: '|  | P | 38.00 | -.0469 | -.0495 | 37.90 | -.0068 | -.0255 |'
  prefs: []
  type: TYPE_TB
- en: '|  | B | 65.40 | -.0410 | -.0291 | 65.70 | -.0117 | -.0079 |'
  prefs: []
  type: TYPE_TB
- en: '|  | H | 78.00 | -.0920 | -.1367 | 76.40 | -.0033 | -.0207 |'
  prefs: []
  type: TYPE_TB
- en: '|  | PC | 93.60 | -.2338 | -.2590 | 93.00 | -.0181 | -.0305 |'
  prefs: []
  type: TYPE_TB
- en: '| D2 | TC | 26.80 | -.0891 | -.1341 | 25.60 | -.0497 | -.0492 |'
  prefs: []
  type: TYPE_TB
- en: '|  | D | 41.60 | -.1106 | -.2475 | 39.10 | -.0280 | -.0500 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Q | 61.80 | -.0329 | -.0588 | 61.00 | -.0361 | -.0149 |'
  prefs: []
  type: TYPE_TB
- en: '|  | SS | 71.40 | -.2537 | -.2575 | 71.60 | -.0574 | -.0896 |'
  prefs: []
  type: TYPE_TB
- en: '|  | N | 94.80 | -.3347 | -.3954 | 93.90 | -.0494 | -.1405 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11: Number of ‘Unmentioned’ labels and average $\Delta$) for different
    aspects.'
  prefs: []
  type: TYPE_NORMAL
- en: A.8 Can PE Guide SDE? Detailed Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Evaluating the performances of sample designs involves fine-tuning models on
    downstream tasks, which can be time-consuming. Therefore, we also pondered whether
    it might be possible to design better samples without training models first. We
    tried to understand the inherent capabilities and potential of the model by experimenting
    with different prompt designs in both the zero-shot and in-context learning scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: A.8.1 Zero-shot and In-context Learning Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Zero-shot and In-context learning ability can directly reveal LLMs’ familiarity
    with the given task. In the zero-shot approach, we use the input (which contains
    the instruction on output format) from each SDE option as the prompt for the original
    frozen LLMs prediction. For the ICL approach, we add two fixed examples from the
    training set before each test instance. Considering the inference time cost caused
    by the increase in sample length, we limit our prediction and analysis to 500
    samples. All other experimental setups remain aligned with those described in
    Experiments I.
  prefs: []
  type: TYPE_NORMAL
- en: 'Zero-shot Study. All six 7B LLMs used in Section [4](#S4 "4 Experiments I:
    Evaluating The Impact of Each SDE Option ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs") exhibit poor
    zero-shot MASA ability, failing to follow the instructions to generate proper
    output in most cases, as shown in Table [13](#A1.T13 "Table 13 ‣ A.8.2 Perplexity
    Analysis ‣ A.8 Can PE Guide SDE? Detailed Results ‣ Appendix A Appendix ‣ Sample
    Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning
    Samples for LLMs"), making it hard to analysis its relationship with SDE results.
    Variations in format preferences across different models are observed, which we
    conjecture is strongly related to the datasets employed for instruction fine-tuning
    in each model. Some patterns are also contradictory between zero-shot and SDE.
    For example, the OU SDE option consistently harms DT performances, however, its
    prompts result in notably fewer format errors in zero-shot inference, for certain
    LLMs. Therefore, zero-shot performances can hardly tell good or bad SDE options.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In-context Learning Study. ICL can effectively improve LLMs’ instruction-following
    abilities resulting in far fewer formatting errors than zero-shot. Therefore we
    report the average sentiment analysis performances of each model on two domains
    in Table [14](#A1.T14 "Table 14 ‣ A.8.2 Perplexity Analysis ‣ A.8 Can PE Guide
    SDE? Detailed Results ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical
    Study of What Makes Good Downstream Fine-Tuning Samples for LLMs"). The results
    suggest that Inst-first and CoT enhance the performance of most models, which
    provides valuable insights for format selection during the fine-tuning process.
    For output designs, JSON and OU options outperform the other approaches for some
    models, differing from the SDE results.'
  prefs: []
  type: TYPE_NORMAL
- en: A.8.2 Perplexity Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Perplexity measures the uncertainty of the model in generating a given text
    sequence Chen et al. ([1998](#bib.bib5)), with lower perplexity values indicating
    more confident predictions by the model. In calculations, we estimate perplexity
    using the common practice of taking the logarithm of the model’s loss.
  prefs: []
  type: TYPE_NORMAL
- en: In our task, we compare the PPL scores of the ICL prompts corresponding to each
    different SDE option, as well as the conditional PPL of the models’ ICL predictions.
    For predictions, we concatenate the prompt and the prediction together as a sequence,
    then consider the prompt as its context.
  prefs: []
  type: TYPE_NORMAL
- en: 'The perplexity results for different designs are shown in Table [12](#A1.T12
    "Table 12 ‣ A.8.2 Perplexity Analysis ‣ A.8 Can PE Guide SDE? Detailed Results
    ‣ Appendix A Appendix ‣ Sample Design Engineering: An Empirical Study of What
    Makes Good Downstream Fine-Tuning Samples for LLMs"). For input designs, the PPL
    score of Inst-first option is lower than that of Inst-last in general, which is
    consistent with the conclusion that Inst-first performs better in ICL and SDE
    experiments. For output designs, the OU option gets the highest score, which is
    inconsistent with its performance on the ICL, but is consistent with its being
    the worst option in the SDE experiment. Surprisingly, the JSON format achieved
    the significantly lowest ppl score, but it was on par with the Lines format in
    ICL and even worse than Lines in SDE. The most interesting result appears in the
    reasoning designs. The CoT and R-CoT options have low PPL scores on prompts but
    have high scores on predictions conversely. Such contradictions make it difficult
    to analyze the results of ICL or SDE through PPL scores.'
  prefs: []
  type: TYPE_NORMAL
- en: The analysis above also highlights the indispensability of our SDE experiments,
    cause we cannot predetermine the final effectiveness of different designs through
    preliminary analysis alone.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6fd7699e9b06656876b04d7a41aea359.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Examples of format error types and how they are processed.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/516f27f97616a4c46a17d7804c5ae455.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Examples of different sample designs on GENIA, MAVEN and Review11.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7c73bea5fd489c8d4c76faa362f2ca61.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Variations of Instructions on different strategies.(taking MAVEN
    as an example)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Perplexity:Prompts | c-llama2-chat | c-llama2-base | intern-chat | intern-base
    | bc2-chat | bc2-base |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 47.662 | 111.063 | 18.422 | 19.036 | 59.046 |
    42.030 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 46.357 | 110.065 | 19.561 | 18.632 | 54.795 | 39.003 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 47.662 | 111.063 | 18.422 | 19.036 | 59.046
    | 42.030 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 47.918 | 191.274 | 18.561 | 19.219 | 60.498 | 42.638 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 29.008 | 78.848 | 14.675 | 13.260 | 38.547 | 25.405 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 41.690 | 92.717 | 17.664 | 16.348 | 51.963 | 35.185 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 55.345 | 129.055 | 20.862 | 21.450 | 69.022 | 49.426 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 29.008 | 78.848 | 14.675 | 13.260 | 38.547 | 25.405
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 18.263 | 41.312 | 10.812 | 9.379 | 23.406 | 15.267 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 18.210 | 42.648 | 10.789 | 9.354 | 22.671 | 15.333 |'
  prefs: []
  type: TYPE_TB
- en: '| Perplexity:Predictions | c-llama2-chat | c-llama2-base | intern-chat | intern-base
    | bc2-chat | bc2-base |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last, No-MI | 1.052 | 1.109 | 1.051 | 1.394 | 1.061 | 1.127
    |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first, _ | 1.088 | 1.284 | 1.046 | 1.360 | 1.066 | 1.113 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 1.052 | 1.109 | 1.051 | 1.394 | 1.061 |
    1.127 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 1.052 | 1.137 | 1.058 | 1.386 | 1.222 | 1.136 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 1.038 | 1.074 | 1.045 | 1.407 | 1.019 | 1.042 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 1.096 | 1.142 | 1.078 | 1.403 | 1.088 | 1.102 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 1.183 | 1.368 | 1.089 | 1.279 | 1.353 | 1.823 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 1.038 | 1.074 | 1.045 | 1.407 | 1.019 | 1.042 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 1.234 | 1.475 | 1.084 | 1.186 | 1.090 | 1.129 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 1.239 | 1.293 | 1.069 | 1.185 | 1.063 | 1.090 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 12: The PPL scores on the ICL prompts and predictions corresponding to
    each SDE options on the MASA ID tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | c-llama2-chat | Intern-chat | bc2-chat | c-llama2-base | Intern-base
    | bc2-base |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | D1 | D2 | D1 | D2 | D1 | D2 | D1 | D2 | D1 | D2 | D1 | D2 |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Ins-last | 74.24 | 31.67 | 85.82 | 11.75 | 40.67 | 22.12 | 88.92
    | 36.60 | 94.89 | 81.60 | 100 | 98.18 |'
  prefs: []
  type: TYPE_TB
- en: '| Ins-first | 70.05 | 44.82 | 98.76 | 99.61 | 59.56 | 24.18 | 88.62 | 27.49
    | 89.79 | 75.59 | 99.66 | 96.26 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 74.24 | 31.67 | 85.82 | 11.75 | 40.67 |
    22.12 | 88.92 | 36.60 | 94.89 | 81.60 | 100 | 98.18 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 1.18 | 1.31 | 99.94 | 97.06 | 4.17 | 1.57 | 72.51 | 12.10 |
    99.57 | 99.79 | 99.99 | 99.94 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 5.94 | 16.49 | 100 | 100 | 96.15 | 73.53 | 99.94 | 100 | 100
    | 100 | 100 | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| _, Numerical, _ | 99.87 | 92.21 | 99.99 | 100 | 100 | 100 | 100 | 100 | 100
    | 100 | 100 | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 45.75 | 18.31 | 70.21 | 31.38 | 44.15 | 50.93 | 72.79 | 87.99
    | 76.80 | 56.87 | 99.74 | 95.33 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 5.94 | 16.49 | 100 | 100 | 96.15 | 73.53 | 99.94 | 100
    | 100 | 100 | 100 | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 35.25 | 34.25 | 100 | 100 | 58.66 | 53.29 | 100 | 100 | 100 | 100 |
    99.99 | 99.99 |'
  prefs: []
  type: TYPE_TB
- en: '|  | R-CoT | 33.84 | 75.87 | 100 | 100 | 80.71 | 77.12 | 98.24 | 90.58 | 100
    | 100 | 100 | 100 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 13: Format error rate(%) in zero-shot scenario'
  prefs: []
  type: TYPE_NORMAL
- en: '| test_size=500 | c-llama2-chat | c-llama2-base | intern-chat | intern-base
    | bc2-chat | bc2-base |'
  prefs: []
  type: TYPE_TB
- en: '| Input | Inst-last | 0.3834 | 0.2835 | 0.1856 | 0.1212 | 0.4402 | 0.4187 |'
  prefs: []
  type: TYPE_TB
- en: '| Inst-first | 0.4832 | 0.2959 | 0.2038 | 0.2044 | 0.5091 | 0.4345 |'
  prefs: []
  type: TYPE_TB
- en: '| Output | Natural, TxtLabel, PU | 0.3834 | 0.2835 | 0.1856 | 0.1212 | 0.4402
    | 0.4187 |'
  prefs: []
  type: TYPE_TB
- en: '| Lines, _, _ | 0.4220 | 0.2921 | 0.2436 | 0.1846 | 0.3971 | 0.4077 |'
  prefs: []
  type: TYPE_TB
- en: '| JSON, _, _ | 0.3773 | 0.2132 | 0.3390 | 0.2954 | 0.4614 | 0.3683 |'
  prefs: []
  type: TYPE_TB
- en: '| _, NumLabel, _ | 0.1522 | 0.1666 | 0.2470 | 0.2603 | 0.2406 | 0.1960 |'
  prefs: []
  type: TYPE_TB
- en: '| _, _, OU | 0.3612 | 0.3168 | 0.2461 | 0.1443 | 0.1948 | 0.1924 |'
  prefs: []
  type: TYPE_TB
- en: '| Reasoning | No-CoT | 0.3773 | 0.2132 | 0.3390 | 0.2954 | 0.4614 | 0.3683
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 0.3383 | 0.2174 | 0.3636 | 0.3167 | 0.4810 | 0.4466 |'
  prefs: []
  type: TYPE_TB
- en: '| R-CoT | 0.3638 | 0.2445 | 0.3522 | 0.2633 | 0.4668 | 0.4075 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 14: The average weighted Kappa $\kappa$ on the MASA ID tasks in in-context
    learning scenario'
  prefs: []
  type: TYPE_NORMAL
