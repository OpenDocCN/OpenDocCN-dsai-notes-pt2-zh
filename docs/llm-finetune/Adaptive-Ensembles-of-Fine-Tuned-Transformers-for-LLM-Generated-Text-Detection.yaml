- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:38:11'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.13335](https://ar5iv.labs.arxiv.org/html/2403.13335)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Zhixin Lai Electrical and Computer Engineering
  prefs: []
  type: TYPE_NORMAL
- en: Cornell University Ithaca, NY, USA
  prefs: []
  type: TYPE_NORMAL
- en: zl768@cornell.edu    Xuesheng Zhang Recommendation
  prefs: []
  type: TYPE_NORMAL
- en: Meituan Beijing, China
  prefs: []
  type: TYPE_NORMAL
- en: xueshengz503@gmail.com    Suiyao Chen Industrial and Management Systems Engineering
  prefs: []
  type: TYPE_NORMAL
- en: University of South Florida Tampa, FL, USA
  prefs: []
  type: TYPE_NORMAL
- en: suiyaochen@usf.edu
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large language models (LLMs) have reached human-like proficiency in generating
    diverse textual content, underscoring the necessity for effective fake text detection
    to avoid potential risks such as fake news in social media. Previous research
    has mostly tested single models on in-distribution datasets, limiting our understanding
    of how these models perform on different types of data for LLM-generated text
    detection task. We researched this by testing five specialized transformer-based
    models on both in-distribution and out-of-distribution datasets to better assess
    their performance and generalizability. Our results revealed that single transformer-based
    classifiers achieved decent performance on in-distribution dataset but limited
    generalization ability on out-of-distribution dataset. To improve it, we combined
    the individual classifiers models using adaptive ensemble algorithms, which improved
    the average accuracy significantly from 91.8% to 99.2% on an in-distribution test
    set and from 62.9% to 72.5% on an out-of-distribution test set. The results indicate
    the effectiveness, good generalization ability, and great potential of adaptive
    ensemble algorithms in LLM-generated text detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: LLM-generated text detection, Adaptive assemble algorithm, Transformer-based
    classifier, Generalization ability, in-distribution dataset, out-of-distribution
    dataset
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recently, LLM has experienced rapid development, and its text generation ability
    is comparable to that of human writing [[1](#bib.bib1), [2](#bib.bib2)]. LLM has
    penetrated into various aspects of daily life and plays a crucial role in many
    professional workflows such as forecasting and anomaly detection [[3](#bib.bib3)],
    text production [[4](#bib.bib4)] and across various domains [[5](#bib.bib5), [6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)], promoting tasks such as advertising slogan creation,
    news writing [[9](#bib.bib9)], story generation, and code generation. In addition,
    their impact has significantly influenced the development of many sectors and
    disciplines, including education [[10](#bib.bib10)], law [[11](#bib.bib11)], biology
    [[12](#bib.bib12)], and medicine [[13](#bib.bib13)]. However, the use of GPTs
    also brings various risks.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, GPT and other high-level language generation models can generate realistic
    text, which may be used to create and disseminate misleading information [[14](#bib.bib14)],
    fake news, or harmful content. This may not only affect the public’s understanding
    of the facts, but also manipulate key areas such as political elections, the stock
    market, and public health. Secondly, LLMs can generate text with a similar style
    to existing content, which may lead to copyright infringement and intellectual
    property disputes [[15](#bib.bib15)]. For example, a model may replicate the style
    of a specific author in creating literary works, which may infringe upon the copyright
    of the original author. In addition, the content generated by LLMs may be used
    to produce pirated books, articles, or other media content, thereby damaging the
    economic interests and intellectual property rights of original content creators.
    Thirdly, LLM-generated content on social media platforms can be exploited to create
    false identities, enabling the manipulation of online conversations and public
    opinion. Automated accounts (bots) can leverage GPT-like models to generate a
    large volume of realistic comments, posts, or messages with deceptive, harassing,
    or persuasive intentions [[16](#bib.bib16), [17](#bib.bib17)]. In addition, the
    widespread use of models such as GPTs may lead to dishonest behavior in academic
    and educational fields. Students may use these tools to automatically generate
    papers and assignments, thereby undermining academic integrity [[18](#bib.bib18),
    [19](#bib.bib19)]. Lastly, many traditional industries are still cautiously adopting
    the power of LLM for text generation due to critical risk concerns such as cybersecurity
    [[20](#bib.bib20), [21](#bib.bib21)], healthcare [[22](#bib.bib22), [23](#bib.bib23),
    [24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26), [27](#bib.bib27)], transportation
    [[28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30)] and sophistication and
    reliability requirements for manufacturing [[31](#bib.bib31), [32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34)], environment [[35](#bib.bib35)], agriculture
    [[36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38)] and energy [[39](#bib.bib39)],
    etc.
  prefs: []
  type: TYPE_NORMAL
- en: However, telling machine-generated text from manually written text has proven
    to be a challenging task, with human performance only slightly surpassing chance
    levels [[40](#bib.bib40)]. Consequently, the development of efficient automated
    methods for identifying machine-generated text and mitigating its potential misuse
    is important. Even prior to the widespread adoption of ChatGPT, research on the
    detection of machine-generated text had garnered attention, particularly in the
    recognition of deeply forged texts [[41](#bib.bib41)]. Nowadays, with ChatGPT’s
    increasing prevalence, the primary focus of machine-generated text detection has
    shifted towards distinguishing between text generated by LLMs and text composed
    by humans [[42](#bib.bib42)]. For instance, Guo et al. have undertaken the task
    of detecting whether a given text, in both English and Chinese, originates from
    ChatGPT or has been written by a human across various domains [[43](#bib.bib43)].
    While the use of pre-trained language models (LMs) as classifiers has been established
    as an effective approach for detecting text generated by Large Language Models
    (LLMs), prior research, often confined to single-model evaluations on familiar
    datasets, provides limited insights into their broader applicability and generalization
    capabilities. Individual classifiers may exhibit instability and struggle to generalize
    when applied to unfamiliar data contexts [[44](#bib.bib44)]. In contrast, ensemble
    learning methods, such as the random forest algorithm [[45](#bib.bib45)], excel
    in such situations by combining multiple models to create a more accurate and
    robust predictor. Recognizing this, we integrated ensemble learning algorithms
    to amalgamate our trained transformer-based classifiers, aiming to enhance their
    performance and generalization capacity.
  prefs: []
  type: TYPE_NORMAL
- en: 'The principal contributions of this work are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We achieved the LLMs generated text detection task by training five distinct
    transformer-based classifiers, each pre-trained on different datasets. .
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We noticed variations in the accuracy of transformer-based classifiers and identified
    a notable constraint in their generalizability by evaluating the classifiers on
    different datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We employed both non-adaptive and adaptive ensemble techniques to improve the
    accuracy of LLM generated text detection. The adaptive ensemble method demonstrated
    the highest accuracy when tested on both in-distribution and out-of-distribution
    datasets, underscoring its superior effectiveness in identifying LLM-generated
    text.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: II Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The LLM-generated text detection task is framed as a binary classification problem.
    Transformer-based classifiers, which has been extensively explored in various
    domains [[46](#bib.bib46), [47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)], serve as one of the most popular and effective approaches for
    this classification task. Additionally, we recognized that ensemble learning algorithms
    offer an efficient means of enhancing classification performance. In this paper,
    we combined individual classifiers with ensemble algorithms, resulting in a significant
    improvement in the performance of LLM-generated text detection on both in-distribution
    and out-of-distribution datasets.
  prefs: []
  type: TYPE_NORMAL
- en: II-A Algorithms for machine-generated text detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Guo et al, applied two methods: logistic regression with GLTR features and
    an end-to-end RoBerta classifier to distinguish whether a text was generated by
    ChatGPT or humans across multiple fields [[43](#bib.bib43)]. Shijaku and Canhasi
    detected TOEFL essays using XGBoost with manually extracted 244 lexical and semantic
    features [[51](#bib.bib51)]. There are also widely-used off-the-shelf GPT detectors,
    such as the OpenAI detection classifier, GPTZero and ZeroGPT [[52](#bib.bib52)].
    OpenAI’s AI text classifier is fine-tuned on the output of an already trained
    language model. They used text generated by 34 models pre-trained by five different
    organizations, and then trained their models on samples from multiple sources
    of human writing and language model-generated text. GPTZero is trained on an extensive
    and diverse corpus of text created by humans and artificial intelligence, with
    a primary focus on English. As a classification model, GPTzero predicts whether
    a given text fragment is generated by a LLM with different text granularities,
    including sentence, paragraph, and entire document levels. These classifiers are
    all based on the transformer structure [[53](#bib.bib53)], providing us with some
    reference for the algorithm of selecting classifiers.'
  prefs: []
  type: TYPE_NORMAL
- en: II-B Ensemble Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ensemble learning refers to the machine learning paradigm where multiple learners
    (also known as models or predictors) are trained to solve the same problem. The
    main advantage of ensemble learning lies in its ability to improve model generalization
    ability. By combining multiple models, it can effectively reduce the risk of overfitting
    and underfitting. In addition, the diversity of different models can improve the
    overall prediction accuracy. Ensemble learning typically performs well in various
    machine learning competitions and practical applications [[54](#bib.bib54), [55](#bib.bib55)].
    We call algorithms without parameter updates in ensemble learning as ”non-adaptive
    ensemble algorithm”, like the hard voting ensemble [[56](#bib.bib56)]. And we
    call algorithms with parameter updates in ensemble learning as ”adaptive ensemble
    algorithm”, like the neural network ensemble and random forest algorithm. Usually,
    adaptive classifier detection performs better by adaptively integrating the outputs
    of different classifiers, assigning dynamic weights to each classifier’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: II-C Ensemble Learning for LLM-generated Text Detection Task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Specifically for LLM-generated text detection, since this is a unified data
    framework, ensemble learning will be a good fit to combine multiple models, instead
    of using fusion mechanisms [[57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59)]
    or model selection techniques [[60](#bib.bib60)]. LLM-Blender [[61](#bib.bib61)]
    is an ensemble framework designed to attain consistently superior performance
    by leveraging the diverse strengths of multiple open-source large language models
    (LLMs). The study [[62](#bib.bib62)] presents ensemble neural models utilizing
    probabilities from multiple pre-trained Large Language Models (LLMs) as features
    for Traditional Machine Learning (TML) classifiers to distinguish between AI-generated
    and human-written text, achieving competitive performance in both English and
    Spanish languages and ranking first in model attribution.
  prefs: []
  type: TYPE_NORMAL
- en: III Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We utilized the DAIGT dataset for training and in-distribution testing, consisting
    of a 2:1 ratio of human-generated to LLM-generated text. The LLM-generated text
    includes outputs from various LLMs, such as ChatGPT and Llama-70b [[63](#bib.bib63)].
    We divided the dataset into training and testing sets in an 80%/20% ratio, as
    shown in Table [I](#S3.T1 "TABLE I ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned
    Transformers for LLM-Generated Text Detection").
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: The item number of training and testing datasets'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Functionality | Human-generated | LLM-generated | Total |'
  prefs: []
  type: TYPE_TB
- en: '| DAIGT | Training | 23833 | 11531 | 35364 |'
  prefs: []
  type: TYPE_TB
- en: '| DAIGT | In-dist.^a testing | 5959 | 2883 | 8842 |'
  prefs: []
  type: TYPE_TB
- en: '| Deepfake | Out-of-dist.^a testing | 800 | 762 | 1562 |'
  prefs: []
  type: TYPE_TB
- en: '| ^adist.: distribution |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE II: Test average word length of training and testing Datasets'
  prefs: []
  type: TYPE_NORMAL
- en: '|      Dataset |      Human-written |      Machine-generated |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|      DAIGT |      466.82 |      369.09 |'
  prefs: []
  type: TYPE_TB
- en: '|      Deepfake |      279.43 |      284.33 |'
  prefs: []
  type: TYPE_TB
- en: 'To assess the generalizability of our text detection methods, we introduced
    the Deepfake dataset as out-of-distribution test set. The Deepfake, generated
    by a range of LLMs, encompasses broader domains including open statements, news
    articles, and scientific texts [[44](#bib.bib44)]. We compared the two datasets
    from the following aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Firstly, the DAIGT dataset has longer text lengths than the Deepfake dataset
    from Table [II](#S3.T2 "TABLE II ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned
    Transformers for LLM-Generated Text Detection").
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, we used the Latent Dirichlet Allocation (LDA) to analyze the dataset
    topic distribution, shown in Fig. [1](#S3.F1 "Figure 1 ‣ III Dataset ‣ Adaptive
    Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection"). The topic
    distribution indicates the dissimilarity in topic type and distribution between
    DAIGT and Deepfake datasets, indicating their divergence in content.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thirdly, from Fig. [2](#S3.F2 "Figure 2 ‣ III Dataset ‣ Adaptive Ensembles of
    Fine-Tuned Transformers for LLM-Generated Text Detection"), part-of-speech distribution
    in human-written and machine-generated text within the same dataset closely aligns,
    suggesting similar linguistic structures. However, when we compare DAIGT with
    Deepfake, a more notable disparity emerges in their part-of-speech distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The analyses from three different aspects of text length, topic, and part-of-speech
    distribution shows great difference between the DAIGT and Deepfake datasets. Therefore,
    we are confident to use Deepfake as an out-of-distribution dataset to test generalizability
    of different models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/048c28144f33ce474906a17502d91550.png)![Refer to caption](img/cb290ded0434eb9a20bdfe85ac04ac32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Datasets topic distribution'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6a602dfe128ba5b6a833a84ce72b61c5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Dataset part-of-speech tag.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ef6dd8996af4bf840371502341d21b66.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Structure of single classifer detection.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5bbed0c3a7de619371ae3ad071ca78b7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Structure of assemble detection.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3eb02fe14f5365507f34af5e360ef0a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Average accuracy of different methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE III: Detailed detection performance on in-distribution dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | Metrics |'
  prefs: []
  type: TYPE_TB
- en: '| Strategy | Method | Human-generated text | LLM-generated text | Global |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Recall | Precision | F1 | Recall | Precision | F1 | Accuracy |'
  prefs: []
  type: TYPE_TB
- en: '|  | DistilBert | 0.863 | 0.997 | 0.925 | 0.994 | 0.780 | 0.875 | 0.906 |'
  prefs: []
  type: TYPE_TB
- en: '|  | DeBERTaV3 | 0.967 | 0.995 | 0.981 | 0.990 | 0.936 | 0.962 | 0.974 |'
  prefs: []
  type: TYPE_TB
- en: '| Single Classifier | FNet | 0.961 | 0.862 | 0.909 | 0.685 | 0.896 | 0.776
    | 0.870 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Albert | 0.959 | 0.929 | 0.943 | 0.85 | 0.909 | 0.879 | 0.923 |'
  prefs: []
  type: TYPE_TB
- en: '|  | XLMRoberta | 0.879 | 0.996 | 0.934 | 0.993 | 0.801 | 0.887 | 0.917 |'
  prefs: []
  type: TYPE_TB
- en: '| Non-adaptive Ensemble | Hard Voting | 0.960 | 0.995 | 0.977 | 0.991 | 0.924
    | 0.956 | 0.970 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Neural Network | 0.996 | 0.992 | 0.994 | 0.984 | 0.992 | 0.988 | 0.992
    |'
  prefs: []
  type: TYPE_TB
- en: '| Adaptive Ensemble | Random Forest | 0.997 | 0.992 | 0.994 | 0.983 | 0.993
    | 0.988 | 0.992 |'
  prefs: []
  type: TYPE_TB
- en: '|  | GBDT | 0.995 | 0.992 | 0.993 | 0.983 | 0.990 | 0.987 | 0.992 |'
  prefs: []
  type: TYPE_TB
- en: 'TABLE IV: Accuracy Comparison between in-distribution and out-of-distribution
    datasets'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | Accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | Method | In-dist. testing | Out-of-dist. testing |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | DAIGT | Deepfake |'
  prefs: []
  type: TYPE_TB
- en: '|  | DistilBert | 0.906 | 0.567 |'
  prefs: []
  type: TYPE_TB
- en: '|  | DeBERTaV3 | 0.974 | 0.616 |'
  prefs: []
  type: TYPE_TB
- en: '| Single Classifier | FNet | 0.870 | 0.659 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Albert | 0.923 | 0.699 |'
  prefs: []
  type: TYPE_TB
- en: '|  | XLMRoberta | 0.917 | 0.602 |'
  prefs: []
  type: TYPE_TB
- en: '| Non-adaptive Ensemble | Hard Voting | 0.970 | 0.651 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Neural Network | 0.992 | 0.736 |'
  prefs: []
  type: TYPE_TB
- en: '| Adaptive Ensemble | Random Forest | 0.992 | 0.722 |'
  prefs: []
  type: TYPE_TB
- en: '|  | GBDT | 0.992 | 0.718 |'
  prefs: []
  type: TYPE_TB
- en: IV Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this study, we firstly developed single classifier models leveraging pretrained
    transformers. Also, we aggregated the output of the classifiers with non-adaptive
    ensemble and adaptive ensemble methods. The performance and generalizability of
    these models and methods was subsequently evaluated on DAIGT and Deepfake datasets.
  prefs: []
  type: TYPE_NORMAL
- en: IV-A Single Classifier Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The classifiers are pre-trained transformer-based LMs, which were subsequently
    fine-tuned for the LLM-generated text detection task. As illustrated in Fig. [3](#S3.F3
    "Figure 3 ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection"), each classifier is associated with a classification head, comprising
    dropout and dense layers, integrated with the backbone of a transformer-based
    LM. We employed five distinct transformer-based LMs as the backbones for five
    individual classifiers. The pre-trained layers of the LM are frozen (not updated
    during training) to preserve their learned features. Only the classifier “head”
    (the last layer) is trained. In addition, we use cross-entropy loss and Adam optimizer
    with a learning rate of 5e-4\. During model training, each text sample is truncated
    to a maximum of 256 tokens, the classifier is trained for 8841 steps and each
    training batch contains 4 samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'The summary of the pre-trained LMs is provided below: 1) DistilBert: DistilBERT
    is developed through the distillation of the BERT base model, is notably smaller
    and faster [[64](#bib.bib64)]. We use the “distil_bert_base_en_uncased” as pretrained
    backbone weight. 2) DeBERTaV3: DeBERTaV3 is an enhanced pre-trained language model
    that outperforms its predecessor by implementing replaced token detection (RTD)
    and introducing a gradient-disentangled embedding sharing method [[65](#bib.bib65)].
    We use the “deberta_v3_base_en” as pretrained backbone weight. 3) FNet: FNet introduces
    a novel approach to speed up Transformer encoders by replacing self-attention
    sublayers with linear transformations, achieving 92-97% of BERT’s accuracy on
    the GLUE benchmark while training significantly faster [[66](#bib.bib66)]. We
    use the “f_net_base_en” as pretrained backbone weight. 4) Albert: Albert presents
    two parameter-reduction techniques that lower memory usage and accelerate training
    of BERT, achieving superior scaling and performance [[67](#bib.bib67)]. We use
    the “albert_base_en_uncased” as pretrained backbone weight. 5) XLMRoberta: XLMRoberta
    is a large-scale multilingual transformer-based LM pretrained on a diverse set
    of one hundred languages using extensive CommonCrawl data [[68](#bib.bib68)].
    We use the “xlm_roberta_base_multi” as pretrained backbone weight.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Non-Adaptive Ensemble
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '1) Hard Voting Ensemble: The hard voting ensemble integrates the outputs of
    the distinct classifiers through a hard voting mechanism. Shown in Fig. [4](#S3.F4
    "Figure 4 ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection"), this ensemble technique operates by aggregating the predictions
    from each individual classifier without extra model training, where each classifier
    contributes a “vote” towards the final decision. The prediction receiving the
    majority of votes is then selected as the ensemble’s output.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Adaptive Ensemble
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Adaptive ensemble presents adaptive approaches of classifier aggregation, including
    neural network ensemble random forest ensemble, and GBDT ensemble. Shown in Fig. [4](#S3.F4
    "Figure 4 ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection"), the adaptive ensemble methods assign dynamic weights to the
    output of each classifier based on their performance, enabling a more effective
    and context-sensitive combination of predictions. 1) Neural Network Ensemble:
    The neural network ensemble integrates with two ReLU-activated dense layers of
    32 and 16 neurons, each followed by 50% dropout for regularization, following
    the output from the five transformer-based classifiers, shown in Fig. [4](#S3.F4
    "Figure 4 ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection"). This structure employs dense layers to effectively synthesize
    the classifiers’ outputs, while the dropout layer aids in preventing overfitting,
    thus enhancing the model’s generalization capabilities. During the model training
    for the Neural Network, the five classifiers are frozen. The model was trained
    for 10 epochs using a batch size of 128 with the Adam optimizer and cross-entropy
    loss. The training process took just around 5 seconds. 2) Random Forest Ensemble:
    The random forest algorithm [[45](#bib.bib45)] with 100 estimators is used to
    adaptively aggregate the outputs of the distinct classifiers, shown in Fig. [4](#S3.F4
    "Figure 4 ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection"). During the model training for Random Forest, the five classifiers
    are frozen. This method capitalizes on the inherent adaptability and decision-making
    prowess of random forests to dynamically integrate classifier outputs, thereby
    enabling a more nuanced and context-sensitive ensemble decision-making process.
    3) GBDT (Gradient Boosting Decision Trees) Ensemble: GBDT [31] with 100 estimators
    adaptively aggregates outputs from the five classifiers, shown in Fig. [4](#S3.F4
    "Figure 4 ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection"). During the model training for the GBDT, the five classifiers
    are frozen. The approach ensures a dynamic and context-sensitive integration of
    diverse classifier predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: V Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We employed the standard metrics conventionally utilized in the domain of text
    classification: recall, precision, F1, and accuracy [[69](#bib.bib69)]. From Table [III](#S3.T3
    "TABLE III ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection") and [IV](#S3.T4 "TABLE IV ‣ III Dataset ‣ Adaptive Ensembles
    of Fine-Tuned Transformers for LLM-Generated Text Detection"), the adaptive ensemble
    methods have superior performance compared to single classifier models and non-adaptive
    ensemble. The adaptive ensemble methods achieve the best F1 scores for both LLM-generated
    and human-written texts, as well as the top accuracy across both in-distribution
    and out-of-distribution datasets. The findings highlight the adaptive ensemble
    methods’ robustness and their enhanced ability to generalize in detecting LLM-generated
    text.'
  prefs: []
  type: TYPE_NORMAL
- en: V-A Single Model Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As indicated in Table [III](#S3.T3 "TABLE III ‣ III Dataset ‣ Adaptive Ensembles
    of Fine-Tuned Transformers for LLM-Generated Text Detection"), the single classifiers
    demonstrate a predilection for higher Precision and F1 scores when classifying
    human-generated text, mainly attributed to the imbalanced dataset. The recall
    rates for human-generated versus LLM-generated text differ significantly among
    classifiers, underscoring the distinctiveness of each model. This diversity suggests
    that these models are well-suited for combination through ensemble algorithms,
    potentially enhancing overall classification performance. In Table [IV](#S3.T4
    "TABLE IV ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated
    Text Detection"), compared to in-distribution test set DAIGT, there is a significant
    accuracy regression on out-of-distribution test set Deepfake. Single classifier
    has bad generalization capabilities for unseen dataset. Also, DeBERTaV3 performs
    best in DAIGT while Albert performs best in Deepfake, which approves the generalization
    capabilities variance among transformer-based classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: V-B Non-Adaptive Ensemble Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The hard voting ensemble method achieved an accuracy of 0.970, surpassing most
    single classifier models, though it slightly underperforms the highest-performing
    DeBERTaV3 classifier, which recorded an accuracy of 0.974 on in-distribution dataset.
    This outcome aligns with expectations, as hard voting is a non-adaptive ensemble
    approach, and its performance is typically near that of the best-performing individual
    model.
  prefs: []
  type: TYPE_NORMAL
- en: V-C Adaptive Ensemble Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Table [III](#S3.T3 "TABLE III ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned
    Transformers for LLM-Generated Text Detection"), the adaptive ensemble detection
    approach achieved an accuracy of 0.992 on the in-distribution test set, outperforming
    single classifier models and non-adaptive ensemble method. It also achieved the
    highest F1 scores for both detecting human and LLM-generated texts, demonstrating
    superior classification capabilities. Table [IV](#S3.T4 "TABLE IV ‣ III Dataset
    ‣ Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection")
    shows that adaptive ensemble methods also excel on out-of-distribution datasets,
    with the Neural Network Ensemble reaching the highest accuracy of 0.736, evidencing
    better generalization capabilities than single transformer-based classifier. In
    Fig. [5](#S3.F5 "Figure 5 ‣ III Dataset ‣ Adaptive Ensembles of Fine-Tuned Transformers
    for LLM-Generated Text Detection"), adaptive assemble methods have the average
    accuracy of 0.992 on DAIGT and 0.725 on Deepfake, while transformer-based classifiers
    have 0.918 on DAIGT and 0.629 on Deepfake. In summary, the adaptive ensemble methods,
    integrated with its constituent transformer-based classifiers, significantly enhances
    the performance and generalization ability of LLM-generated text detection task,
    based on the results cross different datasets.
  prefs: []
  type: TYPE_NORMAL
- en: VI Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper has successfully demonstrated the significant advantages of adaptive
    ensemble methods in the field of text classification in distinguishing between
    text generated by humans and large language models. This paper revealed that while
    individual transformer-based classifiers can tell LLM generated text, they exhibit
    constraints in their capacity to generalize when confronted with out-of-distribution
    data. The implementation of adaptive ensemble strategies has proven to be instrumental
    in mitigating the limitation. The adaptive ensemble not only improved accuracy
    in in-distribution dataset significantly but also showed better generalization
    ability out-of-distribution dataset. This dual enhancement in accuracy and generalizability
    makes the adaptive ensemble method as a robust, excellent tool in the ongoing
    challenge of LLM-generated text detection.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sincere thanks to Zelun Wang for paper review.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida,
    J. Altenschmidt, S. Altman, S. Anadkat *et al.*, “Gpt-4 technical report,” *arXiv
    preprint arXiv:2303.08774*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Anthropic, “Model card and evaluations for claude models,” Anthropic, Tech.
    Rep., 2023\. [Online]. Available: https://www-files.anthropic.com/production/
    images/Model-Card-Claude-2.pdf'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] J. Su, C. Jiang, X. Jin, Y. Qiao, T. Xiao, H. Ma, R. Wei, Z. Jing, J. Xu,
    and J. Lin, “Large language models for forecasting and anomaly detection: A systematic
    literature review,” *arXiv preprint arXiv:2402.10350*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] V. Veselovsky, M. H. Ribeiro, and R. West, “Artificial artificial artificial
    intelligence: Crowd workers widely use large language models for text production
    tasks,” *arXiv preprint arXiv:2306.07899*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] T. Liu, I. Škrjanec, and V. Demberg, “Temperature-scaling surprisal estimates
    improve fit to human reading times–but does it do so for the “right reasons”?”
    in *ICLR 2024 Workshop on Representational Alignment*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] D. Li, J. You, K. Funakoshi, and M. Okumura, “A-tip: attribute-aware text
    infilling via pre-trained language model,” in *Proceedings of the 29th International
    Conference on Computational Linguistics*, 2022, pp. 5857–5869.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Y. Zhou, X. Li, Q. Wang, and J. Shen, “Visual in-context learning for large
    vision-language models,” *arXiv preprint arXiv:2402.11574*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Y. Zhou, X. Geng, T. Shen, C. Tao, G. Long, J.-G. Lou, and J. Shen, “Thread
    of thought unraveling chaotic contexts,” *arXiv preprint arXiv:2311.08734*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] T. Liu, C. Xu, Y. Qiao, C. Jiang, and W. Chen, “News recommendation with
    attention mechanism,” *Journal of Industrial Engineering and Applied Science*,
    vol. 2, no. 1, pp. 21–26, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] T. Susnjak, “Chatgpt: The end of online exam integrity?” *arXiv preprint
    arXiv:2212.09292*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] J. Cui, Z. Li, Y. Yan, B. Chen, and L. Yuan, “Chatlaw: Open-source legal
    large language model with integrated external knowledge bases,” *arXiv preprint
    arXiv:2306.16092*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] S. R. Piccolo, P. Denny, A. Luxton-Reilly, S. Payne, and P. G. Ridge,
    “Many bioinformatics programming tasks can be automated with chatgpt,” *arXiv
    preprint arXiv:2303.13528*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F.
    Tan, and D. S. W. Ting, “Large language models in medicine,” *Nature medicine*,
    vol. 29, no. 8, pp. 1930–1940, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang,
    A. Madotto, and P. Fung, “Survey of hallucination in natural language generation,”
    *ACM Computing Surveys*, vol. 55, no. 12, pp. 1–38, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] J. Lee, T. Le, J. Chen, and D. Lee, “Do language models plagiarize?” in
    *Proceedings of the ACM Web Conference 2023*, 2023, pp. 3637–3647.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] L. Weidinger, J. Mellor, M. Rauh, C. Griffin, J. Uesato, P.-S. Huang,
    M. Cheng, M. Glaese, B. Balle, A. Kasirzadeh *et al.*, “Ethical and social risks
    of harm from language models,” *arXiv preprint arXiv:2112.04359*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] N. Ayoobi, S. Shahriar, and A. Mukherjee, “The looming threat of fake
    and llm-generated linkedin profiles: Challenges and opportunities for detection
    and prevention,” in *Proceedings of the 34th ACM Conference on Hypertext and Social
    Media*, 2023, pp. 1–10.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] C. Stokel-Walker, “Ai bot chatgpt writes smart essays-should academics
    worry?” *Nature*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] E. Kasneci, K. Seßler, S. Küchemann, M. Bannert, D. Dementieva, F. Fischer,
    U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier *et al.*, “Chatgpt for good?
    on opportunities and challenges of large language models for education,” *Learning
    and individual differences*, vol. 103, p. 102274, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Y. Liang, X. Wang, Y. C. Wu, H. Fu, and M. Zhou, “A study on blockchain
    sandwich attack strategies based on mechanism design game theory,” *Electronics*,
    vol. 12, no. 21, p. 4417, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] J. Tian, C. Shen, B. Wang, X. Xia, M. Zhang, C. Lin, and Q. Li, “Lesson:
    Multi-label adversarial false data injection attack for deep learning locational
    detection,” *IEEE Transactions on Dependable and Secure Computing*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] J. Liu, T. Hu, Y. Zhang, X. Gai, Y. Feng, and Z. Liu, “A chatgpt aided
    explainable framework for zero-shot medical image diagnosis,” *arXiv preprint
    arXiv:2307.01981*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] S. Chen, N. Kong, X. Sun, H. Meng, and M. Li, “Claims data-driven modeling
    of hospital time-to-readmission risk with latent heterogeneity,” *Health care
    management science*, vol. 22, pp. 156–179, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Y. Li, W. Wang, X. Yan, M. Gao, and M. Xiao, “Research on the application
    of semantic network in disease diagnosis prompts based on medical corpus,” *International
    Journal of Innovative Research in Computer Science & Technology*, vol. 12, no. 2,
    pp. 1–9, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] S. Chen, W. D. Kearns, J. L. Fozard, and M. Li, “Personalized fall risk
    assessment for long-term care services improvement,” in *2017 Annual Reliability
    and Maintainability Symposium (RAMS)*.   IEEE, 2017, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] W. Dai, J. Tao, X. Yan, Z. Feng, and J. Chen, “Addressing unintended bias
    in toxicity detection: An lstm and attention-based approach,” in *2023 5th International
    Conference on Artificial Intelligence and Computer Applications (ICAICA)*.   IEEE,
    2023, pp. 375–379.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] J. Liu, T. Hu, Y. Zhang, Y. Feng, J. Hao, J. Lv, and Z. Liu, “Parameter-efficient
    transfer learning for medical visual question answering,” *IEEE Transactions on
    Emerging Topics in Computational Intelligence*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] T. Liu, C. Xu, Y. Qiao, C. Jiang, and J. Yu, “Particle filter slam for
    vehicle localization,” *Journal of Industrial Engineering and Applied Science*,
    vol. 2, no. 1, pp. 27–31, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] S. Chen, L. Lu, Y. Xiang, Q. Lu, and M. Li, “A data heterogeneity modeling
    and quantification approach for field pre-assessment of chloride-induced corrosion
    in aging infrastructures,” *Reliability Engineering & System Safety*, vol. 171,
    pp. 123–135, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] J. Tian, B. Wang, R. Guo, Z. Wang, K. Cao, and X. Wang, “Adversarial attacks
    and defenses for deep-learning-based unmanned aerial vehicles,” *IEEE Internet
    of Things Journal*, vol. 9, no. 22, pp. 22 399–22 409, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] S. Chen, L. Lu, and M. Li, “Multi-state reliability demonstration tests,”
    *Quality Engineering*, vol. 29, no. 3, pp. 431–445, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] J. Wu, N. Hovakimyan, and J. Hobbs, “Genco: An auxiliary generator from
    contrastive learning for enhanced few-shot learning in remote sensing,” *arXiv
    preprint arXiv:2307.14612*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] S. Chen, L. Lu, Q. Zhang, and M. Li, “Optimal binomial reliability demonstration
    tests design under acceptance decision uncertainty,” *Quality Engineering*, vol. 32,
    no. 3, pp. 492–508, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] B. Wang, L. Lu, S. Chen, and M. Li, “Optimal test design for reliability
    demonstration under multi-stage acceptance uncertainties,” *Quality Engineering*,
    vol. 0, no. 0, pp. 1–14, 2023\. [Online]. Available: https://doi.org/10.1080/08982112.2023.2249188'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] S. Chen, K. Li, H. Fu, Y. C. Wu, and Y. Huang, “Sea ice extent prediction
    with machine learning methods and subregional analysis in the arctic,” *Atmosphere*,
    vol. 14, no. 6, p. 1023, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] R. Tao, P. Zhao, J. Wu, N. F. Martin, M. T. Harrison, C. Ferreira, Z. Kalantari,
    and N. Hovakimyan, “Optimizing crop management with reinforcement learning and
    imitation learning,” *arXiv preprint arXiv:2209.09991*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] J. Wu, R. Tao, P. Zhao, N. F. Martin, and N. Hovakimyan, “Optimizing nitrogen
    management with deep reinforcement learning and crop simulations,” in *Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition*, 2022,
    pp. 1712–1720.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] J. Wu, D. Pichler, D. Marley, D. Wilson, N. Hovakimyan, and J. Hobbs,
    “Extended agriculture-vision: An extension of a large aerial image dataset for
    agricultural pattern analysis,” *arXiv preprint arXiv:2303.02460*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] J.-Y. Shi, L.-T. Ling, F. Xue, Z.-J. Qin, Y.-J. Li, Z.-X. Lai, and T. Yang,
    “Combining incremental conductance and firefly algorithm for tracking the global
    mpp of pv arrays,” *Journal of Renewable and Sustainable Energy*, vol. 9, no. 2,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] E. Mitchell, Y. Lee, A. Khazatsky, C. D. Manning, and C. Finn, “Detectgpt:
    Zero-shot machine-generated text detection using probability curvature,” in *International
    Conference on Machine Learning*.   PMLR, 2023, pp. 24 950–24 962.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] J. Pu, Z. Sarwar, S. M. Abdullah, A. Rehman, Y. Kim, P. Bhattacharya,
    M. Javed, and B. Viswanath, “Deepfake text detection: Limitations and opportunities,”
    in *2023 IEEE Symposium on Security and Privacy (SP)*.   IEEE, 2023, pp. 1613–1630.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] G. Jawahar, M. Abdul-Mageed, and L. V. Lakshmanan, “Automatic detection
    of machine generated text: A critical survey,” *arXiv preprint arXiv:2011.01314*,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] B. Guo, X. Zhang, Z. Wang, M. Jiang, J. Nie, Y. Ding, J. Yue, and Y. Wu,
    “How close is chatgpt to human experts? comparison corpus, evaluation, and detection,”
    *arXiv preprint arXiv:2301.07597*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Y. Li, Q. Li, L. Cui, W. Bi, L. Wang, L. Yang, S. Shi, and Y. Zhang, “Deepfake
    text detection in the wild,” *arXiv preprint arXiv:2305.13242*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] L. Breiman, “Random forests,” *Machine learning*, vol. 45, pp. 5–32, 2001.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner,
    M. Dehghani, M. Minderer, G. Heigold, S. Gelly *et al.*, “An image is worth 16x16
    words: Transformers for image recognition at scale,” *arXiv preprint arXiv:2010.11929*,
    2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
    of deep bidirectional transformers for language understanding,” *arXiv preprint
    arXiv:1810.04805*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] J. Wu, S. Chen, Q. Zhao, R. Sergazinov, C. Li, S. Liu, C. Zhao, T. Xie,
    H. Guo, C. Ji *et al.*, “Switchtab: Switched autoencoders are effective tabular
    learners,” *arXiv preprint arXiv:2401.02013*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] S. Chen, J. Wu, N. Hovakimyan, and H. Yao, “Recontab: Regularized contrastive
    representation learning for tabular data,” *arXiv preprint arXiv:2310.18541*,
    2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] X. Li, X. Wang, X. Chen, Y. Lu, H. Fu, and Y. C. Wu, “Unlabeled data selection
    for active learning in image classification,” *Scientific Reports*, vol. 14, no. 1,
    p. 424, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] R. Shijaku and E. Canhasi, “Chatgpt generated text detection,” *Publisher:
    Unpublished*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Y. Wang, J. Mansurov, P. Ivanov, J. Su, A. Shelmanov, A. Tsvigun, C. Whitehouse,
    O. M. Afzal, T. Mahmoud, A. F. Aji *et al.*, “M4: Multi-generator, multi-domain,
    and multi-lingual black-box machine-generated text detection,” *arXiv preprint
    arXiv:2305.14902*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” *Advances in neural
    information processing systems*, vol. 30, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] M. Zhu, Y. Zhang, Y. Gong, K. Xing, X. Yan, and J. Song, “Ensemble methodology:
    Innovations in credit default prediction using lightgbm, xgboost, and localensemble,”
    *arXiv preprint arXiv:2402.17979*, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Z. Hu, J. Zhang, H. Wang, S. Liu, and S. Liang, “Leveraging relational
    graph neural network for transductive model ensemble,” in *Proceedings of the
    29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining*, 2023, pp.
    775–787.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] R. Delgado, “A semi-hard voting combiner scheme to ensemble multi-class
    probabilistic classifiers,” *Applied Intelligence*, vol. 52, no. 4, pp. 3653–3677,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] W. Weimin, L. Yufeng, Y. Xu, X. Mingxuan, and G. Min, “Enhancing liver
    segmentation: A deep learning approach with eas feature extraction and multi-scale
    fusion,” *International Journal of Innovative Research in Computer Science & Technology*,
    vol. 12, no. 1, pp. 26–34, 2024.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] D. Li, Y. Wang, K. Funakoshi, and M. Okumura, “Joyful: Joint modality
    fusion and graph contrastive learning for multimodal emotion recognition,” *arXiv
    preprint arXiv:2311.11009*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Y. Wang, D. Li, K. Funakoshi, and M. Okumura, “Emp: emotion-guided multi-modal
    fusion and contrastive learning for personality traits recognition,” in *Proceedings
    of the 2023 ACM International Conference on Multimedia Retrieval*, 2023, pp. 243–252.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Z. Hu, J. Zhang, Y. Yu, Y. Zhuang, and H. Xiong, “How many validation
    labels do you need? exploring the design space of label-efficient model ranking,”
    *arXiv preprint arXiv:2312.01619*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] J. H. Friedman, “Greedy function approximation: a gradient boosting machine,”
    *Annals of statistics*, pp. 1189–1232, 2001.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] H. Abburi, M. Suesserman, N. Pudota, B. Veeramani, E. Bowen, and S. Bhattacharya,
    “Generative ai text classification using ensemble llm approaches,” *arXiv preprint
    arXiv:2309.07755*, 2023.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] D. Kleczek, *DAIGT Proper Train Dataset*, Kaggle, 2013\. [Online]. Available:
    https://www.kaggle.com/datasets/thedrcat/daigt-proper-train-dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] V. Sanh, L. Debut, J. Chaumond, and T. Wolf, “Distilbert, a distilled
    version of bert: smaller, faster, cheaper and lighter,” *arXiv preprint arXiv:1910.01108*,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] P. He, J. Gao, and W. Chen, “Debertav3: Improving deberta using electra-style
    pre-training with gradient-disentangled embedding sharing,” *arXiv preprint arXiv:2111.09543*,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] J. Lee-Thorp, J. Ainslie, I. Eckstein, and S. Ontanon, “Fnet: Mixing tokens
    with fourier transforms,” *arXiv preprint arXiv:2105.03824*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut, “Albert:
    A lite bert for self-supervised learning of language representations,” *arXiv
    preprint arXiv:1909.11942*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] A. Conneau, K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek, F. Guzmán,
    E. Grave, M. Ott, L. Zettlemoyer, and V. Stoyanov, “Unsupervised cross-lingual
    representation learning at scale,” *arXiv preprint arXiv:1911.02116*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] F. Sebastiani, “Machine learning in automated text categorization,” *ACM
    computing surveys (CSUR)*, vol. 34, no. 1, pp. 1–47, 2002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
